Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'photo', 'sketch']
Target     ['cartoon']
# classes  7
# train_x  5,349
# val      2,297
# test     2,344
---------  -----------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/167] time 0.096 (0.135) data 0.000 (0.021) loss 1.1251 (1.3252) teacher_loss 0.3994 (0.5547) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.7256 (0.7706) acc 90.6250 (80.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.3708 (0.3282) teacher/usage_max 0.4193 (0.4350) teacher/usage_min 0.2038 (0.2398) teacher/usage_std 0.0932 (0.0821) nleep/row_max_mean 1594.2917 (1592.2350) nleep/row_max_std 70.5001 (88.9806) nleep/row_min_mean 1586.9058 (1581.4936) lr 1.0000e-05 eta 0:18:41
epoch [1/50] batch [40/167] time 0.084 (0.121) data 0.000 (0.010) loss 1.0961 (1.2031) teacher_loss 0.6269 (0.4958) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0006 (0.0002) kd_loss 0.4689 (0.7072) acc 71.8750 (82.4219) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.6281 (0.3904) teacher/usage_max 0.4164 (0.4338) teacher/usage_min 0.2122 (0.2394) teacher/usage_std 0.0876 (0.0824) nleep/row_max_mean 1630.4224 (1602.7514) nleep/row_max_std 56.8828 (78.7950) nleep/row_min_mean 1626.2610 (1594.3506) lr 1.0000e-05 eta 0:16:46
epoch [1/50] batch [60/167] time 0.181 (0.121) data 0.000 (0.007) loss 1.1606 (1.1595) teacher_loss 0.7800 (0.5176) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0011 (0.0004) kd_loss 0.3800 (0.6416) acc 75.0000 (81.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.7172 (0.4557) teacher/usage_max 0.3850 (0.4307) teacher/usage_min 0.2699 (0.2396) teacher/usage_std 0.0477 (0.0814) nleep/row_max_mean 1603.6860 (1604.3981) nleep/row_max_std 60.1395 (74.7135) nleep/row_min_mean 1600.8701 (1597.4224) lr 1.0000e-05 eta 0:16:39
epoch [1/50] batch [80/167] time 0.087 (0.118) data 0.001 (0.005) loss 0.6587 (1.0891) teacher_loss 0.3709 (0.5103) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0013 (0.0006) kd_loss 0.2871 (0.5785) acc 84.3750 (82.1875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8121 (0.5190) teacher/usage_max 0.4027 (0.4248) teacher/usage_min 0.2957 (0.2460) teacher/usage_std 0.0491 (0.0759) nleep/row_max_mean 1603.6765 (1604.2204) nleep/row_max_std 66.2074 (71.0573) nleep/row_min_mean 1601.6045 (1598.2914) lr 1.0000e-05 eta 0:16:12
epoch [1/50] batch [100/167] time 0.162 (0.123) data 0.000 (0.004) loss 0.7408 (1.0396) teacher_loss 0.3775 (0.5048) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0023 (0.0009) kd_loss 0.3618 (0.5342) acc 84.3750 (82.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3300 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7389 (0.5634) teacher/usage_max 0.4423 (0.4178) teacher/usage_min 0.2292 (0.2504) teacher/usage_std 0.0871 (0.0712) nleep/row_max_mean 1598.5435 (1604.5206) nleep/row_max_std 56.8587 (69.4654) nleep/row_min_mean 1595.8143 (1599.2747) lr 1.0000e-05 eta 0:16:52
epoch [1/50] batch [120/167] time 0.148 (0.128) data 0.000 (0.004) loss 0.9593 (0.9960) teacher_loss 0.6597 (0.5004) loss_zs_kd 0.0013 (0.0002) loss_oracle 0.0055 (0.0016) kd_loss 0.2962 (0.4947) acc 75.0000 (82.2135) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8024 (0.6032) teacher/usage_max 0.3877 (0.4155) teacher/usage_min 0.2839 (0.2537) teacher/usage_std 0.0425 (0.0687) nleep/row_max_mean 1603.3531 (1605.0054) nleep/row_max_std 59.4975 (68.3477) nleep/row_min_mean 1601.2231 (1600.2733) lr 1.0000e-05 eta 0:17:32
epoch [1/50] batch [140/167] time 0.162 (0.132) data 0.000 (0.003) loss 0.5877 (0.9523) teacher_loss 0.2939 (0.4854) loss_zs_kd 0.0004 (0.0003) loss_oracle 0.0141 (0.0027) kd_loss 0.2866 (0.4654) acc 90.6250 (82.6786) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8140 (0.6327) teacher/usage_max 0.4830 (0.4176) teacher/usage_min 0.2264 (0.2543) teacher/usage_std 0.1090 (0.0694) nleep/row_max_mean 1600.1873 (1604.7725) nleep/row_max_std 58.6813 (67.3522) nleep/row_min_mean 1598.0599 (1600.4200) lr 1.0000e-05 eta 0:18:02
epoch [1/50] batch [160/167] time 0.152 (0.134) data 0.000 (0.003) loss 0.9641 (0.9240) teacher_loss 0.6650 (0.4813) loss_zs_kd 0.0006 (0.0004) loss_oracle 0.0110 (0.0039) kd_loss 0.2933 (0.4406) acc 81.2500 (82.9297) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3385 (0.3383) gate/usage_min 0.3298 (0.3299) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.8075 (0.6578) teacher/usage_max 0.4989 (0.4250) teacher/usage_min 0.2088 (0.2502) teacher/usage_std 0.1219 (0.0743) nleep/row_max_mean 1619.3062 (1605.1982) nleep/row_max_std 62.6341 (66.9502) nleep/row_min_mean 1617.1626 (1601.1420) lr 1.0000e-05 eta 0:18:20
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,172
* accuracy: 94.6%
* error: 5.4%
* macro_f1: 95.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      94.6%, epoch: 1 *******
******* Domain c best val test acc: 99.2%, epoch: 1 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [2/50] batch [20/167] time 0.140 (0.157) data 0.000 (0.013) loss 1.3290 (1.0235) teacher_loss 0.3831 (0.3829) loss_zs_kd 0.0063 (0.0077) loss_oracle 0.3844 (0.3059) kd_loss 0.7506 (0.4838) acc 81.2500 (87.0312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3369 (0.3377) gate/usage_min 0.3288 (0.3296) gate/usage_std 0.0034 (0.0034) teacher/entropy 0.3474 (0.6167) teacher/usage_max 0.8467 (0.7031) teacher/usage_min 0.0136 (0.0981) teacher/usage_std 0.3666 (0.2657) nleep/row_max_mean 1608.4635 (1592.8193) nleep/row_max_std 55.4134 (66.6647) nleep/row_min_mean 1601.4532 (1588.8588) lr 2.0000e-03 eta 0:21:21
epoch [2/50] batch [40/167] time 0.154 (0.152) data 0.000 (0.006) loss 1.3730 (1.1377) teacher_loss 0.6810 (0.4125) loss_zs_kd 0.0052 (0.0068) loss_oracle 0.3399 (0.3395) kd_loss 0.5195 (0.5520) acc 71.8750 (85.8594) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3389 (0.3374) gate/usage_min 0.3272 (0.3287) gate/usage_std 0.0048 (0.0037) teacher/entropy 0.5799 (0.5466) teacher/usage_max 0.5052 (0.7000) teacher/usage_min 0.0079 (0.0611) teacher/usage_std 0.2303 (0.2777) nleep/row_max_mean 1590.8091 (1593.4690) nleep/row_max_std 67.1758 (64.2359) nleep/row_min_mean 1580.7224 (1587.4163) lr 2.0000e-03 eta 0:20:36
epoch [2/50] batch [60/167] time 0.070 (0.128) data 0.000 (0.004) loss 1.2407 (1.1896) teacher_loss 0.2833 (0.4109) loss_zs_kd 0.0145 (0.0077) loss_oracle 0.3419 (0.3420) kd_loss 0.7791 (0.6038) acc 90.6250 (85.5729) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3410 (0.3384) gate/usage_min 0.3284 (0.3283) gate/usage_std 0.0055 (0.0042) teacher/entropy 0.3266 (0.4963) teacher/usage_max 0.7784 (0.6824) teacher/usage_min 0.0184 (0.0489) teacher/usage_std 0.3236 (0.2723) nleep/row_max_mean 1570.1079 (1593.3868) nleep/row_max_std 74.0262 (65.0645) nleep/row_min_mean 1558.2224 (1585.4564) lr 2.0000e-03 eta 0:17:23
epoch [2/50] batch [80/167] time 0.091 (0.122) data 0.000 (0.003) loss 1.7800 (1.2588) teacher_loss 0.6036 (0.4100) loss_zs_kd 0.0153 (0.0083) loss_oracle 0.4549 (0.3546) kd_loss 0.9412 (0.6674) acc 71.8750 (85.4688) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3411 (0.3391) gate/usage_min 0.3273 (0.3283) gate/usage_std 0.0058 (0.0046) teacher/entropy 0.1612 (0.4337) teacher/usage_max 0.8974 (0.7187) teacher/usage_min 0.0364 (0.0422) teacher/usage_std 0.3990 (0.2927) nleep/row_max_mean 1608.0149 (1593.4599) nleep/row_max_std 50.5274 (64.2058) nleep/row_min_mean 1590.7959 (1583.9080) lr 2.0000e-03 eta 0:16:26
epoch [2/50] batch [100/167] time 0.168 (0.120) data 0.000 (0.003) loss 1.5382 (1.3178) teacher_loss 0.3550 (0.4092) loss_zs_kd 0.0112 (0.0092) loss_oracle 0.3710 (0.3550) kd_loss 0.9921 (0.7265) acc 87.5000 (85.6250) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3394 (0.3393) gate/usage_min 0.3240 (0.3278) gate/usage_std 0.0067 (0.0049) teacher/entropy 0.0975 (0.3735) teacher/usage_max 0.9492 (0.7592) teacher/usage_min 0.0240 (0.0378) teacher/usage_std 0.4355 (0.3174) nleep/row_max_mean 1604.5896 (1595.0860) nleep/row_max_std 71.5021 (63.2198) nleep/row_min_mean 1586.1265 (1584.0356) lr 2.0000e-03 eta 0:16:12
epoch [2/50] batch [120/167] time 0.193 (0.119) data 0.000 (0.002) loss 1.6393 (1.3694) teacher_loss 0.4654 (0.4127) loss_zs_kd 0.0117 (0.0100) loss_oracle 0.3006 (0.3651) kd_loss 1.0178 (0.7691) acc 84.3750 (85.4427) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3417 (0.3394) gate/usage_min 0.3208 (0.3269) gate/usage_std 0.0090 (0.0054) teacher/entropy 0.0572 (0.3280) teacher/usage_max 0.9796 (0.7895) teacher/usage_min 0.0004 (0.0345) teacher/usage_std 0.4570 (0.3362) nleep/row_max_mean 1597.3530 (1594.5862) nleep/row_max_std 69.1411 (63.4745) nleep/row_min_mean 1576.2886 (1582.2770) lr 2.0000e-03 eta 0:16:01
epoch [2/50] batch [140/167] time 0.072 (0.119) data 0.000 (0.002) loss 1.5544 (1.4028) teacher_loss 0.3303 (0.4090) loss_zs_kd 0.0122 (0.0103) loss_oracle 0.3505 (0.3690) kd_loss 1.0428 (0.8042) acc 87.5000 (85.6473) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3473 (0.3402) gate/usage_min 0.3178 (0.3258) gate/usage_std 0.0121 (0.0061) teacher/entropy 0.0150 (0.2887) teacher/usage_max 0.9968 (0.8152) teacher/usage_min 0.0000 (0.0299) teacher/usage_std 0.4691 (0.3524) nleep/row_max_mean 1610.1021 (1595.3369) nleep/row_max_std 54.2440 (63.2595) nleep/row_min_mean 1586.1453 (1581.6039) lr 2.0000e-03 eta 0:15:55
epoch [2/50] batch [160/167] time 0.144 (0.115) data 0.000 (0.002) loss 1.4368 (1.4220) teacher_loss 0.2473 (0.4017) loss_zs_kd 0.0048 (0.0100) loss_oracle 0.4129 (0.3704) kd_loss 0.9806 (0.8300) acc 93.7500 (85.7812) gate/entropy 1.0975 (1.0983) gate/usage_max 0.3531 (0.3414) gate/usage_min 0.3145 (0.3246) gate/usage_std 0.0158 (0.0071) teacher/entropy 0.0628 (0.2577) teacher/usage_max 0.9784 (0.8346) teacher/usage_min 0.0013 (0.0266) teacher/usage_std 0.4562 (0.3647) nleep/row_max_mean 1577.4731 (1595.8120) nleep/row_max_std 68.4132 (63.3891) nleep/row_min_mean 1556.5237 (1580.7911) lr 2.0000e-03 eta 0:15:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      95.9%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [3/50] batch [20/167] time 0.159 (0.167) data 0.000 (0.017) loss 1.4040 (1.6339) teacher_loss 0.2518 (0.4644) loss_zs_kd 0.0063 (0.0102) loss_oracle 0.3816 (0.3726) kd_loss 0.9582 (0.9781) acc 93.7500 (83.1250) gate/entropy 1.0966 (1.0970) gate/usage_max 0.3611 (0.3582) gate/usage_min 0.3101 (0.3117) gate/usage_std 0.0211 (0.0191) teacher/entropy 0.0695 (0.0534) teacher/usage_max 0.9395 (0.9638) teacher/usage_min 0.0013 (0.0019) teacher/usage_std 0.4293 (0.4461) nleep/row_max_mean 1595.7692 (1601.0668) nleep/row_max_std 68.2774 (64.0075) nleep/row_min_mean 1573.6843 (1577.1714) lr 1.9980e-03 eta 0:22:18
epoch [3/50] batch [40/167] time 0.149 (0.158) data 0.000 (0.009) loss 1.7309 (1.5869) teacher_loss 0.6142 (0.4256) loss_zs_kd 0.0195 (0.0106) loss_oracle 0.3347 (0.3760) kd_loss 0.9395 (0.9680) acc 75.0000 (84.9219) gate/entropy 1.0957 (1.0966) gate/usage_max 0.3680 (0.3615) gate/usage_min 0.3068 (0.3100) gate/usage_std 0.0256 (0.0213) teacher/entropy 0.0680 (0.0559) teacher/usage_max 0.9566 (0.9588) teacher/usage_min 0.0003 (0.0018) teacher/usage_std 0.4410 (0.4427) nleep/row_max_mean 1572.5127 (1598.2353) nleep/row_max_std 80.3691 (64.3833) nleep/row_min_mean 1548.6807 (1573.8432) lr 1.9980e-03 eta 0:20:58
epoch [3/50] batch [60/167] time 0.147 (0.156) data 0.000 (0.006) loss 1.4730 (1.5760) teacher_loss 0.3258 (0.4173) loss_zs_kd 0.0114 (0.0101) loss_oracle 0.4321 (0.3832) kd_loss 0.9255 (0.9621) acc 90.6250 (85.1562) gate/entropy 1.0945 (1.0961) gate/usage_max 0.3750 (0.3649) gate/usage_min 0.3034 (0.3083) gate/usage_std 0.0304 (0.0236) teacher/entropy 0.0704 (0.0540) teacher/usage_max 0.9270 (0.9542) teacher/usage_min 0.0001 (0.0015) teacher/usage_std 0.4208 (0.4396) nleep/row_max_mean 1596.2578 (1599.2779) nleep/row_max_std 69.4197 (62.2792) nleep/row_min_mean 1572.6039 (1574.5306) lr 1.9980e-03 eta 0:20:37
epoch [3/50] batch [80/167] time 0.157 (0.157) data 0.000 (0.005) loss 1.3187 (1.5707) teacher_loss 0.1771 (0.4148) loss_zs_kd 0.0002 (0.0102) loss_oracle 0.4391 (0.3956) kd_loss 0.9219 (0.9530) acc 96.8750 (85.0000) gate/entropy 1.0933 (1.0955) gate/usage_max 0.3814 (0.3683) gate/usage_min 0.3003 (0.3066) gate/usage_std 0.0348 (0.0259) teacher/entropy 0.0607 (0.0563) teacher/usage_max 0.9215 (0.9468) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.4171 (0.4345) nleep/row_max_mean 1579.6040 (1599.2252) nleep/row_max_std 77.5153 (61.7609) nleep/row_min_mean 1557.9468 (1574.5408) lr 1.9980e-03 eta 0:20:49
epoch [3/50] batch [100/167] time 0.152 (0.157) data 0.000 (0.004) loss 1.2256 (1.5466) teacher_loss 0.2653 (0.4045) loss_zs_kd 0.0089 (0.0098) loss_oracle 0.2766 (0.3958) kd_loss 0.8176 (0.9393) acc 90.6250 (85.2500) gate/entropy 1.0919 (1.0949) gate/usage_max 0.3874 (0.3715) gate/usage_min 0.2974 (0.3051) gate/usage_std 0.0389 (0.0281) teacher/entropy 0.1763 (0.0654) teacher/usage_max 0.8249 (0.9325) teacher/usage_min 0.0063 (0.0028) teacher/usage_std 0.3539 (0.4251) nleep/row_max_mean 1592.0051 (1597.6859) nleep/row_max_std 63.5520 (62.2789) nleep/row_min_mean 1571.2739 (1573.5613) lr 1.9980e-03 eta 0:20:44
epoch [3/50] batch [120/167] time 0.136 (0.157) data 0.000 (0.003) loss 1.6421 (1.5336) teacher_loss 0.5294 (0.3974) loss_zs_kd 0.0136 (0.0096) loss_oracle 0.4382 (0.4050) kd_loss 0.8868 (0.9289) acc 81.2500 (85.4948) gate/entropy 1.0908 (1.0943) gate/usage_max 0.3923 (0.3746) gate/usage_min 0.2953 (0.3036) gate/usage_std 0.0422 (0.0302) teacher/entropy 0.1039 (0.0744) teacher/usage_max 0.8051 (0.9098) teacher/usage_min 0.0083 (0.0049) teacher/usage_std 0.3414 (0.4104) nleep/row_max_mean 1606.6571 (1596.8907) nleep/row_max_std 52.9518 (62.3966) nleep/row_min_mean 1585.6333 (1573.2978) lr 1.9980e-03 eta 0:20:37
epoch [3/50] batch [140/167] time 0.159 (0.157) data 0.000 (0.003) loss 1.2398 (1.5295) teacher_loss 0.1706 (0.3984) loss_zs_kd 0.0110 (0.0099) loss_oracle 0.4268 (0.4138) kd_loss 0.8503 (0.9193) acc 93.7500 (85.7366) gate/entropy 1.0899 (1.0937) gate/usage_max 0.3956 (0.3774) gate/usage_min 0.2938 (0.3023) gate/usage_std 0.0446 (0.0321) teacher/entropy 0.1662 (0.0854) teacher/usage_max 0.6841 (0.8807) teacher/usage_min 0.0959 (0.0154) teacher/usage_std 0.2532 (0.3905) nleep/row_max_mean 1602.4270 (1596.1450) nleep/row_max_std 64.2988 (62.7009) nleep/row_min_mean 1581.4988 (1573.0187) lr 1.9980e-03 eta 0:20:39
epoch [3/50] batch [160/167] time 0.065 (0.156) data 0.000 (0.002) loss 1.5996 (1.5191) teacher_loss 0.3783 (0.3877) loss_zs_kd 0.0246 (0.0104) loss_oracle 0.4514 (0.4193) kd_loss 0.9833 (0.9166) acc 84.3750 (86.0938) gate/entropy 1.0892 (1.0932) gate/usage_max 0.3980 (0.3799) gate/usage_min 0.2925 (0.3011) gate/usage_std 0.0463 (0.0338) teacher/entropy 0.1265 (0.0941) teacher/usage_max 0.3384 (0.8384) teacher/usage_min 0.3261 (0.0351) teacher/usage_std 0.0053 (0.3614) nleep/row_max_mean 1578.6716 (1595.3638) nleep/row_max_std 58.5695 (62.6896) nleep/row_min_mean 1559.0991 (1572.6188) lr 1.9980e-03 eta 0:20:25
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      95.9%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [4/50] batch [20/167] time 0.112 (0.135) data 0.000 (0.017) loss 1.3346 (1.4739) teacher_loss 0.1078 (0.3141) loss_zs_kd 0.0069 (0.0215) loss_oracle 0.5495 (0.5143) kd_loss 0.9486 (0.8920) acc 96.8750 (87.9688) gate/entropy 1.0890 (1.0891) gate/usage_max 0.3988 (0.3985) gate/usage_min 0.2914 (0.2919) gate/usage_std 0.0469 (0.0467) teacher/entropy 0.1705 (0.1855) teacher/usage_max 0.4293 (0.4409) teacher/usage_min 0.2779 (0.2260) teacher/usage_std 0.0681 (0.0918) nleep/row_max_mean 1598.4974 (1590.8333) nleep/row_max_std 65.8132 (59.8482) nleep/row_min_mean 1577.3391 (1570.2410) lr 1.9921e-03 eta 0:17:33
epoch [4/50] batch [40/167] time 0.183 (0.117) data 0.000 (0.008) loss 1.4758 (1.4961) teacher_loss 0.3225 (0.3125) loss_zs_kd 0.0114 (0.0202) loss_oracle 0.4951 (0.5362) kd_loss 0.9000 (0.9054) acc 90.6250 (88.5156) gate/entropy 1.0892 (1.0891) gate/usage_max 0.3978 (0.3984) gate/usage_min 0.2910 (0.2915) gate/usage_std 0.0463 (0.0467) teacher/entropy 0.2026 (0.1828) teacher/usage_max 0.3583 (0.4390) teacher/usage_min 0.2889 (0.2277) teacher/usage_std 0.0315 (0.0898) nleep/row_max_mean 1556.9259 (1584.8760) nleep/row_max_std 59.4680 (62.1944) nleep/row_min_mean 1541.1895 (1564.6675) lr 1.9921e-03 eta 0:15:10
epoch [4/50] batch [60/167] time 0.088 (0.118) data 0.001 (0.006) loss 1.4546 (1.5084) teacher_loss 0.1557 (0.3039) loss_zs_kd 0.0089 (0.0185) loss_oracle 0.5796 (0.5450) kd_loss 1.0046 (0.9227) acc 96.8750 (89.0625) gate/entropy 1.0894 (1.0891) gate/usage_max 0.3965 (0.3980) gate/usage_min 0.2901 (0.2912) gate/usage_std 0.0457 (0.0465) teacher/entropy 0.1121 (0.1705) teacher/usage_max 0.4481 (0.4473) teacher/usage_min 0.2754 (0.2277) teacher/usage_std 0.0812 (0.0935) nleep/row_max_mean 1579.4935 (1584.0772) nleep/row_max_std 60.8927 (62.7001) nleep/row_min_mean 1557.7830 (1563.6644) lr 1.9921e-03 eta 0:15:16
epoch [4/50] batch [80/167] time 0.093 (0.118) data 0.000 (0.004) loss 1.5963 (1.5296) teacher_loss 0.2234 (0.3044) loss_zs_kd 0.0227 (0.0183) loss_oracle 0.6171 (0.5659) kd_loss 1.0530 (0.9331) acc 90.6250 (89.0234) gate/entropy 1.0898 (1.0892) gate/usage_max 0.3948 (0.3974) gate/usage_min 0.2894 (0.2908) gate/usage_std 0.0448 (0.0461) teacher/entropy 0.0425 (0.1636) teacher/usage_max 0.3644 (0.4580) teacher/usage_min 0.2825 (0.2215) teacher/usage_std 0.0363 (0.1009) nleep/row_max_mean 1580.7013 (1584.9218) nleep/row_max_std 67.0633 (63.0459) nleep/row_min_mean 1559.9935 (1564.2983) lr 1.9921e-03 eta 0:15:20
epoch [4/50] batch [100/167] time 0.124 (0.118) data 0.000 (0.004) loss 1.9814 (1.5735) teacher_loss 0.5278 (0.3122) loss_zs_kd 0.0346 (0.0195) loss_oracle 0.7960 (0.5959) kd_loss 1.0382 (0.9536) acc 68.7500 (88.5000) gate/entropy 1.0903 (1.0894) gate/usage_max 0.3921 (0.3967) gate/usage_min 0.2889 (0.2904) gate/usage_std 0.0433 (0.0457) teacher/entropy 0.0849 (0.1497) teacher/usage_max 0.6432 (0.4732) teacher/usage_min 0.1783 (0.2140) teacher/usage_std 0.2191 (0.1109) nleep/row_max_mean 1570.7478 (1584.8980) nleep/row_max_std 73.8293 (62.9732) nleep/row_min_mean 1546.5671 (1563.7653) lr 1.9921e-03 eta 0:15:14
epoch [4/50] batch [120/167] time 0.161 (0.123) data 0.000 (0.003) loss 2.2808 (1.6006) teacher_loss 0.7625 (0.3206) loss_zs_kd 0.0520 (0.0202) loss_oracle 0.8191 (0.6153) kd_loss 1.0827 (0.9622) acc 62.5000 (88.1771) gate/entropy 1.0909 (1.0896) gate/usage_max 0.3890 (0.3956) gate/usage_min 0.2887 (0.2902) gate/usage_std 0.0417 (0.0452) teacher/entropy 0.0524 (0.1439) teacher/usage_max 0.7669 (0.4862) teacher/usage_min 0.0754 (0.2097) teacher/usage_std 0.3084 (0.1189) nleep/row_max_mean 1584.4414 (1584.3281) nleep/row_max_std 43.0200 (62.3747) nleep/row_min_mean 1557.6560 (1562.9513) lr 1.9921e-03 eta 0:15:50
epoch [4/50] batch [140/167] time 0.142 (0.127) data 0.000 (0.003) loss 1.8380 (1.6271) teacher_loss 0.3755 (0.3264) loss_zs_kd 0.0122 (0.0203) loss_oracle 0.7960 (0.6368) kd_loss 1.0584 (0.9722) acc 84.3750 (87.9018) gate/entropy 1.0916 (1.0898) gate/usage_max 0.3854 (0.3944) gate/usage_min 0.2892 (0.2900) gate/usage_std 0.0397 (0.0446) teacher/entropy 0.0636 (0.1378) teacher/usage_max 0.5692 (0.4946) teacher/usage_min 0.1756 (0.2021) teacher/usage_std 0.1699 (0.1257) nleep/row_max_mean 1576.9625 (1582.7071) nleep/row_max_std 64.2672 (62.3745) nleep/row_min_mean 1555.0112 (1561.3980) lr 1.9921e-03 eta 0:16:16
epoch [4/50] batch [160/167] time 0.155 (0.129) data 0.000 (0.002) loss 1.9072 (1.6477) teacher_loss 0.4656 (0.3278) loss_zs_kd 0.0427 (0.0209) loss_oracle 0.7918 (0.6562) kd_loss 1.0245 (0.9814) acc 81.2500 (87.6758) gate/entropy 1.0922 (1.0901) gate/usage_max 0.3816 (0.3930) gate/usage_min 0.2895 (0.2899) gate/usage_std 0.0377 (0.0438) teacher/entropy 0.1125 (0.1310) teacher/usage_max 0.4507 (0.5050) teacher/usage_min 0.1607 (0.1937) teacher/usage_std 0.1247 (0.1338) nleep/row_max_mean 1565.0612 (1582.0885) nleep/row_max_std 63.9381 (62.1612) nleep/row_min_mean 1542.9717 (1560.5718) lr 1.9921e-03 eta 0:16:34
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      95.9%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [5/50] batch [20/167] time 0.162 (0.167) data 0.000 (0.014) loss 1.8435 (1.7450) teacher_loss 0.4379 (0.3017) loss_zs_kd 0.0373 (0.0213) loss_oracle 0.7297 (0.7321) kd_loss 1.0220 (1.0666) acc 84.3750 (88.2812) gate/entropy 1.0930 (1.0927) gate/usage_max 0.3765 (0.3784) gate/usage_min 0.2899 (0.2897) gate/usage_std 0.0354 (0.0362) teacher/entropy 0.0896 (0.0656) teacher/usage_max 0.5890 (0.5738) teacher/usage_min 0.1656 (0.1060) teacher/usage_std 0.1837 (0.1973) nleep/row_max_mean 1562.6482 (1579.7052) nleep/row_max_std 64.1169 (59.5113) nleep/row_min_mean 1539.3628 (1555.8754) lr 1.9823e-03 eta 0:21:16
epoch [5/50] batch [40/167] time 0.145 (0.156) data 0.000 (0.007) loss 1.5757 (1.7457) teacher_loss 0.1970 (0.3109) loss_zs_kd 0.0119 (0.0190) loss_oracle 0.7202 (0.7465) kd_loss 1.0126 (1.0521) acc 93.7500 (87.9688) gate/entropy 1.0934 (1.0930) gate/usage_max 0.3725 (0.3764) gate/usage_min 0.2900 (0.2898) gate/usage_std 0.0338 (0.0354) teacher/entropy 0.0943 (0.0720) teacher/usage_max 0.6485 (0.5930) teacher/usage_min 0.1266 (0.1150) teacher/usage_std 0.2265 (0.2029) nleep/row_max_mean 1559.2544 (1577.3594) nleep/row_max_std 66.4439 (58.9837) nleep/row_min_mean 1536.5892 (1553.8916) lr 1.9823e-03 eta 0:19:48
epoch [5/50] batch [60/167] time 0.083 (0.151) data 0.000 (0.005) loss 2.1806 (1.7655) teacher_loss 0.6907 (0.3276) loss_zs_kd 0.0307 (0.0210) loss_oracle 0.8109 (0.7585) kd_loss 1.0691 (1.0482) acc 71.8750 (87.3438) gate/entropy 1.0937 (1.0932) gate/usage_max 0.3687 (0.3744) gate/usage_min 0.2899 (0.2899) gate/usage_std 0.0327 (0.0346) teacher/entropy 0.0447 (0.0718) teacher/usage_max 0.6421 (0.5917) teacher/usage_min 0.0781 (0.1184) teacher/usage_std 0.2334 (0.2013) nleep/row_max_mean 1566.1511 (1575.5459) nleep/row_max_std 59.3163 (58.6522) nleep/row_min_mean 1540.1680 (1551.9979) lr 1.9823e-03 eta 0:19:07
epoch [5/50] batch [80/167] time 0.101 (0.136) data 0.000 (0.004) loss 1.5734 (1.7702) teacher_loss 0.1482 (0.3349) loss_zs_kd 0.0190 (0.0205) loss_oracle 0.7326 (0.7632) kd_loss 1.0494 (1.0435) acc 96.8750 (87.2656) gate/entropy 1.0940 (1.0933) gate/usage_max 0.3648 (0.3725) gate/usage_min 0.2896 (0.2899) gate/usage_std 0.0319 (0.0340) teacher/entropy 0.0635 (0.0731) teacher/usage_max 0.6115 (0.6031) teacher/usage_min 0.0777 (0.1134) teacher/usage_std 0.2185 (0.2084) nleep/row_max_mean 1580.9678 (1574.7823) nleep/row_max_std 51.6874 (58.8663) nleep/row_min_mean 1555.6313 (1550.6516) lr 1.9823e-03 eta 0:17:15
epoch [5/50] batch [100/167] time 0.118 (0.136) data 0.000 (0.003) loss 1.5380 (1.7499) teacher_loss 0.3031 (0.3268) loss_zs_kd 0.0240 (0.0196) loss_oracle 0.6531 (0.7576) kd_loss 0.8964 (1.0345) acc 90.6250 (87.6875) gate/entropy 1.0940 (1.0935) gate/usage_max 0.3610 (0.3705) gate/usage_min 0.2892 (0.2898) gate/usage_std 0.0316 (0.0335) teacher/entropy 0.1868 (0.0768) teacher/usage_max 0.5868 (0.6129) teacher/usage_min 0.2034 (0.1148) teacher/usage_std 0.1792 (0.2132) nleep/row_max_mean 1551.4855 (1574.0314) nleep/row_max_std 59.5540 (58.8995) nleep/row_min_mean 1526.6602 (1549.4398) lr 1.9823e-03 eta 0:17:11
epoch [5/50] batch [120/167] time 0.090 (0.134) data 0.000 (0.003) loss 1.5878 (1.7452) teacher_loss 0.2407 (0.3287) loss_zs_kd 0.0192 (0.0192) loss_oracle 0.6255 (0.7550) kd_loss 1.0248 (1.0294) acc 90.6250 (87.6042) gate/entropy 1.0940 (1.0936) gate/usage_max 0.3572 (0.3686) gate/usage_min 0.2886 (0.2896) gate/usage_std 0.0317 (0.0332) teacher/entropy 0.0627 (0.0782) teacher/usage_max 0.5292 (0.6176) teacher/usage_min 0.2157 (0.1151) teacher/usage_std 0.1394 (0.2159) nleep/row_max_mean 1567.6949 (1574.4139) nleep/row_max_std 60.6672 (57.9763) nleep/row_min_mean 1543.2153 (1549.3348) lr 1.9823e-03 eta 0:16:52
epoch [5/50] batch [140/167] time 0.097 (0.130) data 0.000 (0.002) loss 1.6755 (1.7438) teacher_loss 0.2495 (0.3312) loss_zs_kd 0.0110 (0.0189) loss_oracle 0.7616 (0.7536) kd_loss 1.0396 (1.0263) acc 87.5000 (87.5670) gate/entropy 1.0940 (1.0936) gate/usage_max 0.3579 (0.3669) gate/usage_min 0.2885 (0.2895) gate/usage_std 0.0317 (0.0330) teacher/entropy 0.0626 (0.0790) teacher/usage_max 0.4888 (0.6126) teacher/usage_min 0.1705 (0.1174) teacher/usage_std 0.1300 (0.2127) nleep/row_max_mean 1553.2170 (1573.4870) nleep/row_max_std 66.2795 (58.3391) nleep/row_min_mean 1528.5319 (1548.2635) lr 1.9823e-03 eta 0:16:22
epoch [5/50] batch [160/167] time 0.079 (0.128) data 0.000 (0.002) loss 1.6024 (1.7314) teacher_loss 0.1793 (0.3198) loss_zs_kd 0.0093 (0.0181) loss_oracle 0.7482 (0.7507) kd_loss 1.0443 (1.0271) acc 93.7500 (87.9688) gate/entropy 1.0941 (1.0937) gate/usage_max 0.3611 (0.3660) gate/usage_min 0.2894 (0.2894) gate/usage_std 0.0314 (0.0328) teacher/entropy 0.0644 (0.0777) teacher/usage_max 0.5798 (0.6077) teacher/usage_min 0.0062 (0.1117) teacher/usage_std 0.2410 (0.2124) nleep/row_max_mean 1570.7798 (1572.4083) nleep/row_max_std 54.1856 (57.9878) nleep/row_min_mean 1544.4099 (1547.0917) lr 1.9823e-03 eta 0:15:59
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,205
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.0%, epoch: 5 *******
******* Domain c best val test acc: 99.2%, epoch: 5 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [6/50] batch [20/167] time 0.157 (0.161) data 0.000 (0.013) loss 1.8927 (1.7577) teacher_loss 0.4415 (0.3392) loss_zs_kd 0.0270 (0.0258) loss_oracle 0.8209 (0.7704) kd_loss 1.0273 (1.0204) acc 87.5000 (87.3438) gate/entropy 1.0939 (1.0940) gate/usage_max 0.3665 (0.3645) gate/usage_min 0.2897 (0.2896) gate/usage_std 0.0322 (0.0318) teacher/entropy 0.0524 (0.0620) teacher/usage_max 0.6234 (0.6162) teacher/usage_min 0.0687 (0.0797) teacher/usage_std 0.2272 (0.2271) nleep/row_max_mean 1577.7522 (1568.6047) nleep/row_max_std 46.7224 (49.2328) nleep/row_min_mean 1549.7581 (1541.0164) lr 1.9686e-03 eta 0:20:07
epoch [6/50] batch [40/167] time 0.141 (0.154) data 0.000 (0.006) loss 1.4971 (1.7306) teacher_loss 0.1891 (0.3213) loss_zs_kd 0.0102 (0.0238) loss_oracle 0.6463 (0.7618) kd_loss 0.9798 (1.0165) acc 90.6250 (87.7344) gate/entropy 1.0937 (1.0939) gate/usage_max 0.3695 (0.3663) gate/usage_min 0.2903 (0.2898) gate/usage_std 0.0327 (0.0321) teacher/entropy 0.1003 (0.0635) teacher/usage_max 0.5701 (0.6113) teacher/usage_min 0.1117 (0.0834) teacher/usage_std 0.1875 (0.2230) nleep/row_max_mean 1553.6498 (1567.9461) nleep/row_max_std 68.2329 (51.7596) nleep/row_min_mean 1523.8138 (1539.4166) lr 1.9686e-03 eta 0:19:12
epoch [6/50] batch [60/167] time 0.149 (0.153) data 0.000 (0.004) loss 1.8147 (1.7082) teacher_loss 0.5206 (0.3157) loss_zs_kd 0.0186 (0.0226) loss_oracle 0.6519 (0.7505) kd_loss 0.9589 (1.0059) acc 75.0000 (87.9167) gate/entropy 1.0933 (1.0937) gate/usage_max 0.3737 (0.3682) gate/usage_min 0.2900 (0.2899) gate/usage_std 0.0342 (0.0326) teacher/entropy 0.0813 (0.0682) teacher/usage_max 0.7586 (0.6286) teacher/usage_min 0.0289 (0.0756) teacher/usage_std 0.3099 (0.2330) nleep/row_max_mean 1548.3547 (1567.4852) nleep/row_max_std 69.1745 (54.0332) nleep/row_min_mean 1517.8669 (1537.6763) lr 1.9686e-03 eta 0:19:02
epoch [6/50] batch [80/167] time 0.161 (0.151) data 0.000 (0.003) loss 1.6075 (1.7047) teacher_loss 0.2629 (0.3279) loss_zs_kd 0.0060 (0.0207) loss_oracle 0.7526 (0.7406) kd_loss 0.9652 (0.9962) acc 87.5000 (87.5781) gate/entropy 1.0925 (1.0935) gate/usage_max 0.3793 (0.3703) gate/usage_min 0.2889 (0.2898) gate/usage_std 0.0369 (0.0334) teacher/entropy 0.0938 (0.0700) teacher/usage_max 0.6612 (0.6537) teacher/usage_min 0.0121 (0.0643) teacher/usage_std 0.2650 (0.2484) nleep/row_max_mean 1573.2137 (1568.4758) nleep/row_max_std 45.1993 (54.6753) nleep/row_min_mean 1536.4619 (1537.4026) lr 1.9686e-03 eta 0:18:42
epoch [6/50] batch [100/167] time 0.145 (0.150) data 0.000 (0.003) loss 1.8526 (1.7015) teacher_loss 0.5138 (0.3357) loss_zs_kd 0.0149 (0.0190) loss_oracle 0.7310 (0.7372) kd_loss 0.9658 (0.9877) acc 81.2500 (87.2500) gate/entropy 1.0914 (1.0932) gate/usage_max 0.3852 (0.3727) gate/usage_min 0.2875 (0.2895) gate/usage_std 0.0401 (0.0344) teacher/entropy 0.0312 (0.0692) teacher/usage_max 0.8510 (0.6791) teacher/usage_min 0.0004 (0.0565) teacher/usage_std 0.3710 (0.2639) nleep/row_max_mean 1587.7632 (1569.2000) nleep/row_max_std 46.2010 (54.6477) nleep/row_min_mean 1544.8301 (1537.1926) lr 1.9686e-03 eta 0:18:30
epoch [6/50] batch [120/167] time 0.138 (0.148) data 0.000 (0.002) loss 1.7185 (1.7010) teacher_loss 0.3838 (0.3442) loss_zs_kd 0.0144 (0.0180) loss_oracle 0.7284 (0.7347) kd_loss 0.9633 (0.9804) acc 84.3750 (87.1094) gate/entropy 1.0901 (1.0928) gate/usage_max 0.3914 (0.3753) gate/usage_min 0.2860 (0.2890) gate/usage_std 0.0437 (0.0357) teacher/entropy 0.0277 (0.0694) teacher/usage_max 0.8286 (0.6931) teacher/usage_min 0.0000 (0.0502) teacher/usage_std 0.3571 (0.2733) nleep/row_max_mean 1577.1320 (1569.0559) nleep/row_max_std 66.3438 (55.6929) nleep/row_min_mean 1535.0271 (1536.1613) lr 1.9686e-03 eta 0:18:15
epoch [6/50] batch [140/167] time 0.130 (0.145) data 0.000 (0.002) loss 1.4496 (1.6910) teacher_loss 0.2096 (0.3471) loss_zs_kd 0.0020 (0.0168) loss_oracle 0.6012 (0.7239) kd_loss 0.9384 (0.9736) acc 90.6250 (87.0759) gate/entropy 1.0889 (1.0923) gate/usage_max 0.3968 (0.3780) gate/usage_min 0.2850 (0.2885) gate/usage_std 0.0469 (0.0370) teacher/entropy 0.0368 (0.0701) teacher/usage_max 0.8447 (0.7022) teacher/usage_min 0.0000 (0.0448) teacher/usage_std 0.3671 (0.2792) nleep/row_max_mean 1571.3091 (1567.5044) nleep/row_max_std 58.4714 (56.5339) nleep/row_min_mean 1533.3722 (1534.1943) lr 1.9686e-03 eta 0:17:49
epoch [6/50] batch [160/167] time 0.131 (0.145) data 0.000 (0.002) loss 1.5964 (1.6782) teacher_loss 0.2601 (0.3443) loss_zs_kd 0.0079 (0.0162) loss_oracle 0.7298 (0.7185) kd_loss 0.9674 (0.9665) acc 87.5000 (87.2266) gate/entropy 1.0874 (1.0918) gate/usage_max 0.4026 (0.3807) gate/usage_min 0.2838 (0.2880) gate/usage_std 0.0505 (0.0385) teacher/entropy 0.0393 (0.0697) teacher/usage_max 0.7220 (0.7141) teacher/usage_min 0.0000 (0.0396) teacher/usage_std 0.2973 (0.2868) nleep/row_max_mean 1553.4845 (1567.6729) nleep/row_max_std 62.4456 (56.5025) nleep/row_min_mean 1514.4955 (1533.7448) lr 1.9686e-03 eta 0:17:47
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.0%, epoch: 5 *******
******* Domain c best val test acc: 99.2%, epoch: 5 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [7/50] batch [20/167] time 0.185 (0.134) data 0.000 (0.016) loss 1.4984 (1.6267) teacher_loss 0.1762 (0.3529) loss_zs_kd 0.0189 (0.0125) loss_oracle 0.7535 (0.6955) kd_loss 0.9360 (0.9198) acc 93.7500 (85.7812) gate/entropy 1.0852 (1.0859) gate/usage_max 0.4104 (0.4078) gate/usage_min 0.2823 (0.2826) gate/usage_std 0.0554 (0.0538) teacher/entropy 0.0545 (0.0695) teacher/usage_max 0.7287 (0.7429) teacher/usage_min 0.0018 (0.0046) teacher/usage_std 0.3002 (0.3105) nleep/row_max_mean 1567.3357 (1566.6019) nleep/row_max_std 59.6308 (59.1265) nleep/row_min_mean 1532.1509 (1528.9460) lr 1.9511e-03 eta 0:16:25
epoch [7/50] batch [40/167] time 0.164 (0.129) data 0.000 (0.008) loss 1.4098 (1.6211) teacher_loss 0.0903 (0.3534) loss_zs_kd 0.0039 (0.0120) loss_oracle 0.7251 (0.6915) kd_loss 0.9551 (0.9159) acc 100.0000 (86.0156) gate/entropy 1.0835 (1.0850) gate/usage_max 0.4155 (0.4106) gate/usage_min 0.2813 (0.2821) gate/usage_std 0.0588 (0.0556) teacher/entropy 0.0972 (0.0654) teacher/usage_max 0.5464 (0.7520) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2387 (0.3157) nleep/row_max_mean 1542.5559 (1567.2407) nleep/row_max_std 62.3468 (56.7144) nleep/row_min_mean 1506.7712 (1529.4343) lr 1.9511e-03 eta 0:15:44
epoch [7/50] batch [60/167] time 0.088 (0.123) data 0.000 (0.005) loss 1.5336 (1.6164) teacher_loss 0.2790 (0.3524) loss_zs_kd 0.0099 (0.0115) loss_oracle 0.6962 (0.6905) kd_loss 0.9016 (0.9131) acc 87.5000 (85.9375) gate/entropy 1.0815 (1.0841) gate/usage_max 0.4215 (0.4134) gate/usage_min 0.2799 (0.2815) gate/usage_std 0.0628 (0.0575) teacher/entropy 0.0525 (0.0630) teacher/usage_max 0.7773 (0.7538) teacher/usage_min 0.0001 (0.0046) teacher/usage_std 0.3268 (0.3160) nleep/row_max_mean 1577.7845 (1567.3736) nleep/row_max_std 50.8475 (56.5780) nleep/row_min_mean 1541.3014 (1530.0586) lr 1.9511e-03 eta 0:14:55
epoch [7/50] batch [80/167] time 0.100 (0.120) data 0.000 (0.004) loss 1.6469 (1.6263) teacher_loss 0.4118 (0.3615) loss_zs_kd 0.0057 (0.0115) loss_oracle 0.7120 (0.6894) kd_loss 0.8762 (0.9143) acc 75.0000 (85.8203) gate/entropy 1.0796 (1.0832) gate/usage_max 0.4264 (0.4161) gate/usage_min 0.2791 (0.2810) gate/usage_std 0.0661 (0.0593) teacher/entropy 0.0854 (0.0605) teacher/usage_max 0.7371 (0.7461) teacher/usage_min 0.0000 (0.0043) teacher/usage_std 0.3050 (0.3119) nleep/row_max_mean 1567.4352 (1567.6217) nleep/row_max_std 60.0069 (56.3987) nleep/row_min_mean 1530.4054 (1530.4531) lr 1.9511e-03 eta 0:14:28
epoch [7/50] batch [100/167] time 0.182 (0.120) data 0.000 (0.003) loss 1.7535 (1.6395) teacher_loss 0.4116 (0.3715) loss_zs_kd 0.0106 (0.0114) loss_oracle 0.7546 (0.6918) kd_loss 0.9593 (0.9164) acc 81.2500 (85.4375) gate/entropy 1.0779 (1.0823) gate/usage_max 0.4309 (0.4187) gate/usage_min 0.2787 (0.2805) gate/usage_std 0.0692 (0.0610) teacher/entropy 0.0146 (0.0588) teacher/usage_max 0.6874 (0.7353) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.2810 (0.3062) nleep/row_max_mean 1556.8553 (1567.1876) nleep/row_max_std 65.7159 (56.7914) nleep/row_min_mean 1520.5741 (1530.1291) lr 1.9511e-03 eta 0:14:28
epoch [7/50] batch [120/167] time 0.086 (0.117) data 0.000 (0.003) loss 1.4590 (1.6280) teacher_loss 0.2210 (0.3625) loss_zs_kd 0.0065 (0.0108) loss_oracle 0.6489 (0.6888) kd_loss 0.9104 (0.9157) acc 93.7500 (86.0417) gate/entropy 1.0762 (1.0814) gate/usage_max 0.4351 (0.4212) gate/usage_min 0.2785 (0.2802) gate/usage_std 0.0720 (0.0627) teacher/entropy 0.0483 (0.0588) teacher/usage_max 0.7098 (0.7273) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.2914 (0.3025) nleep/row_max_mean 1566.4167 (1567.7004) nleep/row_max_std 55.9904 (56.7846) nleep/row_min_mean 1532.4095 (1530.8518) lr 1.9511e-03 eta 0:14:08
epoch [7/50] batch [140/167] time 0.134 (0.119) data 0.000 (0.002) loss 1.5887 (1.6301) teacher_loss 0.3697 (0.3684) loss_zs_kd 0.0070 (0.0110) loss_oracle 0.6468 (0.6863) kd_loss 0.8921 (0.9130) acc 81.2500 (85.7366) gate/entropy 1.0738 (1.0805) gate/usage_max 0.4406 (0.4236) gate/usage_min 0.2775 (0.2799) gate/usage_std 0.0758 (0.0643) teacher/entropy 0.0346 (0.0567) teacher/usage_max 0.7634 (0.7294) teacher/usage_min 0.0003 (0.0045) teacher/usage_std 0.3190 (0.3034) nleep/row_max_mean 1565.6660 (1568.1441) nleep/row_max_std 58.6605 (57.1565) nleep/row_min_mean 1532.2007 (1531.2322) lr 1.9511e-03 eta 0:14:15
epoch [7/50] batch [160/167] time 0.144 (0.121) data 0.000 (0.002) loss 1.4321 (1.6242) teacher_loss 0.3113 (0.3682) loss_zs_kd 0.0116 (0.0109) loss_oracle 0.6017 (0.6810) kd_loss 0.8142 (0.9101) acc 87.5000 (85.7227) gate/entropy 1.0716 (1.0795) gate/usage_max 0.4454 (0.4260) gate/usage_min 0.2766 (0.2795) gate/usage_std 0.0792 (0.0659) teacher/entropy 0.0878 (0.0558) teacher/usage_max 0.7990 (0.7294) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.3394 (0.3030) nleep/row_max_mean 1575.7896 (1568.5901) nleep/row_max_std 66.9936 (57.2864) nleep/row_min_mean 1538.4761 (1531.5849) lr 1.9511e-03 eta 0:14:32
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.0%, epoch: 5 *******
******* Domain c best val test acc: 99.2%, epoch: 5 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [8/50] batch [20/167] time 0.153 (0.162) data 0.000 (0.016) loss 1.4501 (1.5576) teacher_loss 0.2578 (0.3516) loss_zs_kd 0.0042 (0.0102) loss_oracle 0.5839 (0.6410) kd_loss 0.8982 (0.8805) acc 90.6250 (85.3125) gate/entropy 1.0691 (1.0700) gate/usage_max 0.4504 (0.4487) gate/usage_min 0.2736 (0.2751) gate/usage_std 0.0828 (0.0816) teacher/entropy 0.0392 (0.0591) teacher/usage_max 0.7072 (0.7100) teacher/usage_min 0.0005 (0.0034) teacher/usage_std 0.2900 (0.2928) nleep/row_max_mean 1568.9410 (1573.0433) nleep/row_max_std 64.8133 (60.9420) nleep/row_min_mean 1529.6897 (1535.2602) lr 1.9298e-03 eta 0:19:20
epoch [8/50] batch [40/167] time 0.139 (0.153) data 0.000 (0.008) loss 1.4161 (1.5461) teacher_loss 0.2758 (0.3635) loss_zs_kd 0.0070 (0.0109) loss_oracle 0.5840 (0.6254) kd_loss 0.8448 (0.8644) acc 90.6250 (85.2344) gate/entropy 1.0662 (1.0688) gate/usage_max 0.4562 (0.4511) gate/usage_min 0.2696 (0.2733) gate/usage_std 0.0869 (0.0833) teacher/entropy 0.0655 (0.0564) teacher/usage_max 0.7500 (0.7415) teacher/usage_min 0.0357 (0.0044) teacher/usage_std 0.3035 (0.3099) nleep/row_max_mean 1576.8616 (1573.8949) nleep/row_max_std 56.0135 (57.0283) nleep/row_min_mean 1537.7050 (1535.6500) lr 1.9298e-03 eta 0:18:12
epoch [8/50] batch [60/167] time 0.129 (0.149) data 0.000 (0.005) loss 1.5057 (1.5199) teacher_loss 0.4460 (0.3532) loss_zs_kd 0.0105 (0.0099) loss_oracle 0.5351 (0.6118) kd_loss 0.7869 (0.8558) acc 81.2500 (85.9896) gate/entropy 1.0642 (1.0676) gate/usage_max 0.4601 (0.4535) gate/usage_min 0.2668 (0.2716) gate/usage_std 0.0897 (0.0850) teacher/entropy 0.0976 (0.0590) teacher/usage_max 0.7899 (0.7469) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.3340 (0.3122) nleep/row_max_mean 1559.9363 (1572.0573) nleep/row_max_std 51.1096 (56.2489) nleep/row_min_mean 1521.5952 (1534.2721) lr 1.9298e-03 eta 0:17:40
epoch [8/50] batch [80/167] time 0.146 (0.149) data 0.000 (0.004) loss 1.4703 (1.5064) teacher_loss 0.4078 (0.3534) loss_zs_kd 0.0116 (0.0097) loss_oracle 0.5480 (0.6098) kd_loss 0.7827 (0.8433) acc 87.5000 (86.2891) gate/entropy 1.0608 (1.0663) gate/usage_max 0.4662 (0.4560) gate/usage_min 0.2629 (0.2698) gate/usage_std 0.0940 (0.0867) teacher/entropy 0.0569 (0.0602) teacher/usage_max 0.8576 (0.7622) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.3752 (0.3205) nleep/row_max_mean 1574.2301 (1572.8413) nleep/row_max_std 60.4733 (56.0791) nleep/row_min_mean 1537.1614 (1534.9337) lr 1.9298e-03 eta 0:17:34
epoch [8/50] batch [100/167] time 0.138 (0.149) data 0.000 (0.003) loss 1.2817 (1.5007) teacher_loss 0.2014 (0.3608) loss_zs_kd 0.0190 (0.0100) loss_oracle 0.5847 (0.6046) kd_loss 0.7784 (0.8326) acc 93.7500 (86.1562) gate/entropy 1.0577 (1.0649) gate/usage_max 0.4716 (0.4586) gate/usage_min 0.2597 (0.2681) gate/usage_std 0.0978 (0.0886) teacher/entropy 0.0679 (0.0617) teacher/usage_max 0.8290 (0.7731) teacher/usage_min 0.0007 (0.0069) teacher/usage_std 0.3573 (0.3262) nleep/row_max_mean 1578.3975 (1573.4112) nleep/row_max_std 51.2155 (56.5549) nleep/row_min_mean 1540.0833 (1535.5581) lr 1.9298e-03 eta 0:17:35
epoch [8/50] batch [120/167] time 0.170 (0.139) data 0.000 (0.003) loss 1.3682 (1.5001) teacher_loss 0.3575 (0.3664) loss_zs_kd 0.0152 (0.0102) loss_oracle 0.6181 (0.6055) kd_loss 0.6941 (0.8258) acc 87.5000 (86.1198) gate/entropy 1.0553 (1.0635) gate/usage_max 0.4757 (0.4611) gate/usage_min 0.2571 (0.2665) gate/usage_std 0.1007 (0.0904) teacher/entropy 0.1221 (0.0631) teacher/usage_max 0.8715 (0.7769) teacher/usage_min 0.0244 (0.0090) teacher/usage_std 0.3819 (0.3277) nleep/row_max_mean 1558.7083 (1572.7464) nleep/row_max_std 75.1259 (57.1803) nleep/row_min_mean 1523.3040 (1535.3675) lr 1.9298e-03 eta 0:16:18
epoch [8/50] batch [140/167] time 0.076 (0.135) data 0.000 (0.002) loss 1.2755 (1.4876) teacher_loss 0.2996 (0.3621) loss_zs_kd 0.0092 (0.0103) loss_oracle 0.5347 (0.6016) kd_loss 0.7039 (0.8196) acc 90.6250 (86.1830) gate/entropy 1.0521 (1.0620) gate/usage_max 0.4809 (0.4636) gate/usage_min 0.2541 (0.2649) gate/usage_std 0.1044 (0.0921) teacher/entropy 0.0944 (0.0627) teacher/usage_max 0.8888 (0.7828) teacher/usage_min 0.0212 (0.0102) teacher/usage_std 0.3937 (0.3309) nleep/row_max_mean 1577.3972 (1572.5609) nleep/row_max_std 63.1616 (57.2712) nleep/row_min_mean 1543.3286 (1535.5931) lr 1.9298e-03 eta 0:15:49
epoch [8/50] batch [160/167] time 0.074 (0.132) data 0.000 (0.002) loss 1.5651 (1.4735) teacher_loss 0.5428 (0.3597) loss_zs_kd 0.0109 (0.0102) loss_oracle 0.6099 (0.5985) kd_loss 0.7118 (0.8095) acc 81.2500 (86.3086) gate/entropy 1.0484 (1.0606) gate/usage_max 0.4868 (0.4661) gate/usage_min 0.2508 (0.2634) gate/usage_std 0.1086 (0.0939) teacher/entropy 0.0383 (0.0643) teacher/usage_max 0.9493 (0.7917) teacher/usage_min 0.0000 (0.0107) teacher/usage_std 0.4360 (0.3361) nleep/row_max_mean 1591.6444 (1572.4899) nleep/row_max_std 48.7121 (57.1121) nleep/row_min_mean 1551.8236 (1535.8342) lr 1.9298e-03 eta 0:15:27
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain c best val acc:      96.0%, epoch: 5 *******
******* Domain c best val test acc: 99.2%, epoch: 5 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [9/50] batch [20/167] time 0.132 (0.148) data 0.000 (0.017) loss 1.3923 (1.3658) teacher_loss 0.3937 (0.3652) loss_zs_kd 0.0135 (0.0098) loss_oracle 0.5585 (0.5574) kd_loss 0.7127 (0.7170) acc 81.2500 (86.5625) gate/entropy 1.0441 (1.0461) gate/usage_max 0.4933 (0.4903) gate/usage_min 0.2475 (0.2490) gate/usage_std 0.1132 (0.1111) teacher/entropy 0.0151 (0.0563) teacher/usage_max 0.9664 (0.9029) teacher/usage_min 0.0001 (0.0130) teacher/usage_std 0.4479 (0.4044) nleep/row_max_mean 1571.2257 (1564.4897) nleep/row_max_std 43.9548 (59.1930) nleep/row_min_mean 1534.2935 (1531.3499) lr 1.9048e-03 eta 0:17:14
epoch [9/50] batch [40/167] time 0.087 (0.129) data 0.000 (0.009) loss 1.2938 (1.3357) teacher_loss 0.2709 (0.3311) loss_zs_kd 0.0110 (0.0090) loss_oracle 0.5477 (0.5628) kd_loss 0.7435 (0.7187) acc 90.6250 (87.5000) gate/entropy 1.0411 (1.0444) gate/usage_max 0.4977 (0.4928) gate/usage_min 0.2454 (0.2478) gate/usage_std 0.1163 (0.1129) teacher/entropy 0.0584 (0.0487) teacher/usage_max 0.8393 (0.9057) teacher/usage_min 0.0015 (0.0132) teacher/usage_std 0.3635 (0.4064) nleep/row_max_mean 1553.4727 (1565.6523) nleep/row_max_std 72.1056 (59.0859) nleep/row_min_mean 1520.2449 (1532.0957) lr 1.9048e-03 eta 0:15:02
epoch [9/50] batch [60/167] time 0.166 (0.134) data 0.000 (0.006) loss 1.2215 (1.3282) teacher_loss 0.2748 (0.3315) loss_zs_kd 0.0054 (0.0089) loss_oracle 0.4972 (0.5520) kd_loss 0.6954 (0.7162) acc 90.6250 (86.9271) gate/entropy 1.0378 (1.0428) gate/usage_max 0.5025 (0.4952) gate/usage_min 0.2430 (0.2466) gate/usage_std 0.1197 (0.1146) teacher/entropy 0.0519 (0.0566) teacher/usage_max 0.9156 (0.8918) teacher/usage_min 0.0338 (0.0151) teacher/usage_std 0.4118 (0.3969) nleep/row_max_mean 1562.9363 (1563.9137) nleep/row_max_std 59.8162 (59.4768) nleep/row_min_mean 1534.4087 (1530.6587) lr 1.9048e-03 eta 0:15:29
epoch [9/50] batch [80/167] time 0.161 (0.140) data 0.000 (0.004) loss 1.1151 (1.3138) teacher_loss 0.1953 (0.3265) loss_zs_kd 0.0100 (0.0086) loss_oracle 0.4458 (0.5406) kd_loss 0.6918 (0.7127) acc 93.7500 (87.3438) gate/entropy 1.0351 (1.0412) gate/usage_max 0.5063 (0.4975) gate/usage_min 0.2412 (0.2455) gate/usage_std 0.1224 (0.1162) teacher/entropy 0.1037 (0.0610) teacher/usage_max 0.8365 (0.8852) teacher/usage_min 0.0468 (0.0156) teacher/usage_std 0.3570 (0.3924) nleep/row_max_mean 1556.8552 (1564.2475) nleep/row_max_std 70.5791 (60.8401) nleep/row_min_mean 1527.8374 (1531.3962) lr 1.9048e-03 eta 0:16:12
epoch [9/50] batch [100/167] time 0.142 (0.143) data 0.000 (0.004) loss 1.1634 (1.3195) teacher_loss 0.3036 (0.3337) loss_zs_kd 0.0030 (0.0093) loss_oracle 0.4110 (0.5328) kd_loss 0.6528 (0.7147) acc 90.6250 (87.1562) gate/entropy 1.0331 (1.0398) gate/usage_max 0.5090 (0.4996) gate/usage_min 0.2396 (0.2444) gate/usage_std 0.1243 (0.1177) teacher/entropy 0.0685 (0.0622) teacher/usage_max 0.9349 (0.8759) teacher/usage_min 0.0038 (0.0174) teacher/usage_std 0.4260 (0.3863) nleep/row_max_mean 1553.4014 (1564.8069) nleep/row_max_std 70.7556 (60.8801) nleep/row_min_mean 1526.6572 (1532.2951) lr 1.9048e-03 eta 0:16:30
epoch [9/50] batch [120/167] time 0.144 (0.144) data 0.000 (0.003) loss 1.3757 (1.3179) teacher_loss 0.3311 (0.3339) loss_zs_kd 0.0126 (0.0090) loss_oracle 0.6010 (0.5313) kd_loss 0.7378 (0.7138) acc 84.3750 (87.1875) gate/entropy 1.0297 (1.0384) gate/usage_max 0.5137 (0.5016) gate/usage_min 0.2374 (0.2434) gate/usage_std 0.1276 (0.1191) teacher/entropy 0.0194 (0.0629) teacher/usage_max 0.8714 (0.8721) teacher/usage_min 0.0000 (0.0197) teacher/usage_std 0.3841 (0.3835) nleep/row_max_mean 1568.5664 (1564.3957) nleep/row_max_std 46.4884 (61.0661) nleep/row_min_mean 1537.4475 (1532.3781) lr 1.9048e-03 eta 0:16:30
epoch [9/50] batch [140/167] time 0.170 (0.146) data 0.000 (0.003) loss 1.4250 (1.3214) teacher_loss 0.4496 (0.3364) loss_zs_kd 0.0129 (0.0092) loss_oracle 0.5563 (0.5330) kd_loss 0.6908 (0.7139) acc 81.2500 (87.1875) gate/entropy 1.0276 (1.0370) gate/usage_max 0.5164 (0.5035) gate/usage_min 0.2361 (0.2425) gate/usage_std 0.1295 (0.1204) teacher/entropy 0.0509 (0.0629) teacher/usage_max 0.8894 (0.8681) teacher/usage_min 0.0042 (0.0201) teacher/usage_std 0.3954 (0.3809) nleep/row_max_mean 1569.2764 (1563.9624) nleep/row_max_std 57.9548 (60.6604) nleep/row_min_mean 1539.9519 (1532.4221) lr 1.9048e-03 eta 0:16:44
epoch [9/50] batch [160/167] time 0.160 (0.148) data 0.000 (0.002) loss 1.3138 (1.3234) teacher_loss 0.2717 (0.3364) loss_zs_kd 0.0073 (0.0095) loss_oracle 0.5642 (0.5343) kd_loss 0.7564 (0.7151) acc 87.5000 (87.3047) gate/entropy 1.0254 (1.0357) gate/usage_max 0.5193 (0.5053) gate/usage_min 0.2346 (0.2416) gate/usage_std 0.1316 (0.1217) teacher/entropy 0.0584 (0.0632) teacher/usage_max 0.7861 (0.8625) teacher/usage_min 0.0483 (0.0202) teacher/usage_std 0.3237 (0.3773) nleep/row_max_mean 1536.0964 (1563.2610) nleep/row_max_std 66.3190 (60.2707) nleep/row_min_mean 1509.9031 (1532.0227) lr 1.9048e-03 eta 0:16:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.0%, epoch: 5 *******
******* Domain c best val test acc: 99.2%, epoch: 5 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [10/50] batch [20/167] time 0.074 (0.122) data 0.000 (0.015) loss 1.0045 (1.2788) teacher_loss 0.0832 (0.2769) loss_zs_kd 0.0023 (0.0121) loss_oracle 0.4477 (0.5331) kd_loss 0.6964 (0.7293) acc 100.0000 (89.6875) gate/entropy 1.0227 (1.0236) gate/usage_max 0.5228 (0.5216) gate/usage_min 0.2327 (0.2334) gate/usage_std 0.1341 (0.1332) teacher/entropy 0.0956 (0.0737) teacher/usage_max 0.8101 (0.7972) teacher/usage_min 0.0003 (0.0162) teacher/usage_std 0.3459 (0.3368) nleep/row_max_mean 1556.1270 (1553.7368) nleep/row_max_std 58.6773 (50.5984) nleep/row_min_mean 1529.0088 (1526.4107) lr 1.8763e-03 eta 0:13:50
epoch [10/50] batch [40/167] time 0.096 (0.112) data 0.000 (0.007) loss 1.3327 (1.3121) teacher_loss 0.3476 (0.2983) loss_zs_kd 0.0200 (0.0128) loss_oracle 0.5235 (0.5406) kd_loss 0.7134 (0.7371) acc 87.5000 (88.4375) gate/entropy 1.0207 (1.0227) gate/usage_max 0.5253 (0.5228) gate/usage_min 0.2314 (0.2327) gate/usage_std 0.1358 (0.1341) teacher/entropy 0.0717 (0.0719) teacher/usage_max 0.8165 (0.7875) teacher/usage_min 0.0368 (0.0180) teacher/usage_std 0.3446 (0.3306) nleep/row_max_mean 1560.9551 (1555.2969) nleep/row_max_std 43.1262 (51.5360) nleep/row_min_mean 1534.0396 (1527.6802) lr 1.8763e-03 eta 0:12:42
epoch [10/50] batch [60/167] time 0.085 (0.113) data 0.000 (0.005) loss 1.1217 (1.3256) teacher_loss 0.1461 (0.3063) loss_zs_kd 0.0086 (0.0131) loss_oracle 0.5126 (0.5344) kd_loss 0.7150 (0.7456) acc 93.7500 (88.4896) gate/entropy 1.0195 (1.0219) gate/usage_max 0.5268 (0.5238) gate/usage_min 0.2305 (0.2322) gate/usage_std 0.1369 (0.1348) teacher/entropy 0.0752 (0.0677) teacher/usage_max 0.8063 (0.7804) teacher/usage_min 0.0086 (0.0182) teacher/usage_std 0.3421 (0.3265) nleep/row_max_mean 1557.8469 (1555.1317) nleep/row_max_std 62.1096 (52.8443) nleep/row_min_mean 1533.2767 (1527.5382) lr 1.8763e-03 eta 0:12:45
epoch [10/50] batch [80/167] time 0.081 (0.112) data 0.000 (0.004) loss 1.2368 (1.3494) teacher_loss 0.3065 (0.3242) loss_zs_kd 0.0058 (0.0139) loss_oracle 0.5112 (0.5356) kd_loss 0.6718 (0.7505) acc 87.5000 (87.7344) gate/entropy 1.0174 (1.0211) gate/usage_max 0.5295 (0.5248) gate/usage_min 0.2290 (0.2316) gate/usage_std 0.1388 (0.1355) teacher/entropy 0.0881 (0.0703) teacher/usage_max 0.8392 (0.7694) teacher/usage_min 0.0003 (0.0216) teacher/usage_std 0.3636 (0.3192) nleep/row_max_mean 1579.3289 (1556.0639) nleep/row_max_std 52.8401 (54.8131) nleep/row_min_mean 1548.2043 (1528.4615) lr 1.8763e-03 eta 0:12:39
epoch [10/50] batch [100/167] time 0.076 (0.111) data 0.000 (0.003) loss 1.4994 (1.3554) teacher_loss 0.5255 (0.3235) loss_zs_kd 0.0182 (0.0146) loss_oracle 0.5452 (0.5349) kd_loss 0.6922 (0.7571) acc 84.3750 (88.1875) gate/entropy 1.0169 (1.0203) gate/usage_max 0.5300 (0.5258) gate/usage_min 0.2285 (0.2310) gate/usage_std 0.1392 (0.1362) teacher/entropy 0.0917 (0.0693) teacher/usage_max 0.8082 (0.7609) teacher/usage_min 0.0070 (0.0210) teacher/usage_std 0.3435 (0.3147) nleep/row_max_mean 1557.4199 (1558.0151) nleep/row_max_std 60.4821 (54.9828) nleep/row_min_mean 1528.8732 (1530.0894) lr 1.8763e-03 eta 0:12:26
epoch [10/50] batch [120/167] time 0.087 (0.109) data 0.000 (0.003) loss 1.5083 (1.3652) teacher_loss 0.4372 (0.3304) loss_zs_kd 0.0284 (0.0146) loss_oracle 0.4983 (0.5324) kd_loss 0.8077 (0.7613) acc 84.3750 (87.8125) gate/entropy 1.0158 (1.0196) gate/usage_max 0.5314 (0.5267) gate/usage_min 0.2276 (0.2305) gate/usage_std 0.1402 (0.1368) teacher/entropy 0.0260 (0.0678) teacher/usage_max 0.7413 (0.7560) teacher/usage_min 0.0000 (0.0191) teacher/usage_std 0.3072 (0.3127) nleep/row_max_mean 1563.3945 (1558.9187) nleep/row_max_std 48.8067 (55.9631) nleep/row_min_mean 1532.0697 (1530.8887) lr 1.8763e-03 eta 0:12:13
epoch [10/50] batch [140/167] time 0.147 (0.110) data 0.000 (0.002) loss 1.5412 (1.3668) teacher_loss 0.4259 (0.3256) loss_zs_kd 0.0256 (0.0151) loss_oracle 0.5164 (0.5291) kd_loss 0.8443 (0.7691) acc 84.3750 (87.9688) gate/entropy 1.0150 (1.0190) gate/usage_max 0.5323 (0.5274) gate/usage_min 0.2269 (0.2300) gate/usage_std 0.1408 (0.1374) teacher/entropy 0.0310 (0.0672) teacher/usage_max 0.6857 (0.7456) teacher/usage_min 0.0004 (0.0179) teacher/usage_std 0.2801 (0.3079) nleep/row_max_mean 1562.1472 (1559.9471) nleep/row_max_std 49.3791 (56.0970) nleep/row_min_mean 1533.0999 (1531.6000) lr 1.8763e-03 eta 0:12:15
epoch [10/50] batch [160/167] time 0.152 (0.110) data 0.000 (0.002) loss 1.4994 (1.3713) teacher_loss 0.3214 (0.3252) loss_zs_kd 0.0110 (0.0153) loss_oracle 0.5928 (0.5223) kd_loss 0.8760 (0.7772) acc 87.5000 (87.8516) gate/entropy 1.0144 (1.0184) gate/usage_max 0.5331 (0.5282) gate/usage_min 0.2261 (0.2296) gate/usage_std 0.1414 (0.1379) teacher/entropy 0.0355 (0.0667) teacher/usage_max 0.6431 (0.7351) teacher/usage_min 0.0331 (0.0182) teacher/usage_std 0.2491 (0.3032) nleep/row_max_mean 1563.6030 (1560.6529) nleep/row_max_std 46.5073 (56.1332) nleep/row_min_mean 1530.7156 (1532.3102) lr 1.8763e-03 eta 0:12:12
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,210
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [11/50] batch [20/167] time 0.152 (0.170) data 0.000 (0.016) loss 1.2486 (1.3985) teacher_loss 0.2137 (0.3049) loss_zs_kd 0.0077 (0.0175) loss_oracle 0.4934 (0.5127) kd_loss 0.7845 (0.8285) acc 93.7500 (88.5938) gate/entropy 1.0128 (1.0131) gate/usage_max 0.5349 (0.5346) gate/usage_min 0.2249 (0.2251) gate/usage_std 0.1426 (0.1425) teacher/entropy 0.0669 (0.0584) teacher/usage_max 0.7145 (0.6720) teacher/usage_min 0.0073 (0.0223) teacher/usage_std 0.2913 (0.2695) nleep/row_max_mean 1566.7527 (1570.7282) nleep/row_max_std 69.6017 (54.3597) nleep/row_min_mean 1540.5173 (1542.3039) lr 1.8443e-03 eta 0:18:51
epoch [11/50] batch [40/167] time 0.159 (0.167) data 0.000 (0.008) loss 1.5610 (1.4190) teacher_loss 0.4497 (0.3277) loss_zs_kd 0.0191 (0.0164) loss_oracle 0.5360 (0.4988) kd_loss 0.8337 (0.8336) acc 78.1250 (87.8906) gate/entropy 1.0122 (1.0127) gate/usage_max 0.5356 (0.5350) gate/usage_min 0.2241 (0.2248) gate/usage_std 0.1432 (0.1427) teacher/entropy 0.0440 (0.0608) teacher/usage_max 0.6868 (0.6619) teacher/usage_min 0.0829 (0.0225) teacher/usage_std 0.2571 (0.2660) nleep/row_max_mean 1568.8868 (1568.7707) nleep/row_max_std 50.8043 (55.6360) nleep/row_min_mean 1542.0825 (1541.0639) lr 1.8443e-03 eta 0:18:30
epoch [11/50] batch [60/167] time 0.158 (0.163) data 0.001 (0.005) loss 1.2514 (1.4074) teacher_loss 0.0599 (0.3213) loss_zs_kd 0.0020 (0.0160) loss_oracle 0.4534 (0.4944) kd_loss 0.9638 (0.8309) acc 100.0000 (88.0729) gate/entropy 1.0121 (1.0125) gate/usage_max 0.5357 (0.5352) gate/usage_min 0.2238 (0.2245) gate/usage_std 0.1432 (0.1429) teacher/entropy 0.1148 (0.0698) teacher/usage_max 0.4824 (0.6550) teacher/usage_min 0.0821 (0.0270) teacher/usage_std 0.1787 (0.2625) nleep/row_max_mean 1550.0035 (1565.1208) nleep/row_max_std 65.3175 (57.0545) nleep/row_min_mean 1525.0291 (1538.0791) lr 1.8443e-03 eta 0:18:01
epoch [11/50] batch [80/167] time 0.170 (0.158) data 0.000 (0.004) loss 1.3069 (1.4118) teacher_loss 0.2900 (0.3249) loss_zs_kd 0.0192 (0.0160) loss_oracle 0.4441 (0.4921) kd_loss 0.7853 (0.8329) acc 87.5000 (87.9688) gate/entropy 1.0110 (1.0123) gate/usage_max 0.5370 (0.5355) gate/usage_min 0.2228 (0.2242) gate/usage_std 0.1442 (0.1431) teacher/entropy 0.0988 (0.0732) teacher/usage_max 0.6773 (0.6485) teacher/usage_min 0.0596 (0.0310) teacher/usage_std 0.2570 (0.2581) nleep/row_max_mean 1562.8192 (1564.3086) nleep/row_max_std 69.7577 (57.9213) nleep/row_min_mean 1539.0861 (1537.3909) lr 1.8443e-03 eta 0:17:19
epoch [11/50] batch [100/167] time 0.128 (0.154) data 0.000 (0.003) loss 1.2439 (1.4061) teacher_loss 0.1827 (0.3232) loss_zs_kd 0.0114 (0.0162) loss_oracle 0.4863 (0.4887) kd_loss 0.8123 (0.8304) acc 93.7500 (88.1250) gate/entropy 1.0107 (1.0120) gate/usage_max 0.5373 (0.5358) gate/usage_min 0.2225 (0.2239) gate/usage_std 0.1444 (0.1433) teacher/entropy 0.0721 (0.0761) teacher/usage_max 0.6742 (0.6478) teacher/usage_min 0.0461 (0.0369) teacher/usage_std 0.2592 (0.2555) nleep/row_max_mean 1558.1732 (1563.0480) nleep/row_max_std 75.5734 (58.6827) nleep/row_min_mean 1534.9341 (1536.5383) lr 1.8443e-03 eta 0:16:53
epoch [11/50] batch [120/167] time 0.159 (0.153) data 0.000 (0.003) loss 1.4485 (1.4040) teacher_loss 0.3941 (0.3283) loss_zs_kd 0.0226 (0.0163) loss_oracle 0.4924 (0.4879) kd_loss 0.7969 (0.8235) acc 84.3750 (87.9427) gate/entropy 1.0098 (1.0117) gate/usage_max 0.5384 (0.5361) gate/usage_min 0.2218 (0.2236) gate/usage_std 0.1452 (0.1436) teacher/entropy 0.1170 (0.0801) teacher/usage_max 0.6392 (0.6516) teacher/usage_min 0.0736 (0.0436) teacher/usage_std 0.2332 (0.2551) nleep/row_max_mean 1562.1068 (1562.3767) nleep/row_max_std 61.5764 (59.2719) nleep/row_min_mean 1537.5774 (1536.2097) lr 1.8443e-03 eta 0:16:42
epoch [11/50] batch [140/167] time 0.097 (0.145) data 0.000 (0.002) loss 1.3856 (1.3915) teacher_loss 0.2397 (0.3203) loss_zs_kd 0.0086 (0.0164) loss_oracle 0.4953 (0.4872) kd_loss 0.8939 (0.8194) acc 87.5000 (88.0580) gate/entropy 1.0103 (1.0115) gate/usage_max 0.5378 (0.5364) gate/usage_min 0.2221 (0.2233) gate/usage_std 0.1447 (0.1438) teacher/entropy 0.1178 (0.0830) teacher/usage_max 0.5209 (0.6534) teacher/usage_min 0.1393 (0.0494) teacher/usage_std 0.1559 (0.2540) nleep/row_max_mean 1550.1495 (1561.5245) nleep/row_max_std 60.1998 (59.1082) nleep/row_min_mean 1526.6112 (1535.6263) lr 1.8443e-03 eta 0:15:51
epoch [11/50] batch [160/167] time 0.146 (0.142) data 0.000 (0.002) loss 1.4349 (1.3836) teacher_loss 0.4165 (0.3195) loss_zs_kd 0.0319 (0.0165) loss_oracle 0.4560 (0.4795) kd_loss 0.7744 (0.8160) acc 84.3750 (88.0664) gate/entropy 1.0091 (1.0112) gate/usage_max 0.5392 (0.5367) gate/usage_min 0.2215 (0.2231) gate/usage_std 0.1458 (0.1440) teacher/entropy 0.0904 (0.0862) teacher/usage_max 0.7108 (0.6543) teacher/usage_min 0.0964 (0.0583) teacher/usage_std 0.2698 (0.2519) nleep/row_max_mean 1556.0476 (1561.1361) nleep/row_max_std 60.1660 (58.9535) nleep/row_min_mean 1530.3640 (1535.4121) lr 1.8443e-03 eta 0:15:23
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [12/50] batch [20/167] time 0.085 (0.120) data 0.000 (0.016) loss 1.2748 (1.2570) teacher_loss 0.3211 (0.2505) loss_zs_kd 0.0167 (0.0159) loss_oracle 0.5170 (0.4746) kd_loss 0.6868 (0.7612) acc 90.6250 (91.4062) gate/entropy 1.0076 (1.0082) gate/usage_max 0.5411 (0.5403) gate/usage_min 0.2211 (0.2213) gate/usage_std 0.1470 (0.1465) teacher/entropy 0.1832 (0.1106) teacher/usage_max 0.7016 (0.6975) teacher/usage_min 0.1303 (0.1167) teacher/usage_std 0.2609 (0.2597) nleep/row_max_mean 1570.1589 (1562.9064) nleep/row_max_std 43.9281 (54.4406) nleep/row_min_mean 1545.9935 (1537.8941) lr 1.8090e-03 eta 0:13:00
epoch [12/50] batch [40/167] time 0.075 (0.119) data 0.000 (0.008) loss 1.1796 (1.2694) teacher_loss 0.2872 (0.2799) loss_zs_kd 0.0114 (0.0162) loss_oracle 0.4318 (0.4819) kd_loss 0.6708 (0.7405) acc 87.5000 (89.8438) gate/entropy 1.0064 (1.0078) gate/usage_max 0.5425 (0.5408) gate/usage_min 0.2208 (0.2212) gate/usage_std 0.1480 (0.1469) teacher/entropy 0.1538 (0.1067) teacher/usage_max 0.7510 (0.7262) teacher/usage_min 0.1224 (0.1051) teacher/usage_std 0.2953 (0.2798) nleep/row_max_mean 1568.5225 (1561.6025) nleep/row_max_std 45.5875 (53.4352) nleep/row_min_mean 1544.1836 (1536.4747) lr 1.8090e-03 eta 0:12:47
epoch [12/50] batch [60/167] time 0.137 (0.117) data 0.000 (0.005) loss 1.2003 (1.2879) teacher_loss 0.2312 (0.3052) loss_zs_kd 0.0068 (0.0178) loss_oracle 0.4830 (0.4912) kd_loss 0.7243 (0.7282) acc 90.6250 (88.8021) gate/entropy 1.0058 (1.0072) gate/usage_max 0.5432 (0.5415) gate/usage_min 0.2208 (0.2211) gate/usage_std 0.1485 (0.1473) teacher/entropy 0.0305 (0.0983) teacher/usage_max 0.8291 (0.7500) teacher/usage_min 0.0618 (0.0916) teacher/usage_std 0.3511 (0.2968) nleep/row_max_mean 1575.7738 (1563.3344) nleep/row_max_std 53.3594 (52.1137) nleep/row_min_mean 1548.2810 (1537.0426) lr 1.8090e-03 eta 0:12:36
epoch [12/50] batch [80/167] time 0.143 (0.121) data 0.000 (0.004) loss 1.2872 (1.2911) teacher_loss 0.3366 (0.3061) loss_zs_kd 0.0091 (0.0184) loss_oracle 0.5114 (0.4930) kd_loss 0.6903 (0.7293) acc 84.3750 (88.5547) gate/entropy 1.0045 (1.0067) gate/usage_max 0.5447 (0.5421) gate/usage_min 0.2205 (0.2209) gate/usage_std 0.1496 (0.1478) teacher/entropy 0.0370 (0.0909) teacher/usage_max 0.8641 (0.7573) teacher/usage_min 0.0313 (0.0859) teacher/usage_std 0.3765 (0.3022) nleep/row_max_mean 1556.9766 (1563.7420) nleep/row_max_std 61.4400 (52.1769) nleep/row_min_mean 1527.4510 (1536.8714) lr 1.8090e-03 eta 0:12:56
epoch [12/50] batch [100/167] time 0.162 (0.127) data 0.000 (0.003) loss 1.2315 (1.2856) teacher_loss 0.2141 (0.3009) loss_zs_kd 0.0197 (0.0183) loss_oracle 0.4959 (0.4950) kd_loss 0.7596 (0.7280) acc 93.7500 (88.7500) gate/entropy 1.0044 (1.0062) gate/usage_max 0.5449 (0.5427) gate/usage_min 0.2207 (0.2209) gate/usage_std 0.1497 (0.1481) teacher/entropy 0.0456 (0.0894) teacher/usage_max 0.7744 (0.7602) teacher/usage_min 0.0742 (0.0832) teacher/usage_std 0.3135 (0.3044) nleep/row_max_mean 1548.8431 (1562.2461) nleep/row_max_std 55.5300 (52.1995) nleep/row_min_mean 1520.2119 (1535.1978) lr 1.8090e-03 eta 0:13:35
epoch [12/50] batch [120/167] time 0.119 (0.128) data 0.000 (0.003) loss 1.3808 (1.2838) teacher_loss 0.4458 (0.3006) loss_zs_kd 0.0248 (0.0177) loss_oracle 0.4819 (0.4967) kd_loss 0.6817 (0.7260) acc 84.3750 (88.9062) gate/entropy 1.0027 (1.0057) gate/usage_max 0.5468 (0.5432) gate/usage_min 0.2202 (0.2208) gate/usage_std 0.1510 (0.1485) teacher/entropy 0.0852 (0.0859) teacher/usage_max 0.8152 (0.7661) teacher/usage_min 0.0539 (0.0796) teacher/usage_std 0.3422 (0.3085) nleep/row_max_mean 1553.1038 (1561.0256) nleep/row_max_std 53.9851 (52.1924) nleep/row_min_mean 1526.2743 (1533.9487) lr 1.8090e-03 eta 0:13:35
epoch [12/50] batch [140/167] time 0.152 (0.129) data 0.000 (0.002) loss 1.2593 (1.2910) teacher_loss 0.3343 (0.3103) loss_zs_kd 0.0121 (0.0176) loss_oracle 0.4631 (0.4967) kd_loss 0.6873 (0.7235) acc 84.3750 (88.5268) gate/entropy 1.0024 (1.0053) gate/usage_max 0.5472 (0.5438) gate/usage_min 0.2204 (0.2207) gate/usage_std 0.1513 (0.1489) teacher/entropy 0.0509 (0.0821) teacher/usage_max 0.8443 (0.7730) teacher/usage_min 0.0664 (0.0745) teacher/usage_std 0.3614 (0.3135) nleep/row_max_mean 1550.2317 (1560.4065) nleep/row_max_std 62.0872 (52.0629) nleep/row_min_mean 1521.8678 (1533.2037) lr 1.8090e-03 eta 0:13:40
epoch [12/50] batch [160/167] time 0.117 (0.129) data 0.000 (0.002) loss 1.3171 (1.2977) teacher_loss 0.3620 (0.3141) loss_zs_kd 0.0288 (0.0178) loss_oracle 0.4994 (0.4968) kd_loss 0.6910 (0.7263) acc 81.2500 (88.2031) gate/entropy 1.0007 (1.0048) gate/usage_max 0.5491 (0.5444) gate/usage_min 0.2199 (0.2206) gate/usage_std 0.1526 (0.1493) teacher/entropy 0.0694 (0.0787) teacher/usage_max 0.8166 (0.7733) teacher/usage_min 0.0839 (0.0721) teacher/usage_std 0.3417 (0.3140) nleep/row_max_mean 1564.8529 (1560.7339) nleep/row_max_std 50.9939 (51.7650) nleep/row_min_mean 1536.5923 (1533.3241) lr 1.8090e-03 eta 0:13:42
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,199
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [13/50] batch [20/167] time 0.150 (0.165) data 0.000 (0.015) loss 1.4556 (1.2818) teacher_loss 0.4372 (0.3144) loss_zs_kd 0.0163 (0.0166) loss_oracle 0.5357 (0.4846) kd_loss 0.7423 (0.7168) acc 84.3750 (87.9688) gate/entropy 1.0002 (1.0002) gate/usage_max 0.5497 (0.5496) gate/usage_min 0.2200 (0.2199) gate/usage_std 0.1530 (0.1530) teacher/entropy 0.0593 (0.0601) teacher/usage_max 0.7707 (0.8002) teacher/usage_min 0.1009 (0.0600) teacher/usage_std 0.3095 (0.3323) nleep/row_max_mean 1553.8722 (1558.8138) nleep/row_max_std 44.9451 (46.8283) nleep/row_min_mean 1525.5177 (1530.6648) lr 1.7705e-03 eta 0:17:24
epoch [13/50] batch [40/167] time 0.091 (0.157) data 0.000 (0.007) loss 1.0810 (1.2957) teacher_loss 0.1480 (0.3283) loss_zs_kd 0.0110 (0.0171) loss_oracle 0.4846 (0.4764) kd_loss 0.6852 (0.7206) acc 96.8750 (87.5000) gate/entropy 0.9994 (0.9998) gate/usage_max 0.5507 (0.5502) gate/usage_min 0.2198 (0.2198) gate/usage_std 0.1537 (0.1534) teacher/entropy 0.0376 (0.0598) teacher/usage_max 0.8590 (0.7957) teacher/usage_min 0.0457 (0.0563) teacher/usage_std 0.3723 (0.3301) nleep/row_max_mean 1557.8689 (1559.1640) nleep/row_max_std 49.2314 (48.4420) nleep/row_min_mean 1527.5645 (1531.4984) lr 1.7705e-03 eta 0:16:29
epoch [13/50] batch [60/167] time 0.171 (0.141) data 0.001 (0.005) loss 1.3732 (1.3030) teacher_loss 0.3293 (0.3270) loss_zs_kd 0.0108 (0.0167) loss_oracle 0.4029 (0.4753) kd_loss 0.8370 (0.7300) acc 81.2500 (87.6042) gate/entropy 0.9988 (0.9994) gate/usage_max 0.5512 (0.5506) gate/usage_min 0.2198 (0.2198) gate/usage_std 0.1541 (0.1537) teacher/entropy 0.0449 (0.0557) teacher/usage_max 0.6820 (0.7895) teacher/usage_min 0.0628 (0.0524) teacher/usage_std 0.2588 (0.3268) nleep/row_max_mean 1553.4268 (1559.0435) nleep/row_max_std 67.0800 (49.0525) nleep/row_min_mean 1524.3400 (1531.4711) lr 1.7705e-03 eta 0:14:43
epoch [13/50] batch [80/167] time 0.096 (0.133) data 0.000 (0.004) loss 1.3083 (1.2998) teacher_loss 0.3566 (0.3242) loss_zs_kd 0.0169 (0.0168) loss_oracle 0.4307 (0.4767) kd_loss 0.7279 (0.7289) acc 87.5000 (87.6562) gate/entropy 0.9973 (0.9990) gate/usage_max 0.5529 (0.5510) gate/usage_min 0.2194 (0.2197) gate/usage_std 0.1553 (0.1540) teacher/entropy 0.0406 (0.0566) teacher/usage_max 0.8055 (0.7895) teacher/usage_min 0.0630 (0.0492) teacher/usage_std 0.3351 (0.3274) nleep/row_max_mean 1557.5864 (1558.1507) nleep/row_max_std 47.5004 (49.8949) nleep/row_min_mean 1532.3926 (1530.6361) lr 1.7705e-03 eta 0:13:51
epoch [13/50] batch [100/167] time 0.088 (0.131) data 0.000 (0.003) loss 1.3772 (1.3059) teacher_loss 0.3748 (0.3267) loss_zs_kd 0.0118 (0.0171) loss_oracle 0.4872 (0.4765) kd_loss 0.7529 (0.7325) acc 90.6250 (87.5000) gate/entropy 0.9968 (0.9987) gate/usage_max 0.5535 (0.5514) gate/usage_min 0.2194 (0.2197) gate/usage_std 0.1557 (0.1542) teacher/entropy 0.0129 (0.0550) teacher/usage_max 0.8099 (0.7867) teacher/usage_min 0.0003 (0.0484) teacher/usage_std 0.3458 (0.3260) nleep/row_max_mean 1554.5637 (1558.2921) nleep/row_max_std 61.2699 (50.1396) nleep/row_min_mean 1524.2739 (1530.8374) lr 1.7705e-03 eta 0:13:35
epoch [13/50] batch [120/167] time 0.094 (0.128) data 0.000 (0.003) loss 1.1709 (1.3032) teacher_loss 0.2668 (0.3191) loss_zs_kd 0.0078 (0.0169) loss_oracle 0.4213 (0.4778) kd_loss 0.6895 (0.7368) acc 90.6250 (87.7344) gate/entropy 0.9965 (0.9983) gate/usage_max 0.5539 (0.5518) gate/usage_min 0.2194 (0.2196) gate/usage_std 0.1560 (0.1545) teacher/entropy 0.0746 (0.0538) teacher/usage_max 0.8097 (0.7830) teacher/usage_min 0.0118 (0.0457) teacher/usage_std 0.3436 (0.3240) nleep/row_max_mean 1565.6580 (1559.0322) nleep/row_max_std 55.4624 (50.5699) nleep/row_min_mean 1537.3896 (1531.4536) lr 1.7705e-03 eta 0:13:16
epoch [13/50] batch [140/167] time 0.074 (0.127) data 0.000 (0.002) loss 1.0447 (1.2996) teacher_loss 0.0776 (0.3144) loss_zs_kd 0.0032 (0.0173) loss_oracle 0.5321 (0.4776) kd_loss 0.6994 (0.7378) acc 96.8750 (87.9911) gate/entropy 0.9959 (0.9980) gate/usage_max 0.5546 (0.5522) gate/usage_min 0.2194 (0.2196) gate/usage_std 0.1565 (0.1548) teacher/entropy 0.1074 (0.0555) teacher/usage_max 0.7620 (0.7797) teacher/usage_min 0.0501 (0.0459) teacher/usage_std 0.3083 (0.3222) nleep/row_max_mean 1569.2214 (1559.4925) nleep/row_max_std 45.1601 (50.4101) nleep/row_min_mean 1541.3766 (1531.9258) lr 1.7705e-03 eta 0:13:06
epoch [13/50] batch [160/167] time 0.098 (0.122) data 0.000 (0.002) loss 1.2589 (1.3001) teacher_loss 0.2918 (0.3129) loss_zs_kd 0.0218 (0.0172) loss_oracle 0.4632 (0.4788) kd_loss 0.7246 (0.7392) acc 90.6250 (87.8711) gate/entropy 0.9952 (0.9977) gate/usage_max 0.5553 (0.5525) gate/usage_min 0.2192 (0.2195) gate/usage_std 0.1570 (0.1550) teacher/entropy 0.0826 (0.0558) teacher/usage_max 0.7613 (0.7774) teacher/usage_min 0.0005 (0.0452) teacher/usage_std 0.3178 (0.3209) nleep/row_max_mean 1554.9287 (1560.3565) nleep/row_max_std 62.7793 (50.7342) nleep/row_min_mean 1528.5244 (1532.6563) lr 1.7705e-03 eta 0:12:33
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,205
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [14/50] batch [20/167] time 0.155 (0.157) data 0.000 (0.013) loss 1.1543 (1.3075) teacher_loss 0.1185 (0.2984) loss_zs_kd 0.0151 (0.0184) loss_oracle 0.5406 (0.4840) kd_loss 0.7580 (0.7578) acc 96.8750 (89.2188) gate/entropy 0.9952 (0.9948) gate/usage_max 0.5553 (0.5557) gate/usage_min 0.2195 (0.2192) gate/usage_std 0.1570 (0.1573) teacher/entropy 0.1138 (0.0572) teacher/usage_max 0.6896 (0.7521) teacher/usage_min 0.1032 (0.0368) teacher/usage_std 0.2555 (0.3061) nleep/row_max_mean 1551.8662 (1560.1131) nleep/row_max_std 53.6059 (56.4689) nleep/row_min_mean 1525.4583 (1530.9106) lr 1.7290e-03 eta 0:16:06
epoch [14/50] batch [40/167] time 0.130 (0.151) data 0.000 (0.007) loss 1.5274 (1.3131) teacher_loss 0.4531 (0.2968) loss_zs_kd 0.0269 (0.0188) loss_oracle 0.4989 (0.4789) kd_loss 0.8114 (0.7675) acc 81.2500 (89.1406) gate/entropy 0.9939 (0.9947) gate/usage_max 0.5568 (0.5559) gate/usage_min 0.2190 (0.2192) gate/usage_std 0.1580 (0.1574) teacher/entropy 0.0355 (0.0580) teacher/usage_max 0.7162 (0.7405) teacher/usage_min 0.0309 (0.0351) teacher/usage_std 0.2855 (0.3013) nleep/row_max_mean 1561.0469 (1557.7755) nleep/row_max_std 48.8293 (54.8537) nleep/row_min_mean 1528.9509 (1529.1319) lr 1.7290e-03 eta 0:15:27
epoch [14/50] batch [60/167] time 0.156 (0.153) data 0.001 (0.005) loss 1.1692 (1.3311) teacher_loss 0.1779 (0.3133) loss_zs_kd 0.0348 (0.0196) loss_oracle 0.4588 (0.4784) kd_loss 0.7446 (0.7688) acc 96.8750 (88.8021) gate/entropy 0.9937 (0.9944) gate/usage_max 0.5569 (0.5562) gate/usage_min 0.2192 (0.2192) gate/usage_std 0.1581 (0.1576) teacher/entropy 0.0681 (0.0610) teacher/usage_max 0.7531 (0.7355) teacher/usage_min 0.0350 (0.0333) teacher/usage_std 0.3055 (0.2988) nleep/row_max_mean 1563.3270 (1558.9326) nleep/row_max_std 55.0152 (54.8215) nleep/row_min_mean 1535.0227 (1529.9961) lr 1.7290e-03 eta 0:15:35
epoch [14/50] batch [80/167] time 0.172 (0.152) data 0.000 (0.003) loss 1.1574 (1.3348) teacher_loss 0.1601 (0.3122) loss_zs_kd 0.0112 (0.0187) loss_oracle 0.4730 (0.4807) kd_loss 0.7551 (0.7729) acc 96.8750 (88.5547) gate/entropy 0.9932 (0.9941) gate/usage_max 0.5575 (0.5565) gate/usage_min 0.2191 (0.2192) gate/usage_std 0.1585 (0.1578) teacher/entropy 0.0399 (0.0605) teacher/usage_max 0.7714 (0.7313) teacher/usage_min 0.0317 (0.0298) teacher/usage_std 0.3170 (0.2977) nleep/row_max_mean 1561.2593 (1559.6366) nleep/row_max_std 47.7123 (54.7640) nleep/row_min_mean 1532.2026 (1530.3223) lr 1.7290e-03 eta 0:15:30
epoch [14/50] batch [100/167] time 0.157 (0.153) data 0.000 (0.003) loss 1.2792 (1.3344) teacher_loss 0.2442 (0.3079) loss_zs_kd 0.0051 (0.0187) loss_oracle 0.4448 (0.4805) kd_loss 0.8100 (0.7769) acc 87.5000 (88.5625) gate/entropy 0.9932 (0.9940) gate/usage_max 0.5575 (0.5567) gate/usage_min 0.2193 (0.2192) gate/usage_std 0.1585 (0.1579) teacher/entropy 0.0457 (0.0615) teacher/usage_max 0.7060 (0.7257) teacher/usage_min 0.0045 (0.0307) teacher/usage_std 0.2881 (0.2941) nleep/row_max_mean 1551.5593 (1559.4943) nleep/row_max_std 55.4247 (54.9200) nleep/row_min_mean 1520.0547 (1529.8292) lr 1.7290e-03 eta 0:15:30
epoch [14/50] batch [120/167] time 0.151 (0.152) data 0.000 (0.002) loss 1.2584 (1.3327) teacher_loss 0.2973 (0.3079) loss_zs_kd 0.0140 (0.0189) loss_oracle 0.4472 (0.4789) kd_loss 0.7305 (0.7758) acc 87.5000 (88.7240) gate/entropy 0.9922 (0.9938) gate/usage_max 0.5586 (0.5569) gate/usage_min 0.2189 (0.2192) gate/usage_std 0.1593 (0.1581) teacher/entropy 0.0366 (0.0599) teacher/usage_max 0.8011 (0.7283) teacher/usage_min 0.0079 (0.0286) teacher/usage_std 0.3391 (0.2964) nleep/row_max_mean 1563.1816 (1559.2716) nleep/row_max_std 49.3458 (54.8054) nleep/row_min_mean 1530.6171 (1529.3599) lr 1.7290e-03 eta 0:15:21
epoch [14/50] batch [140/167] time 0.125 (0.152) data 0.000 (0.002) loss 1.6465 (1.3373) teacher_loss 0.5408 (0.3112) loss_zs_kd 0.0236 (0.0187) loss_oracle 0.4837 (0.4803) kd_loss 0.8521 (0.7766) acc 78.1250 (88.4821) gate/entropy 0.9923 (0.9935) gate/usage_max 0.5584 (0.5571) gate/usage_min 0.2192 (0.2191) gate/usage_std 0.1592 (0.1583) teacher/entropy 0.0369 (0.0584) teacher/usage_max 0.6695 (0.7289) teacher/usage_min 0.0002 (0.0272) teacher/usage_std 0.2732 (0.2970) nleep/row_max_mean 1544.3602 (1558.4372) nleep/row_max_std 55.6511 (54.6846) nleep/row_min_mean 1512.4966 (1528.3940) lr 1.7290e-03 eta 0:15:15
epoch [14/50] batch [160/167] time 0.141 (0.150) data 0.000 (0.002) loss 1.3242 (1.3337) teacher_loss 0.4034 (0.3144) loss_zs_kd 0.0185 (0.0186) loss_oracle 0.4374 (0.4777) kd_loss 0.6929 (0.7712) acc 81.2500 (88.3008) gate/entropy 0.9914 (0.9933) gate/usage_max 0.5595 (0.5574) gate/usage_min 0.2188 (0.2191) gate/usage_std 0.1599 (0.1584) teacher/entropy 0.0428 (0.0589) teacher/usage_max 0.8333 (0.7339) teacher/usage_min 0.0000 (0.0265) teacher/usage_std 0.3600 (0.2998) nleep/row_max_mean 1560.1591 (1558.0919) nleep/row_max_std 50.8191 (54.3982) nleep/row_min_mean 1530.6429 (1528.0752) lr 1.7290e-03 eta 0:15:02
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [15/50] batch [20/167] time 0.159 (0.123) data 0.000 (0.015) loss 1.2252 (1.3162) teacher_loss 0.2414 (0.2981) loss_zs_kd 0.0244 (0.0153) loss_oracle 0.4553 (0.4763) kd_loss 0.7439 (0.7723) acc 90.6250 (89.2188) gate/entropy 0.9914 (0.9915) gate/usage_max 0.5594 (0.5594) gate/usage_min 0.2190 (0.2190) gate/usage_std 0.1599 (0.1598) teacher/entropy 0.0091 (0.0481) teacher/usage_max 0.8137 (0.7418) teacher/usage_min 0.0001 (0.0291) teacher/usage_std 0.3481 (0.3023) nleep/row_max_mean 1564.3674 (1558.7009) nleep/row_max_std 45.5439 (51.0486) nleep/row_min_mean 1536.4971 (1528.5440) lr 1.6845e-03 eta 0:12:18
epoch [15/50] batch [40/167] time 0.196 (0.117) data 0.000 (0.008) loss 1.4052 (1.3452) teacher_loss 0.4046 (0.3296) loss_zs_kd 0.0119 (0.0177) loss_oracle 0.4573 (0.4809) kd_loss 0.7659 (0.7663) acc 81.2500 (87.1875) gate/entropy 0.9913 (0.9914) gate/usage_max 0.5596 (0.5595) gate/usage_min 0.2190 (0.2190) gate/usage_std 0.1600 (0.1599) teacher/entropy 0.0550 (0.0555) teacher/usage_max 0.7403 (0.7401) teacher/usage_min 0.0625 (0.0316) teacher/usage_std 0.2930 (0.3019) nleep/row_max_mean 1551.9756 (1556.5965) nleep/row_max_std 48.3802 (51.6186) nleep/row_min_mean 1525.3114 (1527.0592) lr 1.6845e-03 eta 0:11:39
epoch [15/50] batch [60/167] time 0.091 (0.112) data 0.001 (0.005) loss 1.3186 (1.3491) teacher_loss 0.2442 (0.3137) loss_zs_kd 0.0069 (0.0176) loss_oracle 0.4276 (0.4857) kd_loss 0.8571 (0.7838) acc 84.3750 (87.3438) gate/entropy 0.9912 (0.9912) gate/usage_max 0.5596 (0.5597) gate/usage_min 0.2191 (0.2189) gate/usage_std 0.1600 (0.1600) teacher/entropy 0.0546 (0.0564) teacher/usage_max 0.6429 (0.7203) teacher/usage_min 0.0311 (0.0344) teacher/usage_std 0.2498 (0.2906) nleep/row_max_mean 1553.0645 (1556.9636) nleep/row_max_std 55.8282 (51.6545) nleep/row_min_mean 1526.3386 (1527.3058) lr 1.6845e-03 eta 0:11:08
epoch [15/50] batch [80/167] time 0.087 (0.112) data 0.000 (0.004) loss 1.2593 (1.3564) teacher_loss 0.2923 (0.3142) loss_zs_kd 0.0258 (0.0179) loss_oracle 0.4498 (0.4855) kd_loss 0.7291 (0.7906) acc 87.5000 (87.3047) gate/entropy 0.9905 (0.9910) gate/usage_max 0.5605 (0.5599) gate/usage_min 0.2188 (0.2189) gate/usage_std 0.1606 (0.1602) teacher/entropy 0.0687 (0.0531) teacher/usage_max 0.7648 (0.7164) teacher/usage_min 0.0420 (0.0368) teacher/usage_std 0.3113 (0.2882) nleep/row_max_mean 1559.1890 (1558.4366) nleep/row_max_std 48.7337 (51.5398) nleep/row_min_mean 1531.6600 (1528.7722) lr 1.6845e-03 eta 0:11:03
epoch [15/50] batch [100/167] time 0.080 (0.113) data 0.000 (0.003) loss 1.5741 (1.3620) teacher_loss 0.5946 (0.3153) loss_zs_kd 0.0293 (0.0184) loss_oracle 0.4398 (0.4804) kd_loss 0.7450 (0.7973) acc 71.8750 (87.1875) gate/entropy 0.9902 (0.9909) gate/usage_max 0.5608 (0.5600) gate/usage_min 0.2188 (0.2189) gate/usage_std 0.1608 (0.1603) teacher/entropy 0.0596 (0.0527) teacher/usage_max 0.7567 (0.7094) teacher/usage_min 0.0943 (0.0425) teacher/usage_std 0.3002 (0.2828) nleep/row_max_mean 1570.6899 (1558.9152) nleep/row_max_std 44.6336 (51.3219) nleep/row_min_mean 1543.5487 (1529.3309) lr 1.6845e-03 eta 0:11:06
epoch [15/50] batch [120/167] time 0.089 (0.113) data 0.000 (0.003) loss 1.3954 (1.3602) teacher_loss 0.2268 (0.3123) loss_zs_kd 0.0195 (0.0188) loss_oracle 0.5086 (0.4733) kd_loss 0.9046 (0.8019) acc 90.6250 (87.2396) gate/entropy 0.9902 (0.9908) gate/usage_max 0.5607 (0.5601) gate/usage_min 0.2189 (0.2189) gate/usage_std 0.1608 (0.1604) teacher/entropy 0.0319 (0.0534) teacher/usage_max 0.6159 (0.7035) teacher/usage_min 0.0937 (0.0465) teacher/usage_std 0.2153 (0.2787) nleep/row_max_mean 1551.7600 (1559.0207) nleep/row_max_std 56.4921 (52.3059) nleep/row_min_mean 1523.8274 (1529.5408) lr 1.6845e-03 eta 0:11:05
epoch [15/50] batch [140/167] time 0.146 (0.119) data 0.000 (0.002) loss 1.2180 (1.3595) teacher_loss 0.3737 (0.3117) loss_zs_kd 0.0068 (0.0183) loss_oracle 0.4384 (0.4704) kd_loss 0.6217 (0.8035) acc 84.3750 (87.4330) gate/entropy 0.9899 (0.9907) gate/usage_max 0.5611 (0.5602) gate/usage_min 0.2188 (0.2189) gate/usage_std 0.1611 (0.1605) teacher/entropy 0.0770 (0.0541) teacher/usage_max 0.8706 (0.7010) teacher/usage_min 0.0140 (0.0476) teacher/usage_std 0.3822 (0.2772) nleep/row_max_mean 1560.4132 (1559.1606) nleep/row_max_std 58.2891 (53.0542) nleep/row_min_mean 1531.1968 (1529.6995) lr 1.6845e-03 eta 0:11:40
epoch [15/50] batch [160/167] time 0.158 (0.124) data 0.000 (0.002) loss 1.4057 (1.3604) teacher_loss 0.2367 (0.3086) loss_zs_kd 0.0134 (0.0180) loss_oracle 0.5209 (0.4688) kd_loss 0.9018 (0.8085) acc 90.6250 (87.6562) gate/entropy 0.9898 (0.9906) gate/usage_max 0.5612 (0.5604) gate/usage_min 0.2189 (0.2189) gate/usage_std 0.1611 (0.1605) teacher/entropy 0.0472 (0.0545) teacher/usage_max 0.6020 (0.6952) teacher/usage_min 0.1068 (0.0494) teacher/usage_std 0.2043 (0.2734) nleep/row_max_mean 1547.1298 (1558.4452) nleep/row_max_std 72.9967 (53.8622) nleep/row_min_mean 1516.3472 (1529.0986) lr 1.6845e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,310
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 98.5%
******* Domain c best val acc:      96.2%, epoch: 10 *******
******* Domain c best val test acc: 99.1%, epoch: 10 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [16/50] batch [20/167] time 0.116 (0.159) data 0.000 (0.014) loss 1.3235 (1.3854) teacher_loss 0.2040 (0.2930) loss_zs_kd 0.0147 (0.0175) loss_oracle 0.5136 (0.5102) kd_loss 0.8553 (0.8286) acc 93.7500 (87.9688) gate/entropy 0.9896 (0.9895) gate/usage_max 0.5614 (0.5615) gate/usage_min 0.2189 (0.2188) gate/usage_std 0.1613 (0.1613) teacher/entropy 0.0918 (0.0556) teacher/usage_max 0.6040 (0.6712) teacher/usage_min 0.0938 (0.0700) teacher/usage_std 0.2094 (0.2547) nleep/row_max_mean 1557.9573 (1555.1008) nleep/row_max_std 43.5334 (53.9333) nleep/row_min_mean 1530.8743 (1526.2523) lr 1.6374e-03 eta 0:15:24
epoch [16/50] batch [40/167] time 0.133 (0.150) data 0.000 (0.007) loss 1.3161 (1.3561) teacher_loss 0.3061 (0.2847) loss_zs_kd 0.0251 (0.0178) loss_oracle 0.5120 (0.5005) kd_loss 0.7415 (0.8121) acc 90.6250 (88.4375) gate/entropy 0.9893 (0.9894) gate/usage_max 0.5617 (0.5616) gate/usage_min 0.2188 (0.2188) gate/usage_std 0.1615 (0.1614) teacher/entropy 0.0334 (0.0535) teacher/usage_max 0.7872 (0.6909) teacher/usage_min 0.0215 (0.0648) teacher/usage_std 0.3283 (0.2667) nleep/row_max_mean 1561.3104 (1558.2972) nleep/row_max_std 52.3740 (53.5467) nleep/row_min_mean 1532.2961 (1529.1328) lr 1.6374e-03 eta 0:14:29
epoch [16/50] batch [60/167] time 0.135 (0.147) data 0.000 (0.005) loss 1.3502 (1.3593) teacher_loss 0.3586 (0.2797) loss_zs_kd 0.0233 (0.0187) loss_oracle 0.4544 (0.4955) kd_loss 0.7528 (0.8225) acc 87.5000 (88.5938) gate/entropy 0.9887 (0.9893) gate/usage_max 0.5624 (0.5617) gate/usage_min 0.2186 (0.2188) gate/usage_std 0.1620 (0.1615) teacher/entropy 0.0605 (0.0526) teacher/usage_max 0.7468 (0.6807) teacher/usage_min 0.0573 (0.0699) teacher/usage_std 0.2978 (0.2595) nleep/row_max_mean 1563.4109 (1558.1512) nleep/row_max_std 55.7331 (54.9195) nleep/row_min_mean 1533.6964 (1528.7678) lr 1.6374e-03 eta 0:14:10
epoch [16/50] batch [80/167] time 0.166 (0.146) data 0.000 (0.004) loss 1.3767 (1.3591) teacher_loss 0.2523 (0.2778) loss_zs_kd 0.0166 (0.0179) loss_oracle 0.4307 (0.4878) kd_loss 0.9007 (0.8285) acc 93.7500 (88.9062) gate/entropy 0.9891 (0.9893) gate/usage_max 0.5620 (0.5617) gate/usage_min 0.2188 (0.2188) gate/usage_std 0.1617 (0.1615) teacher/entropy 0.0966 (0.0562) teacher/usage_max 0.5507 (0.6706) teacher/usage_min 0.1587 (0.0722) teacher/usage_std 0.1629 (0.2542) nleep/row_max_mean 1550.7201 (1557.6420) nleep/row_max_std 69.2041 (55.7165) nleep/row_min_mean 1524.9503 (1528.3113) lr 1.6374e-03 eta 0:14:03
epoch [16/50] batch [100/167] time 0.100 (0.138) data 0.000 (0.003) loss 1.2595 (1.3682) teacher_loss 0.1727 (0.2859) loss_zs_kd 0.0212 (0.0188) loss_oracle 0.4802 (0.4807) kd_loss 0.8361 (0.8326) acc 90.6250 (88.6562) gate/entropy 0.9890 (0.9892) gate/usage_max 0.5621 (0.5618) gate/usage_min 0.2188 (0.2188) gate/usage_std 0.1617 (0.1616) teacher/entropy 0.0855 (0.0587) teacher/usage_max 0.6312 (0.6635) teacher/usage_min 0.0558 (0.0760) teacher/usage_std 0.2354 (0.2497) nleep/row_max_mean 1557.2231 (1558.5055) nleep/row_max_std 63.6882 (55.9105) nleep/row_min_mean 1526.7673 (1529.2094) lr 1.6374e-03 eta 0:13:10
epoch [16/50] batch [120/167] time 0.060 (0.135) data 0.000 (0.002) loss 1.3383 (1.3763) teacher_loss 0.1995 (0.2862) loss_zs_kd 0.0195 (0.0191) loss_oracle 0.3876 (0.4761) kd_loss 0.9353 (0.8424) acc 93.7500 (88.4375) gate/entropy 0.9891 (0.9891) gate/usage_max 0.5620 (0.5619) gate/usage_min 0.2189 (0.2188) gate/usage_std 0.1617 (0.1616) teacher/entropy 0.0581 (0.0587) teacher/usage_max 0.5542 (0.6551) teacher/usage_min 0.0925 (0.0801) teacher/usage_std 0.1890 (0.2439) nleep/row_max_mean 1558.2063 (1558.6430) nleep/row_max_std 52.8388 (55.7318) nleep/row_min_mean 1528.5736 (1529.2894) lr 1.6374e-03 eta 0:12:52
epoch [16/50] batch [140/167] time 0.089 (0.130) data 0.000 (0.002) loss 1.3525 (1.3838) teacher_loss 0.2916 (0.2867) loss_zs_kd 0.0196 (0.0192) loss_oracle 0.4122 (0.4733) kd_loss 0.8451 (0.8508) acc 87.5000 (88.5714) gate/entropy 0.9882 (0.9891) gate/usage_max 0.5629 (0.5620) gate/usage_min 0.2186 (0.2188) gate/usage_std 0.1623 (0.1617) teacher/entropy 0.0414 (0.0584) teacher/usage_max 0.6691 (0.6462) teacher/usage_min 0.1223 (0.0868) teacher/usage_std 0.2400 (0.2376) nleep/row_max_mean 1564.6422 (1558.9367) nleep/row_max_std 54.1496 (55.5610) nleep/row_min_mean 1536.0928 (1529.5682) lr 1.6374e-03 eta 0:12:23
epoch [16/50] batch [160/167] time 0.078 (0.126) data 0.000 (0.002) loss 1.6671 (1.3933) teacher_loss 0.3453 (0.2867) loss_zs_kd 0.0270 (0.0196) loss_oracle 0.4933 (0.4721) kd_loss 1.0617 (0.8607) acc 81.2500 (88.5156) gate/entropy 0.9887 (0.9890) gate/usage_max 0.5623 (0.5620) gate/usage_min 0.2188 (0.2188) gate/usage_std 0.1619 (0.1617) teacher/entropy 0.0112 (0.0573) teacher/usage_max 0.4694 (0.6369) teacher/usage_min 0.0618 (0.0905) teacher/usage_std 0.1920 (0.2320) nleep/row_max_mean 1548.5734 (1558.8954) nleep/row_max_std 49.6477 (55.6653) nleep/row_min_mean 1523.3179 (1529.4792) lr 1.6374e-03 eta 0:11:55
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,211
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,315
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.7%
******* Domain c best val acc:      96.3%, epoch: 16 *******
******* Domain c best val test acc: 98.8%, epoch: 16 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [17/50] batch [20/167] time 0.086 (0.137) data 0.000 (0.019) loss 1.4479 (1.4518) teacher_loss 0.1599 (0.2709) loss_zs_kd 0.0138 (0.0270) loss_oracle 0.4830 (0.5170) kd_loss 1.0395 (0.9088) acc 90.6250 (89.3750) gate/entropy 0.9887 (0.9886) gate/usage_max 0.5624 (0.5625) gate/usage_min 0.2187 (0.2187) gate/usage_std 0.1620 (0.1620) teacher/entropy 0.0246 (0.0473) teacher/usage_max 0.4798 (0.5941) teacher/usage_min 0.1866 (0.1357) teacher/usage_std 0.1197 (0.1975) nleep/row_max_mean 1559.8998 (1563.3524) nleep/row_max_std 42.6167 (49.2493) nleep/row_min_mean 1531.6743 (1533.1562) lr 1.5878e-03 eta 0:12:56
epoch [17/50] batch [40/167] time 0.148 (0.126) data 0.000 (0.009) loss 1.3691 (1.4547) teacher_loss 0.1526 (0.2797) loss_zs_kd 0.0189 (0.0264) loss_oracle 0.4784 (0.4896) kd_loss 0.9678 (0.9170) acc 96.8750 (89.7656) gate/entropy 0.9886 (0.9886) gate/usage_max 0.5625 (0.5625) gate/usage_min 0.2186 (0.2186) gate/usage_std 0.1620 (0.1621) teacher/entropy 0.0216 (0.0411) teacher/usage_max 0.5596 (0.5920) teacher/usage_min 0.1550 (0.1371) teacher/usage_std 0.1686 (0.1962) nleep/row_max_mean 1564.8843 (1561.9334) nleep/row_max_std 50.7634 (50.4067) nleep/row_min_mean 1534.5884 (1531.9656) lr 1.5878e-03 eta 0:11:52
epoch [17/50] batch [60/167] time 0.136 (0.134) data 0.000 (0.006) loss 1.5355 (1.4457) teacher_loss 0.5400 (0.2947) loss_zs_kd 0.0160 (0.0259) loss_oracle 0.5278 (0.4813) kd_loss 0.7236 (0.8974) acc 81.2500 (89.0104) gate/entropy 0.9878 (0.9885) gate/usage_max 0.5633 (0.5626) gate/usage_min 0.2181 (0.2186) gate/usage_std 0.1626 (0.1621) teacher/entropy 0.0420 (0.0448) teacher/usage_max 0.7960 (0.6090) teacher/usage_min 0.0699 (0.1265) teacher/usage_std 0.3282 (0.2084) nleep/row_max_mean 1574.3953 (1562.2912) nleep/row_max_std 41.6089 (50.9547) nleep/row_min_mean 1542.4805 (1532.0753) lr 1.5878e-03 eta 0:12:35
epoch [17/50] batch [80/167] time 0.133 (0.137) data 0.000 (0.005) loss 1.3837 (1.4312) teacher_loss 0.2457 (0.2953) loss_zs_kd 0.0143 (0.0244) loss_oracle 0.5499 (0.4810) kd_loss 0.8559 (0.8833) acc 93.7500 (88.9062) gate/entropy 0.9881 (0.9884) gate/usage_max 0.5630 (0.5627) gate/usage_min 0.2183 (0.2185) gate/usage_std 0.1624 (0.1622) teacher/entropy 0.0664 (0.0459) teacher/usage_max 0.6302 (0.6230) teacher/usage_min 0.1569 (0.1186) teacher/usage_std 0.2111 (0.2181) nleep/row_max_mean 1550.1439 (1561.0063) nleep/row_max_std 59.6078 (52.2973) nleep/row_min_mean 1521.1992 (1530.6555) lr 1.5878e-03 eta 0:12:46
epoch [17/50] batch [100/167] time 0.160 (0.139) data 0.000 (0.004) loss 1.4742 (1.4281) teacher_loss 0.2453 (0.2963) loss_zs_kd 0.0224 (0.0247) loss_oracle 0.5477 (0.4879) kd_loss 0.9438 (0.8755) acc 87.5000 (88.7500) gate/entropy 0.9880 (0.9884) gate/usage_max 0.5631 (0.5627) gate/usage_min 0.2182 (0.2185) gate/usage_std 0.1625 (0.1622) teacher/entropy 0.0214 (0.0451) teacher/usage_max 0.5839 (0.6320) teacher/usage_min 0.1035 (0.1116) teacher/usage_std 0.1966 (0.2246) nleep/row_max_mean 1547.1871 (1558.8492) nleep/row_max_std 60.3741 (53.4860) nleep/row_min_mean 1517.2467 (1528.3495) lr 1.5878e-03 eta 0:12:55
epoch [17/50] batch [120/167] time 0.158 (0.140) data 0.000 (0.003) loss 1.6237 (1.4303) teacher_loss 0.4676 (0.2961) loss_zs_kd 0.0393 (0.0246) loss_oracle 0.5182 (0.4930) kd_loss 0.8774 (0.8755) acc 78.1250 (88.5677) gate/entropy 0.9877 (0.9883) gate/usage_max 0.5634 (0.5627) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1627 (0.1622) teacher/entropy 0.0790 (0.0468) teacher/usage_max 0.5938 (0.6300) teacher/usage_min 0.1000 (0.1113) teacher/usage_std 0.2025 (0.2236) nleep/row_max_mean 1552.0466 (1557.7473) nleep/row_max_std 53.6271 (54.1648) nleep/row_min_mean 1523.7788 (1527.2475) lr 1.5878e-03 eta 0:13:00
epoch [17/50] batch [140/167] time 0.148 (0.142) data 0.000 (0.003) loss 1.5704 (1.4343) teacher_loss 0.3011 (0.2892) loss_zs_kd 0.0294 (0.0243) loss_oracle 0.5660 (0.5020) kd_loss 0.9716 (0.8820) acc 84.3750 (89.0402) gate/entropy 0.9878 (0.9883) gate/usage_max 0.5633 (0.5628) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1626 (0.1622) teacher/entropy 0.0186 (0.0460) teacher/usage_max 0.5581 (0.6241) teacher/usage_min 0.1243 (0.1129) teacher/usage_std 0.1775 (0.2202) nleep/row_max_mean 1552.6155 (1556.3823) nleep/row_max_std 52.5100 (54.2484) nleep/row_min_mean 1524.6633 (1526.0416) lr 1.5878e-03 eta 0:13:08
epoch [17/50] batch [160/167] time 0.149 (0.143) data 0.000 (0.003) loss 1.5383 (1.4391) teacher_loss 0.3613 (0.2899) loss_zs_kd 0.0218 (0.0245) loss_oracle 0.5061 (0.5036) kd_loss 0.9131 (0.8851) acc 84.3750 (88.9062) gate/entropy 0.9879 (0.9883) gate/usage_max 0.5632 (0.5628) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1625 (0.1623) teacher/entropy 0.0511 (0.0476) teacher/usage_max 0.5862 (0.6191) teacher/usage_min 0.1575 (0.1164) teacher/usage_std 0.1833 (0.2165) nleep/row_max_mean 1560.1718 (1555.2845) nleep/row_max_std 51.4226 (53.9425) nleep/row_min_mean 1527.8672 (1525.0748) lr 1.5878e-03 eta 0:13:09
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,317
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.8%
******* Domain c best val acc:      96.3%, epoch: 16 *******
******* Domain c best val test acc: 98.8%, epoch: 16 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [18/50] batch [20/167] time 0.086 (0.110) data 0.000 (0.013) loss 1.4878 (1.4530) teacher_loss 0.1156 (0.2408) loss_zs_kd 0.0370 (0.0233) loss_oracle 0.4580 (0.5237) kd_loss 1.1248 (0.9387) acc 96.8750 (90.6250) gate/entropy 0.9879 (0.9881) gate/usage_max 0.5632 (0.5630) gate/usage_min 0.2180 (0.2181) gate/usage_std 0.1625 (0.1624) teacher/entropy 0.0602 (0.0577) teacher/usage_max 0.4236 (0.5547) teacher/usage_min 0.2238 (0.1231) teacher/usage_std 0.0827 (0.1834) nleep/row_max_mean 1540.9574 (1546.6235) nleep/row_max_std 48.8640 (51.8712) nleep/row_min_mean 1516.7493 (1516.8328) lr 1.5358e-03 eta 0:10:01
epoch [18/50] batch [40/167] time 0.134 (0.114) data 0.000 (0.007) loss 1.2728 (1.4373) teacher_loss 0.1909 (0.2484) loss_zs_kd 0.0247 (0.0235) loss_oracle 0.5080 (0.5017) kd_loss 0.8155 (0.9263) acc 93.7500 (90.2344) gate/entropy 0.9875 (0.9880) gate/usage_max 0.5637 (0.5631) gate/usage_min 0.2176 (0.2180) gate/usage_std 0.1629 (0.1624) teacher/entropy 0.1178 (0.0577) teacher/usage_max 0.6191 (0.5661) teacher/usage_min 0.1219 (0.1290) teacher/usage_std 0.2097 (0.1859) nleep/row_max_mean 1556.7917 (1548.9498) nleep/row_max_std 52.3037 (51.9580) nleep/row_min_mean 1528.0198 (1518.7483) lr 1.5358e-03 eta 0:10:21
epoch [18/50] batch [60/167] time 0.081 (0.109) data 0.001 (0.005) loss 1.5827 (1.4532) teacher_loss 0.3669 (0.2664) loss_zs_kd 0.0240 (0.0221) loss_oracle 0.5863 (0.5023) kd_loss 0.9106 (0.9246) acc 84.3750 (89.3229) gate/entropy 0.9879 (0.9880) gate/usage_max 0.5632 (0.5631) gate/usage_min 0.2179 (0.2180) gate/usage_std 0.1625 (0.1625) teacher/entropy 0.0589 (0.0588) teacher/usage_max 0.5789 (0.5710) teacher/usage_min 0.1039 (0.1250) teacher/usage_std 0.1942 (0.1887) nleep/row_max_mean 1551.8401 (1548.7812) nleep/row_max_std 62.7315 (51.5700) nleep/row_min_mean 1520.3320 (1518.6736) lr 1.5358e-03 eta 0:09:53
epoch [18/50] batch [80/167] time 0.174 (0.111) data 0.000 (0.003) loss 1.5211 (1.4653) teacher_loss 0.2876 (0.2764) loss_zs_kd 0.0199 (0.0236) loss_oracle 0.5797 (0.5011) kd_loss 0.9337 (0.9266) acc 90.6250 (89.2188) gate/entropy 0.9880 (0.9880) gate/usage_max 0.5631 (0.5631) gate/usage_min 0.2179 (0.2179) gate/usage_std 0.1624 (0.1625) teacher/entropy 0.1340 (0.0598) teacher/usage_max 0.4748 (0.5672) teacher/usage_min 0.1102 (0.1165) teacher/usage_std 0.1597 (0.1898) nleep/row_max_mean 1546.6272 (1548.8371) nleep/row_max_std 55.3204 (51.2947) nleep/row_min_mean 1519.5762 (1518.4060) lr 1.5358e-03 eta 0:10:04
epoch [18/50] batch [100/167] time 0.183 (0.112) data 0.000 (0.003) loss 1.5676 (1.4648) teacher_loss 0.3520 (0.2708) loss_zs_kd 0.0317 (0.0232) loss_oracle 0.5301 (0.5025) kd_loss 0.9347 (0.9312) acc 81.2500 (89.4062) gate/entropy 0.9877 (0.9880) gate/usage_max 0.5634 (0.5631) gate/usage_min 0.2176 (0.2179) gate/usage_std 0.1627 (0.1625) teacher/entropy 0.0671 (0.0599) teacher/usage_max 0.5459 (0.5622) teacher/usage_min 0.0937 (0.1110) teacher/usage_std 0.1856 (0.1905) nleep/row_max_mean 1556.8315 (1549.2492) nleep/row_max_std 48.5115 (51.6005) nleep/row_min_mean 1525.7181 (1518.5987) lr 1.5358e-03 eta 0:10:05
epoch [18/50] batch [120/167] time 0.078 (0.110) data 0.000 (0.002) loss 1.4147 (1.4601) teacher_loss 0.1566 (0.2628) loss_zs_kd 0.0256 (0.0239) loss_oracle 0.4860 (0.4999) kd_loss 1.0023 (0.9354) acc 93.7500 (89.7656) gate/entropy 0.9880 (0.9880) gate/usage_max 0.5631 (0.5631) gate/usage_min 0.2177 (0.2179) gate/usage_std 0.1625 (0.1625) teacher/entropy 0.0829 (0.0620) teacher/usage_max 0.4580 (0.5567) teacher/usage_min 0.2017 (0.1109) teacher/usage_std 0.1048 (0.1880) nleep/row_max_mean 1547.6411 (1549.6104) nleep/row_max_std 51.6160 (51.4904) nleep/row_min_mean 1521.3103 (1518.9460) lr 1.5358e-03 eta 0:09:51
epoch [18/50] batch [140/167] time 0.090 (0.109) data 0.000 (0.002) loss 1.5146 (1.4725) teacher_loss 0.3247 (0.2698) loss_zs_kd 0.0365 (0.0243) loss_oracle 0.4561 (0.4949) kd_loss 0.9435 (0.9431) acc 87.5000 (89.3080) gate/entropy 0.9876 (0.9880) gate/usage_max 0.5635 (0.5631) gate/usage_min 0.2174 (0.2178) gate/usage_std 0.1628 (0.1625) teacher/entropy 0.0137 (0.0611) teacher/usage_max 0.5924 (0.5507) teacher/usage_min 0.0618 (0.1123) teacher/usage_std 0.2168 (0.1849) nleep/row_max_mean 1560.1970 (1550.2704) nleep/row_max_std 51.0546 (51.4399) nleep/row_min_mean 1527.8462 (1519.5925) lr 1.5358e-03 eta 0:09:46
epoch [18/50] batch [160/167] time 0.062 (0.110) data 0.000 (0.002) loss 1.5591 (1.4807) teacher_loss 0.2922 (0.2729) loss_zs_kd 0.0245 (0.0248) loss_oracle 0.4912 (0.4940) kd_loss 1.0091 (0.9483) acc 84.3750 (89.2773) gate/entropy 0.9878 (0.9880) gate/usage_max 0.5634 (0.5631) gate/usage_min 0.2175 (0.2178) gate/usage_std 0.1626 (0.1625) teacher/entropy 0.0578 (0.0611) teacher/usage_max 0.4764 (0.5477) teacher/usage_min 0.1056 (0.1107) teacher/usage_std 0.1628 (0.1842) nleep/row_max_mean 1563.2505 (1551.2971) nleep/row_max_std 40.4041 (51.3867) nleep/row_min_mean 1534.1835 (1520.6606) lr 1.5358e-03 eta 0:09:47
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,212
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,317
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.8%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [19/50] batch [20/167] time 0.135 (0.174) data 0.000 (0.017) loss 1.5163 (1.5111) teacher_loss 0.2673 (0.2523) loss_zs_kd 0.0277 (0.0279) loss_oracle 0.4674 (0.4800) kd_loss 1.0014 (1.0049) acc 90.6250 (90.7812) gate/entropy 0.9884 (0.9881) gate/usage_max 0.5627 (0.5630) gate/usage_min 0.2177 (0.2176) gate/usage_std 0.1622 (0.1624) teacher/entropy 0.0144 (0.0612) teacher/usage_max 0.5279 (0.5277) teacher/usage_min 0.0008 (0.0886) teacher/usage_std 0.2363 (0.1872) nleep/row_max_mean 1556.8423 (1561.3361) nleep/row_max_std 50.6367 (52.7881) nleep/row_min_mean 1525.1208 (1531.4411) lr 1.4818e-03 eta 0:15:25
epoch [19/50] batch [40/167] time 0.193 (0.167) data 0.000 (0.009) loss 1.3864 (1.4929) teacher_loss 0.2228 (0.2572) loss_zs_kd 0.0279 (0.0246) loss_oracle 0.4686 (0.4671) kd_loss 0.9154 (0.9898) acc 87.5000 (90.1562) gate/entropy 0.9882 (0.9881) gate/usage_max 0.5628 (0.5630) gate/usage_min 0.2175 (0.2175) gate/usage_std 0.1623 (0.1624) teacher/entropy 0.0943 (0.0632) teacher/usage_max 0.5362 (0.5357) teacher/usage_min 0.0723 (0.0874) teacher/usage_std 0.1938 (0.1896) nleep/row_max_mean 1553.2322 (1562.4597) nleep/row_max_std 49.0608 (51.4508) nleep/row_min_mean 1522.6899 (1532.2607) lr 1.4818e-03 eta 0:14:45
epoch [19/50] batch [60/167] time 0.141 (0.162) data 0.001 (0.006) loss 1.4603 (1.4993) teacher_loss 0.1975 (0.2669) loss_zs_kd 0.0292 (0.0245) loss_oracle 0.5759 (0.4754) kd_loss 0.9602 (0.9826) acc 90.6250 (89.5833) gate/entropy 0.9884 (0.9881) gate/usage_max 0.5626 (0.5630) gate/usage_min 0.2176 (0.2175) gate/usage_std 0.1621 (0.1624) teacher/entropy 0.1347 (0.0679) teacher/usage_max 0.4459 (0.5316) teacher/usage_min 0.1533 (0.0877) teacher/usage_std 0.1286 (0.1883) nleep/row_max_mean 1552.0427 (1562.5279) nleep/row_max_std 42.3267 (50.4163) nleep/row_min_mean 1524.7739 (1532.2344) lr 1.4818e-03 eta 0:14:17
epoch [19/50] batch [80/167] time 0.141 (0.158) data 0.000 (0.004) loss 1.5324 (1.5017) teacher_loss 0.2308 (0.2641) loss_zs_kd 0.0404 (0.0261) loss_oracle 0.5383 (0.4777) kd_loss 1.0123 (0.9857) acc 93.7500 (89.8438) gate/entropy 0.9882 (0.9881) gate/usage_max 0.5629 (0.5630) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1623 (0.1624) teacher/entropy 0.0260 (0.0663) teacher/usage_max 0.5060 (0.5296) teacher/usage_min 0.0576 (0.0842) teacher/usage_std 0.1970 (0.1893) nleep/row_max_mean 1554.4404 (1562.3765) nleep/row_max_std 50.4202 (51.1577) nleep/row_min_mean 1523.9860 (1531.9951) lr 1.4818e-03 eta 0:13:51
epoch [19/50] batch [100/167] time 0.146 (0.156) data 0.000 (0.004) loss 1.4195 (1.4947) teacher_loss 0.1125 (0.2540) loss_zs_kd 0.0215 (0.0262) loss_oracle 0.4685 (0.4779) kd_loss 1.0620 (0.9886) acc 93.7500 (90.0625) gate/entropy 0.9882 (0.9881) gate/usage_max 0.5629 (0.5630) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1623 (0.1624) teacher/entropy 0.0108 (0.0661) teacher/usage_max 0.5321 (0.5349) teacher/usage_min 0.0005 (0.0797) teacher/usage_std 0.2368 (0.1933) nleep/row_max_mean 1559.3796 (1561.2599) nleep/row_max_std 69.2431 (52.1744) nleep/row_min_mean 1528.7101 (1530.8975) lr 1.4818e-03 eta 0:13:37
epoch [19/50] batch [120/167] time 0.154 (0.154) data 0.000 (0.003) loss 1.6929 (1.5010) teacher_loss 0.3743 (0.2534) loss_zs_kd 0.0280 (0.0269) loss_oracle 0.5008 (0.4817) kd_loss 1.0542 (0.9932) acc 84.3750 (90.2344) gate/entropy 0.9885 (0.9882) gate/usage_max 0.5626 (0.5629) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1621 (0.1623) teacher/entropy 0.0740 (0.0635) teacher/usage_max 0.5307 (0.5344) teacher/usage_min 0.0604 (0.0752) teacher/usage_std 0.1993 (0.1954) nleep/row_max_mean 1559.0148 (1560.8501) nleep/row_max_std 54.7787 (52.8153) nleep/row_min_mean 1528.8159 (1530.3663) lr 1.4818e-03 eta 0:13:27
epoch [19/50] batch [140/167] time 0.161 (0.152) data 0.000 (0.003) loss 1.6785 (1.5079) teacher_loss 0.4016 (0.2511) loss_zs_kd 0.0416 (0.0273) loss_oracle 0.5232 (0.4836) kd_loss 0.9945 (1.0013) acc 78.1250 (90.2902) gate/entropy 0.9879 (0.9882) gate/usage_max 0.5631 (0.5629) gate/usage_min 0.2169 (0.2174) gate/usage_std 0.1625 (0.1623) teacher/entropy 0.0505 (0.0602) teacher/usage_max 0.4970 (0.5364) teacher/usage_min 0.0129 (0.0699) teacher/usage_std 0.2266 (0.1988) nleep/row_max_mean 1562.4073 (1560.6085) nleep/row_max_std 54.6429 (53.2018) nleep/row_min_mean 1532.6223 (1530.0043) lr 1.4818e-03 eta 0:13:13
epoch [19/50] batch [160/167] time 0.078 (0.144) data 0.000 (0.002) loss 1.9087 (1.5083) teacher_loss 0.6489 (0.2495) loss_zs_kd 0.0389 (0.0275) loss_oracle 0.5197 (0.4860) kd_loss 0.9805 (1.0020) acc 68.7500 (90.2930) gate/entropy 0.9879 (0.9882) gate/usage_max 0.5632 (0.5629) gate/usage_min 0.2168 (0.2173) gate/usage_std 0.1626 (0.1623) teacher/entropy 0.0336 (0.0600) teacher/usage_max 0.5315 (0.5353) teacher/usage_min 0.0816 (0.0686) teacher/usage_std 0.1875 (0.1993) nleep/row_max_mean 1563.0083 (1560.3725) nleep/row_max_std 47.3899 (52.6642) nleep/row_min_mean 1528.0389 (1529.8095) lr 1.4818e-03 eta 0:12:28
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [20/50] batch [20/167] time 0.070 (0.132) data 0.000 (0.017) loss 1.3584 (1.5204) teacher_loss 0.1076 (0.2324) loss_zs_kd 0.0153 (0.0332) loss_oracle 0.4926 (0.4974) kd_loss 0.9969 (1.0227) acc 96.8750 (90.9375) gate/entropy 0.9893 (0.9886) gate/usage_max 0.5617 (0.5624) gate/usage_min 0.2173 (0.2170) gate/usage_std 0.1615 (0.1620) teacher/entropy 0.1386 (0.0522) teacher/usage_max 0.5407 (0.5302) teacher/usage_min 0.0585 (0.0520) teacher/usage_std 0.2026 (0.2056) nleep/row_max_mean 1546.2031 (1555.8879) nleep/row_max_std 51.5735 (51.1407) nleep/row_min_mean 1516.8997 (1524.9666) lr 1.4258e-03 eta 0:11:21
epoch [20/50] batch [40/167] time 0.115 (0.114) data 0.000 (0.009) loss 1.6286 (1.5381) teacher_loss 0.2980 (0.2451) loss_zs_kd 0.0316 (0.0308) loss_oracle 0.5316 (0.4950) kd_loss 1.0491 (1.0300) acc 90.6250 (90.6250) gate/entropy 0.9886 (0.9887) gate/usage_max 0.5625 (0.5623) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1620 (0.1619) teacher/entropy 0.0209 (0.0449) teacher/usage_max 0.4933 (0.5428) teacher/usage_min 0.0366 (0.0490) teacher/usage_std 0.2100 (0.2110) nleep/row_max_mean 1553.5867 (1552.8931) nleep/row_max_std 48.7989 (52.9942) nleep/row_min_mean 1524.6494 (1521.9697) lr 1.4258e-03 eta 0:09:43
epoch [20/50] batch [60/167] time 0.077 (0.113) data 0.001 (0.006) loss 1.8101 (1.5406) teacher_loss 0.3335 (0.2342) loss_zs_kd 0.0322 (0.0308) loss_oracle 0.6041 (0.5020) kd_loss 1.1584 (1.0400) acc 84.3750 (90.9375) gate/entropy 0.9886 (0.9888) gate/usage_max 0.5624 (0.5623) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1620 (0.1619) teacher/entropy 0.0521 (0.0416) teacher/usage_max 0.5733 (0.5500) teacher/usage_min 0.1054 (0.0454) teacher/usage_std 0.1912 (0.2158) nleep/row_max_mean 1555.1772 (1553.2102) nleep/row_max_std 48.6179 (52.1240) nleep/row_min_mean 1525.3826 (1522.4289) lr 1.4258e-03 eta 0:09:40
epoch [20/50] batch [80/167] time 0.077 (0.115) data 0.000 (0.004) loss 1.6335 (1.5354) teacher_loss 0.2959 (0.2245) loss_zs_kd 0.0376 (0.0305) loss_oracle 0.4593 (0.4998) kd_loss 1.0891 (1.0458) acc 84.3750 (91.1328) gate/entropy 0.9887 (0.9888) gate/usage_max 0.5623 (0.5622) gate/usage_min 0.2166 (0.2170) gate/usage_std 0.1619 (0.1618) teacher/entropy 0.0228 (0.0376) teacher/usage_max 0.5764 (0.5588) teacher/usage_min 0.0001 (0.0408) teacher/usage_std 0.2437 (0.2208) nleep/row_max_mean 1556.0376 (1552.9753) nleep/row_max_std 62.9329 (52.7885) nleep/row_min_mean 1520.0383 (1522.0116) lr 1.4258e-03 eta 0:09:45
epoch [20/50] batch [100/167] time 0.162 (0.115) data 0.000 (0.004) loss 1.5401 (1.5389) teacher_loss 0.2779 (0.2259) loss_zs_kd 0.0412 (0.0318) loss_oracle 0.4155 (0.4964) kd_loss 1.0339 (1.0489) acc 87.5000 (91.0312) gate/entropy 0.9890 (0.9889) gate/usage_max 0.5620 (0.5621) gate/usage_min 0.2166 (0.2169) gate/usage_std 0.1617 (0.1618) teacher/entropy 0.0491 (0.0353) teacher/usage_max 0.5120 (0.5555) teacher/usage_min 0.0323 (0.0402) teacher/usage_std 0.2141 (0.2200) nleep/row_max_mean 1550.9143 (1553.5510) nleep/row_max_std 49.5787 (53.2806) nleep/row_min_mean 1522.2263 (1522.4451) lr 1.4258e-03 eta 0:09:43
epoch [20/50] batch [120/167] time 0.189 (0.125) data 0.000 (0.003) loss 1.4466 (1.5351) teacher_loss 0.2404 (0.2266) loss_zs_kd 0.0157 (0.0316) loss_oracle 0.5443 (0.4928) kd_loss 0.9263 (1.0463) acc 93.7500 (90.8333) gate/entropy 0.9894 (0.9890) gate/usage_max 0.5616 (0.5620) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1614 (0.1617) teacher/entropy 0.0276 (0.0340) teacher/usage_max 0.5938 (0.5571) teacher/usage_min 0.0601 (0.0393) teacher/usage_std 0.2180 (0.2209) nleep/row_max_mean 1563.7683 (1554.4350) nleep/row_max_std 60.9763 (53.8036) nleep/row_min_mean 1526.8501 (1523.1270) lr 1.4258e-03 eta 0:10:29
epoch [20/50] batch [140/167] time 0.188 (0.132) data 0.000 (0.003) loss 1.6255 (1.5373) teacher_loss 0.3940 (0.2254) loss_zs_kd 0.0406 (0.0324) loss_oracle 0.4982 (0.4962) kd_loss 0.9621 (1.0477) acc 81.2500 (90.9375) gate/entropy 0.9889 (0.9891) gate/usage_max 0.5621 (0.5619) gate/usage_min 0.2164 (0.2169) gate/usage_std 0.1618 (0.1616) teacher/entropy 0.0197 (0.0329) teacher/usage_max 0.5625 (0.5529) teacher/usage_min 0.0096 (0.0397) teacher/usage_std 0.2354 (0.2198) nleep/row_max_mean 1570.7371 (1554.0389) nleep/row_max_std 58.5427 (54.0135) nleep/row_min_mean 1535.1976 (1522.7718) lr 1.4258e-03 eta 0:11:02
epoch [20/50] batch [160/167] time 0.162 (0.136) data 0.000 (0.002) loss 1.6273 (1.5383) teacher_loss 0.2901 (0.2281) loss_zs_kd 0.0240 (0.0317) loss_oracle 0.5089 (0.4966) kd_loss 1.0708 (1.0461) acc 84.3750 (90.9375) gate/entropy 0.9901 (0.9891) gate/usage_max 0.5608 (0.5618) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1608 (0.1616) teacher/entropy 0.0191 (0.0313) teacher/usage_max 0.5565 (0.5544) teacher/usage_min 0.0000 (0.0385) teacher/usage_std 0.2402 (0.2208) nleep/row_max_mean 1545.6835 (1554.6170) nleep/row_max_std 69.8526 (54.2941) nleep/row_min_mean 1515.9512 (1523.2706) lr 1.4258e-03 eta 0:11:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [21/50] batch [20/167] time 0.168 (0.183) data 0.000 (0.017) loss 1.7244 (1.5991) teacher_loss 0.4975 (0.2667) loss_zs_kd 0.0547 (0.0375) loss_oracle 0.4668 (0.5124) kd_loss 0.9661 (1.0575) acc 75.0000 (89.8438) gate/entropy 0.9896 (0.9899) gate/usage_max 0.5613 (0.5610) gate/usage_min 0.2163 (0.2165) gate/usage_std 0.1612 (0.1610) teacher/entropy 0.0249 (0.0217) teacher/usage_max 0.5523 (0.5768) teacher/usage_min 0.0325 (0.0269) teacher/usage_std 0.2200 (0.2317) nleep/row_max_mean 1564.7073 (1559.3749) nleep/row_max_std 53.3600 (56.1915) nleep/row_min_mean 1530.6848 (1526.6539) lr 1.3681e-03 eta 0:15:14
epoch [21/50] batch [40/167] time 0.071 (0.165) data 0.000 (0.009) loss 1.4642 (1.5843) teacher_loss 0.1463 (0.2581) loss_zs_kd 0.0061 (0.0323) loss_oracle 0.5070 (0.5154) kd_loss 1.0613 (1.0523) acc 93.7500 (90.0000) gate/entropy 0.9910 (0.9901) gate/usage_max 0.5599 (0.5608) gate/usage_min 0.2168 (0.2165) gate/usage_std 0.1602 (0.1609) teacher/entropy 0.0041 (0.0227) teacher/usage_max 0.5311 (0.5629) teacher/usage_min 0.0005 (0.0336) teacher/usage_std 0.2368 (0.2251) nleep/row_max_mean 1554.1897 (1557.9645) nleep/row_max_std 67.5824 (56.3751) nleep/row_min_mean 1521.4871 (1525.9754) lr 1.3681e-03 eta 0:13:39
epoch [21/50] batch [60/167] time 0.190 (0.144) data 0.001 (0.006) loss 1.4149 (1.5751) teacher_loss 0.1133 (0.2418) loss_zs_kd 0.0210 (0.0312) loss_oracle 0.4714 (0.5222) kd_loss 1.0554 (1.0567) acc 96.8750 (90.5729) gate/entropy 0.9903 (0.9902) gate/usage_max 0.5606 (0.5607) gate/usage_min 0.2163 (0.2165) gate/usage_std 0.1607 (0.1608) teacher/entropy 0.0101 (0.0200) teacher/usage_max 0.5283 (0.5656) teacher/usage_min 0.0030 (0.0288) teacher/usage_std 0.2349 (0.2285) nleep/row_max_mean 1573.6240 (1560.7177) nleep/row_max_std 57.9090 (55.0883) nleep/row_min_mean 1541.8020 (1528.3693) lr 1.3681e-03 eta 0:11:50
epoch [21/50] batch [80/167] time 0.188 (0.139) data 0.000 (0.004) loss 1.4408 (1.5722) teacher_loss 0.1817 (0.2368) loss_zs_kd 0.0358 (0.0327) loss_oracle 0.4894 (0.5190) kd_loss 0.9965 (1.0595) acc 93.7500 (91.0547) gate/entropy 0.9902 (0.9903) gate/usage_max 0.5607 (0.5606) gate/usage_min 0.2161 (0.2164) gate/usage_std 0.1608 (0.1608) teacher/entropy 0.0425 (0.0203) teacher/usage_max 0.5003 (0.5655) teacher/usage_min 0.0279 (0.0259) teacher/usage_std 0.2163 (0.2303) nleep/row_max_mean 1566.0790 (1561.7931) nleep/row_max_std 48.6206 (55.0459) nleep/row_min_mean 1536.1511 (1529.3321) lr 1.3681e-03 eta 0:11:26
epoch [21/50] batch [100/167] time 0.089 (0.136) data 0.000 (0.004) loss 1.3781 (1.5730) teacher_loss 0.1313 (0.2450) loss_zs_kd 0.0097 (0.0321) loss_oracle 0.4837 (0.5142) kd_loss 1.0001 (1.0549) acc 96.8750 (90.4688) gate/entropy 0.9907 (0.9904) gate/usage_max 0.5602 (0.5605) gate/usage_min 0.2161 (0.2164) gate/usage_std 0.1604 (0.1607) teacher/entropy 0.0072 (0.0189) teacher/usage_max 0.5326 (0.5642) teacher/usage_min 0.0001 (0.0226) teacher/usage_std 0.2372 (0.2318) nleep/row_max_mean 1575.0114 (1561.6969) nleep/row_max_std 44.6257 (54.7373) nleep/row_min_mean 1542.6289 (1529.2021) lr 1.3681e-03 eta 0:11:06
epoch [21/50] batch [120/167] time 0.191 (0.134) data 0.000 (0.003) loss 1.5160 (1.5700) teacher_loss 0.0737 (0.2396) loss_zs_kd 0.0171 (0.0315) loss_oracle 0.4765 (0.5135) kd_loss 1.1955 (1.0579) acc 100.0000 (90.4948) gate/entropy 0.9915 (0.9905) gate/usage_max 0.5593 (0.5604) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1598 (0.1606) teacher/entropy 0.0373 (0.0183) teacher/usage_max 0.6529 (0.5674) teacher/usage_min 0.0611 (0.0211) teacher/usage_std 0.2439 (0.2334) nleep/row_max_mean 1543.6305 (1560.8338) nleep/row_max_std 57.6448 (55.2214) nleep/row_min_mean 1514.2893 (1528.3650) lr 1.3681e-03 eta 0:10:55
epoch [21/50] batch [140/167] time 0.152 (0.130) data 0.000 (0.003) loss 1.6118 (1.5727) teacher_loss 0.2326 (0.2429) loss_zs_kd 0.0416 (0.0316) loss_oracle 0.5518 (0.5112) kd_loss 1.0824 (1.0584) acc 93.7500 (90.3795) gate/entropy 0.9912 (0.9906) gate/usage_max 0.5596 (0.5603) gate/usage_min 0.2159 (0.2163) gate/usage_std 0.1600 (0.1605) teacher/entropy 0.0136 (0.0174) teacher/usage_max 0.5623 (0.5676) teacher/usage_min 0.0042 (0.0186) teacher/usage_std 0.2386 (0.2350) nleep/row_max_mean 1564.8259 (1559.9070) nleep/row_max_std 48.3793 (55.3185) nleep/row_min_mean 1530.0565 (1527.4517) lr 1.3681e-03 eta 0:10:32
epoch [21/50] batch [160/167] time 0.162 (0.127) data 0.000 (0.002) loss 1.5773 (1.5726) teacher_loss 0.2385 (0.2405) loss_zs_kd 0.0483 (0.0319) loss_oracle 0.5779 (0.5107) kd_loss 1.0257 (1.0608) acc 90.6250 (90.4883) gate/entropy 0.9913 (0.9907) gate/usage_max 0.5595 (0.5601) gate/usage_min 0.2157 (0.2163) gate/usage_std 0.1600 (0.1604) teacher/entropy 0.0069 (0.0173) teacher/usage_max 0.5018 (0.5693) teacher/usage_min 0.0000 (0.0177) teacher/usage_std 0.2357 (0.2364) nleep/row_max_mean 1559.2061 (1559.1879) nleep/row_max_std 59.5608 (55.5882) nleep/row_min_mean 1525.3541 (1526.8120) lr 1.3681e-03 eta 0:10:15
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [22/50] batch [20/167] time 0.164 (0.159) data 0.000 (0.015) loss 1.4365 (1.5518) teacher_loss 0.1965 (0.2358) loss_zs_kd 0.0199 (0.0313) loss_oracle 0.4358 (0.4981) kd_loss 1.0121 (1.0512) acc 93.7500 (90.6250) gate/entropy 0.9921 (0.9920) gate/usage_max 0.5586 (0.5587) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1593 (0.1594) teacher/entropy 0.0348 (0.0150) teacher/usage_max 0.5053 (0.5627) teacher/usage_min 0.0088 (0.0061) teacher/usage_std 0.2296 (0.2404) nleep/row_max_mean 1554.1857 (1548.9878) nleep/row_max_std 56.8744 (56.1317) nleep/row_min_mean 1521.5908 (1517.8154) lr 1.3090e-03 eta 0:12:48
epoch [22/50] batch [40/167] time 0.131 (0.158) data 0.000 (0.007) loss 1.3596 (1.5441) teacher_loss 0.2193 (0.2353) loss_zs_kd 0.0320 (0.0315) loss_oracle 0.4865 (0.4796) kd_loss 0.8810 (1.0532) acc 90.6250 (90.0781) gate/entropy 0.9924 (0.9922) gate/usage_max 0.5583 (0.5585) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1591 (0.1593) teacher/entropy 0.0202 (0.0151) teacher/usage_max 0.6461 (0.5736) teacher/usage_min 0.0001 (0.0051) teacher/usage_std 0.2641 (0.2445) nleep/row_max_mean 1544.6702 (1548.3670) nleep/row_max_std 55.5357 (55.1886) nleep/row_min_mean 1514.5905 (1517.2849) lr 1.3090e-03 eta 0:12:40
epoch [22/50] batch [60/167] time 0.157 (0.154) data 0.001 (0.005) loss 1.3750 (1.5355) teacher_loss 0.0935 (0.2316) loss_zs_kd 0.0256 (0.0311) loss_oracle 0.3305 (0.4654) kd_loss 1.1034 (1.0556) acc 96.8750 (90.5729) gate/entropy 0.9931 (0.9923) gate/usage_max 0.5575 (0.5584) gate/usage_min 0.2157 (0.2157) gate/usage_std 0.1586 (0.1592) teacher/entropy 0.0250 (0.0144) teacher/usage_max 0.6071 (0.5727) teacher/usage_min 0.0008 (0.0065) teacher/usage_std 0.2510 (0.2429) nleep/row_max_mean 1540.7527 (1548.4206) nleep/row_max_std 58.8718 (55.3084) nleep/row_min_mean 1513.7498 (1517.2184) lr 1.3090e-03 eta 0:12:17
epoch [22/50] batch [80/167] time 0.119 (0.150) data 0.000 (0.004) loss 1.3350 (1.5242) teacher_loss 0.1505 (0.2265) loss_zs_kd 0.0092 (0.0308) loss_oracle 0.4720 (0.4663) kd_loss 0.9439 (1.0492) acc 96.8750 (90.7812) gate/entropy 0.9930 (0.9924) gate/usage_max 0.5576 (0.5582) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1586 (0.1591) teacher/entropy 0.0693 (0.0149) teacher/usage_max 0.5232 (0.5705) teacher/usage_min 0.0454 (0.0065) teacher/usage_std 0.2070 (0.2423) nleep/row_max_mean 1559.2020 (1549.9554) nleep/row_max_std 54.6013 (55.3958) nleep/row_min_mean 1530.1770 (1518.4747) lr 1.3090e-03 eta 0:11:53
epoch [22/50] batch [100/167] time 0.147 (0.148) data 0.000 (0.003) loss 1.4994 (1.5225) teacher_loss 0.1855 (0.2272) loss_zs_kd 0.0228 (0.0309) loss_oracle 0.4229 (0.4622) kd_loss 1.0911 (1.0487) acc 93.7500 (90.8125) gate/entropy 0.9941 (0.9926) gate/usage_max 0.5564 (0.5581) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1578 (0.1590) teacher/entropy 0.0195 (0.0147) teacher/usage_max 0.5901 (0.5750) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.2469 (0.2444) nleep/row_max_mean 1536.4508 (1550.7824) nleep/row_max_std 59.7860 (55.5279) nleep/row_min_mean 1505.2869 (1519.1094) lr 1.3090e-03 eta 0:11:40
epoch [22/50] batch [120/167] time 0.138 (0.148) data 0.000 (0.003) loss 1.6710 (1.5243) teacher_loss 0.2928 (0.2277) loss_zs_kd 0.0431 (0.0310) loss_oracle 0.5085 (0.4671) kd_loss 1.1024 (1.0476) acc 87.5000 (90.5990) gate/entropy 0.9938 (0.9927) gate/usage_max 0.5566 (0.5579) gate/usage_min 0.2153 (0.2155) gate/usage_std 0.1580 (0.1589) teacher/entropy 0.0137 (0.0147) teacher/usage_max 0.5653 (0.5737) teacher/usage_min 0.0299 (0.0058) teacher/usage_std 0.2243 (0.2440) nleep/row_max_mean 1546.7778 (1552.0970) nleep/row_max_std 65.1807 (55.6601) nleep/row_min_mean 1512.9712 (1519.9506) lr 1.3090e-03 eta 0:11:39
epoch [22/50] batch [140/167] time 0.152 (0.148) data 0.000 (0.002) loss 1.5654 (1.5183) teacher_loss 0.2847 (0.2274) loss_zs_kd 0.0486 (0.0310) loss_oracle 0.4364 (0.4640) kd_loss 1.0382 (1.0434) acc 87.5000 (90.6250) gate/entropy 0.9934 (0.9928) gate/usage_max 0.5572 (0.5578) gate/usage_min 0.2148 (0.2154) gate/usage_std 0.1584 (0.1588) teacher/entropy 0.0148 (0.0151) teacher/usage_max 0.5259 (0.5700) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.2366 (0.2433) nleep/row_max_mean 1565.3198 (1552.6848) nleep/row_max_std 32.0763 (55.9162) nleep/row_min_mean 1531.6433 (1520.4481) lr 1.3090e-03 eta 0:11:34
epoch [22/50] batch [160/167] time 0.067 (0.147) data 0.000 (0.002) loss 1.4223 (1.5154) teacher_loss 0.2178 (0.2282) loss_zs_kd 0.0214 (0.0306) loss_oracle 0.4507 (0.4633) kd_loss 0.9685 (1.0402) acc 96.8750 (90.6445) gate/entropy 0.9943 (0.9930) gate/usage_max 0.5561 (0.5576) gate/usage_min 0.2149 (0.2154) gate/usage_std 0.1576 (0.1587) teacher/entropy 0.0030 (0.0151) teacher/usage_max 0.5630 (0.5712) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.2413 (0.2437) nleep/row_max_mean 1552.2905 (1553.4407) nleep/row_max_std 66.5892 (56.3427) nleep/row_min_mean 1518.7621 (1521.1247) lr 1.3090e-03 eta 0:11:28
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,188
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [23/50] batch [20/167] time 0.102 (0.131) data 0.000 (0.016) loss 1.3570 (1.4940) teacher_loss 0.1812 (0.2363) loss_zs_kd 0.0255 (0.0338) loss_oracle 0.4145 (0.4615) kd_loss 0.9558 (1.0100) acc 93.7500 (91.2500) gate/entropy 0.9941 (0.9944) gate/usage_max 0.5562 (0.5559) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1577 (0.1575) teacher/entropy 0.0171 (0.0134) teacher/usage_max 0.5653 (0.5520) teacher/usage_min 0.0302 (0.0070) teacher/usage_std 0.2242 (0.2372) nleep/row_max_mean 1568.5198 (1557.9481) nleep/row_max_std 43.9745 (56.4442) nleep/row_min_mean 1531.0049 (1523.7333) lr 1.2487e-03 eta 0:10:11
epoch [23/50] batch [40/167] time 0.079 (0.128) data 0.000 (0.008) loss 1.3981 (1.4947) teacher_loss 0.2217 (0.2275) loss_zs_kd 0.0327 (0.0322) loss_oracle 0.4190 (0.4530) kd_loss 0.9506 (1.0246) acc 90.6250 (91.4062) gate/entropy 0.9949 (0.9946) gate/usage_max 0.5554 (0.5557) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1572 (0.1574) teacher/entropy 0.0366 (0.0141) teacher/usage_max 0.5461 (0.5558) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2387 (0.2400) nleep/row_max_mean 1551.8854 (1556.8202) nleep/row_max_std 52.6446 (56.9129) nleep/row_min_mean 1518.5001 (1523.4127) lr 1.2487e-03 eta 0:09:51
epoch [23/50] batch [60/167] time 0.097 (0.120) data 0.001 (0.005) loss 1.4488 (1.4891) teacher_loss 0.1846 (0.2152) loss_zs_kd 0.0351 (0.0313) loss_oracle 0.4608 (0.4674) kd_loss 1.0162 (1.0245) acc 90.6250 (91.8750) gate/entropy 0.9948 (0.9948) gate/usage_max 0.5555 (0.5555) gate/usage_min 0.2142 (0.2146) gate/usage_std 0.1572 (0.1572) teacher/entropy 0.0093 (0.0150) teacher/usage_max 0.5022 (0.5478) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2357 (0.2381) nleep/row_max_mean 1560.5255 (1556.8962) nleep/row_max_std 52.1820 (56.7467) nleep/row_min_mean 1526.3745 (1523.3613) lr 1.2487e-03 eta 0:09:14
epoch [23/50] batch [80/167] time 0.157 (0.118) data 0.000 (0.004) loss 1.3953 (1.4886) teacher_loss 0.0971 (0.2221) loss_zs_kd 0.0328 (0.0315) loss_oracle 0.4718 (0.4619) kd_loss 1.0459 (1.0198) acc 100.0000 (91.5234) gate/entropy 0.9949 (0.9949) gate/usage_max 0.5553 (0.5554) gate/usage_min 0.2141 (0.2146) gate/usage_std 0.1571 (0.1571) teacher/entropy 0.0102 (0.0164) teacher/usage_max 0.5338 (0.5514) teacher/usage_min 0.0000 (0.0050) teacher/usage_std 0.2373 (0.2386) nleep/row_max_mean 1561.2820 (1557.4491) nleep/row_max_std 53.1105 (56.4739) nleep/row_min_mean 1529.5507 (1524.1330) lr 1.2487e-03 eta 0:09:03
epoch [23/50] batch [100/167] time 0.170 (0.117) data 0.000 (0.003) loss 1.4221 (1.4818) teacher_loss 0.1494 (0.2180) loss_zs_kd 0.0275 (0.0306) loss_oracle 0.4598 (0.4582) kd_loss 1.0290 (1.0193) acc 96.8750 (91.4688) gate/entropy 0.9957 (0.9950) gate/usage_max 0.5545 (0.5552) gate/usage_min 0.2141 (0.2145) gate/usage_std 0.1565 (0.1570) teacher/entropy 0.0340 (0.0168) teacher/usage_max 0.5294 (0.5593) teacher/usage_min 0.0133 (0.0045) teacher/usage_std 0.2282 (0.2416) nleep/row_max_mean 1555.2717 (1557.5175) nleep/row_max_std 52.1556 (56.3400) nleep/row_min_mean 1522.5203 (1524.2848) lr 1.2487e-03 eta 0:08:56
epoch [23/50] batch [120/167] time 0.155 (0.117) data 0.000 (0.003) loss 1.5444 (1.4777) teacher_loss 0.3469 (0.2180) loss_zs_kd 0.0442 (0.0303) loss_oracle 0.4467 (0.4559) kd_loss 0.9521 (1.0166) acc 84.3750 (91.4844) gate/entropy 0.9957 (0.9952) gate/usage_max 0.5544 (0.5550) gate/usage_min 0.2138 (0.2144) gate/usage_std 0.1565 (0.1569) teacher/entropy 0.0574 (0.0192) teacher/usage_max 0.5176 (0.5588) teacher/usage_min 0.0140 (0.0042) teacher/usage_std 0.2267 (0.2414) nleep/row_max_mean 1561.8927 (1557.1803) nleep/row_max_std 55.1569 (56.1673) nleep/row_min_mean 1527.1963 (1524.1279) lr 1.2487e-03 eta 0:08:53
epoch [23/50] batch [140/167] time 0.166 (0.123) data 0.000 (0.002) loss 1.6326 (1.4728) teacher_loss 0.2677 (0.2162) loss_zs_kd 0.0505 (0.0312) loss_oracle 0.4863 (0.4573) kd_loss 1.0965 (1.0123) acc 90.6250 (91.6071) gate/entropy 0.9965 (0.9953) gate/usage_max 0.5535 (0.5549) gate/usage_min 0.2139 (0.2143) gate/usage_std 0.1559 (0.1568) teacher/entropy 0.0258 (0.0207) teacher/usage_max 0.6161 (0.5613) teacher/usage_min 0.0004 (0.0043) teacher/usage_std 0.2539 (0.2419) nleep/row_max_mean 1547.9355 (1557.3031) nleep/row_max_std 56.7832 (56.3504) nleep/row_min_mean 1519.0181 (1524.2763) lr 1.2487e-03 eta 0:09:19
epoch [23/50] batch [160/167] time 0.139 (0.129) data 0.000 (0.002) loss 1.4022 (1.4662) teacher_loss 0.2678 (0.2160) loss_zs_kd 0.0294 (0.0314) loss_oracle 0.4088 (0.4585) kd_loss 0.9153 (1.0053) acc 90.6250 (91.6602) gate/entropy 0.9971 (0.9955) gate/usage_max 0.5528 (0.5547) gate/usage_min 0.2138 (0.2143) gate/usage_std 0.1554 (0.1567) teacher/entropy 0.0371 (0.0225) teacher/usage_max 0.5784 (0.5621) teacher/usage_min 0.0010 (0.0048) teacher/usage_std 0.2437 (0.2415) nleep/row_max_mean 1565.0428 (1557.3446) nleep/row_max_std 57.8270 (56.2450) nleep/row_min_mean 1527.9946 (1524.3640) lr 1.2487e-03 eta 0:09:40
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,191
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [24/50] batch [20/167] time 0.152 (0.170) data 0.000 (0.016) loss 1.4083 (1.4328) teacher_loss 0.3035 (0.2649) loss_zs_kd 0.0313 (0.0228) loss_oracle 0.5039 (0.4750) kd_loss 0.8371 (0.9191) acc 84.3750 (89.8438) gate/entropy 0.9965 (0.9969) gate/usage_max 0.5535 (0.5529) gate/usage_min 0.2133 (0.2136) gate/usage_std 0.1559 (0.1555) teacher/entropy 0.0324 (0.0528) teacher/usage_max 0.6745 (0.5759) teacher/usage_min 0.0036 (0.0111) teacher/usage_std 0.2740 (0.2425) nleep/row_max_mean 1573.7001 (1558.0210) nleep/row_max_std 51.3788 (54.5860) nleep/row_min_mean 1534.4219 (1524.9902) lr 1.1874e-03 eta 0:12:44
epoch [24/50] batch [40/167] time 0.150 (0.160) data 0.000 (0.008) loss 1.3562 (1.4075) teacher_loss 0.1708 (0.2315) loss_zs_kd 0.0218 (0.0255) loss_oracle 0.5982 (0.4740) kd_loss 0.8754 (0.9262) acc 93.7500 (91.2500) gate/entropy 0.9979 (0.9971) gate/usage_max 0.5519 (0.5528) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1548 (0.1554) teacher/entropy 0.0620 (0.0494) teacher/usage_max 0.5972 (0.5777) teacher/usage_min 0.0255 (0.0144) teacher/usage_std 0.2355 (0.2403) nleep/row_max_mean 1549.1694 (1556.5348) nleep/row_max_std 60.4388 (57.0595) nleep/row_min_mean 1517.5417 (1523.3207) lr 1.1874e-03 eta 0:11:53
epoch [24/50] batch [60/167] time 0.139 (0.152) data 0.001 (0.006) loss 1.5620 (1.4223) teacher_loss 0.4333 (0.2443) loss_zs_kd 0.0213 (0.0267) loss_oracle 0.4356 (0.4820) kd_loss 0.9003 (0.9237) acc 84.3750 (90.5729) gate/entropy 0.9977 (0.9971) gate/usage_max 0.5520 (0.5527) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1549 (0.1554) teacher/entropy 0.0338 (0.0471) teacher/usage_max 0.6009 (0.5810) teacher/usage_min 0.0276 (0.0144) teacher/usage_std 0.2356 (0.2412) nleep/row_max_mean 1551.5742 (1557.4752) nleep/row_max_std 58.7341 (56.6998) nleep/row_min_mean 1517.4783 (1523.8796) lr 1.1874e-03 eta 0:11:15
epoch [24/50] batch [80/167] time 0.090 (0.143) data 0.000 (0.004) loss 1.4915 (1.4128) teacher_loss 0.3734 (0.2464) loss_zs_kd 0.0377 (0.0280) loss_oracle 0.4913 (0.4837) kd_loss 0.8536 (0.9105) acc 87.5000 (90.5078) gate/entropy 0.9975 (0.9972) gate/usage_max 0.5522 (0.5527) gate/usage_min 0.2132 (0.2134) gate/usage_std 0.1550 (0.1553) teacher/entropy 0.0326 (0.0480) teacher/usage_max 0.6540 (0.5903) teacher/usage_min 0.0060 (0.0157) teacher/usage_std 0.2646 (0.2430) nleep/row_max_mean 1558.4340 (1558.9974) nleep/row_max_std 62.1911 (56.6876) nleep/row_min_mean 1524.3682 (1525.2227) lr 1.1874e-03 eta 0:10:32
epoch [24/50] batch [100/167] time 0.188 (0.137) data 0.000 (0.003) loss 1.5797 (1.4058) teacher_loss 0.4613 (0.2397) loss_zs_kd 0.0524 (0.0290) loss_oracle 0.4938 (0.4892) kd_loss 0.8453 (0.9070) acc 81.2500 (90.7188) gate/entropy 0.9978 (0.9973) gate/usage_max 0.5519 (0.5525) gate/usage_min 0.2131 (0.2133) gate/usage_std 0.1548 (0.1552) teacher/entropy 0.0184 (0.0472) teacher/usage_max 0.6821 (0.5932) teacher/usage_min 0.0006 (0.0191) teacher/usage_std 0.2785 (0.2423) nleep/row_max_mean 1548.8721 (1558.2637) nleep/row_max_std 49.7424 (56.8389) nleep/row_min_mean 1514.7911 (1524.4839) lr 1.1874e-03 eta 0:10:05
epoch [24/50] batch [120/167] time 0.111 (0.136) data 0.000 (0.003) loss 1.2345 (1.4085) teacher_loss 0.1896 (0.2427) loss_zs_kd 0.0278 (0.0296) loss_oracle 0.4434 (0.4956) kd_loss 0.8094 (0.9032) acc 90.6250 (90.5208) gate/entropy 0.9978 (0.9973) gate/usage_max 0.5518 (0.5525) gate/usage_min 0.2131 (0.2133) gate/usage_std 0.1548 (0.1552) teacher/entropy 0.0208 (0.0495) teacher/usage_max 0.7208 (0.5934) teacher/usage_min 0.0012 (0.0242) teacher/usage_std 0.2964 (0.2401) nleep/row_max_mean 1552.9349 (1558.2161) nleep/row_max_std 66.6572 (56.9572) nleep/row_min_mean 1516.5723 (1524.4110) lr 1.1874e-03 eta 0:09:57
epoch [24/50] batch [140/167] time 0.110 (0.134) data 0.000 (0.003) loss 1.4636 (1.4012) teacher_loss 0.3863 (0.2402) loss_zs_kd 0.0213 (0.0290) loss_oracle 0.5337 (0.4975) kd_loss 0.7998 (0.8978) acc 84.3750 (90.6027) gate/entropy 0.9972 (0.9974) gate/usage_max 0.5525 (0.5524) gate/usage_min 0.2128 (0.2132) gate/usage_std 0.1553 (0.1551) teacher/entropy 0.0870 (0.0542) teacher/usage_max 0.6614 (0.5933) teacher/usage_min 0.0571 (0.0321) teacher/usage_std 0.2494 (0.2364) nleep/row_max_mean 1568.1044 (1557.5382) nleep/row_max_std 54.7729 (56.9954) nleep/row_min_mean 1530.2216 (1523.8742) lr 1.1874e-03 eta 0:09:45
epoch [24/50] batch [160/167] time 0.079 (0.131) data 0.000 (0.002) loss 1.4724 (1.3953) teacher_loss 0.3371 (0.2367) loss_zs_kd 0.0324 (0.0292) loss_oracle 0.6198 (0.4992) kd_loss 0.8091 (0.8945) acc 84.3750 (90.6445) gate/entropy 0.9974 (0.9974) gate/usage_max 0.5523 (0.5523) gate/usage_min 0.2128 (0.2132) gate/usage_std 0.1551 (0.1551) teacher/entropy 0.0860 (0.0555) teacher/usage_max 0.6629 (0.5956) teacher/usage_min 0.1461 (0.0372) teacher/usage_std 0.2337 (0.2350) nleep/row_max_mean 1566.2693 (1557.2198) nleep/row_max_std 38.7369 (56.8060) nleep/row_min_mean 1526.5732 (1523.4609) lr 1.1874e-03 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 18 *******
******* Domain c best val test acc: 98.8%, epoch: 18 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [25/50] batch [20/167] time 0.166 (0.166) data 0.000 (0.015) loss 1.2104 (1.3955) teacher_loss 0.2603 (0.2634) loss_zs_kd 0.0387 (0.0365) loss_oracle 0.4897 (0.5425) kd_loss 0.6859 (0.8426) acc 87.5000 (90.0000) gate/entropy 0.9971 (0.9976) gate/usage_max 0.5527 (0.5521) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1554 (0.1549) teacher/entropy 0.0187 (0.0704) teacher/usage_max 0.8752 (0.6359) teacher/usage_min 0.0597 (0.1062) teacher/usage_std 0.3832 (0.2266) nleep/row_max_mean 1566.0122 (1549.2965) nleep/row_max_std 58.7372 (57.3044) nleep/row_min_mean 1523.8250 (1512.8991) lr 1.1253e-03 eta 0:11:57
epoch [25/50] batch [40/167] time 0.163 (0.168) data 0.000 (0.007) loss 1.3514 (1.3626) teacher_loss 0.1784 (0.2397) loss_zs_kd 0.0261 (0.0326) loss_oracle 0.6115 (0.5316) kd_loss 0.8541 (0.8407) acc 96.8750 (91.1719) gate/entropy 0.9978 (0.9976) gate/usage_max 0.5519 (0.5521) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1548 (0.1550) teacher/entropy 0.0933 (0.0796) teacher/usage_max 0.6006 (0.6282) teacher/usage_min 0.1438 (0.1102) teacher/usage_std 0.1944 (0.2212) nleep/row_max_mean 1541.1031 (1549.5980) nleep/row_max_std 61.7737 (58.2726) nleep/row_min_mean 1504.3035 (1513.3256) lr 1.1253e-03 eta 0:12:03
epoch [25/50] batch [60/167] time 0.193 (0.172) data 0.001 (0.005) loss 1.3020 (1.3569) teacher_loss 0.2198 (0.2444) loss_zs_kd 0.0395 (0.0332) loss_oracle 0.4869 (0.5165) kd_loss 0.8189 (0.8377) acc 93.7500 (90.9375) gate/entropy 0.9971 (0.9975) gate/usage_max 0.5527 (0.5522) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1554 (0.1550) teacher/entropy 0.0953 (0.0802) teacher/usage_max 0.6332 (0.6310) teacher/usage_min 0.0805 (0.1074) teacher/usage_std 0.2281 (0.2233) nleep/row_max_mean 1554.2854 (1549.5821) nleep/row_max_std 50.9935 (58.0902) nleep/row_min_mean 1519.1353 (1513.6184) lr 1.1253e-03 eta 0:12:15
epoch [25/50] batch [80/167] time 0.163 (0.172) data 0.000 (0.004) loss 1.2376 (1.3574) teacher_loss 0.1345 (0.2458) loss_zs_kd 0.0191 (0.0326) loss_oracle 0.5366 (0.5219) kd_loss 0.8252 (0.8344) acc 96.8750 (90.8594) gate/entropy 0.9976 (0.9974) gate/usage_max 0.5522 (0.5523) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1550 (0.1551) teacher/entropy 0.0977 (0.0823) teacher/usage_max 0.6331 (0.6334) teacher/usage_min 0.1794 (0.1125) teacher/usage_std 0.2120 (0.2239) nleep/row_max_mean 1540.8590 (1550.4206) nleep/row_max_std 52.3722 (58.1881) nleep/row_min_mean 1511.1610 (1514.1309) lr 1.1253e-03 eta 0:12:11
epoch [25/50] batch [100/167] time 0.158 (0.168) data 0.000 (0.003) loss 1.1717 (1.3451) teacher_loss 0.2268 (0.2517) loss_zs_kd 0.0410 (0.0324) loss_oracle 0.4740 (0.5188) kd_loss 0.6873 (0.8178) acc 93.7500 (90.8125) gate/entropy 0.9964 (0.9973) gate/usage_max 0.5535 (0.5524) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1559 (0.1552) teacher/entropy 0.0614 (0.0823) teacher/usage_max 0.8203 (0.6520) teacher/usage_min 0.0340 (0.1059) teacher/usage_std 0.3473 (0.2357) nleep/row_max_mean 1564.0591 (1551.4367) nleep/row_max_std 59.5070 (59.1745) nleep/row_min_mean 1521.8274 (1514.4661) lr 1.1253e-03 eta 0:11:52
epoch [25/50] batch [120/167] time 0.177 (0.168) data 0.000 (0.003) loss 1.2204 (1.3353) teacher_loss 0.2011 (0.2473) loss_zs_kd 0.0229 (0.0311) loss_oracle 0.5578 (0.5175) kd_loss 0.7289 (0.8137) acc 87.5000 (90.9375) gate/entropy 0.9970 (0.9972) gate/usage_max 0.5529 (0.5525) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1555 (0.1553) teacher/entropy 0.0990 (0.0839) teacher/usage_max 0.7343 (0.6552) teacher/usage_min 0.0877 (0.1073) teacher/usage_std 0.2859 (0.2372) nleep/row_max_mean 1541.0267 (1551.2237) nleep/row_max_std 71.6729 (59.0252) nleep/row_min_mean 1507.0496 (1514.3903) lr 1.1253e-03 eta 0:11:49
epoch [25/50] batch [140/167] time 0.165 (0.168) data 0.000 (0.002) loss 1.3372 (1.3363) teacher_loss 0.3466 (0.2583) loss_zs_kd 0.0344 (0.0311) loss_oracle 0.5496 (0.5171) kd_loss 0.6985 (0.8040) acc 87.5000 (90.4911) gate/entropy 0.9962 (0.9971) gate/usage_max 0.5537 (0.5527) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1561 (0.1554) teacher/entropy 0.0661 (0.0841) teacher/usage_max 0.8099 (0.6662) teacher/usage_min 0.0690 (0.1063) teacher/usage_std 0.3377 (0.2439) nleep/row_max_mean 1538.9075 (1551.2844) nleep/row_max_std 71.2858 (58.8227) nleep/row_min_mean 1500.9094 (1514.3409) lr 1.1253e-03 eta 0:11:45
epoch [25/50] batch [160/167] time 0.083 (0.162) data 0.000 (0.002) loss 1.2543 (1.3308) teacher_loss 0.1851 (0.2595) loss_zs_kd 0.0219 (0.0309) loss_oracle 0.4924 (0.5157) kd_loss 0.8120 (0.7980) acc 90.6250 (90.5273) gate/entropy 0.9961 (0.9969) gate/usage_max 0.5539 (0.5529) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1562 (0.1555) teacher/entropy 0.0592 (0.0824) teacher/usage_max 0.6849 (0.6750) teacher/usage_min 0.1179 (0.1055) teacher/usage_std 0.2507 (0.2493) nleep/row_max_mean 1548.3455 (1551.3057) nleep/row_max_std 59.8897 (58.3077) nleep/row_min_mean 1510.9624 (1514.1169) lr 1.1253e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,214
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,314
* accuracy: 98.7%
* error: 1.3%
* macro_f1: 98.8%
******* Domain c best val acc:      96.4%, epoch: 25 *******
******* Domain c best val test acc: 98.7%, epoch: 25 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [26/50] batch [20/167] time 0.089 (0.126) data 0.000 (0.016) loss 1.1150 (1.2751) teacher_loss 0.2635 (0.2851) loss_zs_kd 0.0165 (0.0224) loss_oracle 0.4797 (0.5091) kd_loss 0.6034 (0.7241) acc 87.5000 (88.7500) gate/entropy 0.9954 (0.9956) gate/usage_max 0.5547 (0.5544) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1567 (0.1565) teacher/entropy 0.0637 (0.0771) teacher/usage_max 0.9183 (0.7649) teacher/usage_min 0.0109 (0.0751) teacher/usage_std 0.4144 (0.3081) nleep/row_max_mean 1548.8262 (1550.7768) nleep/row_max_std 48.9638 (55.6521) nleep/row_min_mean 1513.0607 (1511.5101) lr 1.0628e-03 eta 0:08:42
epoch [26/50] batch [40/167] time 0.085 (0.114) data 0.000 (0.008) loss 1.3229 (1.2782) teacher_loss 0.2261 (0.3090) loss_zs_kd 0.0159 (0.0234) loss_oracle 0.5663 (0.5042) kd_loss 0.8057 (0.7054) acc 90.6250 (87.5781) gate/entropy 0.9954 (0.9954) gate/usage_max 0.5547 (0.5547) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1567 (0.1567) teacher/entropy 0.0748 (0.0728) teacher/usage_max 0.6783 (0.7897) teacher/usage_min 0.1601 (0.0674) teacher/usage_std 0.2439 (0.3252) nleep/row_max_mean 1542.0212 (1550.9104) nleep/row_max_std 55.7423 (54.4922) nleep/row_min_mean 1503.9194 (1511.3022) lr 1.0628e-03 eta 0:07:51
epoch [26/50] batch [60/167] time 0.148 (0.118) data 0.001 (0.005) loss 1.2246 (1.2654) teacher_loss 0.3113 (0.2920) loss_zs_kd 0.0304 (0.0237) loss_oracle 0.4686 (0.5060) kd_loss 0.6638 (0.7086) acc 84.3750 (88.4375) gate/entropy 0.9946 (0.9952) gate/usage_max 0.5556 (0.5549) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1573 (0.1568) teacher/entropy 0.0732 (0.0664) teacher/usage_max 0.8339 (0.7929) teacher/usage_min 0.0652 (0.0662) teacher/usage_std 0.3543 (0.3274) nleep/row_max_mean 1548.9583 (1551.4252) nleep/row_max_std 60.4683 (53.9959) nleep/row_min_mean 1509.4949 (1511.3467) lr 1.0628e-03 eta 0:08:05
epoch [26/50] batch [80/167] time 0.103 (0.119) data 0.000 (0.004) loss 1.3527 (1.2535) teacher_loss 0.3769 (0.2872) loss_zs_kd 0.0216 (0.0236) loss_oracle 0.5137 (0.5017) kd_loss 0.7081 (0.7036) acc 84.3750 (88.7500) gate/entropy 0.9944 (0.9951) gate/usage_max 0.5558 (0.5551) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1575 (0.1570) teacher/entropy 0.0399 (0.0643) teacher/usage_max 0.8161 (0.8000) teacher/usage_min 0.0270 (0.0624) teacher/usage_std 0.3455 (0.3324) nleep/row_max_mean 1547.1189 (1551.6540) nleep/row_max_std 49.6789 (54.6549) nleep/row_min_mean 1506.3691 (1511.3790) lr 1.0628e-03 eta 0:08:05
epoch [26/50] batch [100/167] time 0.161 (0.123) data 0.000 (0.003) loss 1.3575 (1.2528) teacher_loss 0.3568 (0.2888) loss_zs_kd 0.0308 (0.0242) loss_oracle 0.5418 (0.4991) kd_loss 0.7143 (0.7024) acc 87.5000 (88.9062) gate/entropy 0.9931 (0.9949) gate/usage_max 0.5573 (0.5553) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1585 (0.1571) teacher/entropy 0.0394 (0.0627) teacher/usage_max 0.8137 (0.8023) teacher/usage_min 0.0800 (0.0572) teacher/usage_std 0.3398 (0.3345) nleep/row_max_mean 1569.5168 (1551.6947) nleep/row_max_std 49.1116 (54.7837) nleep/row_min_mean 1526.3369 (1511.4185) lr 1.0628e-03 eta 0:08:20
epoch [26/50] batch [120/167] time 0.130 (0.127) data 0.000 (0.003) loss 1.4611 (1.2573) teacher_loss 0.4688 (0.2942) loss_zs_kd 0.0213 (0.0236) loss_oracle 0.4621 (0.4956) kd_loss 0.7506 (0.7035) acc 78.1250 (88.6458) gate/entropy 0.9939 (0.9947) gate/usage_max 0.5564 (0.5555) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1579 (0.1573) teacher/entropy 0.0037 (0.0598) teacher/usage_max 0.8118 (0.8035) teacher/usage_min 0.0625 (0.0529) teacher/usage_std 0.3393 (0.3357) nleep/row_max_mean 1549.9092 (1551.9419) nleep/row_max_std 52.0415 (54.9147) nleep/row_min_mean 1509.2501 (1511.5101) lr 1.0628e-03 eta 0:08:34
epoch [26/50] batch [140/167] time 0.130 (0.128) data 0.000 (0.002) loss 1.3473 (1.2638) teacher_loss 0.3628 (0.2976) loss_zs_kd 0.0405 (0.0238) loss_oracle 0.4775 (0.4960) kd_loss 0.7254 (0.7064) acc 90.6250 (88.5714) gate/entropy 0.9931 (0.9945) gate/usage_max 0.5573 (0.5557) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1585 (0.1574) teacher/entropy 0.0654 (0.0567) teacher/usage_max 0.7661 (0.8030) teacher/usage_min 0.0148 (0.0490) teacher/usage_std 0.3172 (0.3358) nleep/row_max_mean 1559.3967 (1552.6733) nleep/row_max_std 47.2855 (55.0786) nleep/row_min_mean 1517.7094 (1511.9740) lr 1.0628e-03 eta 0:08:36
epoch [26/50] batch [160/167] time 0.132 (0.130) data 0.000 (0.002) loss 1.2434 (1.2640) teacher_loss 0.2617 (0.2994) loss_zs_kd 0.0141 (0.0232) loss_oracle 0.4733 (0.4948) kd_loss 0.7380 (0.7056) acc 87.5000 (88.4180) gate/entropy 0.9930 (0.9943) gate/usage_max 0.5575 (0.5559) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1586 (0.1575) teacher/entropy 0.0111 (0.0537) teacher/usage_max 0.8108 (0.8065) teacher/usage_min 0.0008 (0.0446) teacher/usage_std 0.3462 (0.3386) nleep/row_max_mean 1552.6736 (1552.9870) nleep/row_max_std 51.6103 (54.8641) nleep/row_min_mean 1517.4357 (1512.3002) lr 1.0628e-03 eta 0:08:42
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,222
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,298
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [27/50] batch [20/167] time 0.192 (0.191) data 0.000 (0.016) loss 1.2649 (1.2200) teacher_loss 0.2435 (0.2687) loss_zs_kd 0.0103 (0.0174) loss_oracle 0.4588 (0.4740) kd_loss 0.7868 (0.7055) acc 90.6250 (90.6250) gate/entropy 0.9929 (0.9929) gate/usage_max 0.5575 (0.5576) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1586 (0.1587) teacher/entropy 0.0424 (0.0439) teacher/usage_max 0.7178 (0.8117) teacher/usage_min 0.0000 (0.0090) teacher/usage_std 0.2952 (0.3464) nleep/row_max_mean 1546.7302 (1550.9863) nleep/row_max_std 66.2926 (57.5107) nleep/row_min_mean 1508.8457 (1511.3140) lr 1.0000e-03 eta 0:12:42
epoch [27/50] batch [40/167] time 0.092 (0.172) data 0.000 (0.008) loss 1.2961 (1.2215) teacher_loss 0.2685 (0.2592) loss_zs_kd 0.0202 (0.0190) loss_oracle 0.5070 (0.4794) kd_loss 0.7640 (0.7131) acc 90.6250 (90.8594) gate/entropy 0.9930 (0.9928) gate/usage_max 0.5574 (0.5577) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1586 (0.1588) teacher/entropy 0.0193 (0.0424) teacher/usage_max 0.7742 (0.8054) teacher/usage_min 0.0070 (0.0127) teacher/usage_std 0.3235 (0.3426) nleep/row_max_mean 1546.2700 (1550.3615) nleep/row_max_std 49.7085 (57.4529) nleep/row_min_mean 1505.8982 (1510.8538) lr 1.0000e-03 eta 0:11:21
epoch [27/50] batch [60/167] time 0.166 (0.149) data 0.000 (0.005) loss 1.3285 (1.2410) teacher_loss 0.2757 (0.2700) loss_zs_kd 0.0246 (0.0194) loss_oracle 0.4936 (0.4836) kd_loss 0.7936 (0.7196) acc 87.5000 (90.1042) gate/entropy 0.9925 (0.9927) gate/usage_max 0.5580 (0.5577) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1590 (0.1588) teacher/entropy 0.0429 (0.0418) teacher/usage_max 0.7169 (0.7987) teacher/usage_min 0.0567 (0.0139) teacher/usage_std 0.2799 (0.3382) nleep/row_max_mean 1544.4146 (1548.9754) nleep/row_max_std 61.3511 (58.4011) nleep/row_min_mean 1512.0275 (1509.9071) lr 1.0000e-03 eta 0:09:46
epoch [27/50] batch [80/167] time 0.179 (0.142) data 0.000 (0.004) loss 1.3015 (1.2493) teacher_loss 0.2272 (0.2746) loss_zs_kd 0.0096 (0.0202) loss_oracle 0.4354 (0.4857) kd_loss 0.8517 (0.7218) acc 90.6250 (89.9609) gate/entropy 0.9922 (0.9926) gate/usage_max 0.5583 (0.5579) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1592 (0.1589) teacher/entropy 0.0225 (0.0388) teacher/usage_max 0.6691 (0.7994) teacher/usage_min 0.0000 (0.0138) teacher/usage_std 0.2732 (0.3389) nleep/row_max_mean 1555.1760 (1549.4440) nleep/row_max_std 53.0752 (57.0950) nleep/row_min_mean 1516.3666 (1510.1038) lr 1.0000e-03 eta 0:09:17
epoch [27/50] batch [100/167] time 0.080 (0.137) data 0.000 (0.003) loss 1.3002 (1.2612) teacher_loss 0.2698 (0.2846) loss_zs_kd 0.0242 (0.0199) loss_oracle 0.4822 (0.4866) kd_loss 0.7771 (0.7233) acc 90.6250 (89.4062) gate/entropy 0.9920 (0.9925) gate/usage_max 0.5585 (0.5580) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1593 (0.1590) teacher/entropy 0.0003 (0.0380) teacher/usage_max 0.7813 (0.7984) teacher/usage_min 0.0312 (0.0131) teacher/usage_std 0.3231 (0.3385) nleep/row_max_mean 1557.9564 (1549.3276) nleep/row_max_std 42.8397 (56.7058) nleep/row_min_mean 1514.9729 (1509.9140) lr 1.0000e-03 eta 0:08:55
epoch [27/50] batch [120/167] time 0.074 (0.133) data 0.000 (0.003) loss 1.4977 (1.2643) teacher_loss 0.4512 (0.2888) loss_zs_kd 0.0273 (0.0203) loss_oracle 0.4747 (0.4828) kd_loss 0.7955 (0.7240) acc 75.0000 (89.0885) gate/entropy 0.9917 (0.9924) gate/usage_max 0.5589 (0.5581) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1596 (0.1591) teacher/entropy 0.0090 (0.0380) teacher/usage_max 0.7476 (0.7975) teacher/usage_min 0.0024 (0.0117) teacher/usage_std 0.3099 (0.3381) nleep/row_max_mean 1542.1249 (1548.5279) nleep/row_max_std 53.0474 (55.8177) nleep/row_min_mean 1503.1550 (1509.3642) lr 1.0000e-03 eta 0:08:37
epoch [27/50] batch [140/167] time 0.099 (0.129) data 0.000 (0.002) loss 1.3357 (1.2619) teacher_loss 0.3611 (0.2876) loss_zs_kd 0.0184 (0.0201) loss_oracle 0.4204 (0.4827) kd_loss 0.7552 (0.7229) acc 81.2500 (88.9732) gate/entropy 0.9918 (0.9923) gate/usage_max 0.5587 (0.5582) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1595 (0.1591) teacher/entropy 0.0864 (0.0377) teacher/usage_max 0.7066 (0.7991) teacher/usage_min 0.0059 (0.0118) teacher/usage_std 0.2879 (0.3391) nleep/row_max_mean 1535.7744 (1548.4617) nleep/row_max_std 61.3462 (54.9264) nleep/row_min_mean 1497.9951 (1509.4013) lr 1.0000e-03 eta 0:08:19
epoch [27/50] batch [160/167] time 0.178 (0.128) data 0.000 (0.002) loss 1.2779 (1.2629) teacher_loss 0.3619 (0.2898) loss_zs_kd 0.0207 (0.0203) loss_oracle 0.4713 (0.4846) kd_loss 0.6700 (0.7206) acc 87.5000 (88.9062) gate/entropy 0.9916 (0.9922) gate/usage_max 0.5590 (0.5583) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1597 (0.1592) teacher/entropy 0.0317 (0.0375) teacher/usage_max 0.8635 (0.8018) teacher/usage_min 0.0002 (0.0117) teacher/usage_std 0.3790 (0.3407) nleep/row_max_mean 1533.9680 (1547.4463) nleep/row_max_std 53.4522 (54.4696) nleep/row_min_mean 1499.9249 (1508.6605) lr 1.0000e-03 eta 0:08:14
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,212
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,311
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 98.5%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [28/50] batch [20/167] time 0.165 (0.175) data 0.000 (0.020) loss 1.3393 (1.2555) teacher_loss 0.2644 (0.2791) loss_zs_kd 0.0297 (0.0213) loss_oracle 0.4247 (0.4660) kd_loss 0.8477 (0.7329) acc 90.6250 (88.7500) gate/entropy 0.9918 (0.9914) gate/usage_max 0.5588 (0.5592) gate/usage_min 0.2132 (0.2130) gate/usage_std 0.1595 (0.1598) teacher/entropy 0.0239 (0.0248) teacher/usage_max 0.6742 (0.8011) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.2753 (0.3415) nleep/row_max_mean 1535.8121 (1545.3663) nleep/row_max_std 52.3584 (53.6031) nleep/row_min_mean 1499.7491 (1506.2693) lr 9.3721e-04 eta 0:11:07
epoch [28/50] batch [40/167] time 0.159 (0.167) data 0.000 (0.010) loss 1.3269 (1.2275) teacher_loss 0.3886 (0.2653) loss_zs_kd 0.0219 (0.0201) loss_oracle 0.4909 (0.4793) kd_loss 0.6820 (0.7125) acc 81.2500 (89.5312) gate/entropy 0.9906 (0.9913) gate/usage_max 0.5600 (0.5593) gate/usage_min 0.2128 (0.2130) gate/usage_std 0.1604 (0.1599) teacher/entropy 0.0072 (0.0311) teacher/usage_max 0.8767 (0.8168) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.3875 (0.3509) nleep/row_max_mean 1549.6608 (1546.5457) nleep/row_max_std 50.7916 (55.9081) nleep/row_min_mean 1509.7223 (1507.2833) lr 9.3721e-04 eta 0:10:35
epoch [28/50] batch [60/167] time 0.161 (0.169) data 0.000 (0.007) loss 1.1376 (1.2391) teacher_loss 0.3201 (0.2793) loss_zs_kd 0.0173 (0.0207) loss_oracle 0.4525 (0.4796) kd_loss 0.5826 (0.7097) acc 84.3750 (88.8542) gate/entropy 0.9907 (0.9912) gate/usage_max 0.5599 (0.5595) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1603 (0.1600) teacher/entropy 0.0389 (0.0283) teacher/usage_max 0.9533 (0.8234) teacher/usage_min 0.0000 (0.0079) teacher/usage_std 0.4388 (0.3543) nleep/row_max_mean 1547.8107 (1548.1453) nleep/row_max_std 60.2814 (54.9078) nleep/row_min_mean 1503.5100 (1508.4005) lr 9.3721e-04 eta 0:10:40
epoch [28/50] batch [80/167] time 0.158 (0.172) data 0.000 (0.005) loss 1.2909 (1.2436) teacher_loss 0.3281 (0.2835) loss_zs_kd 0.0214 (0.0213) loss_oracle 0.5145 (0.4809) kd_loss 0.6949 (0.7090) acc 84.3750 (88.5938) gate/entropy 0.9908 (0.9911) gate/usage_max 0.5599 (0.5596) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1603 (0.1601) teacher/entropy 0.0225 (0.0272) teacher/usage_max 0.8471 (0.8255) teacher/usage_min 0.0265 (0.0095) teacher/usage_std 0.3655 (0.3552) nleep/row_max_mean 1543.5095 (1548.6260) nleep/row_max_std 57.8349 (55.1585) nleep/row_min_mean 1506.9734 (1508.9295) lr 9.3721e-04 eta 0:10:46
epoch [28/50] batch [100/167] time 0.178 (0.173) data 0.000 (0.004) loss 1.5348 (1.2479) teacher_loss 0.6094 (0.2906) loss_zs_kd 0.0223 (0.0214) loss_oracle 0.4670 (0.4801) kd_loss 0.6808 (0.7065) acc 75.0000 (88.4062) gate/entropy 0.9896 (0.9910) gate/usage_max 0.5611 (0.5597) gate/usage_min 0.2127 (0.2130) gate/usage_std 0.1612 (0.1601) teacher/entropy 0.0130 (0.0259) teacher/usage_max 0.8706 (0.8296) teacher/usage_min 0.0000 (0.0091) teacher/usage_std 0.3836 (0.3578) nleep/row_max_mean 1563.6024 (1549.2550) nleep/row_max_std 56.8657 (55.0425) nleep/row_min_mean 1521.6342 (1509.5458) lr 9.3721e-04 eta 0:10:46
epoch [28/50] batch [120/167] time 0.166 (0.173) data 0.000 (0.004) loss 1.0680 (1.2420) teacher_loss 0.1572 (0.2874) loss_zs_kd 0.0107 (0.0212) loss_oracle 0.5204 (0.4793) kd_loss 0.6453 (0.7044) acc 90.6250 (88.6198) gate/entropy 0.9902 (0.9909) gate/usage_max 0.5605 (0.5598) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1607 (0.1602) teacher/entropy 0.0435 (0.0256) teacher/usage_max 0.8799 (0.8322) teacher/usage_min 0.0452 (0.0088) teacher/usage_std 0.3867 (0.3595) nleep/row_max_mean 1557.8005 (1549.0849) nleep/row_max_std 57.3003 (55.9259) nleep/row_min_mean 1516.0427 (1509.4830) lr 9.3721e-04 eta 0:10:44
epoch [28/50] batch [140/167] time 0.088 (0.164) data 0.000 (0.003) loss 1.1395 (1.2407) teacher_loss 0.1868 (0.2887) loss_zs_kd 0.0167 (0.0211) loss_oracle 0.5003 (0.4785) kd_loss 0.6942 (0.7021) acc 90.6250 (88.7723) gate/entropy 0.9905 (0.9908) gate/usage_max 0.5602 (0.5599) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1605 (0.1603) teacher/entropy 0.0304 (0.0260) teacher/usage_max 0.8373 (0.8342) teacher/usage_min 0.0012 (0.0087) teacher/usage_std 0.3623 (0.3608) nleep/row_max_mean 1542.9160 (1548.7898) nleep/row_max_std 51.0025 (55.9162) nleep/row_min_mean 1506.2961 (1509.3203) lr 9.3721e-04 eta 0:10:07
epoch [28/50] batch [160/167] time 0.093 (0.159) data 0.000 (0.003) loss 1.3309 (1.2403) teacher_loss 0.2886 (0.2861) loss_zs_kd 0.0326 (0.0209) loss_oracle 0.5027 (0.4806) kd_loss 0.7747 (0.7035) acc 90.6250 (88.8672) gate/entropy 0.9905 (0.9907) gate/usage_max 0.5602 (0.5600) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1605 (0.1604) teacher/entropy 0.0540 (0.0261) teacher/usage_max 0.7272 (0.8326) teacher/usage_min 0.0618 (0.0095) teacher/usage_std 0.2851 (0.3596) nleep/row_max_mean 1521.7931 (1548.2661) nleep/row_max_std 72.9205 (55.8595) nleep/row_min_mean 1488.8441 (1509.1786) lr 9.3721e-04 eta 0:09:44
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,209
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,311
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 98.5%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [29/50] batch [20/167] time 0.125 (0.123) data 0.000 (0.016) loss 1.3629 (1.2194) teacher_loss 0.3258 (0.2874) loss_zs_kd 0.0206 (0.0223) loss_oracle 0.5200 (0.4822) kd_loss 0.7669 (0.6798) acc 84.3750 (89.0625) gate/entropy 0.9895 (0.9896) gate/usage_max 0.5613 (0.5611) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1613 (0.1612) teacher/entropy 0.0112 (0.0220) teacher/usage_max 0.7778 (0.8628) teacher/usage_min 0.0000 (0.0140) teacher/usage_std 0.3271 (0.3785) nleep/row_max_mean 1556.7944 (1549.8236) nleep/row_max_std 42.4103 (55.3958) nleep/row_min_mean 1518.0879 (1512.1061) lr 8.7467e-04 eta 0:07:27
epoch [29/50] batch [40/167] time 0.085 (0.119) data 0.000 (0.008) loss 1.3387 (1.2261) teacher_loss 0.4058 (0.2925) loss_zs_kd 0.0121 (0.0216) loss_oracle 0.4867 (0.4779) kd_loss 0.6835 (0.6838) acc 84.3750 (88.9844) gate/entropy 0.9894 (0.9896) gate/usage_max 0.5614 (0.5612) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1613 (0.1612) teacher/entropy 0.0447 (0.0237) teacher/usage_max 0.8350 (0.8565) teacher/usage_min 0.0303 (0.0147) teacher/usage_std 0.3573 (0.3741) nleep/row_max_mean 1543.0403 (1547.9864) nleep/row_max_std 73.8784 (57.1776) nleep/row_min_mean 1503.2190 (1510.8411) lr 8.7467e-04 eta 0:07:11
epoch [29/50] batch [60/167] time 0.091 (0.119) data 0.000 (0.005) loss 1.1156 (1.2325) teacher_loss 0.1968 (0.2915) loss_zs_kd 0.0218 (0.0202) loss_oracle 0.4669 (0.4765) kd_loss 0.6744 (0.6927) acc 93.7500 (88.8542) gate/entropy 0.9902 (0.9896) gate/usage_max 0.5605 (0.5612) gate/usage_min 0.2132 (0.2130) gate/usage_std 0.1608 (0.1612) teacher/entropy 0.0627 (0.0273) teacher/usage_max 0.8268 (0.8428) teacher/usage_min 0.0454 (0.0183) teacher/usage_std 0.3506 (0.3648) nleep/row_max_mean 1515.1611 (1545.9129) nleep/row_max_std 60.7140 (58.8413) nleep/row_min_mean 1481.4414 (1509.2508) lr 8.7467e-04 eta 0:07:08
epoch [29/50] batch [80/167] time 0.193 (0.130) data 0.000 (0.004) loss 1.2038 (1.2303) teacher_loss 0.2786 (0.2923) loss_zs_kd 0.0121 (0.0194) loss_oracle 0.5083 (0.4756) kd_loss 0.6650 (0.6905) acc 90.6250 (88.8281) gate/entropy 0.9899 (0.9896) gate/usage_max 0.5608 (0.5612) gate/usage_min 0.2132 (0.2130) gate/usage_std 0.1610 (0.1612) teacher/entropy 0.0732 (0.0299) teacher/usage_max 0.8255 (0.8425) teacher/usage_min 0.0451 (0.0202) teacher/usage_std 0.3497 (0.3643) nleep/row_max_mean 1523.1294 (1544.2051) nleep/row_max_std 67.8339 (58.8562) nleep/row_min_mean 1493.2668 (1508.0476) lr 8.7467e-04 eta 0:07:48
epoch [29/50] batch [100/167] time 0.172 (0.140) data 0.000 (0.003) loss 1.4360 (1.2397) teacher_loss 0.4868 (0.2966) loss_zs_kd 0.0160 (0.0199) loss_oracle 0.4128 (0.4768) kd_loss 0.7348 (0.6947) acc 78.1250 (88.6250) gate/entropy 0.9888 (0.9895) gate/usage_max 0.5621 (0.5613) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1618 (0.1613) teacher/entropy 0.0427 (0.0324) teacher/usage_max 0.7797 (0.8350) teacher/usage_min 0.0419 (0.0210) teacher/usage_std 0.3205 (0.3598) nleep/row_max_mean 1547.1902 (1543.5329) nleep/row_max_std 57.0641 (58.7841) nleep/row_min_mean 1511.5012 (1507.7542) lr 8.7467e-04 eta 0:08:18
epoch [29/50] batch [120/167] time 0.190 (0.146) data 0.000 (0.003) loss 1.3521 (1.2373) teacher_loss 0.4650 (0.2951) loss_zs_kd 0.0144 (0.0197) loss_oracle 0.4862 (0.4754) kd_loss 0.6368 (0.6946) acc 84.3750 (88.6458) gate/entropy 0.9896 (0.9894) gate/usage_max 0.5612 (0.5614) gate/usage_min 0.2132 (0.2130) gate/usage_std 0.1612 (0.1613) teacher/entropy 0.0436 (0.0341) teacher/usage_max 0.8865 (0.8333) teacher/usage_min 0.0163 (0.0231) teacher/usage_std 0.3925 (0.3584) nleep/row_max_mean 1531.5569 (1544.3776) nleep/row_max_std 59.4391 (58.7925) nleep/row_min_mean 1500.7411 (1508.7770) lr 8.7467e-04 eta 0:08:39
epoch [29/50] batch [140/167] time 0.158 (0.149) data 0.000 (0.002) loss 0.9415 (1.2352) teacher_loss 0.0264 (0.2946) loss_zs_kd 0.0042 (0.0198) loss_oracle 0.4375 (0.4748) kd_loss 0.6943 (0.6932) acc 100.0000 (88.5491) gate/entropy 0.9892 (0.9894) gate/usage_max 0.5616 (0.5615) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1615 (0.1614) teacher/entropy 0.0409 (0.0360) teacher/usage_max 0.8278 (0.8329) teacher/usage_min 0.0315 (0.0249) teacher/usage_std 0.3525 (0.3580) nleep/row_max_mean 1535.1195 (1544.6659) nleep/row_max_std 56.1133 (57.9694) nleep/row_min_mean 1504.4117 (1509.4412) lr 8.7467e-04 eta 0:08:45
epoch [29/50] batch [160/167] time 0.157 (0.149) data 0.000 (0.002) loss 1.2471 (1.2357) teacher_loss 0.3274 (0.2927) loss_zs_kd 0.0176 (0.0198) loss_oracle 0.5021 (0.4751) kd_loss 0.6599 (0.6955) acc 87.5000 (88.6328) gate/entropy 0.9879 (0.9893) gate/usage_max 0.5631 (0.5615) gate/usage_min 0.2128 (0.2130) gate/usage_std 0.1625 (0.1615) teacher/entropy 0.0016 (0.0369) teacher/usage_max 0.9061 (0.8294) teacher/usage_min 0.0312 (0.0267) teacher/usage_std 0.4052 (0.3555) nleep/row_max_mean 1558.4475 (1544.6500) nleep/row_max_std 42.1412 (56.9477) nleep/row_min_mean 1523.3562 (1509.7165) lr 8.7467e-04 eta 0:08:43
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,209
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,315
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.8%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [30/50] batch [20/167] time 0.087 (0.125) data 0.000 (0.017) loss 1.1415 (1.2171) teacher_loss 0.3188 (0.2813) loss_zs_kd 0.0056 (0.0167) loss_oracle 0.4239 (0.4825) kd_loss 0.6079 (0.6862) acc 87.5000 (89.8438) gate/entropy 0.9884 (0.9885) gate/usage_max 0.5625 (0.5624) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1621 (0.1620) teacher/entropy 0.0630 (0.0478) teacher/usage_max 0.8975 (0.8277) teacher/usage_min 0.0462 (0.0385) teacher/usage_std 0.3989 (0.3527) nleep/row_max_mean 1558.8588 (1548.2136) nleep/row_max_std 48.3996 (53.7809) nleep/row_min_mean 1521.0408 (1514.3357) lr 8.1262e-04 eta 0:07:16
epoch [30/50] batch [40/167] time 0.206 (0.123) data 0.000 (0.009) loss 1.0830 (1.2105) teacher_loss 0.2162 (0.2820) loss_zs_kd 0.0308 (0.0176) loss_oracle 0.4468 (0.4756) kd_loss 0.6280 (0.6819) acc 87.5000 (89.3750) gate/entropy 0.9885 (0.9885) gate/usage_max 0.5624 (0.5624) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1621 (0.1621) teacher/entropy 0.0501 (0.0505) teacher/usage_max 0.8875 (0.8301) teacher/usage_min 0.0091 (0.0485) teacher/usage_std 0.3938 (0.3533) nleep/row_max_mean 1540.0537 (1547.7190) nleep/row_max_std 60.1167 (54.0026) nleep/row_min_mean 1506.4965 (1513.9757) lr 8.1262e-04 eta 0:07:05
epoch [30/50] batch [60/167] time 0.094 (0.120) data 0.000 (0.006) loss 1.4356 (1.2012) teacher_loss 0.4625 (0.2655) loss_zs_kd 0.0252 (0.0189) loss_oracle 0.5256 (0.4763) kd_loss 0.6977 (0.6882) acc 84.3750 (90.4167) gate/entropy 0.9879 (0.9884) gate/usage_max 0.5631 (0.5625) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1625 (0.1621) teacher/entropy 0.0269 (0.0501) teacher/usage_max 0.8346 (0.8234) teacher/usage_min 0.0030 (0.0456) teacher/usage_std 0.3604 (0.3492) nleep/row_max_mean 1544.3854 (1545.9017) nleep/row_max_std 44.4799 (54.8584) nleep/row_min_mean 1514.3044 (1513.0884) lr 8.1262e-04 eta 0:06:53
epoch [30/50] batch [80/167] time 0.087 (0.121) data 0.000 (0.005) loss 1.1078 (1.2131) teacher_loss 0.2223 (0.2713) loss_zs_kd 0.0238 (0.0199) loss_oracle 0.5069 (0.4763) kd_loss 0.6201 (0.6936) acc 90.6250 (90.0000) gate/entropy 0.9879 (0.9883) gate/usage_max 0.5630 (0.5626) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1625 (0.1622) teacher/entropy 0.0627 (0.0521) teacher/usage_max 0.8846 (0.8151) teacher/usage_min 0.0573 (0.0443) teacher/usage_std 0.3898 (0.3441) nleep/row_max_mean 1545.6807 (1544.7850) nleep/row_max_std 53.9382 (55.6975) nleep/row_min_mean 1515.1996 (1512.0482) lr 8.1262e-04 eta 0:06:53
epoch [30/50] batch [100/167] time 0.087 (0.119) data 0.000 (0.004) loss 1.2521 (1.2144) teacher_loss 0.2151 (0.2695) loss_zs_kd 0.0125 (0.0200) loss_oracle 0.4859 (0.4815) kd_loss 0.7877 (0.6941) acc 93.7500 (90.0625) gate/entropy 0.9880 (0.9883) gate/usage_max 0.5630 (0.5626) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1624 (0.1622) teacher/entropy 0.0198 (0.0510) teacher/usage_max 0.7460 (0.8156) teacher/usage_min 0.0318 (0.0411) teacher/usage_std 0.3020 (0.3450) nleep/row_max_mean 1549.0282 (1544.8901) nleep/row_max_std 58.3956 (55.5884) nleep/row_min_mean 1513.2756 (1512.2548) lr 8.1262e-04 eta 0:06:46
epoch [30/50] batch [120/167] time 0.095 (0.117) data 0.000 (0.003) loss 1.4374 (1.2165) teacher_loss 0.4419 (0.2700) loss_zs_kd 0.0249 (0.0203) loss_oracle 0.5107 (0.4833) kd_loss 0.7277 (0.6947) acc 87.5000 (89.9479) gate/entropy 0.9881 (0.9882) gate/usage_max 0.5629 (0.5627) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1624 (0.1623) teacher/entropy 0.0629 (0.0511) teacher/usage_max 0.7648 (0.8147) teacher/usage_min 0.0412 (0.0419) teacher/usage_std 0.3114 (0.3443) nleep/row_max_mean 1542.2102 (1544.8682) nleep/row_max_std 60.3838 (55.5650) nleep/row_min_mean 1508.9197 (1512.3050) lr 8.1262e-04 eta 0:06:37
epoch [30/50] batch [140/167] time 0.061 (0.118) data 0.000 (0.003) loss 1.2481 (1.2255) teacher_loss 0.3018 (0.2774) loss_zs_kd 0.0136 (0.0205) loss_oracle 0.5059 (0.4817) kd_loss 0.6866 (0.6970) acc 90.6250 (89.4196) gate/entropy 0.9875 (0.9882) gate/usage_max 0.5634 (0.5628) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1628 (0.1623) teacher/entropy 0.0306 (0.0496) teacher/usage_max 0.8435 (0.8137) teacher/usage_min 0.0194 (0.0404) teacher/usage_std 0.3639 (0.3437) nleep/row_max_mean 1554.6442 (1545.1075) nleep/row_max_std 51.0417 (55.0836) nleep/row_min_mean 1519.3688 (1512.6119) lr 8.1262e-04 eta 0:06:35
epoch [30/50] batch [160/167] time 0.090 (0.117) data 0.000 (0.002) loss 1.2027 (1.2205) teacher_loss 0.1998 (0.2735) loss_zs_kd 0.0174 (0.0204) loss_oracle 0.4976 (0.4790) kd_loss 0.7453 (0.6973) acc 90.6250 (89.6289) gate/entropy 0.9881 (0.9881) gate/usage_max 0.5628 (0.5628) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1623 (0.1623) teacher/entropy 0.0689 (0.0483) teacher/usage_max 0.7383 (0.8146) teacher/usage_min 0.0052 (0.0381) teacher/usage_std 0.3042 (0.3446) nleep/row_max_mean 1534.2249 (1545.2595) nleep/row_max_std 48.4404 (54.4809) nleep/row_min_mean 1504.7856 (1512.8935) lr 8.1262e-04 eta 0:06:30
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,210
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,315
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.7%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [31/50] batch [20/167] time 0.136 (0.170) data 0.000 (0.016) loss 1.2676 (1.2057) teacher_loss 0.3465 (0.2531) loss_zs_kd 0.0189 (0.0160) loss_oracle 0.4264 (0.4685) kd_loss 0.6984 (0.7104) acc 90.6250 (90.9375) gate/entropy 0.9876 (0.9876) gate/usage_max 0.5634 (0.5633) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0218 (0.0520) teacher/usage_max 0.8398 (0.7956) teacher/usage_min 0.0029 (0.0363) teacher/usage_std 0.3636 (0.3328) nleep/row_max_mean 1533.6077 (1542.1872) nleep/row_max_std 53.3975 (52.1606) nleep/row_min_mean 1504.7490 (1511.4633) lr 7.5131e-04 eta 0:09:24
epoch [31/50] batch [40/167] time 0.208 (0.170) data 0.000 (0.008) loss 1.0958 (1.2242) teacher_loss 0.1140 (0.2799) loss_zs_kd 0.0208 (0.0180) loss_oracle 0.4386 (0.4718) kd_loss 0.7521 (0.6994) acc 93.7500 (89.3750) gate/entropy 0.9883 (0.9875) gate/usage_max 0.5627 (0.5634) gate/usage_min 0.2132 (0.2130) gate/usage_std 0.1622 (0.1628) teacher/entropy 0.0316 (0.0461) teacher/usage_max 0.7734 (0.8141) teacher/usage_min 0.0372 (0.0366) teacher/usage_std 0.3173 (0.3444) nleep/row_max_mean 1522.8167 (1542.8484) nleep/row_max_std 54.8163 (51.7405) nleep/row_min_mean 1492.1533 (1511.7582) lr 7.5131e-04 eta 0:09:22
epoch [31/50] batch [60/167] time 0.150 (0.168) data 0.001 (0.005) loss 1.1450 (1.2181) teacher_loss 0.1514 (0.2786) loss_zs_kd 0.0140 (0.0181) loss_oracle 0.4239 (0.4693) kd_loss 0.7747 (0.6958) acc 90.6250 (89.1146) gate/entropy 0.9876 (0.9875) gate/usage_max 0.5633 (0.5635) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1627 (0.1628) teacher/entropy 0.0849 (0.0464) teacher/usage_max 0.6902 (0.8175) teacher/usage_min 0.0368 (0.0335) teacher/usage_std 0.2701 (0.3471) nleep/row_max_mean 1542.0339 (1544.3389) nleep/row_max_std 55.3346 (51.5824) nleep/row_min_mean 1513.2455 (1513.1962) lr 7.5131e-04 eta 0:09:11
epoch [31/50] batch [80/167] time 0.165 (0.165) data 0.000 (0.004) loss 1.3709 (1.2145) teacher_loss 0.4718 (0.2741) loss_zs_kd 0.0158 (0.0187) loss_oracle 0.3990 (0.4673) kd_loss 0.6917 (0.6975) acc 81.2500 (89.2969) gate/entropy 0.9873 (0.9874) gate/usage_max 0.5637 (0.5635) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1630 (0.1628) teacher/entropy 0.0553 (0.0482) teacher/usage_max 0.8113 (0.8138) teacher/usage_min 0.0326 (0.0346) teacher/usage_std 0.3417 (0.3446) nleep/row_max_mean 1542.3646 (1544.0165) nleep/row_max_std 64.0603 (52.6239) nleep/row_min_mean 1510.8105 (1513.1585) lr 7.5131e-04 eta 0:08:58
epoch [31/50] batch [100/167] time 0.149 (0.163) data 0.000 (0.003) loss 1.2821 (1.2227) teacher_loss 0.2989 (0.2749) loss_zs_kd 0.0145 (0.0183) loss_oracle 0.4744 (0.4686) kd_loss 0.7387 (0.7044) acc 90.6250 (89.3438) gate/entropy 0.9870 (0.9874) gate/usage_max 0.5640 (0.5636) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1632 (0.1629) teacher/entropy 0.0374 (0.0490) teacher/usage_max 0.7828 (0.8056) teacher/usage_min 0.0928 (0.0398) teacher/usage_std 0.3181 (0.3388) nleep/row_max_mean 1555.2271 (1543.9973) nleep/row_max_std 55.2384 (53.9372) nleep/row_min_mean 1526.4375 (1513.2787) lr 7.5131e-04 eta 0:08:49
epoch [31/50] batch [120/167] time 0.074 (0.161) data 0.000 (0.003) loss 1.1662 (1.2255) teacher_loss 0.2488 (0.2830) loss_zs_kd 0.0136 (0.0181) loss_oracle 0.4411 (0.4669) kd_loss 0.6900 (0.7000) acc 90.6250 (89.0104) gate/entropy 0.9869 (0.9874) gate/usage_max 0.5641 (0.5636) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1632 (0.1629) teacher/entropy 0.0334 (0.0508) teacher/usage_max 0.8349 (0.8085) teacher/usage_min 0.0050 (0.0406) teacher/usage_std 0.3603 (0.3405) nleep/row_max_mean 1554.8398 (1543.9566) nleep/row_max_std 56.6466 (54.9432) nleep/row_min_mean 1520.4933 (1513.3004) lr 7.5131e-04 eta 0:08:38
epoch [31/50] batch [140/167] time 0.073 (0.149) data 0.000 (0.002) loss 1.0862 (1.2283) teacher_loss 0.2191 (0.2869) loss_zs_kd 0.0176 (0.0179) loss_oracle 0.4550 (0.4653) kd_loss 0.6308 (0.6998) acc 90.6250 (88.6830) gate/entropy 0.9869 (0.9873) gate/usage_max 0.5641 (0.5637) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1632 (0.1629) teacher/entropy 0.0390 (0.0517) teacher/usage_max 0.8976 (0.8077) teacher/usage_min 0.0418 (0.0417) teacher/usage_std 0.3990 (0.3398) nleep/row_max_mean 1539.5516 (1543.4290) nleep/row_max_std 60.3940 (55.7891) nleep/row_min_mean 1510.8826 (1512.9322) lr 7.5131e-04 eta 0:07:55
epoch [31/50] batch [160/167] time 0.081 (0.142) data 0.000 (0.002) loss 1.2090 (1.2379) teacher_loss 0.3820 (0.2930) loss_zs_kd 0.0143 (0.0186) loss_oracle 0.4772 (0.4668) kd_loss 0.5814 (0.7022) acc 87.5000 (88.4961) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5642 (0.5638) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0393 (0.0508) teacher/usage_max 0.9491 (0.8060) teacher/usage_min 0.0198 (0.0417) teacher/usage_std 0.4354 (0.3388) nleep/row_max_mean 1530.1516 (1542.9103) nleep/row_max_std 68.1790 (55.9140) nleep/row_min_mean 1504.0330 (1512.5441) lr 7.5131e-04 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,217
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [32/50] batch [20/167] time 0.100 (0.116) data 0.000 (0.017) loss 1.1191 (1.2145) teacher_loss 0.1989 (0.2834) loss_zs_kd 0.0162 (0.0214) loss_oracle 0.5153 (0.4742) kd_loss 0.6545 (0.6833) acc 93.7500 (88.9062) gate/entropy 0.9876 (0.9867) gate/usage_max 0.5634 (0.5644) gate/usage_min 0.2132 (0.2129) gate/usage_std 0.1627 (0.1634) teacher/entropy 0.0667 (0.0405) teacher/usage_max 0.8400 (0.8373) teacher/usage_min 0.0186 (0.0386) teacher/usage_std 0.3617 (0.3589) nleep/row_max_mean 1507.2114 (1537.6050) nleep/row_max_std 71.4812 (56.2489) nleep/row_min_mean 1483.8994 (1507.3615) lr 6.9098e-04 eta 0:06:06
epoch [32/50] batch [40/167] time 0.087 (0.113) data 0.000 (0.009) loss 1.4158 (1.2383) teacher_loss 0.3953 (0.2901) loss_zs_kd 0.0223 (0.0212) loss_oracle 0.5225 (0.4781) kd_loss 0.7481 (0.6985) acc 84.3750 (88.2812) gate/entropy 0.9863 (0.9867) gate/usage_max 0.5648 (0.5643) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1637 (0.1634) teacher/entropy 0.0618 (0.0462) teacher/usage_max 0.7473 (0.8150) teacher/usage_min 0.1138 (0.0437) teacher/usage_std 0.2929 (0.3440) nleep/row_max_mean 1547.2860 (1535.1099) nleep/row_max_std 50.1845 (54.8321) nleep/row_min_mean 1513.7261 (1505.2582) lr 6.9098e-04 eta 0:05:55
epoch [32/50] batch [60/167] time 0.098 (0.117) data 0.001 (0.006) loss 1.1898 (1.2229) teacher_loss 0.2408 (0.2829) loss_zs_kd 0.0298 (0.0209) loss_oracle 0.5001 (0.4784) kd_loss 0.6841 (0.6904) acc 87.5000 (88.5938) gate/entropy 0.9868 (0.9867) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1633 (0.1634) teacher/entropy 0.0602 (0.0476) teacher/usage_max 0.8177 (0.8222) teacher/usage_min 0.0865 (0.0441) teacher/usage_std 0.3425 (0.3488) nleep/row_max_mean 1529.7087 (1534.1861) nleep/row_max_std 62.1806 (56.5182) nleep/row_min_mean 1498.1758 (1504.1410) lr 6.9098e-04 eta 0:06:04
epoch [32/50] batch [80/167] time 0.194 (0.120) data 0.001 (0.004) loss 1.2307 (1.2170) teacher_loss 0.2611 (0.2752) loss_zs_kd 0.0281 (0.0203) loss_oracle 0.4923 (0.4768) kd_loss 0.7093 (0.6933) acc 90.6250 (88.9453) gate/entropy 0.9863 (0.9867) gate/usage_max 0.5648 (0.5644) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1637 (0.1634) teacher/entropy 0.0361 (0.0471) teacher/usage_max 0.8124 (0.8195) teacher/usage_min 0.0149 (0.0433) teacher/usage_std 0.3448 (0.3471) nleep/row_max_mean 1538.3019 (1534.2031) nleep/row_max_std 51.7584 (56.0527) nleep/row_min_mean 1507.0908 (1503.9231) lr 6.9098e-04 eta 0:06:11
epoch [32/50] batch [100/167] time 0.164 (0.126) data 0.000 (0.004) loss 1.3188 (1.2208) teacher_loss 0.2942 (0.2754) loss_zs_kd 0.0230 (0.0199) loss_oracle 0.4749 (0.4795) kd_loss 0.7757 (0.6957) acc 90.6250 (89.0000) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5645 (0.5644) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0596 (0.0480) teacher/usage_max 0.7180 (0.8159) teacher/usage_min 0.0883 (0.0438) teacher/usage_std 0.2754 (0.3446) nleep/row_max_mean 1540.8071 (1534.4693) nleep/row_max_std 54.7480 (56.2470) nleep/row_min_mean 1508.9504 (1504.2435) lr 6.9098e-04 eta 0:06:27
epoch [32/50] batch [120/167] time 0.149 (0.131) data 0.000 (0.003) loss 1.1319 (1.2286) teacher_loss 0.1865 (0.2871) loss_zs_kd 0.0295 (0.0206) loss_oracle 0.4543 (0.4777) kd_loss 0.7036 (0.6923) acc 90.6250 (88.5677) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5644 (0.5645) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0596 (0.0465) teacher/usage_max 0.7963 (0.8211) teacher/usage_min 0.0967 (0.0431) teacher/usage_std 0.3274 (0.3481) nleep/row_max_mean 1531.2845 (1534.2531) nleep/row_max_std 63.4631 (56.5130) nleep/row_min_mean 1504.4669 (1503.9529) lr 6.9098e-04 eta 0:06:38
epoch [32/50] batch [140/167] time 0.161 (0.133) data 0.000 (0.003) loss 1.2393 (1.2300) teacher_loss 0.3114 (0.2914) loss_zs_kd 0.0156 (0.0208) loss_oracle 0.4901 (0.4782) kd_loss 0.6749 (0.6891) acc 84.3750 (88.3482) gate/entropy 0.9865 (0.9865) gate/usage_max 0.5646 (0.5645) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0392 (0.0441) teacher/usage_max 0.8475 (0.8270) teacher/usage_min 0.0479 (0.0409) teacher/usage_std 0.3643 (0.3522) nleep/row_max_mean 1526.4392 (1534.2160) nleep/row_max_std 68.4845 (57.1246) nleep/row_min_mean 1495.9907 (1503.7854) lr 6.9098e-04 eta 0:06:43
epoch [32/50] batch [160/167] time 0.124 (0.135) data 0.000 (0.002) loss 1.0356 (1.2324) teacher_loss 0.2158 (0.2940) loss_zs_kd 0.0118 (0.0207) loss_oracle 0.4555 (0.4797) kd_loss 0.5862 (0.6882) acc 93.7500 (88.2031) gate/entropy 0.9859 (0.9865) gate/usage_max 0.5652 (0.5646) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1640 (0.1636) teacher/entropy 0.0673 (0.0439) teacher/usage_max 0.9117 (0.8281) teacher/usage_min 0.0159 (0.0406) teacher/usage_std 0.4096 (0.3529) nleep/row_max_mean 1530.8051 (1534.3079) nleep/row_max_std 66.3985 (57.1966) nleep/row_min_mean 1501.1240 (1503.8193) lr 6.9098e-04 eta 0:06:45
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,209
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,317
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [33/50] batch [20/167] time 0.156 (0.156) data 0.000 (0.016) loss 1.4972 (1.2485) teacher_loss 0.6162 (0.3130) loss_zs_kd 0.0303 (0.0215) loss_oracle 0.4536 (0.4858) kd_loss 0.6391 (0.6819) acc 78.1250 (89.0625) gate/entropy 0.9863 (0.9860) gate/usage_max 0.5648 (0.5651) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1637 (0.1639) teacher/entropy 0.0793 (0.0526) teacher/usage_max 0.8436 (0.8253) teacher/usage_min 0.0546 (0.0413) teacher/usage_std 0.3613 (0.3508) nleep/row_max_mean 1527.3562 (1536.8244) nleep/row_max_std 48.7908 (54.5896) nleep/row_min_mean 1497.3560 (1505.8721) lr 6.3188e-04 eta 0:07:46
epoch [33/50] batch [40/167] time 0.141 (0.147) data 0.000 (0.008) loss 1.2298 (1.2248) teacher_loss 0.2773 (0.2923) loss_zs_kd 0.0265 (0.0198) loss_oracle 0.4796 (0.4814) kd_loss 0.6994 (0.6818) acc 90.6250 (89.2969) gate/entropy 0.9855 (0.9860) gate/usage_max 0.5656 (0.5651) gate/usage_min 0.2128 (0.2130) gate/usage_std 0.1643 (0.1639) teacher/entropy 0.0185 (0.0470) teacher/usage_max 0.8432 (0.8317) teacher/usage_min 0.0682 (0.0452) teacher/usage_std 0.3606 (0.3547) nleep/row_max_mean 1556.9385 (1539.5951) nleep/row_max_std 49.4637 (54.5224) nleep/row_min_mean 1522.1213 (1508.5030) lr 6.3188e-04 eta 0:07:16
epoch [33/50] batch [60/167] time 0.090 (0.133) data 0.001 (0.005) loss 1.2238 (1.2317) teacher_loss 0.3793 (0.2975) loss_zs_kd 0.0268 (0.0210) loss_oracle 0.5087 (0.4840) kd_loss 0.5768 (0.6817) acc 87.5000 (89.0625) gate/entropy 0.9853 (0.9859) gate/usage_max 0.5658 (0.5652) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1644 (0.1640) teacher/entropy 0.0513 (0.0432) teacher/usage_max 0.9374 (0.8360) teacher/usage_min 0.0031 (0.0465) teacher/usage_std 0.4278 (0.3576) nleep/row_max_mean 1547.9211 (1540.8525) nleep/row_max_std 48.3890 (54.6294) nleep/row_min_mean 1516.9712 (1509.7932) lr 6.3188e-04 eta 0:06:30
epoch [33/50] batch [80/167] time 0.171 (0.131) data 0.000 (0.004) loss 1.2561 (1.2430) teacher_loss 0.2585 (0.3062) loss_zs_kd 0.0233 (0.0206) loss_oracle 0.4717 (0.4839) kd_loss 0.7501 (0.6845) acc 90.6250 (88.7500) gate/entropy 0.9859 (0.9859) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0278 (0.0436) teacher/usage_max 0.7811 (0.8327) teacher/usage_min 0.0869 (0.0509) teacher/usage_std 0.3171 (0.3550) nleep/row_max_mean 1532.3777 (1540.5006) nleep/row_max_std 51.5239 (54.8716) nleep/row_min_mean 1506.3403 (1509.7739) lr 6.3188e-04 eta 0:06:22
epoch [33/50] batch [100/167] time 0.080 (0.129) data 0.001 (0.003) loss 1.0778 (1.2325) teacher_loss 0.1576 (0.2981) loss_zs_kd 0.0082 (0.0198) loss_oracle 0.4650 (0.4818) kd_loss 0.6836 (0.6835) acc 93.7500 (89.0000) gate/entropy 0.9860 (0.9858) gate/usage_max 0.5651 (0.5653) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0613 (0.0446) teacher/usage_max 0.8145 (0.8328) teacher/usage_min 0.0650 (0.0521) teacher/usage_std 0.3410 (0.3549) nleep/row_max_mean 1542.8083 (1539.8478) nleep/row_max_std 64.3710 (55.2494) nleep/row_min_mean 1511.5283 (1509.3455) lr 6.3188e-04 eta 0:06:15
epoch [33/50] batch [120/167] time 0.092 (0.129) data 0.000 (0.003) loss 1.4506 (1.2234) teacher_loss 0.5686 (0.2914) loss_zs_kd 0.0236 (0.0195) loss_oracle 0.4686 (0.4811) kd_loss 0.6359 (0.6818) acc 81.2500 (89.1667) gate/entropy 0.9851 (0.9858) gate/usage_max 0.5660 (0.5653) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1646 (0.1641) teacher/entropy 0.0312 (0.0444) teacher/usage_max 0.8969 (0.8349) teacher/usage_min 0.0312 (0.0520) teacher/usage_std 0.3988 (0.3562) nleep/row_max_mean 1553.0167 (1540.0572) nleep/row_max_std 56.3850 (55.4389) nleep/row_min_mean 1519.7650 (1509.5727) lr 6.3188e-04 eta 0:06:11
epoch [33/50] batch [140/167] time 0.078 (0.124) data 0.000 (0.002) loss 1.1395 (1.2192) teacher_loss 0.1869 (0.2847) loss_zs_kd 0.0179 (0.0189) loss_oracle 0.4470 (0.4807) kd_loss 0.7201 (0.6847) acc 93.7500 (89.4420) gate/entropy 0.9855 (0.9858) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0608 (0.0452) teacher/usage_max 0.7744 (0.8308) teacher/usage_min 0.0524 (0.0529) teacher/usage_std 0.3158 (0.3535) nleep/row_max_mean 1544.3904 (1540.2637) nleep/row_max_std 57.4530 (55.0760) nleep/row_min_mean 1512.4601 (1509.8781) lr 6.3188e-04 eta 0:05:55
epoch [33/50] batch [160/167] time 0.069 (0.123) data 0.000 (0.002) loss 1.0372 (1.2151) teacher_loss 0.1268 (0.2785) loss_zs_kd 0.0103 (0.0183) loss_oracle 0.4377 (0.4815) kd_loss 0.6863 (0.6867) acc 93.7500 (89.5508) gate/entropy 0.9854 (0.9857) gate/usage_max 0.5658 (0.5654) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1644 (0.1641) teacher/entropy 0.0303 (0.0454) teacher/usage_max 0.8436 (0.8284) teacher/usage_min 0.0449 (0.0538) teacher/usage_std 0.3618 (0.3518) nleep/row_max_mean 1541.7184 (1540.3473) nleep/row_max_std 57.5933 (55.0533) nleep/row_min_mean 1511.7229 (1509.8152) lr 6.3188e-04 eta 0:05:50
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,213
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [34/50] batch [20/167] time 0.137 (0.166) data 0.000 (0.017) loss 1.2630 (1.2088) teacher_loss 0.3204 (0.2855) loss_zs_kd 0.0130 (0.0175) loss_oracle 0.4064 (0.4765) kd_loss 0.7329 (0.6764) acc 87.5000 (89.8438) gate/entropy 0.9859 (0.9853) gate/usage_max 0.5652 (0.5658) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1640 (0.1644) teacher/entropy 0.0720 (0.0381) teacher/usage_max 0.7521 (0.8462) teacher/usage_min 0.1200 (0.0382) teacher/usage_std 0.2961 (0.3645) nleep/row_max_mean 1532.0471 (1543.5876) nleep/row_max_std 54.4163 (51.8769) nleep/row_min_mean 1502.6846 (1511.7788) lr 5.7422e-04 eta 0:07:48
epoch [34/50] batch [40/167] time 0.152 (0.159) data 0.000 (0.009) loss 1.0679 (1.1878) teacher_loss 0.1248 (0.2577) loss_zs_kd 0.0036 (0.0174) loss_oracle 0.4560 (0.4759) kd_loss 0.7132 (0.6834) acc 93.7500 (90.6250) gate/entropy 0.9857 (0.9853) gate/usage_max 0.5655 (0.5659) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1642 (0.1645) teacher/entropy 0.0517 (0.0374) teacher/usage_max 0.7934 (0.8392) teacher/usage_min 0.0677 (0.0380) teacher/usage_std 0.3266 (0.3603) nleep/row_max_mean 1538.6862 (1543.8171) nleep/row_max_std 55.1117 (53.3372) nleep/row_min_mean 1508.8420 (1512.0768) lr 5.7422e-04 eta 0:07:24
epoch [34/50] batch [60/167] time 0.128 (0.157) data 0.001 (0.006) loss 1.3114 (1.2105) teacher_loss 0.3768 (0.2700) loss_zs_kd 0.0239 (0.0191) loss_oracle 0.5053 (0.4801) kd_loss 0.6700 (0.6909) acc 87.5000 (90.1562) gate/entropy 0.9852 (0.9853) gate/usage_max 0.5659 (0.5659) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1645 (0.1644) teacher/entropy 0.0152 (0.0383) teacher/usage_max 0.8750 (0.8302) teacher/usage_min 0.0056 (0.0381) teacher/usage_std 0.3858 (0.3545) nleep/row_max_mean 1527.9916 (1540.2840) nleep/row_max_std 55.6740 (54.4533) nleep/row_min_mean 1497.2576 (1509.0576) lr 5.7422e-04 eta 0:07:15
epoch [34/50] batch [80/167] time 0.156 (0.155) data 0.000 (0.004) loss 1.0801 (1.2090) teacher_loss 0.2226 (0.2701) loss_zs_kd 0.0113 (0.0200) loss_oracle 0.4713 (0.4819) kd_loss 0.6162 (0.6880) acc 90.6250 (90.0391) gate/entropy 0.9855 (0.9852) gate/usage_max 0.5656 (0.5659) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1643 (0.1645) teacher/entropy 0.0607 (0.0412) teacher/usage_max 0.8864 (0.8302) teacher/usage_min 0.0391 (0.0384) teacher/usage_std 0.3913 (0.3545) nleep/row_max_mean 1525.9373 (1539.4641) nleep/row_max_std 58.6069 (53.9978) nleep/row_min_mean 1500.2157 (1508.5675) lr 5.7422e-04 eta 0:07:07
epoch [34/50] batch [100/167] time 0.163 (0.154) data 0.000 (0.004) loss 1.1135 (1.2094) teacher_loss 0.2081 (0.2697) loss_zs_kd 0.0113 (0.0197) loss_oracle 0.5193 (0.4803) kd_loss 0.6401 (0.6898) acc 96.8750 (89.6562) gate/entropy 0.9845 (0.9853) gate/usage_max 0.5667 (0.5659) gate/usage_min 0.2128 (0.2130) gate/usage_std 0.1650 (0.1645) teacher/entropy 0.0312 (0.0424) teacher/usage_max 0.8915 (0.8270) teacher/usage_min 0.0312 (0.0406) teacher/usage_std 0.3951 (0.3521) nleep/row_max_mean 1558.9358 (1538.4975) nleep/row_max_std 43.2472 (54.4573) nleep/row_min_mean 1528.2393 (1507.7731) lr 5.7422e-04 eta 0:07:01
epoch [34/50] batch [120/167] time 0.150 (0.151) data 0.000 (0.003) loss 1.1288 (1.2103) teacher_loss 0.2343 (0.2745) loss_zs_kd 0.0045 (0.0192) loss_oracle 0.4237 (0.4776) kd_loss 0.6804 (0.6873) acc 87.5000 (89.4531) gate/entropy 0.9852 (0.9852) gate/usage_max 0.5659 (0.5659) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1645 (0.1645) teacher/entropy 0.0070 (0.0416) teacher/usage_max 0.8745 (0.8304) teacher/usage_min 0.0312 (0.0392) teacher/usage_std 0.3835 (0.3545) nleep/row_max_mean 1535.1865 (1539.3183) nleep/row_max_std 69.5971 (55.0891) nleep/row_min_mean 1505.9642 (1508.5544) lr 5.7422e-04 eta 0:06:49
epoch [34/50] batch [140/167] time 0.123 (0.150) data 0.000 (0.003) loss 1.3183 (1.2132) teacher_loss 0.3300 (0.2781) loss_zs_kd 0.0153 (0.0191) loss_oracle 0.4657 (0.4788) kd_loss 0.7479 (0.6862) acc 87.5000 (89.1071) gate/entropy 0.9854 (0.9852) gate/usage_max 0.5658 (0.5660) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1644 (0.1645) teacher/entropy 0.0901 (0.0417) teacher/usage_max 0.7134 (0.8314) teacher/usage_min 0.0280 (0.0383) teacher/usage_std 0.2848 (0.3552) nleep/row_max_mean 1529.6743 (1539.2272) nleep/row_max_std 57.8526 (55.0251) nleep/row_min_mean 1502.9872 (1508.6217) lr 5.7422e-04 eta 0:06:44
epoch [34/50] batch [160/167] time 0.151 (0.149) data 0.000 (0.002) loss 1.2995 (1.2154) teacher_loss 0.2653 (0.2791) loss_zs_kd 0.0332 (0.0194) loss_oracle 0.4609 (0.4787) kd_loss 0.7871 (0.6873) acc 87.5000 (89.1602) gate/entropy 0.9849 (0.9852) gate/usage_max 0.5662 (0.5660) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1647 (0.1645) teacher/entropy 0.0470 (0.0411) teacher/usage_max 0.7181 (0.8309) teacher/usage_min 0.0424 (0.0379) teacher/usage_std 0.2837 (0.3549) nleep/row_max_mean 1546.6707 (1539.2851) nleep/row_max_std 54.2522 (55.3112) nleep/row_min_mean 1518.0895 (1508.6747) lr 5.7422e-04 eta 0:06:39
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,211
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [35/50] batch [20/167] time 0.087 (0.132) data 0.000 (0.019) loss 1.0923 (1.2469) teacher_loss 0.2113 (0.3059) loss_zs_kd 0.0221 (0.0202) loss_oracle 0.4656 (0.4782) kd_loss 0.6371 (0.6918) acc 93.7500 (87.9688) gate/entropy 0.9849 (0.9848) gate/usage_max 0.5663 (0.5664) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1648 (0.1648) teacher/entropy 0.0295 (0.0325) teacher/usage_max 0.8965 (0.8349) teacher/usage_min 0.0330 (0.0392) teacher/usage_std 0.3985 (0.3581) nleep/row_max_mean 1545.0090 (1541.4801) nleep/row_max_std 57.7367 (60.4088) nleep/row_min_mean 1513.1023 (1510.6931) lr 5.1825e-04 eta 0:05:51
epoch [35/50] batch [40/167] time 0.096 (0.121) data 0.000 (0.009) loss 1.2967 (1.2388) teacher_loss 0.2240 (0.2886) loss_zs_kd 0.0095 (0.0199) loss_oracle 0.4369 (0.4751) kd_loss 0.8495 (0.7028) acc 93.7500 (89.2969) gate/entropy 0.9850 (0.9848) gate/usage_max 0.5662 (0.5664) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1647 (0.1648) teacher/entropy 0.0721 (0.0342) teacher/usage_max 0.6248 (0.8212) teacher/usage_min 0.0629 (0.0378) teacher/usage_std 0.2299 (0.3492) nleep/row_max_mean 1535.4490 (1540.7299) nleep/row_max_std 47.4654 (58.2560) nleep/row_min_mean 1509.5010 (1510.1135) lr 5.1825e-04 eta 0:05:19
epoch [35/50] batch [60/167] time 0.083 (0.117) data 0.000 (0.006) loss 1.2244 (1.2424) teacher_loss 0.3025 (0.2909) loss_zs_kd 0.0222 (0.0201) loss_oracle 0.4639 (0.4794) kd_loss 0.6788 (0.7017) acc 87.5000 (89.2708) gate/entropy 0.9851 (0.9848) gate/usage_max 0.5661 (0.5664) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1646 (0.1648) teacher/entropy 0.1159 (0.0365) teacher/usage_max 0.7614 (0.8201) teacher/usage_min 0.0617 (0.0365) teacher/usage_std 0.3063 (0.3488) nleep/row_max_mean 1523.0979 (1540.0614) nleep/row_max_std 56.2668 (57.9225) nleep/row_min_mean 1497.7712 (1509.4919) lr 5.1825e-04 eta 0:05:06
epoch [35/50] batch [80/167] time 0.182 (0.120) data 0.000 (0.005) loss 1.2860 (1.2353) teacher_loss 0.1558 (0.2914) loss_zs_kd 0.0166 (0.0198) loss_oracle 0.5470 (0.4801) kd_loss 0.8484 (0.6938) acc 93.7500 (88.9453) gate/entropy 0.9847 (0.9848) gate/usage_max 0.5664 (0.5664) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1649 (0.1648) teacher/entropy 0.0115 (0.0364) teacher/usage_max 0.6870 (0.8283) teacher/usage_min 0.0020 (0.0337) teacher/usage_std 0.2801 (0.3545) nleep/row_max_mean 1540.7100 (1540.4125) nleep/row_max_std 60.1514 (57.8587) nleep/row_min_mean 1511.3157 (1509.8045) lr 5.1825e-04 eta 0:05:10
epoch [35/50] batch [100/167] time 0.146 (0.117) data 0.000 (0.004) loss 1.1059 (1.2274) teacher_loss 0.1492 (0.2804) loss_zs_kd 0.0065 (0.0198) loss_oracle 0.4569 (0.4817) kd_loss 0.7250 (0.6963) acc 90.6250 (89.4375) gate/entropy 0.9846 (0.9848) gate/usage_max 0.5666 (0.5664) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1650 (0.1648) teacher/entropy 0.0687 (0.0358) teacher/usage_max 0.7617 (0.8264) teacher/usage_min 0.0667 (0.0341) teacher/usage_std 0.3059 (0.3530) nleep/row_max_mean 1548.9512 (1540.9710) nleep/row_max_std 59.5519 (57.5446) nleep/row_min_mean 1519.1327 (1510.1530) lr 5.1825e-04 eta 0:05:01
epoch [35/50] batch [120/167] time 0.166 (0.124) data 0.000 (0.003) loss 1.0350 (1.2312) teacher_loss 0.1219 (0.2826) loss_zs_kd 0.0148 (0.0201) loss_oracle 0.4614 (0.4826) kd_loss 0.6750 (0.6973) acc 96.8750 (89.3490) gate/entropy 0.9843 (0.9847) gate/usage_max 0.5669 (0.5664) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1652 (0.1649) teacher/entropy 0.0100 (0.0374) teacher/usage_max 0.8749 (0.8237) teacher/usage_min 0.0022 (0.0373) teacher/usage_std 0.3861 (0.3508) nleep/row_max_mean 1552.0627 (1541.3126) nleep/row_max_std 50.4629 (56.9383) nleep/row_min_mean 1519.7869 (1510.5565) lr 5.1825e-04 eta 0:05:17
epoch [35/50] batch [140/167] time 0.140 (0.129) data 0.000 (0.003) loss 1.0308 (1.2314) teacher_loss 0.0813 (0.2836) loss_zs_kd 0.0097 (0.0197) loss_oracle 0.5440 (0.4823) kd_loss 0.6727 (0.6969) acc 100.0000 (89.3080) gate/entropy 0.9845 (0.9847) gate/usage_max 0.5667 (0.5665) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1651 (0.1649) teacher/entropy 0.0204 (0.0389) teacher/usage_max 0.8681 (0.8225) teacher/usage_min 0.0315 (0.0379) teacher/usage_std 0.3792 (0.3499) nleep/row_max_mean 1542.3857 (1541.4524) nleep/row_max_std 47.4613 (56.7541) nleep/row_min_mean 1515.1819 (1510.7397) lr 5.1825e-04 eta 0:05:27
epoch [35/50] batch [160/167] time 0.120 (0.129) data 0.000 (0.003) loss 1.0501 (1.2266) teacher_loss 0.2328 (0.2806) loss_zs_kd 0.0069 (0.0198) loss_oracle 0.3736 (0.4812) kd_loss 0.6270 (0.6955) acc 93.7500 (89.4141) gate/entropy 0.9846 (0.9847) gate/usage_max 0.5666 (0.5665) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1650 (0.1649) teacher/entropy 0.0365 (0.0400) teacher/usage_max 0.8979 (0.8229) teacher/usage_min 0.0002 (0.0387) teacher/usage_std 0.4013 (0.3500) nleep/row_max_mean 1541.6239 (1542.4101) nleep/row_max_std 66.2314 (56.3017) nleep/row_min_mean 1512.6355 (1511.6980) lr 5.1825e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [36/50] batch [20/167] time 0.145 (0.162) data 0.000 (0.017) loss 1.3258 (1.2228) teacher_loss 0.5165 (0.2929) loss_zs_kd 0.0082 (0.0160) loss_oracle 0.4375 (0.4804) kd_loss 0.5864 (0.6817) acc 84.3750 (89.6875) gate/entropy 0.9841 (0.9845) gate/usage_max 0.5671 (0.5667) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1654 (0.1651) teacher/entropy 0.0112 (0.0498) teacher/usage_max 0.9683 (0.8270) teacher/usage_min 0.0028 (0.0431) teacher/usage_std 0.4491 (0.3518) nleep/row_max_mean 1558.6787 (1548.6533) nleep/row_max_std 55.7084 (59.4182) nleep/row_min_mean 1526.0361 (1518.4775) lr 4.6417e-04 eta 0:06:43
epoch [36/50] batch [40/167] time 0.176 (0.155) data 0.000 (0.009) loss 1.2621 (1.2102) teacher_loss 0.3451 (0.2792) loss_zs_kd 0.0298 (0.0173) loss_oracle 0.4394 (0.4760) kd_loss 0.6824 (0.6844) acc 93.7500 (89.4531) gate/entropy 0.9847 (0.9844) gate/usage_max 0.5665 (0.5668) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1649 (0.1651) teacher/entropy 0.0323 (0.0498) teacher/usage_max 0.8440 (0.8246) teacher/usage_min 0.0288 (0.0504) teacher/usage_std 0.3633 (0.3497) nleep/row_max_mean 1538.0551 (1548.1277) nleep/row_max_std 63.5308 (59.2247) nleep/row_min_mean 1506.1113 (1517.8550) lr 4.6417e-04 eta 0:06:20
epoch [36/50] batch [60/167] time 0.160 (0.154) data 0.000 (0.006) loss 1.1465 (1.2027) teacher_loss 0.1751 (0.2670) loss_zs_kd 0.0249 (0.0172) loss_oracle 0.4726 (0.4719) kd_loss 0.7226 (0.6912) acc 93.7500 (89.7917) gate/entropy 0.9843 (0.9844) gate/usage_max 0.5669 (0.5668) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0804 (0.0559) teacher/usage_max 0.7525 (0.8110) teacher/usage_min 0.0867 (0.0558) teacher/usage_std 0.2979 (0.3403) nleep/row_max_mean 1550.1986 (1545.7466) nleep/row_max_std 51.2801 (58.5388) nleep/row_min_mean 1523.3552 (1515.8795) lr 4.6417e-04 eta 0:06:15
epoch [36/50] batch [80/167] time 0.097 (0.140) data 0.000 (0.004) loss 1.1586 (1.2078) teacher_loss 0.1650 (0.2675) loss_zs_kd 0.0083 (0.0179) loss_oracle 0.4381 (0.4727) kd_loss 0.7705 (0.6951) acc 90.6250 (89.6094) gate/entropy 0.9844 (0.9844) gate/usage_max 0.5668 (0.5668) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1651 (0.1651) teacher/entropy 0.0499 (0.0536) teacher/usage_max 0.7333 (0.8096) teacher/usage_min 0.0766 (0.0576) teacher/usage_std 0.2866 (0.3391) nleep/row_max_mean 1552.5503 (1546.3683) nleep/row_max_std 65.0100 (58.2947) nleep/row_min_mean 1522.7816 (1516.5263) lr 4.6417e-04 eta 0:05:40
epoch [36/50] batch [100/167] time 0.095 (0.136) data 0.000 (0.004) loss 1.2368 (1.2111) teacher_loss 0.2456 (0.2723) loss_zs_kd 0.0115 (0.0182) loss_oracle 0.5139 (0.4731) kd_loss 0.7285 (0.6932) acc 93.7500 (89.4688) gate/entropy 0.9840 (0.9844) gate/usage_max 0.5673 (0.5668) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1654 (0.1651) teacher/entropy 0.0374 (0.0535) teacher/usage_max 0.7923 (0.8116) teacher/usage_min 0.1009 (0.0566) teacher/usage_std 0.3245 (0.3405) nleep/row_max_mean 1562.8357 (1546.6600) nleep/row_max_std 59.4086 (58.5003) nleep/row_min_mean 1529.4846 (1516.7940) lr 4.6417e-04 eta 0:05:27
epoch [36/50] batch [120/167] time 0.141 (0.134) data 0.000 (0.003) loss 1.4494 (1.2214) teacher_loss 0.4552 (0.2789) loss_zs_kd 0.0094 (0.0179) loss_oracle 0.5295 (0.4732) kd_loss 0.7247 (0.6971) acc 87.5000 (89.2969) gate/entropy 0.9841 (0.9843) gate/usage_max 0.5671 (0.5669) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0498 (0.0545) teacher/usage_max 0.7813 (0.8065) teacher/usage_min 0.0452 (0.0589) teacher/usage_std 0.3210 (0.3371) nleep/row_max_mean 1549.8706 (1547.6363) nleep/row_max_std 64.9546 (58.5683) nleep/row_min_mean 1517.1208 (1517.4548) lr 4.6417e-04 eta 0:05:19
epoch [36/50] batch [140/167] time 0.112 (0.130) data 0.000 (0.003) loss 1.2283 (1.2224) teacher_loss 0.2426 (0.2799) loss_zs_kd 0.0213 (0.0180) loss_oracle 0.4839 (0.4741) kd_loss 0.7330 (0.6964) acc 87.5000 (89.3750) gate/entropy 0.9846 (0.9843) gate/usage_max 0.5666 (0.5669) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1649 (0.1652) teacher/entropy 0.0628 (0.0563) teacher/usage_max 0.7608 (0.8053) teacher/usage_min 0.0687 (0.0583) teacher/usage_std 0.3051 (0.3363) nleep/row_max_mean 1538.7983 (1546.3325) nleep/row_max_std 51.0129 (58.2756) nleep/row_min_mean 1509.0250 (1516.3045) lr 4.6417e-04 eta 0:05:07
epoch [36/50] batch [160/167] time 0.078 (0.127) data 0.000 (0.002) loss 1.2657 (1.2257) teacher_loss 0.2739 (0.2829) loss_zs_kd 0.0100 (0.0180) loss_oracle 0.4756 (0.4746) kd_loss 0.7490 (0.6966) acc 93.7500 (89.2578) gate/entropy 0.9843 (0.9843) gate/usage_max 0.5669 (0.5669) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1652 (0.1652) teacher/entropy 0.0407 (0.0567) teacher/usage_max 0.7671 (0.8047) teacher/usage_min 0.0940 (0.0592) teacher/usage_std 0.3073 (0.3358) nleep/row_max_mean 1548.4504 (1546.3053) nleep/row_max_std 37.6525 (58.1024) nleep/row_min_mean 1519.6628 (1516.2442) lr 4.6417e-04 eta 0:04:56
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [37/50] batch [20/167] time 0.136 (0.136) data 0.000 (0.014) loss 1.2588 (1.1639) teacher_loss 0.2654 (0.2383) loss_zs_kd 0.0202 (0.0160) loss_oracle 0.5331 (0.4774) kd_loss 0.7167 (0.6790) acc 90.6250 (92.3438) gate/entropy 0.9839 (0.9841) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0695 (0.0635) teacher/usage_max 0.7676 (0.8160) teacher/usage_min 0.0358 (0.0522) teacher/usage_std 0.3140 (0.3438) nleep/row_max_mean 1556.0037 (1544.7992) nleep/row_max_std 43.6532 (54.1878) nleep/row_min_mean 1522.5989 (1514.9924) lr 4.1221e-04 eta 0:05:15
epoch [37/50] batch [40/167] time 0.148 (0.147) data 0.000 (0.007) loss 1.2330 (1.2041) teacher_loss 0.3339 (0.2714) loss_zs_kd 0.0306 (0.0174) loss_oracle 0.4523 (0.4727) kd_loss 0.6577 (0.6876) acc 84.3750 (90.1562) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5671 (0.5671) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0613 (0.0620) teacher/usage_max 0.8393 (0.8083) teacher/usage_min 0.0163 (0.0530) teacher/usage_std 0.3616 (0.3386) nleep/row_max_mean 1545.2091 (1544.6179) nleep/row_max_std 61.2162 (54.3254) nleep/row_min_mean 1514.6182 (1514.8323) lr 4.1221e-04 eta 0:05:38
epoch [37/50] batch [60/167] time 0.132 (0.148) data 0.000 (0.005) loss 1.3566 (1.2225) teacher_loss 0.4727 (0.2855) loss_zs_kd 0.0130 (0.0187) loss_oracle 0.4494 (0.4773) kd_loss 0.6527 (0.6890) acc 78.1250 (89.3750) gate/entropy 0.9838 (0.9841) gate/usage_max 0.5674 (0.5672) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1655 (0.1654) teacher/entropy 0.0285 (0.0613) teacher/usage_max 0.8799 (0.8074) teacher/usage_min 0.0012 (0.0509) teacher/usage_std 0.3894 (0.3383) nleep/row_max_mean 1546.1383 (1546.8484) nleep/row_max_std 49.5509 (53.7141) nleep/row_min_mean 1514.4600 (1516.4829) lr 4.1221e-04 eta 0:05:38
epoch [37/50] batch [80/167] time 0.156 (0.150) data 0.000 (0.004) loss 1.2849 (1.2219) teacher_loss 0.2998 (0.2821) loss_zs_kd 0.0297 (0.0191) loss_oracle 0.4946 (0.4739) kd_loss 0.7229 (0.6932) acc 84.3750 (89.2188) gate/entropy 0.9837 (0.9840) gate/usage_max 0.5675 (0.5672) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1656 (0.1654) teacher/entropy 0.0210 (0.0588) teacher/usage_max 0.8123 (0.8055) teacher/usage_min 0.0058 (0.0490) teacher/usage_std 0.3462 (0.3375) nleep/row_max_mean 1557.5657 (1547.7232) nleep/row_max_std 49.5338 (53.5721) nleep/row_min_mean 1522.9670 (1517.2396) lr 4.1221e-04 eta 0:05:38
epoch [37/50] batch [100/167] time 0.123 (0.148) data 0.000 (0.003) loss 1.1991 (1.2243) teacher_loss 0.1586 (0.2785) loss_zs_kd 0.0166 (0.0192) loss_oracle 0.5423 (0.4753) kd_loss 0.7610 (0.6986) acc 96.8750 (89.5312) gate/entropy 0.9836 (0.9840) gate/usage_max 0.5676 (0.5672) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1654) teacher/entropy 0.0415 (0.0585) teacher/usage_max 0.7524 (0.8000) teacher/usage_min 0.0746 (0.0486) teacher/usage_std 0.2990 (0.3341) nleep/row_max_mean 1554.5610 (1547.3672) nleep/row_max_std 45.6470 (53.7374) nleep/row_min_mean 1519.4448 (1516.9022) lr 4.1221e-04 eta 0:05:30
epoch [37/50] batch [120/167] time 0.156 (0.147) data 0.000 (0.002) loss 1.2711 (1.2252) teacher_loss 0.2769 (0.2802) loss_zs_kd 0.0266 (0.0195) loss_oracle 0.5270 (0.4749) kd_loss 0.7173 (0.6978) acc 87.5000 (89.6615) gate/entropy 0.9837 (0.9840) gate/usage_max 0.5676 (0.5672) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1656 (0.1654) teacher/entropy 0.0591 (0.0585) teacher/usage_max 0.7797 (0.8008) teacher/usage_min 0.0769 (0.0474) teacher/usage_std 0.3168 (0.3347) nleep/row_max_mean 1549.2571 (1545.6046) nleep/row_max_std 54.6608 (54.0936) nleep/row_min_mean 1517.4692 (1515.3398) lr 4.1221e-04 eta 0:05:27
epoch [37/50] batch [140/167] time 0.136 (0.147) data 0.000 (0.002) loss 1.4888 (1.2335) teacher_loss 0.6206 (0.2843) loss_zs_kd 0.0148 (0.0199) loss_oracle 0.4497 (0.4765) kd_loss 0.6360 (0.7011) acc 81.2500 (89.4643) gate/entropy 0.9836 (0.9840) gate/usage_max 0.5676 (0.5672) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1654) teacher/entropy 0.0450 (0.0580) teacher/usage_max 0.8785 (0.7977) teacher/usage_min 0.0126 (0.0467) teacher/usage_std 0.3875 (0.3328) nleep/row_max_mean 1545.1328 (1545.6192) nleep/row_max_std 62.7550 (54.0658) nleep/row_min_mean 1513.3665 (1515.2009) lr 4.1221e-04 eta 0:05:23
epoch [37/50] batch [160/167] time 0.158 (0.147) data 0.000 (0.002) loss 1.1387 (1.2373) teacher_loss 0.1511 (0.2863) loss_zs_kd 0.0087 (0.0200) loss_oracle 0.4757 (0.4776) kd_loss 0.7454 (0.7023) acc 93.7500 (89.3359) gate/entropy 0.9841 (0.9840) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0784 (0.0577) teacher/usage_max 0.7294 (0.7968) teacher/usage_min 0.0544 (0.0453) teacher/usage_std 0.2877 (0.3326) nleep/row_max_mean 1541.9524 (1544.3424) nleep/row_max_std 59.5152 (54.6057) nleep/row_min_mean 1513.1741 (1514.0202) lr 4.1221e-04 eta 0:05:19
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,213
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,317
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [38/50] batch [20/167] time 0.095 (0.137) data 0.000 (0.017) loss 1.1866 (1.2021) teacher_loss 0.2755 (0.2489) loss_zs_kd 0.0079 (0.0150) loss_oracle 0.5265 (0.4841) kd_loss 0.6439 (0.7036) acc 93.7500 (91.5625) gate/entropy 0.9836 (0.9839) gate/usage_max 0.5676 (0.5674) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1655) teacher/entropy 0.0227 (0.0492) teacher/usage_max 0.8948 (0.8035) teacher/usage_min 0.0315 (0.0269) teacher/usage_std 0.3974 (0.3393) nleep/row_max_mean 1542.4513 (1538.7717) nleep/row_max_std 58.8369 (57.9166) nleep/row_min_mean 1508.8071 (1508.3771) lr 3.6258e-04 eta 0:04:53
epoch [38/50] batch [40/167] time 0.108 (0.124) data 0.000 (0.009) loss 1.3403 (1.2278) teacher_loss 0.3446 (0.2592) loss_zs_kd 0.0149 (0.0178) loss_oracle 0.5088 (0.4805) kd_loss 0.7339 (0.7194) acc 90.6250 (90.0781) gate/entropy 0.9839 (0.9839) gate/usage_max 0.5673 (0.5673) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1655 (0.1655) teacher/entropy 0.0726 (0.0537) teacher/usage_max 0.7457 (0.7820) teacher/usage_min 0.0001 (0.0279) teacher/usage_std 0.3095 (0.3278) nleep/row_max_mean 1537.6575 (1539.2600) nleep/row_max_std 57.4671 (56.6307) nleep/row_min_mean 1508.2019 (1508.9451) lr 3.6258e-04 eta 0:04:24
epoch [38/50] batch [60/167] time 0.088 (0.120) data 0.001 (0.006) loss 1.2385 (1.2318) teacher_loss 0.3196 (0.2776) loss_zs_kd 0.0225 (0.0184) loss_oracle 0.4488 (0.4797) kd_loss 0.6833 (0.7051) acc 90.6250 (89.8438) gate/entropy 0.9836 (0.9838) gate/usage_max 0.5676 (0.5674) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1656) teacher/entropy 0.0655 (0.0572) teacher/usage_max 0.8082 (0.7935) teacher/usage_min 0.0459 (0.0281) teacher/usage_std 0.3383 (0.3340) nleep/row_max_mean 1540.4216 (1541.4147) nleep/row_max_std 53.6216 (55.8244) nleep/row_min_mean 1511.8582 (1510.8983) lr 3.6258e-04 eta 0:04:14
epoch [38/50] batch [80/167] time 0.069 (0.117) data 0.000 (0.004) loss 1.2198 (1.2512) teacher_loss 0.2363 (0.2871) loss_zs_kd 0.0187 (0.0197) loss_oracle 0.4634 (0.4765) kd_loss 0.7425 (0.7160) acc 87.5000 (89.5312) gate/entropy 0.9834 (0.9838) gate/usage_max 0.5679 (0.5674) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1658 (0.1655) teacher/entropy 0.0771 (0.0563) teacher/usage_max 0.7326 (0.7828) teacher/usage_min 0.0091 (0.0266) teacher/usage_std 0.3001 (0.3277) nleep/row_max_mean 1547.2175 (1540.2712) nleep/row_max_std 54.7760 (55.6046) nleep/row_min_mean 1520.5227 (1510.0235) lr 3.6258e-04 eta 0:04:05
epoch [38/50] batch [100/167] time 0.091 (0.116) data 0.000 (0.004) loss 1.2195 (1.2535) teacher_loss 0.2759 (0.2854) loss_zs_kd 0.0128 (0.0192) loss_oracle 0.4328 (0.4739) kd_loss 0.7208 (0.7215) acc 93.7500 (89.4062) gate/entropy 0.9841 (0.9838) gate/usage_max 0.5672 (0.5674) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.0583 (0.0561) teacher/usage_max 0.7757 (0.7772) teacher/usage_min 0.0226 (0.0265) teacher/usage_std 0.3213 (0.3241) nleep/row_max_mean 1545.7051 (1540.3699) nleep/row_max_std 50.5196 (55.3237) nleep/row_min_mean 1513.3113 (1510.0731) lr 3.6258e-04 eta 0:04:00
epoch [38/50] batch [120/167] time 0.097 (0.117) data 0.000 (0.003) loss 1.0599 (1.2516) teacher_loss 0.1302 (0.2822) loss_zs_kd 0.0143 (0.0190) loss_oracle 0.4106 (0.4721) kd_loss 0.7173 (0.7239) acc 100.0000 (89.4792) gate/entropy 0.9836 (0.9838) gate/usage_max 0.5677 (0.5674) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1655) teacher/entropy 0.0369 (0.0567) teacher/usage_max 0.8011 (0.7740) teacher/usage_min 0.0003 (0.0276) teacher/usage_std 0.3405 (0.3221) nleep/row_max_mean 1541.8835 (1540.2983) nleep/row_max_std 48.2033 (54.6758) nleep/row_min_mean 1513.2065 (1510.0950) lr 3.6258e-04 eta 0:03:59
epoch [38/50] batch [140/167] time 0.157 (0.120) data 0.000 (0.003) loss 1.1124 (1.2516) teacher_loss 0.1437 (0.2811) loss_zs_kd 0.0330 (0.0188) loss_oracle 0.5326 (0.4735) kd_loss 0.6859 (0.7243) acc 96.8750 (89.5312) gate/entropy 0.9834 (0.9838) gate/usage_max 0.5679 (0.5674) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1659 (0.1656) teacher/entropy 0.0912 (0.0571) teacher/usage_max 0.7804 (0.7731) teacher/usage_min 0.0895 (0.0270) teacher/usage_std 0.3165 (0.3217) nleep/row_max_mean 1545.5271 (1540.2833) nleep/row_max_std 39.5570 (53.7463) nleep/row_min_mean 1517.8364 (1510.1645) lr 3.6258e-04 eta 0:04:03
epoch [38/50] batch [160/167] time 0.192 (0.127) data 0.000 (0.002) loss 1.4900 (1.2488) teacher_loss 0.5904 (0.2801) loss_zs_kd 0.0161 (0.0192) loss_oracle 0.4627 (0.4754) kd_loss 0.6601 (0.7213) acc 78.1250 (89.6094) gate/entropy 0.9838 (0.9838) gate/usage_max 0.5674 (0.5675) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0792 (0.0577) teacher/usage_max 0.8169 (0.7756) teacher/usage_min 0.0095 (0.0268) teacher/usage_std 0.3484 (0.3231) nleep/row_max_mean 1518.1019 (1539.7746) nleep/row_max_std 55.6584 (53.3447) nleep/row_min_mean 1494.4532 (1509.7525) lr 3.6258e-04 eta 0:04:14
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,219
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,315
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.7%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [39/50] batch [20/167] time 0.154 (0.175) data 0.000 (0.018) loss 1.3596 (1.2333) teacher_loss 0.4665 (0.2726) loss_zs_kd 0.0306 (0.0226) loss_oracle 0.4363 (0.4648) kd_loss 0.6597 (0.7170) acc 81.2500 (88.9062) gate/entropy 0.9837 (0.9837) gate/usage_max 0.5676 (0.5675) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1656) teacher/entropy 0.0493 (0.0558) teacher/usage_max 0.8490 (0.7821) teacher/usage_min 0.0000 (0.0254) teacher/usage_std 0.3698 (0.3283) nleep/row_max_mean 1527.9449 (1528.8337) nleep/row_max_std 59.1872 (55.2926) nleep/row_min_mean 1500.0243 (1500.1407) lr 3.1545e-04 eta 0:05:47
epoch [39/50] batch [40/167] time 0.161 (0.161) data 0.000 (0.009) loss 1.1934 (1.2457) teacher_loss 0.1981 (0.2777) loss_zs_kd 0.0158 (0.0219) loss_oracle 0.5266 (0.4725) kd_loss 0.7242 (0.7208) acc 96.8750 (89.2188) gate/entropy 0.9835 (0.9837) gate/usage_max 0.5678 (0.5676) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1658 (0.1657) teacher/entropy 0.0779 (0.0530) teacher/usage_max 0.7508 (0.7810) teacher/usage_min 0.0061 (0.0216) teacher/usage_std 0.3107 (0.3274) nleep/row_max_mean 1538.4109 (1533.8894) nleep/row_max_std 55.5365 (54.5783) nleep/row_min_mean 1510.6804 (1504.4708) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [60/167] time 0.153 (0.158) data 0.000 (0.006) loss 1.1026 (1.2557) teacher_loss 0.1245 (0.2829) loss_zs_kd 0.0085 (0.0220) loss_oracle 0.5094 (0.4751) kd_loss 0.7192 (0.7242) acc 93.7500 (88.7500) gate/entropy 0.9836 (0.9837) gate/usage_max 0.5676 (0.5676) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0252 (0.0531) teacher/usage_max 0.8129 (0.7772) teacher/usage_min 0.0586 (0.0223) teacher/usage_std 0.3403 (0.3252) nleep/row_max_mean 1545.6824 (1534.9551) nleep/row_max_std 46.0716 (54.3585) nleep/row_min_mean 1516.5211 (1505.3302) lr 3.1545e-04 eta 0:05:06
epoch [39/50] batch [80/167] time 0.157 (0.156) data 0.000 (0.005) loss 1.0948 (1.2574) teacher_loss 0.1861 (0.2793) loss_zs_kd 0.0086 (0.0215) loss_oracle 0.4423 (0.4767) kd_loss 0.6833 (0.7290) acc 93.7500 (89.0625) gate/entropy 0.9835 (0.9837) gate/usage_max 0.5677 (0.5676) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1658 (0.1657) teacher/entropy 0.0323 (0.0540) teacher/usage_max 0.8436 (0.7713) teacher/usage_min 0.0291 (0.0245) teacher/usage_std 0.3631 (0.3210) nleep/row_max_mean 1549.4590 (1536.1758) nleep/row_max_std 40.0105 (53.8670) nleep/row_min_mean 1517.5629 (1506.6086) lr 3.1545e-04 eta 0:04:59
epoch [39/50] batch [100/167] time 0.141 (0.146) data 0.000 (0.004) loss 1.0941 (1.2513) teacher_loss 0.2125 (0.2750) loss_zs_kd 0.0156 (0.0218) loss_oracle 0.4225 (0.4772) kd_loss 0.6626 (0.7269) acc 90.6250 (89.3438) gate/entropy 0.9836 (0.9836) gate/usage_max 0.5677 (0.5676) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0823 (0.0570) teacher/usage_max 0.8117 (0.7706) teacher/usage_min 0.0056 (0.0284) teacher/usage_std 0.3459 (0.3196) nleep/row_max_mean 1528.9783 (1537.0855) nleep/row_max_std 57.5368 (54.4675) nleep/row_min_mean 1505.5276 (1507.5761) lr 3.1545e-04 eta 0:04:38
epoch [39/50] batch [120/167] time 0.184 (0.141) data 0.000 (0.003) loss 1.3072 (1.2553) teacher_loss 0.2489 (0.2778) loss_zs_kd 0.0263 (0.0213) loss_oracle 0.4961 (0.4770) kd_loss 0.7971 (0.7283) acc 87.5000 (89.1667) gate/entropy 0.9840 (0.9836) gate/usage_max 0.5673 (0.5676) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1654 (0.1657) teacher/entropy 0.0428 (0.0562) teacher/usage_max 0.7126 (0.7700) teacher/usage_min 0.0664 (0.0307) teacher/usage_std 0.2755 (0.3187) nleep/row_max_mean 1528.0283 (1537.0984) nleep/row_max_std 53.0211 (54.7000) nleep/row_min_mean 1500.5134 (1507.6290) lr 3.1545e-04 eta 0:04:25
epoch [39/50] batch [140/167] time 0.157 (0.139) data 0.000 (0.003) loss 1.4167 (1.2512) teacher_loss 0.2602 (0.2751) loss_zs_kd 0.0199 (0.0208) loss_oracle 0.5123 (0.4765) kd_loss 0.8904 (0.7274) acc 90.6250 (89.2188) gate/entropy 0.9841 (0.9836) gate/usage_max 0.5672 (0.5676) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1654 (0.1657) teacher/entropy 0.0497 (0.0583) teacher/usage_max 0.6046 (0.7687) teacher/usage_min 0.0014 (0.0313) teacher/usage_std 0.2500 (0.3179) nleep/row_max_mean 1523.2686 (1536.5139) nleep/row_max_std 53.0459 (54.2792) nleep/row_min_mean 1496.6738 (1507.2989) lr 3.1545e-04 eta 0:04:19
epoch [39/50] batch [160/167] time 0.076 (0.136) data 0.000 (0.002) loss 1.0780 (1.2539) teacher_loss 0.1437 (0.2793) loss_zs_kd 0.0104 (0.0210) loss_oracle 0.4747 (0.4794) kd_loss 0.6917 (0.7244) acc 93.7500 (89.0820) gate/entropy 0.9831 (0.9836) gate/usage_max 0.5682 (0.5676) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1661 (0.1657) teacher/entropy 0.0666 (0.0607) teacher/usage_max 0.7975 (0.7694) teacher/usage_min 0.0235 (0.0335) teacher/usage_std 0.3343 (0.3178) nleep/row_max_mean 1549.6084 (1536.1390) nleep/row_max_std 43.5464 (53.7318) nleep/row_min_mean 1522.6930 (1507.1065) lr 3.1545e-04 eta 0:04:11
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,221
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,316
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.8%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [40/50] batch [20/167] time 0.085 (0.136) data 0.000 (0.020) loss 1.1402 (1.2448) teacher_loss 0.1693 (0.2658) loss_zs_kd 0.0342 (0.0215) loss_oracle 0.4647 (0.4895) kd_loss 0.7214 (0.7235) acc 93.7500 (88.5938) gate/entropy 0.9837 (0.9835) gate/usage_max 0.5675 (0.5677) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1656 (0.1658) teacher/entropy 0.0597 (0.0648) teacher/usage_max 0.7764 (0.7669) teacher/usage_min 0.0637 (0.0559) teacher/usage_std 0.3157 (0.3119) nleep/row_max_mean 1516.9110 (1532.2662) nleep/row_max_std 57.3724 (54.2067) nleep/row_min_mean 1492.1946 (1504.7879) lr 2.7103e-04 eta 0:04:07
epoch [40/50] batch [40/167] time 0.167 (0.133) data 0.000 (0.010) loss 1.1465 (1.2270) teacher_loss 0.0817 (0.2638) loss_zs_kd 0.0146 (0.0207) loss_oracle 0.5009 (0.4889) kd_loss 0.8071 (0.7084) acc 96.8750 (89.7656) gate/entropy 0.9840 (0.9835) gate/usage_max 0.5672 (0.5677) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1654 (0.1658) teacher/entropy 0.0925 (0.0715) teacher/usage_max 0.6504 (0.7757) teacher/usage_min 0.0938 (0.0564) teacher/usage_std 0.2337 (0.3179) nleep/row_max_mean 1497.2906 (1530.8119) nleep/row_max_std 54.6577 (55.2401) nleep/row_min_mean 1480.6567 (1503.6863) lr 2.7103e-04 eta 0:03:59
epoch [40/50] batch [60/167] time 0.156 (0.143) data 0.001 (0.007) loss 1.2995 (1.2068) teacher_loss 0.4021 (0.2488) loss_zs_kd 0.0204 (0.0193) loss_oracle 0.4835 (0.4838) kd_loss 0.6454 (0.7065) acc 78.1250 (90.3125) gate/entropy 0.9832 (0.9835) gate/usage_max 0.5681 (0.5677) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1660 (0.1658) teacher/entropy 0.0820 (0.0743) teacher/usage_max 0.8297 (0.7747) teacher/usage_min 0.0552 (0.0571) teacher/usage_std 0.3518 (0.3170) nleep/row_max_mean 1545.7081 (1532.6934) nleep/row_max_std 38.5307 (55.3363) nleep/row_min_mean 1516.8546 (1505.2384) lr 2.7103e-04 eta 0:04:13
epoch [40/50] batch [80/167] time 0.154 (0.144) data 0.000 (0.005) loss 1.1035 (1.2135) teacher_loss 0.1542 (0.2552) loss_zs_kd 0.0114 (0.0188) loss_oracle 0.4793 (0.4800) kd_loss 0.7040 (0.7089) acc 93.7500 (89.9609) gate/entropy 0.9838 (0.9835) gate/usage_max 0.5674 (0.5677) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1655 (0.1658) teacher/entropy 0.0826 (0.0754) teacher/usage_max 0.7697 (0.7711) teacher/usage_min 0.0982 (0.0576) teacher/usage_std 0.3088 (0.3147) nleep/row_max_mean 1525.5055 (1532.9839) nleep/row_max_std 61.9910 (56.0528) nleep/row_min_mean 1496.4105 (1505.4047) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [100/167] time 0.171 (0.146) data 0.000 (0.004) loss 1.1417 (1.2213) teacher_loss 0.1377 (0.2612) loss_zs_kd 0.0170 (0.0195) loss_oracle 0.4411 (0.4785) kd_loss 0.7749 (0.7111) acc 93.7500 (89.9375) gate/entropy 0.9838 (0.9835) gate/usage_max 0.5674 (0.5677) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1656 (0.1658) teacher/entropy 0.0370 (0.0755) teacher/usage_max 0.7428 (0.7686) teacher/usage_min 0.0314 (0.0569) teacher/usage_std 0.3002 (0.3133) nleep/row_max_mean 1529.9266 (1533.6006) nleep/row_max_std 58.8461 (55.7085) nleep/row_min_mean 1501.9052 (1505.9229) lr 2.7103e-04 eta 0:04:14
epoch [40/50] batch [120/167] time 0.160 (0.149) data 0.000 (0.004) loss 1.2372 (1.2373) teacher_loss 0.2893 (0.2722) loss_zs_kd 0.0215 (0.0197) loss_oracle 0.4803 (0.4821) kd_loss 0.6969 (0.7142) acc 93.7500 (89.6094) gate/entropy 0.9834 (0.9835) gate/usage_max 0.5678 (0.5677) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1658 (0.1658) teacher/entropy 0.0971 (0.0757) teacher/usage_max 0.7622 (0.7653) teacher/usage_min 0.1021 (0.0625) teacher/usage_std 0.3036 (0.3104) nleep/row_max_mean 1534.4146 (1534.5223) nleep/row_max_std 59.8046 (55.6910) nleep/row_min_mean 1507.5760 (1506.7784) lr 2.7103e-04 eta 0:04:16
epoch [40/50] batch [140/167] time 0.145 (0.151) data 0.000 (0.003) loss 0.9581 (1.2375) teacher_loss 0.1506 (0.2720) loss_zs_kd 0.0166 (0.0197) loss_oracle 0.4191 (0.4822) kd_loss 0.5897 (0.7145) acc 93.7500 (89.6205) gate/entropy 0.9833 (0.9835) gate/usage_max 0.5679 (0.5677) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0751 (0.0757) teacher/usage_max 0.8973 (0.7650) teacher/usage_min 0.0450 (0.0637) teacher/usage_std 0.3988 (0.3100) nleep/row_max_mean 1548.4629 (1534.9283) nleep/row_max_std 51.0982 (55.6351) nleep/row_min_mean 1520.7629 (1507.1320) lr 2.7103e-04 eta 0:04:16
epoch [40/50] batch [160/167] time 0.148 (0.150) data 0.000 (0.003) loss 1.4606 (1.2403) teacher_loss 0.5423 (0.2744) loss_zs_kd 0.0145 (0.0194) loss_oracle 0.4491 (0.4822) kd_loss 0.6865 (0.7152) acc 78.1250 (89.6094) gate/entropy 0.9834 (0.9835) gate/usage_max 0.5678 (0.5678) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1658 (0.1658) teacher/entropy 0.0493 (0.0744) teacher/usage_max 0.8232 (0.7658) teacher/usage_min 0.0829 (0.0657) teacher/usage_std 0.3464 (0.3103) nleep/row_max_mean 1537.3716 (1536.0689) nleep/row_max_std 60.1607 (55.4185) nleep/row_min_mean 1510.2792 (1508.0922) lr 2.7103e-04 eta 0:04:11
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,218
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [41/50] batch [20/167] time 0.085 (0.121) data 0.000 (0.017) loss 1.4351 (1.2837) teacher_loss 0.2072 (0.2756) loss_zs_kd 0.0102 (0.0208) loss_oracle 0.5790 (0.4824) kd_loss 0.9332 (0.7565) acc 90.6250 (89.8438) gate/entropy 0.9839 (0.9834) gate/usage_max 0.5674 (0.5678) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1655 (0.1658) teacher/entropy 0.1042 (0.0740) teacher/usage_max 0.5088 (0.7235) teacher/usage_min 0.1985 (0.0868) teacher/usage_std 0.1299 (0.2813) nleep/row_max_mean 1525.2729 (1541.8908) nleep/row_max_std 63.0124 (56.8797) nleep/row_min_mean 1496.8853 (1511.8709) lr 2.2949e-04 eta 0:03:20
epoch [41/50] batch [40/167] time 0.188 (0.128) data 0.000 (0.008) loss 1.0178 (1.2389) teacher_loss 0.1826 (0.2639) loss_zs_kd 0.0218 (0.0192) loss_oracle 0.4602 (0.4823) kd_loss 0.5942 (0.7241) acc 90.6250 (89.9219) gate/entropy 0.9833 (0.9835) gate/usage_max 0.5680 (0.5678) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0454 (0.0695) teacher/usage_max 0.9225 (0.7620) teacher/usage_min 0.0316 (0.0724) teacher/usage_std 0.4167 (0.3073) nleep/row_max_mean 1543.6398 (1539.5759) nleep/row_max_std 61.6099 (59.4353) nleep/row_min_mean 1512.3984 (1509.8376) lr 2.2949e-04 eta 0:03:28
epoch [41/50] batch [60/167] time 0.070 (0.125) data 0.000 (0.006) loss 1.3759 (1.2361) teacher_loss 0.3309 (0.2700) loss_zs_kd 0.0229 (0.0201) loss_oracle 0.4814 (0.4833) kd_loss 0.7928 (0.7144) acc 87.5000 (90.3125) gate/entropy 0.9834 (0.9834) gate/usage_max 0.5679 (0.5678) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.1030 (0.0703) teacher/usage_max 0.6552 (0.7713) teacher/usage_min 0.0999 (0.0682) teacher/usage_std 0.2352 (0.3136) nleep/row_max_mean 1529.8264 (1539.6193) nleep/row_max_std 58.5720 (57.9193) nleep/row_min_mean 1506.6237 (1510.2210) lr 2.2949e-04 eta 0:03:21
epoch [41/50] batch [80/167] time 0.102 (0.120) data 0.000 (0.004) loss 1.1333 (1.2322) teacher_loss 0.2400 (0.2700) loss_zs_kd 0.0387 (0.0208) loss_oracle 0.4678 (0.4853) kd_loss 0.6400 (0.7091) acc 90.6250 (90.2344) gate/entropy 0.9831 (0.9834) gate/usage_max 0.5682 (0.5678) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1661 (0.1658) teacher/entropy 0.0643 (0.0760) teacher/usage_max 0.8539 (0.7710) teacher/usage_min 0.0402 (0.0728) teacher/usage_std 0.3690 (0.3128) nleep/row_max_mean 1546.2382 (1539.4188) nleep/row_max_std 53.8868 (58.0638) nleep/row_min_mean 1518.8807 (1510.0078) lr 2.2949e-04 eta 0:03:11
epoch [41/50] batch [100/167] time 0.144 (0.120) data 0.000 (0.003) loss 1.2648 (1.2393) teacher_loss 0.2059 (0.2729) loss_zs_kd 0.0374 (0.0203) loss_oracle 0.4922 (0.4863) kd_loss 0.7941 (0.7131) acc 90.6250 (90.0312) gate/entropy 0.9833 (0.9834) gate/usage_max 0.5680 (0.5679) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0783 (0.0771) teacher/usage_max 0.6789 (0.7659) teacher/usage_min 0.0976 (0.0760) teacher/usage_std 0.2497 (0.3090) nleep/row_max_mean 1542.0474 (1539.7132) nleep/row_max_std 46.4406 (57.1296) nleep/row_min_mean 1514.4493 (1510.5794) lr 2.2949e-04 eta 0:03:07
epoch [41/50] batch [120/167] time 0.198 (0.122) data 0.000 (0.003) loss 1.2519 (1.2419) teacher_loss 0.2560 (0.2732) loss_zs_kd 0.0132 (0.0204) loss_oracle 0.4818 (0.4867) kd_loss 0.7484 (0.7152) acc 93.7500 (90.0781) gate/entropy 0.9833 (0.9834) gate/usage_max 0.5679 (0.5679) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1659 (0.1659) teacher/entropy 0.0308 (0.0759) teacher/usage_max 0.7791 (0.7650) teacher/usage_min 0.0908 (0.0792) teacher/usage_std 0.3156 (0.3080) nleep/row_max_mean 1539.3970 (1539.8934) nleep/row_max_std 54.7910 (57.1564) nleep/row_min_mean 1506.0698 (1510.8461) lr 2.2949e-04 eta 0:03:08
epoch [41/50] batch [140/167] time 0.144 (0.119) data 0.000 (0.003) loss 1.3624 (1.2412) teacher_loss 0.2731 (0.2729) loss_zs_kd 0.0316 (0.0203) loss_oracle 0.5108 (0.4859) kd_loss 0.8181 (0.7152) acc 87.5000 (90.0893) gate/entropy 0.9835 (0.9834) gate/usage_max 0.5677 (0.5679) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.1202 (0.0763) teacher/usage_max 0.6110 (0.7645) teacher/usage_min 0.1426 (0.0785) teacher/usage_std 0.2009 (0.3078) nleep/row_max_mean 1531.2883 (1539.5426) nleep/row_max_std 35.7117 (56.6444) nleep/row_min_mean 1506.8538 (1510.7082) lr 2.2949e-04 eta 0:03:02
epoch [41/50] batch [160/167] time 0.132 (0.123) data 0.000 (0.002) loss 1.1807 (1.2469) teacher_loss 0.2741 (0.2767) loss_zs_kd 0.0218 (0.0202) loss_oracle 0.4824 (0.4857) kd_loss 0.6545 (0.7173) acc 87.5000 (89.7852) gate/entropy 0.9832 (0.9834) gate/usage_max 0.5680 (0.5679) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.1107 (0.0754) teacher/usage_max 0.7927 (0.7633) teacher/usage_min 0.0897 (0.0797) teacher/usage_std 0.3250 (0.3068) nleep/row_max_mean 1523.3838 (1539.3729) nleep/row_max_std 64.0564 (56.2910) nleep/row_min_mean 1502.4807 (1510.5954) lr 2.2949e-04 eta 0:03:05
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,214
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [42/50] batch [20/167] time 0.158 (0.180) data 0.000 (0.016) loss 1.1451 (1.2568) teacher_loss 0.1260 (0.2875) loss_zs_kd 0.0136 (0.0193) loss_oracle 0.4504 (0.4756) kd_loss 0.7871 (0.7218) acc 96.8750 (90.9375) gate/entropy 0.9837 (0.9834) gate/usage_max 0.5675 (0.5679) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1656 (0.1659) teacher/entropy 0.0836 (0.0823) teacher/usage_max 0.6845 (0.7520) teacher/usage_min 0.1111 (0.0889) teacher/usage_std 0.2512 (0.2984) nleep/row_max_mean 1524.1508 (1531.2717) nleep/row_max_std 48.7911 (56.6618) nleep/row_min_mean 1494.6373 (1503.8739) lr 1.9098e-04 eta 0:04:26
epoch [42/50] batch [40/167] time 0.148 (0.164) data 0.000 (0.008) loss 1.4713 (1.2447) teacher_loss 0.4009 (0.2924) loss_zs_kd 0.0242 (0.0199) loss_oracle 0.5171 (0.4783) kd_loss 0.7998 (0.7032) acc 81.2500 (89.8438) gate/entropy 0.9835 (0.9834) gate/usage_max 0.5677 (0.5679) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0567 (0.0816) teacher/usage_max 0.6988 (0.7719) teacher/usage_min 0.1154 (0.0786) teacher/usage_std 0.2600 (0.3122) nleep/row_max_mean 1523.2079 (1533.0750) nleep/row_max_std 53.3769 (55.2685) nleep/row_min_mean 1496.7393 (1505.4367) lr 1.9098e-04 eta 0:03:59
epoch [42/50] batch [60/167] time 0.154 (0.161) data 0.000 (0.005) loss 1.3156 (1.2502) teacher_loss 0.2561 (0.2812) loss_zs_kd 0.0206 (0.0205) loss_oracle 0.5095 (0.4829) kd_loss 0.7944 (0.7173) acc 90.6250 (89.7396) gate/entropy 0.9833 (0.9833) gate/usage_max 0.5680 (0.5679) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0685 (0.0796) teacher/usage_max 0.6891 (0.7596) teacher/usage_min 0.1099 (0.0845) teacher/usage_std 0.2543 (0.3035) nleep/row_max_mean 1535.8523 (1535.0880) nleep/row_max_std 48.3803 (54.4878) nleep/row_min_mean 1511.2288 (1507.2993) lr 1.9098e-04 eta 0:03:52
epoch [42/50] batch [80/167] time 0.197 (0.163) data 0.001 (0.004) loss 1.2529 (1.2493) teacher_loss 0.2842 (0.2778) loss_zs_kd 0.0228 (0.0202) loss_oracle 0.4916 (0.4836) kd_loss 0.7115 (0.7196) acc 90.6250 (89.8828) gate/entropy 0.9831 (0.9833) gate/usage_max 0.5681 (0.5680) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0595 (0.0796) teacher/usage_max 0.7847 (0.7571) teacher/usage_min 0.0762 (0.0899) teacher/usage_std 0.3202 (0.3014) nleep/row_max_mean 1549.1005 (1536.0384) nleep/row_max_std 54.3243 (54.1617) nleep/row_min_mean 1517.3463 (1508.2301) lr 1.9098e-04 eta 0:03:51
epoch [42/50] batch [100/167] time 0.080 (0.158) data 0.000 (0.003) loss 1.2550 (1.2552) teacher_loss 0.3362 (0.2831) loss_zs_kd 0.0245 (0.0205) loss_oracle 0.4722 (0.4845) kd_loss 0.6705 (0.7196) acc 81.2500 (89.6562) gate/entropy 0.9831 (0.9833) gate/usage_max 0.5682 (0.5680) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1659) teacher/entropy 0.0881 (0.0779) teacher/usage_max 0.7980 (0.7588) teacher/usage_min 0.0602 (0.0886) teacher/usage_std 0.3302 (0.3027) nleep/row_max_mean 1545.5874 (1537.5729) nleep/row_max_std 44.5997 (54.2019) nleep/row_min_mean 1514.0381 (1509.5763) lr 1.9098e-04 eta 0:03:41
epoch [42/50] batch [120/167] time 0.178 (0.146) data 0.000 (0.003) loss 1.4702 (1.2633) teacher_loss 0.4859 (0.2890) loss_zs_kd 0.0406 (0.0210) loss_oracle 0.5082 (0.4850) kd_loss 0.7098 (0.7213) acc 81.2500 (89.4271) gate/entropy 0.9826 (0.9832) gate/usage_max 0.5687 (0.5680) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1665 (0.1660) teacher/entropy 0.0768 (0.0778) teacher/usage_max 0.7691 (0.7570) teacher/usage_min 0.1036 (0.0906) teacher/usage_std 0.3083 (0.3013) nleep/row_max_mean 1554.7529 (1538.3157) nleep/row_max_std 54.2876 (54.0798) nleep/row_min_mean 1523.3237 (1510.0494) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [140/167] time 0.114 (0.142) data 0.000 (0.002) loss 1.1082 (1.2665) teacher_loss 0.2573 (0.2959) loss_zs_kd 0.0230 (0.0208) loss_oracle 0.4301 (0.4849) kd_loss 0.6244 (0.7178) acc 90.6250 (89.0848) gate/entropy 0.9832 (0.9832) gate/usage_max 0.5681 (0.5680) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.1139 (0.0794) teacher/usage_max 0.8206 (0.7591) teacher/usage_min 0.0780 (0.0906) teacher/usage_std 0.3447 (0.3027) nleep/row_max_mean 1532.6416 (1537.7843) nleep/row_max_std 58.9554 (54.9378) nleep/row_min_mean 1509.1289 (1509.6087) lr 1.9098e-04 eta 0:03:13
epoch [42/50] batch [160/167] time 0.164 (0.140) data 0.000 (0.002) loss 1.2943 (1.2659) teacher_loss 0.3863 (0.2953) loss_zs_kd 0.0237 (0.0208) loss_oracle 0.4262 (0.4837) kd_loss 0.6830 (0.7184) acc 84.3750 (89.0625) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5681 (0.5680) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.0887 (0.0803) teacher/usage_max 0.7846 (0.7576) teacher/usage_min 0.0633 (0.0909) teacher/usage_std 0.3211 (0.3017) nleep/row_max_mean 1539.1145 (1537.9033) nleep/row_max_std 41.8212 (54.9712) nleep/row_min_mean 1514.4429 (1509.8234) lr 1.9098e-04 eta 0:03:07
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,214
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [43/50] batch [20/167] time 0.151 (0.131) data 0.000 (0.016) loss 1.2590 (1.2377) teacher_loss 0.2799 (0.2742) loss_zs_kd 0.0349 (0.0172) loss_oracle 0.4562 (0.4766) kd_loss 0.7335 (0.7166) acc 87.5000 (88.1250) gate/entropy 0.9837 (0.9832) gate/usage_max 0.5675 (0.5681) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1656 (0.1660) teacher/entropy 0.1164 (0.0782) teacher/usage_max 0.7037 (0.7612) teacher/usage_min 0.1388 (0.0900) teacher/usage_std 0.2620 (0.3040) nleep/row_max_mean 1522.6343 (1540.8570) nleep/row_max_std 65.5967 (58.6548) nleep/row_min_mean 1492.8843 (1511.8708) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [40/167] time 0.136 (0.122) data 0.000 (0.008) loss 1.2774 (1.2385) teacher_loss 0.2027 (0.2666) loss_zs_kd 0.0071 (0.0181) loss_oracle 0.4875 (0.4753) kd_loss 0.8274 (0.7251) acc 93.7500 (88.9062) gate/entropy 0.9835 (0.9832) gate/usage_max 0.5677 (0.5681) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1658 (0.1660) teacher/entropy 0.0912 (0.0752) teacher/usage_max 0.6331 (0.7554) teacher/usage_min 0.1707 (0.0907) teacher/usage_std 0.2122 (0.3005) nleep/row_max_mean 1526.6699 (1539.0996) nleep/row_max_std 58.2516 (59.5765) nleep/row_min_mean 1501.1472 (1510.3480) lr 1.5567e-04 eta 0:02:38
epoch [43/50] batch [60/167] time 0.152 (0.136) data 0.000 (0.006) loss 1.2710 (1.2504) teacher_loss 0.2680 (0.2682) loss_zs_kd 0.0068 (0.0186) loss_oracle 0.5055 (0.4843) kd_loss 0.7469 (0.7307) acc 90.6250 (89.4271) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5682 (0.5681) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0302 (0.0720) teacher/usage_max 0.7796 (0.7530) teacher/usage_min 0.1078 (0.0927) teacher/usage_std 0.3156 (0.2986) nleep/row_max_mean 1550.0364 (1540.6690) nleep/row_max_std 49.1712 (57.9762) nleep/row_min_mean 1523.0414 (1511.4843) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [80/167] time 0.168 (0.141) data 0.000 (0.004) loss 1.3151 (1.2591) teacher_loss 0.2761 (0.2771) loss_zs_kd 0.0205 (0.0191) loss_oracle 0.4425 (0.4838) kd_loss 0.8075 (0.7306) acc 90.6250 (89.2578) gate/entropy 0.9833 (0.9832) gate/usage_max 0.5679 (0.5681) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.1109 (0.0756) teacher/usage_max 0.6330 (0.7492) teacher/usage_min 0.1656 (0.0955) teacher/usage_std 0.2124 (0.2959) nleep/row_max_mean 1531.3446 (1540.0162) nleep/row_max_std 54.5504 (58.0425) nleep/row_min_mean 1504.4617 (1511.0685) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [100/167] time 0.152 (0.144) data 0.000 (0.003) loss 1.1971 (1.2546) teacher_loss 0.1898 (0.2738) loss_zs_kd 0.0097 (0.0196) loss_oracle 0.4241 (0.4831) kd_loss 0.7904 (0.7295) acc 96.8750 (89.4062) gate/entropy 0.9838 (0.9832) gate/usage_max 0.5674 (0.5681) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1655 (0.1660) teacher/entropy 0.0710 (0.0767) teacher/usage_max 0.6927 (0.7493) teacher/usage_min 0.1536 (0.0967) teacher/usage_std 0.2541 (0.2958) nleep/row_max_mean 1509.5280 (1539.3891) nleep/row_max_std 62.9870 (57.0359) nleep/row_min_mean 1479.8478 (1510.3643) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [120/167] time 0.153 (0.143) data 0.000 (0.003) loss 1.5726 (1.2668) teacher_loss 0.4587 (0.2800) loss_zs_kd 0.0261 (0.0201) loss_oracle 0.5214 (0.4843) kd_loss 0.8401 (0.7346) acc 87.5000 (89.1927) gate/entropy 0.9834 (0.9832) gate/usage_max 0.5679 (0.5681) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.0704 (0.0773) teacher/usage_max 0.6413 (0.7432) teacher/usage_min 0.1594 (0.0960) teacher/usage_std 0.2184 (0.2922) nleep/row_max_mean 1540.5071 (1538.6542) nleep/row_max_std 54.3933 (57.0892) nleep/row_min_mean 1508.3923 (1509.7524) lr 1.5567e-04 eta 0:02:54
epoch [43/50] batch [140/167] time 0.153 (0.144) data 0.000 (0.003) loss 1.1034 (1.2662) teacher_loss 0.0929 (0.2833) loss_zs_kd 0.0156 (0.0200) loss_oracle 0.4770 (0.4840) kd_loss 0.7641 (0.7308) acc 96.8750 (89.0402) gate/entropy 0.9834 (0.9832) gate/usage_max 0.5679 (0.5681) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.0825 (0.0785) teacher/usage_max 0.7065 (0.7459) teacher/usage_min 0.0942 (0.0936) teacher/usage_std 0.2674 (0.2941) nleep/row_max_mean 1532.2211 (1538.8212) nleep/row_max_std 65.6462 (56.8668) nleep/row_min_mean 1508.3411 (1509.9971) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [160/167] time 0.157 (0.145) data 0.000 (0.002) loss 1.1616 (1.2640) teacher_loss 0.1609 (0.2835) loss_zs_kd 0.0185 (0.0200) loss_oracle 0.3991 (0.4827) kd_loss 0.7919 (0.7292) acc 96.8750 (88.9648) gate/entropy 0.9833 (0.9832) gate/usage_max 0.5680 (0.5681) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.0870 (0.0787) teacher/usage_max 0.6734 (0.7474) teacher/usage_min 0.0944 (0.0925) teacher/usage_std 0.2470 (0.2951) nleep/row_max_mean 1525.1930 (1538.7287) nleep/row_max_std 63.7123 (56.6445) nleep/row_min_mean 1498.7219 (1509.9712) lr 1.5567e-04 eta 0:02:50
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,216
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [44/50] batch [20/167] time 0.080 (0.107) data 0.000 (0.015) loss 1.2313 (1.2640) teacher_loss 0.3250 (0.2820) loss_zs_kd 0.0355 (0.0220) loss_oracle 0.5067 (0.4886) kd_loss 0.6351 (0.7267) acc 90.6250 (89.8438) gate/entropy 0.9832 (0.9831) gate/usage_max 0.5680 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1661) teacher/entropy 0.1183 (0.0742) teacher/usage_max 0.8032 (0.7545) teacher/usage_min 0.0738 (0.0837) teacher/usage_std 0.3328 (0.3010) nleep/row_max_mean 1528.3247 (1540.4240) nleep/row_max_std 64.9282 (52.7211) nleep/row_min_mean 1502.6613 (1511.5408) lr 1.2369e-04 eta 0:02:02
epoch [44/50] batch [40/167] time 0.087 (0.111) data 0.000 (0.008) loss 1.3404 (1.2572) teacher_loss 0.1962 (0.2700) loss_zs_kd 0.0113 (0.0225) loss_oracle 0.5134 (0.4834) kd_loss 0.8818 (0.7342) acc 90.6250 (89.9219) gate/entropy 0.9836 (0.9832) gate/usage_max 0.5677 (0.5681) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1657 (0.1660) teacher/entropy 0.0706 (0.0759) teacher/usage_max 0.5987 (0.7449) teacher/usage_min 0.1929 (0.0872) teacher/usage_std 0.1877 (0.2946) nleep/row_max_mean 1528.0833 (1539.8363) nleep/row_max_std 56.0138 (53.6095) nleep/row_min_mean 1502.7012 (1511.2657) lr 1.2369e-04 eta 0:02:04
epoch [44/50] batch [60/167] time 0.157 (0.114) data 0.001 (0.005) loss 1.1769 (1.2625) teacher_loss 0.1896 (0.2741) loss_zs_kd 0.0224 (0.0228) loss_oracle 0.5073 (0.4850) kd_loss 0.7225 (0.7345) acc 93.7500 (89.6354) gate/entropy 0.9829 (0.9831) gate/usage_max 0.5684 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0213 (0.0745) teacher/usage_max 0.8124 (0.7459) teacher/usage_min 0.0300 (0.0872) teacher/usage_std 0.3427 (0.2950) nleep/row_max_mean 1551.7742 (1540.3134) nleep/row_max_std 37.8941 (53.6730) nleep/row_min_mean 1524.1448 (1511.7560) lr 1.2369e-04 eta 0:02:06
epoch [44/50] batch [80/167] time 0.074 (0.116) data 0.000 (0.004) loss 1.2988 (1.2682) teacher_loss 0.2314 (0.2774) loss_zs_kd 0.0179 (0.0224) loss_oracle 0.4752 (0.4855) kd_loss 0.8209 (0.7369) acc 96.8750 (89.5703) gate/entropy 0.9835 (0.9831) gate/usage_max 0.5678 (0.5682) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1658 (0.1661) teacher/entropy 0.0790 (0.0757) teacher/usage_max 0.6513 (0.7423) teacher/usage_min 0.0967 (0.0883) teacher/usage_std 0.2336 (0.2926) nleep/row_max_mean 1532.8650 (1540.5386) nleep/row_max_std 44.8403 (53.3914) nleep/row_min_mean 1503.6409 (1512.2055) lr 1.2369e-04 eta 0:02:06
epoch [44/50] batch [100/167] time 0.087 (0.114) data 0.000 (0.003) loss 1.4772 (1.2651) teacher_loss 0.4233 (0.2735) loss_zs_kd 0.0385 (0.0224) loss_oracle 0.5118 (0.4855) kd_loss 0.7787 (0.7377) acc 81.2500 (89.7500) gate/entropy 0.9830 (0.9831) gate/usage_max 0.5683 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0533 (0.0742) teacher/usage_max 0.7228 (0.7430) teacher/usage_min 0.1278 (0.0884) teacher/usage_std 0.2756 (0.2930) nleep/row_max_mean 1545.3660 (1541.4150) nleep/row_max_std 55.4443 (53.3082) nleep/row_min_mean 1516.3660 (1512.8618) lr 1.2369e-04 eta 0:02:02
epoch [44/50] batch [120/167] time 0.110 (0.113) data 0.000 (0.003) loss 1.1548 (1.2622) teacher_loss 0.2623 (0.2723) loss_zs_kd 0.0088 (0.0217) loss_oracle 0.4789 (0.4866) kd_loss 0.6487 (0.7357) acc 93.7500 (89.6875) gate/entropy 0.9830 (0.9831) gate/usage_max 0.5683 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.1446 (0.0745) teacher/usage_max 0.7608 (0.7448) teacher/usage_min 0.0168 (0.0874) teacher/usage_std 0.3137 (0.2942) nleep/row_max_mean 1531.9690 (1541.2783) nleep/row_max_std 65.9027 (53.7419) nleep/row_min_mean 1505.0112 (1512.5725) lr 1.2369e-04 eta 0:01:58
epoch [44/50] batch [140/167] time 0.143 (0.114) data 0.000 (0.002) loss 1.4881 (1.2632) teacher_loss 0.4613 (0.2723) loss_zs_kd 0.0340 (0.0213) loss_oracle 0.4265 (0.4865) kd_loss 0.7965 (0.7370) acc 90.6250 (89.7545) gate/entropy 0.9831 (0.9831) gate/usage_max 0.5682 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0776 (0.0756) teacher/usage_max 0.6755 (0.7423) teacher/usage_min 0.0410 (0.0869) teacher/usage_std 0.2614 (0.2927) nleep/row_max_mean 1529.3779 (1540.3821) nleep/row_max_std 57.6264 (54.1483) nleep/row_min_mean 1500.8259 (1511.6131) lr 1.2369e-04 eta 0:01:57
epoch [44/50] batch [160/167] time 0.079 (0.113) data 0.000 (0.002) loss 1.2171 (1.2661) teacher_loss 0.2040 (0.2732) loss_zs_kd 0.0227 (0.0208) loss_oracle 0.4344 (0.4871) kd_loss 0.7846 (0.7389) acc 93.7500 (89.6875) gate/entropy 0.9826 (0.9831) gate/usage_max 0.5687 (0.5682) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1665 (0.1661) teacher/entropy 0.0487 (0.0784) teacher/usage_max 0.7203 (0.7373) teacher/usage_min 0.0760 (0.0898) teacher/usage_std 0.2785 (0.2892) nleep/row_max_mean 1550.4031 (1539.8798) nleep/row_max_std 46.1571 (53.7055) nleep/row_min_mean 1521.4623 (1511.2614) lr 1.2369e-04 eta 0:01:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,217
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [45/50] batch [20/167] time 0.093 (0.125) data 0.000 (0.012) loss 1.2300 (1.2433) teacher_loss 0.2285 (0.2626) loss_zs_kd 0.0473 (0.0227) loss_oracle 0.5090 (0.4952) kd_loss 0.7234 (0.7218) acc 90.6250 (89.8438) gate/entropy 0.9831 (0.9831) gate/usage_max 0.5681 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1660 (0.1661) teacher/entropy 0.0751 (0.0941) teacher/usage_max 0.7565 (0.7393) teacher/usage_min 0.0888 (0.1014) teacher/usage_std 0.3004 (0.2888) nleep/row_max_mean 1533.5105 (1536.1852) nleep/row_max_std 52.2908 (50.4560) nleep/row_min_mean 1499.9508 (1508.2769) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [40/167] time 0.086 (0.104) data 0.000 (0.006) loss 1.1659 (1.2399) teacher_loss 0.2075 (0.2606) loss_zs_kd 0.0093 (0.0197) loss_oracle 0.4858 (0.4984) kd_loss 0.7108 (0.7202) acc 90.6250 (89.6094) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5685 (0.5682) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0685 (0.0863) teacher/usage_max 0.7771 (0.7488) teacher/usage_min 0.0933 (0.0921) teacher/usage_std 0.3142 (0.2958) nleep/row_max_mean 1545.3503 (1538.2970) nleep/row_max_std 50.5104 (49.3676) nleep/row_min_mean 1519.0139 (1510.1091) lr 9.5173e-05 eta 0:01:39
epoch [45/50] batch [60/167] time 0.074 (0.097) data 0.000 (0.004) loss 1.2480 (1.2525) teacher_loss 0.3118 (0.2656) loss_zs_kd 0.0180 (0.0200) loss_oracle 0.4451 (0.4953) kd_loss 0.7046 (0.7293) acc 93.7500 (89.7396) gate/entropy 0.9828 (0.9830) gate/usage_max 0.5685 (0.5682) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0904 (0.0837) teacher/usage_max 0.7617 (0.7420) teacher/usage_min 0.1159 (0.0951) teacher/usage_std 0.3029 (0.2911) nleep/row_max_mean 1546.4277 (1539.0566) nleep/row_max_std 53.5648 (49.7162) nleep/row_min_mean 1516.6487 (1510.9109) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [80/167] time 0.133 (0.102) data 0.000 (0.003) loss 1.4702 (1.2544) teacher_loss 0.5412 (0.2651) loss_zs_kd 0.0259 (0.0200) loss_oracle 0.5486 (0.4949) kd_loss 0.6417 (0.7318) acc 81.2500 (89.6094) gate/entropy 0.9824 (0.9830) gate/usage_max 0.5689 (0.5683) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1666 (0.1661) teacher/entropy 0.0455 (0.0870) teacher/usage_max 0.8722 (0.7359) teacher/usage_min 0.0617 (0.0971) teacher/usage_std 0.3811 (0.2870) nleep/row_max_mean 1562.7582 (1540.1955) nleep/row_max_std 53.9108 (50.2447) nleep/row_min_mean 1525.5775 (1512.0954) lr 9.5173e-05 eta 0:01:34
epoch [45/50] batch [100/167] time 0.125 (0.111) data 0.000 (0.003) loss 1.1578 (1.2580) teacher_loss 0.2424 (0.2649) loss_zs_kd 0.0097 (0.0204) loss_oracle 0.4711 (0.4932) kd_loss 0.6749 (0.7363) acc 90.6250 (89.7188) gate/entropy 0.9832 (0.9830) gate/usage_max 0.5680 (0.5682) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1661) teacher/entropy 0.1196 (0.0852) teacher/usage_max 0.7627 (0.7330) teacher/usage_min 0.1150 (0.0946) teacher/usage_std 0.3036 (0.2855) nleep/row_max_mean 1539.3635 (1540.4586) nleep/row_max_std 57.5000 (51.2210) nleep/row_min_mean 1513.2859 (1512.2855) lr 9.5173e-05 eta 0:01:40
epoch [45/50] batch [120/167] time 0.161 (0.116) data 0.000 (0.002) loss 1.1223 (1.2582) teacher_loss 0.1613 (0.2665) loss_zs_kd 0.0168 (0.0203) loss_oracle 0.4884 (0.4898) kd_loss 0.7084 (0.7366) acc 96.8750 (89.7135) gate/entropy 0.9828 (0.9830) gate/usage_max 0.5685 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0858 (0.0856) teacher/usage_max 0.7600 (0.7322) teacher/usage_min 0.0473 (0.0927) teacher/usage_std 0.3075 (0.2851) nleep/row_max_mean 1547.2144 (1540.4941) nleep/row_max_std 53.5538 (52.2069) nleep/row_min_mean 1517.5530 (1512.2386) lr 9.5173e-05 eta 0:01:42
epoch [45/50] batch [140/167] time 0.132 (0.120) data 0.000 (0.002) loss 1.1483 (1.2630) teacher_loss 0.1809 (0.2720) loss_zs_kd 0.0328 (0.0202) loss_oracle 0.4541 (0.4885) kd_loss 0.7239 (0.7366) acc 87.5000 (89.3750) gate/entropy 0.9830 (0.9830) gate/usage_max 0.5683 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0509 (0.0846) teacher/usage_max 0.7820 (0.7332) teacher/usage_min 0.0956 (0.0917) teacher/usage_std 0.3175 (0.2860) nleep/row_max_mean 1544.7772 (1540.9352) nleep/row_max_std 54.7948 (52.8111) nleep/row_min_mean 1513.1495 (1512.5161) lr 9.5173e-05 eta 0:01:43
epoch [45/50] batch [160/167] time 0.142 (0.124) data 0.000 (0.002) loss 1.2382 (1.2606) teacher_loss 0.3425 (0.2735) loss_zs_kd 0.0241 (0.0200) loss_oracle 0.4966 (0.4883) kd_loss 0.6353 (0.7329) acc 87.5000 (89.4336) gate/entropy 0.9823 (0.9830) gate/usage_max 0.5690 (0.5683) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1667 (0.1661) teacher/entropy 0.0657 (0.0839) teacher/usage_max 0.8569 (0.7377) teacher/usage_min 0.0364 (0.0892) teacher/usage_std 0.3714 (0.2892) nleep/row_max_mean 1566.9681 (1541.7116) nleep/row_max_std 52.1553 (53.3347) nleep/row_min_mean 1535.1891 (1513.0075) lr 9.5173e-05 eta 0:01:44
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,218
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [46/50] batch [20/167] time 0.072 (0.164) data 0.000 (0.013) loss 1.1190 (1.2824) teacher_loss 0.2295 (0.2981) loss_zs_kd 0.0234 (0.0250) loss_oracle 0.4785 (0.4733) kd_loss 0.6386 (0.7351) acc 93.7500 (88.2812) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5686 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0555 (0.0827) teacher/usage_max 0.8637 (0.7362) teacher/usage_min 0.0245 (0.0872) teacher/usage_std 0.3767 (0.2888) nleep/row_max_mean 1565.5558 (1543.6324) nleep/row_max_std 60.3910 (57.6116) nleep/row_min_mean 1528.2427 (1514.3228) lr 7.0224e-05 eta 0:02:13
epoch [46/50] batch [40/167] time 0.095 (0.127) data 0.000 (0.007) loss 1.1247 (1.2761) teacher_loss 0.1947 (0.2756) loss_zs_kd 0.0083 (0.0226) loss_oracle 0.4859 (0.4796) kd_loss 0.6829 (0.7495) acc 90.6250 (88.9062) gate/entropy 0.9829 (0.9830) gate/usage_max 0.5684 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0776 (0.0798) teacher/usage_max 0.7966 (0.7244) teacher/usage_min 0.0992 (0.0919) teacher/usage_std 0.3276 (0.2817) nleep/row_max_mean 1551.6714 (1542.9395) nleep/row_max_std 58.0090 (58.4581) nleep/row_min_mean 1523.2490 (1513.7911) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [60/167] time 0.071 (0.127) data 0.000 (0.005) loss 1.3553 (1.2851) teacher_loss 0.3329 (0.2842) loss_zs_kd 0.0063 (0.0216) loss_oracle 0.4885 (0.4876) kd_loss 0.7750 (0.7463) acc 90.6250 (88.9583) gate/entropy 0.9832 (0.9830) gate/usage_max 0.5681 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1662) teacher/entropy 0.1306 (0.0792) teacher/usage_max 0.6460 (0.7287) teacher/usage_min 0.1640 (0.0958) teacher/usage_std 0.2214 (0.2835) nleep/row_max_mean 1539.4843 (1544.7703) nleep/row_max_std 47.9982 (56.3999) nleep/row_min_mean 1513.6730 (1515.4149) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [80/167] time 0.081 (0.123) data 0.000 (0.003) loss 1.1843 (1.2802) teacher_loss 0.1563 (0.2775) loss_zs_kd 0.0058 (0.0206) loss_oracle 0.4472 (0.4858) kd_loss 0.8015 (0.7495) acc 93.7500 (89.4531) gate/entropy 0.9831 (0.9830) gate/usage_max 0.5682 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1662) teacher/entropy 0.1263 (0.0801) teacher/usage_max 0.6241 (0.7245) teacher/usage_min 0.1699 (0.0953) teacher/usage_std 0.2061 (0.2807) nleep/row_max_mean 1538.2585 (1543.6374) nleep/row_max_std 53.1340 (56.7484) nleep/row_min_mean 1512.3898 (1514.7622) lr 7.0224e-05 eta 0:01:32
epoch [46/50] batch [100/167] time 0.070 (0.121) data 0.000 (0.003) loss 1.4259 (1.2762) teacher_loss 0.3945 (0.2744) loss_zs_kd 0.0141 (0.0203) loss_oracle 0.5188 (0.4863) kd_loss 0.7649 (0.7485) acc 90.6250 (89.7500) gate/entropy 0.9832 (0.9830) gate/usage_max 0.5681 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1662) teacher/entropy 0.0478 (0.0807) teacher/usage_max 0.7430 (0.7249) teacher/usage_min 0.1041 (0.0976) teacher/usage_std 0.2904 (0.2806) nleep/row_max_mean 1538.9744 (1543.1498) nleep/row_max_std 55.5669 (56.8032) nleep/row_min_mean 1507.4304 (1514.2416) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [120/167] time 0.080 (0.116) data 0.000 (0.002) loss 1.4396 (1.2774) teacher_loss 0.3692 (0.2806) loss_zs_kd 0.0251 (0.0212) loss_oracle 0.5054 (0.4879) kd_loss 0.8051 (0.7422) acc 90.6250 (89.5312) gate/entropy 0.9833 (0.9830) gate/usage_max 0.5679 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.1056 (0.0814) teacher/usage_max 0.6406 (0.7307) teacher/usage_min 0.1559 (0.0948) teacher/usage_std 0.2181 (0.2846) nleep/row_max_mean 1520.6031 (1543.3411) nleep/row_max_std 53.7135 (56.3411) nleep/row_min_mean 1495.3431 (1514.3871) lr 7.0224e-05 eta 0:01:22
epoch [46/50] batch [140/167] time 0.077 (0.113) data 0.000 (0.002) loss 1.2064 (1.2743) teacher_loss 0.2126 (0.2790) loss_zs_kd 0.0108 (0.0205) loss_oracle 0.4694 (0.4877) kd_loss 0.7537 (0.7412) acc 93.7500 (89.6205) gate/entropy 0.9834 (0.9830) gate/usage_max 0.5678 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1658 (0.1662) teacher/entropy 0.0954 (0.0821) teacher/usage_max 0.7050 (0.7310) teacher/usage_min 0.1345 (0.0942) teacher/usage_std 0.2630 (0.2848) nleep/row_max_mean 1535.5702 (1542.3734) nleep/row_max_std 56.1248 (56.2797) nleep/row_min_mean 1507.8787 (1513.5456) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [160/167] time 0.072 (0.113) data 0.000 (0.002) loss 1.1406 (1.2743) teacher_loss 0.2337 (0.2770) loss_zs_kd 0.0124 (0.0205) loss_oracle 0.4960 (0.4889) kd_loss 0.6527 (0.7426) acc 90.6250 (89.7070) gate/entropy 0.9825 (0.9830) gate/usage_max 0.5688 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0774 (0.0834) teacher/usage_max 0.8288 (0.7282) teacher/usage_min 0.0754 (0.0961) teacher/usage_std 0.3504 (0.2828) nleep/row_max_mean 1542.8951 (1541.6198) nleep/row_max_std 55.9093 (55.8483) nleep/row_min_mean 1519.2539 (1512.9439) lr 7.0224e-05 eta 0:01:16
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,216
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [47/50] batch [20/167] time 0.163 (0.168) data 0.000 (0.015) loss 1.3265 (1.2985) teacher_loss 0.2937 (0.2727) loss_zs_kd 0.0147 (0.0183) loss_oracle 0.4756 (0.4967) kd_loss 0.7876 (0.7683) acc 84.3750 (90.1562) gate/entropy 0.9831 (0.9830) gate/usage_max 0.5682 (0.5682) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0660 (0.0814) teacher/usage_max 0.7026 (0.7041) teacher/usage_min 0.0740 (0.1102) teacher/usage_std 0.2681 (0.2654) nleep/row_max_mean 1544.4604 (1541.7022) nleep/row_max_std 50.1873 (53.3142) nleep/row_min_mean 1513.9114 (1514.0470) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [40/167] time 0.130 (0.158) data 0.000 (0.007) loss 1.5768 (1.3080) teacher_loss 0.5635 (0.2898) loss_zs_kd 0.0310 (0.0193) loss_oracle 0.4692 (0.4925) kd_loss 0.7632 (0.7624) acc 78.1250 (88.9844) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5685 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0459 (0.0831) teacher/usage_max 0.7489 (0.7085) teacher/usage_min 0.0355 (0.1134) teacher/usage_std 0.3029 (0.2678) nleep/row_max_mean 1547.1764 (1541.9818) nleep/row_max_std 54.2838 (54.0637) nleep/row_min_mean 1514.2682 (1514.1684) lr 4.8943e-05 eta 0:01:39
epoch [47/50] batch [60/167] time 0.115 (0.155) data 0.001 (0.005) loss 1.2745 (1.2930) teacher_loss 0.2566 (0.2803) loss_zs_kd 0.0201 (0.0200) loss_oracle 0.4578 (0.4935) kd_loss 0.7789 (0.7560) acc 90.6250 (89.6354) gate/entropy 0.9830 (0.9830) gate/usage_max 0.5682 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1662) teacher/entropy 0.0790 (0.0819) teacher/usage_max 0.6957 (0.7164) teacher/usage_min 0.1328 (0.1085) teacher/usage_std 0.2567 (0.2733) nleep/row_max_mean 1546.6924 (1541.3841) nleep/row_max_std 58.7969 (54.7932) nleep/row_min_mean 1517.5332 (1513.2879) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [80/167] time 0.163 (0.156) data 0.000 (0.004) loss 1.3533 (1.2939) teacher_loss 0.3474 (0.2779) loss_zs_kd 0.0326 (0.0195) loss_oracle 0.4951 (0.4917) kd_loss 0.7421 (0.7604) acc 87.5000 (89.6484) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5686 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0801 (0.0813) teacher/usage_max 0.7312 (0.7125) teacher/usage_min 0.0724 (0.1103) teacher/usage_std 0.2858 (0.2706) nleep/row_max_mean 1541.7170 (1539.4877) nleep/row_max_std 58.0890 (55.3281) nleep/row_min_mean 1513.9741 (1511.4381) lr 4.8943e-05 eta 0:01:31
epoch [47/50] batch [100/167] time 0.160 (0.157) data 0.001 (0.003) loss 1.0428 (1.2828) teacher_loss 0.0625 (0.2721) loss_zs_kd 0.0087 (0.0194) loss_oracle 0.4814 (0.4911) kd_loss 0.7352 (0.7554) acc 100.0000 (89.9375) gate/entropy 0.9828 (0.9830) gate/usage_max 0.5685 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0565 (0.0810) teacher/usage_max 0.7646 (0.7178) teacher/usage_min 0.0931 (0.1086) teacher/usage_std 0.3056 (0.2742) nleep/row_max_mean 1555.0590 (1540.0775) nleep/row_max_std 54.5465 (55.1348) nleep/row_min_mean 1524.2853 (1511.8286) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [120/167] time 0.137 (0.156) data 0.000 (0.003) loss 1.2934 (1.2841) teacher_loss 0.3366 (0.2704) loss_zs_kd 0.0104 (0.0198) loss_oracle 0.4494 (0.4925) kd_loss 0.7270 (0.7576) acc 84.3750 (89.9219) gate/entropy 0.9830 (0.9830) gate/usage_max 0.5682 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1661 (0.1662) teacher/entropy 0.0407 (0.0814) teacher/usage_max 0.7903 (0.7151) teacher/usage_min 0.0536 (0.1076) teacher/usage_std 0.3258 (0.2726) nleep/row_max_mean 1531.3108 (1539.6379) nleep/row_max_std 59.5878 (55.4894) nleep/row_min_mean 1507.4663 (1511.4712) lr 4.8943e-05 eta 0:01:25
epoch [47/50] batch [140/167] time 0.171 (0.155) data 0.000 (0.002) loss 1.3815 (1.2856) teacher_loss 0.3629 (0.2733) loss_zs_kd 0.0153 (0.0196) loss_oracle 0.4976 (0.4925) kd_loss 0.7621 (0.7563) acc 87.5000 (89.8214) gate/entropy 0.9825 (0.9830) gate/usage_max 0.5688 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0664 (0.0819) teacher/usage_max 0.7240 (0.7160) teacher/usage_min 0.0828 (0.1075) teacher/usage_std 0.2799 (0.2731) nleep/row_max_mean 1561.1992 (1539.8724) nleep/row_max_std 46.3825 (55.6187) nleep/row_min_mean 1529.3096 (1511.6956) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [160/167] time 0.067 (0.147) data 0.000 (0.002) loss 1.2091 (1.2856) teacher_loss 0.2354 (0.2776) loss_zs_kd 0.0247 (0.0198) loss_oracle 0.5042 (0.4914) kd_loss 0.7092 (0.7524) acc 90.6250 (89.5312) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5686 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.1265 (0.0824) teacher/usage_max 0.7178 (0.7195) teacher/usage_min 0.1097 (0.1060) teacher/usage_std 0.2731 (0.2756) nleep/row_max_mean 1547.1101 (1539.5491) nleep/row_max_std 57.5821 (55.4133) nleep/row_min_mean 1517.4612 (1511.4045) lr 4.8943e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [48/50] batch [20/167] time 0.083 (0.124) data 0.000 (0.013) loss 1.2576 (1.2873) teacher_loss 0.1873 (0.2666) loss_zs_kd 0.0120 (0.0181) loss_oracle 0.4976 (0.4967) kd_loss 0.8155 (0.7634) acc 96.8750 (90.0000) gate/entropy 0.9833 (0.9829) gate/usage_max 0.5680 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.1270 (0.0771) teacher/usage_max 0.6097 (0.7136) teacher/usage_min 0.1668 (0.1122) teacher/usage_std 0.1968 (0.2708) nleep/row_max_mean 1522.3107 (1536.5446) nleep/row_max_std 56.6228 (50.6010) nleep/row_min_mean 1499.0428 (1509.2081) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [40/167] time 0.097 (0.115) data 0.000 (0.006) loss 1.3643 (1.2998) teacher_loss 0.2878 (0.2870) loss_zs_kd 0.0381 (0.0198) loss_oracle 0.4834 (0.4956) kd_loss 0.8157 (0.7552) acc 90.6250 (89.2969) gate/entropy 0.9833 (0.9829) gate/usage_max 0.5680 (0.5684) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1662) teacher/entropy 0.0835 (0.0773) teacher/usage_max 0.6517 (0.7219) teacher/usage_min 0.1036 (0.1051) teacher/usage_std 0.2324 (0.2769) nleep/row_max_mean 1506.3557 (1538.9306) nleep/row_max_std 65.6898 (50.8723) nleep/row_min_mean 1484.8923 (1510.7121) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [60/167] time 0.157 (0.117) data 0.001 (0.004) loss 1.2103 (1.2735) teacher_loss 0.2231 (0.2691) loss_zs_kd 0.0068 (0.0194) loss_oracle 0.5202 (0.4917) kd_loss 0.7237 (0.7488) acc 93.7500 (90.1562) gate/entropy 0.9830 (0.9829) gate/usage_max 0.5683 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0546 (0.0834) teacher/usage_max 0.7801 (0.7222) teacher/usage_min 0.0792 (0.1009) teacher/usage_std 0.3169 (0.2777) nleep/row_max_mean 1541.2577 (1535.5420) nleep/row_max_std 46.1446 (53.1008) nleep/row_min_mean 1511.0437 (1507.6876) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [80/167] time 0.094 (0.112) data 0.000 (0.003) loss 1.2737 (1.2853) teacher_loss 0.1763 (0.2807) loss_zs_kd 0.0160 (0.0202) loss_oracle 0.5542 (0.4932) kd_loss 0.8123 (0.7479) acc 93.7500 (89.5703) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0488 (0.0838) teacher/usage_max 0.6918 (0.7228) teacher/usage_min 0.1406 (0.1023) teacher/usage_std 0.2537 (0.2778) nleep/row_max_mean 1540.2135 (1534.4226) nleep/row_max_std 56.6740 (53.3077) nleep/row_min_mean 1509.2136 (1506.5901) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [100/167] time 0.177 (0.115) data 0.000 (0.003) loss 1.4123 (1.2789) teacher_loss 0.2909 (0.2769) loss_zs_kd 0.0144 (0.0203) loss_oracle 0.5634 (0.4923) kd_loss 0.8325 (0.7456) acc 90.6250 (89.7500) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5683 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0778 (0.0847) teacher/usage_max 0.6411 (0.7242) teacher/usage_min 0.1454 (0.1024) teacher/usage_std 0.2194 (0.2787) nleep/row_max_mean 1531.3696 (1533.5131) nleep/row_max_std 50.9047 (53.5638) nleep/row_min_mean 1503.5259 (1505.8450) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [120/167] time 0.091 (0.115) data 0.000 (0.002) loss 1.4747 (1.2776) teacher_loss 0.3738 (0.2743) loss_zs_kd 0.0203 (0.0201) loss_oracle 0.5085 (0.4897) kd_loss 0.8366 (0.7484) acc 81.2500 (89.7917) gate/entropy 0.9833 (0.9829) gate/usage_max 0.5679 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.0774 (0.0833) teacher/usage_max 0.6394 (0.7227) teacher/usage_min 0.1465 (0.1030) teacher/usage_std 0.2182 (0.2777) nleep/row_max_mean 1520.7163 (1532.8605) nleep/row_max_std 46.1734 (53.9441) nleep/row_min_mean 1495.5706 (1505.1953) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [140/167] time 0.159 (0.120) data 0.000 (0.002) loss 1.5564 (1.2803) teacher_loss 0.5616 (0.2772) loss_zs_kd 0.0254 (0.0201) loss_oracle 0.4777 (0.4918) kd_loss 0.7432 (0.7472) acc 78.1250 (89.5759) gate/entropy 0.9830 (0.9829) gate/usage_max 0.5683 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0705 (0.0818) teacher/usage_max 0.7403 (0.7256) teacher/usage_min 0.0700 (0.1023) teacher/usage_std 0.2919 (0.2797) nleep/row_max_mean 1517.6794 (1533.1110) nleep/row_max_std 51.9386 (53.4521) nleep/row_min_mean 1496.1196 (1505.4307) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [160/167] time 0.143 (0.124) data 0.000 (0.002) loss 1.0840 (1.2762) teacher_loss 0.1386 (0.2763) loss_zs_kd 0.0296 (0.0200) loss_oracle 0.4611 (0.4901) kd_loss 0.7000 (0.7448) acc 100.0000 (89.6875) gate/entropy 0.9826 (0.9829) gate/usage_max 0.5687 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.1377 (0.0821) teacher/usage_max 0.7167 (0.7277) teacher/usage_min 0.1321 (0.1019) teacher/usage_std 0.2712 (0.2810) nleep/row_max_mean 1537.9238 (1533.2025) nleep/row_max_std 51.1321 (53.1645) nleep/row_min_mean 1511.5775 (1505.5541) lr 3.1417e-05 eta 0:00:42
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [49/50] batch [20/167] time 0.136 (0.157) data 0.000 (0.013) loss 1.2828 (1.2434) teacher_loss 0.3479 (0.2477) loss_zs_kd 0.0144 (0.0214) loss_oracle 0.4411 (0.4777) kd_loss 0.7072 (0.7461) acc 90.6250 (90.1562) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1663) teacher/entropy 0.0904 (0.0736) teacher/usage_max 0.7577 (0.7353) teacher/usage_min 0.1041 (0.1074) teacher/usage_std 0.3004 (0.2855) nleep/row_max_mean 1543.1096 (1541.7792) nleep/row_max_std 44.8895 (50.4471) nleep/row_min_mean 1518.8679 (1514.3657) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [40/167] time 0.157 (0.152) data 0.000 (0.007) loss 1.1425 (1.2918) teacher_loss 0.1431 (0.2776) loss_zs_kd 0.0119 (0.0217) loss_oracle 0.5212 (0.4887) kd_loss 0.7329 (0.7591) acc 93.7500 (89.2969) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0700 (0.0756) teacher/usage_max 0.7537 (0.7202) teacher/usage_min 0.0916 (0.1100) teacher/usage_std 0.2984 (0.2754) nleep/row_max_mean 1557.0444 (1539.2752) nleep/row_max_std 36.4333 (52.3248) nleep/row_min_mean 1524.8492 (1511.2805) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [60/167] time 0.154 (0.151) data 0.000 (0.004) loss 1.1837 (1.2914) teacher_loss 0.1505 (0.2727) loss_zs_kd 0.0222 (0.0216) loss_oracle 0.5383 (0.4904) kd_loss 0.7529 (0.7627) acc 93.7500 (89.2708) gate/entropy 0.9826 (0.9829) gate/usage_max 0.5686 (0.5684) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0838 (0.0753) teacher/usage_max 0.7154 (0.7165) teacher/usage_min 0.0384 (0.1102) teacher/usage_std 0.2831 (0.2734) nleep/row_max_mean 1548.0873 (1540.1046) nleep/row_max_std 53.4088 (52.3963) nleep/row_min_mean 1518.5464 (1511.9502) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [80/167] time 0.104 (0.140) data 0.000 (0.003) loss 1.3181 (1.2942) teacher_loss 0.3268 (0.2765) loss_zs_kd 0.0116 (0.0213) loss_oracle 0.4705 (0.4915) kd_loss 0.7503 (0.7613) acc 84.3750 (89.4141) gate/entropy 0.9827 (0.9829) gate/usage_max 0.5686 (0.5684) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0654 (0.0775) teacher/usage_max 0.7390 (0.7156) teacher/usage_min 0.1141 (0.1104) teacher/usage_std 0.2872 (0.2726) nleep/row_max_mean 1549.7467 (1539.3599) nleep/row_max_std 54.3825 (52.9905) nleep/row_min_mean 1521.1162 (1511.2933) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [100/167] time 0.095 (0.133) data 0.000 (0.003) loss 1.1662 (1.2881) teacher_loss 0.2416 (0.2715) loss_zs_kd 0.0121 (0.0216) loss_oracle 0.4731 (0.4917) kd_loss 0.6820 (0.7600) acc 84.3750 (89.4375) gate/entropy 0.9826 (0.9829) gate/usage_max 0.5687 (0.5684) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0404 (0.0763) teacher/usage_max 0.8372 (0.7182) teacher/usage_min 0.0510 (0.1089) teacher/usage_std 0.3571 (0.2745) nleep/row_max_mean 1550.3894 (1538.8644) nleep/row_max_std 34.6731 (52.2576) nleep/row_min_mean 1522.5605 (1510.9047) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [120/167] time 0.085 (0.128) data 0.000 (0.002) loss 1.2822 (1.2882) teacher_loss 0.3112 (0.2703) loss_zs_kd 0.0327 (0.0218) loss_oracle 0.4986 (0.4907) kd_loss 0.7054 (0.7617) acc 93.7500 (89.4531) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5684 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0509 (0.0759) teacher/usage_max 0.7998 (0.7168) teacher/usage_min 0.0642 (0.1071) teacher/usage_std 0.3311 (0.2738) nleep/row_max_mean 1537.3387 (1538.6509) nleep/row_max_std 50.4775 (51.6666) nleep/row_min_mean 1510.1655 (1510.8156) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [140/167] time 0.185 (0.127) data 0.001 (0.002) loss 1.0205 (1.2791) teacher_loss 0.0655 (0.2665) loss_zs_kd 0.0215 (0.0217) loss_oracle 0.4726 (0.4899) kd_loss 0.7079 (0.7568) acc 100.0000 (89.5759) gate/entropy 0.9836 (0.9829) gate/usage_max 0.5677 (0.5684) gate/usage_min 0.2131 (0.2129) gate/usage_std 0.1657 (0.1662) teacher/entropy 0.1498 (0.0764) teacher/usage_max 0.6973 (0.7213) teacher/usage_min 0.1424 (0.1047) teacher/usage_std 0.2574 (0.2770) nleep/row_max_mean 1513.1641 (1539.2786) nleep/row_max_std 59.0451 (51.0463) nleep/row_min_mean 1491.3289 (1511.2085) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [160/167] time 0.186 (0.125) data 0.000 (0.002) loss 1.2201 (1.2775) teacher_loss 0.2024 (0.2676) loss_zs_kd 0.0259 (0.0217) loss_oracle 0.4174 (0.4888) kd_loss 0.7960 (0.7547) acc 93.7500 (89.6484) gate/entropy 0.9832 (0.9829) gate/usage_max 0.5681 (0.5684) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1662) teacher/entropy 0.1122 (0.0773) teacher/usage_max 0.6393 (0.7225) teacher/usage_min 0.0145 (0.1034) teacher/usage_std 0.2552 (0.2781) nleep/row_max_mean 1517.9812 (1538.4148) nleep/row_max_std 56.7713 (50.8935) nleep/row_min_mean 1491.4548 (1510.4014) lr 1.7713e-05 eta 0:00:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [50/50] batch [20/167] time 0.122 (0.142) data 0.000 (0.019) loss 1.1566 (1.2674) teacher_loss 0.2064 (0.2695) loss_zs_kd 0.0289 (0.0189) loss_oracle 0.4624 (0.4833) kd_loss 0.7046 (0.7468) acc 96.8750 (89.0625) gate/entropy 0.9824 (0.9829) gate/usage_max 0.5689 (0.5684) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1666 (0.1663) teacher/entropy 0.0677 (0.0831) teacher/usage_max 0.7840 (0.7244) teacher/usage_min 0.0853 (0.1033) teacher/usage_std 0.3192 (0.2788) nleep/row_max_mean 1547.8037 (1533.0872) nleep/row_max_std 43.7986 (52.1024) nleep/row_min_mean 1516.6403 (1505.0299) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [40/167] time 0.147 (0.135) data 0.000 (0.009) loss 1.1483 (1.2944) teacher_loss 0.1545 (0.2809) loss_zs_kd 0.0144 (0.0204) loss_oracle 0.4704 (0.4868) kd_loss 0.7514 (0.7599) acc 93.7500 (88.8281) gate/entropy 0.9833 (0.9829) gate/usage_max 0.5679 (0.5683) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.0615 (0.0805) teacher/usage_max 0.7425 (0.7135) teacher/usage_min 0.0984 (0.1094) teacher/usage_std 0.2904 (0.2710) nleep/row_max_mean 1520.0347 (1530.8885) nleep/row_max_std 70.5410 (53.0996) nleep/row_min_mean 1489.2900 (1503.0219) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [60/167] time 0.159 (0.144) data 0.001 (0.006) loss 1.2547 (1.2834) teacher_loss 0.2532 (0.2757) loss_zs_kd 0.0135 (0.0205) loss_oracle 0.4515 (0.4881) kd_loss 0.7690 (0.7534) acc 90.6250 (89.4271) gate/entropy 0.9830 (0.9829) gate/usage_max 0.5683 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0875 (0.0810) teacher/usage_max 0.6959 (0.7199) teacher/usage_min 0.1042 (0.1079) teacher/usage_std 0.2593 (0.2753) nleep/row_max_mean 1527.8340 (1530.4348) nleep/row_max_std 53.7255 (52.3790) nleep/row_min_mean 1503.2217 (1503.2690) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [80/167] time 0.132 (0.144) data 0.000 (0.005) loss 1.3281 (1.2822) teacher_loss 0.3381 (0.2769) loss_zs_kd 0.0258 (0.0208) loss_oracle 0.4557 (0.4875) kd_loss 0.7492 (0.7512) acc 87.5000 (89.6484) gate/entropy 0.9827 (0.9829) gate/usage_max 0.5686 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0297 (0.0805) teacher/usage_max 0.7797 (0.7229) teacher/usage_min 0.0674 (0.1032) teacher/usage_std 0.3175 (0.2779) nleep/row_max_mean 1540.1610 (1530.3929) nleep/row_max_std 28.0692 (50.5159) nleep/row_min_mean 1513.3207 (1503.4213) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [100/167] time 0.155 (0.145) data 0.000 (0.004) loss 1.1418 (1.2929) teacher_loss 0.1573 (0.2842) loss_zs_kd 0.0189 (0.0208) loss_oracle 0.5165 (0.4905) kd_loss 0.7168 (0.7530) acc 93.7500 (89.3125) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5683 (0.5684) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0850 (0.0799) teacher/usage_max 0.7538 (0.7216) teacher/usage_min 0.0996 (0.1039) teacher/usage_std 0.2979 (0.2772) nleep/row_max_mean 1534.9692 (1530.5570) nleep/row_max_std 34.1515 (50.2970) nleep/row_min_mean 1510.2177 (1503.6627) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [120/167] time 0.133 (0.145) data 0.000 (0.003) loss 1.3217 (1.2965) teacher_loss 0.2785 (0.2880) loss_zs_kd 0.0191 (0.0204) loss_oracle 0.4786 (0.4901) kd_loss 0.7944 (0.7533) acc 90.6250 (89.1927) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5683) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0693 (0.0808) teacher/usage_max 0.6876 (0.7204) teacher/usage_min 0.0469 (0.1044) teacher/usage_std 0.2659 (0.2764) nleep/row_max_mean 1533.8724 (1530.5090) nleep/row_max_std 52.8218 (50.8216) nleep/row_min_mean 1510.3418 (1503.5242) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [140/167] time 0.137 (0.145) data 0.000 (0.003) loss 1.2529 (1.2912) teacher_loss 0.3339 (0.2805) loss_zs_kd 0.0127 (0.0202) loss_oracle 0.5142 (0.4882) kd_loss 0.6554 (0.7564) acc 90.6250 (89.4420) gate/entropy 0.9825 (0.9829) gate/usage_max 0.5688 (0.5683) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0489 (0.0797) teacher/usage_max 0.8537 (0.7183) teacher/usage_min 0.0321 (0.1058) teacher/usage_std 0.3695 (0.2748) nleep/row_max_mean 1535.9551 (1530.9306) nleep/row_max_std 42.2432 (50.2365) nleep/row_min_mean 1509.5642 (1504.0440) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/167] time 0.152 (0.144) data 0.000 (0.002) loss 1.2231 (1.2925) teacher_loss 0.2046 (0.2838) loss_zs_kd 0.0156 (0.0202) loss_oracle 0.4948 (0.4894) kd_loss 0.7634 (0.7538) acc 93.7500 (89.3164) gate/entropy 0.9832 (0.9829) gate/usage_max 0.5681 (0.5684) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1660 (0.1662) teacher/entropy 0.0659 (0.0791) teacher/usage_max 0.7223 (0.7216) teacher/usage_min 0.0426 (0.1052) teacher/usage_std 0.2860 (0.2770) nleep/row_max_mean 1520.5461 (1531.8504) nleep/row_max_std 51.6085 (49.9912) nleep/row_min_mean 1495.1802 (1504.8605) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,215
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.7%, epoch: 26 *******
******* Domain c best val test acc: 98.0%, epoch: 26 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:16

Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'photo', 'sketch']
Target     ['cartoon']
# classes  7
# train_x  5,349
# val      2,297
# test     2,344
---------  -----------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/167] time 0.155 (0.188) data 0.000 (0.020) loss 1.2338 (1.3184) teacher_loss 0.5969 (0.5492) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.6368 (0.7692) acc 84.3750 (80.3125) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3346) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.4628 (0.3303) teacher/usage_max 0.4908 (0.4981) teacher/usage_min 0.1816 (0.2064) teacher/usage_std 0.1263 (0.1275) nleep/row_max_mean 1604.8400 (1593.2305) nleep/row_max_std 68.8594 (83.9294) nleep/row_min_mean 1594.0742 (1578.4275) lr 1.0000e-05 eta 0:26:09
epoch [1/50] batch [40/167] time 0.151 (0.168) data 0.000 (0.010) loss 1.3317 (1.2533) teacher_loss 0.6914 (0.5528) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0047 (0.0006) kd_loss 0.6379 (0.7002) acc 75.0000 (80.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3346) gate/usage_min 0.3316 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.4612 (0.3993) teacher/usage_max 0.4525 (0.4872) teacher/usage_min 0.2178 (0.2075) teacher/usage_std 0.0958 (0.1206) nleep/row_max_mean 1590.4314 (1600.7654) nleep/row_max_std 69.5800 (75.2227) nleep/row_min_mean 1584.6130 (1589.6271) lr 1.0000e-05 eta 0:23:17
epoch [1/50] batch [60/167] time 0.155 (0.163) data 0.000 (0.007) loss 1.1099 (1.1677) teacher_loss 0.5645 (0.5271) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.0041 (0.0017) kd_loss 0.5431 (0.6397) acc 75.0000 (81.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3345 (0.3346) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.5565 (0.4598) teacher/usage_max 0.4824 (0.4826) teacher/usage_min 0.2127 (0.2109) teacher/usage_std 0.1119 (0.1165) nleep/row_max_mean 1604.4612 (1601.5970) nleep/row_max_std 71.5153 (71.5490) nleep/row_min_mean 1599.6742 (1592.4839) lr 1.0000e-05 eta 0:22:32
epoch [1/50] batch [80/167] time 0.116 (0.158) data 0.000 (0.005) loss 1.0764 (1.1116) teacher_loss 0.6130 (0.5109) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0141 (0.0034) kd_loss 0.4559 (0.5989) acc 71.8750 (82.0703) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.6426 (0.5005) teacher/usage_max 0.4481 (0.4785) teacher/usage_min 0.1788 (0.2060) teacher/usage_std 0.1135 (0.1169) nleep/row_max_mean 1594.6501 (1603.3618) nleep/row_max_std 50.4634 (68.1930) nleep/row_min_mean 1591.2605 (1595.5388) lr 1.0000e-05 eta 0:21:49
epoch [1/50] batch [100/167] time 0.168 (0.149) data 0.000 (0.004) loss 0.8151 (1.0709) teacher_loss 0.2742 (0.4960) loss_zs_kd 0.0009 (0.0002) loss_oracle 0.0110 (0.0057) kd_loss 0.5349 (0.5719) acc 96.8750 (82.4375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3345 (0.3346) gate/usage_min 0.3318 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.5634 (0.5274) teacher/usage_max 0.4964 (0.4763) teacher/usage_min 0.1069 (0.2002) teacher/usage_std 0.1652 (0.1181) nleep/row_max_mean 1612.5922 (1604.3538) nleep/row_max_std 46.7255 (65.9301) nleep/row_min_mean 1609.1650 (1597.4549) lr 1.0000e-05 eta 0:20:30
epoch [1/50] batch [120/167] time 0.166 (0.143) data 0.000 (0.003) loss 0.9860 (1.0464) teacher_loss 0.4643 (0.4868) loss_zs_kd 0.0015 (0.0004) loss_oracle 0.0222 (0.0083) kd_loss 0.5099 (0.5553) acc 81.2500 (82.7083) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3346) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.5873 (0.5438) teacher/usage_max 0.6163 (0.4821) teacher/usage_min 0.1183 (0.1921) teacher/usage_std 0.2089 (0.1236) nleep/row_max_mean 1586.1852 (1604.9708) nleep/row_max_std 78.9073 (64.4041) nleep/row_min_mean 1583.0852 (1598.7090) lr 1.0000e-05 eta 0:19:33
epoch [1/50] batch [140/167] time 0.079 (0.138) data 0.000 (0.003) loss 0.9023 (1.0224) teacher_loss 0.4933 (0.4754) loss_zs_kd 0.0011 (0.0004) loss_oracle 0.0297 (0.0113) kd_loss 0.3936 (0.5412) acc 75.0000 (83.0357) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3316 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.7044 (0.5577) teacher/usage_max 0.4786 (0.4925) teacher/usage_min 0.2109 (0.1855) teacher/usage_std 0.1105 (0.1304) nleep/row_max_mean 1599.6442 (1604.9085) nleep/row_max_std 58.9751 (63.4699) nleep/row_min_mean 1596.6906 (1599.0959) lr 1.0000e-05 eta 0:18:51
epoch [1/50] batch [160/167] time 0.121 (0.135) data 0.000 (0.003) loss 0.7018 (1.0106) teacher_loss 0.2529 (0.4707) loss_zs_kd 0.0008 (0.0006) loss_oracle 0.0650 (0.0149) kd_loss 0.4160 (0.5321) acc 90.6250 (83.1445) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3347) gate/usage_min 0.3316 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.6816 (0.5666) teacher/usage_max 0.5575 (0.5062) teacher/usage_min 0.1856 (0.1795) teacher/usage_std 0.1612 (0.1388) nleep/row_max_mean 1591.7603 (1604.6126) nleep/row_max_std 54.6624 (62.5529) nleep/row_min_mean 1588.5262 (1599.0956) lr 1.0000e-05 eta 0:18:27
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,169
* accuracy: 94.4%
* error: 5.6%
* macro_f1: 95.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,327
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      94.4%, epoch: 1 *******
******* Domain c best val test acc: 99.3%, epoch: 1 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [2/50] batch [20/167] time 0.072 (0.131) data 0.000 (0.016) loss 1.6338 (1.1479) teacher_loss 0.6340 (0.4482) loss_zs_kd 0.0105 (0.0069) loss_oracle 0.4552 (0.2204) kd_loss 0.7669 (0.5861) acc 78.1250 (85.0000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3377 (0.3361) gate/usage_min 0.3306 (0.3312) gate/usage_std 0.0031 (0.0021) teacher/entropy 0.3229 (0.5083) teacher/usage_max 0.7824 (0.6785) teacher/usage_min 0.0945 (0.1289) teacher/usage_std 0.3177 (0.2463) nleep/row_max_mean 1601.6582 (1603.8033) nleep/row_max_std 55.0888 (51.6604) nleep/row_min_mean 1594.8450 (1599.1803) lr 2.0000e-03 eta 0:17:50
epoch [2/50] batch [40/167] time 0.136 (0.128) data 0.000 (0.008) loss 1.1471 (1.1492) teacher_loss 0.2020 (0.3908) loss_zs_kd 0.0166 (0.0090) loss_oracle 0.3591 (0.2808) kd_loss 0.7573 (0.6135) acc 96.8750 (86.1719) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3419 (0.3380) gate/usage_min 0.3286 (0.3304) gate/usage_std 0.0061 (0.0033) teacher/entropy 0.3241 (0.4778) teacher/usage_max 0.7967 (0.6905) teacher/usage_min 0.0569 (0.1266) teacher/usage_std 0.3297 (0.2546) nleep/row_max_mean 1583.7438 (1600.9760) nleep/row_max_std 52.2633 (51.1648) nleep/row_min_mean 1575.6205 (1595.7739) lr 2.0000e-03 eta 0:17:21
epoch [2/50] batch [60/167] time 0.157 (0.138) data 0.000 (0.005) loss 1.1220 (1.1792) teacher_loss 0.3059 (0.3880) loss_zs_kd 0.0118 (0.0104) loss_oracle 0.2329 (0.3067) kd_loss 0.6937 (0.6327) acc 90.6250 (86.4583) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3455 (0.3399) gate/usage_min 0.3267 (0.3295) gate/usage_std 0.0086 (0.0047) teacher/entropy 0.3880 (0.4560) teacher/usage_max 0.6513 (0.6812) teacher/usage_min 0.1191 (0.1259) teacher/usage_std 0.2293 (0.2486) nleep/row_max_mean 1593.1149 (1599.2864) nleep/row_max_std 52.7434 (50.2081) nleep/row_min_mean 1586.7563 (1593.5742) lr 2.0000e-03 eta 0:18:40
epoch [2/50] batch [80/167] time 0.158 (0.142) data 0.000 (0.004) loss 1.4573 (1.2280) teacher_loss 0.3825 (0.3973) loss_zs_kd 0.0179 (0.0110) loss_oracle 0.4177 (0.3275) kd_loss 0.8571 (0.6615) acc 84.3750 (86.1328) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3500 (0.3419) gate/usage_min 0.3247 (0.3285) gate/usage_std 0.0118 (0.0061) teacher/entropy 0.2028 (0.4236) teacher/usage_max 0.8629 (0.6906) teacher/usage_min 0.0566 (0.1215) teacher/usage_std 0.3746 (0.2551) nleep/row_max_mean 1603.2324 (1599.0481) nleep/row_max_std 41.8142 (50.1624) nleep/row_min_mean 1593.2333 (1592.6037) lr 2.0000e-03 eta 0:19:14
epoch [2/50] batch [100/167] time 0.140 (0.146) data 0.000 (0.003) loss 1.1253 (1.2260) teacher_loss 0.1835 (0.3780) loss_zs_kd 0.0102 (0.0103) loss_oracle 0.3510 (0.3410) kd_loss 0.7611 (0.6724) acc 93.7500 (86.6250) gate/entropy 1.0977 (1.0983) gate/usage_max 0.3533 (0.3439) gate/usage_min 0.3222 (0.3275) gate/usage_std 0.0142 (0.0075) teacher/entropy 0.3263 (0.4108) teacher/usage_max 0.4632 (0.6769) teacher/usage_min 0.2077 (0.1238) teacher/usage_std 0.1043 (0.2471) nleep/row_max_mean 1580.4070 (1597.6656) nleep/row_max_std 63.5407 (50.8961) nleep/row_min_mean 1571.7847 (1590.7549) lr 2.0000e-03 eta 0:19:39
epoch [2/50] batch [120/167] time 0.166 (0.148) data 0.000 (0.003) loss 1.3557 (1.2462) teacher_loss 0.3345 (0.3737) loss_zs_kd 0.0035 (0.0106) loss_oracle 0.4426 (0.3521) kd_loss 0.7981 (0.6912) acc 87.5000 (86.7188) gate/entropy 1.0975 (1.0982) gate/usage_max 0.3558 (0.3457) gate/usage_min 0.3196 (0.3264) gate/usage_std 0.0160 (0.0088) teacher/entropy 0.2747 (0.3908) teacher/usage_max 0.5844 (0.6595) teacher/usage_min 0.0974 (0.1218) teacher/usage_std 0.1991 (0.2381) nleep/row_max_mean 1599.2476 (1596.4277) nleep/row_max_std 50.2965 (50.9158) nleep/row_min_mean 1587.9489 (1589.0726) lr 2.0000e-03 eta 0:19:56
epoch [2/50] batch [140/167] time 0.133 (0.149) data 0.000 (0.002) loss 1.2050 (1.2657) teacher_loss 0.1087 (0.3664) loss_zs_kd 0.0019 (0.0107) loss_oracle 0.4793 (0.3697) kd_loss 0.8557 (0.7090) acc 96.8750 (87.0536) gate/entropy 1.0972 (1.0980) gate/usage_max 0.3582 (0.3473) gate/usage_min 0.3164 (0.3252) gate/usage_std 0.0180 (0.0100) teacher/entropy 0.2372 (0.3715) teacher/usage_max 0.6367 (0.6486) teacher/usage_min 0.0438 (0.1133) teacher/usage_std 0.2423 (0.2350) nleep/row_max_mean 1596.3948 (1595.0308) nleep/row_max_std 62.7569 (51.4563) nleep/row_min_mean 1587.4796 (1587.0324) lr 2.0000e-03 eta 0:19:55
epoch [2/50] batch [160/167] time 0.126 (0.149) data 0.000 (0.002) loss 1.3979 (1.2921) teacher_loss 0.2768 (0.3670) loss_zs_kd 0.0068 (0.0107) loss_oracle 0.5038 (0.3857) kd_loss 0.8658 (0.7268) acc 93.7500 (86.9336) gate/entropy 1.0967 (1.0979) gate/usage_max 0.3614 (0.3489) gate/usage_min 0.3128 (0.3239) gate/usage_std 0.0205 (0.0111) teacher/entropy 0.1870 (0.3510) teacher/usage_max 0.6897 (0.6479) teacher/usage_min 0.0712 (0.1048) teacher/usage_std 0.2611 (0.2366) nleep/row_max_mean 1584.9353 (1593.8065) nleep/row_max_std 54.9089 (51.5556) nleep/row_min_mean 1568.1506 (1585.0545) lr 2.0000e-03 eta 0:19:52
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,185
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      95.1%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [3/50] batch [20/167] time 0.190 (0.132) data 0.000 (0.011) loss 1.2966 (1.4575) teacher_loss 0.1887 (0.3235) loss_zs_kd 0.0042 (0.0089) loss_oracle 0.5412 (0.5241) kd_loss 0.8351 (0.8675) acc 93.7500 (88.4375) gate/entropy 1.0959 (1.0962) gate/usage_max 0.3661 (0.3644) gate/usage_min 0.3075 (0.3094) gate/usage_std 0.0244 (0.0230) teacher/entropy 0.2262 (0.1811) teacher/usage_max 0.5240 (0.6612) teacher/usage_min 0.0404 (0.0209) teacher/usage_std 0.2103 (0.2673) nleep/row_max_mean 1579.8251 (1582.5324) nleep/row_max_std 55.4247 (50.8026) nleep/row_min_mean 1564.4761 (1566.7158) lr 1.9980e-03 eta 0:17:36
epoch [3/50] batch [40/167] time 0.173 (0.128) data 0.000 (0.006) loss 1.4533 (1.4794) teacher_loss 0.3707 (0.3688) loss_zs_kd 0.0072 (0.0090) loss_oracle 0.5101 (0.4797) kd_loss 0.8239 (0.8663) acc 78.1250 (85.7812) gate/entropy 1.0954 (1.0960) gate/usage_max 0.3691 (0.3660) gate/usage_min 0.3040 (0.3076) gate/usage_std 0.0270 (0.0243) teacher/entropy 0.2209 (0.1784) teacher/usage_max 0.6345 (0.6693) teacher/usage_min 0.0611 (0.0279) teacher/usage_std 0.2350 (0.2680) nleep/row_max_mean 1574.3417 (1579.1515) nleep/row_max_std 56.4122 (52.6217) nleep/row_min_mean 1558.7207 (1563.5869) lr 1.9980e-03 eta 0:17:01
epoch [3/50] batch [60/167] time 0.106 (0.123) data 0.000 (0.004) loss 1.4829 (1.4977) teacher_loss 0.3747 (0.3741) loss_zs_kd 0.0114 (0.0091) loss_oracle 0.4707 (0.4914) kd_loss 0.8671 (0.8733) acc 84.3750 (85.6250) gate/entropy 1.0945 (1.0956) gate/usage_max 0.3740 (0.3678) gate/usage_min 0.3004 (0.3057) gate/usage_std 0.0305 (0.0258) teacher/entropy 0.1585 (0.1643) teacher/usage_max 0.7048 (0.6976) teacher/usage_min 0.0197 (0.0283) teacher/usage_std 0.2826 (0.2818) nleep/row_max_mean 1565.1440 (1577.2669) nleep/row_max_std 60.4623 (52.5374) nleep/row_min_mean 1552.0515 (1561.5143) lr 1.9980e-03 eta 0:16:18
epoch [3/50] batch [80/167] time 0.086 (0.123) data 0.000 (0.003) loss 1.3881 (1.5091) teacher_loss 0.3063 (0.3775) loss_zs_kd 0.0112 (0.0093) loss_oracle 0.4368 (0.5087) kd_loss 0.8578 (0.8727) acc 90.6250 (85.5859) gate/entropy 1.0933 (1.0952) gate/usage_max 0.3795 (0.3701) gate/usage_min 0.2970 (0.3040) gate/usage_std 0.0344 (0.0275) teacher/entropy 0.1472 (0.1593) teacher/usage_max 0.7887 (0.7141) teacher/usage_min 0.0350 (0.0339) teacher/usage_std 0.3271 (0.2889) nleep/row_max_mean 1589.1459 (1576.0630) nleep/row_max_std 46.3098 (52.4911) nleep/row_min_mean 1573.7726 (1560.1273) lr 1.9980e-03 eta 0:16:14
epoch [3/50] batch [100/167] time 0.167 (0.123) data 0.000 (0.002) loss 1.3372 (1.4997) teacher_loss 0.1710 (0.3735) loss_zs_kd 0.0042 (0.0093) loss_oracle 0.5269 (0.5060) kd_loss 0.9007 (0.8685) acc 93.7500 (86.0938) gate/entropy 1.0921 (1.0947) gate/usage_max 0.3851 (0.3725) gate/usage_min 0.2939 (0.3022) gate/usage_std 0.0382 (0.0293) teacher/entropy 0.0734 (0.1580) teacher/usage_max 0.9159 (0.7272) teacher/usage_min 0.0300 (0.0419) teacher/usage_std 0.4120 (0.2947) nleep/row_max_mean 1585.2314 (1575.9832) nleep/row_max_std 43.0884 (52.7760) nleep/row_min_mean 1566.3689 (1559.9421) lr 1.9980e-03 eta 0:16:16
epoch [3/50] batch [120/167] time 0.092 (0.123) data 0.000 (0.002) loss 1.3671 (1.4894) teacher_loss 0.3072 (0.3699) loss_zs_kd 0.0036 (0.0092) loss_oracle 0.4663 (0.5021) kd_loss 0.8249 (0.8638) acc 84.3750 (86.1458) gate/entropy 1.0908 (1.0942) gate/usage_max 0.3907 (0.3751) gate/usage_min 0.2913 (0.3006) gate/usage_std 0.0420 (0.0311) teacher/entropy 0.1537 (0.1577) teacher/usage_max 0.8394 (0.7377) teacher/usage_min 0.0727 (0.0484) teacher/usage_std 0.3579 (0.2996) nleep/row_max_mean 1586.4075 (1576.1123) nleep/row_max_std 42.7748 (53.4856) nleep/row_min_mean 1569.2478 (1559.9508) lr 1.9980e-03 eta 0:16:09
epoch [3/50] batch [140/167] time 0.152 (0.125) data 0.000 (0.002) loss 1.3478 (1.4938) teacher_loss 0.2220 (0.3735) loss_zs_kd 0.0044 (0.0092) loss_oracle 0.4903 (0.5065) kd_loss 0.8784 (0.8624) acc 87.5000 (86.1607) gate/entropy 1.0893 (1.0936) gate/usage_max 0.3967 (0.3778) gate/usage_min 0.2888 (0.2991) gate/usage_std 0.0460 (0.0329) teacher/entropy 0.1297 (0.1542) teacher/usage_max 0.7224 (0.7467) teacher/usage_min 0.0413 (0.0488) teacher/usage_std 0.2864 (0.3045) nleep/row_max_mean 1571.0732 (1575.7546) nleep/row_max_std 58.6041 (53.8359) nleep/row_min_mean 1553.7854 (1559.4773) lr 1.9980e-03 eta 0:16:26
epoch [3/50] batch [160/167] time 0.155 (0.129) data 0.000 (0.002) loss 1.4475 (1.4969) teacher_loss 0.3193 (0.3738) loss_zs_kd 0.0053 (0.0088) loss_oracle 0.6028 (0.5139) kd_loss 0.8242 (0.8617) acc 90.6250 (86.1523) gate/entropy 1.0876 (1.0929) gate/usage_max 0.4029 (0.3805) gate/usage_min 0.2865 (0.2976) gate/usage_std 0.0501 (0.0349) teacher/entropy 0.1675 (0.1500) teacher/usage_max 0.7480 (0.7537) teacher/usage_min 0.0255 (0.0477) teacher/usage_std 0.3045 (0.3087) nleep/row_max_mean 1576.4528 (1575.9831) nleep/row_max_std 66.6845 (54.2662) nleep/row_min_mean 1558.4454 (1559.3351) lr 1.9980e-03 eta 0:16:52
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,187
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain c best val acc:      95.2%, epoch: 3 *******
******* Domain c best val test acc: 99.2%, epoch: 3 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [4/50] batch [20/167] time 0.173 (0.179) data 0.000 (0.015) loss 1.2679 (1.5095) teacher_loss 0.1100 (0.3462) loss_zs_kd 0.0081 (0.0097) loss_oracle 0.5936 (0.5805) kd_loss 0.8571 (0.8682) acc 96.8750 (86.5625) gate/entropy 1.0851 (1.0859) gate/usage_max 0.4110 (0.4084) gate/usage_min 0.2835 (0.2845) gate/usage_std 0.0556 (0.0539) teacher/entropy 0.0864 (0.0962) teacher/usage_max 0.8485 (0.8028) teacher/usage_min 0.0176 (0.0200) teacher/usage_std 0.3674 (0.3387) nleep/row_max_mean 1570.4839 (1576.9496) nleep/row_max_std 47.1457 (56.3393) nleep/row_min_mean 1547.5178 (1555.6231) lr 1.9921e-03 eta 0:23:21
epoch [4/50] batch [40/167] time 0.154 (0.167) data 0.000 (0.008) loss 1.6300 (1.5205) teacher_loss 0.5270 (0.3644) loss_zs_kd 0.0081 (0.0094) loss_oracle 0.5745 (0.5773) kd_loss 0.8117 (0.8628) acc 81.2500 (86.1719) gate/entropy 1.0830 (1.0850) gate/usage_max 0.4171 (0.4113) gate/usage_min 0.2815 (0.2835) gate/usage_std 0.0598 (0.0558) teacher/entropy 0.1406 (0.1027) teacher/usage_max 0.7949 (0.7855) teacher/usage_min 0.0161 (0.0230) teacher/usage_std 0.3339 (0.3287) nleep/row_max_mean 1566.0973 (1573.0490) nleep/row_max_std 62.0133 (55.1077) nleep/row_min_mean 1546.2629 (1552.4398) lr 1.9921e-03 eta 0:21:47
epoch [4/50] batch [60/167] time 0.088 (0.162) data 0.001 (0.005) loss 1.5625 (1.5099) teacher_loss 0.4166 (0.3502) loss_zs_kd 0.0053 (0.0087) loss_oracle 0.5605 (0.5756) kd_loss 0.8631 (0.8676) acc 84.3750 (86.8229) gate/entropy 1.0812 (1.0840) gate/usage_max 0.4222 (0.4141) gate/usage_min 0.2799 (0.2825) gate/usage_std 0.0633 (0.0578) teacher/entropy 0.1516 (0.1054) teacher/usage_max 0.6228 (0.7555) teacher/usage_min 0.0253 (0.0230) teacher/usage_std 0.2443 (0.3129) nleep/row_max_mean 1555.2454 (1571.3944) nleep/row_max_std 49.9333 (54.6538) nleep/row_min_mean 1539.1566 (1551.5862) lr 1.9921e-03 eta 0:21:01
epoch [4/50] batch [80/167] time 0.132 (0.153) data 0.000 (0.004) loss 1.5824 (1.5396) teacher_loss 0.3189 (0.3596) loss_zs_kd 0.0085 (0.0086) loss_oracle 0.5686 (0.5814) kd_loss 0.9749 (0.8850) acc 90.6250 (86.1719) gate/entropy 1.0796 (1.0831) gate/usage_max 0.4265 (0.4167) gate/usage_min 0.2790 (0.2818) gate/usage_std 0.0662 (0.0595) teacher/entropy 0.0544 (0.0992) teacher/usage_max 0.5795 (0.7246) teacher/usage_min 0.0015 (0.0207) teacher/usage_std 0.2436 (0.2984) nleep/row_max_mean 1569.1858 (1569.6995) nleep/row_max_std 46.0217 (53.1837) nleep/row_min_mean 1551.3608 (1550.1850) lr 1.9921e-03 eta 0:19:48
epoch [4/50] batch [100/167] time 0.151 (0.144) data 0.000 (0.003) loss 1.6532 (1.5527) teacher_loss 0.3427 (0.3540) loss_zs_kd 0.0098 (0.0093) loss_oracle 0.6928 (0.5884) kd_loss 0.9592 (0.8999) acc 90.6250 (86.3750) gate/entropy 1.0782 (1.0823) gate/usage_max 0.4301 (0.4190) gate/usage_min 0.2787 (0.2812) gate/usage_std 0.0686 (0.0611) teacher/entropy 0.0530 (0.0923) teacher/usage_max 0.6066 (0.6965) teacher/usage_min 0.0028 (0.0179) teacher/usage_std 0.2498 (0.2877) nleep/row_max_mean 1573.4418 (1567.9750) nleep/row_max_std 52.1979 (52.3318) nleep/row_min_mean 1553.4562 (1548.4947) lr 1.9921e-03 eta 0:18:35
epoch [4/50] batch [120/167] time 0.082 (0.139) data 0.000 (0.003) loss 1.6175 (1.5636) teacher_loss 0.3372 (0.3558) loss_zs_kd 0.0197 (0.0095) loss_oracle 0.5356 (0.5845) kd_loss 1.0026 (0.9107) acc 84.3750 (86.2500) gate/entropy 1.0771 (1.0815) gate/usage_max 0.4329 (0.4211) gate/usage_min 0.2789 (0.2808) gate/usage_std 0.0705 (0.0625) teacher/entropy 0.0545 (0.0868) teacher/usage_max 0.5036 (0.6784) teacher/usage_min 0.0014 (0.0154) teacher/usage_std 0.2347 (0.2817) nleep/row_max_mean 1552.4091 (1567.8963) nleep/row_max_std 50.3716 (51.6783) nleep/row_min_mean 1532.2661 (1548.3079) lr 1.9921e-03 eta 0:17:55
epoch [4/50] batch [140/167] time 0.087 (0.136) data 0.000 (0.002) loss 1.4600 (1.5657) teacher_loss 0.2016 (0.3485) loss_zs_kd 0.0063 (0.0101) loss_oracle 0.6538 (0.5820) kd_loss 0.9284 (0.9212) acc 93.7500 (86.4955) gate/entropy 1.0759 (1.0808) gate/usage_max 0.4358 (0.4230) gate/usage_min 0.2794 (0.2806) gate/usage_std 0.0725 (0.0638) teacher/entropy 0.0667 (0.0826) teacher/usage_max 0.6249 (0.6640) teacher/usage_min 0.0000 (0.0134) teacher/usage_std 0.2568 (0.2766) nleep/row_max_mean 1573.1423 (1567.6926) nleep/row_max_std 51.2338 (51.3129) nleep/row_min_mean 1549.3975 (1547.7596) lr 1.9921e-03 eta 0:17:24
epoch [4/50] batch [160/167] time 0.080 (0.131) data 0.000 (0.002) loss 1.5068 (1.5695) teacher_loss 0.3179 (0.3479) loss_zs_kd 0.0174 (0.0107) loss_oracle 0.4257 (0.5698) kd_loss 0.9674 (0.9313) acc 84.3750 (86.6797) gate/entropy 1.0755 (1.0801) gate/usage_max 0.4368 (0.4247) gate/usage_min 0.2809 (0.2805) gate/usage_std 0.0731 (0.0649) teacher/entropy 0.1130 (0.0837) teacher/usage_max 0.5759 (0.6608) teacher/usage_min 0.0000 (0.0118) teacher/usage_std 0.2437 (0.2753) nleep/row_max_mean 1568.7979 (1566.8587) nleep/row_max_std 67.9722 (52.0623) nleep/row_min_mean 1542.3440 (1546.5087) lr 1.9921e-03 eta 0:16:47
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.0%, epoch: 4 *******
******* Domain c best val test acc: 99.2%, epoch: 4 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [5/50] batch [20/167] time 0.158 (0.132) data 0.000 (0.015) loss 1.6723 (1.6057) teacher_loss 0.4085 (0.3145) loss_zs_kd 0.0135 (0.0152) loss_oracle 0.4262 (0.4753) kd_loss 1.0439 (1.0460) acc 84.3750 (87.9688) gate/entropy 1.0758 (1.0759) gate/usage_max 0.4360 (0.4360) gate/usage_min 0.2786 (0.2801) gate/usage_std 0.0727 (0.0726) teacher/entropy 0.1196 (0.1006) teacher/usage_max 0.7882 (0.7385) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3331 (0.3060) nleep/row_max_mean 1592.4290 (1570.7668) nleep/row_max_std 57.4975 (57.4160) nleep/row_min_mean 1562.2163 (1543.3708) lr 1.9823e-03 eta 0:16:51
epoch [5/50] batch [40/167] time 0.149 (0.140) data 0.000 (0.007) loss 1.7388 (1.6120) teacher_loss 0.3900 (0.2955) loss_zs_kd 0.0262 (0.0162) loss_oracle 0.5077 (0.4950) kd_loss 1.0818 (1.0609) acc 87.5000 (88.8281) gate/entropy 1.0766 (1.0761) gate/usage_max 0.4340 (0.4352) gate/usage_min 0.2767 (0.2790) gate/usage_std 0.0714 (0.0721) teacher/entropy 0.0618 (0.0892) teacher/usage_max 0.7642 (0.7584) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3195 (0.3182) nleep/row_max_mean 1571.7246 (1569.6177) nleep/row_max_std 58.6979 (59.2196) nleep/row_min_mean 1542.3934 (1542.0888) lr 1.9823e-03 eta 0:17:47
epoch [5/50] batch [60/167] time 0.151 (0.142) data 0.000 (0.005) loss 1.5465 (1.6079) teacher_loss 0.2557 (0.2907) loss_zs_kd 0.0293 (0.0176) loss_oracle 0.5907 (0.5013) kd_loss 0.9808 (1.0578) acc 93.7500 (89.5833) gate/entropy 1.0772 (1.0764) gate/usage_max 0.4321 (0.4345) gate/usage_min 0.2748 (0.2779) gate/usage_std 0.0702 (0.0717) teacher/entropy 0.1508 (0.0906) teacher/usage_max 0.7561 (0.7649) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3151 (0.3221) nleep/row_max_mean 1563.9512 (1569.7948) nleep/row_max_std 52.8374 (59.6535) nleep/row_min_mean 1537.5190 (1542.6438) lr 1.9823e-03 eta 0:18:03
epoch [5/50] batch [80/167] time 0.157 (0.143) data 0.000 (0.004) loss 1.7873 (1.6221) teacher_loss 0.5151 (0.2993) loss_zs_kd 0.0124 (0.0177) loss_oracle 0.5600 (0.5235) kd_loss 0.9861 (1.0522) acc 75.0000 (89.2969) gate/entropy 1.0773 (1.0766) gate/usage_max 0.4314 (0.4338) gate/usage_min 0.2724 (0.2768) gate/usage_std 0.0700 (0.0713) teacher/entropy 0.1330 (0.0908) teacher/usage_max 0.7381 (0.7620) teacher/usage_min 0.0016 (0.0010) teacher/usage_std 0.3051 (0.3205) nleep/row_max_mean 1568.5231 (1567.6913) nleep/row_max_std 49.5334 (59.2889) nleep/row_min_mean 1546.4038 (1541.3438) lr 1.9823e-03 eta 0:18:07
epoch [5/50] batch [100/167] time 0.130 (0.144) data 0.000 (0.003) loss 1.5891 (1.6327) teacher_loss 0.2169 (0.3063) loss_zs_kd 0.0219 (0.0179) loss_oracle 0.6512 (0.5419) kd_loss 1.0356 (1.0465) acc 93.7500 (89.0000) gate/entropy 1.0778 (1.0768) gate/usage_max 0.4297 (0.4331) gate/usage_min 0.2710 (0.2758) gate/usage_std 0.0691 (0.0709) teacher/entropy 0.1021 (0.0879) teacher/usage_max 0.7558 (0.7476) teacher/usage_min 0.0453 (0.0026) teacher/usage_std 0.3052 (0.3132) nleep/row_max_mean 1543.8324 (1565.5937) nleep/row_max_std 70.1222 (58.6974) nleep/row_min_mean 1524.8474 (1540.0215) lr 1.9823e-03 eta 0:18:11
epoch [5/50] batch [120/167] time 0.152 (0.144) data 0.001 (0.003) loss 1.4616 (1.6248) teacher_loss 0.2229 (0.3041) loss_zs_kd 0.0289 (0.0188) loss_oracle 0.6761 (0.5592) kd_loss 0.8862 (1.0317) acc 90.6250 (89.0885) gate/entropy 1.0775 (1.0770) gate/usage_max 0.4299 (0.4326) gate/usage_min 0.2688 (0.2748) gate/usage_std 0.0696 (0.0707) teacher/entropy 0.1528 (0.0929) teacher/usage_max 0.5181 (0.7274) teacher/usage_min 0.0261 (0.0053) teacher/usage_std 0.2187 (0.3035) nleep/row_max_mean 1557.5017 (1563.8595) nleep/row_max_std 64.9391 (58.3159) nleep/row_min_mean 1537.7037 (1539.2453) lr 1.9823e-03 eta 0:18:05
epoch [5/50] batch [140/167] time 0.157 (0.145) data 0.000 (0.002) loss 1.6021 (1.6146) teacher_loss 0.4046 (0.3036) loss_zs_kd 0.0195 (0.0187) loss_oracle 0.6760 (0.5746) kd_loss 0.8498 (1.0144) acc 90.6250 (89.1295) gate/entropy 1.0768 (1.0770) gate/usage_max 0.4311 (0.4322) gate/usage_min 0.2665 (0.2738) gate/usage_std 0.0706 (0.0706) teacher/entropy 0.2111 (0.0988) teacher/usage_max 0.5283 (0.7038) teacher/usage_min 0.0710 (0.0093) teacher/usage_std 0.1927 (0.2921) nleep/row_max_mean 1560.5369 (1562.7207) nleep/row_max_std 49.4599 (57.9319) nleep/row_min_mean 1541.2175 (1538.9142) lr 1.9823e-03 eta 0:18:12
epoch [5/50] batch [160/167] time 0.135 (0.145) data 0.000 (0.002) loss 1.4339 (1.6026) teacher_loss 0.1728 (0.3028) loss_zs_kd 0.0084 (0.0186) loss_oracle 0.7585 (0.5904) kd_loss 0.8777 (0.9953) acc 93.7500 (89.0039) gate/entropy 1.0759 (1.0769) gate/usage_max 0.4330 (0.4322) gate/usage_min 0.2647 (0.2728) gate/usage_std 0.0721 (0.0706) teacher/entropy 0.1031 (0.1065) teacher/usage_max 0.6267 (0.6840) teacher/usage_min 0.0872 (0.0191) teacher/usage_std 0.2227 (0.2799) nleep/row_max_mean 1570.2600 (1561.6609) nleep/row_max_std 49.2883 (57.5287) nleep/row_min_mean 1549.8599 (1538.5398) lr 1.9823e-03 eta 0:18:11
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.0%, epoch: 4 *******
******* Domain c best val test acc: 99.2%, epoch: 4 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [6/50] batch [20/167] time 0.070 (0.129) data 0.000 (0.013) loss 1.6554 (1.5149) teacher_loss 0.4334 (0.3325) loss_zs_kd 0.0237 (0.0177) loss_oracle 0.7521 (0.6824) kd_loss 0.8342 (0.8324) acc 87.5000 (87.1875) gate/entropy 1.0744 (1.0750) gate/usage_max 0.4364 (0.4350) gate/usage_min 0.2630 (0.2637) gate/usage_std 0.0744 (0.0735) teacher/entropy 0.1294 (0.1462) teacher/usage_max 0.6851 (0.6349) teacher/usage_min 0.1560 (0.1028) teacher/usage_std 0.2488 (0.2270) nleep/row_max_mean 1557.3606 (1559.5335) nleep/row_max_std 64.7760 (55.4000) nleep/row_min_mean 1537.6149 (1540.8969) lr 1.9686e-03 eta 0:16:08
epoch [6/50] batch [40/167] time 0.155 (0.121) data 0.000 (0.007) loss 1.4065 (1.4824) teacher_loss 0.2902 (0.3184) loss_zs_kd 0.0130 (0.0157) loss_oracle 0.6808 (0.6620) kd_loss 0.7694 (0.8251) acc 87.5000 (87.6562) gate/entropy 1.0728 (1.0743) gate/usage_max 0.4401 (0.4366) gate/usage_min 0.2617 (0.2631) gate/usage_std 0.0770 (0.0746) teacher/entropy 0.1914 (0.1546) teacher/usage_max 0.6892 (0.6351) teacher/usage_min 0.1515 (0.1202) teacher/usage_std 0.2516 (0.2225) nleep/row_max_mean 1567.8279 (1555.8280) nleep/row_max_std 64.4101 (58.0137) nleep/row_min_mean 1546.6691 (1537.3496) lr 1.9686e-03 eta 0:15:03
epoch [6/50] batch [60/167] time 0.072 (0.109) data 0.001 (0.005) loss 1.5074 (1.4984) teacher_loss 0.3252 (0.3227) loss_zs_kd 0.0203 (0.0177) loss_oracle 0.6785 (0.6812) kd_loss 0.8328 (0.8263) acc 90.6250 (87.3958) gate/entropy 1.0713 (1.0736) gate/usage_max 0.4437 (0.4384) gate/usage_min 0.2610 (0.2624) gate/usage_std 0.0793 (0.0758) teacher/entropy 0.1470 (0.1464) teacher/usage_max 0.6469 (0.6542) teacher/usage_min 0.1565 (0.1197) teacher/usage_std 0.2223 (0.2340) nleep/row_max_mean 1557.7612 (1557.6583) nleep/row_max_std 51.9024 (57.3590) nleep/row_min_mean 1538.0891 (1538.1128) lr 1.9686e-03 eta 0:13:32
epoch [6/50] batch [80/167] time 0.099 (0.107) data 0.000 (0.003) loss 1.4565 (1.4882) teacher_loss 0.2300 (0.3109) loss_zs_kd 0.0193 (0.0174) loss_oracle 0.6950 (0.6909) kd_loss 0.8693 (0.8231) acc 90.6250 (87.9297) gate/entropy 1.0696 (1.0727) gate/usage_max 0.4476 (0.4404) gate/usage_min 0.2601 (0.2619) gate/usage_std 0.0819 (0.0771) teacher/entropy 0.1022 (0.1438) teacher/usage_max 0.6603 (0.6660) teacher/usage_min 0.1270 (0.1190) teacher/usage_std 0.2339 (0.2411) nleep/row_max_mean 1545.4814 (1557.7245) nleep/row_max_std 54.9392 (56.0285) nleep/row_min_mean 1524.8301 (1537.7459) lr 1.9686e-03 eta 0:13:18
epoch [6/50] batch [100/167] time 0.188 (0.112) data 0.000 (0.003) loss 1.4992 (1.4911) teacher_loss 0.3396 (0.3132) loss_zs_kd 0.0207 (0.0177) loss_oracle 0.7389 (0.6961) kd_loss 0.7799 (0.8211) acc 84.3750 (87.7188) gate/entropy 1.0671 (1.0718) gate/usage_max 0.4528 (0.4425) gate/usage_min 0.2585 (0.2613) gate/usage_std 0.0854 (0.0785) teacher/entropy 0.2090 (0.1401) teacher/usage_max 0.6157 (0.6756) teacher/usage_min 0.1591 (0.1169) teacher/usage_std 0.2015 (0.2473) nleep/row_max_mean 1562.6288 (1557.3996) nleep/row_max_std 35.0151 (54.6244) nleep/row_min_mean 1542.0663 (1537.2984) lr 1.9686e-03 eta 0:13:50
epoch [6/50] batch [120/167] time 0.167 (0.112) data 0.000 (0.002) loss 1.6364 (1.5004) teacher_loss 0.5055 (0.3218) loss_zs_kd 0.0117 (0.0178) loss_oracle 0.6541 (0.6967) kd_loss 0.7980 (0.8213) acc 78.1250 (87.2396) gate/entropy 1.0650 (1.0708) gate/usage_max 0.4571 (0.4446) gate/usage_min 0.2574 (0.2607) gate/usage_std 0.0883 (0.0799) teacher/entropy 0.1037 (0.1371) teacher/usage_max 0.7677 (0.6789) teacher/usage_min 0.1107 (0.1157) teacher/usage_std 0.3072 (0.2495) nleep/row_max_mean 1554.7294 (1556.8928) nleep/row_max_std 56.1238 (54.7188) nleep/row_min_mean 1530.9200 (1536.5486) lr 1.9686e-03 eta 0:13:46
epoch [6/50] batch [140/167] time 0.105 (0.112) data 0.000 (0.002) loss 1.4560 (1.4957) teacher_loss 0.3065 (0.3200) loss_zs_kd 0.0185 (0.0178) loss_oracle 0.6055 (0.6876) kd_loss 0.8375 (0.8230) acc 87.5000 (87.4554) gate/entropy 1.0637 (1.0699) gate/usage_max 0.4600 (0.4466) gate/usage_min 0.2574 (0.2603) gate/usage_std 0.0901 (0.0812) teacher/entropy 0.1928 (0.1362) teacher/usage_max 0.5374 (0.6756) teacher/usage_min 0.1203 (0.1157) teacher/usage_std 0.1704 (0.2474) nleep/row_max_mean 1553.2982 (1556.4361) nleep/row_max_std 46.1967 (54.9263) nleep/row_min_mean 1534.6411 (1535.9926) lr 1.9686e-03 eta 0:13:42
epoch [6/50] batch [160/167] time 0.149 (0.112) data 0.000 (0.002) loss 1.4734 (1.4953) teacher_loss 0.1576 (0.3174) loss_zs_kd 0.0083 (0.0179) loss_oracle 0.7055 (0.6835) kd_loss 0.9590 (0.8272) acc 96.8750 (87.6367) gate/entropy 1.0623 (1.0690) gate/usage_max 0.4627 (0.4485) gate/usage_min 0.2574 (0.2599) gate/usage_std 0.0920 (0.0825) teacher/entropy 0.1172 (0.1346) teacher/usage_max 0.4544 (0.6688) teacher/usage_min 0.1329 (0.1159) teacher/usage_std 0.1428 (0.2434) nleep/row_max_mean 1557.9498 (1556.3238) nleep/row_max_std 38.0332 (55.4355) nleep/row_min_mean 1540.3118 (1535.8016) lr 1.9686e-03 eta 0:13:44
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,213
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [7/50] batch [20/167] time 0.129 (0.160) data 0.000 (0.013) loss 1.3350 (1.4782) teacher_loss 0.1533 (0.2927) loss_zs_kd 0.0174 (0.0174) loss_oracle 0.5642 (0.6301) kd_loss 0.8909 (0.8617) acc 93.7500 (89.6875) gate/entropy 1.0603 (1.0609) gate/usage_max 0.4665 (0.4654) gate/usage_min 0.2572 (0.2572) gate/usage_std 0.0945 (0.0937) teacher/entropy 0.1446 (0.1439) teacher/usage_max 0.5085 (0.5661) teacher/usage_min 0.2421 (0.1572) teacher/usage_std 0.1239 (0.1741) nleep/row_max_mean 1554.1444 (1555.1655) nleep/row_max_std 51.7790 (57.7979) nleep/row_min_mean 1533.2539 (1535.1029) lr 1.9511e-03 eta 0:19:30
epoch [7/50] batch [40/167] time 0.148 (0.147) data 0.000 (0.007) loss 1.4172 (1.4836) teacher_loss 0.1674 (0.2838) loss_zs_kd 0.0073 (0.0198) loss_oracle 0.6307 (0.6349) kd_loss 0.9308 (0.8725) acc 90.6250 (90.0781) gate/entropy 1.0593 (1.0604) gate/usage_max 0.4685 (0.4665) gate/usage_min 0.2571 (0.2572) gate/usage_std 0.0959 (0.0945) teacher/entropy 0.1321 (0.1403) teacher/usage_max 0.4613 (0.5536) teacher/usage_min 0.2260 (0.1738) teacher/usage_std 0.0972 (0.1639) nleep/row_max_mean 1553.1536 (1552.2778) nleep/row_max_std 58.3160 (58.1363) nleep/row_min_mean 1534.0129 (1532.9927) lr 1.9511e-03 eta 0:17:55
epoch [7/50] batch [60/167] time 0.123 (0.143) data 0.001 (0.005) loss 1.5855 (1.5009) teacher_loss 0.3372 (0.2811) loss_zs_kd 0.0229 (0.0204) loss_oracle 0.6208 (0.6403) kd_loss 0.9264 (0.8895) acc 87.5000 (89.7917) gate/entropy 1.0585 (1.0599) gate/usage_max 0.4699 (0.4674) gate/usage_min 0.2572 (0.2572) gate/usage_std 0.0968 (0.0951) teacher/entropy 0.1405 (0.1411) teacher/usage_max 0.4351 (0.5232) teacher/usage_min 0.1405 (0.1899) teacher/usage_std 0.1364 (0.1441) nleep/row_max_mean 1543.5142 (1549.8835) nleep/row_max_std 64.5449 (56.9092) nleep/row_min_mean 1523.8091 (1531.2699) lr 1.9511e-03 eta 0:17:20
epoch [7/50] batch [80/167] time 0.166 (0.145) data 0.000 (0.003) loss 1.4453 (1.5124) teacher_loss 0.2510 (0.2909) loss_zs_kd 0.0139 (0.0228) loss_oracle 0.5899 (0.6301) kd_loss 0.8924 (0.8951) acc 87.5000 (89.7266) gate/entropy 1.0582 (1.0595) gate/usage_max 0.4705 (0.4681) gate/usage_min 0.2573 (0.2572) gate/usage_std 0.0972 (0.0956) teacher/entropy 0.1798 (0.1377) teacher/usage_max 0.4455 (0.5174) teacher/usage_min 0.2227 (0.1929) teacher/usage_std 0.0910 (0.1398) nleep/row_max_mean 1540.1891 (1550.7067) nleep/row_max_std 57.6363 (55.8178) nleep/row_min_mean 1525.4012 (1532.3093) lr 1.9511e-03 eta 0:17:30
epoch [7/50] batch [100/167] time 0.073 (0.145) data 0.000 (0.003) loss 1.5623 (1.5063) teacher_loss 0.4115 (0.2852) loss_zs_kd 0.0209 (0.0232) loss_oracle 0.5656 (0.6243) kd_loss 0.8575 (0.8974) acc 78.1250 (89.8438) gate/entropy 1.0565 (1.0590) gate/usage_max 0.4734 (0.4689) gate/usage_min 0.2559 (0.2571) gate/usage_std 0.0993 (0.0961) teacher/entropy 0.0844 (0.1330) teacher/usage_max 0.6579 (0.5197) teacher/usage_min 0.0745 (0.1868) teacher/usage_std 0.2427 (0.1428) nleep/row_max_mean 1552.1833 (1550.8519) nleep/row_max_std 57.8982 (56.3772) nleep/row_min_mean 1533.5120 (1532.3735) lr 1.9511e-03 eta 0:17:29
epoch [7/50] batch [120/167] time 0.196 (0.138) data 0.000 (0.002) loss 1.7210 (1.5018) teacher_loss 0.4857 (0.2827) loss_zs_kd 0.0489 (0.0249) loss_oracle 0.6448 (0.6214) kd_loss 0.8884 (0.8959) acc 87.5000 (89.6875) gate/entropy 1.0563 (1.0586) gate/usage_max 0.4738 (0.4696) gate/usage_min 0.2558 (0.2569) gate/usage_std 0.0995 (0.0966) teacher/entropy 0.0657 (0.1296) teacher/usage_max 0.6341 (0.5269) teacher/usage_min 0.0607 (0.1766) teacher/usage_std 0.2349 (0.1500) nleep/row_max_mean 1551.7600 (1551.3706) nleep/row_max_std 52.4827 (56.5748) nleep/row_min_mean 1528.6263 (1532.5655) lr 1.9511e-03 eta 0:16:38
epoch [7/50] batch [140/167] time 0.086 (0.135) data 0.000 (0.002) loss 1.3766 (1.5016) teacher_loss 0.1970 (0.2838) loss_zs_kd 0.0513 (0.0252) loss_oracle 0.6662 (0.6221) kd_loss 0.8208 (0.8941) acc 96.8750 (89.5312) gate/entropy 1.0550 (1.0581) gate/usage_max 0.4760 (0.4705) gate/usage_min 0.2546 (0.2566) gate/usage_std 0.1011 (0.0972) teacher/entropy 0.1983 (0.1247) teacher/usage_max 0.5312 (0.5367) teacher/usage_min 0.1944 (0.1678) teacher/usage_std 0.1437 (0.1575) nleep/row_max_mean 1544.6429 (1552.5524) nleep/row_max_std 60.0498 (56.8629) nleep/row_min_mean 1525.2244 (1533.2847) lr 1.9511e-03 eta 0:16:11
epoch [7/50] batch [160/167] time 0.180 (0.132) data 0.000 (0.002) loss 1.3022 (1.4964) teacher_loss 0.1149 (0.2793) loss_zs_kd 0.0231 (0.0262) loss_oracle 0.6267 (0.6234) kd_loss 0.8625 (0.8923) acc 96.8750 (89.7852) gate/entropy 1.0535 (1.0576) gate/usage_max 0.4785 (0.4714) gate/usage_min 0.2530 (0.2562) gate/usage_std 0.1028 (0.0979) teacher/entropy 0.0825 (0.1206) teacher/usage_max 0.6458 (0.5449) teacher/usage_min 0.0515 (0.1580) teacher/usage_std 0.2436 (0.1646) nleep/row_max_mean 1554.0198 (1553.5064) nleep/row_max_std 70.4771 (57.3610) nleep/row_min_mean 1527.6699 (1533.6773) lr 1.9511e-03 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,210
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [8/50] batch [20/167] time 0.087 (0.115) data 0.000 (0.012) loss 1.3989 (1.4314) teacher_loss 0.2182 (0.2268) loss_zs_kd 0.0182 (0.0278) loss_oracle 0.5951 (0.5874) kd_loss 0.8740 (0.8970) acc 90.6250 (91.5625) gate/entropy 1.0513 (1.0520) gate/usage_max 0.4820 (0.4809) gate/usage_min 0.2508 (0.2515) gate/usage_std 0.1053 (0.1045) teacher/entropy 0.1225 (0.0810) teacher/usage_max 0.5562 (0.5903) teacher/usage_min 0.0957 (0.0884) teacher/usage_std 0.1883 (0.2094) nleep/row_max_mean 1550.5294 (1553.4613) nleep/row_max_std 54.4494 (58.0082) nleep/row_min_mean 1528.8245 (1530.7968) lr 1.9298e-03 eta 0:13:44
epoch [8/50] batch [40/167] time 0.097 (0.117) data 0.000 (0.006) loss 1.4840 (1.4322) teacher_loss 0.2597 (0.2261) loss_zs_kd 0.0238 (0.0297) loss_oracle 0.6078 (0.5836) kd_loss 0.9085 (0.8994) acc 93.7500 (91.4844) gate/entropy 1.0496 (1.0512) gate/usage_max 0.4847 (0.4821) gate/usage_min 0.2488 (0.2507) gate/usage_std 0.1072 (0.1054) teacher/entropy 0.0821 (0.0687) teacher/usage_max 0.5555 (0.6068) teacher/usage_min 0.0341 (0.0640) teacher/usage_std 0.2198 (0.2262) nleep/row_max_mean 1562.5933 (1554.1463) nleep/row_max_std 36.9208 (56.0802) nleep/row_min_mean 1538.0980 (1530.0229) lr 1.9298e-03 eta 0:13:53
epoch [8/50] batch [60/167] time 0.177 (0.123) data 0.001 (0.004) loss 1.4968 (1.4320) teacher_loss 0.2119 (0.2301) loss_zs_kd 0.0290 (0.0299) loss_oracle 0.5878 (0.5791) kd_loss 0.9765 (0.8973) acc 93.7500 (90.9896) gate/entropy 1.0481 (1.0504) gate/usage_max 0.4869 (0.4833) gate/usage_min 0.2471 (0.2498) gate/usage_std 0.1089 (0.1063) teacher/entropy 0.0821 (0.0633) teacher/usage_max 0.4748 (0.6155) teacher/usage_min 0.0794 (0.0532) teacher/usage_std 0.1799 (0.2345) nleep/row_max_mean 1550.6465 (1553.9955) nleep/row_max_std 42.6908 (55.1076) nleep/row_min_mean 1530.1129 (1529.4246) lr 1.9298e-03 eta 0:14:36
epoch [8/50] batch [80/167] time 0.107 (0.117) data 0.000 (0.003) loss 1.3055 (1.4417) teacher_loss 0.1524 (0.2463) loss_zs_kd 0.0318 (0.0292) loss_oracle 0.6318 (0.5828) kd_loss 0.8213 (0.8895) acc 93.7500 (90.2344) gate/entropy 1.0466 (1.0496) gate/usage_max 0.4891 (0.4845) gate/usage_min 0.2454 (0.2489) gate/usage_std 0.1104 (0.1071) teacher/entropy 0.0801 (0.0641) teacher/usage_max 0.7023 (0.6243) teacher/usage_min 0.0334 (0.0487) teacher/usage_std 0.2774 (0.2398) nleep/row_max_mean 1561.3596 (1554.5452) nleep/row_max_std 45.1299 (54.3310) nleep/row_min_mean 1534.8933 (1529.6470) lr 1.9298e-03 eta 0:13:48
epoch [8/50] batch [100/167] time 0.176 (0.116) data 0.000 (0.003) loss 1.3419 (1.4529) teacher_loss 0.2000 (0.2561) loss_zs_kd 0.0214 (0.0298) loss_oracle 0.5520 (0.5833) kd_loss 0.8553 (0.8902) acc 87.5000 (89.7812) gate/entropy 1.0450 (1.0488) gate/usage_max 0.4916 (0.4857) gate/usage_min 0.2437 (0.2480) gate/usage_std 0.1122 (0.1080) teacher/entropy 0.0353 (0.0593) teacher/usage_max 0.7108 (0.6283) teacher/usage_min 0.0027 (0.0430) teacher/usage_std 0.2909 (0.2439) nleep/row_max_mean 1561.3269 (1555.9916) nleep/row_max_std 47.2783 (53.4859) nleep/row_min_mean 1533.8712 (1530.5737) lr 1.9298e-03 eta 0:13:43
epoch [8/50] batch [120/167] time 0.076 (0.116) data 0.000 (0.002) loss 1.3743 (1.4459) teacher_loss 0.2145 (0.2512) loss_zs_kd 0.0213 (0.0292) loss_oracle 0.6029 (0.5851) kd_loss 0.8477 (0.8875) acc 90.6250 (90.0260) gate/entropy 1.0441 (1.0480) gate/usage_max 0.4928 (0.4869) gate/usage_min 0.2426 (0.2471) gate/usage_std 0.1131 (0.1089) teacher/entropy 0.0567 (0.0607) teacher/usage_max 0.6833 (0.6282) teacher/usage_min 0.0019 (0.0411) teacher/usage_std 0.2785 (0.2452) nleep/row_max_mean 1543.1757 (1556.9033) nleep/row_max_std 41.1832 (52.4412) nleep/row_min_mean 1518.9823 (1531.2592) lr 1.9298e-03 eta 0:13:41
epoch [8/50] batch [140/167] time 0.088 (0.117) data 0.000 (0.002) loss 1.4277 (1.4368) teacher_loss 0.3434 (0.2456) loss_zs_kd 0.0379 (0.0301) loss_oracle 0.5275 (0.5867) kd_loss 0.8016 (0.8829) acc 81.2500 (90.2455) gate/entropy 1.0416 (1.0473) gate/usage_max 0.4965 (0.4880) gate/usage_min 0.2402 (0.2463) gate/usage_std 0.1158 (0.1097) teacher/entropy 0.0225 (0.0608) teacher/usage_max 0.8052 (0.6334) teacher/usage_min 0.0068 (0.0379) teacher/usage_std 0.3418 (0.2485) nleep/row_max_mean 1567.5621 (1557.2287) nleep/row_max_std 55.4592 (51.9633) nleep/row_min_mean 1538.6586 (1531.2279) lr 1.9298e-03 eta 0:13:41
epoch [8/50] batch [160/167] time 0.091 (0.117) data 0.000 (0.002) loss 1.5585 (1.4401) teacher_loss 0.2945 (0.2469) loss_zs_kd 0.0460 (0.0297) loss_oracle 0.5697 (0.5859) kd_loss 0.9561 (0.8854) acc 84.3750 (90.1953) gate/entropy 1.0409 (1.0466) gate/usage_max 0.4974 (0.4891) gate/usage_min 0.2391 (0.2455) gate/usage_std 0.1165 (0.1105) teacher/entropy 0.0317 (0.0581) teacher/usage_max 0.5438 (0.6318) teacher/usage_min 0.0199 (0.0362) teacher/usage_std 0.2259 (0.2487) nleep/row_max_mean 1563.9740 (1557.4525) nleep/row_max_std 55.2792 (52.0562) nleep/row_min_mean 1534.5171 (1531.1174) lr 1.9298e-03 eta 0:13:40
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,194
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [9/50] batch [20/167] time 0.151 (0.128) data 0.000 (0.016) loss 1.5192 (1.4975) teacher_loss 0.3062 (0.2845) loss_zs_kd 0.0620 (0.0329) loss_oracle 0.5845 (0.5831) kd_loss 0.8898 (0.9050) acc 90.6250 (89.0625) gate/entropy 1.0392 (1.0398) gate/usage_max 0.4997 (0.4989) gate/usage_min 0.2373 (0.2379) gate/usage_std 0.1181 (0.1175) teacher/entropy 0.0383 (0.0402) teacher/usage_max 0.6410 (0.6114) teacher/usage_min 0.0298 (0.0163) teacher/usage_std 0.2495 (0.2494) nleep/row_max_mean 1550.9026 (1559.1197) nleep/row_max_std 55.6404 (52.1811) nleep/row_min_mean 1522.1124 (1530.8812) lr 1.9048e-03 eta 0:14:52
epoch [9/50] batch [40/167] time 0.190 (0.149) data 0.000 (0.008) loss 1.5466 (1.4638) teacher_loss 0.2902 (0.2514) loss_zs_kd 0.0273 (0.0317) loss_oracle 0.6650 (0.5850) kd_loss 0.9102 (0.9040) acc 87.5000 (90.3906) gate/entropy 1.0392 (1.0394) gate/usage_max 0.4997 (0.4994) gate/usage_min 0.2367 (0.2374) gate/usage_std 0.1182 (0.1179) teacher/entropy 0.0509 (0.0415) teacher/usage_max 0.5893 (0.6138) teacher/usage_min 0.0662 (0.0191) teacher/usage_std 0.2137 (0.2490) nleep/row_max_mean 1548.6936 (1555.3932) nleep/row_max_std 47.1117 (53.1828) nleep/row_min_mean 1523.7854 (1528.0619) lr 1.9048e-03 eta 0:17:16
epoch [9/50] batch [60/167] time 0.147 (0.151) data 0.001 (0.005) loss 1.4949 (1.4581) teacher_loss 0.3285 (0.2504) loss_zs_kd 0.0425 (0.0319) loss_oracle 0.5587 (0.5846) kd_loss 0.8658 (0.8995) acc 84.3750 (90.3646) gate/entropy 1.0371 (1.0390) gate/usage_max 0.5027 (0.5000) gate/usage_min 0.2348 (0.2368) gate/usage_std 0.1203 (0.1184) teacher/entropy 0.0757 (0.0455) teacher/usage_max 0.6165 (0.6140) teacher/usage_min 0.0437 (0.0284) teacher/usage_std 0.2339 (0.2449) nleep/row_max_mean 1565.8831 (1555.2896) nleep/row_max_std 45.9996 (52.7871) nleep/row_min_mean 1539.1346 (1528.6405) lr 1.9048e-03 eta 0:17:31
epoch [9/50] batch [80/167] time 0.162 (0.153) data 0.000 (0.004) loss 1.3320 (1.4434) teacher_loss 0.2001 (0.2496) loss_zs_kd 0.0219 (0.0316) loss_oracle 0.5492 (0.5737) kd_loss 0.8464 (0.8911) acc 90.6250 (90.3906) gate/entropy 1.0369 (1.0385) gate/usage_max 0.5029 (0.5007) gate/usage_min 0.2345 (0.2363) gate/usage_std 0.1204 (0.1188) teacher/entropy 0.0651 (0.0486) teacher/usage_max 0.6713 (0.6229) teacher/usage_min 0.1016 (0.0330) teacher/usage_std 0.2444 (0.2466) nleep/row_max_mean 1553.9424 (1555.9643) nleep/row_max_std 50.4447 (52.7519) nleep/row_min_mean 1528.2899 (1529.1548) lr 1.9048e-03 eta 0:17:37
epoch [9/50] batch [100/167] time 0.163 (0.157) data 0.000 (0.003) loss 1.2979 (1.4412) teacher_loss 0.0674 (0.2512) loss_zs_kd 0.0304 (0.0323) loss_oracle 0.5240 (0.5618) kd_loss 0.9533 (0.8929) acc 100.0000 (90.1875) gate/entropy 1.0356 (1.0380) gate/usage_max 0.5046 (0.5014) gate/usage_min 0.2332 (0.2357) gate/usage_std 0.1217 (0.1193) teacher/entropy 0.0487 (0.0497) teacher/usage_max 0.5314 (0.6173) teacher/usage_min 0.0963 (0.0349) teacher/usage_std 0.1798 (0.2434) nleep/row_max_mean 1564.0814 (1556.8389) nleep/row_max_std 49.2861 (52.4130) nleep/row_min_mean 1535.1517 (1529.7887) lr 1.9048e-03 eta 0:18:03
epoch [9/50] batch [120/167] time 0.166 (0.159) data 0.000 (0.003) loss 1.3369 (1.4346) teacher_loss 0.1991 (0.2549) loss_zs_kd 0.0199 (0.0318) loss_oracle 0.4899 (0.5517) kd_loss 0.8829 (0.8880) acc 90.6250 (89.9479) gate/entropy 1.0342 (1.0375) gate/usage_max 0.5065 (0.5021) gate/usage_min 0.2318 (0.2352) gate/usage_std 0.1231 (0.1198) teacher/entropy 0.0468 (0.0512) teacher/usage_max 0.6241 (0.6219) teacher/usage_min 0.0182 (0.0361) teacher/usage_std 0.2479 (0.2445) nleep/row_max_mean 1570.8514 (1557.5781) nleep/row_max_std 51.0711 (52.0683) nleep/row_min_mean 1544.5623 (1530.4592) lr 1.9048e-03 eta 0:18:19
epoch [9/50] batch [140/167] time 0.159 (0.161) data 0.000 (0.002) loss 1.1280 (1.4246) teacher_loss 0.0654 (0.2512) loss_zs_kd 0.0058 (0.0315) loss_oracle 0.5879 (0.5477) kd_loss 0.7658 (0.8839) acc 96.8750 (90.2009) gate/entropy 1.0338 (1.0370) gate/usage_max 0.5071 (0.5027) gate/usage_min 0.2313 (0.2347) gate/usage_std 0.1235 (0.1203) teacher/entropy 0.0883 (0.0520) teacher/usage_max 0.7472 (0.6261) teacher/usage_min 0.0618 (0.0377) teacher/usage_std 0.2973 (0.2454) nleep/row_max_mean 1557.6704 (1558.5985) nleep/row_max_std 55.8191 (52.2585) nleep/row_min_mean 1531.6304 (1531.4729) lr 1.9048e-03 eta 0:18:23
epoch [9/50] batch [160/167] time 0.071 (0.158) data 0.000 (0.002) loss 1.4304 (1.4251) teacher_loss 0.2675 (0.2539) loss_zs_kd 0.0281 (0.0315) loss_oracle 0.5420 (0.5475) kd_loss 0.8779 (0.8817) acc 84.3750 (90.0195) gate/entropy 1.0313 (1.0365) gate/usage_max 0.5104 (0.5034) gate/usage_min 0.2294 (0.2342) gate/usage_std 0.1258 (0.1208) teacher/entropy 0.0261 (0.0513) teacher/usage_max 0.6637 (0.6296) teacher/usage_min 0.0587 (0.0390) teacher/usage_std 0.2501 (0.2464) nleep/row_max_mean 1586.0300 (1559.6451) nleep/row_max_std 50.0561 (52.6397) nleep/row_min_mean 1555.1418 (1532.3796) lr 1.9048e-03 eta 0:18:03
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,200
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [10/50] batch [20/167] time 0.103 (0.123) data 0.000 (0.011) loss 1.2156 (1.3787) teacher_loss 0.1499 (0.2403) loss_zs_kd 0.0118 (0.0356) loss_oracle 0.5781 (0.5120) kd_loss 0.7708 (0.8647) acc 93.7500 (89.3750) gate/entropy 1.0309 (1.0315) gate/usage_max 0.5110 (0.5101) gate/usage_min 0.2290 (0.2296) gate/usage_std 0.1262 (0.1256) teacher/entropy 0.0062 (0.0540) teacher/usage_max 0.8426 (0.6441) teacher/usage_min 0.0002 (0.0382) teacher/usage_std 0.3657 (0.2547) nleep/row_max_mean 1571.2637 (1556.7359) nleep/row_max_std 56.6962 (57.2318) nleep/row_min_mean 1539.2177 (1529.7681) lr 1.8763e-03 eta 0:14:01
epoch [10/50] batch [40/167] time 0.098 (0.115) data 0.000 (0.006) loss 1.2767 (1.3642) teacher_loss 0.2720 (0.2301) loss_zs_kd 0.0277 (0.0351) loss_oracle 0.5086 (0.5231) kd_loss 0.7366 (0.8550) acc 93.7500 (90.3906) gate/entropy 1.0302 (1.0310) gate/usage_max 0.5119 (0.5108) gate/usage_min 0.2285 (0.2291) gate/usage_std 0.1269 (0.1261) teacher/entropy 0.0523 (0.0463) teacher/usage_max 0.8255 (0.6680) teacher/usage_min 0.0086 (0.0307) teacher/usage_std 0.3539 (0.2688) nleep/row_max_mean 1553.2277 (1556.9909) nleep/row_max_std 70.8923 (56.6550) nleep/row_min_mean 1525.2351 (1528.6859) lr 1.8763e-03 eta 0:13:00
epoch [10/50] batch [60/167] time 0.076 (0.111) data 0.001 (0.004) loss 1.3648 (1.3668) teacher_loss 0.2758 (0.2290) loss_zs_kd 0.0366 (0.0326) loss_oracle 0.4793 (0.5249) kd_loss 0.8310 (0.8591) acc 90.6250 (90.6771) gate/entropy 1.0285 (1.0304) gate/usage_max 0.5141 (0.5116) gate/usage_min 0.2270 (0.2287) gate/usage_std 0.1285 (0.1267) teacher/entropy 0.0595 (0.0403) teacher/usage_max 0.6757 (0.6687) teacher/usage_min 0.0085 (0.0246) teacher/usage_std 0.2727 (0.2710) nleep/row_max_mean 1552.8035 (1556.9471) nleep/row_max_std 59.7811 (56.5122) nleep/row_min_mean 1523.3723 (1528.1653) lr 1.8763e-03 eta 0:12:31
epoch [10/50] batch [80/167] time 0.119 (0.113) data 0.001 (0.003) loss 1.3824 (1.3610) teacher_loss 0.2165 (0.2224) loss_zs_kd 0.0213 (0.0324) loss_oracle 0.4580 (0.5222) kd_loss 0.9262 (0.8614) acc 87.5000 (90.8984) gate/entropy 1.0274 (1.0299) gate/usage_max 0.5155 (0.5122) gate/usage_min 0.2261 (0.2282) gate/usage_std 0.1295 (0.1271) teacher/entropy 0.0488 (0.0396) teacher/usage_max 0.5488 (0.6655) teacher/usage_min 0.0023 (0.0225) teacher/usage_std 0.2376 (0.2699) nleep/row_max_mean 1569.0292 (1556.2976) nleep/row_max_std 56.0682 (56.9547) nleep/row_min_mean 1542.5889 (1527.8035) lr 1.8763e-03 eta 0:12:41
epoch [10/50] batch [100/167] time 0.172 (0.114) data 0.000 (0.002) loss 1.4933 (1.3761) teacher_loss 0.3717 (0.2320) loss_zs_kd 0.0372 (0.0324) loss_oracle 0.4588 (0.5238) kd_loss 0.8736 (0.8660) acc 87.5000 (90.5625) gate/entropy 1.0271 (1.0294) gate/usage_max 0.5158 (0.5128) gate/usage_min 0.2256 (0.2278) gate/usage_std 0.1298 (0.1276) teacher/entropy 0.0042 (0.0401) teacher/usage_max 0.6873 (0.6570) teacher/usage_min 0.0005 (0.0213) teacher/usage_std 0.2808 (0.2663) nleep/row_max_mean 1557.1453 (1555.5953) nleep/row_max_std 60.8429 (56.5931) nleep/row_min_mean 1528.2041 (1527.3887) lr 1.8763e-03 eta 0:12:49
epoch [10/50] batch [120/167] time 0.142 (0.116) data 0.000 (0.002) loss 1.7837 (1.3856) teacher_loss 0.5994 (0.2386) loss_zs_kd 0.0451 (0.0324) loss_oracle 0.6102 (0.5266) kd_loss 0.8567 (0.8676) acc 78.1250 (90.3385) gate/entropy 1.0255 (1.0290) gate/usage_max 0.5178 (0.5134) gate/usage_min 0.2243 (0.2274) gate/usage_std 0.1312 (0.1280) teacher/entropy 0.0225 (0.0399) teacher/usage_max 0.6866 (0.6541) teacher/usage_min 0.0291 (0.0222) teacher/usage_std 0.2706 (0.2647) nleep/row_max_mean 1563.2793 (1554.8829) nleep/row_max_std 51.7983 (56.0185) nleep/row_min_mean 1531.5378 (1526.9063) lr 1.8763e-03 eta 0:13:00
epoch [10/50] batch [140/167] time 0.145 (0.121) data 0.000 (0.002) loss 1.3945 (1.3893) teacher_loss 0.2776 (0.2414) loss_zs_kd 0.0317 (0.0322) loss_oracle 0.5615 (0.5313) kd_loss 0.8202 (0.8662) acc 90.6250 (90.2232) gate/entropy 1.0252 (1.0286) gate/usage_max 0.5182 (0.5139) gate/usage_min 0.2240 (0.2270) gate/usage_std 0.1314 (0.1284) teacher/entropy 0.0569 (0.0413) teacher/usage_max 0.6874 (0.6540) teacher/usage_min 0.0257 (0.0241) teacher/usage_std 0.2721 (0.2642) nleep/row_max_mean 1576.3103 (1555.5582) nleep/row_max_std 55.2795 (55.4934) nleep/row_min_mean 1546.5350 (1527.8204) lr 1.8763e-03 eta 0:13:32
epoch [10/50] batch [160/167] time 0.127 (0.124) data 0.000 (0.002) loss 1.3004 (1.3876) teacher_loss 0.2171 (0.2384) loss_zs_kd 0.0290 (0.0313) loss_oracle 0.5586 (0.5360) kd_loss 0.7896 (0.8656) acc 87.5000 (90.3516) gate/entropy 1.0262 (1.0282) gate/usage_max 0.5169 (0.5144) gate/usage_min 0.2246 (0.2266) gate/usage_std 0.1305 (0.1287) teacher/entropy 0.0359 (0.0428) teacher/usage_max 0.7700 (0.6523) teacher/usage_min 0.0419 (0.0275) teacher/usage_std 0.3145 (0.2619) nleep/row_max_mean 1548.5541 (1555.6830) nleep/row_max_std 66.3016 (55.2425) nleep/row_min_mean 1520.5886 (1528.1573) lr 1.8763e-03 eta 0:13:52
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [11/50] batch [20/167] time 0.167 (0.167) data 0.000 (0.015) loss 1.4957 (1.3724) teacher_loss 0.2445 (0.2140) loss_zs_kd 0.0424 (0.0316) loss_oracle 0.5600 (0.5651) kd_loss 0.9500 (0.8600) acc 90.6250 (91.8750) gate/entropy 1.0238 (1.0246) gate/usage_max 0.5200 (0.5191) gate/usage_min 0.2229 (0.2234) gate/usage_std 0.1327 (0.1321) teacher/entropy 0.0424 (0.0558) teacher/usage_max 0.5296 (0.6375) teacher/usage_min 0.0545 (0.0476) teacher/usage_std 0.2026 (0.2474) nleep/row_max_mean 1558.9902 (1555.8661) nleep/row_max_std 49.1242 (51.0575) nleep/row_min_mean 1532.0026 (1529.7568) lr 1.8443e-03 eta 0:18:31
epoch [11/50] batch [40/167] time 0.157 (0.162) data 0.000 (0.008) loss 1.2735 (1.3692) teacher_loss 0.2472 (0.2101) loss_zs_kd 0.0207 (0.0298) loss_oracle 0.5265 (0.5641) kd_loss 0.7527 (0.8621) acc 87.5000 (92.3438) gate/entropy 1.0238 (1.0243) gate/usage_max 0.5200 (0.5194) gate/usage_min 0.2228 (0.2232) gate/usage_std 0.1327 (0.1323) teacher/entropy 0.0710 (0.0548) teacher/usage_max 0.7652 (0.6342) teacher/usage_min 0.0263 (0.0391) teacher/usage_std 0.3143 (0.2496) nleep/row_max_mean 1549.5713 (1551.9816) nleep/row_max_std 52.1119 (51.5908) nleep/row_min_mean 1526.4983 (1526.3813) lr 1.8443e-03 eta 0:17:53
epoch [11/50] batch [60/167] time 0.145 (0.161) data 0.001 (0.005) loss 1.3327 (1.3720) teacher_loss 0.1616 (0.2069) loss_zs_kd 0.0384 (0.0290) loss_oracle 0.5555 (0.5673) kd_loss 0.8741 (0.8670) acc 96.8750 (92.2917) gate/entropy 1.0228 (1.0240) gate/usage_max 0.5212 (0.5197) gate/usage_min 0.2220 (0.2230) gate/usage_std 0.1336 (0.1326) teacher/entropy 0.0447 (0.0549) teacher/usage_max 0.6261 (0.6273) teacher/usage_min 0.0283 (0.0416) teacher/usage_std 0.2442 (0.2445) nleep/row_max_mean 1565.2776 (1551.4808) nleep/row_max_std 42.8180 (50.4927) nleep/row_min_mean 1539.8116 (1526.1575) lr 1.8443e-03 eta 0:17:46
epoch [11/50] batch [80/167] time 0.073 (0.148) data 0.000 (0.004) loss 1.4026 (1.3893) teacher_loss 0.2282 (0.2217) loss_zs_kd 0.0206 (0.0297) loss_oracle 0.5143 (0.5599) kd_loss 0.9070 (0.8728) acc 90.6250 (91.6406) gate/entropy 1.0229 (1.0237) gate/usage_max 0.5210 (0.5201) gate/usage_min 0.2218 (0.2227) gate/usage_std 0.1335 (0.1328) teacher/entropy 0.0818 (0.0527) teacher/usage_max 0.5318 (0.6230) teacher/usage_min 0.0501 (0.0383) teacher/usage_std 0.2056 (0.2454) nleep/row_max_mean 1546.0967 (1550.7903) nleep/row_max_std 49.1256 (50.6993) nleep/row_min_mean 1520.0406 (1525.4790) lr 1.8443e-03 eta 0:16:16
epoch [11/50] batch [100/167] time 0.182 (0.145) data 0.000 (0.003) loss 1.2712 (1.3816) teacher_loss 0.1892 (0.2157) loss_zs_kd 0.0293 (0.0285) loss_oracle 0.4377 (0.5557) kd_loss 0.8485 (0.8737) acc 96.8750 (91.9062) gate/entropy 1.0221 (1.0235) gate/usage_max 0.5221 (0.5204) gate/usage_min 0.2211 (0.2225) gate/usage_std 0.1343 (0.1330) teacher/entropy 0.0197 (0.0486) teacher/usage_max 0.6919 (0.6260) teacher/usage_min 0.0007 (0.0343) teacher/usage_std 0.2828 (0.2477) nleep/row_max_mean 1552.4875 (1550.4271) nleep/row_max_std 57.7010 (50.5508) nleep/row_min_mean 1526.4172 (1525.1478) lr 1.8443e-03 eta 0:15:51
epoch [11/50] batch [120/167] time 0.088 (0.138) data 0.000 (0.003) loss 1.3227 (1.3856) teacher_loss 0.2103 (0.2177) loss_zs_kd 0.0142 (0.0285) loss_oracle 0.6184 (0.5564) kd_loss 0.7961 (0.8754) acc 93.7500 (91.7448) gate/entropy 1.0214 (1.0232) gate/usage_max 0.5228 (0.5207) gate/usage_min 0.2204 (0.2222) gate/usage_std 0.1348 (0.1332) teacher/entropy 0.0481 (0.0462) teacher/usage_max 0.7299 (0.6276) teacher/usage_min 0.0344 (0.0314) teacher/usage_std 0.2922 (0.2493) nleep/row_max_mean 1560.5764 (1550.0470) nleep/row_max_std 56.0508 (50.0361) nleep/row_min_mean 1532.7461 (1524.6917) lr 1.8443e-03 eta 0:15:04
epoch [11/50] batch [140/167] time 0.193 (0.136) data 0.000 (0.002) loss 1.2140 (1.3868) teacher_loss 0.2349 (0.2189) loss_zs_kd 0.0277 (0.0289) loss_oracle 0.4796 (0.5566) kd_loss 0.7255 (0.8751) acc 96.8750 (91.7411) gate/entropy 1.0215 (1.0230) gate/usage_max 0.5228 (0.5209) gate/usage_min 0.2202 (0.2219) gate/usage_std 0.1348 (0.1334) teacher/entropy 0.0374 (0.0448) teacher/usage_max 0.8403 (0.6304) teacher/usage_min 0.0041 (0.0294) teacher/usage_std 0.3638 (0.2515) nleep/row_max_mean 1544.9095 (1549.7170) nleep/row_max_std 53.6771 (49.6365) nleep/row_min_mean 1518.9222 (1524.3213) lr 1.8443e-03 eta 0:14:50
epoch [11/50] batch [160/167] time 0.078 (0.131) data 0.000 (0.002) loss 1.3804 (1.3890) teacher_loss 0.3026 (0.2201) loss_zs_kd 0.0281 (0.0293) loss_oracle 0.5172 (0.5561) kd_loss 0.8052 (0.8762) acc 87.5000 (91.7969) gate/entropy 1.0199 (1.0228) gate/usage_max 0.5247 (0.5212) gate/usage_min 0.2191 (0.2217) gate/usage_std 0.1361 (0.1336) teacher/entropy 0.0243 (0.0437) teacher/usage_max 0.7434 (0.6308) teacher/usage_min 0.0000 (0.0273) teacher/usage_std 0.3083 (0.2524) nleep/row_max_mean 1567.0057 (1549.4400) nleep/row_max_std 38.9486 (48.9970) nleep/row_min_mean 1538.3354 (1524.0235) lr 1.8443e-03 eta 0:14:17
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [12/50] batch [20/167] time 0.186 (0.162) data 0.000 (0.016) loss 1.4905 (1.3826) teacher_loss 0.3302 (0.2093) loss_zs_kd 0.0301 (0.0259) loss_oracle 0.5963 (0.5672) kd_loss 0.8471 (0.8767) acc 87.5000 (91.2500) gate/entropy 1.0205 (1.0207) gate/usage_max 0.5239 (0.5237) gate/usage_min 0.2193 (0.2194) gate/usage_std 0.1356 (0.1354) teacher/entropy 0.0042 (0.0341) teacher/usage_max 0.7181 (0.6425) teacher/usage_min 0.0313 (0.0264) teacher/usage_std 0.2864 (0.2559) nleep/row_max_mean 1551.4153 (1551.9525) nleep/row_max_std 53.5144 (48.0715) nleep/row_min_mean 1521.6792 (1526.6115) lr 1.8090e-03 eta 0:17:31
epoch [12/50] batch [40/167] time 0.156 (0.161) data 0.000 (0.008) loss 1.3770 (1.3731) teacher_loss 0.2289 (0.2086) loss_zs_kd 0.0352 (0.0279) loss_oracle 0.6790 (0.5717) kd_loss 0.7910 (0.8647) acc 87.5000 (91.2500) gate/entropy 1.0195 (1.0205) gate/usage_max 0.5252 (0.5240) gate/usage_min 0.2187 (0.2192) gate/usage_std 0.1366 (0.1357) teacher/entropy 0.0158 (0.0335) teacher/usage_max 0.7849 (0.6556) teacher/usage_min 0.0623 (0.0252) teacher/usage_std 0.3214 (0.2632) nleep/row_max_mean 1571.9766 (1552.8923) nleep/row_max_std 48.1184 (50.9743) nleep/row_min_mean 1542.0715 (1526.8567) lr 1.8090e-03 eta 0:17:24
epoch [12/50] batch [60/167] time 0.166 (0.160) data 0.001 (0.005) loss 1.4782 (1.3875) teacher_loss 0.2349 (0.2279) loss_zs_kd 0.0459 (0.0288) loss_oracle 0.5278 (0.5662) kd_loss 0.9565 (0.8622) acc 84.3750 (90.6771) gate/entropy 1.0187 (1.0201) gate/usage_max 0.5262 (0.5244) gate/usage_min 0.2184 (0.2191) gate/usage_std 0.1372 (0.1360) teacher/entropy 0.0068 (0.0316) teacher/usage_max 0.5613 (0.6612) teacher/usage_min 0.0314 (0.0288) teacher/usage_std 0.2225 (0.2643) nleep/row_max_mean 1557.8102 (1552.8822) nleep/row_max_std 44.0007 (51.6200) nleep/row_min_mean 1530.4875 (1526.5188) lr 1.8090e-03 eta 0:17:12
epoch [12/50] batch [80/167] time 0.139 (0.158) data 0.000 (0.004) loss 1.3776 (1.3875) teacher_loss 0.2210 (0.2357) loss_zs_kd 0.0454 (0.0298) loss_oracle 0.4771 (0.5574) kd_loss 0.8953 (0.8582) acc 87.5000 (90.3906) gate/entropy 1.0187 (1.0198) gate/usage_max 0.5262 (0.5248) gate/usage_min 0.2185 (0.2189) gate/usage_std 0.1372 (0.1363) teacher/entropy 0.0317 (0.0336) teacher/usage_max 0.6077 (0.6632) teacher/usage_min 0.0012 (0.0298) teacher/usage_std 0.2509 (0.2645) nleep/row_max_mean 1543.4730 (1552.0631) nleep/row_max_std 48.3557 (52.1707) nleep/row_min_mean 1517.4500 (1525.5215) lr 1.8090e-03 eta 0:16:56
epoch [12/50] batch [100/167] time 0.158 (0.156) data 0.000 (0.003) loss 1.2309 (1.3917) teacher_loss 0.1050 (0.2377) loss_zs_kd 0.0278 (0.0302) loss_oracle 0.5503 (0.5551) kd_loss 0.8369 (0.8614) acc 96.8750 (90.4375) gate/entropy 1.0181 (1.0194) gate/usage_max 0.5270 (0.5253) gate/usage_min 0.2182 (0.2188) gate/usage_std 0.1377 (0.1366) teacher/entropy 0.0978 (0.0368) teacher/usage_max 0.6046 (0.6579) teacher/usage_min 0.0440 (0.0336) teacher/usage_std 0.2293 (0.2605) nleep/row_max_mean 1544.6582 (1552.7454) nleep/row_max_std 47.2745 (51.8175) nleep/row_min_mean 1520.9662 (1526.1346) lr 1.8090e-03 eta 0:16:40
epoch [12/50] batch [120/167] time 0.124 (0.155) data 0.000 (0.003) loss 1.3675 (1.3883) teacher_loss 0.2245 (0.2376) loss_zs_kd 0.0552 (0.0322) loss_oracle 0.5643 (0.5493) kd_loss 0.8332 (0.8600) acc 90.6250 (90.6250) gate/entropy 1.0171 (1.0191) gate/usage_max 0.5283 (0.5257) gate/usage_min 0.2176 (0.2186) gate/usage_std 0.1386 (0.1369) teacher/entropy 0.0421 (0.0384) teacher/usage_max 0.6790 (0.6570) teacher/usage_min 0.0141 (0.0352) teacher/usage_std 0.2721 (0.2594) nleep/row_max_mean 1554.6359 (1551.9375) nleep/row_max_std 57.8290 (51.7455) nleep/row_min_mean 1527.9264 (1525.4750) lr 1.8090e-03 eta 0:16:32
epoch [12/50] batch [140/167] time 0.139 (0.153) data 0.000 (0.002) loss 1.2582 (1.3848) teacher_loss 0.0886 (0.2377) loss_zs_kd 0.0223 (0.0330) loss_oracle 0.5405 (0.5464) kd_loss 0.8882 (0.8575) acc 96.8750 (90.6920) gate/entropy 1.0170 (1.0188) gate/usage_max 0.5284 (0.5261) gate/usage_min 0.2176 (0.2185) gate/usage_std 0.1387 (0.1371) teacher/entropy 0.0345 (0.0407) teacher/usage_max 0.6176 (0.6567) teacher/usage_min 0.0406 (0.0361) teacher/usage_std 0.2356 (0.2590) nleep/row_max_mean 1537.9539 (1550.8241) nleep/row_max_std 57.2151 (52.0423) nleep/row_min_mean 1514.1185 (1524.5011) lr 1.8090e-03 eta 0:16:16
epoch [12/50] batch [160/167] time 0.123 (0.151) data 0.000 (0.002) loss 1.4062 (1.3822) teacher_loss 0.2018 (0.2348) loss_zs_kd 0.0276 (0.0330) loss_oracle 0.5808 (0.5436) kd_loss 0.9002 (0.8591) acc 90.6250 (90.8789) gate/entropy 1.0167 (1.0186) gate/usage_max 0.5287 (0.5264) gate/usage_min 0.2174 (0.2183) gate/usage_std 0.1390 (0.1374) teacher/entropy 0.0446 (0.0423) teacher/usage_max 0.5947 (0.6523) teacher/usage_min 0.0704 (0.0389) teacher/usage_std 0.2141 (0.2560) nleep/row_max_mean 1542.7537 (1549.8766) nleep/row_max_std 48.8113 (51.8821) nleep/row_min_mean 1515.4485 (1523.8081) lr 1.8090e-03 eta 0:15:59
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [13/50] batch [20/167] time 0.154 (0.147) data 0.000 (0.014) loss 1.2157 (1.3857) teacher_loss 0.1777 (0.2437) loss_zs_kd 0.0388 (0.0321) loss_oracle 0.4752 (0.5413) kd_loss 0.7811 (0.8553) acc 90.6250 (90.0000) gate/entropy 1.0160 (1.0161) gate/usage_max 0.5297 (0.5295) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1396 (0.1395) teacher/entropy 0.0536 (0.0635) teacher/usage_max 0.7325 (0.6259) teacher/usage_min 0.0053 (0.0492) teacher/usage_std 0.3011 (0.2399) nleep/row_max_mean 1533.8933 (1541.0956) nleep/row_max_std 59.8376 (52.9499) nleep/row_min_mean 1512.5581 (1517.7209) lr 1.7705e-03 eta 0:15:32
epoch [13/50] batch [40/167] time 0.091 (0.129) data 0.000 (0.007) loss 1.2512 (1.3811) teacher_loss 0.1060 (0.2418) loss_zs_kd 0.0263 (0.0356) loss_oracle 0.5996 (0.5506) kd_loss 0.8323 (0.8461) acc 96.8750 (90.3125) gate/entropy 1.0163 (1.0160) gate/usage_max 0.5293 (0.5297) gate/usage_min 0.2172 (0.2170) gate/usage_std 0.1394 (0.1396) teacher/entropy 0.0980 (0.0772) teacher/usage_max 0.6211 (0.6224) teacher/usage_min 0.1014 (0.0636) teacher/usage_std 0.2158 (0.2350) nleep/row_max_mean 1530.5132 (1540.8583) nleep/row_max_std 64.8856 (53.6738) nleep/row_min_mean 1506.5227 (1517.7734) lr 1.7705e-03 eta 0:13:30
epoch [13/50] batch [60/167] time 0.074 (0.121) data 0.000 (0.005) loss 1.1991 (1.3665) teacher_loss 0.0779 (0.2308) loss_zs_kd 0.0202 (0.0349) loss_oracle 0.6207 (0.5460) kd_loss 0.8007 (0.8453) acc 100.0000 (90.9375) gate/entropy 1.0150 (1.0157) gate/usage_max 0.5309 (0.5300) gate/usage_min 0.2166 (0.2169) gate/usage_std 0.1405 (0.1398) teacher/entropy 0.1172 (0.0800) teacher/usage_max 0.6326 (0.6219) teacher/usage_min 0.0861 (0.0743) teacher/usage_std 0.2261 (0.2303) nleep/row_max_mean 1547.5732 (1540.3902) nleep/row_max_std 51.0731 (53.9875) nleep/row_min_mean 1523.8093 (1517.0862) lr 1.7705e-03 eta 0:12:42
epoch [13/50] batch [80/167] time 0.158 (0.120) data 0.000 (0.004) loss 1.4531 (1.3669) teacher_loss 0.2150 (0.2317) loss_zs_kd 0.0274 (0.0337) loss_oracle 0.5750 (0.5419) kd_loss 0.9368 (0.8474) acc 90.6250 (90.9766) gate/entropy 1.0144 (1.0154) gate/usage_max 0.5316 (0.5303) gate/usage_min 0.2164 (0.2168) gate/usage_std 0.1410 (0.1401) teacher/entropy 0.0491 (0.0761) teacher/usage_max 0.5413 (0.6231) teacher/usage_min 0.0769 (0.0699) teacher/usage_std 0.1927 (0.2322) nleep/row_max_mean 1535.8474 (1541.2466) nleep/row_max_std 60.6526 (53.9209) nleep/row_min_mean 1509.8661 (1517.6635) lr 1.7705e-03 eta 0:12:29
epoch [13/50] batch [100/167] time 0.078 (0.118) data 0.000 (0.003) loss 1.3017 (1.3645) teacher_loss 0.2433 (0.2323) loss_zs_kd 0.0128 (0.0332) loss_oracle 0.5033 (0.5385) kd_loss 0.8003 (0.8463) acc 90.6250 (90.7812) gate/entropy 1.0141 (1.0152) gate/usage_max 0.5320 (0.5307) gate/usage_min 0.2163 (0.2167) gate/usage_std 0.1412 (0.1403) teacher/entropy 0.0342 (0.0726) teacher/usage_max 0.7327 (0.6284) teacher/usage_min 0.0338 (0.0654) teacher/usage_std 0.2939 (0.2361) nleep/row_max_mean 1552.5293 (1542.0212) nleep/row_max_std 55.1843 (54.2769) nleep/row_min_mean 1526.0835 (1517.9335) lr 1.7705e-03 eta 0:12:18
epoch [13/50] batch [120/167] time 0.087 (0.117) data 0.000 (0.003) loss 1.0786 (1.3588) teacher_loss 0.1350 (0.2349) loss_zs_kd 0.0203 (0.0335) loss_oracle 0.5422 (0.5367) kd_loss 0.6624 (0.8388) acc 93.7500 (90.6250) gate/entropy 1.0133 (1.0149) gate/usage_max 0.5331 (0.5310) gate/usage_min 0.2161 (0.2166) gate/usage_std 0.1419 (0.1405) teacher/entropy 0.0834 (0.0699) teacher/usage_max 0.8568 (0.6409) teacher/usage_min 0.0635 (0.0609) teacher/usage_std 0.3702 (0.2435) nleep/row_max_mean 1562.3033 (1543.3826) nleep/row_max_std 49.9268 (54.5207) nleep/row_min_mean 1535.6091 (1518.7488) lr 1.7705e-03 eta 0:12:11
epoch [13/50] batch [140/167] time 0.167 (0.121) data 0.000 (0.002) loss 1.6097 (1.3604) teacher_loss 0.4814 (0.2410) loss_zs_kd 0.0431 (0.0335) loss_oracle 0.5314 (0.5316) kd_loss 0.8410 (0.8368) acc 78.1250 (90.4018) gate/entropy 1.0129 (1.0147) gate/usage_max 0.5336 (0.5313) gate/usage_min 0.2160 (0.2165) gate/usage_std 0.1423 (0.1408) teacher/entropy 0.1071 (0.0661) teacher/usage_max 0.6032 (0.6478) teacher/usage_min 0.1236 (0.0570) teacher/usage_std 0.2004 (0.2478) nleep/row_max_mean 1523.2600 (1543.6719) nleep/row_max_std 58.1071 (54.7371) nleep/row_min_mean 1500.9709 (1518.6878) lr 1.7705e-03 eta 0:12:28
epoch [13/50] batch [160/167] time 0.145 (0.124) data 0.000 (0.002) loss 1.3468 (1.3554) teacher_loss 0.2143 (0.2360) loss_zs_kd 0.0330 (0.0336) loss_oracle 0.5132 (0.5285) kd_loss 0.8593 (0.8383) acc 90.6250 (90.7812) gate/entropy 1.0128 (1.0144) gate/usage_max 0.5338 (0.5317) gate/usage_min 0.2160 (0.2164) gate/usage_std 0.1424 (0.1410) teacher/entropy 0.0217 (0.0623) teacher/usage_max 0.6653 (0.6501) teacher/usage_min 0.0003 (0.0533) teacher/usage_std 0.2715 (0.2498) nleep/row_max_mean 1533.8202 (1543.6098) nleep/row_max_std 64.6775 (54.6756) nleep/row_min_mean 1506.2944 (1518.3426) lr 1.7705e-03 eta 0:12:46
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,208
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [14/50] batch [20/167] time 0.169 (0.170) data 0.000 (0.014) loss 1.3628 (1.3143) teacher_loss 0.2925 (0.2031) loss_zs_kd 0.0302 (0.0320) loss_oracle 0.4392 (0.5133) kd_loss 0.8356 (0.8385) acc 90.6250 (92.0312) gate/entropy 1.0114 (1.0119) gate/usage_max 0.5354 (0.5348) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1436 (0.1431) teacher/entropy 0.0050 (0.0267) teacher/usage_max 0.7178 (0.6884) teacher/usage_min 0.0001 (0.0142) teacher/usage_std 0.2953 (0.2830) nleep/row_max_mean 1551.9766 (1544.0019) nleep/row_max_std 51.8774 (50.9327) nleep/row_min_mean 1519.0249 (1513.0735) lr 1.7290e-03 eta 0:17:24
epoch [14/50] batch [40/167] time 0.132 (0.158) data 0.000 (0.007) loss 1.2256 (1.3119) teacher_loss 0.0689 (0.1955) loss_zs_kd 0.0360 (0.0342) loss_oracle 0.4483 (0.5084) kd_loss 0.9145 (0.8451) acc 100.0000 (92.4219) gate/entropy 1.0109 (1.0117) gate/usage_max 0.5360 (0.5350) gate/usage_min 0.2148 (0.2153) gate/usage_std 0.1440 (0.1433) teacher/entropy 0.0281 (0.0262) teacher/usage_max 0.5843 (0.6792) teacher/usage_min 0.0000 (0.0089) teacher/usage_std 0.2456 (0.2799) nleep/row_max_mean 1556.9170 (1545.6681) nleep/row_max_std 48.8958 (50.2620) nleep/row_min_mean 1524.6028 (1514.4108) lr 1.7290e-03 eta 0:16:11
epoch [14/50] batch [60/167] time 0.154 (0.156) data 0.000 (0.005) loss 1.3123 (1.3272) teacher_loss 0.2194 (0.2003) loss_zs_kd 0.0236 (0.0361) loss_oracle 0.5367 (0.5137) kd_loss 0.8128 (0.8519) acc 90.6250 (92.0833) gate/entropy 1.0113 (1.0115) gate/usage_max 0.5354 (0.5352) gate/usage_min 0.2149 (0.2152) gate/usage_std 0.1436 (0.1434) teacher/entropy 0.0539 (0.0273) teacher/usage_max 0.6849 (0.6683) teacher/usage_min 0.0027 (0.0083) teacher/usage_std 0.2789 (0.2748) nleep/row_max_mean 1552.2957 (1546.0054) nleep/row_max_std 41.5542 (52.4171) nleep/row_min_mean 1524.2423 (1514.5473) lr 1.7290e-03 eta 0:15:52
epoch [14/50] batch [80/167] time 0.163 (0.154) data 0.000 (0.004) loss 1.4034 (1.3388) teacher_loss 0.2309 (0.2116) loss_zs_kd 0.0388 (0.0348) loss_oracle 0.4445 (0.5109) kd_loss 0.9308 (0.8544) acc 90.6250 (91.6406) gate/entropy 1.0112 (1.0114) gate/usage_max 0.5356 (0.5353) gate/usage_min 0.2146 (0.2150) gate/usage_std 0.1437 (0.1435) teacher/entropy 0.0587 (0.0275) teacher/usage_max 0.5198 (0.6646) teacher/usage_min 0.0002 (0.0081) teacher/usage_std 0.2361 (0.2730) nleep/row_max_mean 1536.8969 (1545.2182) nleep/row_max_std 59.1565 (54.0597) nleep/row_min_mean 1509.0197 (1513.9782) lr 1.7290e-03 eta 0:15:41
epoch [14/50] batch [100/167] time 0.112 (0.145) data 0.000 (0.003) loss 1.6532 (1.3423) teacher_loss 0.3500 (0.2185) loss_zs_kd 0.0250 (0.0338) loss_oracle 0.5856 (0.5073) kd_loss 0.9979 (0.8532) acc 90.6250 (91.4062) gate/entropy 1.0106 (1.0113) gate/usage_max 0.5362 (0.5354) gate/usage_min 0.2143 (0.2149) gate/usage_std 0.1442 (0.1436) teacher/entropy 0.0052 (0.0299) teacher/usage_max 0.5009 (0.6628) teacher/usage_min 0.0000 (0.0070) teacher/usage_std 0.2357 (0.2730) nleep/row_max_mean 1547.6062 (1544.9956) nleep/row_max_std 53.7992 (54.8560) nleep/row_min_mean 1514.0608 (1513.7296) lr 1.7290e-03 eta 0:14:41
epoch [14/50] batch [120/167] time 0.164 (0.141) data 0.000 (0.003) loss 1.3244 (1.3531) teacher_loss 0.1921 (0.2231) loss_zs_kd 0.0332 (0.0340) loss_oracle 0.5441 (0.5093) kd_loss 0.8436 (0.8584) acc 96.8750 (91.2500) gate/entropy 1.0091 (1.0112) gate/usage_max 0.5380 (0.5356) gate/usage_min 0.2133 (0.2148) gate/usage_std 0.1454 (0.1437) teacher/entropy 0.0280 (0.0295) teacher/usage_max 0.6728 (0.6565) teacher/usage_min 0.0006 (0.0060) teacher/usage_std 0.2745 (0.2707) nleep/row_max_mean 1565.2146 (1544.8861) nleep/row_max_std 40.7173 (53.9132) nleep/row_min_mean 1529.8965 (1513.4793) lr 1.7290e-03 eta 0:14:16
epoch [14/50] batch [140/167] time 0.051 (0.135) data 0.000 (0.002) loss 1.4578 (1.3553) teacher_loss 0.3451 (0.2230) loss_zs_kd 0.0492 (0.0337) loss_oracle 0.5046 (0.5081) kd_loss 0.8358 (0.8614) acc 96.8750 (91.2500) gate/entropy 1.0102 (1.0111) gate/usage_max 0.5367 (0.5357) gate/usage_min 0.2134 (0.2146) gate/usage_std 0.1446 (0.1438) teacher/entropy 0.0694 (0.0291) teacher/usage_max 0.6277 (0.6530) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2577 (0.2698) nleep/row_max_mean 1551.4581 (1544.0965) nleep/row_max_std 39.4516 (53.7240) nleep/row_min_mean 1517.7161 (1512.5739) lr 1.7290e-03 eta 0:13:35
epoch [14/50] batch [160/167] time 0.064 (0.128) data 0.000 (0.002) loss 1.3500 (1.3570) teacher_loss 0.2709 (0.2261) loss_zs_kd 0.0302 (0.0339) loss_oracle 0.4758 (0.5064) kd_loss 0.8261 (0.8607) acc 87.5000 (91.1719) gate/entropy 1.0103 (1.0110) gate/usage_max 0.5365 (0.5357) gate/usage_min 0.2132 (0.2145) gate/usage_std 0.1444 (0.1438) teacher/entropy 0.0429 (0.0295) teacher/usage_max 0.6764 (0.6529) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2762 (0.2699) nleep/row_max_mean 1552.4612 (1543.8649) nleep/row_max_std 33.1447 (53.6095) nleep/row_min_mean 1519.1875 (1512.1337) lr 1.7290e-03 eta 0:12:51
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,188
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [15/50] batch [20/167] time 0.152 (0.135) data 0.000 (0.013) loss 1.3173 (1.3928) teacher_loss 0.2645 (0.2476) loss_zs_kd 0.0224 (0.0290) loss_oracle 0.4714 (0.4962) kd_loss 0.8059 (0.8826) acc 84.3750 (91.0938) gate/entropy 1.0109 (1.0104) gate/usage_max 0.5357 (0.5362) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1439 (0.1443) teacher/entropy 0.0507 (0.0332) teacher/usage_max 0.6913 (0.6288) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2828 (0.2598) nleep/row_max_mean 1541.5679 (1544.4448) nleep/row_max_std 62.2450 (53.9554) nleep/row_min_mean 1507.3622 (1510.3998) lr 1.6845e-03 eta 0:13:26
epoch [15/50] batch [40/167] time 0.155 (0.129) data 0.000 (0.007) loss 1.1835 (1.3744) teacher_loss 0.0913 (0.2298) loss_zs_kd 0.0173 (0.0302) loss_oracle 0.4810 (0.5017) kd_loss 0.8431 (0.8786) acc 100.0000 (91.1719) gate/entropy 1.0112 (1.0106) gate/usage_max 0.5352 (0.5360) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1436 (0.1442) teacher/entropy 0.0237 (0.0343) teacher/usage_max 0.6777 (0.6298) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.2768 (0.2617) nleep/row_max_mean 1540.9810 (1544.7624) nleep/row_max_std 63.0952 (54.3088) nleep/row_min_mean 1507.7045 (1511.3774) lr 1.6845e-03 eta 0:12:51
epoch [15/50] batch [60/167] time 0.157 (0.128) data 0.001 (0.005) loss 1.3837 (1.3650) teacher_loss 0.1662 (0.2179) loss_zs_kd 0.0132 (0.0289) loss_oracle 0.4900 (0.5009) kd_loss 0.9659 (0.8822) acc 90.6250 (91.3021) gate/entropy 1.0105 (1.0106) gate/usage_max 0.5360 (0.5359) gate/usage_min 0.2122 (0.2128) gate/usage_std 0.1442 (0.1441) teacher/entropy 0.0114 (0.0341) teacher/usage_max 0.5307 (0.6232) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2370 (0.2603) nleep/row_max_mean 1564.9608 (1546.0145) nleep/row_max_std 44.9359 (53.1454) nleep/row_min_mean 1527.8218 (1512.4950) lr 1.6845e-03 eta 0:12:38
epoch [15/50] batch [80/167] time 0.155 (0.134) data 0.000 (0.004) loss 1.5235 (1.3778) teacher_loss 0.2493 (0.2342) loss_zs_kd 0.0260 (0.0292) loss_oracle 0.5599 (0.5013) kd_loss 0.9813 (0.8784) acc 90.6250 (90.4688) gate/entropy 1.0102 (1.0106) gate/usage_max 0.5362 (0.5359) gate/usage_min 0.2118 (0.2126) gate/usage_std 0.1444 (0.1441) teacher/entropy 0.0148 (0.0331) teacher/usage_max 0.5043 (0.6281) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2357 (0.2620) nleep/row_max_mean 1560.9106 (1545.7006) nleep/row_max_std 45.8909 (53.4731) nleep/row_min_mean 1528.6245 (1512.4505) lr 1.6845e-03 eta 0:13:17
epoch [15/50] batch [100/167] time 0.147 (0.138) data 0.000 (0.003) loss 1.3387 (1.3738) teacher_loss 0.1726 (0.2323) loss_zs_kd 0.0394 (0.0293) loss_oracle 0.4853 (0.5023) kd_loss 0.9037 (0.8756) acc 90.6250 (90.6875) gate/entropy 1.0108 (1.0106) gate/usage_max 0.5355 (0.5358) gate/usage_min 0.2117 (0.2125) gate/usage_std 0.1439 (0.1441) teacher/entropy 0.0313 (0.0332) teacher/usage_max 0.5858 (0.6298) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2459 (0.2630) nleep/row_max_mean 1539.8647 (1545.7058) nleep/row_max_std 51.7419 (52.9217) nleep/row_min_mean 1509.2960 (1512.6394) lr 1.6845e-03 eta 0:13:35
epoch [15/50] batch [120/167] time 0.154 (0.140) data 0.000 (0.002) loss 1.4431 (1.3614) teacher_loss 0.2214 (0.2255) loss_zs_kd 0.0478 (0.0286) loss_oracle 0.5409 (0.5025) kd_loss 0.9273 (0.8703) acc 93.7500 (91.0417) gate/entropy 1.0098 (1.0107) gate/usage_max 0.5366 (0.5358) gate/usage_min 0.2111 (0.2123) gate/usage_std 0.1447 (0.1440) teacher/entropy 0.0010 (0.0339) teacher/usage_max 0.5939 (0.6344) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2479 (0.2644) nleep/row_max_mean 1550.1726 (1544.3727) nleep/row_max_std 54.0908 (53.2850) nleep/row_min_mean 1516.9117 (1511.7239) lr 1.6845e-03 eta 0:13:47
epoch [15/50] batch [140/167] time 0.157 (0.142) data 0.000 (0.002) loss 1.1226 (1.3577) teacher_loss 0.1369 (0.2255) loss_zs_kd 0.0262 (0.0288) loss_oracle 0.4160 (0.4997) kd_loss 0.7646 (0.8679) acc 93.7500 (90.9598) gate/entropy 1.0112 (1.0107) gate/usage_max 0.5348 (0.5357) gate/usage_min 0.2116 (0.2122) gate/usage_std 0.1435 (0.1440) teacher/entropy 0.0431 (0.0341) teacher/usage_max 0.7558 (0.6364) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3149 (0.2652) nleep/row_max_mean 1534.2947 (1543.6923) nleep/row_max_std 62.1581 (53.4004) nleep/row_min_mean 1503.8273 (1511.2211) lr 1.6845e-03 eta 0:13:55
epoch [15/50] batch [160/167] time 0.139 (0.143) data 0.000 (0.002) loss 1.3876 (1.3559) teacher_loss 0.2633 (0.2257) loss_zs_kd 0.0420 (0.0293) loss_oracle 0.4771 (0.4983) kd_loss 0.8648 (0.8664) acc 90.6250 (91.0547) gate/entropy 1.0105 (1.0107) gate/usage_max 0.5357 (0.5357) gate/usage_min 0.2110 (0.2121) gate/usage_std 0.1442 (0.1440) teacher/entropy 0.0161 (0.0335) teacher/usage_max 0.6571 (0.6384) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2684 (0.2659) nleep/row_max_mean 1538.5847 (1543.6655) nleep/row_max_std 53.6416 (53.2258) nleep/row_min_mean 1507.6481 (1511.4161) lr 1.6845e-03 eta 0:13:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,187
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [16/50] batch [20/167] time 0.077 (0.124) data 0.000 (0.014) loss 1.3940 (1.3459) teacher_loss 0.2460 (0.2482) loss_zs_kd 0.0358 (0.0339) loss_oracle 0.4482 (0.5016) kd_loss 0.9061 (0.8299) acc 90.6250 (89.6875) gate/entropy 1.0102 (1.0104) gate/usage_max 0.5361 (0.5358) gate/usage_min 0.2107 (0.2109) gate/usage_std 0.1444 (0.1442) teacher/entropy 0.0200 (0.0365) teacher/usage_max 0.5981 (0.6765) teacher/usage_min 0.0017 (0.0019) teacher/usage_std 0.2480 (0.2797) nleep/row_max_mean 1549.8129 (1544.8367) nleep/row_max_std 41.8375 (50.3097) nleep/row_min_mean 1521.5188 (1514.3953) lr 1.6374e-03 eta 0:12:04
epoch [16/50] batch [40/167] time 0.106 (0.114) data 0.001 (0.007) loss 1.2716 (1.3304) teacher_loss 0.1600 (0.2242) loss_zs_kd 0.0336 (0.0308) loss_oracle 0.5133 (0.4952) kd_loss 0.8382 (0.8432) acc 96.8750 (91.0938) gate/entropy 1.0104 (1.0104) gate/usage_max 0.5358 (0.5358) gate/usage_min 0.2108 (0.2109) gate/usage_std 0.1442 (0.1442) teacher/entropy 0.0156 (0.0310) teacher/usage_max 0.6928 (0.6660) teacher/usage_min 0.0001 (0.0014) teacher/usage_std 0.2834 (0.2759) nleep/row_max_mean 1526.5881 (1541.6263) nleep/row_max_std 68.5896 (52.5743) nleep/row_min_mean 1495.7056 (1511.5468) lr 1.6374e-03 eta 0:11:01
epoch [16/50] batch [60/167] time 0.079 (0.114) data 0.001 (0.005) loss 1.3220 (1.3410) teacher_loss 0.2138 (0.2311) loss_zs_kd 0.0321 (0.0309) loss_oracle 0.4515 (0.4987) kd_loss 0.8664 (0.8450) acc 90.6250 (90.6250) gate/entropy 1.0101 (1.0103) gate/usage_max 0.5362 (0.5359) gate/usage_min 0.2106 (0.2108) gate/usage_std 0.1445 (0.1443) teacher/entropy 0.0240 (0.0295) teacher/usage_max 0.6468 (0.6669) teacher/usage_min 0.0091 (0.0032) teacher/usage_std 0.2605 (0.2756) nleep/row_max_mean 1545.5061 (1542.1214) nleep/row_max_std 52.9890 (52.3132) nleep/row_min_mean 1517.3174 (1512.1128) lr 1.6374e-03 eta 0:11:01
epoch [16/50] batch [80/167] time 0.066 (0.114) data 0.000 (0.004) loss 1.3612 (1.3517) teacher_loss 0.2286 (0.2330) loss_zs_kd 0.0415 (0.0298) loss_oracle 0.5276 (0.4987) kd_loss 0.8480 (0.8545) acc 93.7500 (90.5469) gate/entropy 1.0106 (1.0102) gate/usage_max 0.5355 (0.5360) gate/usage_min 0.2107 (0.2107) gate/usage_std 0.1440 (0.1444) teacher/entropy 0.0421 (0.0307) teacher/usage_max 0.6421 (0.6535) teacher/usage_min 0.0006 (0.0043) teacher/usage_std 0.2624 (0.2705) nleep/row_max_mean 1528.9510 (1543.0752) nleep/row_max_std 45.6371 (51.9689) nleep/row_min_mean 1503.5677 (1513.4390) lr 1.6374e-03 eta 0:10:58
epoch [16/50] batch [100/167] time 0.082 (0.114) data 0.000 (0.003) loss 1.3268 (1.3505) teacher_loss 0.1398 (0.2300) loss_zs_kd 0.0462 (0.0316) loss_oracle 0.4387 (0.5019) kd_loss 0.9446 (0.8537) acc 100.0000 (90.7500) gate/entropy 1.0093 (1.0101) gate/usage_max 0.5370 (0.5360) gate/usage_min 0.2099 (0.2106) gate/usage_std 0.1451 (0.1444) teacher/entropy 0.0064 (0.0320) teacher/usage_max 0.5627 (0.6525) teacher/usage_min 0.0011 (0.0054) teacher/usage_std 0.2405 (0.2697) nleep/row_max_mean 1548.7233 (1544.1340) nleep/row_max_std 48.8939 (51.9574) nleep/row_min_mean 1521.3767 (1514.4211) lr 1.6374e-03 eta 0:10:57
epoch [16/50] batch [120/167] time 0.088 (0.110) data 0.000 (0.003) loss 1.5034 (1.3510) teacher_loss 0.3152 (0.2301) loss_zs_kd 0.0363 (0.0313) loss_oracle 0.5186 (0.5022) kd_loss 0.9108 (0.8541) acc 87.5000 (90.7552) gate/entropy 1.0098 (1.0101) gate/usage_max 0.5364 (0.5361) gate/usage_min 0.2099 (0.2105) gate/usage_std 0.1447 (0.1444) teacher/entropy 0.0202 (0.0319) teacher/usage_max 0.5884 (0.6523) teacher/usage_min 0.0037 (0.0056) teacher/usage_std 0.2445 (0.2694) nleep/row_max_mean 1555.5703 (1544.1030) nleep/row_max_std 38.5366 (51.5060) nleep/row_min_mean 1522.4852 (1514.3688) lr 1.6374e-03 eta 0:10:29
epoch [16/50] batch [140/167] time 0.169 (0.112) data 0.000 (0.002) loss 1.2978 (1.3471) teacher_loss 0.0731 (0.2274) loss_zs_kd 0.0321 (0.0304) loss_oracle 0.5466 (0.5017) kd_loss 0.9354 (0.8537) acc 100.0000 (90.9152) gate/entropy 1.0100 (1.0101) gate/usage_max 0.5361 (0.5361) gate/usage_min 0.2098 (0.2104) gate/usage_std 0.1445 (0.1444) teacher/entropy 0.0197 (0.0321) teacher/usage_max 0.5561 (0.6522) teacher/usage_min 0.0055 (0.0056) teacher/usage_std 0.2368 (0.2694) nleep/row_max_mean 1542.7150 (1544.2328) nleep/row_max_std 45.8915 (51.0075) nleep/row_min_mean 1510.9580 (1514.4673) lr 1.6374e-03 eta 0:10:40
epoch [16/50] batch [160/167] time 0.084 (0.111) data 0.000 (0.002) loss 1.3493 (1.3506) teacher_loss 0.2689 (0.2291) loss_zs_kd 0.0270 (0.0309) loss_oracle 0.4066 (0.5031) kd_loss 0.8637 (0.8546) acc 90.6250 (90.8203) gate/entropy 1.0099 (1.0101) gate/usage_max 0.5361 (0.5361) gate/usage_min 0.2096 (0.2104) gate/usage_std 0.1445 (0.1444) teacher/entropy 0.0544 (0.0327) teacher/usage_max 0.6041 (0.6498) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.2506 (0.2684) nleep/row_max_mean 1547.9700 (1544.4474) nleep/row_max_std 43.0436 (50.3308) nleep/row_min_mean 1515.6821 (1514.6443) lr 1.6374e-03 eta 0:10:32
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,188
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [17/50] batch [20/167] time 0.160 (0.172) data 0.000 (0.014) loss 1.4211 (1.3467) teacher_loss 0.2626 (0.2243) loss_zs_kd 0.0428 (0.0307) loss_oracle 0.5999 (0.5076) kd_loss 0.8371 (0.8532) acc 90.6250 (90.9375) gate/entropy 1.0104 (1.0098) gate/usage_max 0.5355 (0.5361) gate/usage_min 0.2096 (0.2094) gate/usage_std 0.1441 (0.1446) teacher/entropy 0.0270 (0.0345) teacher/usage_max 0.6790 (0.6473) teacher/usage_min 0.0080 (0.0105) teacher/usage_std 0.2743 (0.2648) nleep/row_max_mean 1530.7087 (1551.5937) nleep/row_max_std 63.4071 (47.8082) nleep/row_min_mean 1503.7596 (1521.2353) lr 1.5878e-03 eta 0:16:12
epoch [17/50] batch [40/167] time 0.141 (0.161) data 0.000 (0.007) loss 1.2361 (1.3344) teacher_loss 0.0638 (0.2135) loss_zs_kd 0.0116 (0.0297) loss_oracle 0.5182 (0.5102) kd_loss 0.9074 (0.8509) acc 100.0000 (91.4844) gate/entropy 1.0097 (1.0098) gate/usage_max 0.5362 (0.5361) gate/usage_min 0.2092 (0.2093) gate/usage_std 0.1447 (0.1446) teacher/entropy 0.0699 (0.0324) teacher/usage_max 0.5330 (0.6527) teacher/usage_min 0.0359 (0.0090) teacher/usage_std 0.2144 (0.2680) nleep/row_max_mean 1561.4160 (1550.0185) nleep/row_max_std 38.8226 (49.1244) nleep/row_min_mean 1533.7753 (1520.2595) lr 1.5878e-03 eta 0:15:05
epoch [17/50] batch [60/167] time 0.134 (0.156) data 0.000 (0.005) loss 1.2633 (1.3277) teacher_loss 0.0637 (0.2094) loss_zs_kd 0.0369 (0.0293) loss_oracle 0.5249 (0.5017) kd_loss 0.9187 (0.8527) acc 100.0000 (91.5625) gate/entropy 1.0099 (1.0098) gate/usage_max 0.5360 (0.5361) gate/usage_min 0.2092 (0.2093) gate/usage_std 0.1445 (0.1446) teacher/entropy 0.0062 (0.0342) teacher/usage_max 0.5947 (0.6482) teacher/usage_min 0.0002 (0.0107) teacher/usage_std 0.2480 (0.2651) nleep/row_max_mean 1536.1707 (1549.5366) nleep/row_max_std 62.8065 (50.3864) nleep/row_min_mean 1508.9143 (1520.3000) lr 1.5878e-03 eta 0:14:36
epoch [17/50] batch [80/167] time 0.115 (0.153) data 0.000 (0.004) loss 1.2138 (1.3421) teacher_loss 0.1210 (0.2241) loss_zs_kd 0.0277 (0.0310) loss_oracle 0.5135 (0.4995) kd_loss 0.8222 (0.8527) acc 96.8750 (90.9375) gate/entropy 1.0096 (1.0098) gate/usage_max 0.5363 (0.5361) gate/usage_min 0.2090 (0.2092) gate/usage_std 0.1447 (0.1446) teacher/entropy 0.0138 (0.0351) teacher/usage_max 0.7138 (0.6477) teacher/usage_min 0.0000 (0.0110) teacher/usage_std 0.2933 (0.2652) nleep/row_max_mean 1560.4482 (1549.5532) nleep/row_max_std 50.8716 (51.8515) nleep/row_min_mean 1527.7861 (1520.4108) lr 1.5878e-03 eta 0:14:14
epoch [17/50] batch [100/167] time 0.139 (0.151) data 0.000 (0.003) loss 1.2040 (1.3480) teacher_loss 0.1451 (0.2205) loss_zs_kd 0.0385 (0.0309) loss_oracle 0.6146 (0.5044) kd_loss 0.7323 (0.8598) acc 100.0000 (91.0000) gate/entropy 1.0098 (1.0098) gate/usage_max 0.5360 (0.5361) gate/usage_min 0.2088 (0.2092) gate/usage_std 0.1446 (0.1446) teacher/entropy 0.0538 (0.0342) teacher/usage_max 0.7803 (0.6412) teacher/usage_min 0.0009 (0.0108) teacher/usage_std 0.3283 (0.2630) nleep/row_max_mean 1542.7317 (1549.6957) nleep/row_max_std 70.1897 (52.8742) nleep/row_min_mean 1510.4225 (1520.2938) lr 1.5878e-03 eta 0:14:00
epoch [17/50] batch [120/167] time 0.141 (0.150) data 0.000 (0.003) loss 1.4194 (1.3517) teacher_loss 0.2103 (0.2197) loss_zs_kd 0.0255 (0.0312) loss_oracle 0.6123 (0.5074) kd_loss 0.8902 (0.8626) acc 90.6250 (91.1198) gate/entropy 1.0102 (1.0099) gate/usage_max 0.5354 (0.5360) gate/usage_min 0.2085 (0.2091) gate/usage_std 0.1442 (0.1446) teacher/entropy 0.0093 (0.0334) teacher/usage_max 0.6249 (0.6385) teacher/usage_min 0.0017 (0.0105) teacher/usage_std 0.2560 (0.2624) nleep/row_max_mean 1554.7942 (1549.1635) nleep/row_max_std 48.0947 (53.4967) nleep/row_min_mean 1522.1450 (1519.6777) lr 1.5878e-03 eta 0:13:54
epoch [17/50] batch [140/167] time 0.169 (0.151) data 0.000 (0.002) loss 1.3560 (1.3474) teacher_loss 0.3046 (0.2173) loss_zs_kd 0.0259 (0.0308) loss_oracle 0.4858 (0.5085) kd_loss 0.7955 (0.8605) acc 90.6250 (91.1830) gate/entropy 1.0106 (1.0099) gate/usage_max 0.5350 (0.5360) gate/usage_min 0.2085 (0.2090) gate/usage_std 0.1439 (0.1445) teacher/entropy 0.0568 (0.0336) teacher/usage_max 0.6965 (0.6411) teacher/usage_min 0.0211 (0.0121) teacher/usage_std 0.2780 (0.2627) nleep/row_max_mean 1538.2069 (1549.0436) nleep/row_max_std 63.3995 (53.8624) nleep/row_min_mean 1514.8887 (1519.6705) lr 1.5878e-03 eta 0:13:57
epoch [17/50] batch [160/167] time 0.085 (0.145) data 0.000 (0.002) loss 1.2389 (1.3439) teacher_loss 0.1489 (0.2182) loss_zs_kd 0.0099 (0.0303) loss_oracle 0.4838 (0.5072) kd_loss 0.8431 (0.8569) acc 90.6250 (91.1719) gate/entropy 1.0106 (1.0099) gate/usage_max 0.5349 (0.5359) gate/usage_min 0.2085 (0.2089) gate/usage_std 0.1439 (0.1445) teacher/entropy 0.0269 (0.0344) teacher/usage_max 0.6763 (0.6444) teacher/usage_min 0.0317 (0.0125) teacher/usage_std 0.2648 (0.2638) nleep/row_max_mean 1535.8226 (1548.7211) nleep/row_max_std 55.4068 (54.4847) nleep/row_min_mean 1510.9647 (1519.4807) lr 1.5878e-03 eta 0:13:19
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [18/50] batch [20/167] time 0.092 (0.124) data 0.000 (0.014) loss 1.1522 (1.3369) teacher_loss 0.1087 (0.2201) loss_zs_kd 0.0151 (0.0291) loss_oracle 0.4556 (0.5191) kd_loss 0.8081 (0.8427) acc 96.8750 (92.6562) gate/entropy 1.0105 (1.0099) gate/usage_max 0.5350 (0.5358) gate/usage_min 0.2085 (0.2083) gate/usage_std 0.1439 (0.1445) teacher/entropy 0.0520 (0.0518) teacher/usage_max 0.6831 (0.6397) teacher/usage_min 0.0045 (0.0247) teacher/usage_std 0.2774 (0.2543) nleep/row_max_mean 1535.7832 (1551.5548) nleep/row_max_std 58.7597 (53.4824) nleep/row_min_mean 1510.2190 (1523.7406) lr 1.5358e-03 eta 0:11:21
epoch [18/50] batch [40/167] time 0.171 (0.121) data 0.000 (0.007) loss 1.3212 (1.3481) teacher_loss 0.1198 (0.2220) loss_zs_kd 0.0333 (0.0294) loss_oracle 0.4855 (0.5206) kd_loss 0.9419 (0.8510) acc 96.8750 (92.3438) gate/entropy 1.0097 (1.0099) gate/usage_max 0.5360 (0.5358) gate/usage_min 0.2080 (0.2082) gate/usage_std 0.1446 (0.1445) teacher/entropy 0.0594 (0.0489) teacher/usage_max 0.4929 (0.6332) teacher/usage_min 0.0204 (0.0281) teacher/usage_std 0.2213 (0.2524) nleep/row_max_mean 1562.1099 (1550.0066) nleep/row_max_std 49.2984 (53.5148) nleep/row_min_mean 1533.4418 (1523.0242) lr 1.5358e-03 eta 0:11:00
epoch [18/50] batch [60/167] time 0.203 (0.122) data 0.001 (0.005) loss 1.3470 (1.3769) teacher_loss 0.2363 (0.2309) loss_zs_kd 0.0242 (0.0316) loss_oracle 0.5932 (0.5448) kd_loss 0.8020 (0.8578) acc 90.6250 (91.6667) gate/entropy 1.0096 (1.0098) gate/usage_max 0.5361 (0.5358) gate/usage_min 0.2079 (0.2082) gate/usage_std 0.1447 (0.1445) teacher/entropy 0.0269 (0.0470) teacher/usage_max 0.7480 (0.6292) teacher/usage_min 0.0961 (0.0339) teacher/usage_std 0.2942 (0.2495) nleep/row_max_mean 1544.7688 (1549.2770) nleep/row_max_std 58.1913 (52.9669) nleep/row_min_mean 1522.1384 (1522.7920) lr 1.5358e-03 eta 0:11:05
epoch [18/50] batch [80/167] time 0.072 (0.120) data 0.000 (0.004) loss 1.5946 (1.3791) teacher_loss 0.3328 (0.2326) loss_zs_kd 0.0284 (0.0306) loss_oracle 0.6353 (0.5438) kd_loss 0.9300 (0.8592) acc 87.5000 (91.2891) gate/entropy 1.0099 (1.0098) gate/usage_max 0.5357 (0.5358) gate/usage_min 0.2080 (0.2081) gate/usage_std 0.1445 (0.1445) teacher/entropy 0.1207 (0.0498) teacher/usage_max 0.4587 (0.6253) teacher/usage_min 0.1363 (0.0414) teacher/usage_std 0.1410 (0.2454) nleep/row_max_mean 1541.5020 (1547.4432) nleep/row_max_std 40.6315 (52.6423) nleep/row_min_mean 1519.9713 (1521.3579) lr 1.5358e-03 eta 0:10:49
epoch [18/50] batch [100/167] time 0.157 (0.120) data 0.000 (0.003) loss 1.3531 (1.3715) teacher_loss 0.2545 (0.2212) loss_zs_kd 0.0221 (0.0298) loss_oracle 0.4453 (0.5483) kd_loss 0.8648 (0.8613) acc 84.3750 (91.8438) gate/entropy 1.0096 (1.0098) gate/usage_max 0.5360 (0.5358) gate/usage_min 0.2080 (0.2081) gate/usage_std 0.1447 (0.1445) teacher/entropy 0.0503 (0.0529) teacher/usage_max 0.6154 (0.6198) teacher/usage_min 0.0406 (0.0467) teacher/usage_std 0.2348 (0.2407) nleep/row_max_mean 1547.2358 (1546.6143) nleep/row_max_std 50.2447 (52.7256) nleep/row_min_mean 1526.6456 (1521.0301) lr 1.5358e-03 eta 0:10:50
epoch [18/50] batch [120/167] time 0.142 (0.129) data 0.000 (0.003) loss 1.3107 (1.3714) teacher_loss 0.1484 (0.2191) loss_zs_kd 0.0210 (0.0301) loss_oracle 0.4419 (0.5452) kd_loss 0.9309 (0.8646) acc 90.6250 (91.6927) gate/entropy 1.0094 (1.0098) gate/usage_max 0.5363 (0.5359) gate/usage_min 0.2078 (0.2081) gate/usage_std 0.1449 (0.1446) teacher/entropy 0.0514 (0.0540) teacher/usage_max 0.5345 (0.6151) teacher/usage_min 0.0684 (0.0516) teacher/usage_std 0.1956 (0.2369) nleep/row_max_mean 1554.3518 (1546.8308) nleep/row_max_std 52.9780 (52.3975) nleep/row_min_mean 1530.6987 (1521.4163) lr 1.5358e-03 eta 0:11:33
epoch [18/50] batch [140/167] time 0.173 (0.133) data 0.000 (0.002) loss 1.2906 (1.3751) teacher_loss 0.1730 (0.2219) loss_zs_kd 0.0538 (0.0308) loss_oracle 0.5022 (0.5435) kd_loss 0.8396 (0.8661) acc 90.6250 (91.5625) gate/entropy 1.0101 (1.0098) gate/usage_max 0.5355 (0.5359) gate/usage_min 0.2081 (0.2080) gate/usage_std 0.1443 (0.1446) teacher/entropy 0.0604 (0.0556) teacher/usage_max 0.6411 (0.6126) teacher/usage_min 0.0496 (0.0567) teacher/usage_std 0.2421 (0.2338) nleep/row_max_mean 1532.2007 (1547.0317) nleep/row_max_std 51.6894 (52.3950) nleep/row_min_mean 1508.8401 (1521.7590) lr 1.5358e-03 eta 0:11:56
epoch [18/50] batch [160/167] time 0.154 (0.137) data 0.000 (0.002) loss 1.3599 (1.3782) teacher_loss 0.1552 (0.2208) loss_zs_kd 0.0394 (0.0322) loss_oracle 0.6318 (0.5484) kd_loss 0.8691 (0.8671) acc 96.8750 (91.5625) gate/entropy 1.0092 (1.0097) gate/usage_max 0.5366 (0.5360) gate/usage_min 0.2077 (0.2080) gate/usage_std 0.1450 (0.1446) teacher/entropy 0.0400 (0.0548) teacher/usage_max 0.6417 (0.6127) teacher/usage_min 0.1082 (0.0577) teacher/usage_std 0.2256 (0.2331) nleep/row_max_mean 1559.8728 (1547.3039) nleep/row_max_std 47.9040 (52.1498) nleep/row_min_mean 1535.0187 (1522.0360) lr 1.5358e-03 eta 0:12:12
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,183
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [19/50] batch [20/167] time 0.138 (0.162) data 0.000 (0.015) loss 1.5840 (1.4124) teacher_loss 0.2835 (0.2202) loss_zs_kd 0.0537 (0.0374) loss_oracle 0.5599 (0.5540) kd_loss 0.9937 (0.8965) acc 90.6250 (91.5625) gate/entropy 1.0096 (1.0095) gate/usage_max 0.5361 (0.5362) gate/usage_min 0.2077 (0.2078) gate/usage_std 0.1447 (0.1448) teacher/entropy 0.0372 (0.0477) teacher/usage_max 0.4844 (0.5891) teacher/usage_min 0.1396 (0.0640) teacher/usage_std 0.1439 (0.2198) nleep/row_max_mean 1554.1621 (1555.0094) nleep/row_max_std 50.2999 (48.0432) nleep/row_min_mean 1526.7948 (1528.9502) lr 1.4818e-03 eta 0:14:23
epoch [19/50] batch [40/167] time 0.071 (0.149) data 0.000 (0.007) loss 1.5116 (1.4024) teacher_loss 0.2690 (0.2363) loss_zs_kd 0.0150 (0.0366) loss_oracle 0.6748 (0.5488) kd_loss 0.8977 (0.8734) acc 90.6250 (91.0938) gate/entropy 1.0100 (1.0095) gate/usage_max 0.5356 (0.5362) gate/usage_min 0.2079 (0.2077) gate/usage_std 0.1444 (0.1448) teacher/entropy 0.0627 (0.0483) teacher/usage_max 0.5456 (0.6138) teacher/usage_min 0.0128 (0.0551) teacher/usage_std 0.2306 (0.2340) nleep/row_max_mean 1537.9968 (1553.6487) nleep/row_max_std 60.7667 (50.6642) nleep/row_min_mean 1509.6113 (1527.0117) lr 1.4818e-03 eta 0:13:10
epoch [19/50] batch [60/167] time 0.168 (0.130) data 0.001 (0.005) loss 1.3839 (1.3738) teacher_loss 0.2014 (0.2218) loss_zs_kd 0.0237 (0.0342) loss_oracle 0.4984 (0.5414) kd_loss 0.9214 (0.8642) acc 93.7500 (91.5104) gate/entropy 1.0095 (1.0095) gate/usage_max 0.5362 (0.5362) gate/usage_min 0.2077 (0.2077) gate/usage_std 0.1448 (0.1448) teacher/entropy 0.0008 (0.0438) teacher/usage_max 0.5936 (0.6294) teacher/usage_min 0.0000 (0.0448) teacher/usage_std 0.2478 (0.2441) nleep/row_max_mean 1554.7876 (1552.1281) nleep/row_max_std 39.5590 (51.5415) nleep/row_min_mean 1526.3385 (1525.4192) lr 1.4818e-03 eta 0:11:26
epoch [19/50] batch [80/167] time 0.080 (0.124) data 0.000 (0.004) loss 1.4250 (1.3689) teacher_loss 0.2849 (0.2175) loss_zs_kd 0.0224 (0.0325) loss_oracle 0.5708 (0.5389) kd_loss 0.8435 (0.8657) acc 87.5000 (91.9141) gate/entropy 1.0093 (1.0094) gate/usage_max 0.5364 (0.5363) gate/usage_min 0.2077 (0.2077) gate/usage_std 0.1449 (0.1449) teacher/entropy 0.0366 (0.0405) teacher/usage_max 0.6520 (0.6312) teacher/usage_min 0.0003 (0.0387) teacher/usage_std 0.2663 (0.2470) nleep/row_max_mean 1537.9094 (1550.7765) nleep/row_max_std 50.1122 (51.6029) nleep/row_min_mean 1513.3264 (1523.9893) lr 1.4818e-03 eta 0:10:50
epoch [19/50] batch [100/167] time 0.186 (0.122) data 0.000 (0.003) loss 1.4524 (1.3752) teacher_loss 0.1623 (0.2200) loss_zs_kd 0.0559 (0.0343) loss_oracle 0.5869 (0.5477) kd_loss 0.9688 (0.8643) acc 93.7500 (91.6250) gate/entropy 1.0088 (1.0094) gate/usage_max 0.5370 (0.5364) gate/usage_min 0.2075 (0.2077) gate/usage_std 0.1453 (0.1449) teacher/entropy 0.0543 (0.0393) teacher/usage_max 0.4836 (0.6338) teacher/usage_min 0.0438 (0.0351) teacher/usage_std 0.2048 (0.2500) nleep/row_max_mean 1547.3569 (1549.0877) nleep/row_max_std 46.2927 (51.1289) nleep/row_min_mean 1518.8821 (1522.1554) lr 1.4818e-03 eta 0:10:37
epoch [19/50] batch [120/167] time 0.180 (0.122) data 0.000 (0.003) loss 1.4763 (1.3713) teacher_loss 0.3554 (0.2138) loss_zs_kd 0.0406 (0.0336) loss_oracle 0.5010 (0.5541) kd_loss 0.8501 (0.8637) acc 78.1250 (91.7448) gate/entropy 1.0085 (1.0093) gate/usage_max 0.5374 (0.5364) gate/usage_min 0.2073 (0.2077) gate/usage_std 0.1456 (0.1449) teacher/entropy 0.0105 (0.0387) teacher/usage_max 0.6859 (0.6339) teacher/usage_min 0.0313 (0.0326) teacher/usage_std 0.2696 (0.2511) nleep/row_max_mean 1561.8770 (1548.6886) nleep/row_max_std 52.5176 (50.9697) nleep/row_min_mean 1531.9160 (1521.7411) lr 1.4818e-03 eta 0:10:37
epoch [19/50] batch [140/167] time 0.098 (0.119) data 0.000 (0.002) loss 1.3260 (1.3729) teacher_loss 0.1484 (0.2198) loss_zs_kd 0.0314 (0.0335) loss_oracle 0.5368 (0.5547) kd_loss 0.8936 (0.8590) acc 93.7500 (91.4509) gate/entropy 1.0089 (1.0093) gate/usage_max 0.5369 (0.5364) gate/usage_min 0.2075 (0.2077) gate/usage_std 0.1453 (0.1449) teacher/entropy 0.0222 (0.0391) teacher/usage_max 0.6136 (0.6390) teacher/usage_min 0.0313 (0.0319) teacher/usage_std 0.2382 (0.2535) nleep/row_max_mean 1547.7913 (1548.2448) nleep/row_max_std 41.9173 (50.8924) nleep/row_min_mean 1521.7837 (1521.1704) lr 1.4818e-03 eta 0:10:21
epoch [19/50] batch [160/167] time 0.099 (0.117) data 0.000 (0.002) loss 1.3409 (1.3739) teacher_loss 0.1893 (0.2224) loss_zs_kd 0.0230 (0.0338) loss_oracle 0.4724 (0.5555) kd_loss 0.9039 (0.8569) acc 90.6250 (91.3281) gate/entropy 1.0083 (1.0092) gate/usage_max 0.5376 (0.5365) gate/usage_min 0.2073 (0.2076) gate/usage_std 0.1458 (0.1450) teacher/entropy 0.0396 (0.0380) teacher/usage_max 0.5657 (0.6425) teacher/usage_min 0.0053 (0.0305) teacher/usage_std 0.2386 (0.2556) nleep/row_max_mean 1558.8263 (1548.3617) nleep/row_max_std 48.7619 (51.0816) nleep/row_min_mean 1530.6864 (1521.1444) lr 1.4818e-03 eta 0:10:09
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,193
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [20/50] batch [20/167] time 0.109 (0.153) data 0.000 (0.016) loss 1.3868 (1.3266) teacher_loss 0.2464 (0.1857) loss_zs_kd 0.0535 (0.0276) loss_oracle 0.5190 (0.5111) kd_loss 0.8542 (0.8715) acc 90.6250 (91.7188) gate/entropy 1.0079 (1.0086) gate/usage_max 0.5382 (0.5373) gate/usage_min 0.2072 (0.2075) gate/usage_std 0.1462 (0.1456) teacher/entropy 0.0264 (0.0304) teacher/usage_max 0.6549 (0.6314) teacher/usage_min 0.0124 (0.0251) teacher/usage_std 0.2623 (0.2508) nleep/row_max_mean 1556.9490 (1553.0114) nleep/row_max_std 56.4469 (51.0716) nleep/row_min_mean 1527.6813 (1524.5647) lr 1.4258e-03 eta 0:13:11
epoch [20/50] batch [40/167] time 0.183 (0.159) data 0.000 (0.008) loss 1.2579 (1.3298) teacher_loss 0.1665 (0.1905) loss_zs_kd 0.0331 (0.0298) loss_oracle 0.6419 (0.5267) kd_loss 0.7539 (0.8610) acc 93.7500 (91.6406) gate/entropy 1.0086 (1.0086) gate/usage_max 0.5373 (0.5373) gate/usage_min 0.2075 (0.2074) gate/usage_std 0.1455 (0.1456) teacher/entropy 0.0258 (0.0292) teacher/usage_max 0.7930 (0.6465) teacher/usage_min 0.0195 (0.0261) teacher/usage_std 0.3322 (0.2570) nleep/row_max_mean 1543.1768 (1551.9465) nleep/row_max_std 56.7590 (50.7943) nleep/row_min_mean 1515.3125 (1523.6597) lr 1.4258e-03 eta 0:13:38
epoch [20/50] batch [60/167] time 0.188 (0.165) data 0.001 (0.006) loss 1.2733 (1.3255) teacher_loss 0.2703 (0.1997) loss_zs_kd 0.0223 (0.0301) loss_oracle 0.4925 (0.5356) kd_loss 0.7456 (0.8430) acc 93.7500 (91.4062) gate/entropy 1.0084 (1.0085) gate/usage_max 0.5376 (0.5375) gate/usage_min 0.2076 (0.2075) gate/usage_std 0.1457 (0.1456) teacher/entropy 0.0567 (0.0301) teacher/usage_max 0.7597 (0.6690) teacher/usage_min 0.0106 (0.0257) teacher/usage_std 0.3145 (0.2684) nleep/row_max_mean 1541.1295 (1550.5987) nleep/row_max_std 50.7173 (50.0605) nleep/row_min_mean 1515.9680 (1522.5613) lr 1.4258e-03 eta 0:14:06
epoch [20/50] batch [80/167] time 0.154 (0.166) data 0.000 (0.004) loss 1.4155 (1.3329) teacher_loss 0.2079 (0.1984) loss_zs_kd 0.0367 (0.0298) loss_oracle 0.5871 (0.5430) kd_loss 0.8957 (0.8481) acc 93.7500 (91.7188) gate/entropy 1.0081 (1.0083) gate/usage_max 0.5380 (0.5377) gate/usage_min 0.2077 (0.2075) gate/usage_std 0.1460 (0.1458) teacher/entropy 0.0385 (0.0332) teacher/usage_max 0.5911 (0.6588) teacher/usage_min 0.0354 (0.0292) teacher/usage_std 0.2287 (0.2621) nleep/row_max_mean 1534.2529 (1550.1357) nleep/row_max_std 43.9978 (48.9185) nleep/row_min_mean 1506.9413 (1522.4491) lr 1.4258e-03 eta 0:14:06
epoch [20/50] batch [100/167] time 0.160 (0.165) data 0.000 (0.003) loss 1.4761 (1.3336) teacher_loss 0.2425 (0.1980) loss_zs_kd 0.0364 (0.0312) loss_oracle 0.5228 (0.5430) kd_loss 0.9540 (0.8485) acc 90.6250 (91.8438) gate/entropy 1.0073 (1.0082) gate/usage_max 0.5391 (0.5378) gate/usage_min 0.2074 (0.2075) gate/usage_std 0.1467 (0.1459) teacher/entropy 0.0525 (0.0362) teacher/usage_max 0.5146 (0.6545) teacher/usage_min 0.1147 (0.0309) teacher/usage_std 0.1654 (0.2596) nleep/row_max_mean 1556.1306 (1549.2321) nleep/row_max_std 35.4921 (48.1933) nleep/row_min_mean 1530.6006 (1522.0423) lr 1.4258e-03 eta 0:13:58
epoch [20/50] batch [120/167] time 0.150 (0.162) data 0.000 (0.003) loss 1.4559 (1.3369) teacher_loss 0.1939 (0.1988) loss_zs_kd 0.0297 (0.0305) loss_oracle 0.6193 (0.5397) kd_loss 0.9374 (0.8530) acc 93.7500 (91.7708) gate/entropy 1.0081 (1.0082) gate/usage_max 0.5381 (0.5379) gate/usage_min 0.2077 (0.2075) gate/usage_std 0.1460 (0.1459) teacher/entropy 0.0471 (0.0396) teacher/usage_max 0.5375 (0.6465) teacher/usage_min 0.0915 (0.0363) teacher/usage_std 0.1840 (0.2541) nleep/row_max_mean 1541.3295 (1548.4212) nleep/row_max_std 47.0368 (47.7998) nleep/row_min_mean 1518.5513 (1521.8135) lr 1.4258e-03 eta 0:13:41
epoch [20/50] batch [140/167] time 0.142 (0.162) data 0.000 (0.002) loss 1.5009 (1.3450) teacher_loss 0.3051 (0.2029) loss_zs_kd 0.0322 (0.0311) loss_oracle 0.5551 (0.5385) kd_loss 0.9021 (0.8573) acc 90.6250 (91.6071) gate/entropy 1.0073 (1.0081) gate/usage_max 0.5390 (0.5380) gate/usage_min 0.2073 (0.2075) gate/usage_std 0.1467 (0.1460) teacher/entropy 0.0138 (0.0418) teacher/usage_max 0.6224 (0.6405) teacher/usage_min 0.0655 (0.0404) teacher/usage_std 0.2278 (0.2501) nleep/row_max_mean 1550.2572 (1548.1440) nleep/row_max_std 43.9228 (47.3494) nleep/row_min_mean 1525.0399 (1521.9110) lr 1.4258e-03 eta 0:13:35
epoch [20/50] batch [160/167] time 0.074 (0.154) data 0.000 (0.002) loss 1.2746 (1.3474) teacher_loss 0.2110 (0.2018) loss_zs_kd 0.0137 (0.0305) loss_oracle 0.4946 (0.5408) kd_loss 0.8094 (0.8600) acc 90.6250 (91.6992) gate/entropy 1.0080 (1.0081) gate/usage_max 0.5381 (0.5380) gate/usage_min 0.2076 (0.2075) gate/usage_std 0.1461 (0.1460) teacher/entropy 0.1200 (0.0440) teacher/usage_max 0.6008 (0.6357) teacher/usage_min 0.0569 (0.0447) teacher/usage_std 0.2221 (0.2464) nleep/row_max_mean 1535.5029 (1547.0625) nleep/row_max_std 40.9317 (46.9232) nleep/row_min_mean 1512.8352 (1521.2634) lr 1.4258e-03 eta 0:12:50
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,181
* accuracy: 94.9%
* error: 5.1%
* macro_f1: 95.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [21/50] batch [20/167] time 0.092 (0.127) data 0.000 (0.016) loss 1.2926 (1.4116) teacher_loss 0.0899 (0.2270) loss_zs_kd 0.0211 (0.0373) loss_oracle 0.5393 (0.5482) kd_loss 0.9225 (0.8918) acc 96.8750 (90.4688) gate/entropy 1.0082 (1.0076) gate/usage_max 0.5379 (0.5386) gate/usage_min 0.2076 (0.2074) gate/usage_std 0.1459 (0.1464) teacher/entropy 0.0663 (0.0636) teacher/usage_max 0.5533 (0.5780) teacher/usage_min 0.1707 (0.1009) teacher/usage_std 0.1613 (0.1994) nleep/row_max_mean 1516.9304 (1536.7475) nleep/row_max_std 55.2198 (42.4918) nleep/row_min_mean 1496.5104 (1514.2991) lr 1.3681e-03 eta 0:10:32
epoch [21/50] batch [40/167] time 0.090 (0.117) data 0.000 (0.008) loss 1.3944 (1.4327) teacher_loss 0.1515 (0.2306) loss_zs_kd 0.0415 (0.0366) loss_oracle 0.6232 (0.5672) kd_loss 0.9106 (0.9003) acc 96.8750 (90.3906) gate/entropy 1.0081 (1.0076) gate/usage_max 0.5380 (0.5386) gate/usage_min 0.2077 (0.2074) gate/usage_std 0.1460 (0.1464) teacher/entropy 0.1080 (0.0781) teacher/usage_max 0.5259 (0.5591) teacher/usage_min 0.2221 (0.1343) teacher/usage_std 0.1367 (0.1809) nleep/row_max_mean 1528.1405 (1538.2316) nleep/row_max_std 45.8219 (43.2822) nleep/row_min_mean 1505.5221 (1516.2955) lr 1.3681e-03 eta 0:09:42
epoch [21/50] batch [60/167] time 0.079 (0.117) data 0.000 (0.005) loss 1.3025 (1.4409) teacher_loss 0.1002 (0.2203) loss_zs_kd 0.0311 (0.0351) loss_oracle 0.5327 (0.5756) kd_loss 0.9204 (0.9153) acc 93.7500 (91.2500) gate/entropy 1.0074 (1.0076) gate/usage_max 0.5389 (0.5387) gate/usage_min 0.2075 (0.2074) gate/usage_std 0.1466 (0.1464) teacher/entropy 0.0836 (0.0837) teacher/usage_max 0.5098 (0.5377) teacher/usage_min 0.0851 (0.1505) teacher/usage_std 0.1807 (0.1655) nleep/row_max_mean 1548.1077 (1537.9997) nleep/row_max_std 44.4932 (44.0176) nleep/row_min_mean 1525.2129 (1515.9392) lr 1.3681e-03 eta 0:09:38
epoch [21/50] batch [80/167] time 0.074 (0.118) data 0.000 (0.004) loss 1.3609 (1.4335) teacher_loss 0.2083 (0.2182) loss_zs_kd 0.0239 (0.0337) loss_oracle 0.5268 (0.5650) kd_loss 0.8773 (0.9160) acc 93.7500 (91.6016) gate/entropy 1.0071 (1.0075) gate/usage_max 0.5393 (0.5387) gate/usage_min 0.2076 (0.2075) gate/usage_std 0.1468 (0.1465) teacher/entropy 0.1026 (0.0883) teacher/usage_max 0.5615 (0.5330) teacher/usage_min 0.1530 (0.1598) teacher/usage_std 0.1702 (0.1598) nleep/row_max_mean 1540.2815 (1537.8857) nleep/row_max_std 53.6207 (44.6758) nleep/row_min_mean 1518.2139 (1516.0029) lr 1.3681e-03 eta 0:09:43
epoch [21/50] batch [100/167] time 0.169 (0.123) data 0.000 (0.003) loss 1.4251 (1.4416) teacher_loss 0.1306 (0.2162) loss_zs_kd 0.0476 (0.0339) loss_oracle 0.5650 (0.5605) kd_loss 0.9881 (0.9282) acc 96.8750 (91.6250) gate/entropy 1.0073 (1.0075) gate/usage_max 0.5391 (0.5388) gate/usage_min 0.2078 (0.2075) gate/usage_std 0.1467 (0.1465) teacher/entropy 0.0831 (0.0911) teacher/usage_max 0.4679 (0.5209) teacher/usage_min 0.2621 (0.1722) teacher/usage_std 0.0952 (0.1493) nleep/row_max_mean 1539.5254 (1537.4884) nleep/row_max_std 51.8696 (46.1140) nleep/row_min_mean 1515.9668 (1515.6394) lr 1.3681e-03 eta 0:10:05
epoch [21/50] batch [120/167] time 0.161 (0.130) data 0.000 (0.003) loss 1.6636 (1.4581) teacher_loss 0.2734 (0.2153) loss_zs_kd 0.0488 (0.0340) loss_oracle 0.6440 (0.5718) kd_loss 1.0438 (0.9399) acc 90.6250 (91.7188) gate/entropy 1.0070 (1.0074) gate/usage_max 0.5395 (0.5389) gate/usage_min 0.2079 (0.2076) gate/usage_std 0.1469 (0.1466) teacher/entropy 0.1561 (0.0937) teacher/usage_max 0.4996 (0.5085) teacher/usage_min 0.1422 (0.1810) teacher/usage_std 0.1469 (0.1403) nleep/row_max_mean 1539.0144 (1537.6930) nleep/row_max_std 50.8323 (46.8384) nleep/row_min_mean 1518.6716 (1515.9464) lr 1.3681e-03 eta 0:10:34
epoch [21/50] batch [140/167] time 0.161 (0.134) data 0.000 (0.002) loss 1.5538 (1.4761) teacher_loss 0.1387 (0.2122) loss_zs_kd 0.0416 (0.0345) loss_oracle 0.6922 (0.5797) kd_loss 1.0481 (0.9569) acc 96.8750 (91.9420) gate/entropy 1.0067 (1.0073) gate/usage_max 0.5400 (0.5390) gate/usage_min 0.2080 (0.2076) gate/usage_std 0.1472 (0.1466) teacher/entropy 0.1223 (0.0977) teacher/usage_max 0.3589 (0.4938) teacher/usage_min 0.3067 (0.1924) teacher/usage_std 0.0213 (0.1289) nleep/row_max_mean 1545.4500 (1538.1156) nleep/row_max_std 73.0604 (48.1208) nleep/row_min_mean 1520.0532 (1516.2833) lr 1.3681e-03 eta 0:10:54
epoch [21/50] batch [160/167] time 0.161 (0.138) data 0.000 (0.002) loss 1.9872 (1.5118) teacher_loss 0.1382 (0.2125) loss_zs_kd 0.0582 (0.0351) loss_oracle 1.0848 (0.6053) kd_loss 1.2776 (0.9791) acc 93.7500 (91.9141) gate/entropy 1.0064 (1.0073) gate/usage_max 0.5405 (0.5391) gate/usage_min 0.2082 (0.2077) gate/usage_std 0.1475 (0.1467) teacher/entropy 0.0873 (0.1003) teacher/usage_max 0.5476 (0.4951) teacher/usage_min 0.1555 (0.1942) teacher/usage_std 0.1621 (0.1289) nleep/row_max_mean 1551.9224 (1538.9376) nleep/row_max_std 40.7635 (48.3660) nleep/row_min_mean 1525.8242 (1516.8750) lr 1.3681e-03 eta 0:11:08
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [22/50] batch [20/167] time 0.137 (0.174) data 0.000 (0.015) loss 1.7838 (1.9178) teacher_loss 0.1819 (0.1878) loss_zs_kd 0.0760 (0.0493) loss_oracle 0.7249 (0.8835) kd_loss 1.2015 (1.2636) acc 93.7500 (92.9688) gate/entropy 1.0063 (1.0065) gate/usage_max 0.5407 (0.5405) gate/usage_min 0.2091 (0.2088) gate/usage_std 0.1476 (0.1475) teacher/entropy 0.1102 (0.0897) teacher/usage_max 0.6265 (0.6480) teacher/usage_min 0.1331 (0.1360) teacher/usage_std 0.2119 (0.2263) nleep/row_max_mean 1544.7041 (1545.3787) nleep/row_max_std 51.1593 (52.6466) nleep/row_min_mean 1515.4136 (1517.9941) lr 1.3090e-03 eta 0:13:58
epoch [22/50] batch [40/167] time 0.080 (0.142) data 0.000 (0.007) loss 1.7590 (1.9018) teacher_loss 0.1413 (0.1873) loss_zs_kd 0.0607 (0.0471) loss_oracle 0.6800 (0.8249) kd_loss 1.2474 (1.2785) acc 96.8750 (93.2031) gate/entropy 1.0059 (1.0062) gate/usage_max 0.5414 (0.5409) gate/usage_min 0.2094 (0.2090) gate/usage_std 0.1480 (0.1477) teacher/entropy 0.1116 (0.0853) teacher/usage_max 0.6521 (0.6523) teacher/usage_min 0.1622 (0.1364) teacher/usage_std 0.2256 (0.2290) nleep/row_max_mean 1534.2578 (1547.7076) nleep/row_max_std 52.9576 (51.7899) nleep/row_min_mean 1508.3009 (1519.7960) lr 1.3090e-03 eta 0:11:24
epoch [22/50] batch [60/167] time 0.092 (0.128) data 0.000 (0.005) loss 1.7627 (1.9032) teacher_loss 0.0806 (0.1754) loss_zs_kd 0.0267 (0.0464) loss_oracle 0.7881 (0.8231) kd_loss 1.2748 (1.2931) acc 96.8750 (93.6979) gate/entropy 1.0053 (1.0060) gate/usage_max 0.5422 (0.5412) gate/usage_min 0.2099 (0.2092) gate/usage_std 0.1485 (0.1479) teacher/entropy 0.0891 (0.0827) teacher/usage_max 0.5844 (0.6709) teacher/usage_min 0.1624 (0.1277) teacher/usage_std 0.1814 (0.2421) nleep/row_max_mean 1555.7334 (1547.9418) nleep/row_max_std 44.1834 (50.2977) nleep/row_min_mean 1528.0127 (1519.7008) lr 1.3090e-03 eta 0:10:13
epoch [22/50] batch [80/167] time 0.144 (0.126) data 0.000 (0.004) loss 1.9793 (1.9062) teacher_loss 0.1731 (0.1786) loss_zs_kd 0.0553 (0.0473) loss_oracle 0.9105 (0.8323) kd_loss 1.3233 (1.2877) acc 96.8750 (93.7109) gate/entropy 1.0048 (1.0058) gate/usage_max 0.5429 (0.5415) gate/usage_min 0.2102 (0.2094) gate/usage_std 0.1490 (0.1481) teacher/entropy 0.0904 (0.0857) teacher/usage_max 0.6850 (0.6690) teacher/usage_min 0.1201 (0.1256) teacher/usage_std 0.2505 (0.2412) nleep/row_max_mean 1550.2976 (1547.4648) nleep/row_max_std 57.3550 (51.1445) nleep/row_min_mean 1523.4009 (1519.2691) lr 1.3090e-03 eta 0:09:58
epoch [22/50] batch [100/167] time 0.076 (0.123) data 0.000 (0.003) loss 1.5430 (1.9024) teacher_loss 0.0909 (0.1719) loss_zs_kd 0.0282 (0.0471) loss_oracle 0.7555 (0.8407) kd_loss 1.0602 (1.2866) acc 96.8750 (94.1562) gate/entropy 1.0055 (1.0057) gate/usage_max 0.5421 (0.5417) gate/usage_min 0.2110 (0.2097) gate/usage_std 0.1484 (0.1482) teacher/entropy 0.2134 (0.0878) teacher/usage_max 0.5602 (0.6673) teacher/usage_min 0.1693 (0.1260) teacher/usage_std 0.1656 (0.2399) nleep/row_max_mean 1530.8344 (1546.7188) nleep/row_max_std 56.7568 (51.3757) nleep/row_min_mean 1509.3035 (1518.7676) lr 1.3090e-03 eta 0:09:44
epoch [22/50] batch [120/167] time 0.078 (0.122) data 0.000 (0.003) loss 1.8606 (1.8980) teacher_loss 0.2064 (0.1763) loss_zs_kd 0.0888 (0.0471) loss_oracle 0.8099 (0.8284) kd_loss 1.2048 (1.2840) acc 93.7500 (93.8281) gate/entropy 1.0043 (1.0055) gate/usage_max 0.5438 (0.5419) gate/usage_min 0.2110 (0.2099) gate/usage_std 0.1494 (0.1483) teacher/entropy 0.0897 (0.0873) teacher/usage_max 0.5134 (0.6628) teacher/usage_min 0.2351 (0.1288) teacher/usage_std 0.1275 (0.2366) nleep/row_max_mean 1556.7935 (1546.4465) nleep/row_max_std 31.3265 (51.2241) nleep/row_min_mean 1528.1638 (1518.4171) lr 1.3090e-03 eta 0:09:37
epoch [22/50] batch [140/167] time 0.087 (0.120) data 0.000 (0.002) loss 2.0428 (1.8966) teacher_loss 0.2686 (0.1737) loss_zs_kd 0.0771 (0.0482) loss_oracle 0.9571 (0.8356) kd_loss 1.2571 (1.2810) acc 90.6250 (93.9955) gate/entropy 1.0043 (1.0054) gate/usage_max 0.5437 (0.5421) gate/usage_min 0.2115 (0.2101) gate/usage_std 0.1494 (0.1485) teacher/entropy 0.1099 (0.0875) teacher/usage_max 0.6083 (0.6578) teacher/usage_min 0.1613 (0.1328) teacher/usage_std 0.1965 (0.2329) nleep/row_max_mean 1548.2820 (1547.1990) nleep/row_max_std 50.8688 (50.6992) nleep/row_min_mean 1517.3005 (1518.9150) lr 1.3090e-03 eta 0:09:25
epoch [22/50] batch [160/167] time 0.071 (0.120) data 0.000 (0.002) loss 1.8359 (1.9062) teacher_loss 0.0587 (0.1739) loss_zs_kd 0.0566 (0.0492) loss_oracle 1.0270 (0.8480) kd_loss 1.2355 (1.2837) acc 100.0000 (94.0039) gate/entropy 1.0044 (1.0053) gate/usage_max 0.5437 (0.5423) gate/usage_min 0.2120 (0.2103) gate/usage_std 0.1494 (0.1485) teacher/entropy 0.0606 (0.0851) teacher/usage_max 0.6117 (0.6580) teacher/usage_min 0.1398 (0.1327) teacher/usage_std 0.2018 (0.2331) nleep/row_max_mean 1561.7117 (1547.4700) nleep/row_max_std 52.5780 (50.3685) nleep/row_min_mean 1528.0098 (1518.8267) lr 1.3090e-03 eta 0:09:20
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,313
* accuracy: 98.7%
* error: 1.3%
* macro_f1: 98.7%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [23/50] batch [20/167] time 0.136 (0.159) data 0.000 (0.014) loss 1.9423 (2.0195) teacher_loss 0.1735 (0.1986) loss_zs_kd 0.0423 (0.0562) loss_oracle 0.9506 (1.0006) kd_loss 1.2724 (1.2925) acc 90.6250 (92.5000) gate/entropy 1.0043 (1.0043) gate/usage_max 0.5440 (0.5439) gate/usage_min 0.2126 (0.2124) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0582 (0.0682) teacher/usage_max 0.6563 (0.6702) teacher/usage_min 0.1330 (0.1247) teacher/usage_std 0.2306 (0.2418) nleep/row_max_mean 1560.7112 (1551.4449) nleep/row_max_std 41.2422 (50.2263) nleep/row_min_mean 1528.3090 (1519.1571) lr 1.2487e-03 eta 0:12:20
epoch [23/50] batch [40/167] time 0.137 (0.152) data 0.000 (0.007) loss 2.0278 (2.0218) teacher_loss 0.1303 (0.1859) loss_zs_kd 0.0356 (0.0520) loss_oracle 1.1095 (1.0101) kd_loss 1.3250 (1.3048) acc 96.8750 (93.1250) gate/entropy 1.0040 (1.0044) gate/usage_max 0.5444 (0.5439) gate/usage_min 0.2131 (0.2127) gate/usage_std 0.1497 (0.1494) teacher/entropy 0.0671 (0.0677) teacher/usage_max 0.5959 (0.6870) teacher/usage_min 0.1250 (0.1157) teacher/usage_std 0.1960 (0.2535) nleep/row_max_mean 1566.6160 (1552.5126) nleep/row_max_std 46.6359 (51.2869) nleep/row_min_mean 1530.3840 (1519.6058) lr 1.2487e-03 eta 0:11:43
epoch [23/50] batch [60/167] time 0.120 (0.147) data 0.000 (0.005) loss 2.2189 (2.0380) teacher_loss 0.1731 (0.1952) loss_zs_kd 0.0445 (0.0506) loss_oracle 1.2688 (1.0212) kd_loss 1.3892 (1.3069) acc 93.7500 (93.1250) gate/entropy 1.0034 (1.0043) gate/usage_max 0.5452 (0.5440) gate/usage_min 0.2134 (0.2129) gate/usage_std 0.1502 (0.1495) teacher/entropy 0.0755 (0.0690) teacher/usage_max 0.7898 (0.6884) teacher/usage_min 0.0654 (0.1136) teacher/usage_std 0.3244 (0.2546) nleep/row_max_mean 1573.8727 (1553.7681) nleep/row_max_std 29.9447 (50.6792) nleep/row_min_mean 1537.4521 (1520.6603) lr 1.2487e-03 eta 0:11:17
epoch [23/50] batch [80/167] time 0.125 (0.148) data 0.000 (0.004) loss 2.1655 (2.0360) teacher_loss 0.2451 (0.1952) loss_zs_kd 0.0647 (0.0513) loss_oracle 1.0786 (1.0176) kd_loss 1.3488 (1.3063) acc 93.7500 (93.1641) gate/entropy 1.0043 (1.0043) gate/usage_max 0.5442 (0.5441) gate/usage_min 0.2142 (0.2132) gate/usage_std 0.1495 (0.1495) teacher/entropy 0.0437 (0.0650) teacher/usage_max 0.6143 (0.6848) teacher/usage_min 0.1241 (0.1153) teacher/usage_std 0.2065 (0.2522) nleep/row_max_mean 1558.8925 (1553.6724) nleep/row_max_std 38.6783 (50.7657) nleep/row_min_mean 1522.7793 (1520.3983) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [100/167] time 0.146 (0.149) data 0.000 (0.003) loss 1.8969 (2.0327) teacher_loss 0.1248 (0.1895) loss_zs_kd 0.0487 (0.0502) loss_oracle 0.9631 (1.0187) kd_loss 1.2662 (1.3087) acc 93.7500 (93.2812) gate/entropy 1.0041 (1.0043) gate/usage_max 0.5446 (0.5441) gate/usage_min 0.2146 (0.2134) gate/usage_std 0.1497 (0.1495) teacher/entropy 0.0484 (0.0629) teacher/usage_max 0.6148 (0.6901) teacher/usage_min 0.1665 (0.1131) teacher/usage_std 0.2002 (0.2558) nleep/row_max_mean 1550.0259 (1552.7326) nleep/row_max_std 57.0144 (50.9921) nleep/row_min_mean 1514.4858 (1519.5486) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [120/167] time 0.151 (0.150) data 0.000 (0.002) loss 2.0387 (2.0353) teacher_loss 0.1106 (0.1932) loss_zs_kd 0.0410 (0.0506) loss_oracle 1.0957 (1.0171) kd_loss 1.3597 (1.3083) acc 96.8750 (92.9427) gate/entropy 1.0045 (1.0043) gate/usage_max 0.5442 (0.5442) gate/usage_min 0.2153 (0.2137) gate/usage_std 0.1495 (0.1495) teacher/entropy 0.0461 (0.0627) teacher/usage_max 0.7799 (0.6919) teacher/usage_min 0.0925 (0.1127) teacher/usage_std 0.3161 (0.2570) nleep/row_max_mean 1558.8884 (1552.3236) nleep/row_max_std 49.3479 (51.0616) nleep/row_min_mean 1524.9148 (1519.0796) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [140/167] time 0.139 (0.150) data 0.000 (0.002) loss 2.0273 (2.0320) teacher_loss 0.2105 (0.1871) loss_zs_kd 0.0778 (0.0499) loss_oracle 0.9599 (1.0165) kd_loss 1.2979 (1.3116) acc 93.7500 (93.2143) gate/entropy 1.0043 (1.0043) gate/usage_max 0.5445 (0.5442) gate/usage_min 0.2157 (0.2140) gate/usage_std 0.1496 (0.1495) teacher/entropy 0.0498 (0.0609) teacher/usage_max 0.6863 (0.6942) teacher/usage_min 0.1282 (0.1119) teacher/usage_std 0.2507 (0.2585) nleep/row_max_mean 1539.5634 (1551.3110) nleep/row_max_std 55.9507 (51.2941) nleep/row_min_mean 1506.6621 (1518.1139) lr 1.2487e-03 eta 0:11:20
epoch [23/50] batch [160/167] time 0.088 (0.147) data 0.000 (0.002) loss 1.8282 (2.0328) teacher_loss 0.0904 (0.1926) loss_zs_kd 0.0343 (0.0510) loss_oracle 0.8193 (1.0024) kd_loss 1.3109 (1.3135) acc 96.8750 (93.0469) gate/entropy 1.0045 (1.0043) gate/usage_max 0.5442 (0.5442) gate/usage_min 0.2163 (0.2142) gate/usage_std 0.1494 (0.1495) teacher/entropy 0.0550 (0.0600) teacher/usage_max 0.7014 (0.6955) teacher/usage_min 0.1340 (0.1129) teacher/usage_std 0.2605 (0.2593) nleep/row_max_mean 1554.1632 (1550.7605) nleep/row_max_std 36.3033 (50.8162) nleep/row_min_mean 1523.6809 (1517.6252) lr 1.2487e-03 eta 0:11:04
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,200
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [24/50] batch [20/167] time 0.099 (0.137) data 0.000 (0.015) loss 1.8473 (1.8818) teacher_loss 0.1649 (0.1678) loss_zs_kd 0.0598 (0.0442) loss_oracle 0.7799 (0.8191) kd_loss 1.2625 (1.2824) acc 93.7500 (94.3750) gate/entropy 1.0049 (1.0048) gate/usage_max 0.5439 (0.5439) gate/usage_min 0.2170 (0.2168) gate/usage_std 0.1492 (0.1492) teacher/entropy 0.0685 (0.0691) teacher/usage_max 0.5598 (0.6405) teacher/usage_min 0.1873 (0.1273) teacher/usage_std 0.1624 (0.2239) nleep/row_max_mean 1543.2012 (1545.6786) nleep/row_max_std 49.3744 (51.4343) nleep/row_min_mean 1511.5824 (1515.3745) lr 1.1874e-03 eta 0:10:14
epoch [24/50] batch [40/167] time 0.179 (0.121) data 0.000 (0.008) loss 1.5976 (1.8514) teacher_loss 0.0876 (0.1664) loss_zs_kd 0.0564 (0.0452) loss_oracle 0.7704 (0.8021) kd_loss 1.0966 (1.2613) acc 96.8750 (94.6094) gate/entropy 1.0055 (1.0049) gate/usage_max 0.5432 (0.5439) gate/usage_min 0.2176 (0.2170) gate/usage_std 0.1487 (0.1492) teacher/entropy 0.0614 (0.0708) teacher/usage_max 0.4352 (0.6185) teacher/usage_min 0.1834 (0.1421) teacher/usage_std 0.1082 (0.2082) nleep/row_max_mean 1534.3969 (1545.0836) nleep/row_max_std 61.3443 (50.9511) nleep/row_min_mean 1505.2726 (1515.3052) lr 1.1874e-03 eta 0:09:02
epoch [24/50] batch [60/167] time 0.158 (0.119) data 0.000 (0.005) loss 2.0218 (1.8667) teacher_loss 0.1752 (0.1687) loss_zs_kd 0.0749 (0.0485) loss_oracle 0.9755 (0.8302) kd_loss 1.3215 (1.2587) acc 96.8750 (94.2708) gate/entropy 1.0042 (1.0050) gate/usage_max 0.5448 (0.5438) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1497 (0.1491) teacher/entropy 0.0429 (0.0732) teacher/usage_max 0.6705 (0.6074) teacher/usage_min 0.1584 (0.1471) teacher/usage_std 0.2385 (0.2008) nleep/row_max_mean 1555.7144 (1544.5285) nleep/row_max_std 35.9802 (50.2732) nleep/row_min_mean 1525.3240 (1515.0522) lr 1.1874e-03 eta 0:08:48
epoch [24/50] batch [80/167] time 0.087 (0.117) data 0.000 (0.004) loss 1.6988 (1.8536) teacher_loss 0.1224 (0.1613) loss_zs_kd 0.0310 (0.0481) loss_oracle 0.8821 (0.8387) kd_loss 1.1199 (1.2489) acc 96.8750 (94.6484) gate/entropy 1.0053 (1.0051) gate/usage_max 0.5436 (0.5437) gate/usage_min 0.2181 (0.2174) gate/usage_std 0.1489 (0.1490) teacher/entropy 0.1397 (0.0745) teacher/usage_max 0.4687 (0.5891) teacher/usage_min 0.2596 (0.1532) teacher/usage_std 0.0958 (0.1899) nleep/row_max_mean 1548.2869 (1543.9849) nleep/row_max_std 60.0304 (50.4803) nleep/row_min_mean 1518.8191 (1514.8459) lr 1.1874e-03 eta 0:08:38
epoch [24/50] batch [100/167] time 0.096 (0.116) data 0.000 (0.003) loss 1.7079 (1.8474) teacher_loss 0.0746 (0.1594) loss_zs_kd 0.0203 (0.0475) loss_oracle 0.8622 (0.8347) kd_loss 1.1921 (1.2470) acc 96.8750 (94.6250) gate/entropy 1.0069 (1.0053) gate/usage_max 0.5417 (0.5435) gate/usage_min 0.2191 (0.2176) gate/usage_std 0.1475 (0.1489) teacher/entropy 0.1293 (0.0779) teacher/usage_max 0.4855 (0.5844) teacher/usage_min 0.1842 (0.1567) teacher/usage_std 0.1230 (0.1863) nleep/row_max_mean 1533.0745 (1542.0776) nleep/row_max_std 52.1240 (51.0462) nleep/row_min_mean 1509.5977 (1513.4049) lr 1.1874e-03 eta 0:08:29
epoch [24/50] batch [120/167] time 0.147 (0.120) data 0.000 (0.003) loss 1.9148 (1.8430) teacher_loss 0.2020 (0.1614) loss_zs_kd 0.0421 (0.0476) loss_oracle 0.8094 (0.8290) kd_loss 1.2870 (1.2433) acc 90.6250 (94.5052) gate/entropy 1.0065 (1.0055) gate/usage_max 0.5422 (0.5433) gate/usage_min 0.2191 (0.2179) gate/usage_std 0.1479 (0.1487) teacher/entropy 0.0359 (0.0769) teacher/usage_max 0.5135 (0.5746) teacher/usage_min 0.1873 (0.1635) teacher/usage_std 0.1354 (0.1791) nleep/row_max_mean 1535.0879 (1540.7622) nleep/row_max_std 40.3776 (50.6739) nleep/row_min_mean 1509.3423 (1512.3770) lr 1.1874e-03 eta 0:08:48
epoch [24/50] batch [140/167] time 0.150 (0.124) data 0.000 (0.002) loss 2.0525 (1.8365) teacher_loss 0.3271 (0.1589) loss_zs_kd 0.0656 (0.0475) loss_oracle 0.8120 (0.8259) kd_loss 1.2867 (1.2409) acc 84.3750 (94.5312) gate/entropy 1.0069 (1.0056) gate/usage_max 0.5417 (0.5432) gate/usage_min 0.2196 (0.2181) gate/usage_std 0.1475 (0.1486) teacher/entropy 0.0548 (0.0750) teacher/usage_max 0.5456 (0.5654) teacher/usage_min 0.1647 (0.1693) teacher/usage_std 0.1585 (0.1723) nleep/row_max_mean 1534.7651 (1540.2944) nleep/row_max_std 50.2733 (50.0477) nleep/row_min_mean 1507.3026 (1512.1902) lr 1.1874e-03 eta 0:09:03
epoch [24/50] batch [160/167] time 0.136 (0.127) data 0.000 (0.002) loss 2.0240 (1.8382) teacher_loss 0.3146 (0.1574) loss_zs_kd 0.0577 (0.0478) loss_oracle 0.9822 (0.8325) kd_loss 1.1894 (1.2407) acc 93.7500 (94.5898) gate/entropy 1.0073 (1.0058) gate/usage_max 0.5413 (0.5429) gate/usage_min 0.2200 (0.2183) gate/usage_std 0.1473 (0.1484) teacher/entropy 0.0288 (0.0746) teacher/usage_max 0.5218 (0.5627) teacher/usage_min 0.1648 (0.1713) teacher/usage_std 0.1465 (0.1706) nleep/row_max_mean 1546.4176 (1539.8976) nleep/row_max_std 47.5462 (50.2515) nleep/row_min_mean 1515.2740 (1511.9220) lr 1.1874e-03 eta 0:09:12
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [25/50] batch [20/167] time 0.151 (0.160) data 0.000 (0.012) loss 1.5554 (1.8751) teacher_loss 0.0189 (0.1741) loss_zs_kd 0.0437 (0.0514) loss_oracle 0.8083 (0.9044) kd_loss 1.1105 (1.2230) acc 100.0000 (92.1875) gate/entropy 1.0084 (1.0076) gate/usage_max 0.5400 (0.5409) gate/usage_min 0.2209 (0.2204) gate/usage_std 0.1464 (0.1470) teacher/entropy 0.0824 (0.0741) teacher/usage_max 0.3651 (0.5360) teacher/usage_min 0.3086 (0.1932) teacher/usage_std 0.0236 (0.1485) nleep/row_max_mean 1541.5182 (1541.9970) nleep/row_max_std 53.9197 (50.3741) nleep/row_min_mean 1512.5869 (1514.4690) lr 1.1253e-03 eta 0:11:30
epoch [25/50] batch [40/167] time 0.155 (0.155) data 0.000 (0.006) loss 1.5983 (1.8586) teacher_loss 0.0344 (0.1558) loss_zs_kd 0.0268 (0.0494) loss_oracle 0.7934 (0.9010) kd_loss 1.1538 (1.2276) acc 100.0000 (93.9062) gate/entropy 1.0085 (1.0078) gate/usage_max 0.5399 (0.5408) gate/usage_min 0.2213 (0.2206) gate/usage_std 0.1463 (0.1469) teacher/entropy 0.0751 (0.0712) teacher/usage_max 0.5400 (0.5433) teacher/usage_min 0.1614 (0.1884) teacher/usage_std 0.1565 (0.1541) nleep/row_max_mean 1543.9749 (1543.2109) nleep/row_max_std 49.7410 (51.0618) nleep/row_min_mean 1520.1119 (1515.5210) lr 1.1253e-03 eta 0:11:07
epoch [25/50] batch [60/167] time 0.119 (0.157) data 0.001 (0.004) loss 1.7775 (1.8574) teacher_loss 0.0729 (0.1551) loss_zs_kd 0.0480 (0.0507) loss_oracle 0.8625 (0.9006) kd_loss 1.2494 (1.2267) acc 100.0000 (94.3750) gate/entropy 1.0088 (1.0080) gate/usage_max 0.5397 (0.5405) gate/usage_min 0.2218 (0.2209) gate/usage_std 0.1461 (0.1467) teacher/entropy 0.0668 (0.0716) teacher/usage_max 0.5852 (0.5472) teacher/usage_min 0.1936 (0.1875) teacher/usage_std 0.1785 (0.1568) nleep/row_max_mean 1537.7467 (1542.7593) nleep/row_max_std 51.5628 (50.6813) nleep/row_min_mean 1511.1320 (1515.2287) lr 1.1253e-03 eta 0:11:10
epoch [25/50] batch [80/167] time 0.150 (0.145) data 0.000 (0.003) loss 1.8472 (1.8332) teacher_loss 0.0875 (0.1568) loss_zs_kd 0.0724 (0.0490) loss_oracle 0.9008 (0.8717) kd_loss 1.2731 (1.2161) acc 96.8750 (94.3359) gate/entropy 1.0093 (1.0083) gate/usage_max 0.5391 (0.5402) gate/usage_min 0.2223 (0.2212) gate/usage_std 0.1456 (0.1464) teacher/entropy 0.0407 (0.0730) teacher/usage_max 0.4734 (0.5324) teacher/usage_min 0.1876 (0.1948) teacher/usage_std 0.1167 (0.1470) nleep/row_max_mean 1542.1587 (1540.4275) nleep/row_max_std 32.7028 (49.6090) nleep/row_min_mean 1513.8612 (1513.2415) lr 1.1253e-03 eta 0:10:19
epoch [25/50] batch [100/167] time 0.074 (0.140) data 0.000 (0.003) loss 1.8746 (1.8172) teacher_loss 0.1323 (0.1528) loss_zs_kd 0.0408 (0.0486) loss_oracle 0.8735 (0.8657) kd_loss 1.2851 (1.2072) acc 93.7500 (94.6875) gate/entropy 1.0097 (1.0085) gate/usage_max 0.5386 (0.5400) gate/usage_min 0.2228 (0.2215) gate/usage_std 0.1453 (0.1463) teacher/entropy 0.0468 (0.0737) teacher/usage_max 0.5458 (0.5206) teacher/usage_min 0.1700 (0.2012) teacher/usage_std 0.1573 (0.1387) nleep/row_max_mean 1540.3416 (1540.2719) nleep/row_max_std 43.2724 (49.2885) nleep/row_min_mean 1515.4844 (1513.1347) lr 1.1253e-03 eta 0:09:52
epoch [25/50] batch [120/167] time 0.075 (0.136) data 0.000 (0.002) loss 1.8016 (1.8157) teacher_loss 0.0978 (0.1531) loss_zs_kd 0.0678 (0.0495) loss_oracle 1.0166 (0.8702) kd_loss 1.1616 (1.2027) acc 100.0000 (94.8177) gate/entropy 1.0099 (1.0087) gate/usage_max 0.5384 (0.5397) gate/usage_min 0.2231 (0.2217) gate/usage_std 0.1451 (0.1461) teacher/entropy 0.0612 (0.0735) teacher/usage_max 0.5253 (0.5160) teacher/usage_min 0.1716 (0.2021) teacher/usage_std 0.1460 (0.1360) nleep/row_max_mean 1544.8574 (1540.3891) nleep/row_max_std 53.6722 (49.3437) nleep/row_min_mean 1515.5441 (1513.1686) lr 1.1253e-03 eta 0:09:33
epoch [25/50] batch [140/167] time 0.089 (0.135) data 0.000 (0.002) loss 1.5562 (1.8122) teacher_loss 0.0911 (0.1542) loss_zs_kd 0.0309 (0.0492) loss_oracle 0.7900 (0.8703) kd_loss 1.0545 (1.1983) acc 100.0000 (94.8214) gate/entropy 1.0116 (1.0089) gate/usage_max 0.5364 (0.5394) gate/usage_min 0.2244 (0.2220) gate/usage_std 0.1437 (0.1459) teacher/entropy 0.0875 (0.0738) teacher/usage_max 0.4056 (0.5147) teacher/usage_min 0.2065 (0.2018) teacher/usage_std 0.0899 (0.1357) nleep/row_max_mean 1539.2673 (1541.0445) nleep/row_max_std 55.5134 (49.4718) nleep/row_min_mean 1508.3434 (1513.7388) lr 1.1253e-03 eta 0:09:26
epoch [25/50] batch [160/167] time 0.159 (0.129) data 0.000 (0.002) loss 1.8978 (1.8099) teacher_loss 0.1787 (0.1555) loss_zs_kd 0.0649 (0.0486) loss_oracle 0.9693 (0.8692) kd_loss 1.2021 (1.1955) acc 87.5000 (94.6875) gate/entropy 1.0096 (1.0092) gate/usage_max 0.5387 (0.5392) gate/usage_min 0.2237 (0.2222) gate/usage_std 0.1453 (0.1457) teacher/entropy 0.0271 (0.0732) teacher/usage_max 0.4701 (0.5125) teacher/usage_min 0.2418 (0.2018) teacher/usage_std 0.0985 (0.1345) nleep/row_max_mean 1572.4070 (1542.0818) nleep/row_max_std 38.1272 (49.3589) nleep/row_min_mean 1541.8809 (1514.5959) lr 1.1253e-03 eta 0:09:01
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,200
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [26/50] batch [20/167] time 0.136 (0.144) data 0.000 (0.014) loss 1.7745 (1.8047) teacher_loss 0.0582 (0.1487) loss_zs_kd 0.0434 (0.0489) loss_oracle 0.8936 (0.9334) kd_loss 1.2478 (1.1649) acc 100.0000 (94.3750) gate/entropy 1.0121 (1.0115) gate/usage_max 0.5358 (0.5366) gate/usage_min 0.2254 (0.2250) gate/usage_std 0.1433 (0.1438) teacher/entropy 0.0336 (0.0624) teacher/usage_max 0.4683 (0.5102) teacher/usage_min 0.2194 (0.1732) teacher/usage_std 0.1027 (0.1434) nleep/row_max_mean 1545.0476 (1543.9706) nleep/row_max_std 37.9024 (46.2678) nleep/row_min_mean 1519.4203 (1515.8940) lr 1.0628e-03 eta 0:09:58
epoch [26/50] batch [40/167] time 0.162 (0.147) data 0.000 (0.007) loss 1.8352 (1.8187) teacher_loss 0.1552 (0.1483) loss_zs_kd 0.0494 (0.0490) loss_oracle 0.8675 (0.9387) kd_loss 1.2215 (1.1765) acc 93.7500 (94.6875) gate/entropy 1.0127 (1.0116) gate/usage_max 0.5351 (0.5364) gate/usage_min 0.2262 (0.2252) gate/usage_std 0.1428 (0.1437) teacher/entropy 0.0572 (0.0668) teacher/usage_max 0.5577 (0.5160) teacher/usage_min 0.2156 (0.1840) teacher/usage_std 0.1587 (0.1424) nleep/row_max_mean 1540.1908 (1545.0621) nleep/row_max_std 38.4794 (45.7857) nleep/row_min_mean 1517.7930 (1517.1236) lr 1.0628e-03 eta 0:10:07
epoch [26/50] batch [60/167] time 0.140 (0.151) data 0.000 (0.005) loss 1.4291 (1.8290) teacher_loss 0.0383 (0.1440) loss_zs_kd 0.0421 (0.0515) loss_oracle 0.7882 (0.9517) kd_loss 0.9757 (1.1834) acc 96.8750 (94.9479) gate/entropy 1.0130 (1.0118) gate/usage_max 0.5349 (0.5362) gate/usage_min 0.2268 (0.2255) gate/usage_std 0.1426 (0.1436) teacher/entropy 0.1191 (0.0647) teacher/usage_max 0.4350 (0.5233) teacher/usage_min 0.2707 (0.1852) teacher/usage_std 0.0725 (0.1455) nleep/row_max_mean 1542.5977 (1545.0221) nleep/row_max_std 46.5532 (45.8458) nleep/row_min_mean 1512.3705 (1517.0214) lr 1.0628e-03 eta 0:10:22
epoch [26/50] batch [80/167] time 0.161 (0.150) data 0.000 (0.004) loss 1.7149 (1.8435) teacher_loss 0.0921 (0.1502) loss_zs_kd 0.0481 (0.0514) loss_oracle 0.8798 (0.9620) kd_loss 1.1588 (1.1865) acc 96.8750 (94.6875) gate/entropy 1.0126 (1.0121) gate/usage_max 0.5353 (0.5359) gate/usage_min 0.2270 (0.2259) gate/usage_std 0.1429 (0.1433) teacher/entropy 0.0474 (0.0662) teacher/usage_max 0.4341 (0.5278) teacher/usage_min 0.2585 (0.1860) teacher/usage_std 0.0740 (0.1473) nleep/row_max_mean 1545.8408 (1544.4556) nleep/row_max_std 44.6066 (45.4825) nleep/row_min_mean 1519.3044 (1516.5691) lr 1.0628e-03 eta 0:10:15
epoch [26/50] batch [100/167] time 0.129 (0.150) data 0.000 (0.003) loss 1.9445 (1.8455) teacher_loss 0.2347 (0.1525) loss_zs_kd 0.0471 (0.0512) loss_oracle 0.9219 (0.9599) kd_loss 1.2253 (1.1875) acc 87.5000 (94.6250) gate/entropy 1.0144 (1.0123) gate/usage_max 0.5331 (0.5356) gate/usage_min 0.2284 (0.2262) gate/usage_std 0.1413 (0.1431) teacher/entropy 0.0585 (0.0655) teacher/usage_max 0.6073 (0.5253) teacher/usage_min 0.1740 (0.1883) teacher/usage_std 0.1946 (0.1454) nleep/row_max_mean 1527.5579 (1544.4309) nleep/row_max_std 49.6055 (44.8839) nleep/row_min_mean 1502.2031 (1516.5033) lr 1.0628e-03 eta 0:10:09
epoch [26/50] batch [120/167] time 0.163 (0.149) data 0.000 (0.002) loss 1.9170 (1.8483) teacher_loss 0.1916 (0.1545) loss_zs_kd 0.0463 (0.0509) loss_oracle 0.9836 (0.9588) kd_loss 1.2104 (1.1890) acc 90.6250 (94.5833) gate/entropy 1.0147 (1.0126) gate/usage_max 0.5328 (0.5353) gate/usage_min 0.2290 (0.2266) gate/usage_std 0.1411 (0.1429) teacher/entropy 0.0657 (0.0659) teacher/usage_max 0.5628 (0.5245) teacher/usage_min 0.2136 (0.1907) teacher/usage_std 0.1623 (0.1442) nleep/row_max_mean 1539.0956 (1543.9070) nleep/row_max_std 48.0297 (44.7482) nleep/row_min_mean 1510.5479 (1516.1720) lr 1.0628e-03 eta 0:10:04
epoch [26/50] batch [140/167] time 0.151 (0.148) data 0.000 (0.002) loss 1.9405 (1.8504) teacher_loss 0.2618 (0.1516) loss_zs_kd 0.0705 (0.0509) loss_oracle 1.0264 (0.9635) kd_loss 1.1303 (1.1916) acc 93.7500 (94.7768) gate/entropy 1.0144 (1.0129) gate/usage_max 0.5332 (0.5349) gate/usage_min 0.2292 (0.2270) gate/usage_std 0.1414 (0.1426) teacher/entropy 0.0635 (0.0666) teacher/usage_max 0.5060 (0.5227) teacher/usage_min 0.1682 (0.1910) teacher/usage_std 0.1380 (0.1433) nleep/row_max_mean 1550.9319 (1543.3733) nleep/row_max_std 38.6680 (45.2265) nleep/row_min_mean 1521.0007 (1515.7299) lr 1.0628e-03 eta 0:09:57
epoch [26/50] batch [160/167] time 0.118 (0.148) data 0.000 (0.002) loss 1.9216 (1.8495) teacher_loss 0.2019 (0.1511) loss_zs_kd 0.0623 (0.0509) loss_oracle 1.0092 (0.9617) kd_loss 1.1839 (1.1921) acc 90.6250 (94.8438) gate/entropy 1.0152 (1.0133) gate/usage_max 0.5322 (0.5345) gate/usage_min 0.2301 (0.2274) gate/usage_std 0.1407 (0.1423) teacher/entropy 0.0440 (0.0660) teacher/usage_max 0.5343 (0.5218) teacher/usage_min 0.1845 (0.1921) teacher/usage_std 0.1475 (0.1425) nleep/row_max_mean 1554.7388 (1543.3381) nleep/row_max_std 41.3643 (45.5969) nleep/row_min_mean 1525.0862 (1515.5756) lr 1.0628e-03 eta 0:09:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,193
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [27/50] batch [20/167] time 0.193 (0.125) data 0.000 (0.012) loss 1.7485 (1.8539) teacher_loss 0.0997 (0.1390) loss_zs_kd 0.0878 (0.0499) loss_oracle 0.8640 (0.9250) kd_loss 1.1729 (1.2274) acc 96.8750 (95.3125) gate/entropy 1.0169 (1.0169) gate/usage_max 0.5302 (0.5301) gate/usage_min 0.2318 (0.2316) gate/usage_std 0.1392 (0.1392) teacher/entropy 0.0625 (0.0620) teacher/usage_max 0.4521 (0.5082) teacher/usage_min 0.2646 (0.1909) teacher/usage_std 0.0843 (0.1342) nleep/row_max_mean 1539.3563 (1539.8839) nleep/row_max_std 43.2667 (46.5369) nleep/row_min_mean 1508.0212 (1512.0194) lr 1.0000e-03 eta 0:08:18
epoch [27/50] batch [40/167] time 0.171 (0.123) data 0.000 (0.006) loss 1.5812 (1.8471) teacher_loss 0.0121 (0.1541) loss_zs_kd 0.0331 (0.0514) loss_oracle 0.8232 (0.9041) kd_loss 1.1410 (1.2152) acc 100.0000 (94.9219) gate/entropy 1.0178 (1.0172) gate/usage_max 0.5291 (0.5298) gate/usage_min 0.2327 (0.2320) gate/usage_std 0.1385 (0.1389) teacher/entropy 0.0867 (0.0533) teacher/usage_max 0.4555 (0.5132) teacher/usage_min 0.2687 (0.2025) teacher/usage_std 0.0865 (0.1346) nleep/row_max_mean 1548.2854 (1543.0077) nleep/row_max_std 53.3300 (47.1034) nleep/row_min_mean 1519.4384 (1514.8440) lr 1.0000e-03 eta 0:08:09
epoch [27/50] batch [60/167] time 0.095 (0.118) data 0.001 (0.004) loss 1.8325 (1.8393) teacher_loss 0.1315 (0.1583) loss_zs_kd 0.0701 (0.0510) loss_oracle 0.9325 (0.8986) kd_loss 1.1998 (1.2062) acc 96.8750 (94.5833) gate/entropy 1.0180 (1.0176) gate/usage_max 0.5289 (0.5294) gate/usage_min 0.2332 (0.2324) gate/usage_std 0.1383 (0.1387) teacher/entropy 0.0183 (0.0548) teacher/usage_max 0.3702 (0.4999) teacher/usage_min 0.2811 (0.2078) teacher/usage_std 0.0380 (0.1270) nleep/row_max_mean 1544.9324 (1542.9203) nleep/row_max_std 45.9070 (45.9878) nleep/row_min_mean 1511.9092 (1514.9649) lr 1.0000e-03 eta 0:07:45
epoch [27/50] batch [80/167] time 0.084 (0.115) data 0.000 (0.003) loss 1.6766 (1.8216) teacher_loss 0.0531 (0.1476) loss_zs_kd 0.0252 (0.0497) loss_oracle 1.0060 (0.8975) kd_loss 1.1078 (1.2004) acc 100.0000 (94.8438) gate/entropy 1.0191 (1.0179) gate/usage_max 0.5276 (0.5289) gate/usage_min 0.2343 (0.2328) gate/usage_std 0.1373 (0.1383) teacher/entropy 0.0684 (0.0582) teacher/usage_max 0.4638 (0.4971) teacher/usage_min 0.2013 (0.2062) teacher/usage_std 0.1072 (0.1255) nleep/row_max_mean 1556.8529 (1542.1402) nleep/row_max_std 31.1022 (45.2386) nleep/row_min_mean 1525.8005 (1514.4320) lr 1.0000e-03 eta 0:07:33
epoch [27/50] batch [100/167] time 0.194 (0.118) data 0.000 (0.003) loss 1.6181 (1.8230) teacher_loss 0.0104 (0.1481) loss_zs_kd 0.0243 (0.0497) loss_oracle 0.8934 (0.9041) kd_loss 1.1489 (1.1980) acc 100.0000 (94.7812) gate/entropy 1.0203 (1.0183) gate/usage_max 0.5260 (0.5285) gate/usage_min 0.2356 (0.2333) gate/usage_std 0.1363 (0.1380) teacher/entropy 0.0433 (0.0585) teacher/usage_max 0.4153 (0.5097) teacher/usage_min 0.2734 (0.1984) teacher/usage_std 0.0600 (0.1344) nleep/row_max_mean 1540.4491 (1541.8725) nleep/row_max_std 46.8137 (45.7492) nleep/row_min_mean 1508.3353 (1513.9298) lr 1.0000e-03 eta 0:07:41
epoch [27/50] batch [120/167] time 0.177 (0.119) data 0.000 (0.002) loss 1.5977 (1.8289) teacher_loss 0.0236 (0.1468) loss_zs_kd 0.0183 (0.0500) loss_oracle 0.7850 (0.9109) kd_loss 1.1725 (1.2016) acc 100.0000 (94.8698) gate/entropy 1.0213 (1.0187) gate/usage_max 0.5247 (0.5280) gate/usage_min 0.2369 (0.2338) gate/usage_std 0.1353 (0.1376) teacher/entropy 0.0397 (0.0563) teacher/usage_max 0.4469 (0.5179) teacher/usage_min 0.2713 (0.1963) teacher/usage_std 0.0804 (0.1394) nleep/row_max_mean 1546.1321 (1542.2657) nleep/row_max_std 51.4274 (45.7872) nleep/row_min_mean 1514.4331 (1514.0765) lr 1.0000e-03 eta 0:07:42
epoch [27/50] batch [140/167] time 0.158 (0.119) data 0.000 (0.002) loss 1.7359 (1.8305) teacher_loss 0.0940 (0.1497) loss_zs_kd 0.0382 (0.0494) loss_oracle 0.8629 (0.9109) kd_loss 1.1914 (1.2007) acc 96.8750 (94.7768) gate/entropy 1.0220 (1.0191) gate/usage_max 0.5238 (0.5275) gate/usage_min 0.2380 (0.2343) gate/usage_std 0.1347 (0.1373) teacher/entropy 0.0414 (0.0555) teacher/usage_max 0.4270 (0.5229) teacher/usage_min 0.2550 (0.1943) teacher/usage_std 0.0711 (0.1427) nleep/row_max_mean 1538.8782 (1543.5024) nleep/row_max_std 54.4619 (45.7664) nleep/row_min_mean 1511.5186 (1515.0324) lr 1.0000e-03 eta 0:07:40
epoch [27/50] batch [160/167] time 0.162 (0.124) data 0.000 (0.002) loss 1.7481 (1.8268) teacher_loss 0.0933 (0.1479) loss_zs_kd 0.0440 (0.0488) loss_oracle 0.8974 (0.9100) kd_loss 1.1841 (1.1995) acc 96.8750 (94.8438) gate/entropy 1.0236 (1.0195) gate/usage_max 0.5218 (0.5270) gate/usage_min 0.2385 (0.2347) gate/usage_std 0.1333 (0.1369) teacher/entropy 0.0250 (0.0543) teacher/usage_max 0.5189 (0.5253) teacher/usage_min 0.1996 (0.1932) teacher/usage_std 0.1354 (0.1441) nleep/row_max_mean 1531.2776 (1543.8943) nleep/row_max_std 63.3668 (46.6393) nleep/row_min_mean 1500.4261 (1515.2758) lr 1.0000e-03 eta 0:07:57
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [28/50] batch [20/167] time 0.145 (0.165) data 0.000 (0.018) loss 1.6462 (1.7722) teacher_loss 0.0504 (0.1280) loss_zs_kd 0.0572 (0.0425) loss_oracle 0.8740 (0.8557) kd_loss 1.1302 (1.1952) acc 100.0000 (95.7812) gate/entropy 1.0237 (1.0235) gate/usage_max 0.5217 (0.5219) gate/usage_min 0.2378 (0.2380) gate/usage_std 0.1332 (0.1334) teacher/entropy 0.0450 (0.0527) teacher/usage_max 0.4563 (0.5251) teacher/usage_min 0.2183 (0.1904) teacher/usage_std 0.0973 (0.1448) nleep/row_max_mean 1549.7131 (1548.3116) nleep/row_max_std 52.4067 (52.6603) nleep/row_min_mean 1515.2507 (1518.7103) lr 9.3721e-04 eta 0:10:28
epoch [28/50] batch [40/167] time 0.151 (0.157) data 0.000 (0.009) loss 1.7532 (1.7782) teacher_loss 0.1391 (0.1457) loss_zs_kd 0.0479 (0.0461) loss_oracle 0.8187 (0.8523) kd_loss 1.1808 (1.1833) acc 96.8750 (94.9219) gate/entropy 1.0248 (1.0240) gate/usage_max 0.5203 (0.5213) gate/usage_min 0.2380 (0.2381) gate/usage_std 0.1322 (0.1329) teacher/entropy 0.0250 (0.0545) teacher/usage_max 0.5067 (0.5134) teacher/usage_min 0.2116 (0.1928) teacher/usage_std 0.1259 (0.1370) nleep/row_max_mean 1541.4062 (1545.9503) nleep/row_max_std 54.8266 (53.0942) nleep/row_min_mean 1510.0795 (1516.6758) lr 9.3721e-04 eta 0:09:55
epoch [28/50] batch [60/167] time 0.148 (0.154) data 0.000 (0.006) loss 1.6749 (1.7790) teacher_loss 0.0649 (0.1474) loss_zs_kd 0.0355 (0.0456) loss_oracle 0.8556 (0.8550) kd_loss 1.1644 (1.1813) acc 96.8750 (95.1042) gate/entropy 1.0260 (1.0245) gate/usage_max 0.5187 (0.5207) gate/usage_min 0.2383 (0.2381) gate/usage_std 0.1311 (0.1325) teacher/entropy 0.0194 (0.0549) teacher/usage_max 0.3455 (0.5000) teacher/usage_min 0.3127 (0.2019) teacher/usage_std 0.0147 (0.1275) nleep/row_max_mean 1550.0535 (1545.1794) nleep/row_max_std 46.6345 (52.3510) nleep/row_min_mean 1516.7092 (1515.9031) lr 9.3721e-04 eta 0:09:43
epoch [28/50] batch [80/167] time 0.148 (0.154) data 0.000 (0.005) loss 1.9686 (1.7900) teacher_loss 0.1616 (0.1507) loss_zs_kd 0.0555 (0.0478) loss_oracle 0.9983 (0.8650) kd_loss 1.2801 (1.1828) acc 93.7500 (94.8438) gate/entropy 1.0263 (1.0249) gate/usage_max 0.5182 (0.5201) gate/usage_min 0.2380 (0.2381) gate/usage_std 0.1308 (0.1321) teacher/entropy 0.0718 (0.0548) teacher/usage_max 0.4992 (0.5025) teacher/usage_min 0.0941 (0.1969) teacher/usage_std 0.1733 (0.1317) nleep/row_max_mean 1538.7229 (1544.1315) nleep/row_max_std 33.8478 (51.0141) nleep/row_min_mean 1511.1699 (1515.1136) lr 9.3721e-04 eta 0:09:40
epoch [28/50] batch [100/167] time 0.081 (0.143) data 0.000 (0.004) loss 1.8641 (1.7882) teacher_loss 0.1424 (0.1466) loss_zs_kd 0.0436 (0.0472) loss_oracle 0.9429 (0.8715) kd_loss 1.2284 (1.1822) acc 93.7500 (95.0000) gate/entropy 1.0278 (1.0253) gate/usage_max 0.5163 (0.5196) gate/usage_min 0.2383 (0.2381) gate/usage_std 0.1294 (0.1317) teacher/entropy 0.0838 (0.0531) teacher/usage_max 0.4529 (0.5035) teacher/usage_min 0.1393 (0.1962) teacher/usage_std 0.1384 (0.1324) nleep/row_max_mean 1535.7883 (1543.3927) nleep/row_max_std 61.6379 (50.5933) nleep/row_min_mean 1509.2939 (1514.4344) lr 9.3721e-04 eta 0:08:55
epoch [28/50] batch [120/167] time 0.069 (0.138) data 0.000 (0.003) loss 1.7883 (1.7903) teacher_loss 0.1387 (0.1481) loss_zs_kd 0.0487 (0.0484) loss_oracle 0.8668 (0.8771) kd_loss 1.1918 (1.1794) acc 96.8750 (94.8438) gate/entropy 1.0285 (1.0257) gate/usage_max 0.5153 (0.5191) gate/usage_min 0.2381 (0.2381) gate/usage_std 0.1287 (0.1313) teacher/entropy 0.0322 (0.0532) teacher/usage_max 0.4739 (0.5033) teacher/usage_min 0.2509 (0.1950) teacher/usage_std 0.0999 (0.1327) nleep/row_max_mean 1542.0869 (1542.9325) nleep/row_max_std 48.9824 (50.0503) nleep/row_min_mean 1513.4475 (1513.8633) lr 9.3721e-04 eta 0:08:34
epoch [28/50] batch [140/167] time 0.102 (0.133) data 0.000 (0.003) loss 1.7729 (1.7855) teacher_loss 0.0973 (0.1451) loss_zs_kd 0.0491 (0.0481) loss_oracle 0.9618 (0.8744) kd_loss 1.1702 (1.1791) acc 96.8750 (94.8884) gate/entropy 1.0293 (1.0262) gate/usage_max 0.5142 (0.5184) gate/usage_min 0.2381 (0.2381) gate/usage_std 0.1280 (0.1309) teacher/entropy 0.0707 (0.0533) teacher/usage_max 0.5641 (0.5025) teacher/usage_min 0.2143 (0.1971) teacher/usage_std 0.1632 (0.1314) nleep/row_max_mean 1533.8230 (1542.2375) nleep/row_max_std 49.0194 (50.1170) nleep/row_min_mean 1506.3151 (1513.2977) lr 9.3721e-04 eta 0:08:10
epoch [28/50] batch [160/167] time 0.184 (0.132) data 0.000 (0.002) loss 1.8211 (1.7825) teacher_loss 0.1312 (0.1447) loss_zs_kd 0.0413 (0.0480) loss_oracle 1.0107 (0.8760) kd_loss 1.1639 (1.1758) acc 93.7500 (94.9219) gate/entropy 1.0291 (1.0266) gate/usage_max 0.5146 (0.5178) gate/usage_min 0.2372 (0.2380) gate/usage_std 0.1282 (0.1305) teacher/entropy 0.0560 (0.0540) teacher/usage_max 0.5683 (0.5010) teacher/usage_min 0.1822 (0.1978) teacher/usage_std 0.1684 (0.1305) nleep/row_max_mean 1549.9802 (1541.6458) nleep/row_max_std 42.0225 (49.6414) nleep/row_min_mean 1517.6421 (1512.8050) lr 9.3721e-04 eta 0:08:04
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,202
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [29/50] batch [20/167] time 0.085 (0.130) data 0.000 (0.015) loss 1.8658 (1.7047) teacher_loss 0.2290 (0.1515) loss_zs_kd 0.0555 (0.0495) loss_oracle 0.8230 (0.8138) kd_loss 1.1976 (1.1215) acc 90.6250 (95.4688) gate/entropy 1.0308 (1.0311) gate/usage_max 0.5121 (0.5118) gate/usage_min 0.2375 (0.2380) gate/usage_std 0.1265 (0.1263) teacher/entropy 0.0223 (0.0700) teacher/usage_max 0.4720 (0.4728) teacher/usage_min 0.2508 (0.2298) teacher/usage_std 0.0986 (0.1050) nleep/row_max_mean 1542.7778 (1532.5448) nleep/row_max_std 33.6308 (51.3019) nleep/row_min_mean 1515.6245 (1504.6608) lr 8.7467e-04 eta 0:07:55
epoch [29/50] batch [40/167] time 0.116 (0.125) data 0.000 (0.008) loss 1.7365 (1.7192) teacher_loss 0.1176 (0.1403) loss_zs_kd 0.0868 (0.0508) loss_oracle 0.8545 (0.8210) kd_loss 1.1482 (1.1430) acc 96.8750 (95.7812) gate/entropy 1.0311 (1.0314) gate/usage_max 0.5117 (0.5113) gate/usage_min 0.2371 (0.2379) gate/usage_std 0.1263 (0.1259) teacher/entropy 0.0465 (0.0662) teacher/usage_max 0.4682 (0.4898) teacher/usage_min 0.2482 (0.2187) teacher/usage_std 0.0965 (0.1168) nleep/row_max_mean 1549.9427 (1533.0055) nleep/row_max_std 53.4614 (51.4912) nleep/row_min_mean 1521.5420 (1505.2096) lr 8.7467e-04 eta 0:07:34
epoch [29/50] batch [60/167] time 0.155 (0.133) data 0.001 (0.005) loss 1.7152 (1.7058) teacher_loss 0.2170 (0.1437) loss_zs_kd 0.0608 (0.0499) loss_oracle 0.8656 (0.8026) kd_loss 1.0350 (1.1359) acc 90.6250 (95.8854) gate/entropy 1.0331 (1.0318) gate/usage_max 0.5089 (0.5107) gate/usage_min 0.2378 (0.2379) gate/usage_std 0.1243 (0.1256) teacher/entropy 0.1431 (0.0663) teacher/usage_max 0.4664 (0.4777) teacher/usage_min 0.2317 (0.2212) teacher/usage_std 0.0983 (0.1104) nleep/row_max_mean 1520.3794 (1534.3039) nleep/row_max_std 57.0523 (51.2947) nleep/row_min_mean 1494.7930 (1506.2415) lr 8.7467e-04 eta 0:08:00
epoch [29/50] batch [80/167] time 0.161 (0.138) data 0.000 (0.004) loss 1.4928 (1.6867) teacher_loss 0.0124 (0.1465) loss_zs_kd 0.0157 (0.0482) loss_oracle 0.6861 (0.7922) kd_loss 1.1295 (1.1200) acc 100.0000 (95.6641) gate/entropy 1.0347 (1.0322) gate/usage_max 0.5067 (0.5101) gate/usage_min 0.2384 (0.2379) gate/usage_std 0.1228 (0.1252) teacher/entropy 0.0149 (0.0704) teacher/usage_max 0.3724 (0.4712) teacher/usage_min 0.2812 (0.2194) teacher/usage_std 0.0384 (0.1081) nleep/row_max_mean 1526.9819 (1533.5531) nleep/row_max_std 54.7794 (51.5207) nleep/row_min_mean 1498.6198 (1505.5157) lr 8.7467e-04 eta 0:08:15
epoch [29/50] batch [100/167] time 0.163 (0.142) data 0.000 (0.003) loss 1.9349 (1.6789) teacher_loss 0.3805 (0.1530) loss_zs_kd 0.0793 (0.0482) loss_oracle 0.8173 (0.7819) kd_loss 1.1061 (1.1109) acc 84.3750 (95.2500) gate/entropy 1.0329 (1.0326) gate/usage_max 0.5091 (0.5096) gate/usage_min 0.2366 (0.2378) gate/usage_std 0.1245 (0.1248) teacher/entropy 0.1181 (0.0731) teacher/usage_max 0.4985 (0.4656) teacher/usage_min 0.2356 (0.2222) teacher/usage_std 0.1175 (0.1043) nleep/row_max_mean 1550.5277 (1532.8843) nleep/row_max_std 49.8717 (51.9422) nleep/row_min_mean 1522.6516 (1504.9336) lr 8.7467e-04 eta 0:08:27
epoch [29/50] batch [120/167] time 0.153 (0.146) data 0.000 (0.003) loss 1.4481 (1.6605) teacher_loss 0.1795 (0.1576) loss_zs_kd 0.0573 (0.0478) loss_oracle 0.5512 (0.7660) kd_loss 0.9643 (1.0961) acc 93.7500 (94.9219) gate/entropy 1.0351 (1.0329) gate/usage_max 0.5060 (0.5092) gate/usage_min 0.2378 (0.2378) gate/usage_std 0.1223 (0.1245) teacher/entropy 0.1278 (0.0750) teacher/usage_max 0.4329 (0.4602) teacher/usage_min 0.2254 (0.2242) teacher/usage_std 0.0849 (0.1010) nleep/row_max_mean 1528.0767 (1532.9005) nleep/row_max_std 53.3637 (52.0126) nleep/row_min_mean 1497.7981 (1504.7434) lr 8.7467e-04 eta 0:08:37
epoch [29/50] batch [140/167] time 0.142 (0.148) data 0.000 (0.002) loss 1.2440 (1.6402) teacher_loss 0.2191 (0.1706) loss_zs_kd 0.0522 (0.0459) loss_oracle 0.5432 (0.7441) kd_loss 0.7271 (1.0745) acc 93.7500 (94.5089) gate/entropy 1.0356 (1.0332) gate/usage_max 0.5053 (0.5088) gate/usage_min 0.2377 (0.2377) gate/usage_std 0.1218 (0.1242) teacher/entropy 0.1367 (0.0762) teacher/usage_max 0.7435 (0.4680) teacher/usage_min 0.1160 (0.2175) teacher/usage_std 0.2902 (0.1074) nleep/row_max_mean 1515.7725 (1533.2107) nleep/row_max_std 67.8362 (52.3415) nleep/row_min_mean 1484.3761 (1504.6463) lr 8.7467e-04 eta 0:08:44
epoch [29/50] batch [160/167] time 0.142 (0.149) data 0.000 (0.002) loss 1.2327 (1.6189) teacher_loss 0.1639 (0.1792) loss_zs_kd 0.0425 (0.0456) loss_oracle 0.5219 (0.7189) kd_loss 0.7866 (1.0574) acc 93.7500 (94.1016) gate/entropy 1.0340 (1.0334) gate/usage_max 0.5076 (0.5084) gate/usage_min 0.2365 (0.2377) gate/usage_std 0.1234 (0.1240) teacher/entropy 0.0845 (0.0773) teacher/usage_max 0.7340 (0.4762) teacher/usage_min 0.1071 (0.2137) teacher/usage_std 0.2841 (0.1129) nleep/row_max_mean 1556.4104 (1532.7727) nleep/row_max_std 51.5524 (52.5425) nleep/row_min_mean 1519.0183 (1503.8770) lr 8.7467e-04 eta 0:08:43
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [30/50] batch [20/167] time 0.157 (0.127) data 0.000 (0.010) loss 1.0908 (1.3580) teacher_loss 0.1055 (0.2138) loss_zs_kd 0.0482 (0.0460) loss_oracle 0.5161 (0.5231) kd_loss 0.7031 (0.8597) acc 96.8750 (92.8125) gate/entropy 1.0343 (1.0346) gate/usage_max 0.5072 (0.5067) gate/usage_min 0.2369 (0.2370) gate/usage_std 0.1232 (0.1229) teacher/entropy 0.1088 (0.0683) teacher/usage_max 0.8216 (0.6587) teacher/usage_min 0.0389 (0.1218) teacher/usage_std 0.3477 (0.2365) nleep/row_max_mean 1547.0247 (1537.4943) nleep/row_max_std 51.0248 (53.3671) nleep/row_min_mean 1509.6541 (1503.3098) lr 8.1262e-04 eta 0:07:23
epoch [30/50] batch [40/167] time 0.079 (0.120) data 0.000 (0.005) loss 1.3937 (1.3906) teacher_loss 0.1441 (0.2145) loss_zs_kd 0.0494 (0.0457) loss_oracle 0.5772 (0.5467) kd_loss 0.9363 (0.8799) acc 96.8750 (91.4062) gate/entropy 1.0334 (1.0343) gate/usage_max 0.5083 (0.5071) gate/usage_min 0.2364 (0.2369) gate/usage_std 0.1240 (0.1231) teacher/entropy 0.0266 (0.0467) teacher/usage_max 0.6120 (0.6602) teacher/usage_min 0.0941 (0.1198) teacher/usage_std 0.2133 (0.2373) nleep/row_max_mean 1559.1311 (1538.6249) nleep/row_max_std 48.0995 (55.7691) nleep/row_min_mean 1516.1641 (1502.4362) lr 8.1262e-04 eta 0:06:57
epoch [30/50] batch [60/167] time 0.095 (0.121) data 0.001 (0.004) loss 1.3492 (1.3821) teacher_loss 0.1968 (0.1996) loss_zs_kd 0.0529 (0.0444) loss_oracle 0.5671 (0.5511) kd_loss 0.8423 (0.8848) acc 96.8750 (92.2396) gate/entropy 1.0335 (1.0341) gate/usage_max 0.5082 (0.5074) gate/usage_min 0.2366 (0.2368) gate/usage_std 0.1239 (0.1233) teacher/entropy 0.0142 (0.0416) teacher/usage_max 0.7467 (0.6596) teacher/usage_min 0.0968 (0.1225) teacher/usage_std 0.2933 (0.2363) nleep/row_max_mean 1544.1926 (1540.1280) nleep/row_max_std 56.4788 (56.0672) nleep/row_min_mean 1500.3226 (1502.5720) lr 8.1262e-04 eta 0:06:55
epoch [30/50] batch [80/167] time 0.087 (0.119) data 0.000 (0.003) loss 1.3549 (1.3843) teacher_loss 0.1698 (0.2048) loss_zs_kd 0.0557 (0.0448) loss_oracle 0.5027 (0.5508) kd_loss 0.9059 (0.8817) acc 93.7500 (91.9141) gate/entropy 1.0329 (1.0338) gate/usage_max 0.5091 (0.5078) gate/usage_min 0.2363 (0.2367) gate/usage_std 0.1245 (0.1236) teacher/entropy 0.0384 (0.0362) teacher/usage_max 0.6454 (0.6706) teacher/usage_min 0.0589 (0.1182) teacher/usage_std 0.2409 (0.2436) nleep/row_max_mean 1533.0374 (1540.9006) nleep/row_max_std 65.6092 (56.9983) nleep/row_min_mean 1494.0613 (1502.0761) lr 8.1262e-04 eta 0:06:46
epoch [30/50] batch [100/167] time 0.076 (0.118) data 0.000 (0.002) loss 1.2640 (1.3856) teacher_loss 0.2094 (0.2080) loss_zs_kd 0.0438 (0.0459) loss_oracle 0.5218 (0.5542) kd_loss 0.7718 (0.8775) acc 93.7500 (91.9062) gate/entropy 1.0318 (1.0335) gate/usage_max 0.5105 (0.5082) gate/usage_min 0.2358 (0.2365) gate/usage_std 0.1255 (0.1239) teacher/entropy 0.0149 (0.0327) teacher/usage_max 0.8418 (0.6804) teacher/usage_min 0.0659 (0.1137) teacher/usage_std 0.3597 (0.2504) nleep/row_max_mean 1553.3411 (1542.3346) nleep/row_max_std 60.7356 (57.2000) nleep/row_min_mean 1508.1130 (1502.3677) lr 8.1262e-04 eta 0:06:43
epoch [30/50] batch [120/167] time 0.181 (0.118) data 0.000 (0.002) loss 1.5009 (1.3904) teacher_loss 0.3210 (0.2138) loss_zs_kd 0.0344 (0.0457) loss_oracle 0.5376 (0.5533) kd_loss 0.8939 (0.8771) acc 87.5000 (91.7708) gate/entropy 1.0310 (1.0332) gate/usage_max 0.5116 (0.5086) gate/usage_min 0.2353 (0.2364) gate/usage_std 0.1263 (0.1242) teacher/entropy 0.0265 (0.0299) teacher/usage_max 0.6655 (0.6845) teacher/usage_min 0.1235 (0.1122) teacher/usage_std 0.2376 (0.2531) nleep/row_max_mean 1558.0710 (1543.4929) nleep/row_max_std 54.9283 (56.9593) nleep/row_min_mean 1510.7251 (1502.3464) lr 8.1262e-04 eta 0:06:39
epoch [30/50] batch [140/167] time 0.133 (0.117) data 0.000 (0.002) loss 1.4034 (1.3914) teacher_loss 0.1977 (0.2183) loss_zs_kd 0.0571 (0.0449) loss_oracle 0.5591 (0.5488) kd_loss 0.8976 (0.8761) acc 93.7500 (91.5179) gate/entropy 1.0311 (1.0329) gate/usage_max 0.5116 (0.5090) gate/usage_min 0.2356 (0.2363) gate/usage_std 0.1262 (0.1245) teacher/entropy 0.0004 (0.0279) teacher/usage_max 0.6875 (0.6880) teacher/usage_min 0.1250 (0.1119) teacher/usage_std 0.2517 (0.2552) nleep/row_max_mean 1559.2534 (1544.9985) nleep/row_max_std 51.5518 (56.4122) nleep/row_min_mean 1505.4469 (1502.5540) lr 8.1262e-04 eta 0:06:34
epoch [30/50] batch [160/167] time 0.163 (0.118) data 0.000 (0.001) loss 1.4870 (1.3875) teacher_loss 0.2991 (0.2180) loss_zs_kd 0.0238 (0.0440) loss_oracle 0.5332 (0.5445) kd_loss 0.9094 (0.8752) acc 87.5000 (91.4844) gate/entropy 1.0287 (1.0326) gate/usage_max 0.5148 (0.5095) gate/usage_min 0.2342 (0.2361) gate/usage_std 0.1285 (0.1248) teacher/entropy 0.0406 (0.0276) teacher/usage_max 0.6247 (0.6893) teacher/usage_min 0.1065 (0.1105) teacher/usage_std 0.2164 (0.2561) nleep/row_max_mean 1575.7085 (1546.0223) nleep/row_max_std 46.4189 (56.9774) nleep/row_min_mean 1524.7043 (1502.7439) lr 8.1262e-04 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,182
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [31/50] batch [20/167] time 0.134 (0.159) data 0.000 (0.013) loss 1.3064 (1.3178) teacher_loss 0.1839 (0.1974) loss_zs_kd 0.0228 (0.0344) loss_oracle 0.5435 (0.5391) kd_loss 0.8394 (0.8336) acc 93.7500 (92.0312) gate/entropy 1.0282 (1.0293) gate/usage_max 0.5155 (0.5141) gate/usage_min 0.2342 (0.2347) gate/usage_std 0.1290 (0.1280) teacher/entropy 0.0112 (0.0219) teacher/usage_max 0.7500 (0.7506) teacher/usage_min 0.1229 (0.0706) teacher/usage_std 0.2946 (0.3004) nleep/row_max_mean 1574.7815 (1556.3469) nleep/row_max_std 55.9522 (58.3893) nleep/row_min_mean 1518.6045 (1502.1303) lr 7.5131e-04 eta 0:08:47
epoch [31/50] batch [40/167] time 0.165 (0.153) data 0.000 (0.006) loss 1.3571 (1.3524) teacher_loss 0.2440 (0.2061) loss_zs_kd 0.0584 (0.0371) loss_oracle 0.5581 (0.5425) kd_loss 0.8049 (0.8565) acc 87.5000 (92.1094) gate/entropy 1.0277 (1.0289) gate/usage_max 0.5161 (0.5145) gate/usage_min 0.2341 (0.2346) gate/usage_std 0.1294 (0.1283) teacher/entropy 0.0241 (0.0255) teacher/usage_max 0.7818 (0.7159) teacher/usage_min 0.0792 (0.0739) teacher/usage_std 0.3181 (0.2800) nleep/row_max_mean 1560.4520 (1554.4385) nleep/row_max_std 67.3388 (58.4631) nleep/row_min_mean 1504.7075 (1501.5910) lr 7.5131e-04 eta 0:08:25
epoch [31/50] batch [60/167] time 0.193 (0.157) data 0.001 (0.004) loss 1.3638 (1.3536) teacher_loss 0.1395 (0.1992) loss_zs_kd 0.0227 (0.0382) loss_oracle 0.5305 (0.5390) kd_loss 0.9477 (0.8658) acc 90.6250 (92.0312) gate/entropy 1.0283 (1.0286) gate/usage_max 0.5154 (0.5150) gate/usage_min 0.2347 (0.2345) gate/usage_std 0.1289 (0.1286) teacher/entropy 0.0490 (0.0253) teacher/usage_max 0.5712 (0.7041) teacher/usage_min 0.0508 (0.0705) teacher/usage_std 0.2148 (0.2735) nleep/row_max_mean 1559.0378 (1554.8040) nleep/row_max_std 50.4593 (59.0969) nleep/row_min_mean 1507.1678 (1502.0467) lr 7.5131e-04 eta 0:08:34
epoch [31/50] batch [80/167] time 0.159 (0.158) data 0.000 (0.003) loss 1.3077 (1.3457) teacher_loss 0.1384 (0.1942) loss_zs_kd 0.0358 (0.0379) loss_oracle 0.4868 (0.5349) kd_loss 0.9080 (0.8652) acc 96.8750 (92.6172) gate/entropy 1.0278 (1.0282) gate/usage_max 0.5161 (0.5154) gate/usage_min 0.2347 (0.2344) gate/usage_std 0.1294 (0.1289) teacher/entropy 0.0313 (0.0256) teacher/usage_max 0.6452 (0.7043) teacher/usage_min 0.0307 (0.0651) teacher/usage_std 0.2509 (0.2744) nleep/row_max_mean 1550.7181 (1555.5725) nleep/row_max_std 58.2342 (59.5457) nleep/row_min_mean 1500.3046 (1502.4376) lr 7.5131e-04 eta 0:08:34
epoch [31/50] batch [100/167] time 0.164 (0.157) data 0.000 (0.003) loss 1.1960 (1.3466) teacher_loss 0.0233 (0.1937) loss_zs_kd 0.0287 (0.0378) loss_oracle 0.4957 (0.5331) kd_loss 0.9105 (0.8675) acc 100.0000 (92.5938) gate/entropy 1.0262 (1.0280) gate/usage_max 0.5182 (0.5158) gate/usage_min 0.2339 (0.2344) gate/usage_std 0.1309 (0.1292) teacher/entropy 0.0148 (0.0240) teacher/usage_max 0.6563 (0.7032) teacher/usage_min 0.0678 (0.0603) teacher/usage_std 0.2436 (0.2745) nleep/row_max_mean 1566.0547 (1555.3498) nleep/row_max_std 61.2096 (59.9336) nleep/row_min_mean 1511.5105 (1502.1145) lr 7.5131e-04 eta 0:08:30
epoch [31/50] batch [120/167] time 0.103 (0.148) data 0.000 (0.002) loss 1.1512 (1.3488) teacher_loss 0.1291 (0.1998) loss_zs_kd 0.0179 (0.0373) loss_oracle 0.4829 (0.5301) kd_loss 0.7718 (0.8653) acc 96.8750 (92.5521) gate/entropy 1.0258 (1.0277) gate/usage_max 0.5188 (0.5163) gate/usage_min 0.2339 (0.2343) gate/usage_std 0.1312 (0.1295) teacher/entropy 0.0259 (0.0241) teacher/usage_max 0.8190 (0.7057) teacher/usage_min 0.0017 (0.0552) teacher/usage_std 0.3510 (0.2774) nleep/row_max_mean 1573.3787 (1556.2830) nleep/row_max_std 59.9801 (60.1265) nleep/row_min_mean 1513.4414 (1502.3475) lr 7.5131e-04 eta 0:07:56
epoch [31/50] batch [140/167] time 0.093 (0.145) data 0.000 (0.002) loss 1.3516 (1.3508) teacher_loss 0.2557 (0.2055) loss_zs_kd 0.0222 (0.0370) loss_oracle 0.5554 (0.5266) kd_loss 0.8071 (0.8635) acc 90.6250 (92.1652) gate/entropy 1.0253 (1.0273) gate/usage_max 0.5195 (0.5167) gate/usage_min 0.2339 (0.2342) gate/usage_std 0.1317 (0.1298) teacher/entropy 0.0201 (0.0238) teacher/usage_max 0.7836 (0.7080) teacher/usage_min 0.0000 (0.0495) teacher/usage_std 0.3304 (0.2799) nleep/row_max_mean 1560.7952 (1556.8552) nleep/row_max_std 46.9160 (59.7258) nleep/row_min_mean 1499.4756 (1502.6515) lr 7.5131e-04 eta 0:07:42
epoch [31/50] batch [160/167] time 0.160 (0.142) data 0.000 (0.002) loss 1.2947 (1.3528) teacher_loss 0.2134 (0.2072) loss_zs_kd 0.0464 (0.0368) loss_oracle 0.5466 (0.5274) kd_loss 0.7847 (0.8634) acc 96.8750 (91.9922) gate/entropy 1.0242 (1.0270) gate/usage_max 0.5208 (0.5171) gate/usage_min 0.2336 (0.2342) gate/usage_std 0.1327 (0.1301) teacher/entropy 0.0161 (0.0226) teacher/usage_max 0.8141 (0.7094) teacher/usage_min 0.0000 (0.0450) teacher/usage_std 0.3483 (0.2818) nleep/row_max_mean 1558.9357 (1556.6233) nleep/row_max_std 54.9892 (59.6519) nleep/row_min_mean 1502.9512 (1502.2883) lr 7.5131e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,182
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [32/50] batch [20/167] time 0.125 (0.144) data 0.000 (0.016) loss 1.4156 (1.3246) teacher_loss 0.2365 (0.1978) loss_zs_kd 0.0187 (0.0290) loss_oracle 0.5457 (0.5089) kd_loss 0.8969 (0.8578) acc 93.7500 (92.1875) gate/entropy 1.0234 (1.0238) gate/usage_max 0.5219 (0.5214) gate/usage_min 0.2335 (0.2336) gate/usage_std 0.1334 (0.1330) teacher/entropy 0.0073 (0.0144) teacher/usage_max 0.6856 (0.7233) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.2802 (0.3019) nleep/row_max_mean 1553.9824 (1562.9834) nleep/row_max_std 62.0416 (59.1680) nleep/row_min_mean 1497.0212 (1506.6484) lr 6.9098e-04 eta 0:07:34
epoch [32/50] batch [40/167] time 0.079 (0.131) data 0.000 (0.008) loss 1.3408 (1.3480) teacher_loss 0.1779 (0.2115) loss_zs_kd 0.0290 (0.0300) loss_oracle 0.4510 (0.5137) kd_loss 0.9229 (0.8646) acc 90.6250 (91.6406) gate/entropy 1.0236 (1.0236) gate/usage_max 0.5217 (0.5217) gate/usage_min 0.2339 (0.2336) gate/usage_std 0.1332 (0.1332) teacher/entropy 0.0017 (0.0170) teacher/usage_max 0.6565 (0.7115) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.2681 (0.2968) nleep/row_max_mean 1560.9021 (1560.7775) nleep/row_max_std 49.3457 (59.4375) nleep/row_min_mean 1507.2300 (1505.0605) lr 6.9098e-04 eta 0:06:50
epoch [32/50] batch [60/167] time 0.164 (0.134) data 0.001 (0.006) loss 1.2589 (1.3537) teacher_loss 0.1984 (0.2210) loss_zs_kd 0.0244 (0.0309) loss_oracle 0.5040 (0.5129) kd_loss 0.7962 (0.8608) acc 87.5000 (90.8333) gate/entropy 1.0234 (1.0233) gate/usage_max 0.5220 (0.5220) gate/usage_min 0.2340 (0.2336) gate/usage_std 0.1335 (0.1335) teacher/entropy 0.0044 (0.0157) teacher/usage_max 0.8116 (0.7173) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3468 (0.2993) nleep/row_max_mean 1537.8885 (1558.6789) nleep/row_max_std 71.0148 (59.9468) nleep/row_min_mean 1481.9749 (1503.1570) lr 6.9098e-04 eta 0:06:58
epoch [32/50] batch [80/167] time 0.165 (0.139) data 0.000 (0.004) loss 1.3649 (1.3531) teacher_loss 0.2282 (0.2164) loss_zs_kd 0.0463 (0.0312) loss_oracle 0.4853 (0.5101) kd_loss 0.8709 (0.8661) acc 93.7500 (91.1719) gate/entropy 1.0211 (1.0230) gate/usage_max 0.5249 (0.5224) gate/usage_min 0.2329 (0.2335) gate/usage_std 0.1355 (0.1338) teacher/entropy 0.0015 (0.0144) teacher/usage_max 0.7189 (0.7116) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2958 (0.2962) nleep/row_max_mean 1556.5186 (1557.4939) nleep/row_max_std 49.6642 (59.1635) nleep/row_min_mean 1502.8105 (1502.4148) lr 6.9098e-04 eta 0:07:08
epoch [32/50] batch [100/167] time 0.138 (0.142) data 0.000 (0.003) loss 1.2899 (1.3609) teacher_loss 0.0872 (0.2217) loss_zs_kd 0.0466 (0.0312) loss_oracle 0.4626 (0.5097) kd_loss 0.9481 (0.8687) acc 96.8750 (90.8750) gate/entropy 1.0210 (1.0228) gate/usage_max 0.5251 (0.5228) gate/usage_min 0.2331 (0.2335) gate/usage_std 0.1356 (0.1340) teacher/entropy 0.0003 (0.0132) teacher/usage_max 0.6250 (0.7092) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2568 (0.2953) nleep/row_max_mean 1563.9755 (1556.9567) nleep/row_max_std 52.1160 (58.5675) nleep/row_min_mean 1511.0027 (1501.9596) lr 6.9098e-04 eta 0:07:17
epoch [32/50] batch [120/167] time 0.179 (0.146) data 0.000 (0.003) loss 1.2641 (1.3679) teacher_loss 0.1432 (0.2229) loss_zs_kd 0.0290 (0.0321) loss_oracle 0.5855 (0.5137) kd_loss 0.8137 (0.8721) acc 90.6250 (90.7812) gate/entropy 1.0215 (1.0225) gate/usage_max 0.5244 (0.5231) gate/usage_min 0.2338 (0.2335) gate/usage_std 0.1352 (0.1342) teacher/entropy 0.0065 (0.0133) teacher/usage_max 0.7827 (0.7044) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.3299 (0.2932) nleep/row_max_mean 1534.7695 (1555.5862) nleep/row_max_std 71.2397 (58.3342) nleep/row_min_mean 1477.5881 (1500.9643) lr 6.9098e-04 eta 0:07:24
epoch [32/50] batch [140/167] time 0.143 (0.148) data 0.000 (0.002) loss 1.6443 (1.3629) teacher_loss 0.4930 (0.2187) loss_zs_kd 0.0399 (0.0319) loss_oracle 0.5541 (0.5145) kd_loss 0.8543 (0.8710) acc 84.3750 (91.1384) gate/entropy 1.0204 (1.0222) gate/usage_max 0.5258 (0.5234) gate/usage_min 0.2333 (0.2335) gate/usage_std 0.1361 (0.1345) teacher/entropy 0.0119 (0.0141) teacher/usage_max 0.7226 (0.7043) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2977 (0.2931) nleep/row_max_mean 1546.2985 (1554.8193) nleep/row_max_std 63.6065 (57.8714) nleep/row_min_mean 1489.7489 (1500.3932) lr 6.9098e-04 eta 0:07:28
epoch [32/50] batch [160/167] time 0.131 (0.148) data 0.000 (0.002) loss 1.2292 (1.3629) teacher_loss 0.1280 (0.2214) loss_zs_kd 0.0245 (0.0317) loss_oracle 0.4949 (0.5139) kd_loss 0.8416 (0.8687) acc 96.8750 (91.1719) gate/entropy 1.0191 (1.0220) gate/usage_max 0.5274 (0.5238) gate/usage_min 0.2328 (0.2334) gate/usage_std 0.1373 (0.1347) teacher/entropy 0.0011 (0.0136) teacher/usage_max 0.7498 (0.7072) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3117 (0.2946) nleep/row_max_mean 1569.0464 (1554.7886) nleep/row_max_std 48.7266 (56.9735) nleep/row_min_mean 1513.5516 (1500.2530) lr 6.9098e-04 eta 0:07:25
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,177
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [33/50] batch [20/167] time 0.084 (0.119) data 0.000 (0.014) loss 1.4399 (1.3219) teacher_loss 0.2291 (0.1819) loss_zs_kd 0.0407 (0.0328) loss_oracle 0.5413 (0.5276) kd_loss 0.9198 (0.8599) acc 90.6250 (93.5938) gate/entropy 1.0192 (1.0195) gate/usage_max 0.5274 (0.5270) gate/usage_min 0.2331 (0.2332) gate/usage_std 0.1372 (0.1370) teacher/entropy 0.0180 (0.0153) teacher/usage_max 0.6332 (0.7111) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.2596 (0.2979) nleep/row_max_mean 1546.0016 (1552.0971) nleep/row_max_std 52.1067 (51.4358) nleep/row_min_mean 1495.7341 (1497.1336) lr 6.3188e-04 eta 0:05:54
epoch [33/50] batch [40/167] time 0.184 (0.119) data 0.000 (0.007) loss 1.3463 (1.3232) teacher_loss 0.2374 (0.1803) loss_zs_kd 0.0364 (0.0338) loss_oracle 0.4977 (0.5274) kd_loss 0.8419 (0.8622) acc 87.5000 (93.0469) gate/entropy 1.0183 (1.0192) gate/usage_max 0.5285 (0.5274) gate/usage_min 0.2328 (0.2332) gate/usage_std 0.1380 (0.1372) teacher/entropy 0.0003 (0.0159) teacher/usage_max 0.7500 (0.7068) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.3118 (0.2945) nleep/row_max_mean 1552.9546 (1551.5629) nleep/row_max_std 48.1668 (49.9927) nleep/row_min_mean 1499.2458 (1497.3038) lr 6.3188e-04 eta 0:05:52
epoch [33/50] batch [60/167] time 0.096 (0.116) data 0.001 (0.005) loss 1.4970 (1.3390) teacher_loss 0.4083 (0.1976) loss_zs_kd 0.0420 (0.0339) loss_oracle 0.4773 (0.5277) kd_loss 0.8290 (0.8606) acc 84.3750 (92.3438) gate/entropy 1.0180 (1.0189) gate/usage_max 0.5288 (0.5277) gate/usage_min 0.2330 (0.2331) gate/usage_std 0.1382 (0.1375) teacher/entropy 0.0173 (0.0161) teacher/usage_max 0.7433 (0.7081) teacher/usage_min 0.0001 (0.0020) teacher/usage_std 0.3082 (0.2947) nleep/row_max_mean 1560.3741 (1552.1322) nleep/row_max_std 48.6672 (49.5432) nleep/row_min_mean 1502.6432 (1498.0113) lr 6.3188e-04 eta 0:05:40
epoch [33/50] batch [80/167] time 0.187 (0.118) data 0.000 (0.004) loss 1.3795 (1.3344) teacher_loss 0.1836 (0.2019) loss_zs_kd 0.0347 (0.0330) loss_oracle 0.4997 (0.5226) kd_loss 0.9288 (0.8547) acc 96.8750 (92.4219) gate/entropy 1.0175 (1.0186) gate/usage_max 0.5295 (0.5281) gate/usage_min 0.2328 (0.2331) gate/usage_std 0.1387 (0.1377) teacher/entropy 0.0107 (0.0165) teacher/usage_max 0.6278 (0.7144) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.2577 (0.2980) nleep/row_max_mean 1546.5732 (1551.9119) nleep/row_max_std 47.8463 (49.6114) nleep/row_min_mean 1495.5459 (1497.8172) lr 6.3188e-04 eta 0:05:45
epoch [33/50] batch [100/167] time 0.107 (0.115) data 0.000 (0.003) loss 1.3922 (1.3354) teacher_loss 0.1589 (0.2023) loss_zs_kd 0.0260 (0.0326) loss_oracle 0.5416 (0.5210) kd_loss 0.9494 (0.8563) acc 93.7500 (92.5312) gate/entropy 1.0176 (1.0184) gate/usage_max 0.5293 (0.5284) gate/usage_min 0.2331 (0.2330) gate/usage_std 0.1386 (0.1379) teacher/entropy 0.0132 (0.0166) teacher/usage_max 0.5980 (0.7118) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.2489 (0.2965) nleep/row_max_mean 1546.4417 (1551.2754) nleep/row_max_std 52.5812 (49.5259) nleep/row_min_mean 1496.0398 (1497.4983) lr 6.3188e-04 eta 0:05:33
epoch [33/50] batch [120/167] time 0.086 (0.115) data 0.000 (0.003) loss 1.2184 (1.3318) teacher_loss 0.1276 (0.1993) loss_zs_kd 0.0325 (0.0321) loss_oracle 0.4902 (0.5210) kd_loss 0.8295 (0.8559) acc 96.8750 (92.5260) gate/entropy 1.0171 (1.0182) gate/usage_max 0.5300 (0.5287) gate/usage_min 0.2329 (0.2330) gate/usage_std 0.1391 (0.1381) teacher/entropy 0.0428 (0.0164) teacher/usage_max 0.7102 (0.7129) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2916 (0.2970) nleep/row_max_mean 1543.7770 (1551.0523) nleep/row_max_std 48.4280 (48.8811) nleep/row_min_mean 1491.8713 (1497.5292) lr 6.3188e-04 eta 0:05:32
epoch [33/50] batch [140/167] time 0.161 (0.114) data 0.000 (0.002) loss 1.2456 (1.3422) teacher_loss 0.1259 (0.2125) loss_zs_kd 0.0243 (0.0323) loss_oracle 0.5602 (0.5193) kd_loss 0.8274 (0.8539) acc 96.8750 (92.0312) gate/entropy 1.0159 (1.0179) gate/usage_max 0.5315 (0.5289) gate/usage_min 0.2324 (0.2330) gate/usage_std 0.1401 (0.1383) teacher/entropy 0.0134 (0.0170) teacher/usage_max 0.7461 (0.7142) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.3097 (0.2974) nleep/row_max_mean 1554.5454 (1550.3904) nleep/row_max_std 52.3604 (49.2780) nleep/row_min_mean 1504.7412 (1497.1859) lr 6.3188e-04 eta 0:05:27
epoch [33/50] batch [160/167] time 0.071 (0.114) data 0.000 (0.002) loss 1.3164 (1.3412) teacher_loss 0.1829 (0.2123) loss_zs_kd 0.0270 (0.0314) loss_oracle 0.4636 (0.5156) kd_loss 0.8881 (0.8554) acc 93.7500 (91.9922) gate/entropy 1.0165 (1.0177) gate/usage_max 0.5308 (0.5292) gate/usage_min 0.2330 (0.2329) gate/usage_std 0.1396 (0.1385) teacher/entropy 0.0019 (0.0167) teacher/usage_max 0.6876 (0.7121) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2811 (0.2964) nleep/row_max_mean 1534.6550 (1550.6635) nleep/row_max_std 54.2670 (49.2415) nleep/row_min_mean 1486.2993 (1497.7864) lr 6.3188e-04 eta 0:05:23
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,187
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [34/50] batch [20/167] time 0.148 (0.169) data 0.000 (0.014) loss 1.5384 (1.3500) teacher_loss 0.3614 (0.2230) loss_zs_kd 0.0099 (0.0266) loss_oracle 0.5108 (0.4934) kd_loss 0.9167 (0.8671) acc 90.6250 (92.6562) gate/entropy 1.0156 (1.0156) gate/usage_max 0.5319 (0.5318) gate/usage_min 0.2327 (0.2326) gate/usage_std 0.1404 (0.1403) teacher/entropy 0.0218 (0.0153) teacher/usage_max 0.6279 (0.7048) teacher/usage_min 0.0002 (0.0002) teacher/usage_std 0.2577 (0.2942) nleep/row_max_mean 1533.7588 (1544.3522) nleep/row_max_std 63.3215 (58.7086) nleep/row_min_mean 1483.2003 (1494.6005) lr 5.7422e-04 eta 0:07:56
epoch [34/50] batch [40/167] time 0.163 (0.161) data 0.000 (0.007) loss 1.4500 (1.3448) teacher_loss 0.4698 (0.2325) loss_zs_kd 0.0243 (0.0278) loss_oracle 0.5547 (0.5051) kd_loss 0.6907 (0.8459) acc 84.3750 (92.4219) gate/entropy 1.0145 (1.0154) gate/usage_max 0.5331 (0.5321) gate/usage_min 0.2322 (0.2326) gate/usage_std 0.1413 (0.1405) teacher/entropy 0.0229 (0.0176) teacher/usage_max 0.8979 (0.7223) teacher/usage_min 0.0002 (0.0001) teacher/usage_std 0.4014 (0.3015) nleep/row_max_mean 1555.1917 (1546.6419) nleep/row_max_std 46.9129 (55.0992) nleep/row_min_mean 1501.4667 (1496.0512) lr 5.7422e-04 eta 0:07:29
epoch [34/50] batch [60/167] time 0.159 (0.158) data 0.000 (0.005) loss 1.2534 (1.3356) teacher_loss 0.1711 (0.2258) loss_zs_kd 0.0257 (0.0268) loss_oracle 0.4938 (0.5028) kd_loss 0.8225 (0.8450) acc 90.6250 (91.9792) gate/entropy 1.0145 (1.0152) gate/usage_max 0.5331 (0.5323) gate/usage_min 0.2324 (0.2326) gate/usage_std 0.1413 (0.1407) teacher/entropy 0.0455 (0.0186) teacher/usage_max 0.7101 (0.7204) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2915 (0.3007) nleep/row_max_mean 1562.5177 (1548.3502) nleep/row_max_std 54.0077 (54.3236) nleep/row_min_mean 1507.6526 (1497.2547) lr 5.7422e-04 eta 0:07:19
epoch [34/50] batch [80/167] time 0.127 (0.154) data 0.000 (0.004) loss 1.3014 (1.3373) teacher_loss 0.0281 (0.2293) loss_zs_kd 0.0185 (0.0269) loss_oracle 0.4752 (0.4993) kd_loss 1.0264 (0.8449) acc 100.0000 (91.5234) gate/entropy 1.0153 (1.0150) gate/usage_max 0.5322 (0.5326) gate/usage_min 0.2330 (0.2325) gate/usage_std 0.1406 (0.1409) teacher/entropy 0.0332 (0.0193) teacher/usage_max 0.5176 (0.7188) teacher/usage_min 0.0001 (0.0003) teacher/usage_std 0.2361 (0.3000) nleep/row_max_mean 1543.7085 (1549.6164) nleep/row_max_std 42.2961 (54.2067) nleep/row_min_mean 1495.4514 (1498.6450) lr 5.7422e-04 eta 0:07:05
epoch [34/50] batch [100/167] time 0.123 (0.152) data 0.000 (0.003) loss 1.5711 (1.3408) teacher_loss 0.4160 (0.2319) loss_zs_kd 0.0354 (0.0270) loss_oracle 0.4888 (0.4980) kd_loss 0.8930 (0.8464) acc 81.2500 (91.3438) gate/entropy 1.0136 (1.0148) gate/usage_max 0.5343 (0.5328) gate/usage_min 0.2321 (0.2325) gate/usage_std 0.1421 (0.1411) teacher/entropy 0.0220 (0.0214) teacher/usage_max 0.6520 (0.7136) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2664 (0.2974) nleep/row_max_mean 1560.6012 (1550.4192) nleep/row_max_std 54.5872 (54.6705) nleep/row_min_mean 1509.1267 (1499.2824) lr 5.7422e-04 eta 0:06:56
epoch [34/50] batch [120/167] time 0.152 (0.152) data 0.000 (0.003) loss 1.4199 (1.3357) teacher_loss 0.4010 (0.2322) loss_zs_kd 0.0505 (0.0274) loss_oracle 0.4683 (0.4958) kd_loss 0.7595 (0.8420) acc 93.7500 (91.2240) gate/entropy 1.0130 (1.0146) gate/usage_max 0.5350 (0.5330) gate/usage_min 0.2319 (0.2324) gate/usage_std 0.1426 (0.1412) teacher/entropy 0.0445 (0.0227) teacher/usage_max 0.7856 (0.7168) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.3316 (0.2987) nleep/row_max_mean 1548.6792 (1550.5666) nleep/row_max_std 61.6805 (54.8673) nleep/row_min_mean 1498.0120 (1499.5649) lr 5.7422e-04 eta 0:06:52
epoch [34/50] batch [140/167] time 0.095 (0.146) data 0.000 (0.002) loss 1.3123 (1.3409) teacher_loss 0.1289 (0.2333) loss_zs_kd 0.0303 (0.0274) loss_oracle 0.4835 (0.4971) kd_loss 0.9265 (0.8454) acc 96.8750 (91.1384) gate/entropy 1.0134 (1.0144) gate/usage_max 0.5345 (0.5333) gate/usage_min 0.2324 (0.2324) gate/usage_std 0.1423 (0.1414) teacher/entropy 0.0085 (0.0230) teacher/usage_max 0.6265 (0.7116) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2573 (0.2965) nleep/row_max_mean 1549.2222 (1549.9300) nleep/row_max_std 43.4027 (54.7141) nleep/row_min_mean 1502.0769 (1499.2774) lr 5.7422e-04 eta 0:06:35
epoch [34/50] batch [160/167] time 0.068 (0.143) data 0.000 (0.002) loss 1.5973 (1.3465) teacher_loss 0.2671 (0.2379) loss_zs_kd 0.0386 (0.0279) loss_oracle 0.5130 (0.4987) kd_loss 1.0543 (0.8453) acc 90.6250 (91.0156) gate/entropy 1.0133 (1.0142) gate/usage_max 0.5346 (0.5335) gate/usage_min 0.2325 (0.2324) gate/usage_std 0.1423 (0.1415) teacher/entropy 0.0233 (0.0233) teacher/usage_max 0.5449 (0.7114) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2385 (0.2967) nleep/row_max_mean 1533.8149 (1549.8379) nleep/row_max_std 45.7254 (54.2008) nleep/row_min_mean 1489.6732 (1499.4517) lr 5.7422e-04 eta 0:06:22
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,181
* accuracy: 94.9%
* error: 5.1%
* macro_f1: 95.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [35/50] batch [20/167] time 0.093 (0.122) data 0.000 (0.017) loss 1.2287 (1.3220) teacher_loss 0.2023 (0.2154) loss_zs_kd 0.0251 (0.0216) loss_oracle 0.4692 (0.4940) kd_loss 0.7793 (0.8489) acc 90.6250 (91.5625) gate/entropy 1.0134 (1.0128) gate/usage_max 0.5346 (0.5352) gate/usage_min 0.2326 (0.2323) gate/usage_std 0.1423 (0.1428) teacher/entropy 0.0268 (0.0215) teacher/usage_max 0.7821 (0.7123) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3296 (0.2961) nleep/row_max_mean 1530.1605 (1544.2104) nleep/row_max_std 52.1145 (52.3587) nleep/row_min_mean 1485.2466 (1497.4311) lr 5.1825e-04 eta 0:05:23
epoch [35/50] batch [40/167] time 0.090 (0.113) data 0.000 (0.008) loss 1.4218 (1.3505) teacher_loss 0.2600 (0.2286) loss_zs_kd 0.0311 (0.0260) loss_oracle 0.4756 (0.5011) kd_loss 0.9085 (0.8583) acc 87.5000 (90.4688) gate/entropy 1.0114 (1.0125) gate/usage_max 0.5369 (0.5355) gate/usage_min 0.2315 (0.2322) gate/usage_std 0.1439 (0.1430) teacher/entropy 0.0011 (0.0230) teacher/usage_max 0.6563 (0.6951) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2680 (0.2884) nleep/row_max_mean 1562.1888 (1544.5083) nleep/row_max_std 43.7754 (50.1533) nleep/row_min_mean 1512.9387 (1497.4822) lr 5.1825e-04 eta 0:04:57
epoch [35/50] batch [60/167] time 0.117 (0.114) data 0.001 (0.006) loss 1.2113 (1.3421) teacher_loss 0.1656 (0.2198) loss_zs_kd 0.0306 (0.0279) loss_oracle 0.4571 (0.5020) kd_loss 0.8018 (0.8574) acc 93.7500 (91.0417) gate/entropy 1.0118 (1.0123) gate/usage_max 0.5364 (0.5358) gate/usage_min 0.2316 (0.2320) gate/usage_std 0.1436 (0.1432) teacher/entropy 0.0569 (0.0223) teacher/usage_max 0.7181 (0.6954) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.2954 (0.2884) nleep/row_max_mean 1542.8375 (1545.1717) nleep/row_max_std 58.7983 (50.3075) nleep/row_min_mean 1498.4545 (1498.4049) lr 5.1825e-04 eta 0:04:56
epoch [35/50] batch [80/167] time 0.094 (0.113) data 0.001 (0.004) loss 1.3097 (1.3404) teacher_loss 0.1596 (0.2204) loss_zs_kd 0.0337 (0.0282) loss_oracle 0.5085 (0.5034) kd_loss 0.8789 (0.8542) acc 93.7500 (91.1328) gate/entropy 1.0121 (1.0122) gate/usage_max 0.5361 (0.5360) gate/usage_min 0.2316 (0.2319) gate/usage_std 0.1434 (0.1433) teacher/entropy 0.0066 (0.0243) teacher/usage_max 0.6874 (0.6958) teacher/usage_min 0.0015 (0.0011) teacher/usage_std 0.2805 (0.2898) nleep/row_max_mean 1536.0627 (1542.8425) nleep/row_max_std 48.5272 (50.4952) nleep/row_min_mean 1491.8120 (1496.4402) lr 5.1825e-04 eta 0:04:53
epoch [35/50] batch [100/167] time 0.155 (0.117) data 0.000 (0.003) loss 1.4170 (1.3418) teacher_loss 0.2360 (0.2135) loss_zs_kd 0.0255 (0.0281) loss_oracle 0.4867 (0.5061) kd_loss 0.9249 (0.8612) acc 90.6250 (91.5625) gate/entropy 1.0107 (1.0120) gate/usage_max 0.5377 (0.5361) gate/usage_min 0.2307 (0.2317) gate/usage_std 0.1445 (0.1434) teacher/entropy 0.0237 (0.0248) teacher/usage_max 0.6069 (0.6863) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2513 (0.2861) nleep/row_max_mean 1542.2239 (1542.0037) nleep/row_max_std 56.5575 (50.9439) nleep/row_min_mean 1497.5554 (1495.8594) lr 5.1825e-04 eta 0:05:00
epoch [35/50] batch [120/167] time 0.153 (0.123) data 0.000 (0.003) loss 1.3307 (1.3424) teacher_loss 0.0506 (0.2108) loss_zs_kd 0.0169 (0.0279) loss_oracle 0.5539 (0.5101) kd_loss 0.9947 (0.8626) acc 100.0000 (91.7969) gate/entropy 1.0124 (1.0119) gate/usage_max 0.5357 (0.5363) gate/usage_min 0.2315 (0.2316) gate/usage_std 0.1431 (0.1435) teacher/entropy 0.0320 (0.0258) teacher/usage_max 0.5159 (0.6836) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2361 (0.2851) nleep/row_max_mean 1529.4597 (1540.9904) nleep/row_max_std 49.4329 (51.3251) nleep/row_min_mean 1486.5295 (1495.1109) lr 5.1825e-04 eta 0:05:13
epoch [35/50] batch [140/167] time 0.185 (0.127) data 0.000 (0.003) loss 1.4098 (1.3494) teacher_loss 0.2411 (0.2140) loss_zs_kd 0.0370 (0.0281) loss_oracle 0.4499 (0.5125) kd_loss 0.9253 (0.8651) acc 90.6250 (91.6964) gate/entropy 1.0111 (1.0118) gate/usage_max 0.5373 (0.5364) gate/usage_min 0.2306 (0.2315) gate/usage_std 0.1442 (0.1436) teacher/entropy 0.0576 (0.0253) teacher/usage_max 0.5664 (0.6808) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2418 (0.2840) nleep/row_max_mean 1534.7512 (1540.4332) nleep/row_max_std 46.7964 (51.0402) nleep/row_min_mean 1492.5370 (1494.9259) lr 5.1825e-04 eta 0:05:22
epoch [35/50] batch [160/167] time 0.149 (0.130) data 0.000 (0.002) loss 1.3585 (1.3513) teacher_loss 0.1818 (0.2168) loss_zs_kd 0.0221 (0.0288) loss_oracle 0.4804 (0.5132) kd_loss 0.9255 (0.8635) acc 90.6250 (91.5430) gate/entropy 1.0107 (1.0117) gate/usage_max 0.5377 (0.5366) gate/usage_min 0.2302 (0.2313) gate/usage_std 0.1445 (0.1437) teacher/entropy 0.0230 (0.0250) teacher/usage_max 0.6083 (0.6826) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2518 (0.2848) nleep/row_max_mean 1528.2549 (1540.0167) nleep/row_max_std 56.6120 (51.0072) nleep/row_min_mean 1485.6577 (1494.6167) lr 5.1825e-04 eta 0:05:26
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,191
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [36/50] batch [20/167] time 0.147 (0.180) data 0.000 (0.014) loss 1.1593 (1.3246) teacher_loss 0.0810 (0.2047) loss_zs_kd 0.0090 (0.0289) loss_oracle 0.5449 (0.5145) kd_loss 0.8014 (0.8482) acc 96.8750 (91.0938) gate/entropy 1.0102 (1.0105) gate/usage_max 0.5383 (0.5380) gate/usage_min 0.2298 (0.2300) gate/usage_std 0.1449 (0.1447) teacher/entropy 0.0012 (0.0199) teacher/usage_max 0.7813 (0.7030) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.3291 (0.2919) nleep/row_max_mean 1548.4368 (1536.6232) nleep/row_max_std 54.5531 (51.5971) nleep/row_min_mean 1500.6523 (1492.7185) lr 4.6417e-04 eta 0:07:26
epoch [36/50] batch [40/167] time 0.062 (0.162) data 0.000 (0.007) loss 1.5355 (1.3650) teacher_loss 0.2750 (0.2336) loss_zs_kd 0.0408 (0.0304) loss_oracle 0.5327 (0.5178) kd_loss 0.9737 (0.8572) acc 84.3750 (91.4062) gate/entropy 1.0101 (1.0104) gate/usage_max 0.5384 (0.5381) gate/usage_min 0.2297 (0.2299) gate/usage_std 0.1450 (0.1448) teacher/entropy 0.0138 (0.0224) teacher/usage_max 0.5579 (0.6891) teacher/usage_min 0.0001 (0.0013) teacher/usage_std 0.2403 (0.2870) nleep/row_max_mean 1540.4272 (1537.6964) nleep/row_max_std 47.2987 (51.0410) nleep/row_min_mean 1497.7010 (1493.6017) lr 4.6417e-04 eta 0:06:40
epoch [36/50] batch [60/167] time 0.065 (0.135) data 0.000 (0.005) loss 1.3199 (1.3659) teacher_loss 0.2595 (0.2329) loss_zs_kd 0.0344 (0.0303) loss_oracle 0.4867 (0.5183) kd_loss 0.7999 (0.8587) acc 90.6250 (91.5104) gate/entropy 1.0094 (1.0103) gate/usage_max 0.5392 (0.5382) gate/usage_min 0.2291 (0.2298) gate/usage_std 0.1456 (0.1449) teacher/entropy 0.0243 (0.0222) teacher/usage_max 0.7549 (0.6880) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.3145 (0.2868) nleep/row_max_mean 1552.3047 (1538.6569) nleep/row_max_std 45.2339 (50.3598) nleep/row_min_mean 1507.2317 (1494.3379) lr 4.6417e-04 eta 0:05:29
epoch [36/50] batch [80/167] time 0.149 (0.125) data 0.000 (0.004) loss 1.3954 (1.3619) teacher_loss 0.2181 (0.2278) loss_zs_kd 0.0137 (0.0298) loss_oracle 0.5286 (0.5148) kd_loss 0.9062 (0.8618) acc 90.6250 (91.3672) gate/entropy 1.0102 (1.0102) gate/usage_max 0.5384 (0.5383) gate/usage_min 0.2294 (0.2297) gate/usage_std 0.1450 (0.1449) teacher/entropy 0.0472 (0.0230) teacher/usage_max 0.5985 (0.6832) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.2491 (0.2842) nleep/row_max_mean 1544.0510 (1538.2922) nleep/row_max_std 44.7811 (50.6314) nleep/row_min_mean 1494.8944 (1493.5927) lr 4.6417e-04 eta 0:05:03
epoch [36/50] batch [100/167] time 0.074 (0.123) data 0.000 (0.003) loss 1.4661 (1.3614) teacher_loss 0.2505 (0.2200) loss_zs_kd 0.0399 (0.0298) loss_oracle 0.5716 (0.5137) kd_loss 0.9098 (0.8696) acc 90.6250 (91.5312) gate/entropy 1.0091 (1.0101) gate/usage_max 0.5396 (0.5384) gate/usage_min 0.2287 (0.2296) gate/usage_std 0.1459 (0.1450) teacher/entropy 0.0215 (0.0219) teacher/usage_max 0.6263 (0.6756) teacher/usage_min 0.0053 (0.0014) teacher/usage_std 0.2547 (0.2810) nleep/row_max_mean 1540.5199 (1537.9644) nleep/row_max_std 46.5162 (50.6426) nleep/row_min_mean 1495.5229 (1493.3028) lr 4.6417e-04 eta 0:04:55
epoch [36/50] batch [120/167] time 0.089 (0.122) data 0.000 (0.002) loss 1.2701 (1.3627) teacher_loss 0.1904 (0.2211) loss_zs_kd 0.0235 (0.0300) loss_oracle 0.4553 (0.5129) kd_loss 0.8403 (0.8702) acc 93.7500 (91.5625) gate/entropy 1.0089 (1.0100) gate/usage_max 0.5399 (0.5386) gate/usage_min 0.2285 (0.2295) gate/usage_std 0.1461 (0.1451) teacher/entropy 0.0213 (0.0225) teacher/usage_max 0.7084 (0.6740) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2907 (0.2800) nleep/row_max_mean 1545.0149 (1537.9694) nleep/row_max_std 50.9038 (51.0238) nleep/row_min_mean 1503.2791 (1493.4675) lr 4.6417e-04 eta 0:04:50
epoch [36/50] batch [140/167] time 0.082 (0.122) data 0.000 (0.002) loss 1.3924 (1.3587) teacher_loss 0.2788 (0.2193) loss_zs_kd 0.0368 (0.0295) loss_oracle 0.4898 (0.5093) kd_loss 0.8504 (0.8700) acc 87.5000 (91.7188) gate/entropy 1.0081 (1.0099) gate/usage_max 0.5408 (0.5387) gate/usage_min 0.2279 (0.2293) gate/usage_std 0.1467 (0.1452) teacher/entropy 0.0225 (0.0229) teacher/usage_max 0.6950 (0.6734) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2844 (0.2794) nleep/row_max_mean 1558.3960 (1537.7899) nleep/row_max_std 30.7103 (50.7737) nleep/row_min_mean 1511.1611 (1493.3768) lr 4.6417e-04 eta 0:04:47
epoch [36/50] batch [160/167] time 0.082 (0.118) data 0.000 (0.002) loss 1.2126 (1.3524) teacher_loss 0.1829 (0.2143) loss_zs_kd 0.0292 (0.0289) loss_oracle 0.5249 (0.5078) kd_loss 0.7528 (0.8698) acc 96.8750 (91.9336) gate/entropy 1.0098 (1.0098) gate/usage_max 0.5387 (0.5387) gate/usage_min 0.2288 (0.2293) gate/usage_std 0.1453 (0.1453) teacher/entropy 0.0476 (0.0236) teacher/usage_max 0.7806 (0.6742) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.3287 (0.2799) nleep/row_max_mean 1540.5286 (1536.9210) nleep/row_max_std 46.7775 (50.4907) nleep/row_min_mean 1495.9528 (1492.7284) lr 4.6417e-04 eta 0:04:37
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [37/50] batch [20/167] time 0.146 (0.162) data 0.000 (0.014) loss 1.5266 (1.3302) teacher_loss 0.3241 (0.2031) loss_zs_kd 0.0426 (0.0315) loss_oracle 0.4685 (0.4859) kd_loss 0.9470 (0.8684) acc 87.5000 (91.8750) gate/entropy 1.0090 (1.0089) gate/usage_max 0.5397 (0.5398) gate/usage_min 0.2282 (0.2282) gate/usage_std 0.1460 (0.1460) teacher/entropy 0.0128 (0.0286) teacher/usage_max 0.5922 (0.6661) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.2474 (0.2751) nleep/row_max_mean 1531.9751 (1536.1253) nleep/row_max_std 59.8782 (47.7325) nleep/row_min_mean 1490.1509 (1494.0948) lr 4.1221e-04 eta 0:06:15
epoch [37/50] batch [40/167] time 0.167 (0.164) data 0.000 (0.007) loss 1.4018 (1.3410) teacher_loss 0.1989 (0.2144) loss_zs_kd 0.0190 (0.0295) loss_oracle 0.4674 (0.4931) kd_loss 0.9597 (0.8652) acc 93.7500 (92.1094) gate/entropy 1.0092 (1.0088) gate/usage_max 0.5394 (0.5399) gate/usage_min 0.2283 (0.2281) gate/usage_std 0.1457 (0.1461) teacher/entropy 0.0177 (0.0253) teacher/usage_max 0.5704 (0.6740) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.2426 (0.2785) nleep/row_max_mean 1538.7314 (1536.8926) nleep/row_max_std 41.8048 (48.8916) nleep/row_min_mean 1495.5087 (1494.5614) lr 4.1221e-04 eta 0:06:16
epoch [37/50] batch [60/167] time 0.155 (0.163) data 0.000 (0.005) loss 1.4346 (1.3353) teacher_loss 0.2611 (0.2098) loss_zs_kd 0.0097 (0.0287) loss_oracle 0.5153 (0.4920) kd_loss 0.9110 (0.8651) acc 90.6250 (92.0312) gate/entropy 1.0090 (1.0087) gate/usage_max 0.5397 (0.5400) gate/usage_min 0.2281 (0.2280) gate/usage_std 0.1460 (0.1462) teacher/entropy 0.0628 (0.0251) teacher/usage_max 0.5731 (0.6743) teacher/usage_min 0.0294 (0.0037) teacher/usage_std 0.2266 (0.2794) nleep/row_max_mean 1533.9752 (1536.6148) nleep/row_max_std 54.7293 (48.2686) nleep/row_min_mean 1490.6844 (1494.2427) lr 4.1221e-04 eta 0:06:11
epoch [37/50] batch [80/167] time 0.143 (0.159) data 0.000 (0.004) loss 1.3606 (1.3436) teacher_loss 0.1976 (0.2082) loss_zs_kd 0.0273 (0.0295) loss_oracle 0.5422 (0.4939) kd_loss 0.8783 (0.8738) acc 90.6250 (91.9141) gate/entropy 1.0077 (1.0086) gate/usage_max 0.5413 (0.5401) gate/usage_min 0.2272 (0.2279) gate/usage_std 0.1470 (0.1462) teacher/entropy 0.0340 (0.0244) teacher/usage_max 0.6463 (0.6670) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2642 (0.2768) nleep/row_max_mean 1543.0625 (1537.5960) nleep/row_max_std 46.5440 (47.2757) nleep/row_min_mean 1499.0342 (1495.2907) lr 4.1221e-04 eta 0:05:58
epoch [37/50] batch [100/167] time 0.143 (0.157) data 0.000 (0.003) loss 1.3791 (1.3381) teacher_loss 0.1955 (0.2030) loss_zs_kd 0.0335 (0.0291) loss_oracle 0.5217 (0.4970) kd_loss 0.9061 (0.8720) acc 90.6250 (92.0312) gate/entropy 1.0084 (1.0086) gate/usage_max 0.5404 (0.5402) gate/usage_min 0.2276 (0.2279) gate/usage_std 0.1464 (0.1463) teacher/entropy 0.0259 (0.0244) teacher/usage_max 0.6242 (0.6685) teacher/usage_min 0.0088 (0.0035) teacher/usage_std 0.2524 (0.2778) nleep/row_max_mean 1528.8079 (1537.3363) nleep/row_max_std 46.5205 (47.0241) nleep/row_min_mean 1490.6499 (1495.0560) lr 4.1221e-04 eta 0:05:51
epoch [37/50] batch [120/167] time 0.147 (0.155) data 0.000 (0.003) loss 1.4107 (1.3485) teacher_loss 0.3164 (0.2134) loss_zs_kd 0.0347 (0.0302) loss_oracle 0.5401 (0.4984) kd_loss 0.8069 (0.8708) acc 81.2500 (91.6146) gate/entropy 1.0075 (1.0085) gate/usage_max 0.5414 (0.5403) gate/usage_min 0.2270 (0.2278) gate/usage_std 0.1471 (0.1463) teacher/entropy 0.0201 (0.0252) teacher/usage_max 0.7460 (0.6693) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.3097 (0.2783) nleep/row_max_mean 1544.2961 (1537.1210) nleep/row_max_std 38.4395 (46.5306) nleep/row_min_mean 1503.3230 (1495.0966) lr 4.1221e-04 eta 0:05:43
epoch [37/50] batch [140/167] time 0.152 (0.155) data 0.000 (0.002) loss 1.2467 (1.3483) teacher_loss 0.1964 (0.2165) loss_zs_kd 0.0463 (0.0308) loss_oracle 0.5073 (0.5011) kd_loss 0.7734 (0.8658) acc 90.6250 (91.3839) gate/entropy 1.0080 (1.0084) gate/usage_max 0.5409 (0.5404) gate/usage_min 0.2272 (0.2277) gate/usage_std 0.1468 (0.1464) teacher/entropy 0.0304 (0.0259) teacher/usage_max 0.7753 (0.6738) teacher/usage_min 0.0004 (0.0032) teacher/usage_std 0.3256 (0.2799) nleep/row_max_mean 1531.8473 (1537.0279) nleep/row_max_std 41.4485 (46.6529) nleep/row_min_mean 1484.8335 (1494.8615) lr 4.1221e-04 eta 0:05:39
epoch [37/50] batch [160/167] time 0.101 (0.154) data 0.000 (0.002) loss 1.4102 (1.3492) teacher_loss 0.3089 (0.2177) loss_zs_kd 0.0348 (0.0310) loss_oracle 0.5119 (0.5018) kd_loss 0.8280 (0.8651) acc 84.3750 (91.4062) gate/entropy 1.0076 (1.0083) gate/usage_max 0.5414 (0.5405) gate/usage_min 0.2268 (0.2276) gate/usage_std 0.1471 (0.1465) teacher/entropy 0.0389 (0.0266) teacher/usage_max 0.6989 (0.6734) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2862 (0.2796) nleep/row_max_mean 1538.8541 (1537.2972) nleep/row_max_std 41.3594 (46.5025) nleep/row_min_mean 1498.2637 (1495.0318) lr 4.1221e-04 eta 0:05:35
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [38/50] batch [20/167] time 0.154 (0.127) data 0.000 (0.012) loss 1.3710 (1.3718) teacher_loss 0.1203 (0.1903) loss_zs_kd 0.0301 (0.0281) loss_oracle 0.4683 (0.5003) kd_loss 1.0015 (0.9174) acc 96.8750 (93.5938) gate/entropy 1.0076 (1.0079) gate/usage_max 0.5413 (0.5410) gate/usage_min 0.2268 (0.2269) gate/usage_std 0.1471 (0.1469) teacher/entropy 0.0441 (0.0268) teacher/usage_max 0.5115 (0.6097) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2359 (0.2556) nleep/row_max_mean 1534.2748 (1536.6217) nleep/row_max_std 39.9537 (45.2729) nleep/row_min_mean 1496.0164 (1495.0491) lr 3.6258e-04 eta 0:04:33
epoch [38/50] batch [40/167] time 0.089 (0.112) data 0.000 (0.006) loss 1.3704 (1.3766) teacher_loss 0.0901 (0.2163) loss_zs_kd 0.0261 (0.0296) loss_oracle 0.5166 (0.5023) kd_loss 1.0090 (0.8943) acc 93.7500 (91.7969) gate/entropy 1.0077 (1.0077) gate/usage_max 0.5412 (0.5412) gate/usage_min 0.2267 (0.2268) gate/usage_std 0.1470 (0.1470) teacher/entropy 0.0239 (0.0323) teacher/usage_max 0.5043 (0.6316) teacher/usage_min 0.0028 (0.0021) teacher/usage_std 0.2338 (0.2634) nleep/row_max_mean 1537.8850 (1538.1728) nleep/row_max_std 49.2477 (46.4242) nleep/row_min_mean 1494.3307 (1495.7727) lr 3.6258e-04 eta 0:03:58
epoch [38/50] batch [60/167] time 0.078 (0.110) data 0.001 (0.004) loss 1.4428 (1.3798) teacher_loss 0.2889 (0.2257) loss_zs_kd 0.0255 (0.0294) loss_oracle 0.5493 (0.5041) kd_loss 0.8665 (0.8874) acc 87.5000 (91.4583) gate/entropy 1.0069 (1.0076) gate/usage_max 0.5421 (0.5413) gate/usage_min 0.2262 (0.2267) gate/usage_std 0.1477 (0.1471) teacher/entropy 0.0079 (0.0327) teacher/usage_max 0.6894 (0.6391) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2819 (0.2656) nleep/row_max_mean 1544.6290 (1539.4085) nleep/row_max_std 56.1149 (47.0709) nleep/row_min_mean 1501.8601 (1496.9445) lr 3.6258e-04 eta 0:03:51
epoch [38/50] batch [80/167] time 0.088 (0.112) data 0.000 (0.003) loss 1.3246 (1.3758) teacher_loss 0.2290 (0.2267) loss_zs_kd 0.0275 (0.0303) loss_oracle 0.5342 (0.5066) kd_loss 0.8148 (0.8807) acc 90.6250 (91.4062) gate/entropy 1.0078 (1.0075) gate/usage_max 0.5411 (0.5414) gate/usage_min 0.2267 (0.2266) gate/usage_std 0.1469 (0.1472) teacher/entropy 0.0085 (0.0324) teacher/usage_max 0.7510 (0.6469) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.3123 (0.2691) nleep/row_max_mean 1529.9586 (1539.3201) nleep/row_max_std 61.7715 (48.3385) nleep/row_min_mean 1482.3447 (1496.7473) lr 3.6258e-04 eta 0:03:54
epoch [38/50] batch [100/167] time 0.101 (0.113) data 0.000 (0.003) loss 1.2828 (1.3694) teacher_loss 0.2771 (0.2271) loss_zs_kd 0.0296 (0.0297) loss_oracle 0.4976 (0.5053) kd_loss 0.7421 (0.8749) acc 90.6250 (91.3750) gate/entropy 1.0069 (1.0074) gate/usage_max 0.5421 (0.5415) gate/usage_min 0.2261 (0.2265) gate/usage_std 0.1477 (0.1472) teacher/entropy 0.0327 (0.0330) teacher/usage_max 0.8081 (0.6525) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.3447 (0.2718) nleep/row_max_mean 1545.1008 (1539.8555) nleep/row_max_std 51.8190 (48.9713) nleep/row_min_mean 1502.1733 (1496.9857) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [120/167] time 0.130 (0.117) data 0.000 (0.002) loss 1.2032 (1.3658) teacher_loss 0.0651 (0.2228) loss_zs_kd 0.0267 (0.0294) loss_oracle 0.5380 (0.5036) kd_loss 0.8558 (0.8765) acc 100.0000 (91.6927) gate/entropy 1.0075 (1.0074) gate/usage_max 0.5415 (0.5416) gate/usage_min 0.2263 (0.2264) gate/usage_std 0.1472 (0.1473) teacher/entropy 0.0236 (0.0334) teacher/usage_max 0.6830 (0.6519) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2791 (0.2718) nleep/row_max_mean 1529.6207 (1540.2486) nleep/row_max_std 51.6058 (49.2333) nleep/row_min_mean 1482.7079 (1497.3563) lr 3.6258e-04 eta 0:03:59
epoch [38/50] batch [140/167] time 0.161 (0.121) data 0.000 (0.002) loss 1.2844 (1.3621) teacher_loss 0.1565 (0.2210) loss_zs_kd 0.0261 (0.0292) loss_oracle 0.5245 (0.5015) kd_loss 0.8527 (0.8758) acc 93.7500 (91.8080) gate/entropy 1.0059 (1.0073) gate/usage_max 0.5433 (0.5417) gate/usage_min 0.2253 (0.2264) gate/usage_std 0.1485 (0.1474) teacher/entropy 0.0290 (0.0332) teacher/usage_max 0.6814 (0.6523) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2784 (0.2714) nleep/row_max_mean 1544.7942 (1540.4032) nleep/row_max_std 44.8482 (48.7710) nleep/row_min_mean 1506.5198 (1497.4734) lr 3.6258e-04 eta 0:04:06
epoch [38/50] batch [160/167] time 0.145 (0.124) data 0.000 (0.002) loss 1.4975 (1.3597) teacher_loss 0.2956 (0.2215) loss_zs_kd 0.0522 (0.0295) loss_oracle 0.5703 (0.5029) kd_loss 0.8907 (0.8721) acc 87.5000 (91.6602) gate/entropy 1.0070 (1.0072) gate/usage_max 0.5421 (0.5418) gate/usage_min 0.2259 (0.2263) gate/usage_std 0.1476 (0.1474) teacher/entropy 0.0090 (0.0330) teacher/usage_max 0.6573 (0.6565) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2684 (0.2732) nleep/row_max_mean 1535.4470 (1539.9039) nleep/row_max_std 55.2936 (49.1440) nleep/row_min_mean 1488.3511 (1496.8747) lr 3.6258e-04 eta 0:04:09
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [39/50] batch [20/167] time 0.157 (0.171) data 0.000 (0.013) loss 1.4140 (1.3479) teacher_loss 0.2204 (0.2099) loss_zs_kd 0.0324 (0.0332) loss_oracle 0.5086 (0.4970) kd_loss 0.9231 (0.8729) acc 90.6250 (92.3438) gate/entropy 1.0070 (1.0066) gate/usage_max 0.5420 (0.5424) gate/usage_min 0.2258 (0.2256) gate/usage_std 0.1476 (0.1479) teacher/entropy 0.0483 (0.0421) teacher/usage_max 0.5754 (0.6488) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2436 (0.2668) nleep/row_max_mean 1530.3459 (1537.7326) nleep/row_max_std 38.0426 (48.7367) nleep/row_min_mean 1488.7832 (1495.7677) lr 3.1545e-04 eta 0:05:39
epoch [39/50] batch [40/167] time 0.137 (0.162) data 0.000 (0.006) loss 1.3280 (1.3616) teacher_loss 0.2812 (0.2279) loss_zs_kd 0.0350 (0.0321) loss_oracle 0.4888 (0.4981) kd_loss 0.7849 (0.8686) acc 84.3750 (91.6406) gate/entropy 1.0075 (1.0066) gate/usage_max 0.5414 (0.5424) gate/usage_min 0.2260 (0.2256) gate/usage_std 0.1471 (0.1479) teacher/entropy 0.1150 (0.0380) teacher/usage_max 0.6574 (0.6547) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2684 (0.2707) nleep/row_max_mean 1533.8418 (1535.0213) nleep/row_max_std 40.6489 (49.2754) nleep/row_min_mean 1488.9568 (1492.9135) lr 3.1545e-04 eta 0:05:18
epoch [39/50] batch [60/167] time 0.134 (0.159) data 0.001 (0.004) loss 1.2875 (1.3625) teacher_loss 0.1508 (0.2304) loss_zs_kd 0.0373 (0.0307) loss_oracle 0.4552 (0.4980) kd_loss 0.8904 (0.8678) acc 96.8750 (91.6667) gate/entropy 1.0066 (1.0066) gate/usage_max 0.5425 (0.5425) gate/usage_min 0.2255 (0.2256) gate/usage_std 0.1479 (0.1479) teacher/entropy 0.0525 (0.0359) teacher/usage_max 0.6100 (0.6569) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2522 (0.2717) nleep/row_max_mean 1525.2246 (1533.3336) nleep/row_max_std 56.4805 (51.4411) nleep/row_min_mean 1488.4017 (1491.2667) lr 3.1545e-04 eta 0:05:08
epoch [39/50] batch [80/167] time 0.101 (0.146) data 0.000 (0.003) loss 1.1921 (1.3604) teacher_loss 0.1569 (0.2269) loss_zs_kd 0.0188 (0.0290) loss_oracle 0.5343 (0.4994) kd_loss 0.7586 (0.8693) acc 90.6250 (91.5234) gate/entropy 1.0057 (1.0065) gate/usage_max 0.5435 (0.5425) gate/usage_min 0.2250 (0.2255) gate/usage_std 0.1486 (0.1480) teacher/entropy 0.0306 (0.0353) teacher/usage_max 0.7878 (0.6549) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3328 (0.2714) nleep/row_max_mean 1535.7312 (1534.1227) nleep/row_max_std 62.2433 (52.3938) nleep/row_min_mean 1492.6262 (1491.9891) lr 3.1545e-04 eta 0:04:41
epoch [39/50] batch [100/167] time 0.108 (0.139) data 0.000 (0.003) loss 1.2672 (1.3588) teacher_loss 0.1392 (0.2245) loss_zs_kd 0.0447 (0.0287) loss_oracle 0.5307 (0.4982) kd_loss 0.8404 (0.8709) acc 96.8750 (91.7188) gate/entropy 1.0067 (1.0065) gate/usage_max 0.5424 (0.5426) gate/usage_min 0.2254 (0.2254) gate/usage_std 0.1478 (0.1480) teacher/entropy 0.0361 (0.0362) teacher/usage_max 0.6859 (0.6526) teacher/usage_min 0.0001 (0.0030) teacher/usage_std 0.2803 (0.2701) nleep/row_max_mean 1525.6831 (1533.6026) nleep/row_max_std 70.4993 (53.6066) nleep/row_min_mean 1482.6559 (1491.6178) lr 3.1545e-04 eta 0:04:25
epoch [39/50] batch [120/167] time 0.176 (0.136) data 0.000 (0.002) loss 1.1647 (1.3540) teacher_loss 0.1595 (0.2180) loss_zs_kd 0.0205 (0.0288) loss_oracle 0.4736 (0.4965) kd_loss 0.7582 (0.8734) acc 90.6250 (91.9792) gate/entropy 1.0056 (1.0064) gate/usage_max 0.5437 (0.5427) gate/usage_min 0.2247 (0.2254) gate/usage_std 0.1488 (0.1480) teacher/entropy 0.0883 (0.0362) teacher/usage_max 0.7204 (0.6491) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2965 (0.2689) nleep/row_max_mean 1559.7651 (1534.7177) nleep/row_max_std 36.4269 (53.7338) nleep/row_min_mean 1514.4565 (1492.7238) lr 3.1545e-04 eta 0:04:16
epoch [39/50] batch [140/167] time 0.103 (0.133) data 0.000 (0.002) loss 1.2974 (1.3531) teacher_loss 0.1143 (0.2200) loss_zs_kd 0.0083 (0.0283) loss_oracle 0.5257 (0.4991) kd_loss 0.9161 (0.8694) acc 93.7500 (91.7411) gate/entropy 1.0063 (1.0064) gate/usage_max 0.5429 (0.5427) gate/usage_min 0.2250 (0.2253) gate/usage_std 0.1482 (0.1481) teacher/entropy 0.0101 (0.0371) teacher/usage_max 0.6267 (0.6539) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2574 (0.2708) nleep/row_max_mean 1538.0557 (1534.9806) nleep/row_max_std 63.3658 (54.5154) nleep/row_min_mean 1494.1571 (1492.9271) lr 3.1545e-04 eta 0:04:07
epoch [39/50] batch [160/167] time 0.068 (0.132) data 0.000 (0.002) loss 1.3828 (1.3553) teacher_loss 0.2269 (0.2201) loss_zs_kd 0.0273 (0.0282) loss_oracle 0.4696 (0.5005) kd_loss 0.9074 (0.8708) acc 90.6250 (91.6602) gate/entropy 1.0061 (1.0064) gate/usage_max 0.5430 (0.5427) gate/usage_min 0.2249 (0.2253) gate/usage_std 0.1483 (0.1481) teacher/entropy 0.0355 (0.0389) teacher/usage_max 0.6085 (0.6501) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2518 (0.2695) nleep/row_max_mean 1520.5875 (1534.1637) nleep/row_max_std 57.8507 (55.0740) nleep/row_min_mean 1481.7041 (1492.3860) lr 3.1545e-04 eta 0:04:03
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [40/50] batch [20/167] time 0.083 (0.109) data 0.000 (0.012) loss 1.3879 (1.4007) teacher_loss 0.1149 (0.2572) loss_zs_kd 0.0378 (0.0296) loss_oracle 0.4943 (0.4993) kd_loss 1.0069 (0.8791) acc 96.8750 (89.6875) gate/entropy 1.0059 (1.0058) gate/usage_max 0.5433 (0.5434) gate/usage_min 0.2247 (0.2247) gate/usage_std 0.1485 (0.1485) teacher/entropy 0.0366 (0.0526) teacher/usage_max 0.5115 (0.6219) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2359 (0.2583) nleep/row_max_mean 1533.5845 (1528.5261) nleep/row_max_std 44.1278 (53.7850) nleep/row_min_mean 1493.6511 (1489.5982) lr 2.7103e-04 eta 0:03:17
epoch [40/50] batch [40/167] time 0.161 (0.133) data 0.000 (0.006) loss 1.4816 (1.4085) teacher_loss 0.3027 (0.2605) loss_zs_kd 0.0391 (0.0278) loss_oracle 0.4843 (0.4985) kd_loss 0.9172 (0.8849) acc 87.5000 (90.0781) gate/entropy 1.0061 (1.0058) gate/usage_max 0.5430 (0.5433) gate/usage_min 0.2248 (0.2247) gate/usage_std 0.1483 (0.1485) teacher/entropy 0.0794 (0.0548) teacher/usage_max 0.5429 (0.6235) teacher/usage_min 0.0001 (0.0031) teacher/usage_std 0.2382 (0.2602) nleep/row_max_mean 1530.3691 (1529.7993) nleep/row_max_std 48.5962 (52.8945) nleep/row_min_mean 1492.3994 (1490.7164) lr 2.7103e-04 eta 0:03:58
epoch [40/50] batch [60/167] time 0.154 (0.143) data 0.001 (0.004) loss 1.2709 (1.4073) teacher_loss 0.0474 (0.2497) loss_zs_kd 0.0075 (0.0261) loss_oracle 0.5285 (0.5057) kd_loss 0.9555 (0.8917) acc 96.8750 (90.7292) gate/entropy 1.0067 (1.0058) gate/usage_max 0.5424 (0.5433) gate/usage_min 0.2250 (0.2246) gate/usage_std 0.1478 (0.1485) teacher/entropy 0.0774 (0.0524) teacher/usage_max 0.5010 (0.6179) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2357 (0.2583) nleep/row_max_mean 1529.8981 (1530.0127) nleep/row_max_std 47.7737 (53.3305) nleep/row_min_mean 1493.1863 (1490.8608) lr 2.7103e-04 eta 0:04:13
epoch [40/50] batch [80/167] time 0.181 (0.145) data 0.000 (0.003) loss 1.4722 (1.3933) teacher_loss 0.2391 (0.2362) loss_zs_kd 0.0107 (0.0252) loss_oracle 0.5659 (0.5095) kd_loss 0.9448 (0.8898) acc 90.6250 (91.3672) gate/entropy 1.0061 (1.0059) gate/usage_max 0.5430 (0.5433) gate/usage_min 0.2246 (0.2246) gate/usage_std 0.1483 (0.1485) teacher/entropy 0.0505 (0.0539) teacher/usage_max 0.5459 (0.6188) teacher/usage_min 0.0020 (0.0039) teacher/usage_std 0.2374 (0.2586) nleep/row_max_mean 1525.6995 (1528.5101) nleep/row_max_std 50.4928 (54.2176) nleep/row_min_mean 1485.8041 (1489.3498) lr 2.7103e-04 eta 0:04:15
epoch [40/50] batch [100/167] time 0.157 (0.146) data 0.000 (0.003) loss 1.7825 (1.3956) teacher_loss 0.5920 (0.2312) loss_zs_kd 0.0095 (0.0246) loss_oracle 0.4868 (0.5112) kd_loss 0.9424 (0.8964) acc 71.8750 (91.4375) gate/entropy 1.0054 (1.0059) gate/usage_max 0.5439 (0.5433) gate/usage_min 0.2242 (0.2246) gate/usage_std 0.1489 (0.1485) teacher/entropy 0.0580 (0.0524) teacher/usage_max 0.5405 (0.6124) teacher/usage_min 0.0294 (0.0040) teacher/usage_std 0.2196 (0.2564) nleep/row_max_mean 1528.9370 (1528.6288) nleep/row_max_std 47.3311 (53.4784) nleep/row_min_mean 1490.2202 (1489.4773) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [120/167] time 0.153 (0.147) data 0.000 (0.002) loss 1.4583 (1.3951) teacher_loss 0.1664 (0.2254) loss_zs_kd 0.0231 (0.0246) loss_oracle 0.4868 (0.5108) kd_loss 1.0369 (0.9020) acc 93.7500 (91.6667) gate/entropy 1.0066 (1.0059) gate/usage_max 0.5425 (0.5433) gate/usage_min 0.2247 (0.2246) gate/usage_std 0.1479 (0.1485) teacher/entropy 0.0318 (0.0508) teacher/usage_max 0.5449 (0.6071) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2385 (0.2552) nleep/row_max_mean 1533.0493 (1529.2652) nleep/row_max_std 48.2859 (53.1681) nleep/row_min_mean 1491.2615 (1489.9998) lr 2.7103e-04 eta 0:04:11
epoch [40/50] batch [140/167] time 0.160 (0.148) data 0.000 (0.002) loss 1.4954 (1.4009) teacher_loss 0.2651 (0.2268) loss_zs_kd 0.0375 (0.0246) loss_oracle 0.4968 (0.5121) kd_loss 0.9632 (0.9058) acc 87.5000 (91.6295) gate/entropy 1.0059 (1.0058) gate/usage_max 0.5433 (0.5433) gate/usage_min 0.2243 (0.2245) gate/usage_std 0.1485 (0.1485) teacher/entropy 0.0699 (0.0502) teacher/usage_max 0.5008 (0.6030) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2357 (0.2540) nleep/row_max_mean 1530.6873 (1530.2380) nleep/row_max_std 45.5648 (52.7267) nleep/row_min_mean 1493.7272 (1490.8384) lr 2.7103e-04 eta 0:04:11
epoch [40/50] batch [160/167] time 0.140 (0.148) data 0.000 (0.002) loss 1.6030 (1.3991) teacher_loss 0.5183 (0.2278) loss_zs_kd 0.0506 (0.0244) loss_oracle 0.4460 (0.5102) kd_loss 0.8364 (0.9040) acc 75.0000 (91.5820) gate/entropy 1.0052 (1.0058) gate/usage_max 0.5441 (0.5434) gate/usage_min 0.2238 (0.2245) gate/usage_std 0.1491 (0.1485) teacher/entropy 0.0560 (0.0510) teacher/usage_max 0.6651 (0.6055) teacher/usage_min 0.0312 (0.0037) teacher/usage_std 0.2596 (0.2547) nleep/row_max_mean 1536.1311 (1530.8617) nleep/row_max_std 46.2356 (52.3637) nleep/row_min_mean 1496.0719 (1491.3600) lr 2.7103e-04 eta 0:04:08
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,188
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [41/50] batch [20/167] time 0.081 (0.132) data 0.000 (0.012) loss 1.2947 (1.4040) teacher_loss 0.2234 (0.2149) loss_zs_kd 0.0344 (0.0239) loss_oracle 0.4648 (0.5195) kd_loss 0.8217 (0.9174) acc 93.7500 (92.1875) gate/entropy 1.0056 (1.0057) gate/usage_max 0.5436 (0.5435) gate/usage_min 0.2240 (0.2241) gate/usage_std 0.1487 (0.1486) teacher/entropy 0.0632 (0.0464) teacher/usage_max 0.6773 (0.5899) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.2766 (0.2482) nleep/row_max_mean 1528.5294 (1527.8380) nleep/row_max_std 60.3575 (53.2855) nleep/row_min_mean 1488.1609 (1488.4338) lr 2.2949e-04 eta 0:03:37
epoch [41/50] batch [40/167] time 0.079 (0.124) data 0.000 (0.006) loss 1.3845 (1.4019) teacher_loss 0.3308 (0.2239) loss_zs_kd 0.0237 (0.0245) loss_oracle 0.4885 (0.5122) kd_loss 0.7976 (0.9096) acc 87.5000 (92.1094) gate/entropy 1.0055 (1.0057) gate/usage_max 0.5437 (0.5434) gate/usage_min 0.2239 (0.2241) gate/usage_std 0.1488 (0.1486) teacher/entropy 0.0734 (0.0440) teacher/usage_max 0.6885 (0.6010) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.2815 (0.2527) nleep/row_max_mean 1534.4260 (1527.9452) nleep/row_max_std 44.0989 (51.5209) nleep/row_min_mean 1490.2905 (1488.3255) lr 2.2949e-04 eta 0:03:22
epoch [41/50] batch [60/167] time 0.065 (0.120) data 0.001 (0.004) loss 1.5364 (1.4118) teacher_loss 0.2766 (0.2371) loss_zs_kd 0.0408 (0.0257) loss_oracle 0.4975 (0.5099) kd_loss 0.9907 (0.9068) acc 84.3750 (90.8854) gate/entropy 1.0067 (1.0056) gate/usage_max 0.5424 (0.5436) gate/usage_min 0.2245 (0.2240) gate/usage_std 0.1479 (0.1487) teacher/entropy 0.0536 (0.0453) teacher/usage_max 0.5116 (0.6005) teacher/usage_min 0.0025 (0.0040) teacher/usage_std 0.2342 (0.2534) nleep/row_max_mean 1511.5863 (1528.9169) nleep/row_max_std 58.4527 (51.9125) nleep/row_min_mean 1473.3224 (1489.4987) lr 2.2949e-04 eta 0:03:12
epoch [41/50] batch [80/167] time 0.108 (0.118) data 0.000 (0.003) loss 1.3170 (1.4057) teacher_loss 0.0908 (0.2350) loss_zs_kd 0.0187 (0.0257) loss_oracle 0.5719 (0.5074) kd_loss 0.9309 (0.9042) acc 96.8750 (91.0156) gate/entropy 1.0061 (1.0056) gate/usage_max 0.5430 (0.5436) gate/usage_min 0.2241 (0.2240) gate/usage_std 0.1483 (0.1487) teacher/entropy 0.0181 (0.0463) teacher/usage_max 0.6000 (0.6015) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2494 (0.2533) nleep/row_max_mean 1530.5266 (1529.3392) nleep/row_max_std 48.0879 (51.8804) nleep/row_min_mean 1486.0063 (1489.6101) lr 2.2949e-04 eta 0:03:07
epoch [41/50] batch [100/167] time 0.138 (0.118) data 0.000 (0.003) loss 1.3985 (1.3994) teacher_loss 0.1566 (0.2296) loss_zs_kd 0.0234 (0.0258) loss_oracle 0.4947 (0.5040) kd_loss 0.9829 (0.9049) acc 93.7500 (91.4688) gate/entropy 1.0058 (1.0056) gate/usage_max 0.5433 (0.5436) gate/usage_min 0.2239 (0.2239) gate/usage_std 0.1485 (0.1487) teacher/entropy 0.0463 (0.0471) teacher/usage_max 0.5020 (0.6008) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2357 (0.2530) nleep/row_max_mean 1519.6677 (1529.8744) nleep/row_max_std 54.7782 (51.6970) nleep/row_min_mean 1480.8011 (1490.2598) lr 2.2949e-04 eta 0:03:05
epoch [41/50] batch [120/167] time 0.190 (0.119) data 0.000 (0.002) loss 1.3772 (1.3934) teacher_loss 0.2605 (0.2290) loss_zs_kd 0.0484 (0.0259) loss_oracle 0.5375 (0.5063) kd_loss 0.8237 (0.8983) acc 90.6250 (91.5625) gate/entropy 1.0056 (1.0056) gate/usage_max 0.5435 (0.5436) gate/usage_min 0.2238 (0.2239) gate/usage_std 0.1487 (0.1488) teacher/entropy 0.0642 (0.0463) teacher/usage_max 0.6696 (0.6085) teacher/usage_min 0.0085 (0.0040) teacher/usage_std 0.2700 (0.2552) nleep/row_max_mean 1528.2433 (1530.9271) nleep/row_max_std 55.4114 (51.6565) nleep/row_min_mean 1488.9097 (1490.9498) lr 2.2949e-04 eta 0:03:04
epoch [41/50] batch [140/167] time 0.158 (0.119) data 0.000 (0.002) loss 1.3114 (1.3966) teacher_loss 0.0714 (0.2300) loss_zs_kd 0.0255 (0.0261) loss_oracle 0.5566 (0.5058) kd_loss 0.9490 (0.9007) acc 100.0000 (91.4509) gate/entropy 1.0057 (1.0056) gate/usage_max 0.5434 (0.5436) gate/usage_min 0.2238 (0.2239) gate/usage_std 0.1486 (0.1487) teacher/entropy 0.0031 (0.0441) teacher/usage_max 0.5937 (0.6084) teacher/usage_min 0.0005 (0.0038) teacher/usage_std 0.2475 (0.2550) nleep/row_max_mean 1521.8167 (1531.4436) nleep/row_max_std 68.8372 (51.5924) nleep/row_min_mean 1483.4009 (1491.1773) lr 2.2949e-04 eta 0:03:02
epoch [41/50] batch [160/167] time 0.157 (0.123) data 0.000 (0.002) loss 1.1948 (1.3970) teacher_loss 0.1484 (0.2313) loss_zs_kd 0.0164 (0.0261) loss_oracle 0.5188 (0.5060) kd_loss 0.7788 (0.8996) acc 96.8750 (91.4062) gate/entropy 1.0061 (1.0056) gate/usage_max 0.5430 (0.5436) gate/usage_min 0.2239 (0.2238) gate/usage_std 0.1483 (0.1487) teacher/entropy 0.0206 (0.0431) teacher/usage_max 0.7751 (0.6109) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.3256 (0.2561) nleep/row_max_mean 1526.6716 (1531.1219) nleep/row_max_std 64.0273 (51.9813) nleep/row_min_mean 1484.4785 (1490.7855) lr 2.2949e-04 eta 0:03:05
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [42/50] batch [20/167] time 0.124 (0.156) data 0.000 (0.013) loss 1.4275 (1.3787) teacher_loss 0.1463 (0.2014) loss_zs_kd 0.0285 (0.0324) loss_oracle 0.4360 (0.5113) kd_loss 1.0489 (0.9054) acc 90.6250 (91.4062) gate/entropy 1.0051 (1.0055) gate/usage_max 0.5442 (0.5437) gate/usage_min 0.2233 (0.2236) gate/usage_std 0.1492 (0.1488) teacher/entropy 0.0666 (0.0364) teacher/usage_max 0.5975 (0.6257) teacher/usage_min 0.0002 (0.0023) teacher/usage_std 0.2487 (0.2594) nleep/row_max_mean 1528.5542 (1531.4608) nleep/row_max_std 42.2571 (48.8571) nleep/row_min_mean 1490.6309 (1490.5475) lr 1.9098e-04 eta 0:03:50
epoch [42/50] batch [40/167] time 0.132 (0.151) data 0.000 (0.006) loss 1.2848 (1.3666) teacher_loss 0.1300 (0.2029) loss_zs_kd 0.0381 (0.0298) loss_oracle 0.4946 (0.5153) kd_loss 0.8885 (0.8911) acc 93.7500 (92.1875) gate/entropy 1.0054 (1.0055) gate/usage_max 0.5438 (0.5437) gate/usage_min 0.2235 (0.2235) gate/usage_std 0.1489 (0.1488) teacher/entropy 0.0174 (0.0355) teacher/usage_max 0.6504 (0.6337) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2658 (0.2638) nleep/row_max_mean 1500.9771 (1528.1544) nleep/row_max_std 70.0923 (50.1579) nleep/row_min_mean 1462.1711 (1487.8372) lr 1.9098e-04 eta 0:03:40
epoch [42/50] batch [60/167] time 0.135 (0.148) data 0.001 (0.004) loss 1.7663 (1.3780) teacher_loss 0.5585 (0.2141) loss_zs_kd 0.0329 (0.0289) loss_oracle 0.4380 (0.5116) kd_loss 0.9723 (0.8936) acc 78.1250 (92.0312) gate/entropy 1.0055 (1.0054) gate/usage_max 0.5437 (0.5438) gate/usage_min 0.2235 (0.2235) gate/usage_std 0.1488 (0.1489) teacher/entropy 0.0406 (0.0373) teacher/usage_max 0.5207 (0.6259) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2363 (0.2608) nleep/row_max_mean 1522.3235 (1526.5174) nleep/row_max_std 41.6790 (50.7020) nleep/row_min_mean 1487.8529 (1487.2499) lr 1.9098e-04 eta 0:03:33
epoch [42/50] batch [80/167] time 0.138 (0.146) data 0.000 (0.003) loss 1.5581 (1.3676) teacher_loss 0.3976 (0.2092) loss_zs_kd 0.0313 (0.0283) loss_oracle 0.4702 (0.5084) kd_loss 0.9098 (0.8900) acc 93.7500 (92.3438) gate/entropy 1.0052 (1.0054) gate/usage_max 0.5440 (0.5439) gate/usage_min 0.2233 (0.2234) gate/usage_std 0.1490 (0.1489) teacher/entropy 0.0185 (0.0368) teacher/usage_max 0.6237 (0.6294) teacher/usage_min 0.0035 (0.0032) teacher/usage_std 0.2547 (0.2620) nleep/row_max_mean 1528.2407 (1526.0314) nleep/row_max_std 56.2675 (51.0797) nleep/row_min_mean 1489.3135 (1486.7935) lr 1.9098e-04 eta 0:03:28
epoch [42/50] batch [100/167] time 0.086 (0.142) data 0.000 (0.003) loss 1.3301 (1.3724) teacher_loss 0.1379 (0.2109) loss_zs_kd 0.0448 (0.0285) loss_oracle 0.4690 (0.5081) kd_loss 0.9353 (0.8932) acc 96.8750 (92.1250) gate/entropy 1.0052 (1.0053) gate/usage_max 0.5441 (0.5439) gate/usage_min 0.2232 (0.2234) gate/usage_std 0.1491 (0.1489) teacher/entropy 0.0269 (0.0356) teacher/usage_max 0.5833 (0.6279) teacher/usage_min 0.0298 (0.0033) teacher/usage_std 0.2291 (0.2614) nleep/row_max_mean 1522.5063 (1526.3993) nleep/row_max_std 53.7652 (50.5579) nleep/row_min_mean 1485.3533 (1487.2028) lr 1.9098e-04 eta 0:03:18
epoch [42/50] batch [120/167] time 0.083 (0.136) data 0.000 (0.002) loss 1.2771 (1.3702) teacher_loss 0.2140 (0.2104) loss_zs_kd 0.0286 (0.0291) loss_oracle 0.4815 (0.5093) kd_loss 0.8080 (0.8906) acc 87.5000 (92.1094) gate/entropy 1.0055 (1.0053) gate/usage_max 0.5437 (0.5439) gate/usage_min 0.2234 (0.2234) gate/usage_std 0.1488 (0.1489) teacher/entropy 0.0491 (0.0359) teacher/usage_max 0.7065 (0.6308) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2898 (0.2620) nleep/row_max_mean 1525.4412 (1526.4432) nleep/row_max_std 46.7575 (50.2237) nleep/row_min_mean 1487.3428 (1487.2460) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [140/167] time 0.141 (0.135) data 0.000 (0.002) loss 1.5824 (1.3721) teacher_loss 0.4657 (0.2150) loss_zs_kd 0.0373 (0.0296) loss_oracle 0.4895 (0.5078) kd_loss 0.8532 (0.8884) acc 87.5000 (91.9643) gate/entropy 1.0051 (1.0052) gate/usage_max 0.5441 (0.5440) gate/usage_min 0.2231 (0.2233) gate/usage_std 0.1491 (0.1490) teacher/entropy 0.0206 (0.0362) teacher/usage_max 0.6854 (0.6321) teacher/usage_min 0.0005 (0.0042) teacher/usage_std 0.2800 (0.2621) nleep/row_max_mean 1511.9236 (1526.7180) nleep/row_max_std 56.5894 (50.0497) nleep/row_min_mean 1474.4500 (1487.5047) lr 1.9098e-04 eta 0:03:03
epoch [42/50] batch [160/167] time 0.082 (0.133) data 0.000 (0.002) loss 1.3624 (1.3726) teacher_loss 0.1778 (0.2160) loss_zs_kd 0.0180 (0.0295) loss_oracle 0.5978 (0.5084) kd_loss 0.8767 (0.8876) acc 90.6250 (91.9141) gate/entropy 1.0054 (1.0052) gate/usage_max 0.5438 (0.5440) gate/usage_min 0.2232 (0.2233) gate/usage_std 0.1489 (0.1490) teacher/entropy 0.0279 (0.0353) teacher/usage_max 0.6487 (0.6336) teacher/usage_min 0.0005 (0.0044) teacher/usage_std 0.2649 (0.2631) nleep/row_max_mean 1519.8430 (1526.0703) nleep/row_max_std 44.8715 (50.0648) nleep/row_min_mean 1477.5851 (1486.8444) lr 1.9098e-04 eta 0:02:57
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,202
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [43/50] batch [20/167] time 0.202 (0.137) data 0.000 (0.014) loss 1.3509 (1.4095) teacher_loss 0.2397 (0.2345) loss_zs_kd 0.0360 (0.0306) loss_oracle 0.4767 (0.5306) kd_loss 0.8549 (0.8943) acc 96.8750 (91.2500) gate/entropy 1.0050 (1.0051) gate/usage_max 0.5442 (0.5442) gate/usage_min 0.2230 (0.2230) gate/usage_std 0.1492 (0.1491) teacher/entropy 0.0550 (0.0336) teacher/usage_max 0.6433 (0.6485) teacher/usage_min 0.0294 (0.0019) teacher/usage_std 0.2507 (0.2709) nleep/row_max_mean 1528.0201 (1524.9106) nleep/row_max_std 48.8746 (45.7897) nleep/row_min_mean 1489.0320 (1485.0887) lr 1.5567e-04 eta 0:03:00
epoch [43/50] batch [40/167] time 0.154 (0.123) data 0.000 (0.007) loss 1.3926 (1.3886) teacher_loss 0.2354 (0.2276) loss_zs_kd 0.0355 (0.0292) loss_oracle 0.4885 (0.5285) kd_loss 0.8953 (0.8822) acc 90.6250 (91.3281) gate/entropy 1.0054 (1.0051) gate/usage_max 0.5438 (0.5442) gate/usage_min 0.2232 (0.2230) gate/usage_std 0.1489 (0.1491) teacher/entropy 0.0255 (0.0345) teacher/usage_max 0.6299 (0.6516) teacher/usage_min 0.0005 (0.0020) teacher/usage_std 0.2582 (0.2710) nleep/row_max_mean 1520.1620 (1524.1698) nleep/row_max_std 57.7751 (48.7479) nleep/row_min_mean 1480.6279 (1484.5987) lr 1.5567e-04 eta 0:02:39
epoch [43/50] batch [60/167] time 0.142 (0.134) data 0.000 (0.005) loss 1.6259 (1.4089) teacher_loss 0.3841 (0.2310) loss_zs_kd 0.0530 (0.0303) loss_oracle 0.5434 (0.5263) kd_loss 0.9436 (0.8996) acc 87.5000 (91.0938) gate/entropy 1.0049 (1.0051) gate/usage_max 0.5444 (0.5441) gate/usage_min 0.2229 (0.2230) gate/usage_std 0.1493 (0.1491) teacher/entropy 0.0080 (0.0352) teacher/usage_max 0.5938 (0.6385) teacher/usage_min 0.0004 (0.0031) teacher/usage_std 0.2476 (0.2651) nleep/row_max_mean 1520.7527 (1523.5987) nleep/row_max_std 49.3120 (48.5647) nleep/row_min_mean 1486.6805 (1484.6858) lr 1.5567e-04 eta 0:02:51
epoch [43/50] batch [80/167] time 0.142 (0.138) data 0.000 (0.004) loss 1.4216 (1.4079) teacher_loss 0.1244 (0.2325) loss_zs_kd 0.0302 (0.0309) loss_oracle 0.5567 (0.5252) kd_loss 1.0038 (0.8974) acc 96.8750 (91.0938) gate/entropy 1.0043 (1.0051) gate/usage_max 0.5451 (0.5441) gate/usage_min 0.2225 (0.2230) gate/usage_std 0.1498 (0.1491) teacher/entropy 0.0009 (0.0352) teacher/usage_max 0.5313 (0.6351) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2371 (0.2637) nleep/row_max_mean 1540.4757 (1524.4233) nleep/row_max_std 33.5713 (48.9107) nleep/row_min_mean 1498.4673 (1485.2763) lr 1.5567e-04 eta 0:02:53
epoch [43/50] batch [100/167] time 0.137 (0.141) data 0.000 (0.003) loss 1.1592 (1.4003) teacher_loss 0.1553 (0.2284) loss_zs_kd 0.0220 (0.0309) loss_oracle 0.4416 (0.5218) kd_loss 0.7721 (0.8955) acc 96.8750 (91.0625) gate/entropy 1.0051 (1.0050) gate/usage_max 0.5442 (0.5442) gate/usage_min 0.2229 (0.2230) gate/usage_std 0.1491 (0.1492) teacher/entropy 0.0605 (0.0376) teacher/usage_max 0.7351 (0.6343) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.3040 (0.2634) nleep/row_max_mean 1526.9253 (1524.7271) nleep/row_max_std 43.8394 (49.2976) nleep/row_min_mean 1485.5277 (1485.7611) lr 1.5567e-04 eta 0:02:53
epoch [43/50] batch [120/167] time 0.155 (0.142) data 0.000 (0.002) loss 1.3998 (1.3971) teacher_loss 0.2903 (0.2249) loss_zs_kd 0.0280 (0.0313) loss_oracle 0.4604 (0.5211) kd_loss 0.8653 (0.8960) acc 87.5000 (91.2240) gate/entropy 1.0045 (1.0050) gate/usage_max 0.5448 (0.5442) gate/usage_min 0.2226 (0.2230) gate/usage_std 0.1496 (0.1492) teacher/entropy 0.0088 (0.0378) teacher/usage_max 0.6865 (0.6312) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.2806 (0.2621) nleep/row_max_mean 1522.8127 (1524.6018) nleep/row_max_std 57.2676 (49.9817) nleep/row_min_mean 1483.7456 (1485.5693) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [140/167] time 0.150 (0.144) data 0.000 (0.002) loss 1.1786 (1.3933) teacher_loss 0.0991 (0.2200) loss_zs_kd 0.0355 (0.0311) loss_oracle 0.5146 (0.5216) kd_loss 0.8044 (0.8969) acc 96.8750 (91.5625) gate/entropy 1.0050 (1.0050) gate/usage_max 0.5442 (0.5442) gate/usage_min 0.2228 (0.2229) gate/usage_std 0.1492 (0.1492) teacher/entropy 0.0708 (0.0379) teacher/usage_max 0.6858 (0.6286) teacher/usage_min 0.0005 (0.0049) teacher/usage_std 0.2801 (0.2610) nleep/row_max_mean 1521.5042 (1525.2561) nleep/row_max_std 66.0954 (50.5988) nleep/row_min_mean 1479.9624 (1486.0272) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [160/167] time 0.149 (0.144) data 0.000 (0.002) loss 1.2922 (1.3909) teacher_loss 0.0918 (0.2206) loss_zs_kd 0.0321 (0.0311) loss_oracle 0.5816 (0.5207) kd_loss 0.8936 (0.8944) acc 96.8750 (91.6016) gate/entropy 1.0055 (1.0050) gate/usage_max 0.5437 (0.5442) gate/usage_min 0.2230 (0.2229) gate/usage_std 0.1488 (0.1492) teacher/entropy 0.0592 (0.0387) teacher/usage_max 0.5905 (0.6287) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.2470 (0.2605) nleep/row_max_mean 1530.3086 (1525.2940) nleep/row_max_std 46.6934 (51.1130) nleep/row_min_mean 1488.7476 (1486.0371) lr 1.5567e-04 eta 0:02:49
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [44/50] batch [20/167] time 0.085 (0.123) data 0.001 (0.013) loss 1.2481 (1.3685) teacher_loss 0.2466 (0.1953) loss_zs_kd 0.0484 (0.0269) loss_oracle 0.5155 (0.5266) kd_loss 0.7195 (0.8964) acc 93.7500 (93.2812) gate/entropy 1.0041 (1.0049) gate/usage_max 0.5453 (0.5443) gate/usage_min 0.2223 (0.2227) gate/usage_std 0.1499 (0.1492) teacher/entropy 0.0891 (0.0484) teacher/usage_max 0.7633 (0.6029) teacher/usage_min 0.0185 (0.0108) teacher/usage_std 0.3148 (0.2496) nleep/row_max_mean 1550.0542 (1535.6513) nleep/row_max_std 54.0337 (52.0240) nleep/row_min_mean 1506.6539 (1493.7061) lr 1.2369e-04 eta 0:02:21
epoch [44/50] batch [40/167] time 0.074 (0.116) data 0.000 (0.007) loss 1.3034 (1.3957) teacher_loss 0.2621 (0.2212) loss_zs_kd 0.0338 (0.0285) loss_oracle 0.4743 (0.5179) kd_loss 0.7872 (0.9014) acc 90.6250 (91.9531) gate/entropy 1.0046 (1.0049) gate/usage_max 0.5446 (0.5444) gate/usage_min 0.2225 (0.2227) gate/usage_std 0.1495 (0.1493) teacher/entropy 0.1164 (0.0446) teacher/usage_max 0.6509 (0.6014) teacher/usage_min 0.0063 (0.0075) teacher/usage_std 0.2632 (0.2505) nleep/row_max_mean 1543.6008 (1534.9789) nleep/row_max_std 38.1684 (51.6333) nleep/row_min_mean 1501.5725 (1493.4152) lr 1.2369e-04 eta 0:02:11
epoch [44/50] batch [60/167] time 0.139 (0.116) data 0.001 (0.005) loss 1.3783 (1.3980) teacher_loss 0.1180 (0.2219) loss_zs_kd 0.0198 (0.0295) loss_oracle 0.5506 (0.5197) kd_loss 0.9750 (0.9016) acc 93.7500 (91.6146) gate/entropy 1.0049 (1.0049) gate/usage_max 0.5444 (0.5444) gate/usage_min 0.2226 (0.2227) gate/usage_std 0.1493 (0.1493) teacher/entropy 0.0348 (0.0453) teacher/usage_max 0.5249 (0.6035) teacher/usage_min 0.0053 (0.0069) teacher/usage_std 0.2331 (0.2509) nleep/row_max_mean 1526.1211 (1535.2690) nleep/row_max_std 50.0980 (52.3319) nleep/row_min_mean 1487.5579 (1493.4713) lr 1.2369e-04 eta 0:02:08
epoch [44/50] batch [80/167] time 0.145 (0.117) data 0.000 (0.004) loss 1.3018 (1.3900) teacher_loss 0.1897 (0.2125) loss_zs_kd 0.0337 (0.0287) loss_oracle 0.4912 (0.5212) kd_loss 0.8497 (0.9026) acc 90.6250 (91.9141) gate/entropy 1.0042 (1.0049) gate/usage_max 0.5452 (0.5444) gate/usage_min 0.2222 (0.2226) gate/usage_std 0.1499 (0.1493) teacher/entropy 0.0601 (0.0445) teacher/usage_max 0.6422 (0.6022) teacher/usage_min 0.0042 (0.0068) teacher/usage_std 0.2609 (0.2506) nleep/row_max_mean 1541.3831 (1534.9876) nleep/row_max_std 47.5296 (52.6287) nleep/row_min_mean 1499.5457 (1493.3106) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [100/167] time 0.073 (0.118) data 0.000 (0.003) loss 1.4191 (1.3955) teacher_loss 0.1944 (0.2232) loss_zs_kd 0.0217 (0.0292) loss_oracle 0.6154 (0.5246) kd_loss 0.9061 (0.8953) acc 90.6250 (91.5312) gate/entropy 1.0049 (1.0049) gate/usage_max 0.5443 (0.5444) gate/usage_min 0.2226 (0.2226) gate/usage_std 0.1493 (0.1493) teacher/entropy 0.0284 (0.0431) teacher/usage_max 0.6129 (0.6127) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.2531 (0.2545) nleep/row_max_mean 1532.7543 (1534.1763) nleep/row_max_std 55.4703 (53.3202) nleep/row_min_mean 1489.7012 (1492.3089) lr 1.2369e-04 eta 0:02:05
epoch [44/50] batch [120/167] time 0.074 (0.118) data 0.000 (0.002) loss 1.4122 (1.3930) teacher_loss 0.1254 (0.2220) loss_zs_kd 0.0355 (0.0292) loss_oracle 0.4791 (0.5251) kd_loss 1.0295 (0.8938) acc 96.8750 (91.5625) gate/entropy 1.0053 (1.0049) gate/usage_max 0.5439 (0.5444) gate/usage_min 0.2228 (0.2226) gate/usage_std 0.1490 (0.1493) teacher/entropy 0.0001 (0.0419) teacher/usage_max 0.5000 (0.6163) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.2357 (0.2561) nleep/row_max_mean 1514.9347 (1533.7217) nleep/row_max_std 61.6927 (53.2614) nleep/row_min_mean 1470.0958 (1491.7425) lr 1.2369e-04 eta 0:02:03
epoch [44/50] batch [140/167] time 0.081 (0.118) data 0.000 (0.002) loss 1.5037 (1.3949) teacher_loss 0.3998 (0.2269) loss_zs_kd 0.0245 (0.0297) loss_oracle 0.5316 (0.5225) kd_loss 0.8258 (0.8919) acc 84.3750 (91.4286) gate/entropy 1.0043 (1.0048) gate/usage_max 0.5450 (0.5444) gate/usage_min 0.2223 (0.2226) gate/usage_std 0.1498 (0.1493) teacher/entropy 0.0602 (0.0416) teacher/usage_max 0.6720 (0.6183) teacher/usage_min 0.0351 (0.0070) teacher/usage_std 0.2616 (0.2570) nleep/row_max_mean 1533.5505 (1533.0590) nleep/row_max_std 50.3358 (53.3207) nleep/row_min_mean 1498.1128 (1491.2999) lr 1.2369e-04 eta 0:02:00
epoch [44/50] batch [160/167] time 0.162 (0.115) data 0.000 (0.002) loss 1.5962 (1.3930) teacher_loss 0.3665 (0.2232) loss_zs_kd 0.0302 (0.0297) loss_oracle 0.5935 (0.5222) kd_loss 0.9179 (0.8938) acc 87.5000 (91.5430) gate/entropy 1.0049 (1.0048) gate/usage_max 0.5443 (0.5444) gate/usage_min 0.2226 (0.2226) gate/usage_std 0.1492 (0.1493) teacher/entropy 0.0559 (0.0415) teacher/usage_max 0.5678 (0.6160) teacher/usage_min 0.0017 (0.0080) teacher/usage_std 0.2411 (0.2556) nleep/row_max_mean 1516.2310 (1532.4910) nleep/row_max_std 56.5545 (53.4567) nleep/row_min_mean 1473.2000 (1490.8622) lr 1.2369e-04 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [45/50] batch [20/167] time 0.167 (0.182) data 0.000 (0.014) loss 1.4475 (1.3809) teacher_loss 0.2024 (0.2541) loss_zs_kd 0.0197 (0.0277) loss_oracle 0.5382 (0.5240) kd_loss 0.9662 (0.8509) acc 90.6250 (90.0000) gate/entropy 1.0045 (1.0047) gate/usage_max 0.5448 (0.5446) gate/usage_min 0.2223 (0.2224) gate/usage_std 0.1496 (0.1495) teacher/entropy 0.0248 (0.0469) teacher/usage_max 0.5475 (0.6577) teacher/usage_min 0.0000 (0.0143) teacher/usage_std 0.2389 (0.2660) nleep/row_max_mean 1532.4514 (1534.6460) nleep/row_max_std 60.8668 (57.7782) nleep/row_min_mean 1488.0767 (1491.8533) lr 9.5173e-05 eta 0:02:58
epoch [45/50] batch [40/167] time 0.153 (0.170) data 0.000 (0.007) loss 1.4503 (1.3851) teacher_loss 0.2386 (0.2345) loss_zs_kd 0.0428 (0.0280) loss_oracle 0.4851 (0.5251) kd_loss 0.9477 (0.8740) acc 90.6250 (90.9375) gate/entropy 1.0048 (1.0047) gate/usage_max 0.5444 (0.5445) gate/usage_min 0.2224 (0.2224) gate/usage_std 0.1493 (0.1494) teacher/entropy 0.0414 (0.0434) teacher/usage_max 0.5490 (0.6384) teacher/usage_min 0.0330 (0.0107) teacher/usage_std 0.2190 (0.2603) nleep/row_max_mean 1514.8674 (1529.5997) nleep/row_max_std 58.2351 (58.6118) nleep/row_min_mean 1475.9001 (1487.6690) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [60/167] time 0.128 (0.167) data 0.001 (0.005) loss 1.1886 (1.3907) teacher_loss 0.0981 (0.2361) loss_zs_kd 0.0225 (0.0287) loss_oracle 0.5162 (0.5249) kd_loss 0.8212 (0.8778) acc 96.8750 (90.9375) gate/entropy 1.0051 (1.0047) gate/usage_max 0.5441 (0.5446) gate/usage_min 0.2226 (0.2224) gate/usage_std 0.1491 (0.1495) teacher/entropy 0.0735 (0.0418) teacher/usage_max 0.6596 (0.6380) teacher/usage_min 0.0000 (0.0096) teacher/usage_std 0.2693 (0.2611) nleep/row_max_mean 1536.4001 (1529.6947) nleep/row_max_std 43.8351 (56.7261) nleep/row_min_mean 1490.6022 (1487.5363) lr 9.5173e-05 eta 0:02:36
epoch [45/50] batch [80/167] time 0.156 (0.164) data 0.000 (0.004) loss 1.3929 (1.3929) teacher_loss 0.1590 (0.2290) loss_zs_kd 0.0221 (0.0285) loss_oracle 0.5116 (0.5264) kd_loss 0.9671 (0.8864) acc 93.7500 (91.1328) gate/entropy 1.0051 (1.0047) gate/usage_max 0.5441 (0.5445) gate/usage_min 0.2225 (0.2224) gate/usage_std 0.1491 (0.1494) teacher/entropy 0.0427 (0.0401) teacher/usage_max 0.5243 (0.6287) teacher/usage_min 0.0001 (0.0099) teacher/usage_std 0.2365 (0.2580) nleep/row_max_mean 1527.5845 (1528.2511) nleep/row_max_std 47.5495 (55.8216) nleep/row_min_mean 1484.2991 (1486.0514) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [100/167] time 0.162 (0.163) data 0.000 (0.003) loss 1.4594 (1.4026) teacher_loss 0.2886 (0.2319) loss_zs_kd 0.0508 (0.0294) loss_oracle 0.5496 (0.5242) kd_loss 0.8706 (0.8939) acc 87.5000 (91.0625) gate/entropy 1.0034 (1.0047) gate/usage_max 0.5460 (0.5445) gate/usage_min 0.2217 (0.2224) gate/usage_std 0.1505 (0.1494) teacher/entropy 0.0421 (0.0390) teacher/usage_max 0.6377 (0.6201) teacher/usage_min 0.0001 (0.0089) teacher/usage_std 0.2611 (0.2558) nleep/row_max_mean 1551.8767 (1528.9750) nleep/row_max_std 47.9188 (55.0701) nleep/row_min_mean 1501.1470 (1486.3250) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [120/167] time 0.095 (0.155) data 0.000 (0.003) loss 1.3667 (1.4106) teacher_loss 0.2621 (0.2307) loss_zs_kd 0.0343 (0.0297) loss_oracle 0.5279 (0.5263) kd_loss 0.8236 (0.9019) acc 87.5000 (91.0938) gate/entropy 1.0055 (1.0048) gate/usage_max 0.5437 (0.5445) gate/usage_min 0.2227 (0.2224) gate/usage_std 0.1488 (0.1494) teacher/entropy 0.0298 (0.0393) teacher/usage_max 0.7133 (0.6173) teacher/usage_min 0.0277 (0.0081) teacher/usage_std 0.2848 (0.2560) nleep/row_max_mean 1524.7129 (1528.8168) nleep/row_max_std 64.5761 (54.5849) nleep/row_min_mean 1478.4482 (1486.2907) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [140/167] time 0.101 (0.152) data 0.000 (0.002) loss 1.5070 (1.4078) teacher_loss 0.0976 (0.2261) loss_zs_kd 0.0241 (0.0304) loss_oracle 0.5338 (0.5246) kd_loss 1.1305 (0.9042) acc 96.8750 (91.2723) gate/entropy 1.0051 (1.0047) gate/usage_max 0.5441 (0.5445) gate/usage_min 0.2225 (0.2224) gate/usage_std 0.1491 (0.1494) teacher/entropy 0.0060 (0.0397) teacher/usage_max 0.6240 (0.6146) teacher/usage_min 0.0004 (0.0079) teacher/usage_std 0.2563 (0.2556) nleep/row_max_mean 1532.9824 (1529.9898) nleep/row_max_std 58.2512 (53.3924) nleep/row_min_mean 1489.2776 (1487.2511) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [160/167] time 0.075 (0.147) data 0.000 (0.002) loss 1.5660 (1.4140) teacher_loss 0.2822 (0.2268) loss_zs_kd 0.0550 (0.0301) loss_oracle 0.4382 (0.5237) kd_loss 1.0372 (0.9103) acc 90.6250 (91.2109) gate/entropy 1.0036 (1.0047) gate/usage_max 0.5459 (0.5445) gate/usage_min 0.2217 (0.2224) gate/usage_std 0.1504 (0.1494) teacher/entropy 0.0247 (0.0395) teacher/usage_max 0.5066 (0.6109) teacher/usage_min 0.0288 (0.0076) teacher/usage_std 0.2160 (0.2545) nleep/row_max_mean 1545.6223 (1530.7406) nleep/row_max_std 45.8601 (53.3608) nleep/row_min_mean 1504.0002 (1487.9768) lr 9.5173e-05 eta 0:02:03
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,200
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [46/50] batch [20/167] time 0.084 (0.133) data 0.000 (0.013) loss 1.3939 (1.4062) teacher_loss 0.0998 (0.2160) loss_zs_kd 0.0358 (0.0298) loss_oracle 0.4834 (0.5266) kd_loss 1.0345 (0.9121) acc 96.8750 (91.8750) gate/entropy 1.0058 (1.0047) gate/usage_max 0.5432 (0.5445) gate/usage_min 0.2228 (0.2223) gate/usage_std 0.1485 (0.1494) teacher/entropy 0.0521 (0.0507) teacher/usage_max 0.5650 (0.5994) teacher/usage_min 0.0005 (0.0091) teacher/usage_std 0.2413 (0.2504) nleep/row_max_mean 1525.2050 (1533.5438) nleep/row_max_std 58.6276 (55.8213) nleep/row_min_mean 1486.9207 (1490.5677) lr 7.0224e-05 eta 0:01:48
epoch [46/50] batch [40/167] time 0.191 (0.128) data 0.000 (0.007) loss 1.3615 (1.4044) teacher_loss 0.1375 (0.2108) loss_zs_kd 0.0273 (0.0291) loss_oracle 0.5108 (0.5236) kd_loss 0.9550 (0.9172) acc 96.8750 (91.7188) gate/entropy 1.0050 (1.0048) gate/usage_max 0.5443 (0.5445) gate/usage_min 0.2223 (0.2223) gate/usage_std 0.1492 (0.1494) teacher/entropy 0.0290 (0.0464) teacher/usage_max 0.5540 (0.5971) teacher/usage_min 0.0001 (0.0084) teacher/usage_std 0.2397 (0.2498) nleep/row_max_mean 1535.1410 (1533.9350) nleep/row_max_std 51.8511 (52.9481) nleep/row_min_mean 1491.3190 (1490.8366) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [60/167] time 0.141 (0.129) data 0.001 (0.005) loss 1.5388 (1.4177) teacher_loss 0.3094 (0.2042) loss_zs_kd 0.0275 (0.0279) loss_oracle 0.5508 (0.5245) kd_loss 0.9402 (0.9373) acc 84.3750 (92.3438) gate/entropy 1.0038 (1.0047) gate/usage_max 0.5456 (0.5446) gate/usage_min 0.2218 (0.2222) gate/usage_std 0.1501 (0.1494) teacher/entropy 0.0358 (0.0439) teacher/usage_max 0.5658 (0.5829) teacher/usage_min 0.0334 (0.0079) teacher/usage_std 0.2225 (0.2454) nleep/row_max_mean 1543.5424 (1534.9902) nleep/row_max_std 48.5061 (52.5886) nleep/row_min_mean 1499.3872 (1492.2302) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [80/167] time 0.162 (0.136) data 0.000 (0.003) loss 1.3849 (1.4206) teacher_loss 0.2774 (0.2068) loss_zs_kd 0.0353 (0.0276) loss_oracle 0.4829 (0.5244) kd_loss 0.8484 (0.9377) acc 90.6250 (92.3047) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5446 (0.5446) gate/usage_min 0.2221 (0.2222) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0628 (0.0440) teacher/usage_max 0.6405 (0.5849) teacher/usage_min 0.0001 (0.0081) teacher/usage_std 0.2621 (0.2456) nleep/row_max_mean 1532.9954 (1534.4994) nleep/row_max_std 49.3592 (52.7978) nleep/row_min_mean 1491.2789 (1491.6275) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [100/167] time 0.159 (0.140) data 0.000 (0.003) loss 1.4695 (1.4276) teacher_loss 0.3008 (0.2094) loss_zs_kd 0.0580 (0.0283) loss_oracle 0.4868 (0.5226) kd_loss 0.8963 (0.9427) acc 87.5000 (92.3438) gate/entropy 1.0047 (1.0047) gate/usage_max 0.5446 (0.5446) gate/usage_min 0.2221 (0.2222) gate/usage_std 0.1495 (0.1495) teacher/entropy 0.0676 (0.0422) teacher/usage_max 0.5792 (0.5825) teacher/usage_min 0.0102 (0.0081) teacher/usage_std 0.2386 (0.2451) nleep/row_max_mean 1526.8748 (1533.8026) nleep/row_max_std 62.0501 (54.1281) nleep/row_min_mean 1486.0500 (1490.9447) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [120/167] time 0.157 (0.143) data 0.000 (0.002) loss 1.5315 (1.4331) teacher_loss 0.3968 (0.2157) loss_zs_kd 0.0401 (0.0280) loss_oracle 0.6071 (0.5225) kd_loss 0.8111 (0.9421) acc 75.0000 (91.8229) gate/entropy 1.0041 (1.0047) gate/usage_max 0.5453 (0.5446) gate/usage_min 0.2218 (0.2222) gate/usage_std 0.1499 (0.1495) teacher/entropy 0.0352 (0.0427) teacher/usage_max 0.7178 (0.5819) teacher/usage_min 0.0122 (0.0086) teacher/usage_std 0.2915 (0.2446) nleep/row_max_mean 1548.6562 (1534.2186) nleep/row_max_std 59.0755 (53.8140) nleep/row_min_mean 1499.4790 (1491.4020) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [140/167] time 0.146 (0.145) data 0.000 (0.002) loss 1.4811 (1.4371) teacher_loss 0.1582 (0.2161) loss_zs_kd 0.0059 (0.0278) loss_oracle 0.4900 (0.5241) kd_loss 1.0750 (0.9450) acc 93.7500 (91.6964) gate/entropy 1.0050 (1.0047) gate/usage_max 0.5442 (0.5446) gate/usage_min 0.2223 (0.2222) gate/usage_std 0.1492 (0.1495) teacher/entropy 0.0077 (0.0418) teacher/usage_max 0.5618 (0.5813) teacher/usage_min 0.0004 (0.0079) teacher/usage_std 0.2408 (0.2447) nleep/row_max_mean 1538.0193 (1534.3705) nleep/row_max_std 55.3829 (53.9066) nleep/row_min_mean 1498.4745 (1491.5109) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [160/167] time 0.160 (0.144) data 0.000 (0.002) loss 1.4700 (1.4412) teacher_loss 0.2302 (0.2174) loss_zs_kd 0.0415 (0.0275) loss_oracle 0.5521 (0.5242) kd_loss 0.9430 (0.9480) acc 90.6250 (91.6797) gate/entropy 1.0041 (1.0047) gate/usage_max 0.5453 (0.5446) gate/usage_min 0.2218 (0.2222) gate/usage_std 0.1499 (0.1495) teacher/entropy 0.0270 (0.0407) teacher/usage_max 0.5710 (0.5782) teacher/usage_min 0.0016 (0.0082) teacher/usage_std 0.2418 (0.2437) nleep/row_max_mean 1552.9844 (1534.4854) nleep/row_max_std 48.5288 (53.6049) nleep/row_min_mean 1506.9196 (1491.5323) lr 7.0224e-05 eta 0:01:37
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [47/50] batch [20/167] time 0.174 (0.123) data 0.000 (0.014) loss 1.5858 (1.4695) teacher_loss 0.3757 (0.2367) loss_zs_kd 0.0179 (0.0270) loss_oracle 0.4864 (0.5187) kd_loss 0.9579 (0.9599) acc 87.5000 (90.4688) gate/entropy 1.0049 (1.0048) gate/usage_max 0.5444 (0.5444) gate/usage_min 0.2222 (0.2222) gate/usage_std 0.1493 (0.1493) teacher/entropy 0.0544 (0.0432) teacher/usage_max 0.5208 (0.5622) teacher/usage_min 0.0050 (0.0033) teacher/usage_std 0.2330 (0.2422) nleep/row_max_mean 1533.0791 (1531.4285) nleep/row_max_std 48.9311 (52.7798) nleep/row_min_mean 1488.3826 (1488.6796) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [40/167] time 0.189 (0.124) data 0.000 (0.007) loss 1.4887 (1.4531) teacher_loss 0.2153 (0.2178) loss_zs_kd 0.0387 (0.0272) loss_oracle 0.4922 (0.5164) kd_loss 1.0078 (0.9635) acc 87.5000 (91.4844) gate/entropy 1.0048 (1.0048) gate/usage_max 0.5444 (0.5445) gate/usage_min 0.2221 (0.2221) gate/usage_std 0.1493 (0.1494) teacher/entropy 0.0362 (0.0449) teacher/usage_max 0.5139 (0.5590) teacher/usage_min 0.0000 (0.0073) teacher/usage_std 0.2360 (0.2394) nleep/row_max_mean 1524.9451 (1532.4802) nleep/row_max_std 55.5878 (52.4314) nleep/row_min_mean 1485.8381 (1490.0310) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [60/167] time 0.105 (0.122) data 0.001 (0.005) loss 1.7402 (1.4607) teacher_loss 0.4982 (0.2228) loss_zs_kd 0.0279 (0.0269) loss_oracle 0.4875 (0.5143) kd_loss 0.9843 (0.9673) acc 78.1250 (91.4583) gate/entropy 1.0051 (1.0047) gate/usage_max 0.5441 (0.5445) gate/usage_min 0.2223 (0.2221) gate/usage_std 0.1491 (0.1494) teacher/entropy 0.0411 (0.0406) teacher/usage_max 0.5053 (0.5618) teacher/usage_min 0.0029 (0.0062) teacher/usage_std 0.2337 (0.2406) nleep/row_max_mean 1520.9224 (1531.3175) nleep/row_max_std 46.9195 (52.6568) nleep/row_min_mean 1477.9375 (1488.9422) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [80/167] time 0.082 (0.120) data 0.000 (0.004) loss 1.4478 (1.4499) teacher_loss 0.1747 (0.2136) loss_zs_kd 0.0259 (0.0265) loss_oracle 0.5232 (0.5172) kd_loss 0.9986 (0.9644) acc 90.6250 (91.8359) gate/entropy 1.0047 (1.0047) gate/usage_max 0.5445 (0.5445) gate/usage_min 0.2221 (0.2221) gate/usage_std 0.1494 (0.1494) teacher/entropy 0.0472 (0.0395) teacher/usage_max 0.4881 (0.5596) teacher/usage_min 0.0277 (0.0067) teacher/usage_std 0.2161 (0.2399) nleep/row_max_mean 1532.6709 (1532.3111) nleep/row_max_std 48.9315 (51.5634) nleep/row_min_mean 1488.9900 (1489.7857) lr 4.8943e-05 eta 0:01:10
epoch [47/50] batch [100/167] time 0.089 (0.116) data 0.000 (0.003) loss 1.3488 (1.4560) teacher_loss 0.1631 (0.2156) loss_zs_kd 0.0210 (0.0266) loss_oracle 0.4260 (0.5152) kd_loss 0.9622 (0.9696) acc 93.7500 (91.8125) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5446 (0.5445) gate/usage_min 0.2220 (0.2221) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0124 (0.0383) teacher/usage_max 0.5662 (0.5601) teacher/usage_min 0.0000 (0.0064) teacher/usage_std 0.2418 (0.2402) nleep/row_max_mean 1540.1665 (1532.3767) nleep/row_max_std 48.9363 (50.6413) nleep/row_min_mean 1497.0981 (1489.9636) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [120/167] time 0.104 (0.116) data 0.000 (0.003) loss 1.5379 (1.4601) teacher_loss 0.2756 (0.2204) loss_zs_kd 0.0325 (0.0267) loss_oracle 0.5344 (0.5170) kd_loss 0.9788 (0.9678) acc 87.5000 (91.5365) gate/entropy 1.0047 (1.0047) gate/usage_max 0.5445 (0.5446) gate/usage_min 0.2220 (0.2221) gate/usage_std 0.1494 (0.1494) teacher/entropy 0.0310 (0.0385) teacher/usage_max 0.5251 (0.5601) teacher/usage_min 0.0055 (0.0080) teacher/usage_std 0.2329 (0.2393) nleep/row_max_mean 1525.3477 (1532.6424) nleep/row_max_std 40.9522 (50.6532) nleep/row_min_mean 1486.1859 (1490.2768) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [140/167] time 0.072 (0.117) data 0.000 (0.002) loss 1.4355 (1.4614) teacher_loss 0.2740 (0.2188) loss_zs_kd 0.0294 (0.0264) loss_oracle 0.5493 (0.5185) kd_loss 0.8721 (0.9702) acc 90.6250 (91.6741) gate/entropy 1.0041 (1.0047) gate/usage_max 0.5452 (0.5446) gate/usage_min 0.2217 (0.2221) gate/usage_std 0.1499 (0.1494) teacher/entropy 0.0470 (0.0380) teacher/usage_max 0.6303 (0.5599) teacher/usage_min 0.0022 (0.0085) teacher/usage_std 0.2576 (0.2389) nleep/row_max_mean 1532.8228 (1532.9222) nleep/row_max_std 58.9158 (50.3670) nleep/row_min_mean 1490.9673 (1490.6566) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [160/167] time 0.163 (0.116) data 0.000 (0.002) loss 1.4996 (1.4676) teacher_loss 0.1127 (0.2219) loss_zs_kd 0.0116 (0.0263) loss_oracle 0.4891 (0.5183) kd_loss 1.1365 (0.9734) acc 96.8750 (91.4062) gate/entropy 1.0051 (1.0047) gate/usage_max 0.5441 (0.5446) gate/usage_min 0.2222 (0.2220) gate/usage_std 0.1491 (0.1494) teacher/entropy 0.0009 (0.0371) teacher/usage_max 0.6249 (0.5630) teacher/usage_min 0.0000 (0.0081) teacher/usage_std 0.2568 (0.2401) nleep/row_max_mean 1524.5947 (1533.2123) nleep/row_max_std 63.3738 (50.3055) nleep/row_min_mean 1486.5388 (1490.9047) lr 4.8943e-05 eta 0:00:58
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [48/50] batch [20/167] time 0.152 (0.166) data 0.000 (0.015) loss 1.5525 (1.5064) teacher_loss 0.1814 (0.2441) loss_zs_kd 0.0257 (0.0324) loss_oracle 0.5423 (0.5217) kd_loss 1.0871 (0.9852) acc 93.7500 (91.7188) gate/entropy 1.0046 (1.0046) gate/usage_max 0.5447 (0.5447) gate/usage_min 0.2219 (0.2219) gate/usage_std 0.1495 (0.1495) teacher/entropy 0.0275 (0.0341) teacher/usage_max 0.5996 (0.5705) teacher/usage_min 0.0001 (0.0055) teacher/usage_std 0.2493 (0.2412) nleep/row_max_mean 1534.4489 (1533.3540) nleep/row_max_std 58.6999 (58.4956) nleep/row_min_mean 1491.8386 (1490.7063) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [40/167] time 0.151 (0.159) data 0.000 (0.007) loss 1.6216 (1.4999) teacher_loss 0.3440 (0.2286) loss_zs_kd 0.0514 (0.0307) loss_oracle 0.5545 (0.5194) kd_loss 0.9746 (0.9962) acc 90.6250 (91.8750) gate/entropy 1.0052 (1.0047) gate/usage_max 0.5440 (0.5445) gate/usage_min 0.2222 (0.2220) gate/usage_std 0.1490 (0.1494) teacher/entropy 0.0285 (0.0333) teacher/usage_max 0.5321 (0.5621) teacher/usage_min 0.0134 (0.0062) teacher/usage_std 0.2284 (0.2393) nleep/row_max_mean 1528.0806 (1536.9373) nleep/row_max_std 60.4908 (56.4547) nleep/row_min_mean 1484.6219 (1493.2515) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [60/167] time 0.140 (0.157) data 0.001 (0.005) loss 1.3549 (1.4961) teacher_loss 0.1438 (0.2285) loss_zs_kd 0.0306 (0.0301) loss_oracle 0.5443 (0.5185) kd_loss 0.9236 (0.9933) acc 96.8750 (91.9271) gate/entropy 1.0044 (1.0047) gate/usage_max 0.5449 (0.5446) gate/usage_min 0.2218 (0.2220) gate/usage_std 0.1497 (0.1494) teacher/entropy 0.0015 (0.0370) teacher/usage_max 0.6248 (0.5627) teacher/usage_min 0.0000 (0.0094) teacher/usage_std 0.2568 (0.2375) nleep/row_max_mean 1538.3500 (1537.8668) nleep/row_max_std 60.4759 (54.2071) nleep/row_min_mean 1495.7028 (1494.3829) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [80/167] time 0.153 (0.156) data 0.000 (0.004) loss 1.5108 (1.4858) teacher_loss 0.3268 (0.2264) loss_zs_kd 0.0543 (0.0305) loss_oracle 0.4591 (0.5179) kd_loss 0.9273 (0.9852) acc 84.3750 (91.6797) gate/entropy 1.0048 (1.0047) gate/usage_max 0.5445 (0.5446) gate/usage_min 0.2220 (0.2220) gate/usage_std 0.1494 (0.1494) teacher/entropy 0.0425 (0.0383) teacher/usage_max 0.5728 (0.5638) teacher/usage_min 0.0000 (0.0110) teacher/usage_std 0.2431 (0.2371) nleep/row_max_mean 1528.0325 (1537.4302) nleep/row_max_std 47.5830 (53.7656) nleep/row_min_mean 1486.9613 (1493.8679) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [100/167] time 0.171 (0.156) data 0.000 (0.003) loss 1.6063 (1.4795) teacher_loss 0.2909 (0.2173) loss_zs_kd 0.0295 (0.0297) loss_oracle 0.5507 (0.5181) kd_loss 1.0253 (0.9883) acc 90.6250 (92.1250) gate/entropy 1.0054 (1.0047) gate/usage_max 0.5437 (0.5445) gate/usage_min 0.2223 (0.2220) gate/usage_std 0.1488 (0.1494) teacher/entropy 0.0683 (0.0385) teacher/usage_max 0.5698 (0.5646) teacher/usage_min 0.0041 (0.0103) teacher/usage_std 0.2401 (0.2380) nleep/row_max_mean 1519.2609 (1537.1237) nleep/row_max_std 53.5316 (52.8196) nleep/row_min_mean 1477.3574 (1493.5979) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [120/167] time 0.157 (0.155) data 0.000 (0.003) loss 1.4374 (1.4783) teacher_loss 0.2643 (0.2195) loss_zs_kd 0.0349 (0.0290) loss_oracle 0.5075 (0.5169) kd_loss 0.9019 (0.9858) acc 93.7500 (92.0833) gate/entropy 1.0045 (1.0047) gate/usage_max 0.5448 (0.5445) gate/usage_min 0.2218 (0.2220) gate/usage_std 0.1496 (0.1494) teacher/entropy 0.0452 (0.0369) teacher/usage_max 0.6003 (0.5702) teacher/usage_min 0.0004 (0.0092) teacher/usage_std 0.2493 (0.2401) nleep/row_max_mean 1530.7488 (1536.9967) nleep/row_max_std 51.6463 (52.0491) nleep/row_min_mean 1487.2380 (1493.3946) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [140/167] time 0.105 (0.150) data 0.000 (0.002) loss 1.4413 (1.4752) teacher_loss 0.2613 (0.2151) loss_zs_kd 0.0412 (0.0287) loss_oracle 0.5174 (0.5190) kd_loss 0.9007 (0.9862) acc 93.7500 (92.2545) gate/entropy 1.0043 (1.0047) gate/usage_max 0.5450 (0.5445) gate/usage_min 0.2217 (0.2220) gate/usage_std 0.1498 (0.1494) teacher/entropy 0.0375 (0.0358) teacher/usage_max 0.6079 (0.5691) teacher/usage_min 0.0000 (0.0082) teacher/usage_std 0.2516 (0.2404) nleep/row_max_mean 1540.0625 (1537.4549) nleep/row_max_std 54.2323 (51.2674) nleep/row_min_mean 1492.6897 (1493.7121) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [160/167] time 0.165 (0.146) data 0.000 (0.002) loss 1.4602 (1.4824) teacher_loss 0.1271 (0.2196) loss_zs_kd 0.0325 (0.0287) loss_oracle 0.6098 (0.5184) kd_loss 1.0120 (0.9893) acc 93.7500 (91.8555) gate/entropy 1.0059 (1.0047) gate/usage_max 0.5431 (0.5446) gate/usage_min 0.2226 (0.2219) gate/usage_std 0.1484 (0.1494) teacher/entropy 0.0293 (0.0358) teacher/usage_max 0.5151 (0.5705) teacher/usage_min 0.0002 (0.0077) teacher/usage_std 0.2359 (0.2412) nleep/row_max_mean 1516.7678 (1537.5958) nleep/row_max_std 49.0223 (50.4280) nleep/row_min_mean 1476.4316 (1493.8456) lr 3.1417e-05 eta 0:00:49
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [49/50] batch [20/167] time 0.073 (0.098) data 0.000 (0.010) loss 1.5920 (1.4959) teacher_loss 0.3413 (0.1857) loss_zs_kd 0.0300 (0.0258) loss_oracle 0.4520 (0.5280) kd_loss 1.0097 (1.0333) acc 84.3750 (93.4375) gate/entropy 1.0043 (1.0049) gate/usage_max 0.5451 (0.5443) gate/usage_min 0.2217 (0.2220) gate/usage_std 0.1498 (0.1493) teacher/entropy 0.0255 (0.0268) teacher/usage_max 0.5050 (0.5483) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2357 (0.2401) nleep/row_max_mean 1542.1462 (1535.5741) nleep/row_max_std 52.2647 (48.2780) nleep/row_min_mean 1497.9459 (1491.4036) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [40/167] time 0.073 (0.105) data 0.000 (0.005) loss 1.4268 (1.4928) teacher_loss 0.2140 (0.2031) loss_zs_kd 0.0333 (0.0260) loss_oracle 0.5643 (0.5188) kd_loss 0.9140 (1.0172) acc 93.7500 (92.7344) gate/entropy 1.0050 (1.0047) gate/usage_max 0.5442 (0.5445) gate/usage_min 0.2220 (0.2219) gate/usage_std 0.1492 (0.1494) teacher/entropy 0.0122 (0.0275) teacher/usage_max 0.6220 (0.5606) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2559 (0.2415) nleep/row_max_mean 1530.4159 (1535.9850) nleep/row_max_std 53.6635 (47.8993) nleep/row_min_mean 1485.7202 (1492.2078) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [60/167] time 0.078 (0.108) data 0.001 (0.003) loss 1.5723 (1.5021) teacher_loss 0.2540 (0.2157) loss_zs_kd 0.0463 (0.0267) loss_oracle 0.5849 (0.5210) kd_loss 1.0028 (1.0126) acc 84.3750 (92.1354) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5447 (0.5445) gate/usage_min 0.2218 (0.2219) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0400 (0.0292) teacher/usage_max 0.4882 (0.5652) teacher/usage_min 0.0249 (0.0063) teacher/usage_std 0.2181 (0.2418) nleep/row_max_mean 1539.4246 (1535.1950) nleep/row_max_std 48.1176 (48.9645) nleep/row_min_mean 1493.5952 (1491.2066) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [80/167] time 0.162 (0.110) data 0.000 (0.003) loss 1.6127 (1.4982) teacher_loss 0.2945 (0.2124) loss_zs_kd 0.0345 (0.0264) loss_oracle 0.5213 (0.5208) kd_loss 1.0402 (1.0123) acc 93.7500 (92.4219) gate/entropy 1.0042 (1.0047) gate/usage_max 0.5451 (0.5445) gate/usage_min 0.2216 (0.2219) gate/usage_std 0.1498 (0.1494) teacher/entropy 0.0436 (0.0303) teacher/usage_max 0.5303 (0.5629) teacher/usage_min 0.0311 (0.0078) teacher/usage_std 0.2170 (0.2401) nleep/row_max_mean 1537.3910 (1535.2955) nleep/row_max_std 51.8703 (49.7742) nleep/row_min_mean 1495.6907 (1491.7330) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [100/167] time 0.178 (0.120) data 0.000 (0.002) loss 1.3834 (1.5052) teacher_loss 0.2177 (0.2248) loss_zs_kd 0.0255 (0.0273) loss_oracle 0.5120 (0.5194) kd_loss 0.8969 (1.0070) acc 93.7500 (91.5938) gate/entropy 1.0045 (1.0047) gate/usage_max 0.5448 (0.5445) gate/usage_min 0.2218 (0.2219) gate/usage_std 0.1496 (0.1494) teacher/entropy 0.0775 (0.0308) teacher/usage_max 0.5671 (0.5654) teacher/usage_min 0.0113 (0.0078) teacher/usage_std 0.2353 (0.2404) nleep/row_max_mean 1546.7007 (1536.0397) nleep/row_max_std 56.2792 (50.2757) nleep/row_min_mean 1502.2804 (1492.5761) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [120/167] time 0.165 (0.125) data 0.000 (0.002) loss 1.3931 (1.5066) teacher_loss 0.1804 (0.2246) loss_zs_kd 0.0282 (0.0275) loss_oracle 0.4794 (0.5183) kd_loss 0.9589 (1.0091) acc 93.7500 (91.5365) gate/entropy 1.0040 (1.0047) gate/usage_max 0.5453 (0.5445) gate/usage_min 0.2215 (0.2219) gate/usage_std 0.1500 (0.1494) teacher/entropy 0.0236 (0.0303) teacher/usage_max 0.5563 (0.5636) teacher/usage_min 0.0008 (0.0080) teacher/usage_std 0.2397 (0.2398) nleep/row_max_mean 1547.0784 (1536.3053) nleep/row_max_std 44.2736 (50.4089) nleep/row_min_mean 1506.2302 (1492.7773) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [140/167] time 0.156 (0.129) data 0.000 (0.002) loss 1.5040 (1.5046) teacher_loss 0.2145 (0.2242) loss_zs_kd 0.0312 (0.0273) loss_oracle 0.5164 (0.5192) kd_loss 1.0157 (1.0072) acc 93.7500 (91.5402) gate/entropy 1.0056 (1.0047) gate/usage_max 0.5435 (0.5445) gate/usage_min 0.2223 (0.2219) gate/usage_std 0.1487 (0.1494) teacher/entropy 0.0449 (0.0310) teacher/usage_max 0.5365 (0.5609) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.2376 (0.2397) nleep/row_max_mean 1522.5093 (1535.7387) nleep/row_max_std 46.9024 (50.6323) nleep/row_min_mean 1476.0317 (1492.1049) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [160/167] time 0.136 (0.132) data 0.000 (0.001) loss 1.5079 (1.5084) teacher_loss 0.2390 (0.2281) loss_zs_kd 0.0458 (0.0268) loss_oracle 0.5232 (0.5184) kd_loss 0.9844 (1.0077) acc 90.6250 (91.3477) gate/entropy 1.0052 (1.0047) gate/usage_max 0.5440 (0.5445) gate/usage_min 0.2221 (0.2219) gate/usage_std 0.1490 (0.1494) teacher/entropy 0.0267 (0.0310) teacher/usage_max 0.5191 (0.5639) teacher/usage_min 0.0111 (0.0070) teacher/usage_std 0.2288 (0.2405) nleep/row_max_mean 1525.4727 (1535.2198) nleep/row_max_std 57.5207 (50.9740) nleep/row_min_mean 1483.1968 (1491.6207) lr 1.7713e-05 eta 0:00:22
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
epoch [50/50] batch [20/167] time 0.157 (0.171) data 0.000 (0.017) loss 1.6256 (1.5282) teacher_loss 0.3395 (0.2123) loss_zs_kd 0.0357 (0.0282) loss_oracle 0.4862 (0.5116) kd_loss 1.0252 (1.0459) acc 84.3750 (91.5625) gate/entropy 1.0042 (1.0047) gate/usage_max 0.5451 (0.5445) gate/usage_min 0.2216 (0.2219) gate/usage_std 0.1498 (0.1494) teacher/entropy 0.0235 (0.0295) teacher/usage_max 0.4863 (0.5779) teacher/usage_min 0.0313 (0.0124) teacher/usage_std 0.2136 (0.2405) nleep/row_max_mean 1533.4082 (1529.6736) nleep/row_max_std 55.9538 (52.6609) nleep/row_min_mean 1491.9697 (1487.6136) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [40/167] time 0.139 (0.146) data 0.001 (0.009) loss 1.5311 (1.4995) teacher_loss 0.1762 (0.2038) loss_zs_kd 0.0380 (0.0277) loss_oracle 0.5770 (0.5109) kd_loss 1.0474 (1.0263) acc 93.7500 (92.2656) gate/entropy 1.0048 (1.0047) gate/usage_max 0.5445 (0.5445) gate/usage_min 0.2219 (0.2219) gate/usage_std 0.1494 (0.1494) teacher/entropy 0.0114 (0.0319) teacher/usage_max 0.5028 (0.5680) teacher/usage_min 0.0308 (0.0088) teacher/usage_std 0.2144 (0.2410) nleep/row_max_mean 1536.5068 (1532.8048) nleep/row_max_std 50.8377 (53.5548) nleep/row_min_mean 1493.1842 (1489.8910) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [60/167] time 0.167 (0.142) data 0.000 (0.006) loss 1.6365 (1.4811) teacher_loss 0.2112 (0.1921) loss_zs_kd 0.0183 (0.0256) loss_oracle 0.5776 (0.5164) kd_loss 1.1273 (1.0180) acc 87.5000 (92.2396) gate/entropy 1.0052 (1.0048) gate/usage_max 0.5439 (0.5445) gate/usage_min 0.2221 (0.2219) gate/usage_std 0.1490 (0.1494) teacher/entropy 0.0237 (0.0313) teacher/usage_max 0.6450 (0.5672) teacher/usage_min 0.0000 (0.0080) teacher/usage_std 0.2638 (0.2409) nleep/row_max_mean 1535.0575 (1533.5686) nleep/row_max_std 50.7796 (54.1654) nleep/row_min_mean 1490.7712 (1489.9631) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [80/167] time 0.088 (0.135) data 0.000 (0.004) loss 1.4361 (1.4889) teacher_loss 0.1760 (0.1933) loss_zs_kd 0.0091 (0.0244) loss_oracle 0.5000 (0.5234) kd_loss 1.0056 (1.0217) acc 93.7500 (92.0703) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5447 (0.5445) gate/usage_min 0.2218 (0.2219) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0305 (0.0309) teacher/usage_max 0.5076 (0.5702) teacher/usage_min 0.0000 (0.0077) teacher/usage_std 0.2358 (0.2413) nleep/row_max_mean 1541.7424 (1534.8781) nleep/row_max_std 45.6931 (53.2933) nleep/row_min_mean 1497.9447 (1491.1451) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [100/167] time 0.183 (0.133) data 0.000 (0.004) loss 1.5127 (1.4904) teacher_loss 0.1789 (0.2002) loss_zs_kd 0.0349 (0.0251) loss_oracle 0.6264 (0.5212) kd_loss 1.0031 (1.0170) acc 93.7500 (91.8438) gate/entropy 1.0052 (1.0047) gate/usage_max 0.5439 (0.5445) gate/usage_min 0.2221 (0.2219) gate/usage_std 0.1490 (0.1494) teacher/entropy 0.0303 (0.0307) teacher/usage_max 0.4964 (0.5644) teacher/usage_min 0.0074 (0.0068) teacher/usage_std 0.2305 (0.2408) nleep/row_max_mean 1522.8501 (1535.6369) nleep/row_max_std 50.5476 (53.0091) nleep/row_min_mean 1476.1417 (1491.6075) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [120/167] time 0.092 (0.128) data 0.000 (0.003) loss 1.3848 (1.4896) teacher_loss 0.1030 (0.1977) loss_zs_kd 0.0357 (0.0251) loss_oracle 0.5272 (0.5170) kd_loss 1.0003 (1.0208) acc 96.8750 (92.0833) gate/entropy 1.0052 (1.0047) gate/usage_max 0.5440 (0.5445) gate/usage_min 0.2221 (0.2219) gate/usage_std 0.1490 (0.1494) teacher/entropy 0.0045 (0.0300) teacher/usage_max 0.5309 (0.5666) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.2370 (0.2414) nleep/row_max_mean 1528.6708 (1535.0540) nleep/row_max_std 53.6310 (52.5470) nleep/row_min_mean 1486.1553 (1491.2021) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [140/167] time 0.172 (0.127) data 0.000 (0.003) loss 1.4166 (1.4859) teacher_loss 0.2349 (0.2002) loss_zs_kd 0.0327 (0.0254) loss_oracle 0.5309 (0.5170) kd_loss 0.8999 (1.0145) acc 87.5000 (92.0982) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5447 (0.5445) gate/usage_min 0.2217 (0.2219) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0489 (0.0304) teacher/usage_max 0.5967 (0.5706) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2486 (0.2428) nleep/row_max_mean 1539.3752 (1535.0959) nleep/row_max_std 44.9426 (52.4180) nleep/row_min_mean 1495.5449 (1491.2141) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/167] time 0.064 (0.126) data 0.000 (0.002) loss 1.4773 (1.4849) teacher_loss 0.2292 (0.1997) loss_zs_kd 0.0279 (0.0258) loss_oracle 0.5031 (0.5171) kd_loss 0.9826 (1.0137) acc 90.6250 (92.2266) gate/entropy 1.0046 (1.0047) gate/usage_max 0.5447 (0.5445) gate/usage_min 0.2218 (0.2219) gate/usage_std 0.1495 (0.1494) teacher/entropy 0.0499 (0.0301) teacher/usage_max 0.5018 (0.5713) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.2357 (0.2430) nleep/row_max_mean 1522.5820 (1534.2949) nleep/row_max_std 50.6834 (51.7119) nleep/row_min_mean 1481.3218 (1490.5276) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.3%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:07

Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------
Dataset    SPG_PACS
Source     ['cartoon', 'photo', 'sketch']
Target     ['art_painting']
# classes  7
# train_x  5,557
# val      2,385
# test     2,048
---------  ------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/173] time 0.081 (0.133) data 0.000 (0.025) loss 1.0801 (1.1000) teacher_loss 0.5993 (0.5188) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.4807 (0.5812) acc 78.1250 (80.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.6167 (0.5182) teacher/usage_max 0.3941 (0.3967) teacher/usage_min 0.2892 (0.2763) teacher/usage_std 0.0444 (0.0505) nleep/row_max_mean 1575.7095 (1584.8381) nleep/row_max_std 131.7358 (130.7091) nleep/row_min_mean 1572.2034 (1579.4083) lr 1.0000e-05 eta 0:19:06
epoch [1/50] batch [40/173] time 0.153 (0.123) data 0.000 (0.013) loss 0.5914 (0.9872) teacher_loss 0.1842 (0.4489) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0012 (0.0002) kd_loss 0.4065 (0.5382) acc 96.8750 (83.5156) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.6932 (0.5613) teacher/usage_max 0.3822 (0.3958) teacher/usage_min 0.2834 (0.2784) teacher/usage_std 0.0403 (0.0503) nleep/row_max_mean 1599.1405 (1585.5451) nleep/row_max_std 106.1244 (126.1315) nleep/row_min_mean 1596.0579 (1580.8747) lr 1.0000e-05 eta 0:17:42
epoch [1/50] batch [60/173] time 0.087 (0.115) data 0.000 (0.008) loss 0.8169 (0.9537) teacher_loss 0.5063 (0.4576) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0026 (0.0008) kd_loss 0.3093 (0.4957) acc 78.1250 (83.3854) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.7902 (0.6036) teacher/usage_max 0.3822 (0.3916) teacher/usage_min 0.2903 (0.2793) teacher/usage_std 0.0378 (0.0480) nleep/row_max_mean 1594.2424 (1590.4994) nleep/row_max_std 115.4460 (118.5281) nleep/row_min_mean 1592.0040 (1586.3819) lr 1.0000e-05 eta 0:16:25
epoch [1/50] batch [80/173] time 0.205 (0.114) data 0.000 (0.006) loss 0.6986 (0.9220) teacher_loss 0.3105 (0.4544) loss_zs_kd 0.0010 (0.0001) loss_oracle 0.0048 (0.0016) kd_loss 0.3852 (0.4668) acc 90.6250 (83.6328) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7140 (0.6323) teacher/usage_max 0.4183 (0.3936) teacher/usage_min 0.2860 (0.2788) teacher/usage_std 0.0602 (0.0492) nleep/row_max_mean 1571.3782 (1592.0608) nleep/row_max_std 134.2293 (112.8317) nleep/row_min_mean 1569.0378 (1588.3350) lr 1.0000e-05 eta 0:16:13
epoch [1/50] batch [100/173] time 0.184 (0.115) data 0.000 (0.005) loss 0.6923 (0.8882) teacher_loss 0.3432 (0.4485) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0113 (0.0029) kd_loss 0.3431 (0.4382) acc 90.6250 (83.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7555 (0.6608) teacher/usage_max 0.3483 (0.3967) teacher/usage_min 0.3237 (0.2758) teacher/usage_std 0.0107 (0.0519) nleep/row_max_mean 1622.2839 (1592.9057) nleep/row_max_std 94.1839 (110.6497) nleep/row_min_mean 1620.1368 (1589.4930) lr 1.0000e-05 eta 0:16:23
epoch [1/50] batch [120/173] time 0.136 (0.118) data 0.000 (0.004) loss 0.7127 (0.8674) teacher_loss 0.3825 (0.4456) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0166 (0.0045) kd_loss 0.3215 (0.4194) acc 84.3750 (83.8021) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7754 (0.6794) teacher/usage_max 0.4669 (0.4045) teacher/usage_min 0.1685 (0.2679) teacher/usage_std 0.1238 (0.0585) nleep/row_max_mean 1621.5155 (1594.1059) nleep/row_max_std 67.4727 (106.5109) nleep/row_min_mean 1619.2562 (1590.9038) lr 1.0000e-05 eta 0:16:42
epoch [1/50] batch [140/173] time 0.079 (0.118) data 0.000 (0.004) loss 0.7363 (0.8431) teacher_loss 0.4073 (0.4366) loss_zs_kd 0.0000 (0.0003) loss_oracle 0.0123 (0.0062) kd_loss 0.3228 (0.4032) acc 84.3750 (84.1741) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7744 (0.6955) teacher/usage_max 0.4708 (0.4092) teacher/usage_min 0.1697 (0.2619) teacher/usage_std 0.1243 (0.0629) nleep/row_max_mean 1605.6731 (1594.4520) nleep/row_max_std 100.7270 (104.2190) nleep/row_min_mean 1603.4775 (1591.4164) lr 1.0000e-05 eta 0:16:41
epoch [1/50] batch [160/173] time 0.076 (0.117) data 0.000 (0.003) loss 0.6250 (0.8318) teacher_loss 0.3329 (0.4356) loss_zs_kd 0.0010 (0.0004) loss_oracle 0.0154 (0.0078) kd_loss 0.2839 (0.3921) acc 93.7500 (84.2578) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8134 (0.7064) teacher/usage_max 0.4839 (0.4173) teacher/usage_min 0.1701 (0.2526) teacher/usage_std 0.1284 (0.0701) nleep/row_max_mean 1596.9402 (1594.9193) nleep/row_max_std 100.2101 (101.8093) nleep/row_min_mean 1594.7709 (1591.9825) lr 1.0000e-05 eta 0:16:35
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,265
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.0%, epoch: 1 *******
******* Domain a best val test acc: 97.7%, epoch: 1 *******
******* Domain a best test acc:     97.7%, epoch: 1 *******
epoch [2/50] batch [20/173] time 0.152 (0.169) data 0.000 (0.013) loss 0.8270 (0.8698) teacher_loss 0.3182 (0.3943) loss_zs_kd 0.0074 (0.0045) loss_oracle 0.2352 (0.2486) kd_loss 0.3876 (0.3490) acc 93.7500 (87.5000) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3284 (0.3292) gate/usage_std 0.0041 (0.0038) teacher/entropy 0.7067 (0.7466) teacher/usage_max 0.5232 (0.4924) teacher/usage_min 0.0885 (0.1243) teacher/usage_std 0.1817 (0.1572) nleep/row_max_mean 1601.4160 (1597.6287) nleep/row_max_std 81.6847 (81.1024) nleep/row_min_mean 1596.2087 (1594.0980) lr 2.0000e-03 eta 0:23:47
epoch [2/50] batch [40/173] time 0.141 (0.158) data 0.000 (0.007) loss 1.1961 (0.9728) teacher_loss 0.3506 (0.3663) loss_zs_kd 0.0069 (0.0057) loss_oracle 0.3204 (0.3002) kd_loss 0.6818 (0.4536) acc 87.5000 (88.2812) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3388 (0.3385) gate/usage_min 0.3262 (0.3283) gate/usage_std 0.0053 (0.0042) teacher/entropy 0.4094 (0.6399) teacher/usage_max 0.7141 (0.5248) teacher/usage_min 0.0225 (0.0798) teacher/usage_std 0.2866 (0.1908) nleep/row_max_mean 1590.6541 (1595.0731) nleep/row_max_std 75.7462 (79.3402) nleep/row_min_mean 1581.7019 (1589.7586) lr 2.0000e-03 eta 0:22:13
epoch [2/50] batch [60/173] time 0.154 (0.156) data 0.000 (0.005) loss 1.4088 (1.0672) teacher_loss 0.3964 (0.3645) loss_zs_kd 0.0054 (0.0070) loss_oracle 0.3610 (0.3353) kd_loss 0.8292 (0.5315) acc 90.6250 (88.2812) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3384 (0.3385) gate/usage_min 0.3237 (0.3271) gate/usage_std 0.0068 (0.0048) teacher/entropy 0.2573 (0.5602) teacher/usage_max 0.7589 (0.5677) teacher/usage_min 0.0554 (0.0646) teacher/usage_std 0.3056 (0.2130) nleep/row_max_mean 1611.1785 (1596.4515) nleep/row_max_std 77.9765 (77.4418) nleep/row_min_mean 1601.9752 (1589.8626) lr 2.0000e-03 eta 0:21:54
epoch [2/50] batch [80/173] time 0.144 (0.155) data 0.000 (0.003) loss 1.5724 (1.1424) teacher_loss 0.4270 (0.3668) loss_zs_kd 0.0154 (0.0080) loss_oracle 0.4203 (0.3421) kd_loss 0.9275 (0.6005) acc 81.2500 (87.8516) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3422 (0.3389) gate/usage_min 0.3213 (0.3260) gate/usage_std 0.0088 (0.0056) teacher/entropy 0.1487 (0.4888) teacher/usage_max 0.8369 (0.6127) teacher/usage_min 0.0207 (0.0578) teacher/usage_std 0.3595 (0.2355) nleep/row_max_mean 1608.7534 (1599.2560) nleep/row_max_std 47.7350 (74.7999) nleep/row_min_mean 1596.4281 (1591.6305) lr 2.0000e-03 eta 0:21:38
epoch [2/50] batch [100/173] time 0.082 (0.143) data 0.000 (0.003) loss 1.1332 (1.1852) teacher_loss 0.0711 (0.3606) loss_zs_kd 0.0035 (0.0083) loss_oracle 0.3416 (0.3491) kd_loss 0.8895 (0.6459) acc 100.0000 (87.9375) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3465 (0.3400) gate/usage_min 0.3188 (0.3248) gate/usage_std 0.0114 (0.0065) teacher/entropy 0.1808 (0.4406) teacher/usage_max 0.7178 (0.6324) teacher/usage_min 0.0114 (0.0548) teacher/usage_std 0.2917 (0.2450) nleep/row_max_mean 1601.8130 (1599.5902) nleep/row_max_std 47.1568 (73.8727) nleep/row_min_mean 1588.8616 (1591.0129) lr 2.0000e-03 eta 0:19:57
epoch [2/50] batch [120/173] time 0.081 (0.138) data 0.000 (0.002) loss 1.4939 (1.2163) teacher_loss 0.4710 (0.3593) loss_zs_kd 0.0095 (0.0090) loss_oracle 0.3938 (0.3560) kd_loss 0.8213 (0.6745) acc 84.3750 (87.6042) gate/entropy 1.0977 (1.0983) gate/usage_max 0.3507 (0.3415) gate/usage_min 0.3162 (0.3235) gate/usage_std 0.0141 (0.0075) teacher/entropy 0.2408 (0.4092) teacher/usage_max 0.7513 (0.6444) teacher/usage_min 0.0248 (0.0564) teacher/usage_std 0.3065 (0.2495) nleep/row_max_mean 1606.5825 (1598.7305) nleep/row_max_std 65.2505 (73.7822) nleep/row_min_mean 1594.8396 (1589.4675) lr 2.0000e-03 eta 0:19:09
epoch [2/50] batch [140/173] time 0.070 (0.134) data 0.000 (0.002) loss 1.3501 (1.2380) teacher_loss 0.3786 (0.3555) loss_zs_kd 0.0173 (0.0098) loss_oracle 0.3227 (0.3603) kd_loss 0.8015 (0.6974) acc 90.6250 (87.7009) gate/entropy 1.0974 (1.0982) gate/usage_max 0.3545 (0.3431) gate/usage_min 0.3137 (0.3223) gate/usage_std 0.0167 (0.0087) teacher/entropy 0.2562 (0.3837) teacher/usage_max 0.7336 (0.6470) teacher/usage_min 0.0516 (0.0578) teacher/usage_std 0.2908 (0.2497) nleep/row_max_mean 1598.2255 (1599.3479) nleep/row_max_std 79.6939 (72.3555) nleep/row_min_mean 1585.7866 (1589.4625) lr 2.0000e-03 eta 0:18:34
epoch [2/50] batch [160/173] time 0.089 (0.130) data 0.000 (0.002) loss 1.3683 (1.2543) teacher_loss 0.3061 (0.3513) loss_zs_kd 0.0089 (0.0102) loss_oracle 0.4035 (0.3624) kd_loss 0.8560 (0.7167) acc 87.5000 (87.7344) gate/entropy 1.0970 (1.0981) gate/usage_max 0.3580 (0.3447) gate/usage_min 0.3110 (0.3211) gate/usage_std 0.0192 (0.0098) teacher/entropy 0.2091 (0.3619) teacher/usage_max 0.5873 (0.6470) teacher/usage_min 0.0889 (0.0585) teacher/usage_std 0.2036 (0.2489) nleep/row_max_mean 1615.9684 (1600.3682) nleep/row_max_std 41.8663 (70.9547) nleep/row_min_mean 1600.2913 (1589.8716) lr 2.0000e-03 eta 0:18:04
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,280
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.6%, epoch: 2 *******
******* Domain a best val test acc: 97.7%, epoch: 2 *******
******* Domain a best test acc:     97.7%, epoch: 2 *******
epoch [3/50] batch [20/173] time 0.176 (0.135) data 0.000 (0.016) loss 1.4191 (1.4494) teacher_loss 0.3841 (0.3820) loss_zs_kd 0.0091 (0.0128) loss_oracle 0.3858 (0.4562) kd_loss 0.8375 (0.8329) acc 81.2500 (84.5312) gate/entropy 1.0962 (1.0964) gate/usage_max 0.3629 (0.3616) gate/usage_min 0.3068 (0.3079) gate/usage_std 0.0230 (0.0220) teacher/entropy 0.2227 (0.2300) teacher/usage_max 0.5865 (0.5695) teacher/usage_min 0.1010 (0.0973) teacher/usage_std 0.1988 (0.1967) nleep/row_max_mean 1580.0221 (1604.2716) nleep/row_max_std 77.6879 (61.0064) nleep/row_min_mean 1567.3318 (1589.9827) lr 1.9980e-03 eta 0:18:39
epoch [3/50] batch [40/173] time 0.144 (0.134) data 0.000 (0.008) loss 1.4647 (1.4085) teacher_loss 0.2647 (0.3394) loss_zs_kd 0.0204 (0.0142) loss_oracle 0.4969 (0.4510) kd_loss 0.9413 (0.8366) acc 90.6250 (87.5000) gate/entropy 1.0958 (1.0962) gate/usage_max 0.3655 (0.3629) gate/usage_min 0.3046 (0.3068) gate/usage_std 0.0250 (0.0230) teacher/entropy 0.1301 (0.2286) teacher/usage_max 0.4722 (0.5480) teacher/usage_min 0.1367 (0.1139) teacher/usage_std 0.1429 (0.1818) nleep/row_max_mean 1620.1957 (1604.6743) nleep/row_max_std 55.9481 (61.3971) nleep/row_min_mean 1603.9753 (1590.0872) lr 1.9980e-03 eta 0:18:26
epoch [3/50] batch [60/173] time 0.073 (0.125) data 0.001 (0.006) loss 1.3988 (1.4036) teacher_loss 0.3322 (0.3357) loss_zs_kd 0.0140 (0.0134) loss_oracle 0.3617 (0.4464) kd_loss 0.8787 (0.8380) acc 90.6250 (87.6562) gate/entropy 1.0955 (1.0960) gate/usage_max 0.3676 (0.3641) gate/usage_min 0.3031 (0.3058) gate/usage_std 0.0265 (0.0239) teacher/entropy 0.2132 (0.2288) teacher/usage_max 0.3691 (0.5369) teacher/usage_min 0.2630 (0.1313) teacher/usage_std 0.0498 (0.1706) nleep/row_max_mean 1609.7419 (1601.6883) nleep/row_max_std 52.6045 (62.3223) nleep/row_min_mean 1595.7140 (1587.3254) lr 1.9980e-03 eta 0:17:09
epoch [3/50] batch [80/173] time 0.143 (0.128) data 0.000 (0.004) loss 1.3026 (1.4007) teacher_loss 0.2239 (0.3336) loss_zs_kd 0.0034 (0.0135) loss_oracle 0.4611 (0.4426) kd_loss 0.8465 (0.8390) acc 93.7500 (87.7344) gate/entropy 1.0952 (1.0959) gate/usage_max 0.3687 (0.3652) gate/usage_min 0.3018 (0.3050) gate/usage_std 0.0274 (0.0247) teacher/entropy 0.2450 (0.2303) teacher/usage_max 0.4273 (0.5180) teacher/usage_min 0.2316 (0.1454) teacher/usage_std 0.0801 (0.1571) nleep/row_max_mean 1578.2131 (1601.0771) nleep/row_max_std 76.1049 (62.8105) nleep/row_min_mean 1562.9656 (1586.7685) lr 1.9980e-03 eta 0:17:30
epoch [3/50] batch [100/173] time 0.149 (0.133) data 0.000 (0.003) loss 1.4366 (1.3982) teacher_loss 0.3130 (0.3243) loss_zs_kd 0.0174 (0.0134) loss_oracle 0.4908 (0.4511) kd_loss 0.8695 (0.8417) acc 87.5000 (88.0312) gate/entropy 1.0950 (1.0957) gate/usage_max 0.3699 (0.3660) gate/usage_min 0.3005 (0.3042) gate/usage_std 0.0284 (0.0254) teacher/entropy 0.2168 (0.2296) teacher/usage_max 0.3874 (0.5056) teacher/usage_min 0.2300 (0.1579) teacher/usage_std 0.0731 (0.1466) nleep/row_max_mean 1584.7729 (1598.7678) nleep/row_max_std 72.9678 (63.4433) nleep/row_min_mean 1568.3680 (1584.2901) lr 1.9980e-03 eta 0:18:07
epoch [3/50] batch [120/173] time 0.173 (0.137) data 0.000 (0.003) loss 1.4213 (1.4098) teacher_loss 0.2703 (0.3248) loss_zs_kd 0.0079 (0.0138) loss_oracle 0.5476 (0.4584) kd_loss 0.8733 (0.8490) acc 90.6250 (87.8906) gate/entropy 1.0947 (1.0956) gate/usage_max 0.3715 (0.3668) gate/usage_min 0.2997 (0.3035) gate/usage_std 0.0295 (0.0260) teacher/entropy 0.2067 (0.2230) teacher/usage_max 0.4312 (0.5022) teacher/usage_min 0.2240 (0.1663) teacher/usage_std 0.0850 (0.1423) nleep/row_max_mean 1585.7920 (1597.0523) nleep/row_max_std 72.6207 (62.7643) nleep/row_min_mean 1571.3981 (1582.4255) lr 1.9980e-03 eta 0:18:43
epoch [3/50] batch [140/173] time 0.158 (0.138) data 0.000 (0.002) loss 1.3049 (1.4130) teacher_loss 0.1665 (0.3158) loss_zs_kd 0.0159 (0.0140) loss_oracle 0.4880 (0.4681) kd_loss 0.8865 (0.8562) acc 96.8750 (88.2143) gate/entropy 1.0945 (1.0954) gate/usage_max 0.3730 (0.3676) gate/usage_min 0.2994 (0.3029) gate/usage_std 0.0303 (0.0265) teacher/entropy 0.1932 (0.2167) teacher/usage_max 0.4608 (0.4983) teacher/usage_min 0.2641 (0.1725) teacher/usage_std 0.0902 (0.1380) nleep/row_max_mean 1595.4983 (1594.8797) nleep/row_max_std 55.4433 (63.1995) nleep/row_min_mean 1581.9314 (1580.1959) lr 1.9980e-03 eta 0:18:42
epoch [3/50] batch [160/173] time 0.163 (0.139) data 0.000 (0.002) loss 1.3616 (1.4239) teacher_loss 0.1319 (0.3145) loss_zs_kd 0.0129 (0.0144) loss_oracle 0.5522 (0.4775) kd_loss 0.9471 (0.8634) acc 93.7500 (88.1836) gate/entropy 1.0942 (1.0953) gate/usage_max 0.3746 (0.3683) gate/usage_min 0.2989 (0.3025) gate/usage_std 0.0313 (0.0271) teacher/entropy 0.1311 (0.2100) teacher/usage_max 0.4267 (0.4952) teacher/usage_min 0.1679 (0.1760) teacher/usage_std 0.1173 (0.1354) nleep/row_max_mean 1584.4154 (1593.4665) nleep/row_max_std 56.7048 (63.2776) nleep/row_min_mean 1564.8103 (1578.4818) lr 1.9980e-03 eta 0:18:51
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,277
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.6%, epoch: 2 *******
******* Domain a best val test acc: 97.7%, epoch: 2 *******
******* Domain a best test acc:     97.8%, epoch: 3 *******
epoch [4/50] batch [20/173] time 0.151 (0.150) data 0.000 (0.019) loss 1.5192 (1.5066) teacher_loss 0.2820 (0.2974) loss_zs_kd 0.0046 (0.0156) loss_oracle 0.5286 (0.5486) kd_loss 0.9706 (0.9271) acc 93.7500 (89.3750) gate/entropy 1.0937 (1.0939) gate/usage_max 0.3777 (0.3765) gate/usage_min 0.2974 (0.2981) gate/usage_std 0.0333 (0.0325) teacher/entropy 0.0819 (0.1400) teacher/usage_max 0.5366 (0.5090) teacher/usage_min 0.1030 (0.1892) teacher/usage_std 0.1781 (0.1367) nleep/row_max_mean 1598.4976 (1586.5349) nleep/row_max_std 52.8352 (62.3388) nleep/row_min_mean 1578.9270 (1567.6610) lr 1.9921e-03 eta 0:20:13
epoch [4/50] batch [40/173] time 0.082 (0.123) data 0.000 (0.010) loss 1.6565 (1.5119) teacher_loss 0.4431 (0.2982) loss_zs_kd 0.0307 (0.0174) loss_oracle 0.5795 (0.5766) kd_loss 0.9083 (0.9168) acc 87.5000 (89.4531) gate/entropy 1.0932 (1.0937) gate/usage_max 0.3802 (0.3777) gate/usage_min 0.2962 (0.2974) gate/usage_std 0.0350 (0.0333) teacher/entropy 0.1437 (0.1445) teacher/usage_max 0.5459 (0.5293) teacher/usage_min 0.1395 (0.1773) teacher/usage_std 0.1664 (0.1504) nleep/row_max_mean 1587.9396 (1582.0005) nleep/row_max_std 65.1355 (64.0631) nleep/row_min_mean 1568.0078 (1562.9307) lr 1.9921e-03 eta 0:16:35
epoch [4/50] batch [60/173] time 0.189 (0.123) data 0.000 (0.007) loss 1.3844 (1.5025) teacher_loss 0.1922 (0.2957) loss_zs_kd 0.0112 (0.0183) loss_oracle 0.4944 (0.5702) kd_loss 0.9394 (0.9126) acc 90.6250 (89.6875) gate/entropy 1.0925 (1.0934) gate/usage_max 0.3834 (0.3791) gate/usage_min 0.2948 (0.2968) gate/usage_std 0.0371 (0.0342) teacher/entropy 0.0958 (0.1437) teacher/usage_max 0.6156 (0.5475) teacher/usage_min 0.1078 (0.1679) teacher/usage_std 0.2112 (0.1624) nleep/row_max_mean 1589.2050 (1582.2636) nleep/row_max_std 60.7738 (63.2623) nleep/row_min_mean 1567.5828 (1563.1982) lr 1.9921e-03 eta 0:16:28
epoch [4/50] batch [80/173] time 0.079 (0.121) data 0.000 (0.005) loss 1.4120 (1.4998) teacher_loss 0.1856 (0.2914) loss_zs_kd 0.0227 (0.0191) loss_oracle 0.5567 (0.5656) kd_loss 0.9368 (0.9160) acc 93.7500 (89.9219) gate/entropy 1.0920 (1.0931) gate/usage_max 0.3861 (0.3805) gate/usage_min 0.2940 (0.2962) gate/usage_std 0.0388 (0.0352) teacher/entropy 0.1540 (0.1416) teacher/usage_max 0.3948 (0.5419) teacher/usage_min 0.2965 (0.1755) teacher/usage_std 0.0437 (0.1577) nleep/row_max_mean 1577.3669 (1581.8628) nleep/row_max_std 49.0951 (62.0337) nleep/row_min_mean 1557.1333 (1562.9841) lr 1.9921e-03 eta 0:16:17
epoch [4/50] batch [100/173] time 0.074 (0.120) data 0.000 (0.004) loss 1.4104 (1.4984) teacher_loss 0.2046 (0.2859) loss_zs_kd 0.0156 (0.0194) loss_oracle 0.5370 (0.5635) kd_loss 0.9295 (0.9211) acc 93.7500 (90.1250) gate/entropy 1.0916 (1.0928) gate/usage_max 0.3878 (0.3818) gate/usage_min 0.2938 (0.2957) gate/usage_std 0.0398 (0.0360) teacher/entropy 0.1460 (0.1404) teacher/usage_max 0.4396 (0.5277) teacher/usage_min 0.2263 (0.1850) teacher/usage_std 0.0871 (0.1477) nleep/row_max_mean 1588.1583 (1582.5354) nleep/row_max_std 58.9859 (61.1893) nleep/row_min_mean 1567.6128 (1563.6534) lr 1.9921e-03 eta 0:16:05
epoch [4/50] batch [120/173] time 0.073 (0.118) data 0.000 (0.003) loss 1.4172 (1.5021) teacher_loss 0.2201 (0.2843) loss_zs_kd 0.0156 (0.0195) loss_oracle 0.5139 (0.5638) kd_loss 0.9323 (0.9262) acc 93.7500 (90.0521) gate/entropy 1.0915 (1.0926) gate/usage_max 0.3885 (0.3829) gate/usage_min 0.2941 (0.2954) gate/usage_std 0.0401 (0.0367) teacher/entropy 0.1267 (0.1406) teacher/usage_max 0.4975 (0.5123) teacher/usage_min 0.1688 (0.1929) teacher/usage_std 0.1342 (0.1375) nleep/row_max_mean 1582.8868 (1582.7522) nleep/row_max_std 54.7180 (60.7315) nleep/row_min_mean 1563.4480 (1564.1419) lr 1.9921e-03 eta 0:15:43
epoch [4/50] batch [140/173] time 0.133 (0.114) data 0.000 (0.003) loss 1.4894 (1.4964) teacher_loss 0.2364 (0.2740) loss_zs_kd 0.0326 (0.0197) loss_oracle 0.5536 (0.5634) kd_loss 0.9599 (0.9308) acc 93.7500 (90.4911) gate/entropy 1.0914 (1.0924) gate/usage_max 0.3892 (0.3838) gate/usage_min 0.2942 (0.2952) gate/usage_std 0.0405 (0.0372) teacher/entropy 0.1399 (0.1402) teacher/usage_max 0.3674 (0.4984) teacher/usage_min 0.2776 (0.2016) teacher/usage_std 0.0397 (0.1276) nleep/row_max_mean 1602.9806 (1583.4371) nleep/row_max_std 50.5403 (60.6968) nleep/row_min_mean 1585.8647 (1564.9990) lr 1.9921e-03 eta 0:15:10
epoch [4/50] batch [160/173] time 0.200 (0.115) data 0.000 (0.003) loss 1.6001 (1.5016) teacher_loss 0.1631 (0.2707) loss_zs_kd 0.0304 (0.0200) loss_oracle 0.6656 (0.5676) kd_loss 1.0890 (0.9371) acc 90.6250 (90.5664) gate/entropy 1.0915 (1.0923) gate/usage_max 0.3887 (0.3844) gate/usage_min 0.2946 (0.2951) gate/usage_std 0.0401 (0.0376) teacher/entropy 0.0362 (0.1385) teacher/usage_max 0.3772 (0.4888) teacher/usage_min 0.2491 (0.2068) teacher/usage_std 0.0596 (0.1213) nleep/row_max_mean 1575.3689 (1583.1895) nleep/row_max_std 59.8948 (60.5094) nleep/row_min_mean 1556.8657 (1564.9311) lr 1.9921e-03 eta 0:15:19
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,279
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.6%, epoch: 2 *******
******* Domain a best val test acc: 97.7%, epoch: 2 *******
******* Domain a best test acc:     97.8%, epoch: 3 *******
epoch [5/50] batch [20/173] time 0.143 (0.173) data 0.000 (0.013) loss 1.5754 (1.5488) teacher_loss 0.1813 (0.2239) loss_zs_kd 0.0455 (0.0273) loss_oracle 0.6638 (0.6111) kd_loss 1.0395 (1.0057) acc 93.7500 (91.8750) gate/entropy 1.0919 (1.0918) gate/usage_max 0.3874 (0.3877) gate/usage_min 0.2967 (0.2960) gate/usage_std 0.0390 (0.0393) teacher/entropy 0.0514 (0.1113) teacher/usage_max 0.4070 (0.4461) teacher/usage_min 0.2380 (0.2289) teacher/usage_std 0.0707 (0.0930) nleep/row_max_mean 1574.3347 (1573.5479) nleep/row_max_std 57.9244 (57.7316) nleep/row_min_mean 1555.8503 (1556.4154) lr 1.9823e-03 eta 0:22:50
epoch [5/50] batch [40/173] time 0.164 (0.163) data 0.000 (0.007) loss 1.3454 (1.5440) teacher_loss 0.0869 (0.1972) loss_zs_kd 0.0192 (0.0284) loss_oracle 0.5634 (0.6299) kd_loss 0.9673 (1.0177) acc 96.8750 (93.2812) gate/entropy 1.0923 (1.0919) gate/usage_max 0.3860 (0.3873) gate/usage_min 0.2988 (0.2969) gate/usage_std 0.0379 (0.0389) teacher/entropy 0.1546 (0.1060) teacher/usage_max 0.4577 (0.4661) teacher/usage_min 0.2622 (0.2222) teacher/usage_std 0.0882 (0.1046) nleep/row_max_mean 1585.3851 (1578.4933) nleep/row_max_std 63.5823 (56.0104) nleep/row_min_mean 1567.5157 (1560.5259) lr 1.9823e-03 eta 0:21:33
epoch [5/50] batch [60/173] time 0.176 (0.158) data 0.001 (0.005) loss 1.5978 (1.5390) teacher_loss 0.0830 (0.1935) loss_zs_kd 0.0389 (0.0313) loss_oracle 0.7806 (0.6168) kd_loss 1.1050 (1.0215) acc 100.0000 (93.2812) gate/entropy 1.0926 (1.0921) gate/usage_max 0.3849 (0.3867) gate/usage_min 0.3011 (0.2979) gate/usage_std 0.0369 (0.0384) teacher/entropy 0.0453 (0.1021) teacher/usage_max 0.6683 (0.4631) teacher/usage_min 0.1564 (0.2194) teacher/usage_std 0.2370 (0.1048) nleep/row_max_mean 1571.0500 (1578.8605) nleep/row_max_std 55.2640 (55.6046) nleep/row_min_mean 1551.3113 (1560.6696) lr 1.9823e-03 eta 0:20:45
epoch [5/50] batch [80/173] time 0.087 (0.152) data 0.000 (0.004) loss 1.4396 (1.5418) teacher_loss 0.1046 (0.1919) loss_zs_kd 0.0301 (0.0321) loss_oracle 0.5393 (0.6217) kd_loss 1.0503 (1.0230) acc 96.8750 (93.2422) gate/entropy 1.0929 (1.0923) gate/usage_max 0.3841 (0.3861) gate/usage_min 0.3031 (0.2990) gate/usage_std 0.0361 (0.0379) teacher/entropy 0.0843 (0.1006) teacher/usage_max 0.4338 (0.4689) teacher/usage_min 0.2018 (0.2162) teacher/usage_std 0.0972 (0.1089) nleep/row_max_mean 1597.9890 (1577.8903) nleep/row_max_std 48.8631 (55.5581) nleep/row_min_mean 1579.8135 (1559.6275) lr 1.9823e-03 eta 0:19:56
epoch [5/50] batch [100/173] time 0.083 (0.143) data 0.000 (0.003) loss 1.7392 (1.5470) teacher_loss 0.3134 (0.1933) loss_zs_kd 0.0238 (0.0322) loss_oracle 0.6571 (0.6233) kd_loss 1.0853 (1.0259) acc 90.6250 (93.1875) gate/entropy 1.0932 (1.0924) gate/usage_max 0.3829 (0.3856) gate/usage_min 0.3054 (0.3001) gate/usage_std 0.0351 (0.0374) teacher/entropy 0.0499 (0.0985) teacher/usage_max 0.6546 (0.4805) teacher/usage_min 0.1355 (0.2094) teacher/usage_std 0.2292 (0.1164) nleep/row_max_mean 1574.7826 (1577.9396) nleep/row_max_std 64.3198 (55.0170) nleep/row_min_mean 1554.0929 (1559.5071) lr 1.9823e-03 eta 0:18:45
epoch [5/50] batch [120/173] time 0.079 (0.139) data 0.000 (0.002) loss 1.4739 (1.5467) teacher_loss 0.0563 (0.1910) loss_zs_kd 0.0261 (0.0325) loss_oracle 0.6829 (0.6249) kd_loss 1.0631 (1.0270) acc 96.8750 (93.3594) gate/entropy 1.0934 (1.0926) gate/usage_max 0.3819 (0.3850) gate/usage_min 0.3081 (0.3012) gate/usage_std 0.0343 (0.0370) teacher/entropy 0.0822 (0.0972) teacher/usage_max 0.6565 (0.4936) teacher/usage_min 0.1418 (0.2018) teacher/usage_std 0.2298 (0.1253) nleep/row_max_mean 1592.6768 (1577.4089) nleep/row_max_std 59.9112 (55.8760) nleep/row_min_mean 1570.9753 (1558.5643) lr 1.9823e-03 eta 0:18:10
epoch [5/50] batch [140/173] time 0.167 (0.138) data 0.000 (0.002) loss 1.4862 (1.5520) teacher_loss 0.1435 (0.1934) loss_zs_kd 0.0372 (0.0336) loss_oracle 0.5855 (0.6299) kd_loss 1.0314 (1.0268) acc 100.0000 (93.1920) gate/entropy 1.0937 (1.0927) gate/usage_max 0.3804 (0.3845) gate/usage_min 0.3078 (0.3023) gate/usage_std 0.0333 (0.0365) teacher/entropy 0.1095 (0.0968) teacher/usage_max 0.7108 (0.5097) teacher/usage_min 0.1322 (0.1933) teacher/usage_std 0.2671 (0.1361) nleep/row_max_mean 1552.9395 (1577.2185) nleep/row_max_std 68.2985 (56.5708) nleep/row_min_mean 1533.6565 (1557.8078) lr 1.9823e-03 eta 0:17:55
epoch [5/50] batch [160/173] time 0.096 (0.133) data 0.000 (0.002) loss 1.5240 (1.5550) teacher_loss 0.1469 (0.1910) loss_zs_kd 0.0621 (0.0350) loss_oracle 0.6063 (0.6368) kd_loss 1.0430 (1.0282) acc 93.7500 (93.3594) gate/entropy 1.0941 (1.0929) gate/usage_max 0.3784 (0.3838) gate/usage_min 0.3056 (0.3028) gate/usage_std 0.0321 (0.0360) teacher/entropy 0.0915 (0.0954) teacher/usage_max 0.6531 (0.5286) teacher/usage_min 0.1347 (0.1850) teacher/usage_std 0.2283 (0.1486) nleep/row_max_mean 1587.1035 (1577.7920) nleep/row_max_std 57.5419 (57.2596) nleep/row_min_mean 1562.3309 (1557.7240) lr 1.9823e-03 eta 0:17:19
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 98.1%, epoch: 5 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [6/50] batch [20/173] time 0.081 (0.133) data 0.000 (0.015) loss 1.6770 (1.5824) teacher_loss 0.2342 (0.1701) loss_zs_kd 0.0577 (0.0444) loss_oracle 0.7503 (0.6933) kd_loss 1.0388 (1.0434) acc 87.5000 (93.2812) gate/entropy 1.0945 (1.0944) gate/usage_max 0.3744 (0.3756) gate/usage_min 0.3018 (0.3030) gate/usage_std 0.0304 (0.0308) teacher/entropy 0.0718 (0.0723) teacher/usage_max 0.8096 (0.7099) teacher/usage_min 0.0501 (0.1076) teacher/usage_std 0.3388 (0.2691) nleep/row_max_mean 1600.7446 (1585.5227) nleep/row_max_std 49.1869 (54.8513) nleep/row_min_mean 1573.1847 (1558.6433) lr 1.9686e-03 eta 0:17:09
epoch [6/50] batch [40/173] time 0.095 (0.126) data 0.000 (0.008) loss 1.4808 (1.5951) teacher_loss 0.0423 (0.1694) loss_zs_kd 0.0378 (0.0473) loss_oracle 0.7688 (0.7163) kd_loss 1.0352 (1.0438) acc 100.0000 (93.7500) gate/entropy 1.0948 (1.0945) gate/usage_max 0.3712 (0.3741) gate/usage_min 0.2998 (0.3019) gate/usage_std 0.0293 (0.0303) teacher/entropy 0.0584 (0.0680) teacher/usage_max 0.6933 (0.6997) teacher/usage_min 0.0905 (0.1119) teacher/usage_std 0.2596 (0.2619) nleep/row_max_mean 1585.9753 (1584.4141) nleep/row_max_std 60.5201 (57.1016) nleep/row_min_mean 1554.8121 (1556.9800) lr 1.9686e-03 eta 0:16:15
epoch [6/50] batch [60/173] time 0.155 (0.133) data 0.000 (0.005) loss 1.6856 (1.5925) teacher_loss 0.2401 (0.1709) loss_zs_kd 0.0753 (0.0480) loss_oracle 0.7586 (0.7179) kd_loss 1.0286 (1.0386) acc 90.6250 (94.2188) gate/entropy 1.0948 (1.0946) gate/usage_max 0.3687 (0.3727) gate/usage_min 0.2975 (0.3008) gate/usage_std 0.0290 (0.0299) teacher/entropy 0.0684 (0.0677) teacher/usage_max 0.5970 (0.6989) teacher/usage_min 0.1861 (0.1084) teacher/usage_std 0.1869 (0.2625) nleep/row_max_mean 1602.8541 (1583.4068) nleep/row_max_std 45.9016 (57.4010) nleep/row_min_mean 1571.2528 (1555.7279) lr 1.9686e-03 eta 0:17:08
epoch [6/50] batch [80/173] time 0.155 (0.137) data 0.000 (0.004) loss 1.5548 (1.5803) teacher_loss 0.1742 (0.1663) loss_zs_kd 0.0626 (0.0458) loss_oracle 0.7239 (0.7188) kd_loss 0.9873 (1.0318) acc 93.7500 (94.3359) gate/entropy 1.0948 (1.0947) gate/usage_max 0.3654 (0.3712) gate/usage_min 0.2950 (0.2997) gate/usage_std 0.0291 (0.0297) teacher/entropy 0.0952 (0.0694) teacher/usage_max 0.5910 (0.7086) teacher/usage_min 0.1546 (0.1018) teacher/usage_std 0.1867 (0.2693) nleep/row_max_mean 1572.5070 (1581.3444) nleep/row_max_std 57.6477 (58.7909) nleep/row_min_mean 1544.1777 (1553.4105) lr 1.9686e-03 eta 0:17:39
epoch [6/50] batch [100/173] time 0.160 (0.142) data 0.000 (0.003) loss 1.4088 (1.5708) teacher_loss 0.1420 (0.1682) loss_zs_kd 0.0371 (0.0457) loss_oracle 0.6116 (0.7128) kd_loss 0.9425 (1.0234) acc 96.8750 (94.3438) gate/entropy 1.0945 (1.0947) gate/usage_max 0.3628 (0.3698) gate/usage_min 0.2924 (0.2985) gate/usage_std 0.0298 (0.0296) teacher/entropy 0.1333 (0.0727) teacher/usage_max 0.8394 (0.7127) teacher/usage_min 0.0713 (0.1008) teacher/usage_std 0.3579 (0.2719) nleep/row_max_mean 1572.1350 (1580.1649) nleep/row_max_std 70.1262 (59.7108) nleep/row_min_mean 1541.5909 (1551.9650) lr 1.9686e-03 eta 0:18:14
epoch [6/50] batch [120/173] time 0.136 (0.144) data 0.000 (0.003) loss 1.7399 (1.5690) teacher_loss 0.4038 (0.1746) loss_zs_kd 0.0681 (0.0452) loss_oracle 0.6201 (0.7100) kd_loss 0.9921 (1.0169) acc 87.5000 (94.0885) gate/entropy 1.0942 (1.0946) gate/usage_max 0.3600 (0.3684) gate/usage_min 0.2897 (0.2972) gate/usage_std 0.0311 (0.0297) teacher/entropy 0.0632 (0.0737) teacher/usage_max 0.7384 (0.7188) teacher/usage_min 0.0620 (0.0960) teacher/usage_std 0.2919 (0.2766) nleep/row_max_mean 1556.6246 (1580.0317) nleep/row_max_std 68.7018 (59.6386) nleep/row_min_mean 1530.6317 (1551.5062) lr 1.9686e-03 eta 0:18:21
epoch [6/50] batch [140/173] time 0.179 (0.145) data 0.000 (0.002) loss 1.4840 (1.5667) teacher_loss 0.1821 (0.1779) loss_zs_kd 0.0357 (0.0443) loss_oracle 0.6336 (0.7090) kd_loss 0.9673 (1.0121) acc 93.7500 (93.8839) gate/entropy 1.0937 (1.0945) gate/usage_max 0.3567 (0.3670) gate/usage_min 0.2870 (0.2960) gate/usage_std 0.0328 (0.0301) teacher/entropy 0.0737 (0.0727) teacher/usage_max 0.8084 (0.7307) teacher/usage_min 0.0428 (0.0905) teacher/usage_std 0.3387 (0.2848) nleep/row_max_mean 1568.5516 (1579.1005) nleep/row_max_std 62.9082 (59.3247) nleep/row_min_mean 1539.1647 (1550.3708) lr 1.9686e-03 eta 0:18:25
epoch [6/50] batch [160/173] time 0.102 (0.145) data 0.000 (0.002) loss 1.6703 (1.5620) teacher_loss 0.2941 (0.1791) loss_zs_kd 0.0405 (0.0429) loss_oracle 0.7791 (0.7062) kd_loss 0.9664 (1.0082) acc 90.6250 (93.8281) gate/entropy 1.0928 (1.0944) gate/usage_max 0.3627 (0.3660) gate/usage_min 0.2836 (0.2946) gate/usage_std 0.0354 (0.0306) teacher/entropy 0.0599 (0.0705) teacher/usage_max 0.8379 (0.7388) teacher/usage_min 0.0365 (0.0851) teacher/usage_std 0.3586 (0.2906) nleep/row_max_mean 1559.1816 (1578.5037) nleep/row_max_std 61.4179 (59.1154) nleep/row_min_mean 1531.0190 (1549.6005) lr 1.9686e-03 eta 0:18:29
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 98.1%, epoch: 5 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [7/50] batch [20/173] time 0.089 (0.119) data 0.000 (0.016) loss 1.4892 (1.4739) teacher_loss 0.1642 (0.1769) loss_zs_kd 0.0314 (0.0341) loss_oracle 0.6700 (0.6484) kd_loss 0.9743 (0.9557) acc 93.7500 (93.2812) gate/entropy 1.0912 (1.0917) gate/usage_max 0.3726 (0.3698) gate/usage_min 0.2783 (0.2799) gate/usage_std 0.0401 (0.0386) teacher/entropy 0.0322 (0.0562) teacher/usage_max 0.7862 (0.7902) teacher/usage_min 0.0250 (0.0251) teacher/usage_std 0.3271 (0.3312) nleep/row_max_mean 1576.5598 (1576.3941) nleep/row_max_std 54.3519 (57.5372) nleep/row_min_mean 1546.5017 (1546.3646) lr 1.9511e-03 eta 0:15:05
epoch [7/50] batch [40/173] time 0.200 (0.120) data 0.000 (0.008) loss 1.5511 (1.5029) teacher_loss 0.2344 (0.2036) loss_zs_kd 0.0377 (0.0340) loss_oracle 0.6500 (0.6582) kd_loss 0.9728 (0.9532) acc 87.5000 (92.0312) gate/entropy 1.0900 (1.0912) gate/usage_max 0.3784 (0.3727) gate/usage_min 0.2750 (0.2782) gate/usage_std 0.0432 (0.0402) teacher/entropy 0.0229 (0.0547) teacher/usage_max 0.8103 (0.7853) teacher/usage_min 0.0315 (0.0300) teacher/usage_std 0.3412 (0.3275) nleep/row_max_mean 1568.6147 (1574.5709) nleep/row_max_std 55.6455 (55.7501) nleep/row_min_mean 1540.8960 (1545.2536) lr 1.9511e-03 eta 0:15:09
epoch [7/50] batch [60/173] time 0.164 (0.118) data 0.000 (0.006) loss 1.4421 (1.4966) teacher_loss 0.1994 (0.2093) loss_zs_kd 0.0317 (0.0332) loss_oracle 0.6220 (0.6560) kd_loss 0.9160 (0.9427) acc 96.8750 (92.4479) gate/entropy 1.0887 (1.0906) gate/usage_max 0.3841 (0.3756) gate/usage_min 0.2719 (0.2766) gate/usage_std 0.0464 (0.0417) teacher/entropy 0.0773 (0.0619) teacher/usage_max 0.7234 (0.7737) teacher/usage_min 0.0261 (0.0331) teacher/usage_std 0.2906 (0.3204) nleep/row_max_mean 1565.4756 (1574.5622) nleep/row_max_std 62.6994 (54.9929) nleep/row_min_mean 1536.6005 (1545.5536) lr 1.9511e-03 eta 0:14:50
epoch [7/50] batch [80/173] time 0.070 (0.118) data 0.000 (0.004) loss 1.4291 (1.4952) teacher_loss 0.1423 (0.2107) loss_zs_kd 0.0221 (0.0319) loss_oracle 0.6855 (0.6563) kd_loss 0.9330 (0.9404) acc 93.7500 (92.4609) gate/entropy 1.0873 (1.0899) gate/usage_max 0.3898 (0.3784) gate/usage_min 0.2688 (0.2750) gate/usage_std 0.0497 (0.0433) teacher/entropy 0.0298 (0.0587) teacher/usage_max 0.8457 (0.7755) teacher/usage_min 0.0002 (0.0317) teacher/usage_std 0.3677 (0.3221) nleep/row_max_mean 1575.8988 (1574.0204) nleep/row_max_std 49.6834 (54.8930) nleep/row_min_mean 1543.5627 (1544.9005) lr 1.9511e-03 eta 0:14:50
epoch [7/50] batch [100/173] time 0.074 (0.117) data 0.000 (0.003) loss 1.4974 (1.4878) teacher_loss 0.2765 (0.2150) loss_zs_kd 0.0367 (0.0326) loss_oracle 0.5972 (0.6441) kd_loss 0.9039 (0.9344) acc 87.5000 (92.3438) gate/entropy 1.0857 (1.0892) gate/usage_max 0.3953 (0.3813) gate/usage_min 0.2657 (0.2735) gate/usage_std 0.0531 (0.0450) teacher/entropy 0.0431 (0.0604) teacher/usage_max 0.8901 (0.7728) teacher/usage_min 0.0093 (0.0330) teacher/usage_std 0.3954 (0.3204) nleep/row_max_mean 1567.5789 (1572.8544) nleep/row_max_std 41.6805 (54.3897) nleep/row_min_mean 1539.5032 (1544.0132) lr 1.9511e-03 eta 0:14:38
epoch [7/50] batch [120/173] time 0.152 (0.118) data 0.000 (0.003) loss 1.6264 (1.4773) teacher_loss 0.4188 (0.2158) loss_zs_kd 0.0347 (0.0313) loss_oracle 0.5399 (0.6317) kd_loss 0.9203 (0.9301) acc 93.7500 (92.3177) gate/entropy 1.0842 (1.0885) gate/usage_max 0.4007 (0.3841) gate/usage_min 0.2628 (0.2719) gate/usage_std 0.0563 (0.0466) teacher/entropy 0.0727 (0.0622) teacher/usage_max 0.6436 (0.7662) teacher/usage_min 0.0657 (0.0371) teacher/usage_std 0.2378 (0.3158) nleep/row_max_mean 1569.5405 (1572.4793) nleep/row_max_std 50.8570 (53.8201) nleep/row_min_mean 1544.0286 (1544.1403) lr 1.9511e-03 eta 0:14:45
epoch [7/50] batch [140/173] time 0.091 (0.119) data 0.001 (0.003) loss 1.4964 (1.4741) teacher_loss 0.3025 (0.2262) loss_zs_kd 0.0406 (0.0308) loss_oracle 0.5121 (0.6171) kd_loss 0.9176 (0.9239) acc 84.3750 (91.6964) gate/entropy 1.0828 (1.0878) gate/usage_max 0.4049 (0.3868) gate/usage_min 0.2605 (0.2704) gate/usage_std 0.0590 (0.0482) teacher/entropy 0.0417 (0.0667) teacher/usage_max 0.8137 (0.7572) teacher/usage_min 0.0811 (0.0420) teacher/usage_std 0.3398 (0.3096) nleep/row_max_mean 1565.8435 (1571.5575) nleep/row_max_std 61.9145 (54.2012) nleep/row_min_mean 1540.1050 (1543.7780) lr 1.9511e-03 eta 0:14:47
epoch [7/50] batch [160/173] time 0.118 (0.120) data 0.000 (0.002) loss 1.3424 (1.4638) teacher_loss 0.1652 (0.2271) loss_zs_kd 0.0243 (0.0302) loss_oracle 0.6123 (0.6081) kd_loss 0.8589 (0.9176) acc 96.8750 (91.6406) gate/entropy 1.0811 (1.0871) gate/usage_max 0.4097 (0.3893) gate/usage_min 0.2574 (0.2690) gate/usage_std 0.0622 (0.0497) teacher/entropy 0.1122 (0.0682) teacher/usage_max 0.6595 (0.7581) teacher/usage_min 0.0323 (0.0402) teacher/usage_std 0.2567 (0.3105) nleep/row_max_mean 1573.9161 (1571.4448) nleep/row_max_std 57.6872 (54.1788) nleep/row_min_mean 1545.8074 (1543.8325) lr 1.9511e-03 eta 0:14:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 98.1%, epoch: 5 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [8/50] batch [20/173] time 0.139 (0.164) data 0.000 (0.015) loss 1.2709 (1.4136) teacher_loss 0.1607 (0.2343) loss_zs_kd 0.0281 (0.0312) loss_oracle 0.5556 (0.5972) kd_loss 0.8184 (0.8651) acc 96.8750 (90.4688) gate/entropy 1.0784 (1.0791) gate/usage_max 0.4169 (0.4150) gate/usage_min 0.2532 (0.2542) gate/usage_std 0.0669 (0.0657) teacher/entropy 0.1115 (0.0829) teacher/usage_max 0.7912 (0.7316) teacher/usage_min 0.0234 (0.0295) teacher/usage_std 0.3305 (0.2969) nleep/row_max_mean 1563.4624 (1569.4343) nleep/row_max_std 55.3277 (53.2568) nleep/row_min_mean 1537.1111 (1543.2885) lr 1.9298e-03 eta 0:20:14
epoch [8/50] batch [40/173] time 0.147 (0.158) data 0.000 (0.007) loss 1.3858 (1.4380) teacher_loss 0.2215 (0.2512) loss_zs_kd 0.0213 (0.0314) loss_oracle 0.5592 (0.6104) kd_loss 0.8740 (0.8660) acc 87.5000 (89.4531) gate/entropy 1.0763 (1.0781) gate/usage_max 0.4224 (0.4175) gate/usage_min 0.2505 (0.2529) gate/usage_std 0.0703 (0.0673) teacher/entropy 0.1313 (0.0783) teacher/usage_max 0.5455 (0.7484) teacher/usage_min 0.1029 (0.0428) teacher/usage_std 0.1811 (0.3041) nleep/row_max_mean 1548.8763 (1567.6784) nleep/row_max_std 74.7791 (55.5191) nleep/row_min_mean 1526.6318 (1541.4251) lr 1.9298e-03 eta 0:19:29
epoch [8/50] batch [60/173] time 0.096 (0.153) data 0.001 (0.005) loss 1.2508 (1.4367) teacher_loss 0.2023 (0.2564) loss_zs_kd 0.0147 (0.0315) loss_oracle 0.5349 (0.6080) kd_loss 0.7737 (0.8606) acc 90.6250 (89.4792) gate/entropy 1.0744 (1.0772) gate/usage_max 0.4274 (0.4201) gate/usage_min 0.2482 (0.2516) gate/usage_std 0.0734 (0.0689) teacher/entropy 0.1843 (0.0818) teacher/usage_max 0.6871 (0.7494) teacher/usage_min 0.0828 (0.0497) teacher/usage_std 0.2573 (0.3033) nleep/row_max_mean 1552.1790 (1567.3933) nleep/row_max_std 70.2301 (56.8737) nleep/row_min_mean 1532.0409 (1541.2206) lr 1.9298e-03 eta 0:18:46
epoch [8/50] batch [80/173] time 0.203 (0.141) data 0.000 (0.004) loss 1.3896 (1.4053) teacher_loss 0.2469 (0.2363) loss_zs_kd 0.0191 (0.0294) loss_oracle 0.6048 (0.6021) kd_loss 0.8307 (0.8531) acc 87.5000 (90.4688) gate/entropy 1.0724 (1.0762) gate/usage_max 0.4321 (0.4225) gate/usage_min 0.2458 (0.2504) gate/usage_std 0.0765 (0.0704) teacher/entropy 0.1261 (0.0887) teacher/usage_max 0.6999 (0.7499) teacher/usage_min 0.1105 (0.0577) teacher/usage_std 0.2612 (0.3021) nleep/row_max_mean 1568.1306 (1566.5349) nleep/row_max_std 64.5965 (57.3747) nleep/row_min_mean 1545.5583 (1540.7195) lr 1.9298e-03 eta 0:17:16
epoch [8/50] batch [100/173] time 0.160 (0.137) data 0.000 (0.003) loss 1.2739 (1.3862) teacher_loss 0.1638 (0.2281) loss_zs_kd 0.0375 (0.0285) loss_oracle 0.5237 (0.5961) kd_loss 0.8295 (0.8458) acc 93.7500 (91.0000) gate/entropy 1.0705 (1.0753) gate/usage_max 0.4366 (0.4249) gate/usage_min 0.2439 (0.2493) gate/usage_std 0.0793 (0.0719) teacher/entropy 0.1228 (0.0931) teacher/usage_max 0.7184 (0.7522) teacher/usage_min 0.1333 (0.0619) teacher/usage_std 0.2723 (0.3029) nleep/row_max_mean 1558.6058 (1566.0931) nleep/row_max_std 56.3692 (57.5239) nleep/row_min_mean 1533.8384 (1540.5627) lr 1.9298e-03 eta 0:16:45
epoch [8/50] batch [120/173] time 0.109 (0.132) data 0.000 (0.003) loss 1.4402 (1.3853) teacher_loss 0.3508 (0.2295) loss_zs_kd 0.0590 (0.0291) loss_oracle 0.5932 (0.5956) kd_loss 0.7633 (0.8435) acc 90.6250 (91.0156) gate/entropy 1.0685 (1.0743) gate/usage_max 0.4410 (0.4272) gate/usage_min 0.2416 (0.2482) gate/usage_std 0.0822 (0.0734) teacher/entropy 0.1320 (0.0948) teacher/usage_max 0.8158 (0.7485) teacher/usage_min 0.0596 (0.0660) teacher/usage_std 0.3422 (0.2997) nleep/row_max_mean 1574.9565 (1566.4574) nleep/row_max_std 45.2083 (56.6151) nleep/row_min_mean 1548.8811 (1541.0797) lr 1.9298e-03 eta 0:16:08
epoch [8/50] batch [140/173] time 0.103 (0.129) data 0.000 (0.002) loss 1.1300 (1.3825) teacher_loss 0.0674 (0.2271) loss_zs_kd 0.0107 (0.0299) loss_oracle 0.5216 (0.5980) kd_loss 0.7964 (0.8414) acc 96.8750 (91.2723) gate/entropy 1.0668 (1.0733) gate/usage_max 0.4448 (0.4295) gate/usage_min 0.2401 (0.2472) gate/usage_std 0.0845 (0.0748) teacher/entropy 0.0985 (0.0945) teacher/usage_max 0.8034 (0.7475) teacher/usage_min 0.0626 (0.0675) teacher/usage_std 0.3337 (0.2989) nleep/row_max_mean 1559.6863 (1566.6364) nleep/row_max_std 47.5213 (55.7095) nleep/row_min_mean 1535.2391 (1541.2294) lr 1.9298e-03 eta 0:15:42
epoch [8/50] batch [160/173] time 0.175 (0.128) data 0.000 (0.002) loss 1.3107 (1.3693) teacher_loss 0.2730 (0.2235) loss_zs_kd 0.0266 (0.0299) loss_oracle 0.4419 (0.5878) kd_loss 0.8035 (0.8370) acc 87.5000 (91.4453) gate/entropy 1.0647 (1.0724) gate/usage_max 0.4492 (0.4317) gate/usage_min 0.2381 (0.2462) gate/usage_std 0.0874 (0.0762) teacher/entropy 0.0610 (0.0957) teacher/usage_max 0.8555 (0.7490) teacher/usage_min 0.0449 (0.0678) teacher/usage_std 0.3699 (0.2998) nleep/row_max_mean 1562.1418 (1566.3308) nleep/row_max_std 46.8742 (55.1082) nleep/row_min_mean 1539.0193 (1540.9177) lr 1.9298e-03 eta 0:15:29
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,292
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.1%, epoch: 8 *******
******* Domain a best val test acc: 97.9%, epoch: 8 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [9/50] batch [20/173] time 0.073 (0.142) data 0.000 (0.019) loss 1.2504 (1.3167) teacher_loss 0.1271 (0.1983) loss_zs_kd 0.0266 (0.0285) loss_oracle 0.5071 (0.5487) kd_loss 0.8565 (0.8299) acc 93.7500 (92.1875) gate/entropy 1.0623 (1.0628) gate/usage_max 0.4540 (0.4530) gate/usage_min 0.2357 (0.2362) gate/usage_std 0.0906 (0.0899) teacher/entropy 0.0812 (0.1126) teacher/usage_max 0.6995 (0.6624) teacher/usage_min 0.1210 (0.0853) teacher/usage_std 0.2600 (0.2478) nleep/row_max_mean 1544.9507 (1559.4138) nleep/row_max_std 44.3820 (52.1182) nleep/row_min_mean 1522.3787 (1535.1300) lr 1.9048e-03 eta 0:17:06
epoch [9/50] batch [40/173] time 0.080 (0.126) data 0.000 (0.010) loss 1.4018 (1.3205) teacher_loss 0.2029 (0.1957) loss_zs_kd 0.0276 (0.0303) loss_oracle 0.5633 (0.5405) kd_loss 0.9035 (0.8393) acc 93.7500 (92.5781) gate/entropy 1.0611 (1.0621) gate/usage_max 0.4561 (0.4542) gate/usage_min 0.2344 (0.2355) gate/usage_std 0.0921 (0.0907) teacher/entropy 0.1012 (0.1052) teacher/usage_max 0.4865 (0.6500) teacher/usage_min 0.0464 (0.0795) teacher/usage_std 0.2030 (0.2426) nleep/row_max_mean 1539.5413 (1558.3994) nleep/row_max_std 47.4847 (51.7346) nleep/row_min_mean 1518.1958 (1534.5361) lr 1.9048e-03 eta 0:15:12
epoch [9/50] batch [60/173] time 0.156 (0.131) data 0.000 (0.006) loss 1.3306 (1.3150) teacher_loss 0.1499 (0.1958) loss_zs_kd 0.0299 (0.0286) loss_oracle 0.5682 (0.5304) kd_loss 0.8816 (0.8397) acc 93.7500 (92.5521) gate/entropy 1.0600 (1.0616) gate/usage_max 0.4576 (0.4551) gate/usage_min 0.2327 (0.2348) gate/usage_std 0.0933 (0.0914) teacher/entropy 0.1244 (0.1093) teacher/usage_max 0.4849 (0.6365) teacher/usage_min 0.0828 (0.0795) teacher/usage_std 0.1784 (0.2360) nleep/row_max_mean 1547.5063 (1554.6223) nleep/row_max_std 60.6443 (52.6358) nleep/row_min_mean 1526.1118 (1531.5442) lr 1.9048e-03 eta 0:15:45
epoch [9/50] batch [80/173] time 0.144 (0.136) data 0.000 (0.005) loss 1.2305 (1.3219) teacher_loss 0.1306 (0.1963) loss_zs_kd 0.0217 (0.0288) loss_oracle 0.4950 (0.5311) kd_loss 0.8416 (0.8457) acc 96.8750 (92.5000) gate/entropy 1.0591 (1.0610) gate/usage_max 0.4591 (0.4560) gate/usage_min 0.2316 (0.2341) gate/usage_std 0.0944 (0.0921) teacher/entropy 0.0967 (0.1039) teacher/usage_max 0.6398 (0.6337) teacher/usage_min 0.0614 (0.0810) teacher/usage_std 0.2374 (0.2331) nleep/row_max_mean 1532.9341 (1554.6491) nleep/row_max_std 56.3662 (53.3011) nleep/row_min_mean 1514.3135 (1531.6882) lr 1.9048e-03 eta 0:16:18
epoch [9/50] batch [100/173] time 0.159 (0.138) data 0.000 (0.004) loss 1.3891 (1.3314) teacher_loss 0.1938 (0.2020) loss_zs_kd 0.0244 (0.0284) loss_oracle 0.6033 (0.5308) kd_loss 0.8814 (0.8498) acc 90.6250 (92.0625) gate/entropy 1.0584 (1.0605) gate/usage_max 0.4599 (0.4568) gate/usage_min 0.2303 (0.2334) gate/usage_std 0.0952 (0.0927) teacher/entropy 0.1019 (0.1010) teacher/usage_max 0.5163 (0.6289) teacher/usage_min 0.0531 (0.0815) teacher/usage_std 0.2012 (0.2307) nleep/row_max_mean 1545.6061 (1553.8496) nleep/row_max_std 48.9888 (53.8603) nleep/row_min_mean 1526.8379 (1531.2355) lr 1.9048e-03 eta 0:16:30
epoch [9/50] batch [120/173] time 0.116 (0.140) data 0.000 (0.003) loss 1.5661 (1.3401) teacher_loss 0.3483 (0.2040) loss_zs_kd 0.0389 (0.0278) loss_oracle 0.5711 (0.5317) kd_loss 0.9128 (0.8563) acc 87.5000 (91.9792) gate/entropy 1.0577 (1.0601) gate/usage_max 0.4602 (0.4574) gate/usage_min 0.2284 (0.2327) gate/usage_std 0.0959 (0.0932) teacher/entropy 0.0638 (0.0985) teacher/usage_max 0.5604 (0.6180) teacher/usage_min 0.0940 (0.0811) teacher/usage_std 0.1906 (0.2262) nleep/row_max_mean 1576.5098 (1554.4319) nleep/row_max_std 42.2047 (53.7810) nleep/row_min_mean 1552.3940 (1532.0468) lr 1.9048e-03 eta 0:16:38
epoch [9/50] batch [140/173] time 0.164 (0.141) data 0.000 (0.003) loss 1.1748 (1.3408) teacher_loss 0.0934 (0.1996) loss_zs_kd 0.0189 (0.0269) loss_oracle 0.4117 (0.5268) kd_loss 0.8661 (0.8644) acc 96.8750 (92.2545) gate/entropy 1.0577 (1.0598) gate/usage_max 0.4595 (0.4577) gate/usage_min 0.2274 (0.2320) gate/usage_std 0.0958 (0.0936) teacher/entropy 0.1074 (0.0954) teacher/usage_max 0.5077 (0.6052) teacher/usage_min 0.0228 (0.0814) teacher/usage_std 0.2202 (0.2208) nleep/row_max_mean 1541.1256 (1553.5846) nleep/row_max_std 64.4579 (54.2193) nleep/row_min_mean 1523.6013 (1531.5051) lr 1.9048e-03 eta 0:16:46
epoch [9/50] batch [160/173] time 0.171 (0.143) data 0.000 (0.003) loss 1.4528 (1.3504) teacher_loss 0.2821 (0.2021) loss_zs_kd 0.0344 (0.0272) loss_oracle 0.4943 (0.5278) kd_loss 0.9063 (0.8707) acc 90.6250 (92.2266) gate/entropy 1.0577 (1.0595) gate/usage_max 0.4585 (0.4579) gate/usage_min 0.2263 (0.2314) gate/usage_std 0.0957 (0.0938) teacher/entropy 0.1315 (0.0983) teacher/usage_max 0.4637 (0.5957) teacher/usage_min 0.1201 (0.0840) teacher/usage_std 0.1521 (0.2161) nleep/row_max_mean 1543.3923 (1552.8906) nleep/row_max_std 53.5110 (54.6863) nleep/row_min_mean 1525.6414 (1531.1874) lr 1.9048e-03 eta 0:16:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.1%, epoch: 8 *******
******* Domain a best val test acc: 97.9%, epoch: 8 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [10/50] batch [20/173] time 0.097 (0.112) data 0.000 (0.013) loss 1.4121 (1.4664) teacher_loss 0.1321 (0.1757) loss_zs_kd 0.0343 (0.0328) loss_oracle 0.5561 (0.6110) kd_loss 0.9848 (0.9688) acc 93.7500 (92.9688) gate/entropy 1.0587 (1.0584) gate/usage_max 0.4546 (0.4558) gate/usage_min 0.2250 (0.2254) gate/usage_std 0.0942 (0.0946) teacher/entropy 0.0822 (0.0820) teacher/usage_max 0.4094 (0.5297) teacher/usage_min 0.2049 (0.1129) teacher/usage_std 0.0913 (0.1751) nleep/row_max_mean 1560.8351 (1558.0958) nleep/row_max_std 55.1926 (56.9029) nleep/row_min_mean 1542.6604 (1538.3373) lr 1.8763e-03 eta 0:13:12
epoch [10/50] batch [40/173] time 0.085 (0.108) data 0.000 (0.007) loss 1.5525 (1.4598) teacher_loss 0.2030 (0.1677) loss_zs_kd 0.0485 (0.0316) loss_oracle 0.6284 (0.6072) kd_loss 1.0110 (0.9727) acc 93.7500 (93.6719) gate/entropy 1.0592 (1.0587) gate/usage_max 0.4517 (0.4544) gate/usage_min 0.2238 (0.2249) gate/usage_std 0.0933 (0.0941) teacher/entropy 0.1104 (0.1014) teacher/usage_max 0.4798 (0.5618) teacher/usage_min 0.2389 (0.1269) teacher/usage_std 0.1050 (0.1845) nleep/row_max_mean 1558.7250 (1554.8795) nleep/row_max_std 53.0818 (59.7248) nleep/row_min_mean 1535.7609 (1535.2012) lr 1.8763e-03 eta 0:12:40
epoch [10/50] batch [60/173] time 0.063 (0.107) data 0.000 (0.004) loss 1.4678 (1.4832) teacher_loss 0.2023 (0.1749) loss_zs_kd 0.0318 (0.0346) loss_oracle 0.6976 (0.6232) kd_loss 0.9007 (0.9794) acc 93.7500 (93.5417) gate/entropy 1.0603 (1.0591) gate/usage_max 0.4481 (0.4529) gate/usage_min 0.2235 (0.2245) gate/usage_std 0.0917 (0.0936) teacher/entropy 0.2322 (0.1076) teacher/usage_max 0.3713 (0.5529) teacher/usage_min 0.3106 (0.1467) teacher/usage_std 0.0270 (0.1735) nleep/row_max_mean 1543.6727 (1553.9065) nleep/row_max_std 70.4960 (60.1893) nleep/row_min_mean 1523.6414 (1533.9399) lr 1.8763e-03 eta 0:12:33
epoch [10/50] batch [80/173] time 0.199 (0.108) data 0.000 (0.003) loss 1.7062 (1.5143) teacher_loss 0.3005 (0.1849) loss_zs_kd 0.0520 (0.0382) loss_oracle 0.6665 (0.6413) kd_loss 1.0464 (0.9897) acc 90.6250 (93.1250) gate/entropy 1.0610 (1.0595) gate/usage_max 0.4443 (0.4512) gate/usage_min 0.2224 (0.2241) gate/usage_std 0.0906 (0.0930) teacher/entropy 0.0786 (0.1060) teacher/usage_max 0.5826 (0.5599) teacher/usage_min 0.2052 (0.1522) teacher/usage_std 0.1763 (0.1755) nleep/row_max_mean 1566.0405 (1554.6500) nleep/row_max_std 57.1147 (58.9733) nleep/row_min_mean 1545.7112 (1534.3853) lr 1.8763e-03 eta 0:12:37
epoch [10/50] batch [100/173] time 0.158 (0.111) data 0.000 (0.003) loss 1.5618 (1.5500) teacher_loss 0.1267 (0.1961) loss_zs_kd 0.0351 (0.0388) loss_oracle 0.7923 (0.6697) kd_loss 1.0215 (0.9996) acc 96.8750 (92.9062) gate/entropy 1.0620 (1.0599) gate/usage_max 0.4395 (0.4493) gate/usage_min 0.2216 (0.2237) gate/usage_std 0.0890 (0.0923) teacher/entropy 0.1053 (0.1025) teacher/usage_max 0.6751 (0.5762) teacher/usage_min 0.1364 (0.1487) teacher/usage_std 0.2426 (0.1848) nleep/row_max_mean 1569.1757 (1555.4365) nleep/row_max_std 60.3175 (59.1822) nleep/row_min_mean 1545.1499 (1534.5904) lr 1.8763e-03 eta 0:12:55
epoch [10/50] batch [120/173] time 0.160 (0.108) data 0.000 (0.002) loss 1.8619 (1.5808) teacher_loss 0.3330 (0.2038) loss_zs_kd 0.0522 (0.0381) loss_oracle 0.8210 (0.6907) kd_loss 1.0923 (1.0126) acc 84.3750 (92.7083) gate/entropy 1.0629 (1.0603) gate/usage_max 0.4339 (0.4472) gate/usage_min 0.2206 (0.2233) gate/usage_std 0.0875 (0.0916) teacher/entropy 0.0439 (0.0963) teacher/usage_max 0.7495 (0.5954) teacher/usage_min 0.0570 (0.1386) teacher/usage_std 0.2995 (0.1975) nleep/row_max_mean 1579.2297 (1555.7820) nleep/row_max_std 46.8406 (59.3711) nleep/row_min_mean 1550.9753 (1534.2573) lr 1.8763e-03 eta 0:12:32
epoch [10/50] batch [140/173] time 0.060 (0.105) data 0.000 (0.002) loss 1.7574 (1.6056) teacher_loss 0.3052 (0.2102) loss_zs_kd 0.0309 (0.0378) loss_oracle 0.7792 (0.7091) kd_loss 1.0471 (1.0219) acc 87.5000 (92.5000) gate/entropy 1.0640 (1.0608) gate/usage_max 0.4274 (0.4448) gate/usage_min 0.2200 (0.2229) gate/usage_std 0.0858 (0.0909) teacher/entropy 0.0828 (0.0901) teacher/usage_max 0.7718 (0.6199) teacher/usage_min 0.0297 (0.1248) teacher/usage_std 0.3176 (0.2141) nleep/row_max_mean 1561.6705 (1557.1941) nleep/row_max_std 52.9071 (59.4923) nleep/row_min_mean 1534.2854 (1534.4722) lr 1.8763e-03 eta 0:12:13
epoch [10/50] batch [160/173] time 0.069 (0.104) data 0.000 (0.002) loss 1.8499 (1.6260) teacher_loss 0.3746 (0.2168) loss_zs_kd 0.0308 (0.0365) loss_oracle 0.7985 (0.7211) kd_loss 1.0606 (1.0304) acc 81.2500 (92.2070) gate/entropy 1.0646 (1.0612) gate/usage_max 0.4206 (0.4422) gate/usage_min 0.2189 (0.2224) gate/usage_std 0.0846 (0.0902) teacher/entropy 0.0327 (0.0828) teacher/usage_max 0.8490 (0.6414) teacher/usage_min 0.0046 (0.1112) teacher/usage_std 0.3692 (0.2291) nleep/row_max_mean 1556.5289 (1557.7999) nleep/row_max_std 63.2520 (60.1959) nleep/row_min_mean 1522.1498 (1533.8938) lr 1.8763e-03 eta 0:12:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,299
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [11/50] batch [20/173] time 0.160 (0.166) data 0.000 (0.013) loss 1.8399 (1.7494) teacher_loss 0.3598 (0.2311) loss_zs_kd 0.0312 (0.0281) loss_oracle 0.9036 (0.8452) kd_loss 1.0126 (1.0816) acc 81.2500 (90.4688) gate/entropy 1.0650 (1.0650) gate/usage_max 0.4098 (0.4129) gate/usage_min 0.2171 (0.2176) gate/usage_std 0.0835 (0.0837) teacher/entropy 0.0091 (0.0124) teacher/usage_max 0.9352 (0.8099) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.4264 (0.3470) nleep/row_max_mean 1560.2385 (1563.0143) nleep/row_max_std 75.1028 (59.1485) nleep/row_min_mean 1520.6930 (1527.6818) lr 1.8443e-03 eta 0:19:02
epoch [11/50] batch [40/173] time 0.134 (0.157) data 0.000 (0.007) loss 1.7164 (1.7278) teacher_loss 0.2205 (0.2263) loss_zs_kd 0.0330 (0.0283) loss_oracle 0.7793 (0.8222) kd_loss 1.0898 (1.0763) acc 90.6250 (90.9375) gate/entropy 1.0651 (1.0650) gate/usage_max 0.4035 (0.4097) gate/usage_min 0.2164 (0.2171) gate/usage_std 0.0832 (0.0836) teacher/entropy 0.0008 (0.0100) teacher/usage_max 0.7811 (0.8125) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.3290 (0.3488) nleep/row_max_mean 1557.8396 (1561.3282) nleep/row_max_std 60.4780 (58.3137) nleep/row_min_mean 1522.3662 (1525.4765) lr 1.8443e-03 eta 0:18:00
epoch [11/50] batch [60/173] time 0.145 (0.154) data 0.001 (0.005) loss 1.7104 (1.7185) teacher_loss 0.2233 (0.2318) loss_zs_kd 0.0183 (0.0264) loss_oracle 0.8013 (0.8162) kd_loss 1.0772 (1.0654) acc 90.6250 (90.8333) gate/entropy 1.0650 (1.0650) gate/usage_max 0.3973 (0.4066) gate/usage_min 0.2158 (0.2167) gate/usage_std 0.0832 (0.0835) teacher/entropy 0.0000 (0.0084) teacher/usage_max 0.7813 (0.8221) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.3291 (0.3548) nleep/row_max_mean 1557.6011 (1561.2246) nleep/row_max_std 50.3061 (56.6708) nleep/row_min_mean 1519.4390 (1524.4483) lr 1.8443e-03 eta 0:17:33
epoch [11/50] batch [80/173] time 0.143 (0.153) data 0.000 (0.004) loss 1.7160 (1.7200) teacher_loss 0.3394 (0.2380) loss_zs_kd 0.0213 (0.0263) loss_oracle 0.7434 (0.8160) kd_loss 0.9942 (1.0608) acc 87.5000 (90.8203) gate/entropy 1.0646 (1.0649) gate/usage_max 0.3938 (0.4035) gate/usage_min 0.2150 (0.2164) gate/usage_std 0.0837 (0.0835) teacher/entropy 0.0216 (0.0076) teacher/usage_max 0.8616 (0.8193) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3778 (0.3532) nleep/row_max_mean 1559.1392 (1561.3860) nleep/row_max_std 67.7061 (56.2866) nleep/row_min_mean 1516.9612 (1523.9568) lr 1.8443e-03 eta 0:17:27
epoch [11/50] batch [100/173] time 0.103 (0.151) data 0.000 (0.003) loss 1.5881 (1.7103) teacher_loss 0.1983 (0.2367) loss_zs_kd 0.0198 (0.0257) loss_oracle 0.7477 (0.8120) kd_loss 1.0060 (1.0547) acc 93.7500 (90.9688) gate/entropy 1.0644 (1.0648) gate/usage_max 0.4001 (0.4023) gate/usage_min 0.2149 (0.2161) gate/usage_std 0.0840 (0.0836) teacher/entropy 0.0203 (0.0068) teacher/usage_max 0.8230 (0.8194) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3537 (0.3532) nleep/row_max_mean 1551.1964 (1560.0018) nleep/row_max_std 68.9327 (56.9196) nleep/row_min_mean 1510.5844 (1521.9464) lr 1.8443e-03 eta 0:17:12
epoch [11/50] batch [120/173] time 0.173 (0.145) data 0.000 (0.002) loss 1.9815 (1.7098) teacher_loss 0.4685 (0.2402) loss_zs_kd 0.0441 (0.0261) loss_oracle 0.8224 (0.8100) kd_loss 1.0797 (1.0515) acc 84.3750 (90.7552) gate/entropy 1.0639 (1.0647) gate/usage_max 0.4066 (0.4025) gate/usage_min 0.2145 (0.2158) gate/usage_std 0.0848 (0.0837) teacher/entropy 0.0010 (0.0063) teacher/usage_max 0.7189 (0.8146) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.2958 (0.3503) nleep/row_max_mean 1556.6218 (1560.1125) nleep/row_max_std 41.0378 (56.5728) nleep/row_min_mean 1513.7961 (1521.1842) lr 1.8443e-03 eta 0:16:25
epoch [11/50] batch [140/173] time 0.191 (0.138) data 0.000 (0.002) loss 1.4840 (1.6976) teacher_loss 0.1421 (0.2402) loss_zs_kd 0.0145 (0.0258) loss_oracle 0.7884 (0.8026) kd_loss 0.9404 (1.0432) acc 90.6250 (90.7366) gate/entropy 1.0631 (1.0645) gate/usage_max 0.4132 (0.4036) gate/usage_min 0.2142 (0.2156) gate/usage_std 0.0858 (0.0839) teacher/entropy 0.0064 (0.0060) teacher/usage_max 0.9046 (0.8179) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4058 (0.3522) nleep/row_max_mean 1568.1703 (1559.3088) nleep/row_max_std 67.1542 (56.5639) nleep/row_min_mean 1522.4617 (1519.8289) lr 1.8443e-03 eta 0:15:38
epoch [11/50] batch [160/173] time 0.159 (0.132) data 0.000 (0.002) loss 1.7896 (1.6881) teacher_loss 0.3326 (0.2402) loss_zs_kd 0.0247 (0.0259) loss_oracle 0.9011 (0.7978) kd_loss 0.9941 (1.0361) acc 84.3750 (90.7422) gate/entropy 1.0622 (1.0643) gate/usage_max 0.4197 (0.4052) gate/usage_min 0.2140 (0.2154) gate/usage_std 0.0871 (0.0843) teacher/entropy 0.0000 (0.0055) teacher/usage_max 0.8125 (0.8195) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3474 (0.3532) nleep/row_max_mean 1550.0215 (1558.7375) nleep/row_max_std 66.2379 (56.9153) nleep/row_min_mean 1502.0078 (1518.5080) lr 1.8443e-03 eta 0:14:54
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,281
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [12/50] batch [20/173] time 0.073 (0.119) data 0.000 (0.015) loss 1.5799 (1.5934) teacher_loss 0.2685 (0.2049) loss_zs_kd 0.0363 (0.0293) loss_oracle 0.7039 (0.7705) kd_loss 0.9413 (0.9886) acc 87.5000 (91.4062) gate/entropy 1.0609 (1.0614) gate/usage_max 0.4294 (0.4265) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.0892 (0.0885) teacher/entropy 0.0176 (0.0031) teacher/usage_max 0.8360 (0.7973) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3617 (0.3393) nleep/row_max_mean 1569.5653 (1559.2491) nleep/row_max_std 64.0659 (56.6727) nleep/row_min_mean 1519.5575 (1512.2634) lr 1.8090e-03 eta 0:13:22
epoch [12/50] batch [40/173] time 0.085 (0.111) data 0.000 (0.008) loss 1.6218 (1.5870) teacher_loss 0.2451 (0.2270) loss_zs_kd 0.0263 (0.0273) loss_oracle 0.7996 (0.7567) kd_loss 0.9637 (0.9679) acc 90.6250 (90.5469) gate/entropy 1.0598 (1.0609) gate/usage_max 0.4355 (0.4295) gate/usage_min 0.2148 (0.2146) gate/usage_std 0.0908 (0.0892) teacher/entropy 0.0000 (0.0033) teacher/usage_max 0.8125 (0.8184) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3474 (0.3523) nleep/row_max_mean 1547.2502 (1558.4979) nleep/row_max_std 57.8671 (57.9054) nleep/row_min_mean 1500.8600 (1511.5045) lr 1.8090e-03 eta 0:12:25
epoch [12/50] batch [60/173] time 0.064 (0.102) data 0.001 (0.005) loss 1.6948 (1.5879) teacher_loss 0.2983 (0.2318) loss_zs_kd 0.0316 (0.0267) loss_oracle 0.7323 (0.7591) kd_loss 1.0146 (0.9631) acc 87.5000 (90.5729) gate/entropy 1.0586 (1.0603) gate/usage_max 0.4417 (0.4325) gate/usage_min 0.2152 (0.2148) gate/usage_std 0.0927 (0.0901) teacher/entropy 0.0057 (0.0029) teacher/usage_max 0.7174 (0.8173) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2951 (0.3520) nleep/row_max_mean 1563.1792 (1558.0341) nleep/row_max_std 54.9825 (56.7723) nleep/row_min_mean 1514.2581 (1510.9257) lr 1.8090e-03 eta 0:11:22
epoch [12/50] batch [80/173] time 0.067 (0.099) data 0.000 (0.004) loss 1.7025 (1.5905) teacher_loss 0.4347 (0.2397) loss_zs_kd 0.0235 (0.0268) loss_oracle 0.7219 (0.7505) kd_loss 0.8951 (0.9621) acc 84.3750 (90.3906) gate/entropy 1.0573 (1.0598) gate/usage_max 0.4474 (0.4355) gate/usage_min 0.2160 (0.2150) gate/usage_std 0.0945 (0.0909) teacher/entropy 0.0001 (0.0028) teacher/usage_max 0.8750 (0.8109) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3864 (0.3482) nleep/row_max_mean 1555.3982 (1556.6441) nleep/row_max_std 63.1849 (56.2106) nleep/row_min_mean 1507.0668 (1509.7606) lr 1.8090e-03 eta 0:10:56
epoch [12/50] batch [100/173] time 0.056 (0.099) data 0.000 (0.003) loss 1.4224 (1.5688) teacher_loss 0.1593 (0.2353) loss_zs_kd 0.0269 (0.0264) loss_oracle 0.6874 (0.7400) kd_loss 0.9060 (0.9503) acc 96.8750 (90.5312) gate/entropy 1.0556 (1.0592) gate/usage_max 0.4539 (0.4385) gate/usage_min 0.2163 (0.2153) gate/usage_std 0.0970 (0.0918) teacher/entropy 0.0000 (0.0035) teacher/usage_max 0.8437 (0.8184) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3665 (0.3525) nleep/row_max_mean 1563.3204 (1555.3150) nleep/row_max_std 56.8577 (56.0532) nleep/row_min_mean 1515.4412 (1508.5678) lr 1.8090e-03 eta 0:10:58
epoch [12/50] batch [120/173] time 0.065 (0.099) data 0.000 (0.003) loss 1.6739 (1.5623) teacher_loss 0.3961 (0.2376) loss_zs_kd 0.0220 (0.0259) loss_oracle 0.7005 (0.7330) kd_loss 0.9166 (0.9453) acc 90.6250 (90.7031) gate/entropy 1.0539 (1.0584) gate/usage_max 0.4596 (0.4415) gate/usage_min 0.2171 (0.2155) gate/usage_std 0.0993 (0.0929) teacher/entropy 0.0007 (0.0046) teacher/usage_max 0.8125 (0.8157) teacher/usage_min 0.0001 (0.0000) teacher/usage_std 0.3474 (0.3511) nleep/row_max_mean 1562.2075 (1555.5284) nleep/row_max_std 42.8989 (55.1377) nleep/row_min_mean 1512.6178 (1508.7690) lr 1.8090e-03 eta 0:10:56
epoch [12/50] batch [140/173] time 0.164 (0.100) data 0.000 (0.002) loss 1.5236 (1.5561) teacher_loss 0.2193 (0.2388) loss_zs_kd 0.0267 (0.0270) loss_oracle 0.7500 (0.7298) kd_loss 0.9159 (0.9388) acc 93.7500 (90.6920) gate/entropy 1.0516 (1.0576) gate/usage_max 0.4663 (0.4446) gate/usage_min 0.2175 (0.2158) gate/usage_std 0.1023 (0.0940) teacher/entropy 0.0194 (0.0066) teacher/usage_max 0.7733 (0.8140) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3246 (0.3502) nleep/row_max_mean 1559.5238 (1555.9985) nleep/row_max_std 42.9389 (54.9969) nleep/row_min_mean 1513.8062 (1509.0717) lr 1.8090e-03 eta 0:10:59
epoch [12/50] batch [160/173] time 0.156 (0.106) data 0.000 (0.002) loss 1.6683 (1.5502) teacher_loss 0.4084 (0.2411) loss_zs_kd 0.0311 (0.0266) loss_oracle 0.7161 (0.7254) kd_loss 0.8863 (0.9332) acc 78.1250 (90.5859) gate/entropy 1.0492 (1.0567) gate/usage_max 0.4727 (0.4477) gate/usage_min 0.2180 (0.2161) gate/usage_std 0.1054 (0.0952) teacher/entropy 0.0093 (0.0070) teacher/usage_max 0.8103 (0.8133) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3461 (0.3497) nleep/row_max_mean 1573.2845 (1555.9657) nleep/row_max_std 46.1739 (55.3921) nleep/row_min_mean 1521.3792 (1508.9358) lr 1.8090e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [13/50] batch [20/173] time 0.124 (0.165) data 0.000 (0.020) loss 1.4519 (1.4644) teacher_loss 0.2335 (0.2176) loss_zs_kd 0.0340 (0.0264) loss_oracle 0.6691 (0.6856) kd_loss 0.8668 (0.8908) acc 93.7500 (91.8750) gate/entropy 1.0456 (1.0468) gate/usage_max 0.4816 (0.4789) gate/usage_min 0.2194 (0.2191) gate/usage_std 0.1098 (0.1084) teacher/entropy 0.0213 (0.0153) teacher/usage_max 0.7999 (0.7828) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3399 (0.3321) nleep/row_max_mean 1553.5540 (1552.6540) nleep/row_max_std 58.3071 (55.0836) nleep/row_min_mean 1506.1831 (1504.6527) lr 1.7705e-03 eta 0:17:58
epoch [13/50] batch [40/173] time 0.149 (0.155) data 0.000 (0.010) loss 1.5157 (1.4531) teacher_loss 0.2613 (0.2249) loss_zs_kd 0.0261 (0.0262) loss_oracle 0.6621 (0.6785) kd_loss 0.9103 (0.8758) acc 87.5000 (91.2500) gate/entropy 1.0430 (1.0455) gate/usage_max 0.4873 (0.4818) gate/usage_min 0.2200 (0.2194) gate/usage_std 0.1128 (0.1099) teacher/entropy 0.0068 (0.0154) teacher/usage_max 0.7498 (0.7953) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.3117 (0.3393) nleep/row_max_mean 1561.5352 (1554.7279) nleep/row_max_std 62.5502 (55.9192) nleep/row_min_mean 1508.5244 (1505.9034) lr 1.7705e-03 eta 0:16:53
epoch [13/50] batch [60/173] time 0.092 (0.138) data 0.001 (0.007) loss 1.4649 (1.4504) teacher_loss 0.2394 (0.2329) loss_zs_kd 0.0200 (0.0261) loss_oracle 0.6917 (0.6701) kd_loss 0.8697 (0.8694) acc 90.6250 (91.1979) gate/entropy 1.0401 (1.0442) gate/usage_max 0.4931 (0.4846) gate/usage_min 0.2205 (0.2197) gate/usage_std 0.1161 (0.1114) teacher/entropy 0.0204 (0.0149) teacher/usage_max 0.7726 (0.7977) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3242 (0.3407) nleep/row_max_mean 1551.1931 (1555.7461) nleep/row_max_std 52.3959 (53.8642) nleep/row_min_mean 1499.9978 (1506.6083) lr 1.7705e-03 eta 0:14:58
epoch [13/50] batch [80/173] time 0.165 (0.133) data 0.000 (0.005) loss 1.2531 (1.4367) teacher_loss 0.0407 (0.2258) loss_zs_kd 0.0188 (0.0249) loss_oracle 0.6677 (0.6612) kd_loss 0.8692 (0.8678) acc 100.0000 (91.5234) gate/entropy 1.0373 (1.0429) gate/usage_max 0.4983 (0.4874) gate/usage_min 0.2210 (0.2200) gate/usage_std 0.1192 (0.1130) teacher/entropy 0.0070 (0.0150) teacher/usage_max 0.7797 (0.7936) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.3282 (0.3388) nleep/row_max_mean 1570.6006 (1557.5008) nleep/row_max_std 38.6212 (53.2692) nleep/row_min_mean 1522.7885 (1507.7982) lr 1.7705e-03 eta 0:14:21
epoch [13/50] batch [100/173] time 0.085 (0.126) data 0.000 (0.004) loss 1.4172 (1.4442) teacher_loss 0.2389 (0.2373) loss_zs_kd 0.0296 (0.0250) loss_oracle 0.6408 (0.6590) kd_loss 0.8431 (0.8649) acc 93.7500 (90.9375) gate/entropy 1.0348 (1.0415) gate/usage_max 0.5029 (0.4900) gate/usage_min 0.2217 (0.2203) gate/usage_std 0.1219 (0.1145) teacher/entropy 0.0187 (0.0139) teacher/usage_max 0.7872 (0.7928) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3325 (0.3382) nleep/row_max_mean 1553.9014 (1558.1167) nleep/row_max_std 44.1946 (52.8109) nleep/row_min_mean 1502.5665 (1508.0461) lr 1.7705e-03 eta 0:13:36
epoch [13/50] batch [120/173] time 0.076 (0.127) data 0.000 (0.004) loss 1.3703 (1.4352) teacher_loss 0.2089 (0.2398) loss_zs_kd 0.0295 (0.0244) loss_oracle 0.6401 (0.6522) kd_loss 0.8266 (0.8570) acc 90.6250 (90.8073) gate/entropy 1.0318 (1.0401) gate/usage_max 0.5079 (0.4926) gate/usage_min 0.2221 (0.2206) gate/usage_std 0.1250 (0.1160) teacher/entropy 0.0073 (0.0140) teacher/usage_max 0.8109 (0.7970) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3464 (0.3406) nleep/row_max_mean 1562.7808 (1557.9204) nleep/row_max_std 48.8453 (53.0203) nleep/row_min_mean 1511.2373 (1507.7872) lr 1.7705e-03 eta 0:13:36
epoch [13/50] batch [140/173] time 0.116 (0.124) data 0.000 (0.003) loss 1.1040 (1.4250) teacher_loss 0.0788 (0.2382) loss_zs_kd 0.0098 (0.0255) loss_oracle 0.5708 (0.6451) kd_loss 0.7349 (0.8515) acc 100.0000 (90.8482) gate/entropy 1.0292 (1.0387) gate/usage_max 0.5120 (0.4951) gate/usage_min 0.2224 (0.2208) gate/usage_std 0.1276 (0.1174) teacher/entropy 0.0218 (0.0144) teacher/usage_max 0.8957 (0.7983) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.3999 (0.3414) nleep/row_max_mean 1558.2877 (1558.0151) nleep/row_max_std 55.6514 (52.9858) nleep/row_min_mean 1507.6705 (1507.8941) lr 1.7705e-03 eta 0:13:17
epoch [13/50] batch [160/173] time 0.070 (0.122) data 0.000 (0.003) loss 1.2441 (1.4139) teacher_loss 0.1765 (0.2335) loss_zs_kd 0.0097 (0.0251) loss_oracle 0.5649 (0.6405) kd_loss 0.7803 (0.8476) acc 93.7500 (91.0742) gate/entropy 1.0264 (1.0374) gate/usage_max 0.5162 (0.4974) gate/usage_min 0.2227 (0.2210) gate/usage_std 0.1303 (0.1189) teacher/entropy 0.0276 (0.0148) teacher/usage_max 0.8252 (0.7977) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3551 (0.3409) nleep/row_max_mean 1564.2755 (1558.2659) nleep/row_max_std 47.8855 (53.3649) nleep/row_min_mean 1514.7313 (1508.2473) lr 1.7705e-03 eta 0:13:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [14/50] batch [20/173] time 0.072 (0.115) data 0.000 (0.016) loss 1.3337 (1.3390) teacher_loss 0.0824 (0.1883) loss_zs_kd 0.0284 (0.0252) loss_oracle 0.5875 (0.6141) kd_loss 0.9433 (0.8310) acc 96.8750 (92.1875) gate/entropy 1.0235 (1.0239) gate/usage_max 0.5206 (0.5200) gate/usage_min 0.2236 (0.2232) gate/usage_std 0.1330 (0.1327) teacher/entropy 0.0544 (0.0240) teacher/usage_max 0.5923 (0.7624) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2475 (0.3235) nleep/row_max_mean 1540.4136 (1550.8319) nleep/row_max_std 54.9567 (54.1293) nleep/row_min_mean 1501.4539 (1504.4663) lr 1.7290e-03 eta 0:12:10
epoch [14/50] batch [40/173] time 0.163 (0.102) data 0.000 (0.008) loss 1.4410 (1.3319) teacher_loss 0.1886 (0.1949) loss_zs_kd 0.0291 (0.0245) loss_oracle 0.6116 (0.6034) kd_loss 0.9321 (0.8230) acc 93.7500 (92.6562) gate/entropy 1.0207 (1.0227) gate/usage_max 0.5245 (0.5216) gate/usage_min 0.2236 (0.2233) gate/usage_std 0.1357 (0.1338) teacher/entropy 0.0281 (0.0271) teacher/usage_max 0.6303 (0.7649) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2586 (0.3235) nleep/row_max_mean 1546.4187 (1551.0481) nleep/row_max_std 62.3820 (53.3325) nleep/row_min_mean 1501.8889 (1505.6695) lr 1.7290e-03 eta 0:10:45
epoch [14/50] batch [60/173] time 0.091 (0.095) data 0.001 (0.006) loss 1.6115 (1.3499) teacher_loss 0.4001 (0.2124) loss_zs_kd 0.0196 (0.0247) loss_oracle 0.5937 (0.6015) kd_loss 0.9047 (0.8244) acc 81.2500 (92.0312) gate/entropy 1.0185 (1.0217) gate/usage_max 0.5274 (0.5231) gate/usage_min 0.2238 (0.2234) gate/usage_std 0.1376 (0.1347) teacher/entropy 0.0512 (0.0311) teacher/usage_max 0.6307 (0.7559) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2587 (0.3186) nleep/row_max_mean 1552.0405 (1550.1660) nleep/row_max_std 60.3982 (54.8532) nleep/row_min_mean 1511.6584 (1505.0314) lr 1.7290e-03 eta 0:10:02
epoch [14/50] batch [80/173] time 0.155 (0.106) data 0.000 (0.004) loss 1.2068 (1.3540) teacher_loss 0.1967 (0.2221) loss_zs_kd 0.0187 (0.0247) loss_oracle 0.5904 (0.5989) kd_loss 0.7055 (0.8202) acc 93.7500 (91.8750) gate/entropy 1.0167 (1.0207) gate/usage_max 0.5298 (0.5245) gate/usage_min 0.2241 (0.2235) gate/usage_std 0.1392 (0.1357) teacher/entropy 0.0622 (0.0347) teacher/usage_max 0.8458 (0.7540) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3678 (0.3179) nleep/row_max_mean 1550.7378 (1550.0091) nleep/row_max_std 61.2665 (54.8936) nleep/row_min_mean 1507.4700 (1505.1975) lr 1.7290e-03 eta 0:11:11
epoch [14/50] batch [100/173] time 0.155 (0.115) data 0.000 (0.003) loss 1.3248 (1.3576) teacher_loss 0.0930 (0.2200) loss_zs_kd 0.0267 (0.0246) loss_oracle 0.6109 (0.5979) kd_loss 0.9130 (0.8263) acc 93.7500 (91.9688) gate/entropy 1.0147 (1.0197) gate/usage_max 0.5325 (0.5258) gate/usage_min 0.2242 (0.2237) gate/usage_std 0.1411 (0.1366) teacher/entropy 0.0776 (0.0412) teacher/usage_max 0.5827 (0.7370) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2452 (0.3102) nleep/row_max_mean 1549.9646 (1549.5898) nleep/row_max_std 49.3023 (54.6438) nleep/row_min_mean 1507.4451 (1504.9371) lr 1.7290e-03 eta 0:12:01
epoch [14/50] batch [120/173] time 0.138 (0.118) data 0.000 (0.003) loss 1.3770 (1.3715) teacher_loss 0.1936 (0.2280) loss_zs_kd 0.0244 (0.0247) loss_oracle 0.6244 (0.5966) kd_loss 0.8590 (0.8329) acc 96.8750 (91.7448) gate/entropy 1.0142 (1.0188) gate/usage_max 0.5331 (0.5270) gate/usage_min 0.2248 (0.2238) gate/usage_std 0.1414 (0.1373) teacher/entropy 0.1091 (0.0432) teacher/usage_max 0.6060 (0.7248) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.2511 (0.3044) nleep/row_max_mean 1545.0250 (1549.3002) nleep/row_max_std 49.4833 (53.7072) nleep/row_min_mean 1501.7781 (1504.7335) lr 1.7290e-03 eta 0:12:23
epoch [14/50] batch [140/173] time 0.155 (0.122) data 0.000 (0.002) loss 1.4876 (1.3828) teacher_loss 0.2432 (0.2334) loss_zs_kd 0.0303 (0.0250) loss_oracle 0.5758 (0.5965) kd_loss 0.9413 (0.8387) acc 90.6250 (91.3616) gate/entropy 1.0129 (1.0180) gate/usage_max 0.5348 (0.5281) gate/usage_min 0.2252 (0.2240) gate/usage_std 0.1426 (0.1381) teacher/entropy 0.0611 (0.0473) teacher/usage_max 0.5635 (0.7115) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.2413 (0.2989) nleep/row_max_mean 1547.1564 (1549.7589) nleep/row_max_std 54.0920 (53.4936) nleep/row_min_mean 1500.1863 (1504.9381) lr 1.7290e-03 eta 0:12:41
epoch [14/50] batch [160/173] time 0.179 (0.125) data 0.000 (0.002) loss 1.4124 (1.3942) teacher_loss 0.2329 (0.2406) loss_zs_kd 0.0327 (0.0248) loss_oracle 0.5401 (0.5915) kd_loss 0.8931 (0.8454) acc 90.6250 (90.8984) gate/entropy 1.0108 (1.0172) gate/usage_max 0.5374 (0.5291) gate/usage_min 0.2252 (0.2241) gate/usage_std 0.1444 (0.1388) teacher/entropy 0.0629 (0.0486) teacher/usage_max 0.6146 (0.7010) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.2536 (0.2944) nleep/row_max_mean 1559.7134 (1550.7785) nleep/row_max_std 40.6457 (52.9495) nleep/row_min_mean 1516.6641 (1505.7523) lr 1.7290e-03 eta 0:13:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,292
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [15/50] batch [20/173] time 0.131 (0.136) data 0.000 (0.015) loss 1.4928 (1.4618) teacher_loss 0.2854 (0.2542) loss_zs_kd 0.0115 (0.0220) loss_oracle 0.5512 (0.5707) kd_loss 0.9261 (0.9112) acc 90.6250 (90.1562) gate/entropy 1.0102 (1.0102) gate/usage_max 0.5382 (0.5382) gate/usage_min 0.2261 (0.2258) gate/usage_std 0.1449 (0.1449) teacher/entropy 0.0821 (0.0629) teacher/usage_max 0.5513 (0.5908) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2394 (0.2520) nleep/row_max_mean 1550.5867 (1554.2337) nleep/row_max_std 56.5841 (55.4235) nleep/row_min_mean 1506.0148 (1506.5383) lr 1.6845e-03 eta 0:14:06
epoch [15/50] batch [40/173] time 0.083 (0.127) data 0.000 (0.008) loss 1.4482 (1.4826) teacher_loss 0.1272 (0.2475) loss_zs_kd 0.0251 (0.0253) loss_oracle 0.6331 (0.5833) kd_loss 0.9919 (0.9308) acc 96.8750 (90.8594) gate/entropy 1.0088 (1.0098) gate/usage_max 0.5399 (0.5387) gate/usage_min 0.2263 (0.2260) gate/usage_std 0.1461 (0.1453) teacher/entropy 0.0583 (0.0544) teacher/usage_max 0.5004 (0.5838) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2357 (0.2496) nleep/row_max_mean 1560.7108 (1556.6012) nleep/row_max_std 46.2122 (54.6250) nleep/row_min_mean 1511.7104 (1507.8188) lr 1.6845e-03 eta 0:13:07
epoch [15/50] batch [60/173] time 0.081 (0.122) data 0.001 (0.005) loss 1.3347 (1.4578) teacher_loss 0.2275 (0.2371) loss_zs_kd 0.0146 (0.0240) loss_oracle 0.5284 (0.5747) kd_loss 0.8357 (0.9214) acc 96.8750 (91.2500) gate/entropy 1.0078 (1.0094) gate/usage_max 0.5411 (0.5392) gate/usage_min 0.2267 (0.2262) gate/usage_std 0.1469 (0.1456) teacher/entropy 0.0432 (0.0528) teacher/usage_max 0.6946 (0.5951) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2843 (0.2533) nleep/row_max_mean 1573.6968 (1557.0275) nleep/row_max_std 48.0555 (54.0758) nleep/row_min_mean 1521.9066 (1508.0253) lr 1.6845e-03 eta 0:12:34
epoch [15/50] batch [80/173] time 0.117 (0.121) data 0.000 (0.004) loss 1.4329 (1.4476) teacher_loss 0.1935 (0.2359) loss_zs_kd 0.0126 (0.0232) loss_oracle 0.6564 (0.5757) kd_loss 0.9049 (0.9123) acc 96.8750 (91.1719) gate/entropy 1.0075 (1.0090) gate/usage_max 0.5415 (0.5397) gate/usage_min 0.2271 (0.2264) gate/usage_std 0.1472 (0.1459) teacher/entropy 0.0295 (0.0527) teacher/usage_max 0.6299 (0.6066) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2585 (0.2569) nleep/row_max_mean 1546.8835 (1556.7482) nleep/row_max_std 61.0478 (53.8785) nleep/row_min_mean 1494.3523 (1507.7025) lr 1.6845e-03 eta 0:12:23
epoch [15/50] batch [100/173] time 0.091 (0.118) data 0.000 (0.003) loss 1.5851 (1.4486) teacher_loss 0.3990 (0.2310) loss_zs_kd 0.0416 (0.0232) loss_oracle 0.5351 (0.5764) kd_loss 0.8978 (0.9178) acc 84.3750 (91.2188) gate/entropy 1.0064 (1.0086) gate/usage_max 0.5428 (0.5401) gate/usage_min 0.2273 (0.2266) gate/usage_std 0.1481 (0.1462) teacher/entropy 0.0723 (0.0509) teacher/usage_max 0.5862 (0.6019) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2460 (0.2555) nleep/row_max_mean 1562.2755 (1555.9769) nleep/row_max_std 53.4628 (54.2293) nleep/row_min_mean 1516.0884 (1507.4398) lr 1.6845e-03 eta 0:12:01
epoch [15/50] batch [120/173] time 0.084 (0.118) data 0.000 (0.003) loss 1.4777 (1.4540) teacher_loss 0.2994 (0.2364) loss_zs_kd 0.0192 (0.0230) loss_oracle 0.4900 (0.5760) kd_loss 0.9237 (0.9181) acc 87.5000 (90.9635) gate/entropy 1.0070 (1.0083) gate/usage_max 0.5421 (0.5405) gate/usage_min 0.2281 (0.2268) gate/usage_std 0.1476 (0.1465) teacher/entropy 0.0354 (0.0501) teacher/usage_max 0.5983 (0.6002) teacher/usage_min 0.0011 (0.0000) teacher/usage_std 0.2484 (0.2547) nleep/row_max_mean 1531.6597 (1555.7782) nleep/row_max_std 65.3300 (54.6293) nleep/row_min_mean 1492.4172 (1507.6411) lr 1.6845e-03 eta 0:12:00
epoch [15/50] batch [140/173] time 0.079 (0.119) data 0.000 (0.002) loss 1.3274 (1.4524) teacher_loss 0.1756 (0.2329) loss_zs_kd 0.0162 (0.0231) loss_oracle 0.5276 (0.5765) kd_loss 0.8799 (0.9197) acc 96.8750 (91.1161) gate/entropy 1.0061 (1.0080) gate/usage_max 0.5431 (0.5408) gate/usage_min 0.2283 (0.2270) gate/usage_std 0.1484 (0.1468) teacher/entropy 0.1125 (0.0488) teacher/usage_max 0.5586 (0.5986) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2405 (0.2541) nleep/row_max_mean 1548.2062 (1555.0243) nleep/row_max_std 72.2245 (55.1171) nleep/row_min_mean 1501.8899 (1507.2324) lr 1.6845e-03 eta 0:12:01
epoch [15/50] batch [160/173] time 0.076 (0.118) data 0.000 (0.002) loss 1.4377 (1.4498) teacher_loss 0.2902 (0.2333) loss_zs_kd 0.0120 (0.0229) loss_oracle 0.5052 (0.5728) kd_loss 0.8889 (0.9187) acc 87.5000 (90.9961) gate/entropy 1.0059 (1.0077) gate/usage_max 0.5433 (0.5412) gate/usage_min 0.2279 (0.2271) gate/usage_std 0.1485 (0.1470) teacher/entropy 0.0334 (0.0476) teacher/usage_max 0.6383 (0.5995) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2614 (0.2544) nleep/row_max_mean 1552.8911 (1554.7373) nleep/row_max_std 58.8486 (55.8245) nleep/row_min_mean 1507.5796 (1507.3239) lr 1.6845e-03 eta 0:11:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,282
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [16/50] batch [20/173] time 0.141 (0.153) data 0.000 (0.014) loss 1.3743 (1.4274) teacher_loss 0.2869 (0.2119) loss_zs_kd 0.0285 (0.0242) loss_oracle 0.5198 (0.5509) kd_loss 0.8133 (0.9279) acc 84.3750 (91.2500) gate/entropy 1.0044 (1.0048) gate/usage_max 0.5451 (0.5446) gate/usage_min 0.2260 (0.2265) gate/usage_std 0.1497 (0.1494) teacher/entropy 0.0118 (0.0372) teacher/usage_max 0.7479 (0.5939) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3107 (0.2527) nleep/row_max_mean 1570.7219 (1557.1148) nleep/row_max_std 66.4747 (59.9219) nleep/row_min_mean 1521.1205 (1511.3496) lr 1.6374e-03 eta 0:15:23
epoch [16/50] batch [40/173] time 0.125 (0.146) data 0.000 (0.007) loss 1.3067 (1.4353) teacher_loss 0.1510 (0.2282) loss_zs_kd 0.0292 (0.0253) loss_oracle 0.5898 (0.5633) kd_loss 0.8462 (0.9128) acc 90.6250 (90.8594) gate/entropy 1.0041 (1.0047) gate/usage_max 0.5454 (0.5448) gate/usage_min 0.2253 (0.2262) gate/usage_std 0.1500 (0.1495) teacher/entropy 0.0035 (0.0368) teacher/usage_max 0.7182 (0.6108) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2955 (0.2568) nleep/row_max_mean 1567.6384 (1556.3549) nleep/row_max_std 49.5326 (58.1266) nleep/row_min_mean 1519.2107 (1511.1277) lr 1.6374e-03 eta 0:14:38
epoch [16/50] batch [60/173] time 0.146 (0.144) data 0.000 (0.005) loss 1.2955 (1.4202) teacher_loss 0.1445 (0.2183) loss_zs_kd 0.0083 (0.0235) loss_oracle 0.5942 (0.5655) kd_loss 0.8498 (0.9074) acc 96.8750 (91.3542) gate/entropy 1.0039 (1.0045) gate/usage_max 0.5456 (0.5449) gate/usage_min 0.2247 (0.2258) gate/usage_std 0.1501 (0.1496) teacher/entropy 0.0222 (0.0345) teacher/usage_max 0.6918 (0.6175) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2830 (0.2589) nleep/row_max_mean 1564.6709 (1555.6968) nleep/row_max_std 44.6758 (58.9328) nleep/row_min_mean 1517.9843 (1510.5838) lr 1.6374e-03 eta 0:14:24
epoch [16/50] batch [80/173] time 0.123 (0.144) data 0.000 (0.003) loss 1.8297 (1.4396) teacher_loss 0.4251 (0.2303) loss_zs_kd 0.0232 (0.0237) loss_oracle 0.7171 (0.5774) kd_loss 1.0345 (0.9088) acc 93.7500 (90.7422) gate/entropy 1.0042 (1.0044) gate/usage_max 0.5453 (0.5451) gate/usage_min 0.2245 (0.2255) gate/usage_std 0.1499 (0.1498) teacher/entropy 0.0029 (0.0321) teacher/usage_max 0.5003 (0.6209) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2357 (0.2610) nleep/row_max_mean 1541.9506 (1554.1705) nleep/row_max_std 64.6557 (58.7332) nleep/row_min_mean 1498.2310 (1509.6948) lr 1.6374e-03 eta 0:14:20
epoch [16/50] batch [100/173] time 0.163 (0.142) data 0.000 (0.003) loss 1.3620 (1.4408) teacher_loss 0.2166 (0.2316) loss_zs_kd 0.0110 (0.0244) loss_oracle 0.5160 (0.5750) kd_loss 0.8819 (0.9095) acc 90.6250 (90.6250) gate/entropy 1.0036 (1.0042) gate/usage_max 0.5459 (0.5453) gate/usage_min 0.2237 (0.2252) gate/usage_std 0.1503 (0.1499) teacher/entropy 0.0339 (0.0321) teacher/usage_max 0.6402 (0.6197) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2620 (0.2602) nleep/row_max_mean 1542.5771 (1552.2101) nleep/row_max_std 72.6672 (58.3817) nleep/row_min_mean 1500.3318 (1508.2179) lr 1.6374e-03 eta 0:14:03
epoch [16/50] batch [120/173] time 0.090 (0.136) data 0.000 (0.002) loss 1.6880 (1.4406) teacher_loss 0.4071 (0.2329) loss_zs_kd 0.0476 (0.0250) loss_oracle 0.6036 (0.5699) kd_loss 0.9553 (0.9102) acc 90.6250 (90.6771) gate/entropy 1.0027 (1.0041) gate/usage_max 0.5469 (0.5454) gate/usage_min 0.2227 (0.2249) gate/usage_std 0.1510 (0.1500) teacher/entropy 0.0240 (0.0320) teacher/usage_max 0.5644 (0.6188) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2415 (0.2601) nleep/row_max_mean 1563.8792 (1551.9845) nleep/row_max_std 53.8311 (57.7913) nleep/row_min_mean 1518.1100 (1508.2503) lr 1.6374e-03 eta 0:13:28
epoch [16/50] batch [140/173] time 0.088 (0.132) data 0.000 (0.002) loss 1.3611 (1.4295) teacher_loss 0.2514 (0.2280) loss_zs_kd 0.0326 (0.0252) loss_oracle 0.5958 (0.5684) kd_loss 0.7954 (0.9046) acc 90.6250 (90.6920) gate/entropy 1.0026 (1.0039) gate/usage_max 0.5470 (0.5456) gate/usage_min 0.2222 (0.2246) gate/usage_std 0.1512 (0.1501) teacher/entropy 0.0417 (0.0322) teacher/usage_max 0.7289 (0.6235) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3008 (0.2616) nleep/row_max_mean 1567.4299 (1551.5677) nleep/row_max_std 49.2513 (57.5457) nleep/row_min_mean 1524.6536 (1508.1520) lr 1.6374e-03 eta 0:13:01
epoch [16/50] batch [160/173] time 0.073 (0.129) data 0.000 (0.002) loss 1.2931 (1.4221) teacher_loss 0.1227 (0.2260) loss_zs_kd 0.0191 (0.0250) loss_oracle 0.6183 (0.5677) kd_loss 0.8517 (0.8997) acc 100.0000 (90.8594) gate/entropy 1.0024 (1.0037) gate/usage_max 0.5473 (0.5458) gate/usage_min 0.2218 (0.2243) gate/usage_std 0.1513 (0.1502) teacher/entropy 0.0355 (0.0314) teacher/usage_max 0.6707 (0.6289) teacher/usage_min 0.0001 (0.0012) teacher/usage_std 0.2738 (0.2634) nleep/row_max_mean 1559.7295 (1551.3806) nleep/row_max_std 37.6135 (57.5841) nleep/row_min_mean 1519.8472 (1508.2308) lr 1.6374e-03 eta 0:12:43
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,280
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [17/50] batch [20/173] time 0.083 (0.137) data 0.000 (0.018) loss 1.5978 (1.3991) teacher_loss 0.3331 (0.2441) loss_zs_kd 0.0129 (0.0267) loss_oracle 0.5754 (0.5787) kd_loss 0.9706 (0.8523) acc 87.5000 (90.4688) gate/entropy 1.0021 (1.0022) gate/usage_max 0.5476 (0.5474) gate/usage_min 0.2211 (0.2213) gate/usage_std 0.1516 (0.1514) teacher/entropy 0.0430 (0.0309) teacher/usage_max 0.5227 (0.6741) teacher/usage_min 0.0001 (0.0015) teacher/usage_std 0.2363 (0.2799) nleep/row_max_mean 1545.0062 (1547.2082) nleep/row_max_std 41.3054 (49.9513) nleep/row_min_mean 1508.8464 (1506.4221) lr 1.5878e-03 eta 0:13:22
epoch [17/50] batch [40/173] time 0.080 (0.132) data 0.000 (0.009) loss 1.5186 (1.4356) teacher_loss 0.3704 (0.2700) loss_zs_kd 0.0381 (0.0270) loss_oracle 0.5753 (0.5755) kd_loss 0.8415 (0.8644) acc 84.3750 (89.8438) gate/entropy 1.0019 (1.0021) gate/usage_max 0.5478 (0.5476) gate/usage_min 0.2206 (0.2211) gate/usage_std 0.1517 (0.1516) teacher/entropy 0.0031 (0.0272) teacher/usage_max 0.7182 (0.6640) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.2955 (0.2769) nleep/row_max_mean 1535.9568 (1550.0522) nleep/row_max_std 56.2180 (49.2372) nleep/row_min_mean 1491.8556 (1508.5388) lr 1.5878e-03 eta 0:12:48
epoch [17/50] batch [60/173] time 0.097 (0.123) data 0.001 (0.006) loss 1.3557 (1.4094) teacher_loss 0.1425 (0.2502) loss_zs_kd 0.0146 (0.0269) loss_oracle 0.5732 (0.5711) kd_loss 0.9193 (0.8602) acc 96.8750 (90.3125) gate/entropy 1.0016 (1.0020) gate/usage_max 0.5481 (0.5477) gate/usage_min 0.2202 (0.2208) gate/usage_std 0.1519 (0.1516) teacher/entropy 0.0365 (0.0273) teacher/usage_max 0.5890 (0.6688) teacher/usage_min 0.0312 (0.0014) teacher/usage_std 0.2301 (0.2788) nleep/row_max_mean 1559.9280 (1551.2013) nleep/row_max_std 53.7669 (49.6551) nleep/row_min_mean 1514.9290 (1509.4351) lr 1.5878e-03 eta 0:11:55
epoch [17/50] batch [80/173] time 0.096 (0.122) data 0.000 (0.005) loss 1.4367 (1.3909) teacher_loss 0.3115 (0.2343) loss_zs_kd 0.0348 (0.0262) loss_oracle 0.5908 (0.5657) kd_loss 0.8124 (0.8606) acc 87.5000 (91.0156) gate/entropy 1.0009 (1.0018) gate/usage_max 0.5489 (0.5478) gate/usage_min 0.2195 (0.2206) gate/usage_std 0.1525 (0.1517) teacher/entropy 0.0035 (0.0260) teacher/usage_max 0.7495 (0.6694) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3115 (0.2784) nleep/row_max_mean 1565.0947 (1551.8975) nleep/row_max_std 55.9445 (50.7615) nleep/row_min_mean 1523.6807 (1510.1779) lr 1.5878e-03 eta 0:11:48
epoch [17/50] batch [100/173] time 0.194 (0.123) data 0.000 (0.004) loss 1.2495 (1.3848) teacher_loss 0.1978 (0.2352) loss_zs_kd 0.0249 (0.0270) loss_oracle 0.5478 (0.5599) kd_loss 0.7653 (0.8562) acc 93.7500 (90.8438) gate/entropy 1.0009 (1.0017) gate/usage_max 0.5488 (0.5480) gate/usage_min 0.2193 (0.2204) gate/usage_std 0.1524 (0.1519) teacher/entropy 0.0388 (0.0268) teacher/usage_max 0.7635 (0.6733) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3191 (0.2796) nleep/row_max_mean 1540.6307 (1552.5490) nleep/row_max_std 62.8773 (52.0604) nleep/row_min_mean 1501.0635 (1510.9223) lr 1.5878e-03 eta 0:11:52
epoch [17/50] batch [120/173] time 0.095 (0.119) data 0.000 (0.003) loss 1.2879 (1.3757) teacher_loss 0.1856 (0.2253) loss_zs_kd 0.0238 (0.0263) loss_oracle 0.5558 (0.5619) kd_loss 0.8125 (0.8563) acc 90.6250 (91.1979) gate/entropy 1.0010 (1.0016) gate/usage_max 0.5487 (0.5481) gate/usage_min 0.2192 (0.2202) gate/usage_std 0.1524 (0.1519) teacher/entropy 0.0025 (0.0272) teacher/usage_max 0.7496 (0.6724) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3116 (0.2790) nleep/row_max_mean 1544.7468 (1552.3964) nleep/row_max_std 62.1608 (52.7557) nleep/row_min_mean 1501.7991 (1510.9826) lr 1.5878e-03 eta 0:11:24
epoch [17/50] batch [140/173] time 0.109 (0.117) data 0.000 (0.003) loss 1.4144 (1.3867) teacher_loss 0.1920 (0.2265) loss_zs_kd 0.0167 (0.0272) loss_oracle 0.6439 (0.5683) kd_loss 0.8921 (0.8625) acc 90.6250 (91.0714) gate/entropy 1.0013 (1.0015) gate/usage_max 0.5484 (0.5482) gate/usage_min 0.2190 (0.2200) gate/usage_std 0.1521 (0.1520) teacher/entropy 0.0039 (0.0259) teacher/usage_max 0.6564 (0.6663) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2681 (0.2766) nleep/row_max_mean 1546.3348 (1552.4289) nleep/row_max_std 65.5181 (52.9412) nleep/row_min_mean 1504.3770 (1511.1647) lr 1.5878e-03 eta 0:11:11
epoch [17/50] batch [160/173] time 0.167 (0.119) data 0.000 (0.002) loss 1.4289 (1.3859) teacher_loss 0.2209 (0.2252) loss_zs_kd 0.0244 (0.0271) loss_oracle 0.5479 (0.5675) kd_loss 0.9218 (0.8633) acc 90.6250 (91.2695) gate/entropy 1.0011 (1.0014) gate/usage_max 0.5486 (0.5483) gate/usage_min 0.2186 (0.2198) gate/usage_std 0.1523 (0.1521) teacher/entropy 0.0327 (0.0269) teacher/usage_max 0.5872 (0.6639) teacher/usage_min 0.0026 (0.0018) teacher/usage_std 0.2448 (0.2756) nleep/row_max_mean 1539.5037 (1552.1429) nleep/row_max_std 71.0304 (53.7047) nleep/row_min_mean 1502.0144 (1511.1622) lr 1.5878e-03 eta 0:11:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [18/50] batch [20/173] time 0.092 (0.133) data 0.000 (0.017) loss 1.4004 (1.3391) teacher_loss 0.1334 (0.1760) loss_zs_kd 0.0295 (0.0261) loss_oracle 0.5614 (0.5352) kd_loss 0.9716 (0.8824) acc 96.8750 (93.5938) gate/entropy 1.0001 (1.0005) gate/usage_max 0.5496 (0.5492) gate/usage_min 0.2175 (0.2179) gate/usage_std 0.1531 (0.1528) teacher/entropy 0.0008 (0.0229) teacher/usage_max 0.5624 (0.6525) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2411 (0.2694) nleep/row_max_mean 1572.0455 (1550.7759) nleep/row_max_std 51.2034 (54.9359) nleep/row_min_mean 1525.9122 (1510.4811) lr 1.5358e-03 eta 0:12:38
epoch [18/50] batch [40/173] time 0.092 (0.117) data 0.000 (0.009) loss 1.1491 (1.3436) teacher_loss 0.1315 (0.2070) loss_zs_kd 0.0135 (0.0255) loss_oracle 0.5265 (0.5354) kd_loss 0.7477 (0.8561) acc 93.7500 (91.9531) gate/entropy 1.0001 (1.0005) gate/usage_max 0.5497 (0.5492) gate/usage_min 0.2173 (0.2177) gate/usage_std 0.1531 (0.1528) teacher/entropy 0.0241 (0.0242) teacher/usage_max 0.7980 (0.6771) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.3388 (0.2810) nleep/row_max_mean 1555.9167 (1549.7913) nleep/row_max_std 65.3737 (54.3640) nleep/row_min_mean 1512.2209 (1509.5783) lr 1.5358e-03 eta 0:11:01
epoch [18/50] batch [60/173] time 0.092 (0.107) data 0.000 (0.006) loss 1.1829 (1.3480) teacher_loss 0.1668 (0.2057) loss_zs_kd 0.0162 (0.0251) loss_oracle 0.4282 (0.5321) kd_loss 0.7939 (0.8637) acc 93.7500 (92.0312) gate/entropy 1.0003 (1.0005) gate/usage_max 0.5494 (0.5492) gate/usage_min 0.2172 (0.2176) gate/usage_std 0.1529 (0.1528) teacher/entropy 0.0182 (0.0240) teacher/usage_max 0.7518 (0.6678) teacher/usage_min 0.0005 (0.0049) teacher/usage_std 0.3126 (0.2764) nleep/row_max_mean 1547.2155 (1549.3633) nleep/row_max_std 57.0342 (53.9802) nleep/row_min_mean 1507.7466 (1509.9026) lr 1.5358e-03 eta 0:10:02
epoch [18/50] batch [80/173] time 0.095 (0.104) data 0.000 (0.004) loss 1.2825 (1.3447) teacher_loss 0.0961 (0.2054) loss_zs_kd 0.0117 (0.0253) loss_oracle 0.5085 (0.5337) kd_loss 0.9263 (0.8598) acc 96.8750 (91.9531) gate/entropy 1.0003 (1.0004) gate/usage_max 0.5494 (0.5493) gate/usage_min 0.2170 (0.2174) gate/usage_std 0.1529 (0.1529) teacher/entropy 0.0328 (0.0237) teacher/usage_max 0.5804 (0.6715) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2447 (0.2773) nleep/row_max_mean 1538.0793 (1548.7917) nleep/row_max_std 45.7295 (53.4748) nleep/row_min_mean 1499.2137 (1509.1747) lr 1.5358e-03 eta 0:09:46
epoch [18/50] batch [100/173] time 0.083 (0.100) data 0.000 (0.004) loss 1.5165 (1.3390) teacher_loss 0.3963 (0.2031) loss_zs_kd 0.0212 (0.0240) loss_oracle 0.4765 (0.5349) kd_loss 0.8714 (0.8565) acc 90.6250 (92.1250) gate/entropy 0.9999 (1.0003) gate/usage_max 0.5498 (0.5494) gate/usage_min 0.2167 (0.2173) gate/usage_std 0.1532 (0.1529) teacher/entropy 0.0319 (0.0237) teacher/usage_max 0.6448 (0.6745) teacher/usage_min 0.0317 (0.0063) teacher/usage_std 0.2504 (0.2782) nleep/row_max_mean 1542.3130 (1547.1179) nleep/row_max_std 55.6903 (53.3997) nleep/row_min_mean 1504.9919 (1507.8234) lr 1.5358e-03 eta 0:09:23
epoch [18/50] batch [120/173] time 0.144 (0.109) data 0.000 (0.003) loss 1.3723 (1.3423) teacher_loss 0.1473 (0.2060) loss_zs_kd 0.0342 (0.0237) loss_oracle 0.4796 (0.5349) kd_loss 0.9681 (0.8570) acc 96.8750 (92.0052) gate/entropy 0.9995 (1.0002) gate/usage_max 0.5503 (0.5495) gate/usage_min 0.2163 (0.2172) gate/usage_std 0.1536 (0.1530) teacher/entropy 0.0040 (0.0240) teacher/usage_max 0.5627 (0.6730) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.2412 (0.2774) nleep/row_max_mean 1540.8450 (1546.4935) nleep/row_max_std 49.5285 (53.0879) nleep/row_min_mean 1503.8562 (1507.1846) lr 1.5358e-03 eta 0:10:08
epoch [18/50] batch [140/173] time 0.148 (0.115) data 0.000 (0.003) loss 1.5046 (1.3407) teacher_loss 0.3417 (0.2094) loss_zs_kd 0.0517 (0.0245) loss_oracle 0.5190 (0.5315) kd_loss 0.8776 (0.8533) acc 87.5000 (92.1429) gate/entropy 0.9992 (1.0001) gate/usage_max 0.5505 (0.5496) gate/usage_min 0.2160 (0.2170) gate/usage_std 0.1537 (0.1531) teacher/entropy 0.0420 (0.0235) teacher/usage_max 0.6249 (0.6774) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.2568 (0.2793) nleep/row_max_mean 1548.8038 (1546.8906) nleep/row_max_std 38.2768 (52.6878) nleep/row_min_mean 1513.2402 (1507.2917) lr 1.5358e-03 eta 0:10:39
epoch [18/50] batch [160/173] time 0.163 (0.119) data 0.000 (0.002) loss 1.5506 (1.3478) teacher_loss 0.4568 (0.2204) loss_zs_kd 0.0238 (0.0248) loss_oracle 0.5054 (0.5289) kd_loss 0.8292 (0.8505) acc 81.2500 (91.7773) gate/entropy 0.9989 (1.0000) gate/usage_max 0.5509 (0.5497) gate/usage_min 0.2157 (0.2169) gate/usage_std 0.1540 (0.1532) teacher/entropy 0.0078 (0.0234) teacher/usage_max 0.7195 (0.6803) teacher/usage_min 0.0000 (0.0058) teacher/usage_std 0.2961 (0.2809) nleep/row_max_mean 1551.5685 (1547.4248) nleep/row_max_std 51.2725 (52.2711) nleep/row_min_mean 1505.9614 (1507.4859) lr 1.5358e-03 eta 0:11:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [19/50] batch [20/173] time 0.160 (0.183) data 0.000 (0.016) loss 1.2351 (1.3548) teacher_loss 0.1628 (0.3072) loss_zs_kd 0.0035 (0.0208) loss_oracle 0.5792 (0.5206) kd_loss 0.7809 (0.7769) acc 93.7500 (88.2812) gate/entropy 0.9992 (0.9987) gate/usage_max 0.5506 (0.5512) gate/usage_min 0.2159 (0.2156) gate/usage_std 0.1538 (0.1542) teacher/entropy 0.0038 (0.0286) teacher/usage_max 0.7806 (0.7563) teacher/usage_min 0.0001 (0.0049) teacher/usage_std 0.3287 (0.3167) nleep/row_max_mean 1551.9375 (1555.1427) nleep/row_max_std 52.9000 (55.7895) nleep/row_min_mean 1508.6674 (1509.7559) lr 1.4818e-03 eta 0:16:50
epoch [19/50] batch [40/173] time 0.158 (0.171) data 0.000 (0.008) loss 1.2635 (1.3084) teacher_loss 0.2791 (0.2821) loss_zs_kd 0.0252 (0.0205) loss_oracle 0.5342 (0.5201) kd_loss 0.7047 (0.7560) acc 90.6250 (89.2188) gate/entropy 0.9979 (0.9985) gate/usage_max 0.5520 (0.5514) gate/usage_min 0.2153 (0.2156) gate/usage_std 0.1548 (0.1543) teacher/entropy 0.0505 (0.0297) teacher/usage_max 0.8134 (0.7790) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3479 (0.3303) nleep/row_max_mean 1563.6035 (1555.3665) nleep/row_max_std 57.7889 (56.0965) nleep/row_min_mean 1517.7832 (1509.9442) lr 1.4818e-03 eta 0:15:40
epoch [19/50] batch [60/173] time 0.103 (0.162) data 0.001 (0.006) loss 1.2733 (1.3146) teacher_loss 0.2180 (0.3006) loss_zs_kd 0.0138 (0.0222) loss_oracle 0.5009 (0.5181) kd_loss 0.7980 (0.7439) acc 87.5000 (87.9688) gate/entropy 0.9976 (0.9982) gate/usage_max 0.5524 (0.5516) gate/usage_min 0.2154 (0.2155) gate/usage_std 0.1551 (0.1545) teacher/entropy 0.0113 (0.0287) teacher/usage_max 0.7518 (0.7939) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.3128 (0.3387) nleep/row_max_mean 1555.7661 (1555.9570) nleep/row_max_std 60.1714 (56.3369) nleep/row_min_mean 1509.6628 (1509.8723) lr 1.4818e-03 eta 0:14:44
epoch [19/50] batch [80/173] time 0.131 (0.149) data 0.000 (0.004) loss 1.2261 (1.3049) teacher_loss 0.3059 (0.3098) loss_zs_kd 0.0135 (0.0218) loss_oracle 0.5232 (0.5079) kd_loss 0.6518 (0.7302) acc 90.6250 (87.8906) gate/entropy 0.9974 (0.9980) gate/usage_max 0.5526 (0.5519) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1552 (0.1547) teacher/entropy 0.0317 (0.0271) teacher/usage_max 0.8959 (0.8113) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.4001 (0.3490) nleep/row_max_mean 1543.3154 (1557.4258) nleep/row_max_std 65.3514 (56.3846) nleep/row_min_mean 1500.0173 (1510.4263) lr 1.4818e-03 eta 0:13:35
epoch [19/50] batch [100/173] time 0.073 (0.138) data 0.000 (0.003) loss 1.2948 (1.2952) teacher_loss 0.2867 (0.3086) loss_zs_kd 0.0234 (0.0209) loss_oracle 0.4497 (0.5073) kd_loss 0.7716 (0.7225) acc 87.5000 (87.7812) gate/entropy 0.9961 (0.9977) gate/usage_max 0.5540 (0.5523) gate/usage_min 0.2150 (0.2154) gate/usage_std 0.1562 (0.1550) teacher/entropy 0.0262 (0.0258) teacher/usage_max 0.7632 (0.8214) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.3190 (0.3549) nleep/row_max_mean 1543.0894 (1558.2457) nleep/row_max_std 57.2068 (56.5261) nleep/row_min_mean 1497.7468 (1510.7720) lr 1.4818e-03 eta 0:12:28
epoch [19/50] batch [120/173] time 0.072 (0.134) data 0.000 (0.003) loss 1.3018 (1.2908) teacher_loss 0.3151 (0.3046) loss_zs_kd 0.0254 (0.0212) loss_oracle 0.5861 (0.5106) kd_loss 0.6809 (0.7203) acc 87.5000 (88.2292) gate/entropy 0.9959 (0.9974) gate/usage_max 0.5543 (0.5526) gate/usage_min 0.2151 (0.2153) gate/usage_std 0.1563 (0.1552) teacher/entropy 0.0495 (0.0253) teacher/usage_max 0.8389 (0.8242) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.3635 (0.3566) nleep/row_max_mean 1549.9589 (1557.1260) nleep/row_max_std 59.4851 (56.7956) nleep/row_min_mean 1499.2781 (1509.7297) lr 1.4818e-03 eta 0:12:07
epoch [19/50] batch [140/173] time 0.173 (0.131) data 0.000 (0.003) loss 1.5567 (1.2829) teacher_loss 0.4238 (0.2982) loss_zs_kd 0.0189 (0.0203) loss_oracle 0.5907 (0.5130) kd_loss 0.8282 (0.7181) acc 87.5000 (88.4375) gate/entropy 0.9951 (0.9971) gate/usage_max 0.5552 (0.5529) gate/usage_min 0.2149 (0.2153) gate/usage_std 0.1570 (0.1554) teacher/entropy 0.0110 (0.0261) teacher/usage_max 0.7159 (0.8256) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2943 (0.3573) nleep/row_max_mean 1558.0184 (1556.7574) nleep/row_max_std 61.4613 (56.8745) nleep/row_min_mean 1510.7338 (1509.6116) lr 1.4818e-03 eta 0:11:49
epoch [19/50] batch [160/173] time 0.080 (0.128) data 0.000 (0.002) loss 1.2722 (1.2797) teacher_loss 0.3189 (0.2978) loss_zs_kd 0.0228 (0.0196) loss_oracle 0.5514 (0.5126) kd_loss 0.6662 (0.7158) acc 87.5000 (88.5742) gate/entropy 0.9946 (0.9969) gate/usage_max 0.5557 (0.5532) gate/usage_min 0.2148 (0.2152) gate/usage_std 0.1574 (0.1556) teacher/entropy 0.0056 (0.0255) teacher/usage_max 0.9052 (0.8286) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.4062 (0.3590) nleep/row_max_mean 1561.1610 (1556.5872) nleep/row_max_std 56.5475 (56.3823) nleep/row_min_mean 1511.9999 (1509.6136) lr 1.4818e-03 eta 0:11:29
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [20/50] batch [20/173] time 0.163 (0.142) data 0.000 (0.016) loss 1.2761 (1.2913) teacher_loss 0.2488 (0.3013) loss_zs_kd 0.0051 (0.0147) loss_oracle 0.4560 (0.5152) kd_loss 0.7967 (0.7251) acc 90.6250 (89.0625) gate/entropy 0.9940 (0.9942) gate/usage_max 0.5565 (0.5562) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1579 (0.1577) teacher/entropy 0.0214 (0.0275) teacher/usage_max 0.7394 (0.8135) teacher/usage_min 0.0000 (0.0086) teacher/usage_std 0.3062 (0.3485) nleep/row_max_mean 1553.4305 (1554.5065) nleep/row_max_std 51.0905 (55.3349) nleep/row_min_mean 1513.0292 (1510.7787) lr 1.4258e-03 eta 0:12:39
epoch [20/50] batch [40/173] time 0.162 (0.147) data 0.000 (0.008) loss 1.2672 (1.2876) teacher_loss 0.3179 (0.2993) loss_zs_kd 0.0214 (0.0162) loss_oracle 0.4626 (0.5035) kd_loss 0.7073 (0.7284) acc 81.2500 (88.7500) gate/entropy 0.9932 (0.9940) gate/usage_max 0.5573 (0.5564) gate/usage_min 0.2144 (0.2147) gate/usage_std 0.1584 (0.1579) teacher/entropy 0.0192 (0.0277) teacher/usage_max 0.8407 (0.8091) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.3646 (0.3463) nleep/row_max_mean 1564.7156 (1554.8455) nleep/row_max_std 50.4546 (53.0226) nleep/row_min_mean 1519.1252 (1510.9751) lr 1.4258e-03 eta 0:13:04
epoch [20/50] batch [60/173] time 0.145 (0.151) data 0.001 (0.006) loss 1.1222 (1.2811) teacher_loss 0.1673 (0.3027) loss_zs_kd 0.0092 (0.0160) loss_oracle 0.4803 (0.5026) kd_loss 0.7102 (0.7190) acc 93.7500 (88.7500) gate/entropy 0.9930 (0.9938) gate/usage_max 0.5576 (0.5566) gate/usage_min 0.2144 (0.2146) gate/usage_std 0.1587 (0.1580) teacher/entropy 0.0449 (0.0282) teacher/usage_max 0.8084 (0.8188) teacher/usage_min 0.0003 (0.0044) teacher/usage_std 0.3449 (0.3524) nleep/row_max_mean 1553.4996 (1551.7104) nleep/row_max_std 35.5089 (54.0456) nleep/row_min_mean 1517.1383 (1508.7037) lr 1.4258e-03 eta 0:13:19
epoch [20/50] batch [80/173] time 0.144 (0.151) data 0.000 (0.004) loss 1.3333 (1.2860) teacher_loss 0.2873 (0.3049) loss_zs_kd 0.0157 (0.0152) loss_oracle 0.5280 (0.5057) kd_loss 0.7741 (0.7206) acc 84.3750 (88.8281) gate/entropy 0.9928 (0.9936) gate/usage_max 0.5577 (0.5569) gate/usage_min 0.2144 (0.2146) gate/usage_std 0.1588 (0.1582) teacher/entropy 0.0350 (0.0287) teacher/usage_max 0.7487 (0.8160) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.3111 (0.3508) nleep/row_max_mean 1540.0609 (1551.5232) nleep/row_max_std 57.9237 (53.9327) nleep/row_min_mean 1500.8440 (1508.6016) lr 1.4258e-03 eta 0:13:17
epoch [20/50] batch [100/173] time 0.140 (0.152) data 0.000 (0.003) loss 1.5669 (1.2887) teacher_loss 0.5092 (0.3047) loss_zs_kd 0.0105 (0.0143) loss_oracle 0.6525 (0.5113) kd_loss 0.7262 (0.7212) acc 81.2500 (88.7812) gate/entropy 0.9928 (0.9935) gate/usage_max 0.5578 (0.5570) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1588 (0.1583) teacher/entropy 0.0231 (0.0291) teacher/usage_max 0.8165 (0.8149) teacher/usage_min 0.0300 (0.0040) teacher/usage_std 0.3454 (0.3498) nleep/row_max_mean 1537.6948 (1550.9186) nleep/row_max_std 60.5228 (53.7150) nleep/row_min_mean 1498.1637 (1508.2250) lr 1.4258e-03 eta 0:13:18
epoch [20/50] batch [120/173] time 0.159 (0.154) data 0.000 (0.003) loss 1.1926 (1.2828) teacher_loss 0.2881 (0.3015) loss_zs_kd 0.0136 (0.0141) loss_oracle 0.4809 (0.5104) kd_loss 0.6573 (0.7190) acc 87.5000 (88.8021) gate/entropy 0.9922 (0.9933) gate/usage_max 0.5585 (0.5572) gate/usage_min 0.2142 (0.2145) gate/usage_std 0.1593 (0.1584) teacher/entropy 0.0115 (0.0302) teacher/usage_max 0.9038 (0.8159) teacher/usage_min 0.0008 (0.0038) teacher/usage_std 0.4053 (0.3504) nleep/row_max_mean 1557.1741 (1551.3960) nleep/row_max_std 56.5932 (53.0162) nleep/row_min_mean 1510.6943 (1508.7641) lr 1.4258e-03 eta 0:13:26
epoch [20/50] batch [140/173] time 0.160 (0.156) data 0.000 (0.003) loss 1.2531 (1.2741) teacher_loss 0.3289 (0.2965) loss_zs_kd 0.0062 (0.0137) loss_oracle 0.4760 (0.5103) kd_loss 0.6831 (0.7156) acc 93.7500 (88.9955) gate/entropy 0.9918 (0.9931) gate/usage_max 0.5588 (0.5574) gate/usage_min 0.2142 (0.2145) gate/usage_std 0.1595 (0.1585) teacher/entropy 0.0267 (0.0307) teacher/usage_max 0.8580 (0.8189) teacher/usage_min 0.0009 (0.0039) teacher/usage_std 0.3754 (0.3522) nleep/row_max_mean 1554.9220 (1551.5296) nleep/row_max_std 59.5688 (52.9077) nleep/row_min_mean 1515.5565 (1508.9947) lr 1.4258e-03 eta 0:13:36
epoch [20/50] batch [160/173] time 0.179 (0.157) data 0.000 (0.002) loss 0.9990 (1.2643) teacher_loss 0.1502 (0.2895) loss_zs_kd 0.0061 (0.0132) loss_oracle 0.3605 (0.5066) kd_loss 0.6654 (0.7149) acc 93.7500 (89.3555) gate/entropy 0.9922 (0.9929) gate/usage_max 0.5584 (0.5576) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1592 (0.1587) teacher/entropy 0.0738 (0.0312) teacher/usage_max 0.8258 (0.8189) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.3554 (0.3522) nleep/row_max_mean 1535.4075 (1551.6328) nleep/row_max_std 51.7463 (52.6063) nleep/row_min_mean 1498.6423 (1509.2099) lr 1.4258e-03 eta 0:13:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [21/50] batch [20/173] time 0.088 (0.141) data 0.000 (0.020) loss 1.3643 (1.2671) teacher_loss 0.4402 (0.2854) loss_zs_kd 0.0142 (0.0137) loss_oracle 0.4633 (0.5171) kd_loss 0.6854 (0.7164) acc 81.2500 (88.1250) gate/entropy 0.9912 (0.9915) gate/usage_max 0.5595 (0.5592) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1600 (0.1598) teacher/entropy 0.0106 (0.0273) teacher/usage_max 0.8727 (0.8201) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3849 (0.3530) nleep/row_max_mean 1558.2882 (1550.9502) nleep/row_max_std 44.6489 (49.1902) nleep/row_min_mean 1510.5042 (1508.8244) lr 1.3681e-03 eta 0:12:10
epoch [21/50] batch [40/173] time 0.094 (0.125) data 0.000 (0.010) loss 1.2807 (1.2667) teacher_loss 0.2458 (0.2799) loss_zs_kd 0.0120 (0.0154) loss_oracle 0.4373 (0.5099) kd_loss 0.8102 (0.7242) acc 87.5000 (88.7500) gate/entropy 0.9912 (0.9913) gate/usage_max 0.5595 (0.5594) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1600 (0.1599) teacher/entropy 0.0428 (0.0288) teacher/usage_max 0.7012 (0.8099) teacher/usage_min 0.0396 (0.0061) teacher/usage_std 0.2752 (0.3477) nleep/row_max_mean 1542.1484 (1550.7856) nleep/row_max_std 55.6429 (51.8063) nleep/row_min_mean 1504.5698 (1508.1854) lr 1.3681e-03 eta 0:10:43
epoch [21/50] batch [60/173] time 0.071 (0.120) data 0.001 (0.007) loss 1.2558 (1.2541) teacher_loss 0.3834 (0.2834) loss_zs_kd 0.0088 (0.0151) loss_oracle 0.5934 (0.5037) kd_loss 0.5713 (0.7113) acc 84.3750 (88.7500) gate/entropy 0.9912 (0.9911) gate/usage_max 0.5596 (0.5596) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1600 (0.1601) teacher/entropy 0.0300 (0.0269) teacher/usage_max 0.9781 (0.8261) teacher/usage_min 0.0020 (0.0068) teacher/usage_std 0.4559 (0.3571) nleep/row_max_mean 1540.7528 (1551.5799) nleep/row_max_std 58.8333 (52.6653) nleep/row_min_mean 1499.2500 (1508.5715) lr 1.3681e-03 eta 0:10:13
epoch [21/50] batch [80/173] time 0.100 (0.116) data 0.000 (0.005) loss 1.2661 (1.2543) teacher_loss 0.2958 (0.2837) loss_zs_kd 0.0253 (0.0150) loss_oracle 0.4580 (0.5033) kd_loss 0.7287 (0.7115) acc 90.6250 (88.7891) gate/entropy 0.9904 (0.9910) gate/usage_max 0.5604 (0.5598) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1606 (0.1602) teacher/entropy 0.0265 (0.0251) teacher/usage_max 0.8062 (0.8278) teacher/usage_min 0.0029 (0.0070) teacher/usage_std 0.3430 (0.3577) nleep/row_max_mean 1547.6788 (1551.3353) nleep/row_max_std 54.2182 (53.2834) nleep/row_min_mean 1507.1270 (1508.3321) lr 1.3681e-03 eta 0:09:53
epoch [21/50] batch [100/173] time 0.194 (0.118) data 0.000 (0.004) loss 1.2037 (1.2559) teacher_loss 0.2318 (0.2832) loss_zs_kd 0.0206 (0.0149) loss_oracle 0.4470 (0.5035) kd_loss 0.7382 (0.7136) acc 90.6250 (88.8125) gate/entropy 0.9899 (0.9908) gate/usage_max 0.5609 (0.5599) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1610 (0.1603) teacher/entropy 0.0121 (0.0234) teacher/usage_max 0.8119 (0.8272) teacher/usage_min 0.0002 (0.0087) teacher/usage_std 0.3470 (0.3569) nleep/row_max_mean 1552.7386 (1550.9986) nleep/row_max_std 59.6828 (54.0341) nleep/row_min_mean 1509.8353 (1507.8846) lr 1.3681e-03 eta 0:10:01
epoch [21/50] batch [120/173] time 0.188 (0.122) data 0.000 (0.004) loss 1.0524 (1.2525) teacher_loss 0.1541 (0.2795) loss_zs_kd 0.0153 (0.0149) loss_oracle 0.4191 (0.5022) kd_loss 0.6811 (0.7145) acc 93.7500 (88.9062) gate/entropy 0.9900 (0.9907) gate/usage_max 0.5608 (0.5601) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1609 (0.1604) teacher/entropy 0.0141 (0.0251) teacher/usage_max 0.8715 (0.8243) teacher/usage_min 0.0000 (0.0094) teacher/usage_std 0.3842 (0.3549) nleep/row_max_mean 1544.2063 (1549.4903) nleep/row_max_std 56.9979 (54.9742) nleep/row_min_mean 1502.6770 (1506.7797) lr 1.3681e-03 eta 0:10:19
epoch [21/50] batch [140/173] time 0.170 (0.127) data 0.000 (0.003) loss 1.0883 (1.2525) teacher_loss 0.1485 (0.2825) loss_zs_kd 0.0070 (0.0149) loss_oracle 0.4864 (0.4986) kd_loss 0.6931 (0.7132) acc 93.7500 (88.8839) gate/entropy 0.9896 (0.9905) gate/usage_max 0.5613 (0.5602) gate/usage_min 0.2138 (0.2140) gate/usage_std 0.1613 (0.1605) teacher/entropy 0.0514 (0.0248) teacher/usage_max 0.8170 (0.8258) teacher/usage_min 0.0000 (0.0087) teacher/usage_std 0.3501 (0.3558) nleep/row_max_mean 1553.6184 (1549.2815) nleep/row_max_std 55.0302 (55.2856) nleep/row_min_mean 1509.5574 (1506.8515) lr 1.3681e-03 eta 0:10:42
epoch [21/50] batch [160/173] time 0.192 (0.130) data 0.000 (0.003) loss 1.2621 (1.2492) teacher_loss 0.2536 (0.2781) loss_zs_kd 0.0163 (0.0147) loss_oracle 0.4911 (0.4971) kd_loss 0.7549 (0.7152) acc 90.6250 (89.1211) gate/entropy 0.9895 (0.9904) gate/usage_max 0.5614 (0.5604) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1613 (0.1606) teacher/entropy 0.0195 (0.0233) teacher/usage_max 0.7846 (0.8252) teacher/usage_min 0.0000 (0.0085) teacher/usage_std 0.3310 (0.3554) nleep/row_max_mean 1545.4811 (1549.1605) nleep/row_max_std 65.1521 (55.9035) nleep/row_min_mean 1503.5112 (1506.6888) lr 1.3681e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.4%, epoch: 10 *******
******* Domain a best val test acc: 97.7%, epoch: 10 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [22/50] batch [20/173] time 0.134 (0.171) data 0.000 (0.016) loss 1.1645 (1.3369) teacher_loss 0.1475 (0.3513) loss_zs_kd 0.0182 (0.0190) loss_oracle 0.5285 (0.5024) kd_loss 0.7436 (0.7249) acc 93.7500 (87.3438) gate/entropy 0.9893 (0.9890) gate/usage_max 0.5616 (0.5619) gate/usage_min 0.2139 (0.2137) gate/usage_std 0.1614 (0.1617) teacher/entropy 0.0461 (0.0235) teacher/usage_max 0.7683 (0.8132) teacher/usage_min 0.0001 (0.0121) teacher/usage_std 0.3218 (0.3500) nleep/row_max_mean 1540.7574 (1551.2462) nleep/row_max_std 68.2090 (59.8697) nleep/row_min_mean 1500.4216 (1508.9700) lr 1.3090e-03 eta 0:14:15
epoch [22/50] batch [40/173] time 0.108 (0.154) data 0.000 (0.008) loss 1.4510 (1.2941) teacher_loss 0.4298 (0.3160) loss_zs_kd 0.0158 (0.0161) loss_oracle 0.4972 (0.4995) kd_loss 0.7646 (0.7203) acc 81.2500 (88.9062) gate/entropy 0.9887 (0.9889) gate/usage_max 0.5622 (0.5620) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1619 (0.1618) teacher/entropy 0.0385 (0.0276) teacher/usage_max 0.7527 (0.8137) teacher/usage_min 0.0000 (0.0135) teacher/usage_std 0.3132 (0.3488) nleep/row_max_mean 1551.7924 (1552.8819) nleep/row_max_std 61.7974 (61.0286) nleep/row_min_mean 1505.9724 (1509.7241) lr 1.3090e-03 eta 0:12:48
epoch [22/50] batch [60/173] time 0.181 (0.153) data 0.001 (0.006) loss 1.1326 (1.2778) teacher_loss 0.1282 (0.2975) loss_zs_kd 0.0106 (0.0151) loss_oracle 0.4668 (0.5013) kd_loss 0.7657 (0.7221) acc 96.8750 (88.9583) gate/entropy 0.9890 (0.9888) gate/usage_max 0.5619 (0.5621) gate/usage_min 0.2139 (0.2137) gate/usage_std 0.1617 (0.1618) teacher/entropy 0.0354 (0.0289) teacher/usage_max 0.7575 (0.8103) teacher/usage_min 0.0313 (0.0131) teacher/usage_std 0.3088 (0.3464) nleep/row_max_mean 1527.2872 (1553.5584) nleep/row_max_std 77.2865 (60.9533) nleep/row_min_mean 1487.1680 (1510.3028) lr 1.3090e-03 eta 0:12:38
epoch [22/50] batch [80/173] time 0.136 (0.141) data 0.000 (0.004) loss 1.2222 (1.2785) teacher_loss 0.3200 (0.2932) loss_zs_kd 0.0123 (0.0153) loss_oracle 0.4718 (0.5046) kd_loss 0.6602 (0.7254) acc 84.3750 (88.8672) gate/entropy 0.9883 (0.9887) gate/usage_max 0.5627 (0.5622) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1622 (0.1619) teacher/entropy 0.0435 (0.0305) teacher/usage_max 0.8610 (0.8047) teacher/usage_min 0.0073 (0.0117) teacher/usage_std 0.3766 (0.3433) nleep/row_max_mean 1563.5671 (1554.9592) nleep/row_max_std 54.0896 (60.4780) nleep/row_min_mean 1521.4629 (1511.7199) lr 1.3090e-03 eta 0:11:33
epoch [22/50] batch [100/173] time 0.161 (0.137) data 0.000 (0.003) loss 1.2917 (1.2767) teacher_loss 0.3437 (0.2933) loss_zs_kd 0.0063 (0.0150) loss_oracle 0.5045 (0.5031) kd_loss 0.6926 (0.7243) acc 93.7500 (88.9688) gate/entropy 0.9880 (0.9886) gate/usage_max 0.5630 (0.5623) gate/usage_min 0.2135 (0.2137) gate/usage_std 0.1625 (0.1620) teacher/entropy 0.0428 (0.0315) teacher/usage_max 0.8254 (0.8046) teacher/usage_min 0.0011 (0.0115) teacher/usage_std 0.3550 (0.3434) nleep/row_max_mean 1568.4988 (1555.6983) nleep/row_max_std 46.2977 (59.6893) nleep/row_min_mean 1525.8197 (1512.7103) lr 1.3090e-03 eta 0:11:13
epoch [22/50] batch [120/173] time 0.089 (0.132) data 0.000 (0.003) loss 1.3014 (1.2772) teacher_loss 0.3136 (0.2863) loss_zs_kd 0.0248 (0.0148) loss_oracle 0.5502 (0.5037) kd_loss 0.7003 (0.7317) acc 87.5000 (89.2708) gate/entropy 0.9880 (0.9886) gate/usage_max 0.5629 (0.5624) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1624 (0.1620) teacher/entropy 0.0459 (0.0315) teacher/usage_max 0.8168 (0.7967) teacher/usage_min 0.0617 (0.0142) teacher/usage_std 0.3428 (0.3382) nleep/row_max_mean 1551.8347 (1554.5041) nleep/row_max_std 58.3496 (60.3345) nleep/row_min_mean 1510.9536 (1512.1310) lr 1.3090e-03 eta 0:10:48
epoch [22/50] batch [140/173] time 0.181 (0.127) data 0.000 (0.002) loss 1.5318 (1.2841) teacher_loss 0.4454 (0.2899) loss_zs_kd 0.0429 (0.0154) loss_oracle 0.5943 (0.5077) kd_loss 0.7679 (0.7326) acc 81.2500 (89.1964) gate/entropy 0.9872 (0.9885) gate/usage_max 0.5638 (0.5625) gate/usage_min 0.2133 (0.2136) gate/usage_std 0.1630 (0.1621) teacher/entropy 0.0067 (0.0308) teacher/usage_max 0.7820 (0.7963) teacher/usage_min 0.0000 (0.0148) teacher/usage_std 0.3295 (0.3378) nleep/row_max_mean 1576.5668 (1554.4268) nleep/row_max_std 52.7487 (60.3896) nleep/row_min_mean 1532.2015 (1512.2429) lr 1.3090e-03 eta 0:10:18
epoch [22/50] batch [160/173] time 0.080 (0.125) data 0.000 (0.002) loss 1.3554 (1.2936) teacher_loss 0.2916 (0.2879) loss_zs_kd 0.0233 (0.0159) loss_oracle 0.5701 (0.5136) kd_loss 0.7671 (0.7410) acc 90.6250 (89.3359) gate/entropy 0.9879 (0.9884) gate/usage_max 0.5631 (0.5625) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1625 (0.1621) teacher/entropy 0.0566 (0.0328) teacher/usage_max 0.7309 (0.7852) teacher/usage_min 0.0402 (0.0183) teacher/usage_std 0.2915 (0.3307) nleep/row_max_mean 1557.5564 (1554.0794) nleep/row_max_std 58.9989 (59.8334) nleep/row_min_mean 1518.9146 (1512.3728) lr 1.3090e-03 eta 0:10:06
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.4%, epoch: 22 *******
******* Domain a best val test acc: 98.0%, epoch: 22 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [23/50] batch [20/173] time 0.158 (0.169) data 0.000 (0.014) loss 1.3541 (1.3369) teacher_loss 0.3749 (0.2961) loss_zs_kd 0.0322 (0.0210) loss_oracle 0.5253 (0.5068) kd_loss 0.7004 (0.7769) acc 84.3750 (88.2812) gate/entropy 0.9880 (0.9877) gate/usage_max 0.5630 (0.5633) gate/usage_min 0.2136 (0.2134) gate/usage_std 0.1624 (0.1627) teacher/entropy 0.0600 (0.0469) teacher/usage_max 0.8016 (0.7317) teacher/usage_min 0.0606 (0.0422) teacher/usage_std 0.3326 (0.2938) nleep/row_max_mean 1535.0166 (1556.4538) nleep/row_max_std 65.4184 (59.7187) nleep/row_min_mean 1504.3746 (1517.6853) lr 1.2487e-03 eta 0:13:33
epoch [23/50] batch [40/173] time 0.157 (0.165) data 0.000 (0.007) loss 1.5706 (1.2960) teacher_loss 0.3598 (0.2558) loss_zs_kd 0.0194 (0.0220) loss_oracle 0.6271 (0.5137) kd_loss 0.8876 (0.7724) acc 87.5000 (90.1562) gate/entropy 0.9874 (0.9877) gate/usage_max 0.5636 (0.5633) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1629 (0.1627) teacher/entropy 0.0056 (0.0403) teacher/usage_max 0.6555 (0.7434) teacher/usage_min 0.0310 (0.0359) teacher/usage_std 0.2553 (0.3021) nleep/row_max_mean 1558.5844 (1552.0745) nleep/row_max_std 45.4518 (57.9338) nleep/row_min_mean 1520.5679 (1514.2227) lr 1.2487e-03 eta 0:13:12
epoch [23/50] batch [60/173] time 0.156 (0.161) data 0.001 (0.005) loss 1.4333 (1.2830) teacher_loss 0.3893 (0.2426) loss_zs_kd 0.0173 (0.0220) loss_oracle 0.5910 (0.5237) kd_loss 0.7398 (0.7675) acc 84.3750 (90.8333) gate/entropy 0.9874 (0.9876) gate/usage_max 0.5636 (0.5634) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1629 (0.1627) teacher/entropy 0.0545 (0.0393) teacher/usage_max 0.7631 (0.7495) teacher/usage_min 0.0502 (0.0353) teacher/usage_std 0.3090 (0.3058) nleep/row_max_mean 1550.3083 (1553.2682) nleep/row_max_std 50.3125 (56.4031) nleep/row_min_mean 1513.8297 (1515.1290) lr 1.2487e-03 eta 0:12:50
epoch [23/50] batch [80/173] time 0.127 (0.156) data 0.000 (0.004) loss 1.3786 (1.2982) teacher_loss 0.2917 (0.2552) loss_zs_kd 0.0216 (0.0232) loss_oracle 0.5961 (0.5321) kd_loss 0.7781 (0.7654) acc 90.6250 (90.1953) gate/entropy 0.9875 (0.9875) gate/usage_max 0.5636 (0.5635) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1628 (0.1628) teacher/entropy 0.0471 (0.0426) teacher/usage_max 0.7342 (0.7483) teacher/usage_min 0.1277 (0.0390) teacher/usage_std 0.2835 (0.3045) nleep/row_max_mean 1545.6782 (1552.8089) nleep/row_max_std 56.8176 (55.6544) nleep/row_min_mean 1508.7081 (1514.8230) lr 1.2487e-03 eta 0:12:21
epoch [23/50] batch [100/173] time 0.150 (0.154) data 0.000 (0.003) loss 1.2623 (1.3069) teacher_loss 0.1493 (0.2567) loss_zs_kd 0.0186 (0.0228) loss_oracle 0.6199 (0.5351) kd_loss 0.7938 (0.7712) acc 100.0000 (90.2812) gate/entropy 0.9873 (0.9875) gate/usage_max 0.5638 (0.5635) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1630 (0.1628) teacher/entropy 0.0928 (0.0451) teacher/usage_max 0.6663 (0.7396) teacher/usage_min 0.1157 (0.0442) teacher/usage_std 0.2391 (0.2983) nleep/row_max_mean 1548.1199 (1551.8250) nleep/row_max_std 45.9762 (55.3434) nleep/row_min_mean 1509.7866 (1514.0698) lr 1.2487e-03 eta 0:12:10
epoch [23/50] batch [120/173] time 0.166 (0.155) data 0.000 (0.003) loss 1.2307 (1.3132) teacher_loss 0.3455 (0.2508) loss_zs_kd 0.0324 (0.0223) loss_oracle 0.5145 (0.5374) kd_loss 0.6117 (0.7825) acc 87.5000 (90.5990) gate/entropy 0.9871 (0.9874) gate/usage_max 0.5640 (0.5636) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1631 (0.1629) teacher/entropy 0.0798 (0.0448) teacher/usage_max 0.8747 (0.7277) teacher/usage_min 0.0596 (0.0448) teacher/usage_std 0.3828 (0.2921) nleep/row_max_mean 1557.2250 (1551.1264) nleep/row_max_std 63.1328 (55.3762) nleep/row_min_mean 1515.1687 (1513.5211) lr 1.2487e-03 eta 0:12:12
epoch [23/50] batch [140/173] time 0.140 (0.156) data 0.000 (0.002) loss 1.2664 (1.3214) teacher_loss 0.1903 (0.2560) loss_zs_kd 0.0109 (0.0218) loss_oracle 0.4947 (0.5368) kd_loss 0.8232 (0.7862) acc 90.6250 (90.2455) gate/entropy 0.9871 (0.9874) gate/usage_max 0.5640 (0.5636) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1631 (0.1629) teacher/entropy 0.0442 (0.0450) teacher/usage_max 0.6825 (0.7236) teacher/usage_min 0.0096 (0.0466) teacher/usage_std 0.2753 (0.2894) nleep/row_max_mean 1555.7507 (1550.2067) nleep/row_max_std 51.1472 (55.3801) nleep/row_min_mean 1516.0406 (1512.6192) lr 1.2487e-03 eta 0:12:13
epoch [23/50] batch [160/173] time 0.189 (0.157) data 0.000 (0.002) loss 1.2514 (1.3253) teacher_loss 0.1495 (0.2551) loss_zs_kd 0.0128 (0.0219) loss_oracle 0.4806 (0.5355) kd_loss 0.8551 (0.7915) acc 93.7500 (90.2148) gate/entropy 0.9874 (0.9873) gate/usage_max 0.5637 (0.5637) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1629 (0.1629) teacher/entropy 0.0728 (0.0448) teacher/usage_max 0.6204 (0.7181) teacher/usage_min 0.0758 (0.0485) teacher/usage_std 0.2233 (0.2861) nleep/row_max_mean 1535.5739 (1549.6388) nleep/row_max_std 63.2752 (55.2229) nleep/row_min_mean 1502.4602 (1512.0291) lr 1.2487e-03 eta 0:12:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,303
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [24/50] batch [20/173] time 0.092 (0.140) data 0.000 (0.017) loss 1.4330 (1.4192) teacher_loss 0.3340 (0.3138) loss_zs_kd 0.0316 (0.0234) loss_oracle 0.4974 (0.5393) kd_loss 0.8345 (0.8241) acc 84.3750 (87.1875) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5642 (0.5641) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1633 (0.1632) teacher/entropy 0.0289 (0.0348) teacher/usage_max 0.6893 (0.6936) teacher/usage_min 0.0608 (0.0525) teacher/usage_std 0.2633 (0.2733) nleep/row_max_mean 1539.2600 (1548.8648) nleep/row_max_std 51.9147 (57.1236) nleep/row_min_mean 1499.3937 (1508.1124) lr 1.1874e-03 eta 0:10:50
epoch [24/50] batch [40/173] time 0.093 (0.123) data 0.000 (0.009) loss 1.3486 (1.3902) teacher_loss 0.3188 (0.2873) loss_zs_kd 0.0120 (0.0226) loss_oracle 0.5141 (0.5439) kd_loss 0.7668 (0.8197) acc 84.3750 (88.3594) gate/entropy 0.9867 (0.9869) gate/usage_max 0.5643 (0.5641) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0217 (0.0335) teacher/usage_max 0.7691 (0.6997) teacher/usage_min 0.0435 (0.0523) teacher/usage_std 0.3137 (0.2764) nleep/row_max_mean 1550.5288 (1548.7977) nleep/row_max_std 65.4967 (56.1831) nleep/row_min_mean 1506.8684 (1508.1657) lr 1.1874e-03 eta 0:09:31
epoch [24/50] batch [60/173] time 0.173 (0.124) data 0.001 (0.006) loss 1.5799 (1.3815) teacher_loss 0.3764 (0.2702) loss_zs_kd 0.0328 (0.0249) loss_oracle 0.5485 (0.5517) kd_loss 0.9129 (0.8230) acc 84.3750 (89.4792) gate/entropy 0.9865 (0.9869) gate/usage_max 0.5646 (0.5642) gate/usage_min 0.2130 (0.2132) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0482 (0.0340) teacher/usage_max 0.5857 (0.6957) teacher/usage_min 0.0964 (0.0528) teacher/usage_std 0.2000 (0.2736) nleep/row_max_mean 1556.6095 (1548.0186) nleep/row_max_std 58.4633 (56.6656) nleep/row_min_mean 1515.4259 (1507.8822) lr 1.1874e-03 eta 0:09:29
epoch [24/50] batch [80/173] time 0.080 (0.118) data 0.000 (0.004) loss 1.4462 (1.3772) teacher_loss 0.3344 (0.2594) loss_zs_kd 0.0116 (0.0239) loss_oracle 0.5353 (0.5536) kd_loss 0.8384 (0.8290) acc 90.6250 (90.0000) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5642 (0.5642) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0261 (0.0345) teacher/usage_max 0.6867 (0.6888) teacher/usage_min 0.0457 (0.0580) teacher/usage_std 0.2658 (0.2684) nleep/row_max_mean 1559.4287 (1547.7138) nleep/row_max_std 62.8762 (56.4851) nleep/row_min_mean 1520.7893 (1508.0214) lr 1.1874e-03 eta 0:09:03
epoch [24/50] batch [100/173] time 0.096 (0.116) data 0.000 (0.004) loss 1.2418 (1.3829) teacher_loss 0.2462 (0.2671) loss_zs_kd 0.0292 (0.0240) loss_oracle 0.5035 (0.5522) kd_loss 0.7293 (0.8277) acc 93.7500 (89.7500) gate/entropy 0.9866 (0.9868) gate/usage_max 0.5645 (0.5642) gate/usage_min 0.2130 (0.2132) gate/usage_std 0.1635 (0.1633) teacher/entropy 0.0458 (0.0370) teacher/usage_max 0.7862 (0.6878) teacher/usage_min 0.1034 (0.0637) teacher/usage_std 0.3202 (0.2664) nleep/row_max_mean 1544.2721 (1547.7585) nleep/row_max_std 61.1392 (57.1068) nleep/row_min_mean 1510.1963 (1508.4044) lr 1.1874e-03 eta 0:08:52
epoch [24/50] batch [120/173] time 0.166 (0.117) data 0.000 (0.003) loss 1.1711 (1.3826) teacher_loss 0.2561 (0.2622) loss_zs_kd 0.0319 (0.0239) loss_oracle 0.4046 (0.5486) kd_loss 0.6968 (0.8342) acc 90.6250 (89.9219) gate/entropy 0.9865 (0.9868) gate/usage_max 0.5646 (0.5642) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0886 (0.0390) teacher/usage_max 0.7735 (0.6788) teacher/usage_min 0.0751 (0.0678) teacher/usage_std 0.3128 (0.2605) nleep/row_max_mean 1559.1689 (1547.2193) nleep/row_max_std 52.6189 (57.5710) nleep/row_min_mean 1521.7869 (1508.3696) lr 1.1874e-03 eta 0:08:51
epoch [24/50] batch [140/173] time 0.164 (0.122) data 0.000 (0.003) loss 1.6956 (1.3816) teacher_loss 0.3844 (0.2569) loss_zs_kd 0.0243 (0.0241) loss_oracle 0.5581 (0.5473) kd_loss 1.0200 (0.8390) acc 81.2500 (90.0670) gate/entropy 0.9866 (0.9868) gate/usage_max 0.5645 (0.5642) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1635 (0.1633) teacher/entropy 0.0314 (0.0403) teacher/usage_max 0.4864 (0.6724) teacher/usage_min 0.0467 (0.0688) teacher/usage_std 0.2028 (0.2570) nleep/row_max_mean 1541.3651 (1547.5930) nleep/row_max_std 48.2401 (57.1941) nleep/row_min_mean 1507.6696 (1509.0523) lr 1.1874e-03 eta 0:09:14
epoch [24/50] batch [160/173] time 0.163 (0.127) data 0.000 (0.002) loss 1.3030 (1.3809) teacher_loss 0.1952 (0.2537) loss_zs_kd 0.0194 (0.0241) loss_oracle 0.5537 (0.5474) kd_loss 0.8213 (0.8414) acc 93.7500 (90.2344) gate/entropy 0.9867 (0.9868) gate/usage_max 0.5644 (0.5643) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1634 (0.1633) teacher/entropy 0.0191 (0.0410) teacher/usage_max 0.7127 (0.6690) teacher/usage_min 0.0364 (0.0707) teacher/usage_std 0.2822 (0.2545) nleep/row_max_mean 1547.1150 (1548.0843) nleep/row_max_std 50.5289 (56.8133) nleep/row_min_mean 1510.2656 (1509.6766) lr 1.1874e-03 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,301
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,993
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [25/50] batch [20/173] time 0.157 (0.158) data 0.000 (0.014) loss 1.4749 (1.3581) teacher_loss 0.3653 (0.2206) loss_zs_kd 0.0214 (0.0246) loss_oracle 0.5504 (0.5388) kd_loss 0.8237 (0.8558) acc 87.5000 (92.6562) gate/entropy 0.9867 (0.9867) gate/usage_max 0.5644 (0.5644) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1634 (0.1634) teacher/entropy 0.0499 (0.0413) teacher/usage_max 0.6780 (0.6537) teacher/usage_min 0.0597 (0.0804) teacher/usage_std 0.2574 (0.2414) nleep/row_max_mean 1545.9399 (1545.6431) nleep/row_max_std 52.1677 (59.4855) nleep/row_min_mean 1509.1692 (1507.0493) lr 1.1253e-03 eta 0:11:49
epoch [25/50] batch [40/173] time 0.124 (0.153) data 0.000 (0.007) loss 1.3358 (1.3888) teacher_loss 0.2569 (0.2441) loss_zs_kd 0.0163 (0.0287) loss_oracle 0.5460 (0.5365) kd_loss 0.7977 (0.8622) acc 90.6250 (91.2500) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5646 (0.5645) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0158 (0.0393) teacher/usage_max 0.7439 (0.6503) teacher/usage_min 0.0999 (0.0810) teacher/usage_std 0.2912 (0.2412) nleep/row_max_mean 1565.0725 (1548.3491) nleep/row_max_std 63.5382 (56.0242) nleep/row_min_mean 1520.7300 (1509.3800) lr 1.1253e-03 eta 0:11:22
epoch [25/50] batch [60/173] time 0.145 (0.150) data 0.001 (0.005) loss 1.5078 (1.3917) teacher_loss 0.3363 (0.2542) loss_zs_kd 0.0433 (0.0296) loss_oracle 0.5551 (0.5340) kd_loss 0.8723 (0.8557) acc 87.5000 (90.6771) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0437 (0.0394) teacher/usage_max 0.6301 (0.6567) teacher/usage_min 0.0313 (0.0796) teacher/usage_std 0.2445 (0.2451) nleep/row_max_mean 1551.9490 (1549.0692) nleep/row_max_std 61.0288 (56.4753) nleep/row_min_mean 1511.0303 (1509.8052) lr 1.1253e-03 eta 0:11:06
epoch [25/50] batch [80/173] time 0.107 (0.141) data 0.000 (0.004) loss 1.2984 (1.3908) teacher_loss 0.1531 (0.2555) loss_zs_kd 0.0311 (0.0286) loss_oracle 0.5340 (0.5306) kd_loss 0.8628 (0.8557) acc 96.8750 (90.5859) gate/entropy 0.9867 (0.9866) gate/usage_max 0.5643 (0.5645) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0051 (0.0426) teacher/usage_max 0.6877 (0.6531) teacher/usage_min 0.1249 (0.0805) teacher/usage_std 0.2519 (0.2434) nleep/row_max_mean 1538.6809 (1547.9638) nleep/row_max_std 68.1168 (57.0505) nleep/row_min_mean 1503.7605 (1509.4706) lr 1.1253e-03 eta 0:10:22
epoch [25/50] batch [100/173] time 0.088 (0.137) data 0.000 (0.003) loss 1.2273 (1.3792) teacher_loss 0.1243 (0.2449) loss_zs_kd 0.0107 (0.0281) loss_oracle 0.5491 (0.5290) kd_loss 0.8231 (0.8558) acc 93.7500 (91.0000) gate/entropy 0.9869 (0.9865) gate/usage_max 0.5641 (0.5645) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1632 (0.1635) teacher/entropy 0.0187 (0.0428) teacher/usage_max 0.7106 (0.6528) teacher/usage_min 0.0312 (0.0822) teacher/usage_std 0.2824 (0.2425) nleep/row_max_mean 1531.0508 (1548.4359) nleep/row_max_std 71.7527 (57.4881) nleep/row_min_mean 1497.4434 (1510.2649) lr 1.1253e-03 eta 0:10:04
epoch [25/50] batch [120/173] time 0.091 (0.134) data 0.000 (0.002) loss 1.2554 (1.3823) teacher_loss 0.1814 (0.2451) loss_zs_kd 0.0218 (0.0285) loss_oracle 0.5452 (0.5310) kd_loss 0.7905 (0.8575) acc 93.7500 (90.8073) gate/entropy 0.9865 (0.9865) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0310 (0.0424) teacher/usage_max 0.7356 (0.6511) teacher/usage_min 0.0937 (0.0794) teacher/usage_std 0.2862 (0.2424) nleep/row_max_mean 1547.9617 (1548.3028) nleep/row_max_std 70.0461 (57.9865) nleep/row_min_mean 1507.9213 (1510.2973) lr 1.1253e-03 eta 0:09:47
epoch [25/50] batch [140/173] time 0.085 (0.132) data 0.000 (0.002) loss 1.6378 (1.3862) teacher_loss 0.3671 (0.2450) loss_zs_kd 0.0196 (0.0286) loss_oracle 0.6143 (0.5345) kd_loss 0.9537 (0.8596) acc 84.3750 (90.6920) gate/entropy 0.9864 (0.9865) gate/usage_max 0.5646 (0.5646) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0231 (0.0424) teacher/usage_max 0.5640 (0.6487) teacher/usage_min 0.0031 (0.0784) teacher/usage_std 0.2396 (0.2414) nleep/row_max_mean 1544.2776 (1547.8934) nleep/row_max_std 51.1365 (57.4617) nleep/row_min_mean 1504.8679 (1510.0171) lr 1.1253e-03 eta 0:09:33
epoch [25/50] batch [160/173] time 0.086 (0.129) data 0.000 (0.002) loss 1.3711 (1.3814) teacher_loss 0.0617 (0.2416) loss_zs_kd 0.0156 (0.0283) loss_oracle 0.5952 (0.5351) kd_loss 1.0041 (0.8581) acc 100.0000 (90.8008) gate/entropy 0.9865 (0.9865) gate/usage_max 0.5646 (0.5646) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1636 (0.1636) teacher/entropy 0.0053 (0.0433) teacher/usage_max 0.5311 (0.6492) teacher/usage_min 0.0313 (0.0781) teacher/usage_std 0.2169 (0.2419) nleep/row_max_mean 1551.9607 (1548.1149) nleep/row_max_std 54.3079 (57.3289) nleep/row_min_mean 1511.7188 (1510.0911) lr 1.1253e-03 eta 0:09:19
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,987
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.0%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [26/50] batch [20/173] time 0.158 (0.166) data 0.000 (0.016) loss 1.2054 (1.3676) teacher_loss 0.1315 (0.2545) loss_zs_kd 0.0112 (0.0254) loss_oracle 0.4646 (0.5275) kd_loss 0.8360 (0.8366) acc 96.8750 (92.0312) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0432 (0.0475) teacher/usage_max 0.6718 (0.6666) teacher/usage_min 0.0444 (0.0639) teacher/usage_std 0.2585 (0.2535) nleep/row_max_mean 1532.6227 (1547.7289) nleep/row_max_std 64.8438 (61.2110) nleep/row_min_mean 1497.7522 (1507.4582) lr 1.0628e-03 eta 0:11:53
epoch [26/50] batch [40/173] time 0.163 (0.162) data 0.000 (0.008) loss 1.3938 (1.3855) teacher_loss 0.1812 (0.2634) loss_zs_kd 0.0173 (0.0266) loss_oracle 0.5645 (0.5255) kd_loss 0.9217 (0.8460) acc 93.7500 (90.7031) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5648) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0278 (0.0418) teacher/usage_max 0.5968 (0.6634) teacher/usage_min 0.0884 (0.0596) teacher/usage_std 0.2080 (0.2544) nleep/row_max_mean 1551.7080 (1546.4060) nleep/row_max_std 62.9419 (60.3857) nleep/row_min_mean 1512.1868 (1506.2542) lr 1.0628e-03 eta 0:11:35
epoch [26/50] batch [60/173] time 0.164 (0.160) data 0.000 (0.005) loss 1.3624 (1.3763) teacher_loss 0.3153 (0.2541) loss_zs_kd 0.0284 (0.0262) loss_oracle 0.4993 (0.5201) kd_loss 0.7832 (0.8490) acc 87.5000 (90.9375) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5647 (0.5648) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0516 (0.0436) teacher/usage_max 0.7189 (0.6583) teacher/usage_min 0.0569 (0.0563) teacher/usage_std 0.2811 (0.2539) nleep/row_max_mean 1545.8687 (1546.0058) nleep/row_max_std 68.7225 (61.1558) nleep/row_min_mean 1504.2412 (1506.1778) lr 1.0628e-03 eta 0:11:22
epoch [26/50] batch [80/173] time 0.136 (0.158) data 0.000 (0.004) loss 1.4288 (1.3767) teacher_loss 0.2600 (0.2588) loss_zs_kd 0.0087 (0.0259) loss_oracle 0.5141 (0.5207) kd_loss 0.9074 (0.8446) acc 90.6250 (90.5859) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5651 (0.5648) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0113 (0.0419) teacher/usage_max 0.6278 (0.6644) teacher/usage_min 0.0313 (0.0529) teacher/usage_std 0.2436 (0.2580) nleep/row_max_mean 1556.7845 (1545.6431) nleep/row_max_std 60.5671 (62.8434) nleep/row_min_mean 1509.5656 (1505.3726) lr 1.0628e-03 eta 0:11:12
epoch [26/50] batch [100/173] time 0.149 (0.158) data 0.000 (0.003) loss 1.6846 (1.3771) teacher_loss 0.4180 (0.2579) loss_zs_kd 0.0185 (0.0253) loss_oracle 0.6197 (0.5213) kd_loss 0.9475 (0.8459) acc 84.3750 (90.5938) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0025 (0.0393) teacher/usage_max 0.5937 (0.6655) teacher/usage_min 0.0315 (0.0476) teacher/usage_std 0.2314 (0.2601) nleep/row_max_mean 1551.2716 (1546.1764) nleep/row_max_std 46.3763 (62.0792) nleep/row_min_mean 1507.6855 (1505.6230) lr 1.0628e-03 eta 0:11:08
epoch [26/50] batch [120/173] time 0.150 (0.157) data 0.000 (0.003) loss 1.2479 (1.3708) teacher_loss 0.1820 (0.2553) loss_zs_kd 0.0264 (0.0244) loss_oracle 0.5891 (0.5222) kd_loss 0.7581 (0.8422) acc 96.8750 (90.6510) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5651 (0.5648) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0308 (0.0375) teacher/usage_max 0.7672 (0.6712) teacher/usage_min 0.0428 (0.0450) teacher/usage_std 0.3126 (0.2633) nleep/row_max_mean 1559.3705 (1546.9088) nleep/row_max_std 57.3371 (61.7901) nleep/row_min_mean 1516.6780 (1505.6355) lr 1.0628e-03 eta 0:11:01
epoch [26/50] batch [140/173] time 0.162 (0.154) data 0.000 (0.002) loss 1.3096 (1.3693) teacher_loss 0.2693 (0.2575) loss_zs_kd 0.0250 (0.0236) loss_oracle 0.5675 (0.5245) kd_loss 0.7441 (0.8377) acc 87.5000 (90.5804) gate/entropy 0.9858 (0.9862) gate/usage_max 0.5653 (0.5648) gate/usage_min 0.2126 (0.2128) gate/usage_std 0.1641 (0.1637) teacher/entropy 0.0013 (0.0354) teacher/usage_max 0.8123 (0.6780) teacher/usage_min 0.0001 (0.0417) teacher/usage_std 0.3472 (0.2674) nleep/row_max_mean 1570.2334 (1547.6356) nleep/row_max_std 49.2957 (61.2802) nleep/row_min_mean 1519.9197 (1505.7409) lr 1.0628e-03 eta 0:10:43
epoch [26/50] batch [160/173] time 0.166 (0.154) data 0.000 (0.002) loss 1.5731 (1.3691) teacher_loss 0.4084 (0.2588) loss_zs_kd 0.0240 (0.0236) loss_oracle 0.5647 (0.5270) kd_loss 0.8703 (0.8350) acc 84.3750 (90.4297) gate/entropy 0.9857 (0.9862) gate/usage_max 0.5654 (0.5649) gate/usage_min 0.2125 (0.2128) gate/usage_std 0.1642 (0.1638) teacher/entropy 0.0208 (0.0345) teacher/usage_max 0.6566 (0.6815) teacher/usage_min 0.0237 (0.0378) teacher/usage_std 0.2586 (0.2703) nleep/row_max_mean 1557.8292 (1547.4583) nleep/row_max_std 54.2603 (61.6809) nleep/row_min_mean 1513.3975 (1505.3562) lr 1.0628e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [27/50] batch [20/173] time 0.074 (0.134) data 0.000 (0.017) loss 1.4610 (1.3337) teacher_loss 0.2689 (0.2360) loss_zs_kd 0.0089 (0.0164) loss_oracle 0.4972 (0.5438) kd_loss 0.9390 (0.8176) acc 87.5000 (91.4062) gate/entropy 0.9863 (0.9860) gate/usage_max 0.5648 (0.5651) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1637 (0.1639) teacher/entropy 0.0153 (0.0337) teacher/usage_max 0.5890 (0.6995) teacher/usage_min 0.0317 (0.0224) teacher/usage_std 0.2298 (0.2835) nleep/row_max_mean 1548.2460 (1546.3993) nleep/row_max_std 58.6882 (59.3872) nleep/row_min_mean 1505.7905 (1502.9775) lr 1.0000e-03 eta 0:09:13
epoch [27/50] batch [40/173] time 0.071 (0.125) data 0.000 (0.009) loss 1.5336 (1.3561) teacher_loss 0.5358 (0.2558) loss_zs_kd 0.0315 (0.0183) loss_oracle 0.5000 (0.5312) kd_loss 0.7320 (0.8255) acc 68.7500 (89.7656) gate/entropy 0.9859 (0.9860) gate/usage_max 0.5652 (0.5651) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1640 (0.1639) teacher/entropy 0.0161 (0.0312) teacher/usage_max 0.8101 (0.6938) teacher/usage_min 0.0011 (0.0221) teacher/usage_std 0.3457 (0.2804) nleep/row_max_mean 1535.0559 (1546.8808) nleep/row_max_std 71.2732 (58.7902) nleep/row_min_mean 1490.8761 (1503.2348) lr 1.0000e-03 eta 0:08:34
epoch [27/50] batch [60/173] time 0.092 (0.120) data 0.000 (0.006) loss 1.3709 (1.3608) teacher_loss 0.2386 (0.2501) loss_zs_kd 0.0155 (0.0193) loss_oracle 0.5372 (0.5398) kd_loss 0.8559 (0.8312) acc 87.5000 (89.7917) gate/entropy 0.9858 (0.9860) gate/usage_max 0.5653 (0.5651) gate/usage_min 0.2125 (0.2126) gate/usage_std 0.1640 (0.1639) teacher/entropy 0.0494 (0.0321) teacher/usage_max 0.6409 (0.6867) teacher/usage_min 0.0001 (0.0246) teacher/usage_std 0.2622 (0.2760) nleep/row_max_mean 1534.7518 (1545.3484) nleep/row_max_std 62.3126 (58.7079) nleep/row_min_mean 1494.9133 (1502.1896) lr 1.0000e-03 eta 0:08:11
epoch [27/50] batch [80/173] time 0.155 (0.120) data 0.000 (0.004) loss 1.2995 (1.3650) teacher_loss 0.2434 (0.2590) loss_zs_kd 0.0270 (0.0205) loss_oracle 0.5207 (0.5395) kd_loss 0.7823 (0.8260) acc 93.7500 (89.7656) gate/entropy 0.9857 (0.9860) gate/usage_max 0.5655 (0.5651) gate/usage_min 0.2125 (0.2126) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0690 (0.0334) teacher/usage_max 0.7004 (0.6908) teacher/usage_min 0.0544 (0.0238) teacher/usage_std 0.2710 (0.2781) nleep/row_max_mean 1546.7712 (1543.7496) nleep/row_max_std 66.2795 (59.1437) nleep/row_min_mean 1505.2208 (1501.1136) lr 1.0000e-03 eta 0:08:09
epoch [27/50] batch [100/173] time 0.164 (0.120) data 0.000 (0.004) loss 1.4055 (1.3556) teacher_loss 0.3772 (0.2496) loss_zs_kd 0.0215 (0.0209) loss_oracle 0.4865 (0.5370) kd_loss 0.7743 (0.8271) acc 84.3750 (90.1250) gate/entropy 0.9854 (0.9859) gate/usage_max 0.5657 (0.5651) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1643 (0.1640) teacher/entropy 0.0232 (0.0321) teacher/usage_max 0.7561 (0.6911) teacher/usage_min 0.0011 (0.0222) teacher/usage_std 0.3148 (0.2787) nleep/row_max_mean 1546.9321 (1543.0807) nleep/row_max_std 62.3702 (59.3791) nleep/row_min_mean 1508.1562 (1500.5853) lr 1.0000e-03 eta 0:08:04
epoch [27/50] batch [120/173] time 0.164 (0.126) data 0.000 (0.003) loss 1.5812 (1.3621) teacher_loss 0.5413 (0.2547) loss_zs_kd 0.0313 (0.0211) loss_oracle 0.5269 (0.5383) kd_loss 0.7609 (0.8277) acc 78.1250 (89.9479) gate/entropy 0.9858 (0.9859) gate/usage_max 0.5653 (0.5651) gate/usage_min 0.2125 (0.2126) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0197 (0.0334) teacher/usage_max 0.7742 (0.6890) teacher/usage_min 0.0000 (0.0223) teacher/usage_std 0.3251 (0.2776) nleep/row_max_mean 1534.2004 (1541.8940) nleep/row_max_std 62.6364 (59.3689) nleep/row_min_mean 1489.3657 (1499.6131) lr 1.0000e-03 eta 0:08:26
epoch [27/50] batch [140/173] time 0.129 (0.129) data 0.000 (0.003) loss 1.5961 (1.3632) teacher_loss 0.3542 (0.2514) loss_zs_kd 0.0368 (0.0211) loss_oracle 0.5359 (0.5376) kd_loss 0.9556 (0.8324) acc 90.6250 (90.2679) gate/entropy 0.9856 (0.9859) gate/usage_max 0.5655 (0.5652) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0283 (0.0332) teacher/usage_max 0.5578 (0.6854) teacher/usage_min 0.0310 (0.0205) teacher/usage_std 0.2220 (0.2767) nleep/row_max_mean 1550.0339 (1541.2225) nleep/row_max_std 49.3162 (58.8184) nleep/row_min_mean 1503.8324 (1499.0750) lr 1.0000e-03 eta 0:08:38
epoch [27/50] batch [160/173] time 0.094 (0.130) data 0.000 (0.002) loss 1.3945 (1.3566) teacher_loss 0.2331 (0.2469) loss_zs_kd 0.0166 (0.0213) loss_oracle 0.5539 (0.5355) kd_loss 0.8762 (0.8313) acc 87.5000 (90.4688) gate/entropy 0.9857 (0.9859) gate/usage_max 0.5653 (0.5652) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1641 (0.1640) teacher/entropy 0.0488 (0.0340) teacher/usage_max 0.6192 (0.6855) teacher/usage_min 0.0122 (0.0198) teacher/usage_std 0.2491 (0.2770) nleep/row_max_mean 1549.7898 (1541.0998) nleep/row_max_std 73.3101 (59.0638) nleep/row_min_mean 1501.5964 (1498.9045) lr 1.0000e-03 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,303
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [28/50] batch [20/173] time 0.165 (0.177) data 0.000 (0.015) loss 1.3837 (1.3272) teacher_loss 0.3950 (0.2373) loss_zs_kd 0.0188 (0.0211) loss_oracle 0.5059 (0.5313) kd_loss 0.7263 (0.8137) acc 81.2500 (90.7812) gate/entropy 0.9858 (0.9858) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0261 (0.0343) teacher/usage_max 0.8049 (0.7023) teacher/usage_min 0.0004 (0.0093) teacher/usage_std 0.3427 (0.2897) nleep/row_max_mean 1541.9213 (1540.2887) nleep/row_max_std 70.3217 (61.2333) nleep/row_min_mean 1494.5151 (1496.7750) lr 9.3721e-04 eta 0:11:40
epoch [28/50] batch [40/173] time 0.162 (0.171) data 0.000 (0.008) loss 1.2974 (1.3460) teacher_loss 0.2857 (0.2396) loss_zs_kd 0.0343 (0.0227) loss_oracle 0.5368 (0.5319) kd_loss 0.7261 (0.8290) acc 87.5000 (90.6250) gate/entropy 0.9859 (0.9859) gate/usage_max 0.5651 (0.5652) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0402 (0.0351) teacher/usage_max 0.7895 (0.6848) teacher/usage_min 0.0055 (0.0093) teacher/usage_std 0.3327 (0.2822) nleep/row_max_mean 1544.1315 (1538.9389) nleep/row_max_std 60.0909 (61.9203) nleep/row_min_mean 1501.2074 (1495.4423) lr 9.3721e-04 eta 0:11:14
epoch [28/50] batch [60/173] time 0.090 (0.157) data 0.001 (0.005) loss 1.5338 (1.3483) teacher_loss 0.4196 (0.2519) loss_zs_kd 0.0258 (0.0225) loss_oracle 0.5409 (0.5267) kd_loss 0.8309 (0.8218) acc 81.2500 (90.1562) gate/entropy 0.9856 (0.9859) gate/usage_max 0.5655 (0.5652) gate/usage_min 0.2123 (0.2124) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0430 (0.0344) teacher/usage_max 0.6737 (0.6934) teacher/usage_min 0.0004 (0.0089) teacher/usage_std 0.2749 (0.2870) nleep/row_max_mean 1546.9153 (1540.6641) nleep/row_max_std 63.1517 (61.2026) nleep/row_min_mean 1501.1924 (1497.0012) lr 9.3721e-04 eta 0:10:14
epoch [28/50] batch [80/173] time 0.094 (0.146) data 0.000 (0.004) loss 1.5818 (1.3629) teacher_loss 0.3498 (0.2518) loss_zs_kd 0.0189 (0.0211) loss_oracle 0.5338 (0.5311) kd_loss 0.9556 (0.8349) acc 87.5000 (90.2344) gate/entropy 0.9859 (0.9859) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0302 (0.0331) teacher/usage_max 0.5542 (0.6807) teacher/usage_min 0.0001 (0.0099) teacher/usage_std 0.2397 (0.2809) nleep/row_max_mean 1528.9915 (1540.5515) nleep/row_max_std 53.7992 (60.8391) nleep/row_min_mean 1490.8340 (1497.0365) lr 9.3721e-04 eta 0:09:28
epoch [28/50] batch [100/173] time 0.090 (0.139) data 0.000 (0.003) loss 1.5384 (1.3536) teacher_loss 0.4249 (0.2465) loss_zs_kd 0.0221 (0.0204) loss_oracle 0.5134 (0.5315) kd_loss 0.8457 (0.8311) acc 84.3750 (90.5312) gate/entropy 0.9857 (0.9859) gate/usage_max 0.5654 (0.5652) gate/usage_min 0.2123 (0.2124) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0226 (0.0346) teacher/usage_max 0.6804 (0.6832) teacher/usage_min 0.0004 (0.0104) teacher/usage_std 0.2778 (0.2815) nleep/row_max_mean 1537.8335 (1540.5386) nleep/row_max_std 63.4818 (60.6865) nleep/row_min_mean 1492.2668 (1497.1991) lr 9.3721e-04 eta 0:08:58
epoch [28/50] batch [120/173] time 0.088 (0.136) data 0.000 (0.003) loss 1.2945 (1.3523) teacher_loss 0.1902 (0.2450) loss_zs_kd 0.0158 (0.0205) loss_oracle 0.5798 (0.5327) kd_loss 0.8064 (0.8307) acc 87.5000 (90.4688) gate/entropy 0.9857 (0.9859) gate/usage_max 0.5654 (0.5652) gate/usage_min 0.2123 (0.2124) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0411 (0.0348) teacher/usage_max 0.7016 (0.6834) teacher/usage_min 0.0014 (0.0108) teacher/usage_std 0.2870 (0.2811) nleep/row_max_mean 1549.1342 (1540.6317) nleep/row_max_std 57.0016 (59.9918) nleep/row_min_mean 1504.7549 (1497.3391) lr 9.3721e-04 eta 0:08:43
epoch [28/50] batch [140/173] time 0.173 (0.134) data 0.000 (0.002) loss 1.3774 (1.3557) teacher_loss 0.2860 (0.2517) loss_zs_kd 0.0222 (0.0205) loss_oracle 0.5438 (0.5311) kd_loss 0.8084 (0.8282) acc 84.3750 (90.2009) gate/entropy 0.9855 (0.9859) gate/usage_max 0.5656 (0.5652) gate/usage_min 0.2122 (0.2124) gate/usage_std 0.1643 (0.1640) teacher/entropy 0.0362 (0.0336) teacher/usage_max 0.7072 (0.6876) teacher/usage_min 0.0439 (0.0110) teacher/usage_std 0.2773 (0.2827) nleep/row_max_mean 1560.5515 (1540.8622) nleep/row_max_std 55.1610 (59.2581) nleep/row_min_mean 1513.4646 (1497.7475) lr 9.3721e-04 eta 0:08:33
epoch [28/50] batch [160/173] time 0.083 (0.129) data 0.000 (0.002) loss 1.2054 (1.3504) teacher_loss 0.2031 (0.2478) loss_zs_kd 0.0198 (0.0201) loss_oracle 0.5237 (0.5301) kd_loss 0.7305 (0.8275) acc 90.6250 (90.4297) gate/entropy 0.9858 (0.9859) gate/usage_max 0.5653 (0.5652) gate/usage_min 0.2123 (0.2124) gate/usage_std 0.1641 (0.1640) teacher/entropy 0.0238 (0.0331) teacher/usage_max 0.8027 (0.6888) teacher/usage_min 0.0000 (0.0107) teacher/usage_std 0.3415 (0.2832) nleep/row_max_mean 1550.3428 (1541.5478) nleep/row_max_std 59.6327 (58.9647) nleep/row_min_mean 1507.9028 (1498.3388) lr 9.3721e-04 eta 0:08:10
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,991
* accuracy: 97.2%
* error: 2.8%
* macro_f1: 97.1%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [29/50] batch [20/173] time 0.153 (0.165) data 0.000 (0.016) loss 1.2964 (1.2991) teacher_loss 0.3213 (0.1969) loss_zs_kd 0.0138 (0.0177) loss_oracle 0.4565 (0.5125) kd_loss 0.7399 (0.8370) acc 84.3750 (92.5000) gate/entropy 0.9859 (0.9859) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0611 (0.0283) teacher/usage_max 0.7523 (0.6845) teacher/usage_min 0.0029 (0.0071) teacher/usage_std 0.3123 (0.2829) nleep/row_max_mean 1541.2263 (1544.3783) nleep/row_max_std 74.0390 (58.9069) nleep/row_min_mean 1497.3353 (1501.4238) lr 8.7467e-04 eta 0:10:23
epoch [29/50] batch [40/173] time 0.154 (0.158) data 0.000 (0.008) loss 1.0945 (1.3213) teacher_loss 0.0788 (0.2204) loss_zs_kd 0.0050 (0.0180) loss_oracle 0.4704 (0.5211) kd_loss 0.7780 (0.8313) acc 100.0000 (91.0938) gate/entropy 0.9864 (0.9858) gate/usage_max 0.5646 (0.5653) gate/usage_min 0.2124 (0.2123) gate/usage_std 0.1636 (0.1640) teacher/entropy 0.0456 (0.0243) teacher/usage_max 0.7291 (0.6941) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.3009 (0.2873) nleep/row_max_mean 1525.7866 (1544.5795) nleep/row_max_std 72.6881 (61.3030) nleep/row_min_mean 1486.5312 (1500.7623) lr 8.7467e-04 eta 0:09:54
epoch [29/50] batch [60/173] time 0.162 (0.152) data 0.001 (0.005) loss 1.3934 (1.3298) teacher_loss 0.3483 (0.2363) loss_zs_kd 0.0196 (0.0190) loss_oracle 0.5399 (0.5247) kd_loss 0.7653 (0.8216) acc 84.3750 (90.7812) gate/entropy 0.9859 (0.9858) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2123 (0.2122) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0274 (0.0250) teacher/usage_max 0.7604 (0.7038) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.3174 (0.2913) nleep/row_max_mean 1544.6577 (1544.4433) nleep/row_max_std 81.0150 (62.8483) nleep/row_min_mean 1495.9146 (1500.0908) lr 8.7467e-04 eta 0:09:28
epoch [29/50] batch [80/173] time 0.141 (0.150) data 0.000 (0.004) loss 1.3730 (1.3264) teacher_loss 0.2842 (0.2358) loss_zs_kd 0.0269 (0.0181) loss_oracle 0.5068 (0.5284) kd_loss 0.8220 (0.8173) acc 87.5000 (90.7422) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5655 (0.5653) gate/usage_min 0.2122 (0.2122) gate/usage_std 0.1642 (0.1641) teacher/entropy 0.0102 (0.0218) teacher/usage_max 0.7181 (0.7116) teacher/usage_min 0.0002 (0.0061) teacher/usage_std 0.2953 (0.2945) nleep/row_max_mean 1544.4659 (1544.9083) nleep/row_max_std 53.4710 (63.3669) nleep/row_min_mean 1497.7759 (1499.9827) lr 8.7467e-04 eta 0:09:19
epoch [29/50] batch [100/173] time 0.143 (0.149) data 0.000 (0.003) loss 1.3199 (1.3356) teacher_loss 0.2635 (0.2441) loss_zs_kd 0.0250 (0.0181) loss_oracle 0.5041 (0.5310) kd_loss 0.7919 (0.8169) acc 90.6250 (90.4062) gate/entropy 0.9855 (0.9858) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2121 (0.2122) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0099 (0.0215) teacher/usage_max 0.7528 (0.7123) teacher/usage_min 0.0313 (0.0064) teacher/usage_std 0.3061 (0.2947) nleep/row_max_mean 1561.2207 (1545.2812) nleep/row_max_std 54.9618 (63.3081) nleep/row_min_mean 1514.4686 (1499.8712) lr 8.7467e-04 eta 0:09:13
epoch [29/50] batch [120/173] time 0.153 (0.149) data 0.000 (0.003) loss 1.3696 (1.3361) teacher_loss 0.2488 (0.2470) loss_zs_kd 0.0149 (0.0186) loss_oracle 0.5672 (0.5349) kd_loss 0.8297 (0.8123) acc 90.6250 (90.3385) gate/entropy 0.9860 (0.9857) gate/usage_max 0.5650 (0.5653) gate/usage_min 0.2123 (0.2122) gate/usage_std 0.1639 (0.1641) teacher/entropy 0.0453 (0.0221) teacher/usage_max 0.6717 (0.7165) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.2743 (0.2972) nleep/row_max_mean 1527.3336 (1546.0799) nleep/row_max_std 64.8208 (63.5593) nleep/row_min_mean 1487.0747 (1500.1237) lr 8.7467e-04 eta 0:09:07
epoch [29/50] batch [140/173] time 0.125 (0.147) data 0.000 (0.002) loss 1.4602 (1.3375) teacher_loss 0.3510 (0.2509) loss_zs_kd 0.0345 (0.0188) loss_oracle 0.5195 (0.5367) kd_loss 0.8321 (0.8089) acc 84.3750 (90.2455) gate/entropy 0.9853 (0.9857) gate/usage_max 0.5658 (0.5654) gate/usage_min 0.2121 (0.2122) gate/usage_std 0.1644 (0.1641) teacher/entropy 0.0001 (0.0217) teacher/usage_max 0.7187 (0.7205) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.2957 (0.2993) nleep/row_max_mean 1570.0945 (1545.8555) nleep/row_max_std 58.4314 (63.7218) nleep/row_min_mean 1510.5869 (1499.6741) lr 8.7467e-04 eta 0:08:59
epoch [29/50] batch [160/173] time 0.120 (0.147) data 0.000 (0.002) loss 1.2982 (1.3305) teacher_loss 0.2916 (0.2489) loss_zs_kd 0.0129 (0.0187) loss_oracle 0.4902 (0.5356) kd_loss 0.7550 (0.8044) acc 84.3750 (90.3516) gate/entropy 0.9854 (0.9857) gate/usage_max 0.5657 (0.5654) gate/usage_min 0.2121 (0.2122) gate/usage_std 0.1644 (0.1641) teacher/entropy 0.0347 (0.0226) teacher/usage_max 0.7637 (0.7243) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.3192 (0.3012) nleep/row_max_mean 1562.2499 (1546.3342) nleep/row_max_std 67.5564 (63.7091) nleep/row_min_mean 1512.8289 (1499.9337) lr 8.7467e-04 eta 0:08:54
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [30/50] batch [20/173] time 0.080 (0.132) data 0.000 (0.015) loss 1.1589 (1.3248) teacher_loss 0.1121 (0.2518) loss_zs_kd 0.0129 (0.0194) loss_oracle 0.5626 (0.5288) kd_loss 0.7591 (0.7988) acc 93.7500 (90.7812) gate/entropy 0.9858 (0.9856) gate/usage_max 0.5653 (0.5655) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1641 (0.1642) teacher/entropy 0.0211 (0.0377) teacher/usage_max 0.7737 (0.7139) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.3248 (0.2956) nleep/row_max_mean 1539.5947 (1540.7904) nleep/row_max_std 67.5295 (65.3916) nleep/row_min_mean 1495.3096 (1495.7864) lr 8.1262e-04 eta 0:07:55
epoch [30/50] batch [40/173] time 0.096 (0.117) data 0.000 (0.008) loss 1.5323 (1.3174) teacher_loss 0.2593 (0.2410) loss_zs_kd 0.0219 (0.0172) loss_oracle 0.6156 (0.5265) kd_loss 0.9543 (0.8046) acc 87.5000 (91.2500) gate/entropy 0.9856 (0.9855) gate/usage_max 0.5655 (0.5656) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1642 (0.1643) teacher/entropy 0.0396 (0.0329) teacher/usage_max 0.5442 (0.7128) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2384 (0.2959) nleep/row_max_mean 1529.9186 (1542.8503) nleep/row_max_std 70.7871 (64.0866) nleep/row_min_mean 1488.1172 (1497.6121) lr 8.1262e-04 eta 0:06:59
epoch [30/50] batch [60/173] time 0.176 (0.116) data 0.001 (0.005) loss 1.3867 (1.3435) teacher_loss 0.2603 (0.2559) loss_zs_kd 0.0157 (0.0177) loss_oracle 0.5377 (0.5302) kd_loss 0.8498 (0.8137) acc 87.5000 (91.0938) gate/entropy 0.9853 (0.9855) gate/usage_max 0.5658 (0.5656) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1644 (0.1643) teacher/entropy 0.0137 (0.0336) teacher/usage_max 0.6849 (0.7024) teacher/usage_min 0.0027 (0.0052) teacher/usage_std 0.2789 (0.2913) nleep/row_max_mean 1556.5366 (1544.1607) nleep/row_max_std 50.8692 (62.1135) nleep/row_min_mean 1509.4829 (1499.0321) lr 8.1262e-04 eta 0:06:52
epoch [30/50] batch [80/173] time 0.159 (0.119) data 0.000 (0.004) loss 1.2972 (1.3526) teacher_loss 0.2577 (0.2597) loss_zs_kd 0.0109 (0.0179) loss_oracle 0.5721 (0.5337) kd_loss 0.7480 (0.8170) acc 84.3750 (90.5078) gate/entropy 0.9854 (0.9855) gate/usage_max 0.5656 (0.5656) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1643 (0.1643) teacher/entropy 0.0265 (0.0333) teacher/usage_max 0.7788 (0.6990) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3277 (0.2889) nleep/row_max_mean 1549.2554 (1543.9080) nleep/row_max_std 55.3369 (61.6738) nleep/row_min_mean 1499.3987 (1498.9925) lr 8.1262e-04 eta 0:07:01
epoch [30/50] batch [100/173] time 0.132 (0.116) data 0.000 (0.003) loss 1.1993 (1.3517) teacher_loss 0.1344 (0.2582) loss_zs_kd 0.0222 (0.0177) loss_oracle 0.5210 (0.5295) kd_loss 0.7932 (0.8200) acc 96.8750 (90.6562) gate/entropy 0.9855 (0.9855) gate/usage_max 0.5656 (0.5656) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1643 (0.1643) teacher/entropy 0.0506 (0.0349) teacher/usage_max 0.7054 (0.6941) teacher/usage_min 0.0006 (0.0053) teacher/usage_std 0.2890 (0.2870) nleep/row_max_mean 1537.7893 (1543.7681) nleep/row_max_std 75.4960 (62.1945) nleep/row_min_mean 1496.7908 (1499.0288) lr 8.1262e-04 eta 0:06:50
epoch [30/50] batch [120/173] time 0.153 (0.124) data 0.000 (0.003) loss 1.4171 (1.3449) teacher_loss 0.3431 (0.2487) loss_zs_kd 0.0271 (0.0174) loss_oracle 0.5496 (0.5324) kd_loss 0.7856 (0.8213) acc 87.5000 (90.9635) gate/entropy 0.9852 (0.9855) gate/usage_max 0.5659 (0.5656) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1645 (0.1643) teacher/entropy 0.0246 (0.0355) teacher/usage_max 0.7417 (0.6920) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.3074 (0.2855) nleep/row_max_mean 1554.3862 (1543.9948) nleep/row_max_std 58.9768 (62.1761) nleep/row_min_mean 1509.7036 (1499.2766) lr 8.1262e-04 eta 0:07:14
epoch [30/50] batch [140/173] time 0.162 (0.128) data 0.000 (0.002) loss 1.3023 (1.3539) teacher_loss 0.2763 (0.2555) loss_zs_kd 0.0243 (0.0175) loss_oracle 0.5302 (0.5347) kd_loss 0.7488 (0.8223) acc 87.5000 (90.5580) gate/entropy 0.9853 (0.9855) gate/usage_max 0.5658 (0.5656) gate/usage_min 0.2119 (0.2121) gate/usage_std 0.1645 (0.1643) teacher/entropy 0.0268 (0.0364) teacher/usage_max 0.7788 (0.6899) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.3277 (0.2846) nleep/row_max_mean 1551.0433 (1544.1660) nleep/row_max_std 64.5138 (61.9547) nleep/row_min_mean 1502.5010 (1499.4019) lr 8.1262e-04 eta 0:07:28
epoch [30/50] batch [160/173] time 0.162 (0.132) data 0.000 (0.002) loss 1.4241 (1.3569) teacher_loss 0.1028 (0.2555) loss_zs_kd 0.0237 (0.0182) loss_oracle 0.5669 (0.5373) kd_loss 1.0260 (0.8237) acc 100.0000 (90.4883) gate/entropy 0.9857 (0.9855) gate/usage_max 0.5654 (0.5656) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1642 (0.1643) teacher/entropy 0.0497 (0.0372) teacher/usage_max 0.5434 (0.6881) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2383 (0.2839) nleep/row_max_mean 1521.9795 (1544.4682) nleep/row_max_std 69.8419 (61.8489) nleep/row_min_mean 1484.6202 (1499.5352) lr 8.1262e-04 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,980
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 96.7%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [31/50] batch [20/173] time 0.121 (0.154) data 0.000 (0.015) loss 1.4380 (1.3405) teacher_loss 0.2731 (0.2183) loss_zs_kd 0.0087 (0.0175) loss_oracle 0.5559 (0.5434) kd_loss 0.8826 (0.8418) acc 90.6250 (92.3438) gate/entropy 0.9853 (0.9855) gate/usage_max 0.5658 (0.5656) gate/usage_min 0.2119 (0.2120) gate/usage_std 0.1644 (0.1643) teacher/entropy 0.0338 (0.0436) teacher/usage_max 0.6279 (0.6616) teacher/usage_min 0.0195 (0.0054) teacher/usage_std 0.2487 (0.2724) nleep/row_max_mean 1561.8247 (1546.3085) nleep/row_max_std 60.0031 (61.4832) nleep/row_min_mean 1516.5239 (1501.9258) lr 7.5131e-04 eta 0:08:50
epoch [31/50] batch [40/173] time 0.156 (0.152) data 0.000 (0.008) loss 1.3108 (1.3667) teacher_loss 0.1858 (0.2444) loss_zs_kd 0.0191 (0.0185) loss_oracle 0.5651 (0.5385) kd_loss 0.8329 (0.8438) acc 96.8750 (91.6406) gate/entropy 0.9852 (0.9855) gate/usage_max 0.5659 (0.5656) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1645 (0.1643) teacher/entropy 0.0213 (0.0426) teacher/usage_max 0.6936 (0.6600) teacher/usage_min 0.0000 (0.0043) teacher/usage_std 0.2838 (0.2714) nleep/row_max_mean 1567.8728 (1546.8027) nleep/row_max_std 54.6845 (62.7174) nleep/row_min_mean 1522.5536 (1501.9580) lr 7.5131e-04 eta 0:08:41
epoch [31/50] batch [60/173] time 0.090 (0.143) data 0.001 (0.005) loss 1.5353 (1.3824) teacher_loss 0.3379 (0.2481) loss_zs_kd 0.0184 (0.0185) loss_oracle 0.4984 (0.5484) kd_loss 0.9389 (0.8509) acc 81.2500 (90.9896) gate/entropy 0.9854 (0.9856) gate/usage_max 0.5656 (0.5655) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1643 (0.1642) teacher/entropy 0.0318 (0.0447) teacher/usage_max 0.5715 (0.6502) teacher/usage_min 0.0311 (0.0054) teacher/usage_std 0.2252 (0.2677) nleep/row_max_mean 1536.2322 (1544.3406) nleep/row_max_std 50.9449 (62.4846) nleep/row_min_mean 1497.1797 (1500.0110) lr 7.5131e-04 eta 0:08:07
epoch [31/50] batch [80/173] time 0.057 (0.132) data 0.000 (0.004) loss 1.3115 (1.3876) teacher_loss 0.3666 (0.2520) loss_zs_kd 0.0212 (0.0186) loss_oracle 0.4936 (0.5519) kd_loss 0.6874 (0.8504) acc 87.5000 (90.7422) gate/entropy 0.9854 (0.9856) gate/usage_max 0.5657 (0.5655) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1644 (0.1642) teacher/entropy 0.0741 (0.0434) teacher/usage_max 0.7948 (0.6520) teacher/usage_min 0.0177 (0.0055) teacher/usage_std 0.3336 (0.2684) nleep/row_max_mean 1543.7777 (1543.9390) nleep/row_max_std 67.6956 (62.5419) nleep/row_min_mean 1498.0273 (1499.6459) lr 7.5131e-04 eta 0:07:24
epoch [31/50] batch [100/173] time 0.123 (0.122) data 0.000 (0.003) loss 1.3421 (1.3925) teacher_loss 0.2212 (0.2539) loss_zs_kd 0.0154 (0.0186) loss_oracle 0.5095 (0.5504) kd_loss 0.8584 (0.8540) acc 93.7500 (90.5938) gate/entropy 0.9857 (0.9856) gate/usage_max 0.5653 (0.5655) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1641 (0.1642) teacher/entropy 0.0610 (0.0430) teacher/usage_max 0.6242 (0.6486) teacher/usage_min 0.0000 (0.0064) teacher/usage_std 0.2566 (0.2673) nleep/row_max_mean 1547.8896 (1543.9872) nleep/row_max_std 41.8484 (61.6200) nleep/row_min_mean 1505.1677 (1499.7536) lr 7.5131e-04 eta 0:06:50
epoch [31/50] batch [120/173] time 0.069 (0.118) data 0.000 (0.003) loss 1.3359 (1.3934) teacher_loss 0.2205 (0.2545) loss_zs_kd 0.0188 (0.0185) loss_oracle 0.6584 (0.5484) kd_loss 0.7768 (0.8555) acc 90.6250 (90.3385) gate/entropy 0.9857 (0.9856) gate/usage_max 0.5654 (0.5655) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0396 (0.0437) teacher/usage_max 0.7346 (0.6464) teacher/usage_min 0.0000 (0.0069) teacher/usage_std 0.3037 (0.2659) nleep/row_max_mean 1539.1533 (1543.6100) nleep/row_max_std 51.8356 (61.3392) nleep/row_min_mean 1498.6219 (1499.3284) lr 7.5131e-04 eta 0:06:33
epoch [31/50] batch [140/173] time 0.192 (0.116) data 0.000 (0.002) loss 1.3925 (1.3947) teacher_loss 0.2617 (0.2578) loss_zs_kd 0.0203 (0.0187) loss_oracle 0.5038 (0.5515) kd_loss 0.8688 (0.8518) acc 93.7500 (90.1116) gate/entropy 0.9856 (0.9856) gate/usage_max 0.5654 (0.5655) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0399 (0.0423) teacher/usage_max 0.6370 (0.6517) teacher/usage_min 0.0270 (0.0071) teacher/usage_std 0.2491 (0.2682) nleep/row_max_mean 1541.2365 (1543.6321) nleep/row_max_std 63.2910 (60.6605) nleep/row_min_mean 1496.6392 (1499.1796) lr 7.5131e-04 eta 0:06:25
epoch [31/50] batch [160/173] time 0.076 (0.115) data 0.000 (0.002) loss 1.3692 (1.3885) teacher_loss 0.2584 (0.2542) loss_zs_kd 0.0266 (0.0186) loss_oracle 0.5106 (0.5502) kd_loss 0.8423 (0.8499) acc 84.3750 (90.1367) gate/entropy 0.9856 (0.9856) gate/usage_max 0.5654 (0.5654) gate/usage_min 0.2117 (0.2119) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0301 (0.0420) teacher/usage_max 0.6751 (0.6540) teacher/usage_min 0.0015 (0.0069) teacher/usage_std 0.2751 (0.2695) nleep/row_max_mean 1563.8728 (1543.9090) nleep/row_max_std 48.7739 (60.3213) nleep/row_min_mean 1511.8899 (1499.2857) lr 7.5131e-04 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,990
* accuracy: 97.2%
* error: 2.8%
* macro_f1: 97.1%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [32/50] batch [20/173] time 0.186 (0.175) data 0.000 (0.016) loss 1.2871 (1.3758) teacher_loss 0.1898 (0.2601) loss_zs_kd 0.0231 (0.0201) loss_oracle 0.5481 (0.5487) kd_loss 0.8117 (0.8313) acc 93.7500 (89.5312) gate/entropy 0.9861 (0.9858) gate/usage_max 0.5649 (0.5652) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1638 (0.1641) teacher/entropy 0.0499 (0.0321) teacher/usage_max 0.6857 (0.6843) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.2803 (0.2826) nleep/row_max_mean 1527.6431 (1547.6951) nleep/row_max_std 79.9696 (57.6516) nleep/row_min_mean 1483.5452 (1502.5068) lr 6.9098e-04 eta 0:09:31
epoch [32/50] batch [40/173] time 0.162 (0.174) data 0.000 (0.008) loss 1.5768 (1.3784) teacher_loss 0.2824 (0.2578) loss_zs_kd 0.0360 (0.0212) loss_oracle 0.5566 (0.5540) kd_loss 0.9981 (0.8329) acc 90.6250 (90.3125) gate/entropy 0.9859 (0.9858) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0095 (0.0301) teacher/usage_max 0.5290 (0.6848) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2369 (0.2831) nleep/row_max_mean 1547.3685 (1546.9497) nleep/row_max_std 50.8723 (57.1702) nleep/row_min_mean 1503.4209 (1501.5055) lr 6.9098e-04 eta 0:09:23
epoch [32/50] batch [60/173] time 0.118 (0.167) data 0.001 (0.005) loss 1.3631 (1.3860) teacher_loss 0.2815 (0.2659) loss_zs_kd 0.0288 (0.0206) loss_oracle 0.5336 (0.5496) kd_loss 0.8004 (0.8349) acc 84.3750 (89.4271) gate/entropy 0.9858 (0.9858) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0017 (0.0294) teacher/usage_max 0.7501 (0.6834) teacher/usage_min 0.0000 (0.0073) teacher/usage_std 0.3119 (0.2821) nleep/row_max_mean 1542.3494 (1548.2008) nleep/row_max_std 74.4418 (56.7284) nleep/row_min_mean 1494.6019 (1502.4425) lr 6.9098e-04 eta 0:09:00
epoch [32/50] batch [80/173] time 0.173 (0.166) data 0.000 (0.004) loss 1.3486 (1.3784) teacher_loss 0.2041 (0.2665) loss_zs_kd 0.0171 (0.0204) loss_oracle 0.5311 (0.5422) kd_loss 0.8704 (0.8305) acc 90.6250 (89.3750) gate/entropy 0.9859 (0.9858) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0356 (0.0286) teacher/usage_max 0.6379 (0.6899) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.2612 (0.2854) nleep/row_max_mean 1558.3146 (1549.2372) nleep/row_max_std 56.1927 (57.1991) nleep/row_min_mean 1508.2126 (1503.4396) lr 6.9098e-04 eta 0:08:52
epoch [32/50] batch [100/173] time 0.139 (0.167) data 0.000 (0.003) loss 1.3267 (1.3767) teacher_loss 0.2924 (0.2637) loss_zs_kd 0.0246 (0.0199) loss_oracle 0.5391 (0.5414) kd_loss 0.7525 (0.8324) acc 84.3750 (89.4688) gate/entropy 0.9855 (0.9858) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2116 (0.2117) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0321 (0.0272) teacher/usage_max 0.7685 (0.6893) teacher/usage_min 0.0000 (0.0084) teacher/usage_std 0.3219 (0.2845) nleep/row_max_mean 1563.7739 (1550.0881) nleep/row_max_std 70.3262 (58.5229) nleep/row_min_mean 1510.5088 (1503.7392) lr 6.9098e-04 eta 0:08:50
epoch [32/50] batch [120/173] time 0.156 (0.166) data 0.000 (0.003) loss 1.3397 (1.3691) teacher_loss 0.2823 (0.2553) loss_zs_kd 0.0049 (0.0198) loss_oracle 0.5191 (0.5458) kd_loss 0.7954 (0.8311) acc 81.2500 (89.8958) gate/entropy 0.9860 (0.9858) gate/usage_max 0.5650 (0.5652) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1639 (0.1640) teacher/entropy 0.0424 (0.0262) teacher/usage_max 0.7119 (0.6918) teacher/usage_min 0.0104 (0.0097) teacher/usage_std 0.2891 (0.2850) nleep/row_max_mean 1550.7031 (1550.3416) nleep/row_max_std 63.3661 (59.3581) nleep/row_min_mean 1505.9993 (1503.9577) lr 6.9098e-04 eta 0:08:44
epoch [32/50] batch [140/173] time 0.210 (0.167) data 0.000 (0.002) loss 1.4474 (1.3735) teacher_loss 0.2761 (0.2606) loss_zs_kd 0.0212 (0.0192) loss_oracle 0.6119 (0.5463) kd_loss 0.8548 (0.8301) acc 87.5000 (89.5759) gate/entropy 0.9858 (0.9858) gate/usage_max 0.5653 (0.5652) gate/usage_min 0.2116 (0.2117) gate/usage_std 0.1641 (0.1640) teacher/entropy 0.0244 (0.0266) teacher/usage_max 0.6698 (0.6923) teacher/usage_min 0.0624 (0.0113) teacher/usage_std 0.2523 (0.2846) nleep/row_max_mean 1549.5343 (1550.8957) nleep/row_max_std 52.2719 (58.8706) nleep/row_min_mean 1503.7943 (1504.5558) lr 6.9098e-04 eta 0:08:45
epoch [32/50] batch [160/173] time 0.084 (0.161) data 0.000 (0.002) loss 1.5080 (1.3735) teacher_loss 0.3844 (0.2657) loss_zs_kd 0.0399 (0.0195) loss_oracle 0.4936 (0.5447) kd_loss 0.8569 (0.8256) acc 84.3750 (89.4531) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5655 (0.5652) gate/usage_min 0.2116 (0.2117) gate/usage_std 0.1642 (0.1640) teacher/entropy 0.0039 (0.0278) teacher/usage_max 0.6873 (0.6958) teacher/usage_min 0.0003 (0.0114) teacher/usage_std 0.2809 (0.2862) nleep/row_max_mean 1544.2607 (1550.5135) nleep/row_max_std 55.7280 (58.9687) nleep/row_min_mean 1501.4900 (1504.4562) lr 6.9098e-04 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [33/50] batch [20/173] time 0.191 (0.132) data 0.000 (0.015) loss 1.3110 (1.3360) teacher_loss 0.1659 (0.2702) loss_zs_kd 0.0245 (0.0195) loss_oracle 0.5819 (0.5259) kd_loss 0.8419 (0.7931) acc 90.6250 (89.6875) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5655 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1642 (0.1641) teacher/entropy 0.0150 (0.0293) teacher/usage_max 0.6929 (0.7294) teacher/usage_min 0.0313 (0.0215) teacher/usage_std 0.2732 (0.3021) nleep/row_max_mean 1548.7297 (1548.4301) nleep/row_max_std 61.1383 (60.1271) nleep/row_min_mean 1505.5804 (1504.2435) lr 6.3188e-04 eta 0:06:46
epoch [33/50] batch [40/173] time 0.192 (0.123) data 0.000 (0.008) loss 1.2340 (1.3530) teacher_loss 0.2447 (0.2511) loss_zs_kd 0.0229 (0.0195) loss_oracle 0.4994 (0.5391) kd_loss 0.7282 (0.8227) acc 90.6250 (90.0781) gate/entropy 0.9859 (0.9858) gate/usage_max 0.5651 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0430 (0.0265) teacher/usage_max 0.7852 (0.7006) teacher/usage_min 0.0239 (0.0215) teacher/usage_std 0.3267 (0.2873) nleep/row_max_mean 1540.5502 (1547.1682) nleep/row_max_std 60.6644 (59.8397) nleep/row_min_mean 1495.2651 (1503.4885) lr 6.3188e-04 eta 0:06:19
epoch [33/50] batch [60/173] time 0.074 (0.122) data 0.001 (0.005) loss 1.4766 (1.3502) teacher_loss 0.2485 (0.2523) loss_zs_kd 0.0306 (0.0202) loss_oracle 0.6440 (0.5405) kd_loss 0.8908 (0.8176) acc 90.6250 (90.1562) gate/entropy 0.9863 (0.9858) gate/usage_max 0.5647 (0.5653) gate/usage_min 0.2117 (0.2116) gate/usage_std 0.1637 (0.1641) teacher/entropy 0.0244 (0.0256) teacher/usage_max 0.6295 (0.7070) teacher/usage_min 0.0297 (0.0202) teacher/usage_std 0.2449 (0.2905) nleep/row_max_mean 1525.2745 (1548.5926) nleep/row_max_std 64.0165 (60.0009) nleep/row_min_mean 1486.3027 (1504.9225) lr 6.3188e-04 eta 0:06:12
epoch [33/50] batch [80/173] time 0.107 (0.121) data 0.000 (0.004) loss 1.2553 (1.3424) teacher_loss 0.1027 (0.2534) loss_zs_kd 0.0098 (0.0204) loss_oracle 0.5686 (0.5385) kd_loss 0.8634 (0.8095) acc 96.8750 (89.9609) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5654 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1642 (0.1641) teacher/entropy 0.0450 (0.0269) teacher/usage_max 0.6384 (0.7144) teacher/usage_min 0.0475 (0.0227) teacher/usage_std 0.2416 (0.2931) nleep/row_max_mean 1560.7212 (1549.2594) nleep/row_max_std 55.1810 (60.4226) nleep/row_min_mean 1516.1445 (1505.5299) lr 6.3188e-04 eta 0:06:06
epoch [33/50] batch [100/173] time 0.159 (0.125) data 0.000 (0.003) loss 1.4138 (1.3453) teacher_loss 0.3351 (0.2536) loss_zs_kd 0.0214 (0.0198) loss_oracle 0.5346 (0.5394) kd_loss 0.8007 (0.8122) acc 84.3750 (89.9688) gate/entropy 0.9856 (0.9857) gate/usage_max 0.5655 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1642 (0.1641) teacher/entropy 0.0031 (0.0266) teacher/usage_max 0.7499 (0.7117) teacher/usage_min 0.0312 (0.0217) teacher/usage_std 0.3043 (0.2913) nleep/row_max_mean 1561.7283 (1549.3428) nleep/row_max_std 65.7607 (60.9290) nleep/row_min_mean 1513.0784 (1505.7286) lr 6.3188e-04 eta 0:06:15
epoch [33/50] batch [120/173] time 0.164 (0.129) data 0.000 (0.003) loss 1.4083 (1.3466) teacher_loss 0.2386 (0.2526) loss_zs_kd 0.0248 (0.0200) loss_oracle 0.5746 (0.5383) kd_loss 0.8700 (0.8149) acc 93.7500 (90.3646) gate/entropy 0.9859 (0.9857) gate/usage_max 0.5651 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0212 (0.0272) teacher/usage_max 0.6561 (0.7082) teacher/usage_min 0.0374 (0.0211) teacher/usage_std 0.2533 (0.2896) nleep/row_max_mean 1523.2131 (1548.4372) nleep/row_max_std 76.7863 (61.7852) nleep/row_min_mean 1484.1221 (1505.2586) lr 6.3188e-04 eta 0:06:27
epoch [33/50] batch [140/173] time 0.165 (0.133) data 0.000 (0.002) loss 1.3314 (1.3460) teacher_loss 0.3471 (0.2484) loss_zs_kd 0.0156 (0.0197) loss_oracle 0.5469 (0.5416) kd_loss 0.7030 (0.8170) acc 90.6250 (90.5804) gate/entropy 0.9858 (0.9858) gate/usage_max 0.5653 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1641 (0.1641) teacher/entropy 0.0137 (0.0277) teacher/usage_max 0.8419 (0.7055) teacher/usage_min 0.0025 (0.0228) teacher/usage_std 0.3650 (0.2880) nleep/row_max_mean 1538.2147 (1546.7632) nleep/row_max_std 67.9850 (61.9414) nleep/row_min_mean 1491.4937 (1504.0487) lr 6.3188e-04 eta 0:06:36
epoch [33/50] batch [160/173] time 0.129 (0.136) data 0.000 (0.002) loss 1.1939 (1.3384) teacher_loss 0.2346 (0.2433) loss_zs_kd 0.0096 (0.0191) loss_oracle 0.4790 (0.5418) kd_loss 0.7150 (0.8146) acc 87.5000 (90.7812) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5654 (0.5653) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1642 (0.1641) teacher/entropy 0.0008 (0.0280) teacher/usage_max 0.8437 (0.7076) teacher/usage_min 0.0001 (0.0230) teacher/usage_std 0.3665 (0.2887) nleep/row_max_mean 1541.4855 (1545.8392) nleep/row_max_std 61.7412 (62.1668) nleep/row_min_mean 1495.0105 (1503.3073) lr 6.3188e-04 eta 0:06:41
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [34/50] batch [20/173] time 0.154 (0.172) data 0.000 (0.014) loss 1.7080 (1.3711) teacher_loss 0.4943 (0.2555) loss_zs_kd 0.0122 (0.0204) loss_oracle 0.6309 (0.5513) kd_loss 0.8922 (0.8298) acc 81.2500 (91.4062) gate/entropy 0.9855 (0.9856) gate/usage_max 0.5656 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1643 (0.1642) teacher/entropy 0.0218 (0.0311) teacher/usage_max 0.6366 (0.6885) teacher/usage_min 0.1251 (0.0352) teacher/usage_std 0.2194 (0.2731) nleep/row_max_mean 1556.8054 (1542.6106) nleep/row_max_std 51.6621 (60.5273) nleep/row_min_mean 1508.9719 (1501.5062) lr 5.7422e-04 eta 0:08:21
epoch [34/50] batch [40/173] time 0.104 (0.153) data 0.000 (0.007) loss 1.2812 (1.3668) teacher_loss 0.1631 (0.2552) loss_zs_kd 0.0130 (0.0195) loss_oracle 0.4871 (0.5442) kd_loss 0.8680 (0.8297) acc 93.7500 (90.8594) gate/entropy 0.9856 (0.9856) gate/usage_max 0.5655 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0487 (0.0301) teacher/usage_max 0.6260 (0.6893) teacher/usage_min 0.0005 (0.0286) teacher/usage_std 0.2569 (0.2754) nleep/row_max_mean 1559.0259 (1543.2878) nleep/row_max_std 52.2995 (60.2641) nleep/row_min_mean 1512.9814 (1502.2604) lr 5.7422e-04 eta 0:07:23
epoch [34/50] batch [60/173] time 0.074 (0.139) data 0.001 (0.005) loss 1.4060 (1.3736) teacher_loss 0.2687 (0.2624) loss_zs_kd 0.0212 (0.0192) loss_oracle 0.5137 (0.5380) kd_loss 0.8698 (0.8326) acc 87.5000 (90.3125) gate/entropy 0.9857 (0.9856) gate/usage_max 0.5654 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1641 (0.1642) teacher/entropy 0.0713 (0.0296) teacher/usage_max 0.6036 (0.6865) teacher/usage_min 0.0667 (0.0260) teacher/usage_std 0.2192 (0.2751) nleep/row_max_mean 1539.0106 (1542.9963) nleep/row_max_std 46.5660 (59.4700) nleep/row_min_mean 1504.6803 (1502.0483) lr 5.7422e-04 eta 0:06:39
epoch [34/50] batch [80/173] time 0.169 (0.131) data 0.000 (0.004) loss 1.4974 (1.3659) teacher_loss 0.3145 (0.2532) loss_zs_kd 0.0203 (0.0185) loss_oracle 0.6313 (0.5405) kd_loss 0.8571 (0.8332) acc 87.5000 (90.3125) gate/entropy 0.9856 (0.9856) gate/usage_max 0.5655 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0015 (0.0296) teacher/usage_max 0.6875 (0.6858) teacher/usage_min 0.0002 (0.0253) teacher/usage_std 0.2810 (0.2756) nleep/row_max_mean 1551.1301 (1543.6768) nleep/row_max_std 46.8828 (59.1177) nleep/row_min_mean 1510.2570 (1502.7451) lr 5.7422e-04 eta 0:06:14
epoch [34/50] batch [100/173] time 0.073 (0.127) data 0.000 (0.003) loss 1.3632 (1.3692) teacher_loss 0.2534 (0.2547) loss_zs_kd 0.0091 (0.0186) loss_oracle 0.5007 (0.5426) kd_loss 0.8550 (0.8340) acc 87.5000 (90.0312) gate/entropy 0.9859 (0.9856) gate/usage_max 0.5651 (0.5654) gate/usage_min 0.2116 (0.2115) gate/usage_std 0.1640 (0.1642) teacher/entropy 0.0105 (0.0293) teacher/usage_max 0.6855 (0.6852) teacher/usage_min 0.0630 (0.0237) teacher/usage_std 0.2606 (0.2755) nleep/row_max_mean 1536.8605 (1543.9261) nleep/row_max_std 60.3337 (59.4757) nleep/row_min_mean 1499.0364 (1502.7407) lr 5.7422e-04 eta 0:05:59
epoch [34/50] batch [120/173] time 0.165 (0.122) data 0.000 (0.003) loss 1.3693 (1.3749) teacher_loss 0.2882 (0.2563) loss_zs_kd 0.0113 (0.0193) loss_oracle 0.6024 (0.5464) kd_loss 0.7742 (0.8358) acc 90.6250 (89.7396) gate/entropy 0.9856 (0.9857) gate/usage_max 0.5655 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0302 (0.0305) teacher/usage_max 0.7497 (0.6820) teacher/usage_min 0.0484 (0.0244) teacher/usage_std 0.3010 (0.2740) nleep/row_max_mean 1541.2891 (1543.3804) nleep/row_max_std 75.4056 (60.1229) nleep/row_min_mean 1498.4492 (1502.3537) lr 5.7422e-04 eta 0:05:44
epoch [34/50] batch [140/173] time 0.076 (0.121) data 0.000 (0.002) loss 1.4564 (1.3766) teacher_loss 0.2790 (0.2565) loss_zs_kd 0.0362 (0.0192) loss_oracle 0.5091 (0.5470) kd_loss 0.9048 (0.8370) acc 84.3750 (89.7098) gate/entropy 0.9857 (0.9857) gate/usage_max 0.5654 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0566 (0.0317) teacher/usage_max 0.5799 (0.6794) teacher/usage_min 0.0312 (0.0258) teacher/usage_std 0.2274 (0.2727) nleep/row_max_mean 1534.9126 (1543.7906) nleep/row_max_std 59.4650 (59.7987) nleep/row_min_mean 1494.8516 (1502.8170) lr 5.7422e-04 eta 0:05:37
epoch [34/50] batch [160/173] time 0.070 (0.119) data 0.000 (0.002) loss 1.3706 (1.3709) teacher_loss 0.2213 (0.2519) loss_zs_kd 0.0241 (0.0189) loss_oracle 0.5036 (0.5474) kd_loss 0.8855 (0.8359) acc 90.6250 (90.0000) gate/entropy 0.9856 (0.9857) gate/usage_max 0.5654 (0.5654) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1642 (0.1642) teacher/entropy 0.0243 (0.0323) teacher/usage_max 0.6358 (0.6800) teacher/usage_min 0.0313 (0.0246) teacher/usage_std 0.2468 (0.2734) nleep/row_max_mean 1540.6321 (1544.1689) nleep/row_max_std 54.3620 (59.9013) nleep/row_min_mean 1501.8729 (1503.1294) lr 5.7422e-04 eta 0:05:29
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [35/50] batch [20/173] time 0.159 (0.150) data 0.000 (0.015) loss 1.3551 (1.3774) teacher_loss 0.2120 (0.2551) loss_zs_kd 0.0173 (0.0174) loss_oracle 0.5576 (0.5373) kd_loss 0.8556 (0.8450) acc 90.6250 (90.4688) gate/entropy 0.9857 (0.9858) gate/usage_max 0.5654 (0.5653) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1641 (0.1641) teacher/entropy 0.0039 (0.0374) teacher/usage_max 0.6873 (0.6651) teacher/usage_min 0.0005 (0.0354) teacher/usage_std 0.2808 (0.2629) nleep/row_max_mean 1557.8516 (1547.5476) nleep/row_max_std 49.9258 (54.7624) nleep/row_min_mean 1512.6792 (1506.2731) lr 5.1825e-04 eta 0:06:53
epoch [35/50] batch [40/173] time 0.121 (0.144) data 0.000 (0.008) loss 1.3152 (1.3645) teacher_loss 0.1704 (0.2476) loss_zs_kd 0.0181 (0.0169) loss_oracle 0.5040 (0.5364) kd_loss 0.8838 (0.8402) acc 93.7500 (90.7812) gate/entropy 0.9854 (0.9857) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2114 (0.2115) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0050 (0.0347) teacher/usage_max 0.6565 (0.6726) teacher/usage_min 0.0000 (0.0266) teacher/usage_std 0.2681 (0.2697) nleep/row_max_mean 1557.5713 (1547.0544) nleep/row_max_std 43.8633 (54.1874) nleep/row_min_mean 1514.5576 (1506.0395) lr 5.1825e-04 eta 0:06:32
epoch [35/50] batch [60/173] time 0.115 (0.141) data 0.001 (0.005) loss 1.3325 (1.3486) teacher_loss 0.2507 (0.2343) loss_zs_kd 0.0098 (0.0166) loss_oracle 0.5462 (0.5380) kd_loss 0.8038 (0.8370) acc 87.5000 (91.5104) gate/entropy 0.9858 (0.9857) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0565 (0.0344) teacher/usage_max 0.6890 (0.6763) teacher/usage_min 0.0357 (0.0240) teacher/usage_std 0.2699 (0.2721) nleep/row_max_mean 1548.9934 (1545.4917) nleep/row_max_std 58.2126 (55.5908) nleep/row_min_mean 1508.1676 (1504.5534) lr 5.1825e-04 eta 0:06:22
epoch [35/50] batch [80/173] time 0.149 (0.141) data 0.000 (0.004) loss 1.2293 (1.3596) teacher_loss 0.1954 (0.2436) loss_zs_kd 0.0306 (0.0170) loss_oracle 0.5001 (0.5418) kd_loss 0.7687 (0.8366) acc 93.7500 (91.2500) gate/entropy 0.9858 (0.9857) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2115 (0.2115) gate/usage_std 0.1641 (0.1641) teacher/entropy 0.0794 (0.0381) teacher/usage_max 0.7000 (0.6728) teacher/usage_min 0.0000 (0.0242) teacher/usage_std 0.2868 (0.2708) nleep/row_max_mean 1532.2714 (1544.6388) nleep/row_max_std 58.8109 (56.8323) nleep/row_min_mean 1494.9703 (1503.9257) lr 5.1825e-04 eta 0:06:18
epoch [35/50] batch [100/173] time 0.151 (0.142) data 0.000 (0.003) loss 1.2706 (1.3558) teacher_loss 0.1899 (0.2400) loss_zs_kd 0.0188 (0.0172) loss_oracle 0.6200 (0.5453) kd_loss 0.7613 (0.8345) acc 93.7500 (91.3438) gate/entropy 0.9857 (0.9857) gate/usage_max 0.5653 (0.5653) gate/usage_min 0.2114 (0.2115) gate/usage_std 0.1641 (0.1641) teacher/entropy 0.0688 (0.0419) teacher/usage_max 0.7198 (0.6708) teacher/usage_min 0.0190 (0.0241) teacher/usage_std 0.2906 (0.2694) nleep/row_max_mean 1555.5894 (1545.1807) nleep/row_max_std 50.6383 (57.3636) nleep/row_min_mean 1514.8140 (1504.3326) lr 5.1825e-04 eta 0:06:19
epoch [35/50] batch [120/173] time 0.123 (0.142) data 0.000 (0.003) loss 1.2678 (1.3600) teacher_loss 0.2304 (0.2379) loss_zs_kd 0.0098 (0.0177) loss_oracle 0.5078 (0.5519) kd_loss 0.7786 (0.8373) acc 87.5000 (91.1979) gate/entropy 0.9855 (0.9857) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2114 (0.2115) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0491 (0.0418) teacher/usage_max 0.7250 (0.6680) teacher/usage_min 0.0534 (0.0255) teacher/usage_std 0.2853 (0.2676) nleep/row_max_mean 1560.6444 (1545.2502) nleep/row_max_std 60.2580 (57.7074) nleep/row_min_mean 1521.1063 (1504.6068) lr 5.1825e-04 eta 0:06:16
epoch [35/50] batch [140/173] time 0.132 (0.142) data 0.000 (0.002) loss 1.4758 (1.3717) teacher_loss 0.3118 (0.2432) loss_zs_kd 0.0287 (0.0182) loss_oracle 0.6587 (0.5545) kd_loss 0.8202 (0.8422) acc 90.6250 (91.0938) gate/entropy 0.9855 (0.9857) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0189 (0.0431) teacher/usage_max 0.7148 (0.6620) teacher/usage_min 0.0956 (0.0265) teacher/usage_std 0.2725 (0.2647) nleep/row_max_mean 1544.9154 (1545.1679) nleep/row_max_std 60.0265 (57.6600) nleep/row_min_mean 1509.7510 (1504.7891) lr 5.1825e-04 eta 0:06:13
epoch [35/50] batch [160/173] time 0.120 (0.142) data 0.000 (0.002) loss 1.3892 (1.3771) teacher_loss 0.2102 (0.2464) loss_zs_kd 0.0299 (0.0188) loss_oracle 0.6068 (0.5553) kd_loss 0.8606 (0.8437) acc 93.7500 (90.8789) gate/entropy 0.9858 (0.9857) gate/usage_max 0.5652 (0.5653) gate/usage_min 0.2114 (0.2114) gate/usage_std 0.1640 (0.1641) teacher/entropy 0.0453 (0.0436) teacher/usage_max 0.6365 (0.6598) teacher/usage_min 0.0001 (0.0281) teacher/usage_std 0.2607 (0.2631) nleep/row_max_mean 1537.6936 (1544.5935) nleep/row_max_std 54.0270 (57.4661) nleep/row_min_mean 1497.2483 (1504.5720) lr 5.1825e-04 eta 0:06:11
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,988
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.0%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [36/50] batch [20/173] time 0.057 (0.119) data 0.000 (0.020) loss 1.3120 (1.3768) teacher_loss 0.1765 (0.2300) loss_zs_kd 0.0186 (0.0225) loss_oracle 0.5518 (0.5622) kd_loss 0.8503 (0.8545) acc 96.8750 (91.5625) gate/entropy 0.9857 (0.9859) gate/usage_max 0.5653 (0.5652) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1641 (0.1640) teacher/entropy 0.0502 (0.0583) teacher/usage_max 0.6478 (0.6325) teacher/usage_min 0.0767 (0.0410) teacher/usage_std 0.2367 (0.2464) nleep/row_max_mean 1546.9358 (1537.3855) nleep/row_max_std 61.8363 (56.9383) nleep/row_min_mean 1505.3486 (1500.7579) lr 4.6417e-04 eta 0:05:07
epoch [36/50] batch [40/173] time 0.092 (0.113) data 0.000 (0.010) loss 1.4197 (1.3941) teacher_loss 0.2599 (0.2498) loss_zs_kd 0.0213 (0.0205) loss_oracle 0.6297 (0.5617) kd_loss 0.8343 (0.8532) acc 90.6250 (90.8594) gate/entropy 0.9862 (0.9859) gate/usage_max 0.5648 (0.5652) gate/usage_min 0.2114 (0.2114) gate/usage_std 0.1638 (0.1640) teacher/entropy 0.0576 (0.0571) teacher/usage_max 0.6533 (0.6349) teacher/usage_min 0.0287 (0.0368) teacher/usage_std 0.2552 (0.2501) nleep/row_max_mean 1526.3921 (1538.2156) nleep/row_max_std 56.8833 (54.3451) nleep/row_min_mean 1490.0537 (1501.5288) lr 4.6417e-04 eta 0:04:47
epoch [36/50] batch [60/173] time 0.137 (0.112) data 0.001 (0.007) loss 1.6395 (1.3936) teacher_loss 0.4242 (0.2533) loss_zs_kd 0.0439 (0.0201) loss_oracle 0.5508 (0.5562) kd_loss 0.9179 (0.8521) acc 81.2500 (90.2604) gate/entropy 0.9858 (0.9858) gate/usage_max 0.5652 (0.5652) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1641 (0.1640) teacher/entropy 0.0283 (0.0506) teacher/usage_max 0.5949 (0.6429) teacher/usage_min 0.0261 (0.0344) teacher/usage_std 0.2344 (0.2550) nleep/row_max_mean 1540.9929 (1540.8799) nleep/row_max_std 52.6941 (53.9229) nleep/row_min_mean 1502.7476 (1503.8977) lr 4.6417e-04 eta 0:04:43
epoch [36/50] batch [80/173] time 0.177 (0.116) data 0.000 (0.005) loss 1.3648 (1.3926) teacher_loss 0.2163 (0.2531) loss_zs_kd 0.0142 (0.0199) loss_oracle 0.5652 (0.5543) kd_loss 0.8588 (0.8524) acc 90.6250 (90.1953) gate/entropy 0.9860 (0.9858) gate/usage_max 0.5650 (0.5652) gate/usage_min 0.2114 (0.2114) gate/usage_std 0.1639 (0.1640) teacher/entropy 0.1219 (0.0498) teacher/usage_max 0.5582 (0.6440) teacher/usage_min 0.0260 (0.0328) teacher/usage_std 0.2250 (0.2565) nleep/row_max_mean 1537.3088 (1541.7480) nleep/row_max_std 60.9091 (53.3371) nleep/row_min_mean 1502.7012 (1504.6744) lr 4.6417e-04 eta 0:04:50
epoch [36/50] batch [100/173] time 0.160 (0.116) data 0.000 (0.004) loss 1.4485 (1.3884) teacher_loss 0.2729 (0.2477) loss_zs_kd 0.0132 (0.0201) loss_oracle 0.5352 (0.5557) kd_loss 0.9014 (0.8527) acc 90.6250 (90.4688) gate/entropy 0.9859 (0.9858) gate/usage_max 0.5651 (0.5652) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1640 (0.1640) teacher/entropy 0.0479 (0.0492) teacher/usage_max 0.5946 (0.6442) teacher/usage_min 0.0606 (0.0325) teacher/usage_std 0.2181 (0.2562) nleep/row_max_mean 1532.6367 (1541.7823) nleep/row_max_std 55.2000 (53.5174) nleep/row_min_mean 1496.9244 (1504.8146) lr 4.6417e-04 eta 0:04:50
epoch [36/50] batch [120/173] time 0.135 (0.123) data 0.000 (0.003) loss 1.3917 (1.3951) teacher_loss 0.1403 (0.2498) loss_zs_kd 0.0090 (0.0210) loss_oracle 0.6273 (0.5584) kd_loss 0.9332 (0.8555) acc 93.7500 (90.2083) gate/entropy 0.9860 (0.9859) gate/usage_max 0.5651 (0.5652) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1639 (0.1640) teacher/entropy 0.0246 (0.0489) teacher/usage_max 0.5873 (0.6415) teacher/usage_min 0.0951 (0.0334) teacher/usage_std 0.2012 (0.2549) nleep/row_max_mean 1549.8301 (1542.3302) nleep/row_max_std 48.2797 (52.8144) nleep/row_min_mean 1508.5458 (1505.1322) lr 4.6417e-04 eta 0:05:03
epoch [36/50] batch [140/173] time 0.163 (0.126) data 0.000 (0.003) loss 1.3864 (1.3900) teacher_loss 0.1810 (0.2409) loss_zs_kd 0.0021 (0.0205) loss_oracle 0.5084 (0.5584) kd_loss 0.9501 (0.8596) acc 93.7500 (90.6696) gate/entropy 0.9862 (0.9859) gate/usage_max 0.5648 (0.5652) gate/usage_min 0.2114 (0.2113) gate/usage_std 0.1638 (0.1640) teacher/entropy 0.0368 (0.0507) teacher/usage_max 0.5513 (0.6354) teacher/usage_min 0.0341 (0.0363) teacher/usage_std 0.2188 (0.2512) nleep/row_max_mean 1543.9302 (1541.9542) nleep/row_max_std 49.6830 (53.3025) nleep/row_min_mean 1508.6631 (1505.1196) lr 4.6417e-04 eta 0:05:09
epoch [36/50] batch [160/173] time 0.159 (0.130) data 0.000 (0.003) loss 1.4197 (1.3907) teacher_loss 0.2496 (0.2440) loss_zs_kd 0.0250 (0.0206) loss_oracle 0.5472 (0.5558) kd_loss 0.8841 (0.8585) acc 93.7500 (90.5273) gate/entropy 0.9860 (0.9859) gate/usage_max 0.5650 (0.5651) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1639 (0.1640) teacher/entropy 0.0222 (0.0500) teacher/usage_max 0.6383 (0.6373) teacher/usage_min 0.0313 (0.0364) teacher/usage_std 0.2478 (0.2516) nleep/row_max_mean 1540.0361 (1541.8365) nleep/row_max_std 56.1814 (53.7690) nleep/row_min_mean 1503.1523 (1504.9609) lr 4.6417e-04 eta 0:05:16
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,993
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [37/50] batch [20/173] time 0.162 (0.186) data 0.000 (0.014) loss 1.2685 (1.4200) teacher_loss 0.1668 (0.2537) loss_zs_kd 0.0120 (0.0192) loss_oracle 0.4895 (0.5403) kd_loss 0.8509 (0.8866) acc 93.7500 (89.6875) gate/entropy 0.9862 (0.9860) gate/usage_max 0.5648 (0.5650) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1638 (0.1639) teacher/entropy 0.1086 (0.0500) teacher/usage_max 0.5822 (0.6093) teacher/usage_min 0.0413 (0.0332) teacher/usage_std 0.2229 (0.2417) nleep/row_max_mean 1534.2234 (1538.4529) nleep/row_max_std 57.7233 (52.6135) nleep/row_min_mean 1495.9340 (1502.6430) lr 4.1221e-04 eta 0:07:26
epoch [37/50] batch [40/173] time 0.167 (0.172) data 0.000 (0.007) loss 1.4437 (1.3960) teacher_loss 0.2595 (0.2495) loss_zs_kd 0.0294 (0.0203) loss_oracle 0.5308 (0.5383) kd_loss 0.9041 (0.8673) acc 87.5000 (90.1562) gate/entropy 0.9865 (0.9861) gate/usage_max 0.5645 (0.5649) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1635 (0.1639) teacher/entropy 0.1082 (0.0566) teacher/usage_max 0.5263 (0.6231) teacher/usage_min 0.0697 (0.0350) teacher/usage_std 0.1930 (0.2453) nleep/row_max_mean 1512.2408 (1539.6677) nleep/row_max_std 64.3692 (55.1808) nleep/row_min_mean 1481.3763 (1503.4374) lr 4.1221e-04 eta 0:06:49
epoch [37/50] batch [60/173] time 0.107 (0.152) data 0.001 (0.005) loss 1.4417 (1.3884) teacher_loss 0.2739 (0.2536) loss_zs_kd 0.0258 (0.0220) loss_oracle 0.5422 (0.5373) kd_loss 0.8838 (0.8551) acc 93.7500 (89.8958) gate/entropy 0.9861 (0.9860) gate/usage_max 0.5649 (0.5650) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1639 (0.1639) teacher/entropy 0.0701 (0.0538) teacher/usage_max 0.5888 (0.6382) teacher/usage_min 0.0632 (0.0358) teacher/usage_std 0.2148 (0.2513) nleep/row_max_mean 1541.8212 (1542.7653) nleep/row_max_std 64.9217 (55.2527) nleep/row_min_mean 1502.3445 (1505.6748) lr 4.1221e-04 eta 0:05:59
epoch [37/50] batch [80/173] time 0.073 (0.145) data 0.000 (0.004) loss 1.4080 (1.3733) teacher_loss 0.2674 (0.2430) loss_zs_kd 0.0117 (0.0217) loss_oracle 0.5817 (0.5359) kd_loss 0.8439 (0.8515) acc 87.5000 (90.5469) gate/entropy 0.9859 (0.9860) gate/usage_max 0.5651 (0.5650) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1639 (0.1639) teacher/entropy 0.0347 (0.0506) teacher/usage_max 0.6701 (0.6450) teacher/usage_min 0.0628 (0.0359) teacher/usage_std 0.2523 (0.2537) nleep/row_max_mean 1548.5573 (1543.6966) nleep/row_max_std 64.9929 (56.7079) nleep/row_min_mean 1507.6732 (1506.3256) lr 4.1221e-04 eta 0:05:38
epoch [37/50] batch [100/173] time 0.099 (0.137) data 0.000 (0.003) loss 1.5610 (1.3794) teacher_loss 0.4535 (0.2465) loss_zs_kd 0.0167 (0.0214) loss_oracle 0.5284 (0.5422) kd_loss 0.8349 (0.8512) acc 87.5000 (90.2188) gate/entropy 0.9856 (0.9860) gate/usage_max 0.5654 (0.5650) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1642 (0.1639) teacher/entropy 0.0808 (0.0508) teacher/usage_max 0.6297 (0.6449) teacher/usage_min 0.0468 (0.0376) teacher/usage_std 0.2381 (0.2531) nleep/row_max_mean 1556.7611 (1544.3159) nleep/row_max_std 49.6086 (56.9550) nleep/row_min_mean 1515.6515 (1506.8936) lr 4.1221e-04 eta 0:05:17
epoch [37/50] batch [120/173] time 0.088 (0.134) data 0.000 (0.003) loss 1.3088 (1.3808) teacher_loss 0.2396 (0.2436) loss_zs_kd 0.0190 (0.0210) loss_oracle 0.5818 (0.5460) kd_loss 0.7687 (0.8536) acc 90.6250 (90.2865) gate/entropy 0.9858 (0.9860) gate/usage_max 0.5652 (0.5650) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1640 (0.1639) teacher/entropy 0.0029 (0.0523) teacher/usage_max 0.7817 (0.6405) teacher/usage_min 0.0000 (0.0389) teacher/usage_std 0.3293 (0.2512) nleep/row_max_mean 1568.1917 (1544.1082) nleep/row_max_std 61.6404 (57.6184) nleep/row_min_mean 1522.9399 (1506.7068) lr 4.1221e-04 eta 0:05:08
epoch [37/50] batch [140/173] time 0.193 (0.131) data 0.000 (0.002) loss 1.4998 (1.3835) teacher_loss 0.1565 (0.2431) loss_zs_kd 0.0238 (0.0207) loss_oracle 0.5603 (0.5496) kd_loss 1.0512 (0.8553) acc 93.7500 (90.2679) gate/entropy 0.9865 (0.9861) gate/usage_max 0.5645 (0.5649) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1635 (0.1638) teacher/entropy 0.0149 (0.0525) teacher/usage_max 0.4680 (0.6384) teacher/usage_min 0.0644 (0.0405) teacher/usage_std 0.1902 (0.2500) nleep/row_max_mean 1517.9392 (1544.0321) nleep/row_max_std 54.7841 (58.0442) nleep/row_min_mean 1492.0688 (1506.5598) lr 4.1221e-04 eta 0:04:59
epoch [37/50] batch [160/173] time 0.066 (0.128) data 0.000 (0.002) loss 1.2416 (1.3850) teacher_loss 0.1006 (0.2449) loss_zs_kd 0.0148 (0.0207) loss_oracle 0.5153 (0.5497) kd_loss 0.8760 (0.8549) acc 96.8750 (90.1758) gate/entropy 0.9861 (0.9861) gate/usage_max 0.5649 (0.5649) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0180 (0.0514) teacher/usage_max 0.6527 (0.6400) teacher/usage_min 0.0324 (0.0422) teacher/usage_std 0.2536 (0.2498) nleep/row_max_mean 1550.1765 (1544.0089) nleep/row_max_std 38.6784 (57.9577) nleep/row_min_mean 1516.5331 (1506.5007) lr 4.1221e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,306
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,987
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.0%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [38/50] batch [20/173] time 0.147 (0.166) data 0.000 (0.019) loss 1.2023 (1.3523) teacher_loss 0.1594 (0.2266) loss_zs_kd 0.0130 (0.0215) loss_oracle 0.5772 (0.5615) kd_loss 0.7478 (0.8341) acc 93.7500 (91.2500) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0276 (0.0498) teacher/usage_max 0.7776 (0.6635) teacher/usage_min 0.0002 (0.0453) teacher/usage_std 0.3270 (0.2570) nleep/row_max_mean 1565.7698 (1548.8934) nleep/row_max_std 59.4031 (58.1407) nleep/row_min_mean 1521.4360 (1510.3620) lr 3.6258e-04 eta 0:06:10
epoch [38/50] batch [40/173] time 0.146 (0.158) data 0.000 (0.010) loss 1.4526 (1.3573) teacher_loss 0.3308 (0.2421) loss_zs_kd 0.0283 (0.0227) loss_oracle 0.5691 (0.5440) kd_loss 0.8231 (0.8318) acc 84.3750 (90.9375) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0376 (0.0513) teacher/usage_max 0.6876 (0.6682) teacher/usage_min 0.0236 (0.0457) teacher/usage_std 0.2729 (0.2597) nleep/row_max_mean 1541.8984 (1548.6020) nleep/row_max_std 59.4811 (58.2692) nleep/row_min_mean 1504.6248 (1510.1207) lr 3.6258e-04 eta 0:05:48
epoch [38/50] batch [60/173] time 0.151 (0.157) data 0.001 (0.007) loss 1.2266 (1.3508) teacher_loss 0.1311 (0.2352) loss_zs_kd 0.0100 (0.0221) loss_oracle 0.5416 (0.5381) kd_loss 0.8196 (0.8355) acc 96.8750 (91.2500) gate/entropy 0.9861 (0.9861) gate/usage_max 0.5649 (0.5648) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0577 (0.0481) teacher/usage_max 0.6748 (0.6666) teacher/usage_min 0.0974 (0.0474) teacher/usage_std 0.2472 (0.2587) nleep/row_max_mean 1558.9049 (1549.3701) nleep/row_max_std 49.5862 (58.7214) nleep/row_min_mean 1520.3601 (1510.7319) lr 3.6258e-04 eta 0:05:44
epoch [38/50] batch [80/173] time 0.163 (0.155) data 0.000 (0.005) loss 1.3528 (1.3576) teacher_loss 0.1303 (0.2327) loss_zs_kd 0.0119 (0.0218) loss_oracle 0.5087 (0.5396) kd_loss 0.9622 (0.8442) acc 93.7500 (91.2500) gate/entropy 0.9862 (0.9861) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0237 (0.0480) teacher/usage_max 0.5545 (0.6570) teacher/usage_min 0.0699 (0.0536) teacher/usage_std 0.2001 (0.2528) nleep/row_max_mean 1549.9033 (1549.7593) nleep/row_max_std 52.9878 (58.8280) nleep/row_min_mean 1510.2908 (1510.9934) lr 3.6258e-04 eta 0:05:36
epoch [38/50] batch [100/173] time 0.137 (0.155) data 0.000 (0.004) loss 1.3257 (1.3525) teacher_loss 0.3361 (0.2331) loss_zs_kd 0.0289 (0.0227) loss_oracle 0.4917 (0.5378) kd_loss 0.7293 (0.8392) acc 87.5000 (91.3125) gate/entropy 0.9860 (0.9861) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2112) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0733 (0.0503) teacher/usage_max 0.7538 (0.6595) teacher/usage_min 0.0793 (0.0536) teacher/usage_std 0.2994 (0.2541) nleep/row_max_mean 1552.9270 (1548.7401) nleep/row_max_std 55.7883 (59.5330) nleep/row_min_mean 1514.6489 (1510.3527) lr 3.6258e-04 eta 0:05:32
epoch [38/50] batch [120/173] time 0.162 (0.156) data 0.000 (0.003) loss 1.2901 (1.3485) teacher_loss 0.1706 (0.2313) loss_zs_kd 0.0337 (0.0226) loss_oracle 0.5180 (0.5362) kd_loss 0.8437 (0.8378) acc 93.7500 (91.3021) gate/entropy 0.9864 (0.9862) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1636 (0.1638) teacher/entropy 0.0555 (0.0521) teacher/usage_max 0.6511 (0.6593) teacher/usage_min 0.0964 (0.0582) teacher/usage_std 0.2336 (0.2525) nleep/row_max_mean 1530.6641 (1548.1987) nleep/row_max_std 61.7018 (60.7017) nleep/row_min_mean 1496.8042 (1510.0200) lr 3.6258e-04 eta 0:05:32
epoch [38/50] batch [140/173] time 0.135 (0.156) data 0.000 (0.003) loss 1.2812 (1.3532) teacher_loss 0.2318 (0.2355) loss_zs_kd 0.0243 (0.0224) loss_oracle 0.4931 (0.5363) kd_loss 0.7907 (0.8384) acc 90.6250 (91.0938) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0114 (0.0510) teacher/usage_max 0.7498 (0.6596) teacher/usage_min 0.0001 (0.0595) teacher/usage_std 0.3117 (0.2523) nleep/row_max_mean 1552.8234 (1548.4520) nleep/row_max_std 52.9606 (60.3136) nleep/row_min_mean 1512.1675 (1510.3312) lr 3.6258e-04 eta 0:05:29
epoch [38/50] batch [160/173] time 0.078 (0.155) data 0.000 (0.003) loss 1.2244 (1.3594) teacher_loss 0.2220 (0.2381) loss_zs_kd 0.0196 (0.0224) loss_oracle 0.5055 (0.5392) kd_loss 0.7398 (0.8405) acc 90.6250 (90.8008) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0701 (0.0524) teacher/usage_max 0.7438 (0.6566) teacher/usage_min 0.0436 (0.0621) teacher/usage_std 0.2983 (0.2499) nleep/row_max_mean 1554.2291 (1548.2155) nleep/row_max_std 50.9893 (60.1678) nleep/row_min_mean 1518.9111 (1510.1909) lr 3.6258e-04 eta 0:05:23
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,989
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.0%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [39/50] batch [20/173] time 0.072 (0.135) data 0.000 (0.017) loss 1.3603 (1.3792) teacher_loss 0.3313 (0.2400) loss_zs_kd 0.0256 (0.0242) loss_oracle 0.4252 (0.5484) kd_loss 0.8036 (0.8530) acc 84.3750 (90.3125) gate/entropy 0.9861 (0.9862) gate/usage_max 0.5649 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0877 (0.0579) teacher/usage_max 0.6625 (0.6391) teacher/usage_min 0.1513 (0.1137) teacher/usage_std 0.2332 (0.2284) nleep/row_max_mean 1549.7561 (1542.0073) nleep/row_max_std 54.6378 (61.3585) nleep/row_min_mean 1508.3585 (1505.7041) lr 3.1545e-04 eta 0:04:37
epoch [39/50] batch [40/173] time 0.089 (0.120) data 0.000 (0.009) loss 1.3846 (1.3810) teacher_loss 0.2736 (0.2174) loss_zs_kd 0.0460 (0.0274) loss_oracle 0.5184 (0.5549) kd_loss 0.8289 (0.8724) acc 90.6250 (91.6406) gate/entropy 0.9858 (0.9862) gate/usage_max 0.5652 (0.5648) gate/usage_min 0.2110 (0.2111) gate/usage_std 0.1641 (0.1638) teacher/entropy 0.0484 (0.0577) teacher/usage_max 0.6701 (0.6181) teacher/usage_min 0.0389 (0.1117) teacher/usage_std 0.2594 (0.2168) nleep/row_max_mean 1551.2605 (1541.3969) nleep/row_max_std 59.7135 (58.0743) nleep/row_min_mean 1512.5924 (1505.8616) lr 3.1545e-04 eta 0:04:05
epoch [39/50] batch [60/173] time 0.095 (0.116) data 0.001 (0.006) loss 1.3853 (1.3789) teacher_loss 0.2606 (0.2162) loss_zs_kd 0.0247 (0.0277) loss_oracle 0.5167 (0.5490) kd_loss 0.8540 (0.8743) acc 90.6250 (91.8229) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0403 (0.0592) teacher/usage_max 0.6535 (0.6150) teacher/usage_min 0.0653 (0.1183) teacher/usage_std 0.2429 (0.2130) nleep/row_max_mean 1548.4373 (1542.7060) nleep/row_max_std 50.6687 (57.5508) nleep/row_min_mean 1515.7751 (1507.2580) lr 3.1545e-04 eta 0:03:54
epoch [39/50] batch [80/173] time 0.092 (0.117) data 0.001 (0.004) loss 1.4123 (1.3769) teacher_loss 0.1555 (0.2108) loss_zs_kd 0.0365 (0.0280) loss_oracle 0.6314 (0.5507) kd_loss 0.9228 (0.8768) acc 93.7500 (91.9922) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.1174 (0.0610) teacher/usage_max 0.5047 (0.6110) teacher/usage_min 0.2067 (0.1264) teacher/usage_std 0.1257 (0.2087) nleep/row_max_mean 1544.8772 (1542.4755) nleep/row_max_std 63.5180 (58.3639) nleep/row_min_mean 1506.0038 (1506.7832) lr 3.1545e-04 eta 0:03:53
epoch [39/50] batch [100/173] time 0.152 (0.120) data 0.000 (0.004) loss 1.3838 (1.3871) teacher_loss 0.1945 (0.2115) loss_zs_kd 0.0329 (0.0284) loss_oracle 0.5622 (0.5511) kd_loss 0.8918 (0.8858) acc 87.5000 (91.9375) gate/entropy 0.9863 (0.9862) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1638) teacher/entropy 0.1046 (0.0606) teacher/usage_max 0.5594 (0.6024) teacher/usage_min 0.1293 (0.1322) teacher/usage_std 0.1763 (0.2025) nleep/row_max_mean 1542.0964 (1541.9306) nleep/row_max_std 65.0256 (59.1212) nleep/row_min_mean 1507.8389 (1506.3312) lr 3.1545e-04 eta 0:03:56
epoch [39/50] batch [120/173] time 0.151 (0.124) data 0.000 (0.003) loss 1.5608 (1.3887) teacher_loss 0.3624 (0.2099) loss_zs_kd 0.0283 (0.0285) loss_oracle 0.5232 (0.5538) kd_loss 0.9227 (0.8876) acc 81.2500 (92.0052) gate/entropy 0.9863 (0.9862) gate/usage_max 0.5647 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.0869 (0.0619) teacher/usage_max 0.5429 (0.5996) teacher/usage_min 0.1855 (0.1389) teacher/usage_std 0.1523 (0.1991) nleep/row_max_mean 1533.9227 (1542.1636) nleep/row_max_std 65.1699 (59.9177) nleep/row_min_mean 1504.6772 (1506.5468) lr 3.1545e-04 eta 0:04:03
epoch [39/50] batch [140/173] time 0.158 (0.128) data 0.000 (0.003) loss 1.4265 (1.3867) teacher_loss 0.2663 (0.2059) loss_zs_kd 0.0278 (0.0290) loss_oracle 0.5705 (0.5541) kd_loss 0.8611 (0.8893) acc 90.6250 (92.2991) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.0763 (0.0617) teacher/usage_max 0.6118 (0.5982) teacher/usage_min 0.1383 (0.1388) teacher/usage_std 0.2021 (0.1986) nleep/row_max_mean 1533.0244 (1541.7851) nleep/row_max_std 69.2435 (60.7476) nleep/row_min_mean 1497.1670 (1506.0670) lr 3.1545e-04 eta 0:04:07
epoch [39/50] batch [160/173] time 0.133 (0.130) data 0.000 (0.002) loss 1.4232 (1.3918) teacher_loss 0.1380 (0.2047) loss_zs_kd 0.0372 (0.0293) loss_oracle 0.5232 (0.5520) kd_loss 1.0050 (0.8964) acc 96.8750 (92.2852) gate/entropy 0.9861 (0.9862) gate/usage_max 0.5649 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0757 (0.0611) teacher/usage_max 0.4658 (0.5915) teacher/usage_min 0.2629 (0.1452) teacher/usage_std 0.0937 (0.1930) nleep/row_max_mean 1538.7679 (1541.3579) nleep/row_max_std 62.7169 (61.1642) nleep/row_min_mean 1508.9602 (1505.7825) lr 3.1545e-04 eta 0:04:09
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.5%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [40/50] batch [20/173] time 0.127 (0.158) data 0.000 (0.025) loss 1.4645 (1.4329) teacher_loss 0.1432 (0.1923) loss_zs_kd 0.0436 (0.0321) loss_oracle 0.5497 (0.5498) kd_loss 1.0246 (0.9497) acc 96.8750 (92.0312) gate/entropy 0.9863 (0.9861) gate/usage_max 0.5647 (0.5649) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.0468 (0.0589) teacher/usage_max 0.4765 (0.5404) teacher/usage_min 0.2316 (0.1948) teacher/usage_std 0.1042 (0.1505) nleep/row_max_mean 1522.3708 (1542.3635) nleep/row_max_std 59.0956 (57.5720) nleep/row_min_mean 1489.9146 (1507.5498) lr 2.7103e-04 eta 0:04:56
epoch [40/50] batch [40/173] time 0.141 (0.154) data 0.000 (0.013) loss 1.3812 (1.4478) teacher_loss 0.0893 (0.1794) loss_zs_kd 0.0434 (0.0335) loss_oracle 0.5618 (0.5490) kd_loss 0.9893 (0.9771) acc 96.8750 (92.8906) gate/entropy 0.9864 (0.9861) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1638) teacher/entropy 0.1031 (0.0602) teacher/usage_max 0.4524 (0.5128) teacher/usage_min 0.2703 (0.1914) teacher/usage_std 0.0843 (0.1389) nleep/row_max_mean 1538.1946 (1540.8704) nleep/row_max_std 62.7008 (56.4626) nleep/row_min_mean 1508.3345 (1506.9735) lr 2.7103e-04 eta 0:04:46
epoch [40/50] batch [60/173] time 0.101 (0.144) data 0.001 (0.009) loss 1.4740 (1.4509) teacher_loss 0.1465 (0.1817) loss_zs_kd 0.0292 (0.0330) loss_oracle 0.6357 (0.5515) kd_loss 0.9951 (0.9770) acc 90.6250 (92.6042) gate/entropy 0.9861 (0.9861) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0224 (0.0594) teacher/usage_max 0.5301 (0.5128) teacher/usage_min 0.2199 (0.1952) teacher/usage_std 0.1397 (0.1374) nleep/row_max_mean 1549.1333 (1541.9841) nleep/row_max_std 52.5501 (56.5275) nleep/row_min_mean 1513.1365 (1507.6635) lr 2.7103e-04 eta 0:04:24
epoch [40/50] batch [80/173] time 0.123 (0.136) data 0.000 (0.006) loss 1.4403 (1.4414) teacher_loss 0.2487 (0.1782) loss_zs_kd 0.0361 (0.0332) loss_oracle 0.5783 (0.5544) kd_loss 0.8844 (0.9694) acc 87.5000 (92.6953) gate/entropy 0.9860 (0.9861) gate/usage_max 0.5650 (0.5649) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0581 (0.0611) teacher/usage_max 0.6081 (0.5183) teacher/usage_min 0.1662 (0.1945) teacher/usage_std 0.1958 (0.1405) nleep/row_max_mean 1553.6184 (1543.1109) nleep/row_max_std 53.7330 (56.2510) nleep/row_min_mean 1517.0492 (1508.6338) lr 2.7103e-04 eta 0:04:07
epoch [40/50] batch [100/173] time 0.096 (0.132) data 0.000 (0.005) loss 1.4864 (1.4411) teacher_loss 0.0951 (0.1775) loss_zs_kd 0.0352 (0.0326) loss_oracle 0.6764 (0.5558) kd_loss 1.0355 (0.9694) acc 96.8750 (92.8750) gate/entropy 0.9865 (0.9861) gate/usage_max 0.5645 (0.5649) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1638) teacher/entropy 0.0345 (0.0596) teacher/usage_max 0.4689 (0.5201) teacher/usage_min 0.1508 (0.1929) teacher/usage_std 0.1340 (0.1421) nleep/row_max_mean 1541.4994 (1544.1777) nleep/row_max_std 55.7723 (55.6964) nleep/row_min_mean 1505.1016 (1509.5889) lr 2.7103e-04 eta 0:03:57
epoch [40/50] batch [120/173] time 0.090 (0.129) data 0.000 (0.004) loss 1.4521 (1.4411) teacher_loss 0.1079 (0.1785) loss_zs_kd 0.0276 (0.0327) loss_oracle 0.6147 (0.5581) kd_loss 1.0231 (0.9672) acc 93.7500 (92.8385) gate/entropy 0.9864 (0.9861) gate/usage_max 0.5646 (0.5649) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1638) teacher/entropy 0.0850 (0.0589) teacher/usage_max 0.4593 (0.5230) teacher/usage_min 0.1157 (0.1897) teacher/usage_std 0.1545 (0.1445) nleep/row_max_mean 1537.2388 (1544.7472) nleep/row_max_std 61.7875 (55.5957) nleep/row_min_mean 1505.4819 (1510.1197) lr 2.7103e-04 eta 0:03:49
epoch [40/50] batch [140/173] time 0.072 (0.127) data 0.000 (0.004) loss 1.4882 (1.4470) teacher_loss 0.1186 (0.1829) loss_zs_kd 0.0525 (0.0331) loss_oracle 0.5143 (0.5591) kd_loss 1.0861 (0.9679) acc 96.8750 (92.7679) gate/entropy 0.9861 (0.9861) gate/usage_max 0.5649 (0.5649) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0172 (0.0577) teacher/usage_max 0.4375 (0.5235) teacher/usage_min 0.2170 (0.1880) teacher/usage_std 0.0904 (0.1454) nleep/row_max_mean 1542.6588 (1544.3874) nleep/row_max_std 44.0237 (55.6916) nleep/row_min_mean 1508.6719 (1509.8736) lr 2.7103e-04 eta 0:03:43
epoch [40/50] batch [160/173] time 0.072 (0.122) data 0.000 (0.003) loss 1.5036 (1.4514) teacher_loss 0.1620 (0.1833) loss_zs_kd 0.0271 (0.0324) loss_oracle 0.6549 (0.5585) kd_loss 1.0006 (0.9726) acc 90.6250 (92.6953) gate/entropy 0.9862 (0.9861) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.1113 (0.0572) teacher/usage_max 0.4292 (0.5191) teacher/usage_min 0.2423 (0.1907) teacher/usage_std 0.0764 (0.1422) nleep/row_max_mean 1541.8201 (1543.6440) nleep/row_max_std 56.6202 (56.0643) nleep/row_min_mean 1504.0732 (1509.3432) lr 2.7103e-04 eta 0:03:32
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.4%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [41/50] batch [20/173] time 0.137 (0.137) data 0.000 (0.018) loss 1.6064 (1.4902) teacher_loss 0.2735 (0.1823) loss_zs_kd 0.0610 (0.0324) loss_oracle 0.5279 (0.5540) kd_loss 1.0384 (1.0148) acc 93.7500 (93.2812) gate/entropy 0.9861 (0.9862) gate/usage_max 0.5649 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0216 (0.0469) teacher/usage_max 0.4875 (0.4897) teacher/usage_min 0.2500 (0.2128) teacher/usage_std 0.1092 (0.1202) nleep/row_max_mean 1545.2495 (1541.2821) nleep/row_max_std 54.9419 (56.6073) nleep/row_min_mean 1511.6161 (1508.5264) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [40/173] time 0.161 (0.146) data 0.000 (0.009) loss 1.3052 (1.4876) teacher_loss 0.1299 (0.1789) loss_zs_kd 0.0277 (0.0340) loss_oracle 0.5882 (0.5545) kd_loss 0.8674 (1.0145) acc 93.7500 (93.3594) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0431 (0.0468) teacher/usage_max 0.6431 (0.4886) teacher/usage_min 0.1703 (0.2119) teacher/usage_std 0.2192 (0.1199) nleep/row_max_mean 1552.1045 (1540.5460) nleep/row_max_std 64.4701 (58.3431) nleep/row_min_mean 1516.0645 (1507.4936) lr 2.2949e-04 eta 0:04:07
epoch [41/50] batch [60/173] time 0.109 (0.145) data 0.000 (0.006) loss 1.6995 (1.4952) teacher_loss 0.2883 (0.1773) loss_zs_kd 0.0434 (0.0334) loss_oracle 0.6235 (0.5597) kd_loss 1.0777 (1.0214) acc 87.5000 (93.2812) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5647 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0267 (0.0498) teacher/usage_max 0.4375 (0.4825) teacher/usage_min 0.2427 (0.2148) teacher/usage_std 0.0801 (0.1152) nleep/row_max_mean 1533.6348 (1540.3256) nleep/row_max_std 56.4919 (58.0499) nleep/row_min_mean 1496.3225 (1507.3407) lr 2.2949e-04 eta 0:04:02
epoch [41/50] batch [80/173] time 0.140 (0.146) data 0.000 (0.005) loss 1.3220 (1.4980) teacher_loss 0.0984 (0.1814) loss_zs_kd 0.0124 (0.0338) loss_oracle 0.5928 (0.5606) kd_loss 0.9209 (1.0194) acc 93.7500 (93.1250) gate/entropy 0.9865 (0.9862) gate/usage_max 0.5645 (0.5648) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0514 (0.0491) teacher/usage_max 0.5836 (0.4853) teacher/usage_min 0.1273 (0.2100) teacher/usage_std 0.1889 (0.1181) nleep/row_max_mean 1536.1688 (1539.5512) nleep/row_max_std 60.1995 (57.6662) nleep/row_min_mean 1502.8806 (1506.4711) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [100/173] time 0.133 (0.147) data 0.000 (0.004) loss 1.5093 (1.4943) teacher_loss 0.0873 (0.1850) loss_zs_kd 0.0154 (0.0332) loss_oracle 0.5982 (0.5607) kd_loss 1.1152 (1.0123) acc 96.8750 (92.8750) gate/entropy 0.9863 (0.9862) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0166 (0.0483) teacher/usage_max 0.4047 (0.4916) teacher/usage_min 0.1907 (0.2057) teacher/usage_std 0.1009 (0.1227) nleep/row_max_mean 1534.0990 (1539.3380) nleep/row_max_std 52.3599 (56.8898) nleep/row_min_mean 1503.5245 (1506.0710) lr 2.2949e-04 eta 0:03:58
epoch [41/50] batch [120/173] time 0.162 (0.148) data 0.000 (0.003) loss 1.6065 (1.4925) teacher_loss 0.2823 (0.1894) loss_zs_kd 0.0424 (0.0331) loss_oracle 0.6073 (0.5568) kd_loss 0.9994 (1.0082) acc 84.3750 (92.8646) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0335 (0.0484) teacher/usage_max 0.5084 (0.4951) teacher/usage_min 0.1461 (0.2049) teacher/usage_std 0.1482 (0.1248) nleep/row_max_mean 1536.8893 (1539.8524) nleep/row_max_std 53.6965 (56.4755) nleep/row_min_mean 1499.9258 (1506.4517) lr 2.2949e-04 eta 0:03:57
epoch [41/50] batch [140/173] time 0.138 (0.148) data 0.000 (0.003) loss 1.5305 (1.4954) teacher_loss 0.1420 (0.1873) loss_zs_kd 0.0238 (0.0323) loss_oracle 0.5945 (0.5564) kd_loss 1.0793 (1.0138) acc 90.6250 (92.8125) gate/entropy 0.9861 (0.9862) gate/usage_max 0.5649 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0445 (0.0476) teacher/usage_max 0.4138 (0.4922) teacher/usage_min 0.1876 (0.2059) teacher/usage_std 0.1033 (0.1232) nleep/row_max_mean 1538.2058 (1538.7938) nleep/row_max_std 45.1633 (56.6663) nleep/row_min_mean 1507.8777 (1505.5937) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [160/173] time 0.139 (0.149) data 0.000 (0.002) loss 1.5558 (1.4877) teacher_loss 0.1968 (0.1856) loss_zs_kd 0.0512 (0.0331) loss_oracle 0.4719 (0.5523) kd_loss 1.0975 (1.0093) acc 90.6250 (92.8125) gate/entropy 0.9865 (0.9862) gate/usage_max 0.5645 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0455 (0.0473) teacher/usage_max 0.3993 (0.4964) teacher/usage_min 0.2886 (0.2057) teacher/usage_std 0.0476 (0.1255) nleep/row_max_mean 1519.0332 (1539.0989) nleep/row_max_std 50.9248 (56.5861) nleep/row_min_mean 1487.3491 (1505.8555) lr 2.2949e-04 eta 0:03:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,292
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [42/50] batch [20/173] time 0.099 (0.132) data 0.000 (0.016) loss 1.4711 (1.5187) teacher_loss 0.1939 (0.1901) loss_zs_kd 0.0497 (0.0388) loss_oracle 0.5087 (0.5488) kd_loss 0.9981 (1.0348) acc 90.6250 (92.3438) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2110 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0566 (0.0405) teacher/usage_max 0.4905 (0.4733) teacher/usage_min 0.2219 (0.2268) teacher/usage_std 0.1143 (0.1062) nleep/row_max_mean 1538.2979 (1541.1630) nleep/row_max_std 51.8554 (56.6811) nleep/row_min_mean 1507.6897 (1507.5774) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [40/173] time 0.177 (0.130) data 0.000 (0.008) loss 1.5194 (1.5048) teacher_loss 0.2485 (0.1830) loss_zs_kd 0.0235 (0.0355) loss_oracle 0.4600 (0.5521) kd_loss 1.0291 (1.0280) acc 90.6250 (92.5781) gate/entropy 0.9863 (0.9862) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0726 (0.0393) teacher/usage_max 0.4650 (0.4807) teacher/usage_min 0.0797 (0.2182) teacher/usage_std 0.1794 (0.1139) nleep/row_max_mean 1537.2452 (1541.9160) nleep/row_max_std 63.9112 (55.8460) nleep/row_min_mean 1507.0767 (1508.0368) lr 1.9098e-04 eta 0:03:17
epoch [42/50] batch [60/173] time 0.090 (0.127) data 0.000 (0.006) loss 1.4051 (1.5088) teacher_loss 0.0341 (0.1843) loss_zs_kd 0.0129 (0.0351) loss_oracle 0.5271 (0.5494) kd_loss 1.1010 (1.0322) acc 100.0000 (92.7083) gate/entropy 0.9865 (0.9862) gate/usage_max 0.5644 (0.5648) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0360 (0.0409) teacher/usage_max 0.4057 (0.4754) teacher/usage_min 0.2957 (0.2260) teacher/usage_std 0.0512 (0.1087) nleep/row_max_mean 1543.5154 (1540.9801) nleep/row_max_std 63.6177 (57.5970) nleep/row_min_mean 1511.2073 (1507.0605) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [80/173] time 0.080 (0.127) data 0.000 (0.004) loss 1.4530 (1.5035) teacher_loss 0.1183 (0.1791) loss_zs_kd 0.0258 (0.0347) loss_oracle 0.4561 (0.5481) kd_loss 1.0937 (1.0330) acc 93.7500 (93.1250) gate/entropy 0.9861 (0.9862) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0326 (0.0384) teacher/usage_max 0.4199 (0.4772) teacher/usage_min 0.2500 (0.2171) teacher/usage_std 0.0694 (0.1122) nleep/row_max_mean 1547.6233 (1540.7330) nleep/row_max_std 72.1416 (57.6432) nleep/row_min_mean 1512.0898 (1506.8024) lr 1.9098e-04 eta 0:03:07
epoch [42/50] batch [100/173] time 0.125 (0.125) data 0.000 (0.003) loss 1.7528 (1.5084) teacher_loss 0.3454 (0.1820) loss_zs_kd 0.0588 (0.0347) loss_oracle 0.5513 (0.5486) kd_loss 1.1024 (1.0347) acc 81.2500 (93.0312) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0274 (0.0363) teacher/usage_max 0.4130 (0.4783) teacher/usage_min 0.1807 (0.2138) teacher/usage_std 0.1079 (0.1138) nleep/row_max_mean 1543.1907 (1541.2230) nleep/row_max_std 53.5878 (57.3111) nleep/row_min_mean 1510.6741 (1507.1809) lr 1.9098e-04 eta 0:03:01
epoch [42/50] batch [120/173] time 0.080 (0.124) data 0.000 (0.003) loss 1.5455 (1.5037) teacher_loss 0.3088 (0.1775) loss_zs_kd 0.0352 (0.0351) loss_oracle 0.5218 (0.5450) kd_loss 0.9583 (1.0361) acc 87.5000 (93.2292) gate/entropy 0.9860 (0.9862) gate/usage_max 0.5650 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0288 (0.0348) teacher/usage_max 0.5640 (0.4793) teacher/usage_min 0.2003 (0.2108) teacher/usage_std 0.1637 (0.1157) nleep/row_max_mean 1541.6450 (1540.5433) nleep/row_max_std 58.9722 (56.6603) nleep/row_min_mean 1505.6978 (1506.5056) lr 1.9098e-04 eta 0:02:57
epoch [42/50] batch [140/173] time 0.138 (0.124) data 0.000 (0.003) loss 1.6502 (1.5113) teacher_loss 0.2799 (0.1809) loss_zs_kd 0.0777 (0.0352) loss_oracle 0.5998 (0.5445) kd_loss 1.0316 (1.0405) acc 87.5000 (93.1250) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0551 (0.0360) teacher/usage_max 0.4569 (0.4751) teacher/usage_min 0.2437 (0.2130) teacher/usage_std 0.0903 (0.1130) nleep/row_max_mean 1538.6172 (1539.1140) nleep/row_max_std 46.7951 (55.8669) nleep/row_min_mean 1504.8298 (1505.3705) lr 1.9098e-04 eta 0:02:56
epoch [42/50] batch [160/173] time 0.132 (0.128) data 0.000 (0.002) loss 1.6743 (1.5096) teacher_loss 0.4311 (0.1799) loss_zs_kd 0.0279 (0.0352) loss_oracle 0.5688 (0.5420) kd_loss 0.9448 (1.0411) acc 84.3750 (93.0859) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0671 (0.0355) teacher/usage_max 0.5388 (0.4755) teacher/usage_min 0.2079 (0.2124) teacher/usage_std 0.1465 (0.1134) nleep/row_max_mean 1538.1836 (1538.4325) nleep/row_max_std 47.4507 (54.9227) nleep/row_min_mean 1505.8699 (1504.8722) lr 1.9098e-04 eta 0:02:58
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,291
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.5%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [43/50] batch [20/173] time 0.164 (0.175) data 0.000 (0.018) loss 1.4572 (1.4985) teacher_loss 0.2671 (0.1794) loss_zs_kd 0.0458 (0.0385) loss_oracle 0.5715 (0.5559) kd_loss 0.8814 (1.0220) acc 90.6250 (93.7500) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0387 (0.0297) teacher/usage_max 0.6324 (0.4970) teacher/usage_min 0.1701 (0.1951) teacher/usage_std 0.2118 (0.1295) nleep/row_max_mean 1545.9424 (1538.2559) nleep/row_max_std 54.8721 (51.3817) nleep/row_min_mean 1507.8384 (1503.8771) lr 1.5567e-04 eta 0:03:59
epoch [43/50] batch [40/173] time 0.169 (0.166) data 0.000 (0.009) loss 1.6073 (1.5077) teacher_loss 0.1275 (0.1760) loss_zs_kd 0.0218 (0.0368) loss_oracle 0.5418 (0.5576) kd_loss 1.1980 (1.0345) acc 93.7500 (93.7500) gate/entropy 0.9867 (0.9863) gate/usage_max 0.5642 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1634 (0.1637) teacher/entropy 0.0420 (0.0320) teacher/usage_max 0.4022 (0.4890) teacher/usage_min 0.2966 (0.2043) teacher/usage_std 0.0488 (0.1240) nleep/row_max_mean 1513.5586 (1536.7754) nleep/row_max_std 63.9454 (52.9689) nleep/row_min_mean 1483.8618 (1502.6482) lr 1.5567e-04 eta 0:03:43
epoch [43/50] batch [60/173] time 0.132 (0.162) data 0.000 (0.006) loss 1.4584 (1.5000) teacher_loss 0.1241 (0.1702) loss_zs_kd 0.0298 (0.0363) loss_oracle 0.4476 (0.5569) kd_loss 1.0956 (1.0332) acc 93.7500 (93.5938) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0121 (0.0326) teacher/usage_max 0.4343 (0.4887) teacher/usage_min 0.2534 (0.2082) teacher/usage_std 0.0753 (0.1218) nleep/row_max_mean 1532.8477 (1538.4941) nleep/row_max_std 56.1985 (51.4375) nleep/row_min_mean 1501.2686 (1504.2806) lr 1.5567e-04 eta 0:03:34
epoch [43/50] batch [80/173] time 0.084 (0.158) data 0.000 (0.005) loss 1.6593 (1.4992) teacher_loss 0.2172 (0.1774) loss_zs_kd 0.0340 (0.0357) loss_oracle 0.5450 (0.5530) kd_loss 1.1526 (1.0275) acc 87.5000 (93.2812) gate/entropy 0.9867 (0.9863) gate/usage_max 0.5643 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1634 (0.1637) teacher/entropy 0.0219 (0.0355) teacher/usage_max 0.3739 (0.4921) teacher/usage_min 0.2568 (0.2079) teacher/usage_std 0.0542 (0.1238) nleep/row_max_mean 1530.1511 (1539.4943) nleep/row_max_std 64.2988 (51.7130) nleep/row_min_mean 1494.3224 (1505.1300) lr 1.5567e-04 eta 0:03:26
epoch [43/50] batch [100/173] time 0.091 (0.150) data 0.000 (0.004) loss 1.6374 (1.5025) teacher_loss 0.2504 (0.1807) loss_zs_kd 0.0335 (0.0349) loss_oracle 0.6103 (0.5512) kd_loss 1.0650 (1.0287) acc 90.6250 (93.2500) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0107 (0.0365) teacher/usage_max 0.4712 (0.4893) teacher/usage_min 0.2500 (0.2075) teacher/usage_std 0.0982 (0.1223) nleep/row_max_mean 1551.1128 (1539.5942) nleep/row_max_std 44.9399 (52.1128) nleep/row_min_mean 1512.2354 (1505.2148) lr 1.5567e-04 eta 0:03:12
epoch [43/50] batch [120/173] time 0.093 (0.143) data 0.000 (0.003) loss 1.4369 (1.4962) teacher_loss 0.1882 (0.1769) loss_zs_kd 0.0382 (0.0347) loss_oracle 0.4939 (0.5486) kd_loss 0.9826 (1.0277) acc 93.7500 (93.4635) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5650 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0367 (0.0370) teacher/usage_max 0.5366 (0.4917) teacher/usage_min 0.1267 (0.2062) teacher/usage_std 0.1673 (0.1240) nleep/row_max_mean 1554.4801 (1539.9605) nleep/row_max_std 50.6732 (52.4861) nleep/row_min_mean 1521.2490 (1505.5376) lr 1.5567e-04 eta 0:03:00
epoch [43/50] batch [140/173] time 0.074 (0.139) data 0.000 (0.003) loss 1.4725 (1.5052) teacher_loss 0.1300 (0.1821) loss_zs_kd 0.0445 (0.0355) loss_oracle 0.5540 (0.5506) kd_loss 1.0433 (1.0300) acc 96.8750 (93.1920) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0293 (0.0362) teacher/usage_max 0.4690 (0.4894) teacher/usage_min 0.1941 (0.2076) teacher/usage_std 0.1123 (0.1223) nleep/row_max_mean 1537.2886 (1540.7923) nleep/row_max_std 45.7561 (52.5625) nleep/row_min_mean 1502.1458 (1506.0422) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [160/173] time 0.074 (0.136) data 0.000 (0.002) loss 1.5449 (1.5057) teacher_loss 0.3662 (0.1818) loss_zs_kd 0.0560 (0.0348) loss_oracle 0.5301 (0.5521) kd_loss 0.8856 (1.0305) acc 81.2500 (93.1055) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0575 (0.0375) teacher/usage_max 0.6099 (0.4880) teacher/usage_min 0.1821 (0.2088) teacher/usage_std 0.1958 (0.1209) nleep/row_max_mean 1536.1545 (1541.5913) nleep/row_max_std 59.8557 (52.4640) nleep/row_min_mean 1499.9900 (1506.9463) lr 1.5567e-04 eta 0:02:46
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [44/50] batch [20/173] time 0.088 (0.133) data 0.000 (0.018) loss 1.6046 (1.5097) teacher_loss 0.2530 (0.1930) loss_zs_kd 0.0510 (0.0331) loss_oracle 0.5846 (0.5512) kd_loss 1.0338 (1.0245) acc 90.6250 (92.1875) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0167 (0.0443) teacher/usage_max 0.4966 (0.4899) teacher/usage_min 0.2499 (0.2161) teacher/usage_std 0.1155 (0.1196) nleep/row_max_mean 1549.2042 (1543.6659) nleep/row_max_std 39.2389 (51.9609) nleep/row_min_mean 1512.4180 (1509.0335) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [40/173] time 0.189 (0.144) data 0.000 (0.009) loss 1.3290 (1.4982) teacher_loss 0.0831 (0.1859) loss_zs_kd 0.0246 (0.0347) loss_oracle 0.5582 (0.5452) kd_loss 0.9545 (1.0223) acc 100.0000 (92.9688) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0830 (0.0382) teacher/usage_max 0.5093 (0.4990) teacher/usage_min 0.2286 (0.2106) teacher/usage_std 0.1251 (0.1252) nleep/row_max_mean 1564.9966 (1544.3096) nleep/row_max_std 48.8545 (51.9994) nleep/row_min_mean 1531.6567 (1509.7947) lr 1.2369e-04 eta 0:02:48
epoch [44/50] batch [60/173] time 0.181 (0.154) data 0.001 (0.006) loss 1.4260 (1.5045) teacher_loss 0.1345 (0.1872) loss_zs_kd 0.0168 (0.0337) loss_oracle 0.5079 (0.5419) kd_loss 1.0291 (1.0295) acc 93.7500 (93.1771) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0404 (0.0354) teacher/usage_max 0.4822 (0.4928) teacher/usage_min 0.1827 (0.2067) teacher/usage_std 0.1223 (0.1231) nleep/row_max_mean 1537.6389 (1543.1345) nleep/row_max_std 63.6637 (55.0340) nleep/row_min_mean 1503.7117 (1508.7408) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [80/173] time 0.173 (0.160) data 0.000 (0.005) loss 1.3726 (1.4980) teacher_loss 0.1029 (0.1800) loss_zs_kd 0.0146 (0.0337) loss_oracle 0.4487 (0.5462) kd_loss 1.0381 (1.0281) acc 96.8750 (93.4375) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0453 (0.0363) teacher/usage_max 0.4691 (0.4929) teacher/usage_min 0.1684 (0.2068) teacher/usage_std 0.1245 (0.1236) nleep/row_max_mean 1539.1279 (1542.0727) nleep/row_max_std 64.3316 (56.1780) nleep/row_min_mean 1508.8177 (1507.9896) lr 1.2369e-04 eta 0:03:00
epoch [44/50] batch [100/173] time 0.177 (0.165) data 0.001 (0.004) loss 1.5265 (1.5007) teacher_loss 0.1225 (0.1769) loss_zs_kd 0.0203 (0.0339) loss_oracle 0.5606 (0.5482) kd_loss 1.1135 (1.0327) acc 93.7500 (93.5625) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0332 (0.0366) teacher/usage_max 0.3930 (0.4866) teacher/usage_min 0.2633 (0.2080) teacher/usage_std 0.0535 (0.1203) nleep/row_max_mean 1536.4791 (1540.8516) nleep/row_max_std 66.1924 (56.8531) nleep/row_min_mean 1503.0314 (1506.9984) lr 1.2369e-04 eta 0:03:02
epoch [44/50] batch [120/173] time 0.133 (0.159) data 0.000 (0.003) loss 1.5315 (1.4978) teacher_loss 0.2381 (0.1790) loss_zs_kd 0.0356 (0.0342) loss_oracle 0.5430 (0.5476) kd_loss 1.0042 (1.0279) acc 90.6250 (93.4115) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0123 (0.0368) teacher/usage_max 0.5313 (0.4898) teacher/usage_min 0.2150 (0.2071) teacher/usage_std 0.1409 (0.1220) nleep/row_max_mean 1542.4131 (1540.7146) nleep/row_max_std 57.4648 (56.6553) nleep/row_min_mean 1506.7808 (1506.7838) lr 1.2369e-04 eta 0:02:53
epoch [44/50] batch [140/173] time 0.163 (0.159) data 0.000 (0.003) loss 1.5627 (1.4961) teacher_loss 0.1680 (0.1794) loss_zs_kd 0.0401 (0.0339) loss_oracle 0.6408 (0.5471) kd_loss 1.0542 (1.0262) acc 93.7500 (93.3929) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0400 (0.0386) teacher/usage_max 0.4478 (0.4889) teacher/usage_min 0.2362 (0.2099) teacher/usage_std 0.0872 (0.1207) nleep/row_max_mean 1531.9036 (1540.0581) nleep/row_max_std 55.8487 (56.5179) nleep/row_min_mean 1499.9900 (1506.1998) lr 1.2369e-04 eta 0:02:49
epoch [44/50] batch [160/173] time 0.153 (0.158) data 0.000 (0.002) loss 1.4769 (1.4952) teacher_loss 0.1417 (0.1815) loss_zs_kd 0.0537 (0.0339) loss_oracle 0.5039 (0.5486) kd_loss 1.0564 (1.0225) acc 100.0000 (93.3398) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0206 (0.0396) teacher/usage_max 0.4703 (0.4911) teacher/usage_min 0.2500 (0.2060) teacher/usage_std 0.0976 (0.1232) nleep/row_max_mean 1534.9290 (1540.2729) nleep/row_max_std 57.9820 (56.4907) nleep/row_min_mean 1502.3651 (1506.3129) lr 1.2369e-04 eta 0:02:45
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [45/50] batch [20/173] time 0.183 (0.139) data 0.000 (0.017) loss 1.5749 (1.4985) teacher_loss 0.2200 (0.1907) loss_zs_kd 0.0360 (0.0322) loss_oracle 0.5637 (0.5454) kd_loss 1.0551 (1.0189) acc 93.7500 (92.5000) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5647 (0.5646) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1636) teacher/entropy 0.0461 (0.0392) teacher/usage_max 0.4464 (0.4899) teacher/usage_min 0.2272 (0.2107) teacher/usage_std 0.0897 (0.1206) nleep/row_max_mean 1537.4922 (1537.5116) nleep/row_max_std 63.1312 (55.9288) nleep/row_min_mean 1501.2496 (1503.9892) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [40/173] time 0.084 (0.127) data 0.000 (0.009) loss 1.3139 (1.4818) teacher_loss 0.1526 (0.1827) loss_zs_kd 0.0402 (0.0319) loss_oracle 0.5147 (0.5508) kd_loss 0.8839 (1.0078) acc 93.7500 (92.5781) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0729 (0.0399) teacher/usage_max 0.5931 (0.5054) teacher/usage_min 0.1672 (0.2023) teacher/usage_std 0.1861 (0.1302) nleep/row_max_mean 1546.6566 (1536.1815) nleep/row_max_std 53.7807 (56.9225) nleep/row_min_mean 1510.8894 (1502.6623) lr 9.5173e-05 eta 0:02:07
epoch [45/50] batch [60/173] time 0.094 (0.122) data 0.001 (0.006) loss 1.5378 (1.4853) teacher_loss 0.0819 (0.1828) loss_zs_kd 0.0234 (0.0325) loss_oracle 0.6573 (0.5492) kd_loss 1.1155 (1.0116) acc 96.8750 (92.9688) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0295 (0.0398) teacher/usage_max 0.4256 (0.5018) teacher/usage_min 0.1856 (0.2012) teacher/usage_std 0.1056 (0.1293) nleep/row_max_mean 1530.5183 (1537.2728) nleep/row_max_std 58.1202 (56.5526) nleep/row_min_mean 1497.9177 (1503.7562) lr 9.5173e-05 eta 0:01:59
epoch [45/50] batch [80/173] time 0.090 (0.118) data 0.000 (0.005) loss 1.4989 (1.4853) teacher_loss 0.2016 (0.1878) loss_zs_kd 0.0543 (0.0324) loss_oracle 0.5364 (0.5489) kd_loss 1.0019 (1.0069) acc 93.7500 (93.1641) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1634 (0.1637) teacher/entropy 0.0748 (0.0427) teacher/usage_max 0.4733 (0.5020) teacher/usage_min 0.1882 (0.2018) teacher/usage_std 0.1164 (0.1296) nleep/row_max_mean 1528.6047 (1537.3461) nleep/row_max_std 73.5771 (57.4423) nleep/row_min_mean 1492.8754 (1503.7816) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [100/173] time 0.182 (0.121) data 0.000 (0.004) loss 1.3345 (1.4830) teacher_loss 0.1320 (0.1854) loss_zs_kd 0.0355 (0.0323) loss_oracle 0.5539 (0.5495) kd_loss 0.9078 (1.0068) acc 90.6250 (93.2188) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0357 (0.0423) teacher/usage_max 0.6096 (0.5034) teacher/usage_min 0.1906 (0.2005) teacher/usage_std 0.1954 (0.1304) nleep/row_max_mean 1534.1169 (1536.8225) nleep/row_max_std 51.9989 (58.2310) nleep/row_min_mean 1501.5632 (1503.4187) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [120/173] time 0.125 (0.119) data 0.000 (0.003) loss 1.5546 (1.4881) teacher_loss 0.1514 (0.1847) loss_zs_kd 0.0235 (0.0326) loss_oracle 0.5476 (0.5511) kd_loss 1.1176 (1.0116) acc 93.7500 (93.2552) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0183 (0.0426) teacher/usage_max 0.4017 (0.4977) teacher/usage_min 0.2189 (0.2017) teacher/usage_std 0.0814 (0.1275) nleep/row_max_mean 1522.6455 (1536.3248) nleep/row_max_std 58.7540 (57.8775) nleep/row_min_mean 1491.8481 (1503.0979) lr 9.5173e-05 eta 0:01:49
epoch [45/50] batch [140/173] time 0.148 (0.125) data 0.000 (0.003) loss 1.3425 (1.4928) teacher_loss 0.1187 (0.1876) loss_zs_kd 0.0274 (0.0330) loss_oracle 0.5331 (0.5530) kd_loss 0.9436 (1.0121) acc 96.8750 (93.1250) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5650 (0.5647) gate/usage_min 0.2110 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.1155 (0.0420) teacher/usage_max 0.4865 (0.4970) teacher/usage_min 0.2332 (0.1996) teacher/usage_std 0.1100 (0.1280) nleep/row_max_mean 1538.6530 (1536.6739) nleep/row_max_std 66.2977 (57.8738) nleep/row_min_mean 1506.9695 (1503.3499) lr 9.5173e-05 eta 0:01:52
epoch [45/50] batch [160/173] time 0.132 (0.125) data 0.000 (0.002) loss 1.5574 (1.4934) teacher_loss 0.1630 (0.1888) loss_zs_kd 0.0369 (0.0334) loss_oracle 0.4745 (0.5524) kd_loss 1.1388 (1.0118) acc 93.7500 (93.1055) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0056 (0.0432) teacher/usage_max 0.4066 (0.4967) teacher/usage_min 0.1880 (0.1987) teacher/usage_std 0.1028 (0.1281) nleep/row_max_mean 1532.6992 (1537.2252) nleep/row_max_std 63.3955 (57.9388) nleep/row_min_mean 1501.4886 (1503.9402) lr 9.5173e-05 eta 0:01:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.3%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [46/50] batch [20/173] time 0.138 (0.172) data 0.000 (0.017) loss 1.4522 (1.4870) teacher_loss 0.2099 (0.1943) loss_zs_kd 0.0211 (0.0335) loss_oracle 0.5285 (0.5464) kd_loss 0.9675 (1.0028) acc 90.6250 (92.3438) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0252 (0.0469) teacher/usage_max 0.5622 (0.5168) teacher/usage_min 0.1449 (0.2124) teacher/usage_std 0.1727 (0.1329) nleep/row_max_mean 1538.8429 (1542.2664) nleep/row_max_std 66.0376 (58.6499) nleep/row_min_mean 1506.0559 (1509.3113) lr 7.0224e-05 eta 0:02:25
epoch [46/50] batch [40/173] time 0.146 (0.160) data 0.000 (0.009) loss 1.6377 (1.4869) teacher_loss 0.3072 (0.1989) loss_zs_kd 0.0365 (0.0364) loss_oracle 0.6070 (0.5400) kd_loss 1.0088 (0.9998) acc 93.7500 (93.1250) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5650 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0035 (0.0408) teacher/usage_max 0.5311 (0.5207) teacher/usage_min 0.1560 (0.1989) teacher/usage_std 0.1538 (0.1390) nleep/row_max_mean 1554.4207 (1542.1387) nleep/row_max_std 65.4050 (59.6779) nleep/row_min_mean 1515.0165 (1508.3659) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [60/173] time 0.150 (0.156) data 0.001 (0.006) loss 1.4833 (1.5046) teacher_loss 0.1475 (0.2038) loss_zs_kd 0.0275 (0.0361) loss_oracle 0.5141 (0.5448) kd_loss 1.0650 (1.0103) acc 96.8750 (92.3438) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0417 (0.0387) teacher/usage_max 0.4367 (0.5084) teacher/usage_min 0.2543 (0.1990) teacher/usage_std 0.0764 (0.1339) nleep/row_max_mean 1537.2133 (1541.7793) nleep/row_max_std 50.4868 (60.0446) nleep/row_min_mean 1508.4558 (1508.1187) lr 7.0224e-05 eta 0:02:05
epoch [46/50] batch [80/173] time 0.169 (0.153) data 0.000 (0.004) loss 1.4142 (1.4986) teacher_loss 0.0671 (0.1937) loss_zs_kd 0.0189 (0.0353) loss_oracle 0.6260 (0.5500) kd_loss 1.0246 (1.0123) acc 100.0000 (92.9688) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0560 (0.0396) teacher/usage_max 0.4577 (0.5031) teacher/usage_min 0.1640 (0.2000) teacher/usage_std 0.1240 (0.1310) nleep/row_max_mean 1537.1133 (1540.4073) nleep/row_max_std 57.8300 (58.7523) nleep/row_min_mean 1505.6663 (1507.0825) lr 7.0224e-05 eta 0:02:00
epoch [46/50] batch [100/173] time 0.089 (0.141) data 0.000 (0.004) loss 1.4913 (1.5033) teacher_loss 0.0953 (0.1969) loss_zs_kd 0.0197 (0.0353) loss_oracle 0.6007 (0.5512) kd_loss 1.0858 (1.0131) acc 96.8750 (92.7188) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0179 (0.0402) teacher/usage_max 0.4377 (0.5013) teacher/usage_min 0.2433 (0.2036) teacher/usage_std 0.0800 (0.1285) nleep/row_max_mean 1524.9286 (1539.8651) nleep/row_max_std 83.4502 (58.1763) nleep/row_min_mean 1491.2478 (1506.4879) lr 7.0224e-05 eta 0:01:48
epoch [46/50] batch [120/173] time 0.103 (0.138) data 0.000 (0.003) loss 1.7851 (1.5042) teacher_loss 0.3616 (0.1993) loss_zs_kd 0.0255 (0.0351) loss_oracle 0.5324 (0.5509) kd_loss 1.1445 (1.0119) acc 87.5000 (92.6562) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0646 (0.0411) teacher/usage_max 0.3754 (0.5003) teacher/usage_min 0.2912 (0.2022) teacher/usage_std 0.0344 (0.1283) nleep/row_max_mean 1532.6454 (1539.1876) nleep/row_max_std 56.2364 (58.1586) nleep/row_min_mean 1501.1505 (1506.0088) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [140/173] time 0.086 (0.136) data 0.000 (0.003) loss 1.4783 (1.5069) teacher_loss 0.2455 (0.1989) loss_zs_kd 0.0481 (0.0346) loss_oracle 0.4943 (0.5487) kd_loss 0.9616 (1.0163) acc 90.6250 (92.5893) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0730 (0.0414) teacher/usage_max 0.5138 (0.4971) teacher/usage_min 0.2428 (0.2021) teacher/usage_std 0.1276 (0.1268) nleep/row_max_mean 1536.1942 (1538.4376) nleep/row_max_std 48.6264 (57.8344) nleep/row_min_mean 1504.7200 (1505.4256) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [160/173] time 0.159 (0.137) data 0.000 (0.002) loss 1.5170 (1.5033) teacher_loss 0.2053 (0.1941) loss_zs_kd 0.0278 (0.0340) loss_oracle 0.5077 (0.5474) kd_loss 1.0440 (1.0184) acc 93.7500 (92.7344) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0467 (0.0410) teacher/usage_max 0.4551 (0.4946) teacher/usage_min 0.2636 (0.2024) teacher/usage_std 0.0864 (0.1256) nleep/row_max_mean 1538.2141 (1537.9714) nleep/row_max_std 57.0765 (57.1498) nleep/row_min_mean 1508.5039 (1505.0918) lr 7.0224e-05 eta 0:01:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.3%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [47/50] batch [20/173] time 0.148 (0.123) data 0.000 (0.016) loss 1.4486 (1.5161) teacher_loss 0.1126 (0.1834) loss_zs_kd 0.0362 (0.0369) loss_oracle 0.5920 (0.5729) kd_loss 1.0218 (1.0278) acc 96.8750 (92.6562) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0703 (0.0505) teacher/usage_max 0.4501 (0.4694) teacher/usage_min 0.2303 (0.2244) teacher/usage_std 0.0902 (0.1064) nleep/row_max_mean 1533.1536 (1533.8647) nleep/row_max_std 49.0812 (53.5246) nleep/row_min_mean 1502.5549 (1501.2124) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [40/173] time 0.148 (0.130) data 0.000 (0.008) loss 1.6010 (1.4917) teacher_loss 0.2168 (0.1749) loss_zs_kd 0.0471 (0.0362) loss_oracle 0.5388 (0.5546) kd_loss 1.0913 (1.0214) acc 93.7500 (93.2031) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5647 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0579 (0.0486) teacher/usage_max 0.3901 (0.4791) teacher/usage_min 0.2515 (0.2198) teacher/usage_std 0.0593 (0.1120) nleep/row_max_mean 1515.8735 (1533.0280) nleep/row_max_std 64.6015 (54.2989) nleep/row_min_mean 1483.9213 (1500.5686) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [60/173] time 0.149 (0.139) data 0.000 (0.006) loss 1.4376 (1.4974) teacher_loss 0.0891 (0.1821) loss_zs_kd 0.0278 (0.0362) loss_oracle 0.6449 (0.5554) kd_loss 1.0121 (1.0195) acc 96.8750 (93.2292) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0518 (0.0463) teacher/usage_max 0.4781 (0.4857) teacher/usage_min 0.1858 (0.2135) teacher/usage_std 0.1193 (0.1177) nleep/row_max_mean 1534.3167 (1534.5363) nleep/row_max_std 45.7110 (53.3490) nleep/row_min_mean 1500.4351 (1502.1627) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [80/173] time 0.152 (0.141) data 0.000 (0.004) loss 1.4717 (1.4934) teacher_loss 0.1952 (0.1837) loss_zs_kd 0.0375 (0.0354) loss_oracle 0.5528 (0.5511) kd_loss 0.9814 (1.0164) acc 93.7500 (93.1250) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0536 (0.0459) teacher/usage_max 0.5107 (0.4893) teacher/usage_min 0.2075 (0.2090) teacher/usage_std 0.1291 (0.1210) nleep/row_max_mean 1538.8113 (1534.3063) nleep/row_max_std 46.7469 (52.9855) nleep/row_min_mean 1507.3511 (1502.0132) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [100/173] time 0.160 (0.143) data 0.000 (0.003) loss 1.4488 (1.4853) teacher_loss 0.1179 (0.1803) loss_zs_kd 0.0216 (0.0340) loss_oracle 0.5533 (0.5552) kd_loss 1.0435 (1.0104) acc 96.8750 (93.3125) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0424 (0.0479) teacher/usage_max 0.4558 (0.4928) teacher/usage_min 0.2317 (0.2046) teacher/usage_std 0.0927 (0.1241) nleep/row_max_mean 1533.4611 (1534.3440) nleep/row_max_std 64.9540 (52.6205) nleep/row_min_mean 1501.1053 (1502.2575) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [120/173] time 0.126 (0.145) data 0.000 (0.003) loss 1.7480 (1.4876) teacher_loss 0.2832 (0.1815) loss_zs_kd 0.0514 (0.0337) loss_oracle 0.6842 (0.5584) kd_loss 1.0970 (1.0100) acc 87.5000 (93.2812) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0065 (0.0473) teacher/usage_max 0.4389 (0.4950) teacher/usage_min 0.2501 (0.2059) teacher/usage_std 0.0787 (0.1248) nleep/row_max_mean 1539.8921 (1535.0112) nleep/row_max_std 51.8592 (52.3163) nleep/row_min_mean 1505.5127 (1502.9458) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [140/173] time 0.144 (0.146) data 0.000 (0.002) loss 1.4909 (1.4825) teacher_loss 0.3070 (0.1815) loss_zs_kd 0.0393 (0.0336) loss_oracle 0.4624 (0.5546) kd_loss 0.9329 (1.0069) acc 87.5000 (93.3036) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0372 (0.0470) teacher/usage_max 0.5805 (0.4983) teacher/usage_min 0.2061 (0.2037) teacher/usage_std 0.1748 (0.1271) nleep/row_max_mean 1545.6952 (1535.5647) nleep/row_max_std 47.3929 (52.2030) nleep/row_min_mean 1509.5654 (1503.4313) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [160/173] time 0.149 (0.147) data 0.000 (0.002) loss 1.6006 (1.4823) teacher_loss 0.2614 (0.1824) loss_zs_kd 0.0472 (0.0333) loss_oracle 0.5419 (0.5540) kd_loss 1.0447 (1.0062) acc 90.6250 (93.2617) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0223 (0.0470) teacher/usage_max 0.4758 (0.4989) teacher/usage_min 0.2118 (0.2038) teacher/usage_std 0.1088 (0.1272) nleep/row_max_mean 1522.5593 (1535.0173) nleep/row_max_std 57.8653 (52.0854) nleep/row_min_mean 1490.1028 (1502.9686) lr 4.8943e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,297
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,994
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [48/50] batch [20/173] time 0.099 (0.128) data 0.000 (0.018) loss 1.3039 (1.4849) teacher_loss 0.1764 (0.2103) loss_zs_kd 0.0323 (0.0319) loss_oracle 0.4608 (0.5594) kd_loss 0.8809 (0.9789) acc 93.7500 (91.4062) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.1098 (0.0438) teacher/usage_max 0.5615 (0.5256) teacher/usage_min 0.1950 (0.1889) teacher/usage_std 0.1626 (0.1451) nleep/row_max_mean 1538.2222 (1534.3596) nleep/row_max_std 54.9341 (51.4070) nleep/row_min_mean 1508.2858 (1501.5637) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [40/173] time 0.074 (0.122) data 0.000 (0.009) loss 1.4941 (1.4707) teacher_loss 0.1802 (0.1877) loss_zs_kd 0.0319 (0.0296) loss_oracle 0.5784 (0.5573) kd_loss 1.0087 (0.9895) acc 93.7500 (92.4219) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0489 (0.0437) teacher/usage_max 0.4867 (0.5142) teacher/usage_min 0.2211 (0.1947) teacher/usage_std 0.1123 (0.1385) nleep/row_max_mean 1520.4617 (1532.2109) nleep/row_max_std 52.8815 (53.5790) nleep/row_min_mean 1490.0621 (1500.2428) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [60/173] time 0.163 (0.116) data 0.000 (0.006) loss 1.4966 (1.4706) teacher_loss 0.3503 (0.1905) loss_zs_kd 0.0464 (0.0307) loss_oracle 0.4939 (0.5534) kd_loss 0.8761 (0.9880) acc 81.2500 (92.2917) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0360 (0.0472) teacher/usage_max 0.6450 (0.5187) teacher/usage_min 0.1250 (0.1930) teacher/usage_std 0.2245 (0.1411) nleep/row_max_mean 1538.0885 (1532.3920) nleep/row_max_std 57.8355 (52.9413) nleep/row_min_mean 1502.8572 (1500.5511) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [80/173] time 0.097 (0.112) data 0.000 (0.005) loss 1.3394 (1.4743) teacher_loss 0.0391 (0.1951) loss_zs_kd 0.0152 (0.0318) loss_oracle 0.4462 (0.5475) kd_loss 1.0697 (0.9895) acc 100.0000 (91.8750) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0485 (0.0473) teacher/usage_max 0.4262 (0.5155) teacher/usage_min 0.2865 (0.1964) teacher/usage_std 0.0657 (0.1384) nleep/row_max_mean 1528.8010 (1533.1277) nleep/row_max_std 56.6209 (52.9649) nleep/row_min_mean 1500.2218 (1501.2584) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [100/173] time 0.089 (0.112) data 0.000 (0.004) loss 1.5602 (1.4796) teacher_loss 0.2633 (0.1979) loss_zs_kd 0.0243 (0.0322) loss_oracle 0.5906 (0.5466) kd_loss 0.9894 (0.9923) acc 90.6250 (91.8125) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5647 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0758 (0.0468) teacher/usage_max 0.4849 (0.5135) teacher/usage_min 0.2023 (0.1980) teacher/usage_std 0.1163 (0.1368) nleep/row_max_mean 1525.3921 (1532.4651) nleep/row_max_std 52.2626 (53.4265) nleep/row_min_mean 1495.5232 (1500.6781) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [120/173] time 0.079 (0.113) data 0.000 (0.003) loss 1.4715 (1.4802) teacher_loss 0.0223 (0.1968) loss_zs_kd 0.0201 (0.0319) loss_oracle 0.5119 (0.5472) kd_loss 1.1833 (0.9939) acc 100.0000 (91.8490) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0120 (0.0462) teacher/usage_max 0.3766 (0.5122) teacher/usage_min 0.2819 (0.1961) teacher/usage_std 0.0391 (0.1367) nleep/row_max_mean 1526.8770 (1532.0449) nleep/row_max_std 59.6779 (53.0305) nleep/row_min_mean 1496.9819 (1500.2713) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [140/173] time 0.087 (0.112) data 0.000 (0.003) loss 1.5571 (1.4874) teacher_loss 0.1712 (0.1992) loss_zs_kd 0.0191 (0.0320) loss_oracle 0.5384 (0.5489) kd_loss 1.1071 (0.9977) acc 93.7500 (91.9196) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0383 (0.0447) teacher/usage_max 0.4083 (0.5090) teacher/usage_min 0.1876 (0.1985) teacher/usage_std 0.1030 (0.1343) nleep/row_max_mean 1522.7670 (1531.9977) nleep/row_max_std 58.1561 (52.8672) nleep/row_min_mean 1494.9324 (1500.1708) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [160/173] time 0.162 (0.117) data 0.000 (0.002) loss 1.5343 (1.4904) teacher_loss 0.2457 (0.1993) loss_zs_kd 0.0378 (0.0322) loss_oracle 0.4768 (0.5508) kd_loss 1.0313 (0.9997) acc 90.6250 (92.0898) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0344 (0.0438) teacher/usage_max 0.4830 (0.5078) teacher/usage_min 0.2188 (0.1969) teacher/usage_std 0.1107 (0.1343) nleep/row_max_mean 1526.9371 (1532.5471) nleep/row_max_std 66.8796 (52.5808) nleep/row_min_mean 1494.5247 (1500.6061) lr 3.1417e-05 eta 0:00:42
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,994
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [49/50] batch [20/173] time 0.156 (0.147) data 0.000 (0.017) loss 1.2730 (1.4383) teacher_loss 0.0652 (0.1547) loss_zs_kd 0.0221 (0.0313) loss_oracle 0.5277 (0.5457) kd_loss 0.9329 (0.9951) acc 100.0000 (95.1562) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0436 (0.0373) teacher/usage_max 0.5777 (0.5167) teacher/usage_min 0.1562 (0.1923) teacher/usage_std 0.1785 (0.1396) nleep/row_max_mean 1519.3369 (1533.4441) nleep/row_max_std 68.5988 (52.6241) nleep/row_min_mean 1488.5468 (1501.6055) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [40/173] time 0.138 (0.150) data 0.000 (0.009) loss 1.4336 (1.4660) teacher_loss 0.1770 (0.1814) loss_zs_kd 0.0410 (0.0335) loss_oracle 0.5177 (0.5524) kd_loss 0.9772 (0.9917) acc 93.7500 (93.6719) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0497 (0.0433) teacher/usage_max 0.5151 (0.5160) teacher/usage_min 0.1390 (0.1914) teacher/usage_std 0.1538 (0.1398) nleep/row_max_mean 1532.5702 (1534.1430) nleep/row_max_std 48.7130 (53.7592) nleep/row_min_mean 1500.7043 (1501.9688) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [60/173] time 0.163 (0.154) data 0.000 (0.006) loss 1.6687 (1.4799) teacher_loss 0.3877 (0.1770) loss_zs_kd 0.0314 (0.0330) loss_oracle 0.6397 (0.5555) kd_loss 0.9455 (1.0086) acc 81.2500 (93.5417) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0705 (0.0422) teacher/usage_max 0.5290 (0.5003) teacher/usage_min 0.1937 (0.2038) teacher/usage_std 0.1425 (0.1275) nleep/row_max_mean 1525.7345 (1532.5332) nleep/row_max_std 59.8109 (55.2363) nleep/row_min_mean 1491.2083 (1500.4673) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [80/173] time 0.159 (0.154) data 0.000 (0.005) loss 1.4551 (1.4721) teacher_loss 0.1002 (0.1779) loss_zs_kd 0.0152 (0.0324) loss_oracle 0.5901 (0.5527) kd_loss 1.0523 (1.0016) acc 96.8750 (93.4766) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5647 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0549 (0.0435) teacher/usage_max 0.4356 (0.5061) teacher/usage_min 0.2537 (0.1968) teacher/usage_std 0.0760 (0.1326) nleep/row_max_mean 1534.2942 (1533.1799) nleep/row_max_std 54.9921 (55.3421) nleep/row_min_mean 1503.1216 (1501.0161) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [100/173] time 0.081 (0.148) data 0.000 (0.004) loss 1.4842 (1.4718) teacher_loss 0.1191 (0.1789) loss_zs_kd 0.0410 (0.0324) loss_oracle 0.4768 (0.5490) kd_loss 1.1062 (1.0022) acc 96.8750 (93.3438) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0235 (0.0417) teacher/usage_max 0.4083 (0.5068) teacher/usage_min 0.2197 (0.1983) teacher/usage_std 0.0817 (0.1324) nleep/row_max_mean 1517.7854 (1533.1929) nleep/row_max_std 56.4238 (55.6839) nleep/row_min_mean 1487.0959 (1501.0390) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [120/173] time 0.081 (0.139) data 0.000 (0.003) loss 1.4490 (1.4651) teacher_loss 0.0281 (0.1752) loss_zs_kd 0.0189 (0.0321) loss_oracle 0.5699 (0.5457) kd_loss 1.1265 (1.0011) acc 100.0000 (93.3333) gate/entropy 0.9867 (0.9863) gate/usage_max 0.5642 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1634 (0.1637) teacher/entropy 0.0335 (0.0430) teacher/usage_max 0.3816 (0.5069) teacher/usage_min 0.3087 (0.1943) teacher/usage_std 0.0341 (0.1341) nleep/row_max_mean 1516.3862 (1533.3606) nleep/row_max_std 64.6389 (55.3092) nleep/row_min_mean 1489.2183 (1501.3245) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [140/173] time 0.164 (0.135) data 0.000 (0.003) loss 1.5266 (1.4656) teacher_loss 0.1840 (0.1749) loss_zs_kd 0.0211 (0.0319) loss_oracle 0.6521 (0.5475) kd_loss 1.0061 (1.0010) acc 93.7500 (93.3482) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5644 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0425 (0.0430) teacher/usage_max 0.5031 (0.5067) teacher/usage_min 0.1745 (0.1949) teacher/usage_std 0.1344 (0.1338) nleep/row_max_mean 1531.0393 (1533.9047) nleep/row_max_std 67.4629 (55.4806) nleep/row_min_mean 1501.0868 (1501.7792) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [160/173] time 0.074 (0.132) data 0.000 (0.002) loss 1.5173 (1.4709) teacher_loss 0.1636 (0.1783) loss_zs_kd 0.0273 (0.0317) loss_oracle 0.5859 (0.5497) kd_loss 1.0471 (1.0019) acc 93.7500 (93.1836) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0705 (0.0431) teacher/usage_max 0.4250 (0.5055) teacher/usage_min 0.2744 (0.1964) teacher/usage_std 0.0657 (0.1328) nleep/row_max_mean 1526.4338 (1534.0424) nleep/row_max_std 64.0514 (55.8469) nleep/row_min_mean 1496.9982 (1501.8588) lr 1.7713e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,994
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
epoch [50/50] batch [20/173] time 0.118 (0.140) data 0.000 (0.020) loss 1.6086 (1.4818) teacher_loss 0.1914 (0.2388) loss_zs_kd 0.0376 (0.0366) loss_oracle 0.6509 (0.5520) kd_loss 1.0730 (0.9487) acc 90.6250 (90.4688) gate/entropy 0.9867 (0.9863) gate/usage_max 0.5642 (0.5647) gate/usage_min 0.2112 (0.2111) gate/usage_std 0.1633 (0.1637) teacher/entropy 0.0756 (0.0573) teacher/usage_max 0.3900 (0.5416) teacher/usage_min 0.2530 (0.1850) teacher/usage_std 0.0584 (0.1569) nleep/row_max_mean 1521.4453 (1536.4162) nleep/row_max_std 48.3875 (56.3463) nleep/row_min_mean 1490.4183 (1503.2491) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [40/173] time 0.138 (0.117) data 0.000 (0.010) loss 1.4217 (1.4903) teacher_loss 0.1177 (0.2173) loss_zs_kd 0.0291 (0.0334) loss_oracle 0.5235 (0.5534) kd_loss 1.0277 (0.9796) acc 93.7500 (91.4844) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.1014 (0.0486) teacher/usage_max 0.4156 (0.5203) teacher/usage_min 0.2809 (0.1912) teacher/usage_std 0.0589 (0.1439) nleep/row_max_mean 1541.5780 (1536.0667) nleep/row_max_std 52.0887 (56.7342) nleep/row_min_mean 1508.6597 (1503.0201) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [60/173] time 0.152 (0.124) data 0.001 (0.007) loss 1.4422 (1.5040) teacher_loss 0.1563 (0.2190) loss_zs_kd 0.0205 (0.0345) loss_oracle 0.5739 (0.5606) kd_loss 0.9887 (0.9873) acc 93.7500 (91.0938) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5647 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0487 (0.0442) teacher/usage_max 0.5117 (0.5162) teacher/usage_min 0.2178 (0.1977) teacher/usage_std 0.1280 (0.1388) nleep/row_max_mean 1532.6306 (1536.2353) nleep/row_max_std 71.7037 (56.0478) nleep/row_min_mean 1496.7625 (1503.0760) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [80/173] time 0.171 (0.132) data 0.000 (0.005) loss 1.6236 (1.4940) teacher_loss 0.2947 (0.2122) loss_zs_kd 0.0393 (0.0335) loss_oracle 0.5673 (0.5536) kd_loss 1.0257 (0.9882) acc 87.5000 (91.4844) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0368 (0.0464) teacher/usage_max 0.4810 (0.5129) teacher/usage_min 0.2172 (0.1955) teacher/usage_std 0.1099 (0.1381) nleep/row_max_mean 1530.8837 (1536.1211) nleep/row_max_std 52.8291 (55.0949) nleep/row_min_mean 1497.7266 (1503.0749) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [100/173] time 0.164 (0.140) data 0.000 (0.004) loss 1.5659 (1.4881) teacher_loss 0.0562 (0.2055) loss_zs_kd 0.0187 (0.0337) loss_oracle 0.7025 (0.5503) kd_loss 1.1492 (0.9906) acc 100.0000 (91.9062) gate/entropy 0.9870 (0.9863) gate/usage_max 0.5639 (0.5647) gate/usage_min 0.2113 (0.2111) gate/usage_std 0.1631 (0.1637) teacher/entropy 0.0260 (0.0475) teacher/usage_max 0.4378 (0.5106) teacher/usage_min 0.2047 (0.2000) teacher/usage_std 0.0967 (0.1353) nleep/row_max_mean 1511.1899 (1536.2779) nleep/row_max_std 58.9943 (55.4113) nleep/row_min_mean 1480.4266 (1503.2938) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [120/173] time 0.168 (0.145) data 0.000 (0.003) loss 1.1950 (1.4814) teacher_loss 0.0762 (0.2018) loss_zs_kd 0.0201 (0.0337) loss_oracle 0.4738 (0.5472) kd_loss 0.8719 (0.9892) acc 96.8750 (92.0833) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5650 (0.5647) gate/usage_min 0.2110 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0266 (0.0467) teacher/usage_max 0.6553 (0.5146) teacher/usage_min 0.1593 (0.1981) teacher/usage_std 0.2279 (0.1377) nleep/row_max_mean 1553.1868 (1537.4512) nleep/row_max_std 54.5025 (54.9902) nleep/row_min_mean 1520.6705 (1504.4508) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [140/173] time 0.161 (0.146) data 0.000 (0.003) loss 1.6870 (1.4852) teacher_loss 0.1740 (0.1997) loss_zs_kd 0.0292 (0.0330) loss_oracle 0.7270 (0.5496) kd_loss 1.1349 (0.9942) acc 96.8750 (92.2321) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0582 (0.0454) teacher/usage_max 0.4490 (0.5108) teacher/usage_min 0.2119 (0.1997) teacher/usage_std 0.0969 (0.1354) nleep/row_max_mean 1529.0339 (1537.4315) nleep/row_max_std 44.7935 (54.9735) nleep/row_min_mean 1494.7461 (1504.3938) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [160/173] time 0.146 (0.148) data 0.000 (0.003) loss 1.5326 (1.4869) teacher_loss 0.2769 (0.1992) loss_zs_kd 0.0353 (0.0334) loss_oracle 0.5216 (0.5496) kd_loss 0.9772 (0.9962) acc 90.6250 (92.3438) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5649 (0.5647) gate/usage_min 0.2111 (0.2111) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0460 (0.0450) teacher/usage_max 0.5261 (0.5091) teacher/usage_min 0.2288 (0.2001) teacher/usage_std 0.1365 (0.1344) nleep/row_max_mean 1543.0898 (1537.3290) nleep/row_max_std 47.9834 (54.3382) nleep/row_min_mean 1509.0554 (1504.3609) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,994
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.7%, epoch: 37 *******
******* Domain a best val test acc: 97.0%, epoch: 37 *******
******* Domain a best test acc:     98.1%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:23

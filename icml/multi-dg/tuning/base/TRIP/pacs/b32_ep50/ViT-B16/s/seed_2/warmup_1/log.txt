Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'photo']
Target     ['sketch']
# classes  7
# train_x  4,241
# val      1,821
# test     3,928
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/132] time 0.169 (0.191) data 0.000 (0.020) loss 1.0873 (1.0554) teacher_loss 0.3815 (0.2643) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.7057 (0.7911) acc 84.3750 (91.2500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3382) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0036 (0.0035) teacher/entropy 0.3935 (0.3058) teacher/usage_max 0.4281 (0.4455) teacher/usage_min 0.2184 (0.2293) teacher/usage_std 0.0868 (0.0913) nleep/row_max_mean 1573.2705 (1571.3283) nleep/row_max_std 70.9602 (64.3904) nleep/row_min_mean 1567.0728 (1559.4253) lr 1.0000e-05 eta 0:20:59
epoch [1/50] batch [40/132] time 0.137 (0.166) data 0.000 (0.010) loss 0.6470 (0.9443) teacher_loss 0.1474 (0.2426) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0007 (0.0002) kd_loss 0.4993 (0.7015) acc 93.7500 (92.2656) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3382) gate/usage_min 0.3300 (0.3300) gate/usage_std 0.0035 (0.0035) teacher/entropy 0.5974 (0.3955) teacher/usage_max 0.4397 (0.4482) teacher/usage_min 0.2693 (0.2338) teacher/usage_std 0.0758 (0.0910) nleep/row_max_mean 1593.6885 (1578.9279) nleep/row_max_std 43.5684 (57.5764) nleep/row_min_mean 1589.1996 (1570.3204) lr 1.0000e-05 eta 0:18:06
epoch [1/50] batch [60/132] time 0.134 (0.155) data 0.000 (0.007) loss 0.7651 (0.8811) teacher_loss 0.2895 (0.2476) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0017 (0.0006) kd_loss 0.4748 (0.6332) acc 84.3750 (91.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3382) gate/usage_min 0.3300 (0.3300) gate/usage_std 0.0035 (0.0035) teacher/entropy 0.6235 (0.4639) teacher/usage_max 0.3556 (0.4386) teacher/usage_min 0.3040 (0.2391) teacher/usage_std 0.0217 (0.0855) nleep/row_max_mean 1571.5227 (1581.3517) nleep/row_max_std 38.7710 (54.0314) nleep/row_min_mean 1568.6041 (1574.3990) lr 1.0000e-05 eta 0:16:54
epoch [1/50] batch [80/132] time 0.159 (0.152) data 0.000 (0.005) loss 0.6066 (0.8273) teacher_loss 0.1867 (0.2456) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0053 (0.0013) kd_loss 0.4173 (0.5811) acc 93.7500 (91.7188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3382) gate/usage_min 0.3299 (0.3300) gate/usage_std 0.0036 (0.0035) teacher/entropy 0.6811 (0.5161) teacher/usage_max 0.3504 (0.4324) teacher/usage_min 0.3050 (0.2435) teacher/usage_std 0.0202 (0.0807) nleep/row_max_mean 1579.9888 (1582.8666) nleep/row_max_std 50.0173 (51.2163) nleep/row_min_mean 1577.0305 (1576.8856) lr 1.0000e-05 eta 0:16:33
epoch [1/50] batch [100/132] time 0.134 (0.150) data 0.000 (0.004) loss 0.7591 (0.7986) teacher_loss 0.3422 (0.2617) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0096 (0.0023) kd_loss 0.4121 (0.5357) acc 87.5000 (91.1250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3381 (0.3382) gate/usage_min 0.3300 (0.3300) gate/usage_std 0.0035 (0.0035) teacher/entropy 0.6860 (0.5615) teacher/usage_max 0.3822 (0.4276) teacher/usage_min 0.2646 (0.2474) teacher/usage_std 0.0500 (0.0768) nleep/row_max_mean 1586.9010 (1583.5055) nleep/row_max_std 41.6606 (49.9524) nleep/row_min_mean 1584.5234 (1578.2268) lr 1.0000e-05 eta 0:16:18
epoch [1/50] batch [120/132] time 0.081 (0.142) data 0.000 (0.003) loss 0.6001 (0.7649) teacher_loss 0.3772 (0.2657) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0083 (0.0038) kd_loss 0.2187 (0.4973) acc 90.6250 (91.1719) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3382) gate/usage_min 0.3299 (0.3300) gate/usage_std 0.0036 (0.0035) teacher/entropy 0.8809 (0.6001) teacher/usage_max 0.4426 (0.4244) teacher/usage_min 0.2743 (0.2487) teacher/usage_std 0.0773 (0.0749) nleep/row_max_mean 1583.4508 (1583.9337) nleep/row_max_std 33.9859 (48.4165) nleep/row_min_mean 1581.9611 (1579.1851) lr 1.0000e-05 eta 0:15:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,801
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,482
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      98.9%, epoch: 1 *******
******* Domain s best val test acc: 88.6%, epoch: 1 *******
******* Domain s best test acc:     88.6%, epoch: 1 *******
epoch [2/50] batch [20/132] time 0.098 (0.110) data 0.000 (0.015) loss 1.2743 (0.8309) teacher_loss 0.3278 (0.2319) loss_zs_kd 0.0008 (0.0018) loss_oracle 0.2457 (0.1763) kd_loss 0.8233 (0.5100) acc 90.6250 (92.6562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3372 (0.3378) gate/usage_min 0.3288 (0.3294) gate/usage_std 0.0035 (0.0035) teacher/entropy 0.2736 (0.5890) teacher/usage_max 0.8897 (0.6920) teacher/usage_min 0.0491 (0.1376) teacher/usage_std 0.3935 (0.2547) nleep/row_max_mean 1585.8345 (1583.3485) nleep/row_max_std 47.6783 (44.1144) nleep/row_min_mean 1580.4933 (1580.2423) lr 2.0000e-03 eta 0:11:46
epoch [2/50] batch [40/132] time 0.192 (0.118) data 0.000 (0.008) loss 1.7920 (1.0415) teacher_loss 0.6556 (0.2246) loss_zs_kd 0.0031 (0.0022) loss_oracle 0.2858 (0.2142) kd_loss 0.9919 (0.7087) acc 75.0000 (93.2031) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3390 (0.3375) gate/usage_min 0.3264 (0.3285) gate/usage_std 0.0052 (0.0038) teacher/entropy 0.0906 (0.3860) teacher/usage_max 0.9788 (0.8138) teacher/usage_min 0.0070 (0.0801) teacher/usage_std 0.4564 (0.3403) nleep/row_max_mean 1581.5308 (1583.0391) nleep/row_max_std 49.5415 (43.9588) nleep/row_min_mean 1573.0347 (1577.9830) lr 2.0000e-03 eta 0:12:39
epoch [2/50] batch [60/132] time 0.191 (0.121) data 0.000 (0.005) loss 1.3648 (1.1467) teacher_loss 0.1973 (0.2240) loss_zs_kd 0.0038 (0.0021) loss_oracle 0.2547 (0.2404) kd_loss 1.0382 (0.8014) acc 87.5000 (92.9688) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3451 (0.3390) gate/usage_min 0.3233 (0.3273) gate/usage_std 0.0090 (0.0049) teacher/entropy 0.0260 (0.2865) teacher/usage_max 0.9950 (0.8660) teacher/usage_min 0.0012 (0.0570) teacher/usage_std 0.4678 (0.3771) nleep/row_max_mean 1579.6204 (1582.2240) nleep/row_max_std 41.6386 (44.9417) nleep/row_min_mean 1568.6674 (1575.4581) lr 2.0000e-03 eta 0:12:55
epoch [2/50] batch [80/132] time 0.167 (0.121) data 0.000 (0.004) loss 1.2338 (1.1995) teacher_loss 0.0902 (0.2246) loss_zs_kd 0.0005 (0.0023) loss_oracle 0.3355 (0.2579) kd_loss 0.9756 (0.8448) acc 96.8750 (92.8125) gate/entropy 1.0978 (1.0984) gate/usage_max 0.3516 (0.3413) gate/usage_min 0.3202 (0.3259) gate/usage_std 0.0133 (0.0064) teacher/entropy 0.0730 (0.2353) teacher/usage_max 0.9646 (0.8916) teacher/usage_min 0.0049 (0.0450) teacher/usage_std 0.4465 (0.3950) nleep/row_max_mean 1579.3577 (1581.6810) nleep/row_max_std 50.6343 (45.4593) nleep/row_min_mean 1565.6807 (1573.7826) lr 2.0000e-03 eta 0:12:54
epoch [2/50] batch [100/132] time 0.161 (0.128) data 0.000 (0.003) loss 1.0573 (1.2081) teacher_loss 0.0274 (0.2105) loss_zs_kd 0.0000 (0.0021) loss_oracle 0.3153 (0.2723) kd_loss 0.8723 (0.8604) acc 100.0000 (93.1875) gate/entropy 1.0973 (1.0982) gate/usage_max 0.3574 (0.3440) gate/usage_min 0.3173 (0.3245) gate/usage_std 0.0174 (0.0082) teacher/entropy 0.1683 (0.2122) teacher/usage_max 0.8944 (0.9013) teacher/usage_min 0.0257 (0.0393) teacher/usage_std 0.3974 (0.4019) nleep/row_max_mean 1580.6964 (1580.6287) nleep/row_max_std 46.2869 (45.8876) nleep/row_min_mean 1570.1335 (1572.0924) lr 2.0000e-03 eta 0:13:36
epoch [2/50] batch [120/132] time 0.166 (0.135) data 0.000 (0.003) loss 1.1629 (1.2021) teacher_loss 0.1345 (0.1995) loss_zs_kd 0.0000 (0.0022) loss_oracle 0.3998 (0.2876) kd_loss 0.8285 (0.8576) acc 96.8750 (93.5156) gate/entropy 1.0966 (1.0980) gate/usage_max 0.3632 (0.3468) gate/usage_min 0.3144 (0.3230) gate/usage_std 0.0214 (0.0101) teacher/entropy 0.2120 (0.2090) teacher/usage_max 0.7898 (0.8959) teacher/usage_min 0.0950 (0.0388) teacher/usage_std 0.3229 (0.3982) nleep/row_max_mean 1577.1379 (1580.3094) nleep/row_max_std 47.3583 (46.0452) nleep/row_min_mean 1567.2860 (1571.4338) lr 2.0000e-03 eta 0:14:16
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,491
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.1%, epoch: 2 *******
******* Domain s best val test acc: 88.9%, epoch: 2 *******
******* Domain s best test acc:     88.9%, epoch: 2 *******
epoch [3/50] batch [20/132] time 0.123 (0.168) data 0.000 (0.015) loss 1.0353 (1.0980) teacher_loss 0.0720 (0.1882) loss_zs_kd 0.0025 (0.0039) loss_oracle 0.3604 (0.3363) kd_loss 0.7819 (0.7397) acc 96.8750 (94.3750) gate/entropy 1.0957 (1.0959) gate/usage_max 0.3692 (0.3677) gate/usage_min 0.3118 (0.3124) gate/usage_std 0.0256 (0.0245) teacher/entropy 0.2655 (0.3190) teacher/usage_max 0.6843 (0.6246) teacher/usage_min 0.0744 (0.1170) teacher/usage_std 0.2574 (0.2165) nleep/row_max_mean 1586.9365 (1573.4125) nleep/row_max_std 32.9845 (42.4987) nleep/row_min_mean 1577.6749 (1564.8962) lr 1.9980e-03 eta 0:17:39
epoch [3/50] batch [40/132] time 0.111 (0.152) data 0.000 (0.007) loss 1.0878 (1.0755) teacher_loss 0.2055 (0.1799) loss_zs_kd 0.0073 (0.0043) loss_oracle 0.3701 (0.3363) kd_loss 0.6937 (0.7252) acc 90.6250 (94.2188) gate/entropy 1.0953 (1.0957) gate/usage_max 0.3717 (0.3691) gate/usage_min 0.3115 (0.3120) gate/usage_std 0.0272 (0.0255) teacher/entropy 0.3755 (0.3384) teacher/usage_max 0.5365 (0.5868) teacher/usage_min 0.1356 (0.1229) teacher/usage_std 0.1637 (0.1957) nleep/row_max_mean 1569.4166 (1572.0377) nleep/row_max_std 42.0715 (43.3731) nleep/row_min_mean 1560.5923 (1563.4503) lr 1.9980e-03 eta 0:15:56
epoch [3/50] batch [60/132] time 0.082 (0.131) data 0.000 (0.005) loss 1.2101 (1.0814) teacher_loss 0.1893 (0.1790) loss_zs_kd 0.0032 (0.0054) loss_oracle 0.4136 (0.3387) kd_loss 0.8124 (0.7303) acc 93.7500 (94.0625) gate/entropy 1.0950 (1.0955) gate/usage_max 0.3739 (0.3703) gate/usage_min 0.3113 (0.3118) gate/usage_std 0.0287 (0.0263) teacher/entropy 0.2616 (0.3339) teacher/usage_max 0.4973 (0.5752) teacher/usage_min 0.1157 (0.1244) teacher/usage_std 0.1603 (0.1895) nleep/row_max_mean 1569.4341 (1571.5912) nleep/row_max_std 50.2563 (43.3454) nleep/row_min_mean 1560.2916 (1562.9409) lr 1.9980e-03 eta 0:13:43
epoch [3/50] batch [80/132] time 0.097 (0.129) data 0.000 (0.004) loss 1.2829 (1.1057) teacher_loss 0.1702 (0.1680) loss_zs_kd 0.0087 (0.0050) loss_oracle 0.4594 (0.3667) kd_loss 0.8787 (0.7518) acc 93.7500 (94.2578) gate/entropy 1.0946 (1.0954) gate/usage_max 0.3757 (0.3715) gate/usage_min 0.3114 (0.3117) gate/usage_std 0.0300 (0.0271) teacher/entropy 0.2096 (0.3142) teacher/usage_max 0.5329 (0.5726) teacher/usage_min 0.0522 (0.1112) teacher/usage_std 0.2045 (0.1937) nleep/row_max_mean 1557.5082 (1570.7314) nleep/row_max_std 34.6229 (43.3473) nleep/row_min_mean 1546.0183 (1561.6533) lr 1.9980e-03 eta 0:13:28
epoch [3/50] batch [100/132] time 0.091 (0.125) data 0.000 (0.003) loss 1.3493 (1.1401) teacher_loss 0.2748 (0.1736) loss_zs_kd 0.0116 (0.0051) loss_oracle 0.4853 (0.3775) kd_loss 0.8260 (0.7753) acc 90.6250 (94.1875) gate/entropy 1.0945 (1.0952) gate/usage_max 0.3763 (0.3724) gate/usage_min 0.3109 (0.3116) gate/usage_std 0.0304 (0.0277) teacher/entropy 0.2689 (0.2975) teacher/usage_max 0.6046 (0.5831) teacher/usage_min 0.0322 (0.0962) teacher/usage_std 0.2346 (0.2045) nleep/row_max_mean 1543.1658 (1568.9875) nleep/row_max_std 54.1442 (43.0613) nleep/row_min_mean 1532.4680 (1559.6373) lr 1.9980e-03 eta 0:13:01
epoch [3/50] batch [120/132] time 0.082 (0.124) data 0.000 (0.003) loss 1.4057 (1.1732) teacher_loss 0.1562 (0.1742) loss_zs_kd 0.0033 (0.0051) loss_oracle 0.4392 (0.3793) kd_loss 1.0282 (0.8068) acc 96.8750 (94.2448) gate/entropy 1.0947 (1.0951) gate/usage_max 0.3750 (0.3730) gate/usage_min 0.3088 (0.3113) gate/usage_std 0.0296 (0.0281) teacher/entropy 0.0939 (0.2747) teacher/usage_max 0.8152 (0.6159) teacher/usage_min 0.0119 (0.0863) teacher/usage_std 0.3470 (0.2242) nleep/row_max_mean 1545.7822 (1567.6766) nleep/row_max_std 54.2035 (42.9264) nleep/row_min_mean 1532.2593 (1557.8112) lr 1.9980e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,528
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 3 *******
******* Domain s best val test acc: 89.8%, epoch: 3 *******
******* Domain s best test acc:     89.8%, epoch: 3 *******
epoch [4/50] batch [20/132] time 0.078 (0.134) data 0.000 (0.017) loss 1.4983 (1.4821) teacher_loss 0.1976 (0.1839) loss_zs_kd 0.0057 (0.0040) loss_oracle 0.6193 (0.6278) kd_loss 0.9882 (0.9823) acc 90.6250 (93.7500) gate/entropy 1.0954 (1.0952) gate/usage_max 0.3702 (0.3716) gate/usage_min 0.3065 (0.3070) gate/usage_std 0.0270 (0.0277) teacher/entropy 0.1468 (0.1444) teacher/usage_max 0.8906 (0.8580) teacher/usage_min 0.0003 (0.0481) teacher/usage_std 0.3965 (0.3718) nleep/row_max_mean 1553.8726 (1561.9770) nleep/row_max_std 48.1391 (43.4155) nleep/row_min_mean 1537.8892 (1546.6260) lr 1.9921e-03 eta 0:13:48
epoch [4/50] batch [40/132] time 0.163 (0.137) data 0.000 (0.009) loss 1.2494 (1.4869) teacher_loss 0.0485 (0.1978) loss_zs_kd 0.0037 (0.0049) loss_oracle 0.5148 (0.6400) kd_loss 0.9417 (0.9666) acc 100.0000 (93.6719) gate/entropy 1.0957 (1.0954) gate/usage_max 0.3672 (0.3701) gate/usage_min 0.3057 (0.3065) gate/usage_std 0.0255 (0.0269) teacher/entropy 0.1733 (0.1579) teacher/usage_max 0.7903 (0.8229) teacher/usage_min 0.0923 (0.0577) teacher/usage_std 0.3233 (0.3479) nleep/row_max_mean 1561.3688 (1559.0145) nleep/row_max_std 50.0027 (44.2180) nleep/row_min_mean 1546.5814 (1543.7953) lr 1.9921e-03 eta 0:14:01
epoch [4/50] batch [60/132] time 0.135 (0.140) data 0.000 (0.006) loss 1.3849 (1.4556) teacher_loss 0.2266 (0.1840) loss_zs_kd 0.0055 (0.0061) loss_oracle 0.5641 (0.6305) kd_loss 0.8735 (0.9533) acc 93.7500 (93.9062) gate/entropy 1.0960 (1.0956) gate/usage_max 0.3643 (0.3686) gate/usage_min 0.3058 (0.3063) gate/usage_std 0.0240 (0.0262) teacher/entropy 0.2480 (0.1711) teacher/usage_max 0.7643 (0.7784) teacher/usage_min 0.0302 (0.0576) teacher/usage_std 0.3130 (0.3215) nleep/row_max_mean 1541.7200 (1555.9214) nleep/row_max_std 49.3680 (43.9994) nleep/row_min_mean 1527.7151 (1540.7047) lr 1.9921e-03 eta 0:14:20
epoch [4/50] batch [80/132] time 0.158 (0.143) data 0.000 (0.005) loss 1.5009 (1.4422) teacher_loss 0.2940 (0.1791) loss_zs_kd 0.0220 (0.0073) loss_oracle 0.5551 (0.6164) kd_loss 0.9183 (0.9512) acc 87.5000 (93.9844) gate/entropy 1.0963 (1.0957) gate/usage_max 0.3613 (0.3671) gate/usage_min 0.3062 (0.3062) gate/usage_std 0.0225 (0.0254) teacher/entropy 0.1896 (0.1719) teacher/usage_max 0.8075 (0.7566) teacher/usage_min 0.0545 (0.0580) teacher/usage_std 0.3370 (0.3086) nleep/row_max_mean 1550.3323 (1553.7114) nleep/row_max_std 48.4198 (44.3195) nleep/row_min_mean 1534.8555 (1538.3859) lr 1.9921e-03 eta 0:14:36
epoch [4/50] batch [100/132] time 0.151 (0.144) data 0.000 (0.004) loss 1.3339 (1.4300) teacher_loss 0.2140 (0.1845) loss_zs_kd 0.0148 (0.0075) loss_oracle 0.3655 (0.5871) kd_loss 0.9298 (0.9481) acc 90.6250 (93.7500) gate/entropy 1.0965 (1.0959) gate/usage_max 0.3582 (0.3656) gate/usage_min 0.3057 (0.3062) gate/usage_std 0.0215 (0.0247) teacher/entropy 0.1792 (0.1726) teacher/usage_max 0.7250 (0.7483) teacher/usage_min 0.0453 (0.0584) teacher/usage_std 0.2870 (0.3029) nleep/row_max_mean 1545.6764 (1552.5676) nleep/row_max_std 38.3001 (43.6706) nleep/row_min_mean 1529.7400 (1537.0789) lr 1.9921e-03 eta 0:14:40
epoch [4/50] batch [120/132] time 0.111 (0.142) data 0.000 (0.003) loss 1.2290 (1.4216) teacher_loss 0.1459 (0.1897) loss_zs_kd 0.0081 (0.0078) loss_oracle 0.4376 (0.5633) kd_loss 0.8602 (0.9464) acc 93.7500 (93.5677) gate/entropy 1.0967 (1.0960) gate/usage_max 0.3545 (0.3641) gate/usage_min 0.3056 (0.3061) gate/usage_std 0.0205 (0.0241) teacher/entropy 0.2504 (0.1718) teacher/usage_max 0.6349 (0.7432) teacher/usage_min 0.0506 (0.0571) teacher/usage_std 0.2389 (0.2999) nleep/row_max_mean 1534.8740 (1552.7381) nleep/row_max_std 63.0291 (43.2424) nleep/row_min_mean 1521.0784 (1537.1395) lr 1.9921e-03 eta 0:14:25
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,547
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 3 *******
******* Domain s best val test acc: 89.8%, epoch: 3 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [5/50] batch [20/132] time 0.129 (0.127) data 0.000 (0.017) loss 1.6510 (1.4529) teacher_loss 0.3633 (0.2210) loss_zs_kd 0.0126 (0.0054) loss_oracle 0.5592 (0.5255) kd_loss 1.0018 (0.9664) acc 90.6250 (93.7500) gate/entropy 1.0966 (1.0967) gate/usage_max 0.3484 (0.3500) gate/usage_min 0.3036 (0.3046) gate/usage_std 0.0210 (0.0204) teacher/entropy 0.0561 (0.1058) teacher/usage_max 0.9728 (0.8986) teacher/usage_min 0.0020 (0.0218) teacher/usage_std 0.4523 (0.4009) nleep/row_max_mean 1552.1394 (1548.7266) nleep/row_max_std 50.5027 (44.8425) nleep/row_min_mean 1532.1643 (1530.7652) lr 1.9823e-03 eta 0:12:50
epoch [5/50] batch [40/132] time 0.142 (0.117) data 0.000 (0.009) loss 1.2705 (1.4496) teacher_loss 0.0236 (0.2049) loss_zs_kd 0.0000 (0.0075) loss_oracle 0.4957 (0.5300) kd_loss 0.9991 (0.9759) acc 100.0000 (93.4375) gate/entropy 1.0962 (1.0966) gate/usage_max 0.3552 (0.3509) gate/usage_min 0.3016 (0.3037) gate/usage_std 0.0229 (0.0211) teacher/entropy 0.0377 (0.0845) teacher/usage_max 0.9889 (0.9247) teacher/usage_min 0.0021 (0.0162) teacher/usage_std 0.4635 (0.4188) nleep/row_max_mean 1555.5625 (1550.2763) nleep/row_max_std 50.0076 (43.9943) nleep/row_min_mean 1534.7849 (1530.9735) lr 1.9823e-03 eta 0:11:48
epoch [5/50] batch [60/132] time 0.084 (0.114) data 0.000 (0.006) loss 1.4331 (1.4457) teacher_loss 0.1613 (0.2015) loss_zs_kd 0.0237 (0.0075) loss_oracle 0.5738 (0.5235) kd_loss 0.9731 (0.9787) acc 93.7500 (93.3854) gate/entropy 1.0954 (1.0963) gate/usage_max 0.3625 (0.3536) gate/usage_min 0.2986 (0.3025) gate/usage_std 0.0264 (0.0223) teacher/entropy 0.0469 (0.0706) teacher/usage_max 0.9235 (0.9366) teacher/usage_min 0.0020 (0.0123) teacher/usage_std 0.4183 (0.4272) nleep/row_max_mean 1544.1437 (1549.5623) nleep/row_max_std 54.5358 (44.5375) nleep/row_min_mean 1522.3069 (1529.3822) lr 1.9823e-03 eta 0:11:25
epoch [5/50] batch [80/132] time 0.087 (0.116) data 0.000 (0.004) loss 1.4074 (1.4390) teacher_loss 0.1184 (0.1967) loss_zs_kd 0.0004 (0.0068) loss_oracle 0.6590 (0.5280) kd_loss 0.9593 (0.9750) acc 96.8750 (93.6328) gate/entropy 1.0944 (1.0960) gate/usage_max 0.3703 (0.3569) gate/usage_min 0.2954 (0.3011) gate/usage_std 0.0306 (0.0239) teacher/entropy 0.0358 (0.0636) teacher/usage_max 0.9901 (0.9452) teacher/usage_min 0.0038 (0.0099) teacher/usage_std 0.4644 (0.4331) nleep/row_max_mean 1550.6283 (1549.0920) nleep/row_max_std 54.2386 (45.2290) nleep/row_min_mean 1524.6016 (1527.9641) lr 1.9823e-03 eta 0:11:33
epoch [5/50] batch [100/132] time 0.098 (0.115) data 0.000 (0.004) loss 1.4104 (1.4320) teacher_loss 0.1072 (0.1908) loss_zs_kd 0.0021 (0.0063) loss_oracle 0.6672 (0.5359) kd_loss 0.9685 (0.9701) acc 96.8750 (93.6562) gate/entropy 1.0931 (1.0955) gate/usage_max 0.3781 (0.3603) gate/usage_min 0.2924 (0.2996) gate/usage_std 0.0351 (0.0257) teacher/entropy 0.0043 (0.0580) teacher/usage_max 0.9993 (0.9507) teacher/usage_min 0.0000 (0.0081) teacher/usage_std 0.4709 (0.4370) nleep/row_max_mean 1549.5549 (1548.2856) nleep/row_max_std 41.2741 (45.2729) nleep/row_min_mean 1524.1042 (1526.2859) lr 1.9823e-03 eta 0:11:26
epoch [5/50] batch [120/132] time 0.074 (0.114) data 0.000 (0.003) loss 1.3076 (1.4225) teacher_loss 0.1416 (0.1884) loss_zs_kd 0.0008 (0.0062) loss_oracle 0.5500 (0.5392) kd_loss 0.8907 (0.9615) acc 93.7500 (93.7240) gate/entropy 1.0915 (1.0950) gate/usage_max 0.3859 (0.3640) gate/usage_min 0.2892 (0.2981) gate/usage_std 0.0399 (0.0277) teacher/entropy 0.0751 (0.0566) teacher/usage_max 0.9372 (0.9535) teacher/usage_min 0.0259 (0.0074) teacher/usage_std 0.4270 (0.4389) nleep/row_max_mean 1533.8281 (1547.1554) nleep/row_max_std 44.0408 (45.1194) nleep/row_min_mean 1510.3992 (1524.5472) lr 1.9823e-03 eta 0:11:16
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,523
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [6/50] batch [20/132] time 0.164 (0.174) data 0.000 (0.015) loss 1.4111 (1.3353) teacher_loss 0.2336 (0.1565) loss_zs_kd 0.0196 (0.0068) loss_oracle 0.5873 (0.6020) kd_loss 0.8740 (0.8744) acc 90.6250 (94.2188) gate/entropy 1.0885 (1.0895) gate/usage_max 0.3980 (0.3944) gate/usage_min 0.2840 (0.2857) gate/usage_std 0.0478 (0.0454) teacher/entropy 0.0604 (0.0719) teacher/usage_max 0.9418 (0.9252) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4309 (0.4201) nleep/row_max_mean 1546.2690 (1538.3636) nleep/row_max_std 38.5013 (44.2113) nleep/row_min_mean 1517.5392 (1512.2379) lr 1.9686e-03 eta 0:17:13
epoch [6/50] batch [40/132] time 0.147 (0.165) data 0.000 (0.008) loss 1.1115 (1.3089) teacher_loss 0.0819 (0.1559) loss_zs_kd 0.0011 (0.0071) loss_oracle 0.4816 (0.5568) kd_loss 0.7883 (0.8711) acc 96.8750 (94.6094) gate/entropy 1.0865 (1.0885) gate/usage_max 0.4050 (0.3980) gate/usage_min 0.2813 (0.2841) gate/usage_std 0.0524 (0.0478) teacher/entropy 0.1664 (0.0695) teacher/usage_max 0.8064 (0.9164) teacher/usage_min 0.0149 (0.0013) teacher/usage_std 0.3411 (0.4141) nleep/row_max_mean 1532.9587 (1537.9029) nleep/row_max_std 47.0356 (44.3922) nleep/row_min_mean 1506.0946 (1511.3288) lr 1.9686e-03 eta 0:16:13
epoch [6/50] batch [60/132] time 0.133 (0.160) data 0.000 (0.005) loss 1.2901 (1.2844) teacher_loss 0.2264 (0.1587) loss_zs_kd 0.0012 (0.0065) loss_oracle 0.4526 (0.5228) kd_loss 0.8368 (0.8610) acc 93.7500 (94.6354) gate/entropy 1.0846 (1.0875) gate/usage_max 0.4110 (0.4014) gate/usage_min 0.2787 (0.2828) gate/usage_std 0.0564 (0.0500) teacher/entropy 0.0960 (0.0784) teacher/usage_max 0.8449 (0.8941) teacher/usage_min 0.0018 (0.0015) teacher/usage_std 0.3670 (0.3999) nleep/row_max_mean 1529.9583 (1534.5933) nleep/row_max_std 47.4061 (46.1910) nleep/row_min_mean 1503.6514 (1508.3251) lr 1.9686e-03 eta 0:15:38
epoch [6/50] batch [80/132] time 0.147 (0.159) data 0.000 (0.004) loss 1.1533 (1.2701) teacher_loss 0.1004 (0.1518) loss_zs_kd 0.0024 (0.0065) loss_oracle 0.3461 (0.5153) kd_loss 0.8787 (0.8574) acc 93.7500 (94.7656) gate/entropy 1.0832 (1.0866) gate/usage_max 0.4153 (0.4044) gate/usage_min 0.2769 (0.2815) gate/usage_std 0.0593 (0.0520) teacher/entropy 0.0581 (0.0828) teacher/usage_max 0.8063 (0.8705) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3437 (0.3851) nleep/row_max_mean 1534.5364 (1533.5664) nleep/row_max_std 49.0533 (46.1276) nleep/row_min_mean 1510.6487 (1507.9014) lr 1.9686e-03 eta 0:15:29
epoch [6/50] batch [100/132] time 0.160 (0.157) data 0.000 (0.003) loss 1.0918 (1.2514) teacher_loss 0.0707 (0.1480) loss_zs_kd 0.0098 (0.0069) loss_oracle 0.4178 (0.4979) kd_loss 0.8072 (0.8510) acc 96.8750 (94.8125) gate/entropy 1.0819 (1.0858) gate/usage_max 0.4188 (0.4069) gate/usage_min 0.2747 (0.2804) gate/usage_std 0.0618 (0.0537) teacher/entropy 0.2224 (0.0943) teacher/usage_max 0.5094 (0.8372) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.2358 (0.3672) nleep/row_max_mean 1544.7590 (1534.2120) nleep/row_max_std 40.4387 (45.5235) nleep/row_min_mean 1517.3757 (1508.7729) lr 1.9686e-03 eta 0:15:18
epoch [6/50] batch [120/132] time 0.143 (0.156) data 0.000 (0.003) loss 1.6143 (1.2686) teacher_loss 0.3912 (0.1538) loss_zs_kd 0.0038 (0.0069) loss_oracle 0.6766 (0.5146) kd_loss 0.8829 (0.8540) acc 90.6250 (94.7135) gate/entropy 1.0814 (1.0851) gate/usage_max 0.4198 (0.4090) gate/usage_min 0.2730 (0.2793) gate/usage_std 0.0627 (0.0551) teacher/entropy 0.1331 (0.1037) teacher/usage_max 0.5263 (0.7903) teacher/usage_min 0.0001 (0.0018) teacher/usage_std 0.2366 (0.3462) nleep/row_max_mean 1525.7441 (1533.9528) nleep/row_max_std 46.0630 (45.5141) nleep/row_min_mean 1504.5198 (1508.7306) lr 1.9686e-03 eta 0:15:07
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [7/50] batch [20/132] time 0.144 (0.137) data 0.001 (0.013) loss 1.3775 (1.3835) teacher_loss 0.1141 (0.1449) loss_zs_kd 0.0098 (0.0067) loss_oracle 0.5584 (0.6062) kd_loss 0.9793 (0.9322) acc 96.8750 (94.5312) gate/entropy 1.0819 (1.0817) gate/usage_max 0.4177 (0.4186) gate/usage_min 0.2717 (0.2721) gate/usage_std 0.0617 (0.0622) teacher/entropy 0.0961 (0.1493) teacher/usage_max 0.6815 (0.6609) teacher/usage_min 0.0008 (0.0260) teacher/usage_std 0.2781 (0.2631) nleep/row_max_mean 1535.4417 (1532.4066) nleep/row_max_std 52.3967 (46.6197) nleep/row_min_mean 1512.4136 (1511.1978) lr 1.9511e-03 eta 0:13:12
epoch [7/50] batch [40/132] time 0.113 (0.126) data 0.000 (0.007) loss 1.1765 (1.3734) teacher_loss 0.0168 (0.1499) loss_zs_kd 0.0023 (0.0072) loss_oracle 0.5370 (0.5610) kd_loss 0.8899 (0.9394) acc 100.0000 (94.6094) gate/entropy 1.0823 (1.0819) gate/usage_max 0.4156 (0.4176) gate/usage_min 0.2706 (0.2716) gate/usage_std 0.0608 (0.0617) teacher/entropy 0.1355 (0.1368) teacher/usage_max 0.5239 (0.6483) teacher/usage_min 0.0924 (0.0290) teacher/usage_std 0.1797 (0.2563) nleep/row_max_mean 1523.9519 (1534.1388) nleep/row_max_std 44.0987 (44.3513) nleep/row_min_mean 1503.9152 (1513.0947) lr 1.9511e-03 eta 0:12:07
epoch [7/50] batch [60/132] time 0.163 (0.118) data 0.001 (0.005) loss 1.2661 (1.3591) teacher_loss 0.1192 (0.1461) loss_zs_kd 0.0070 (0.0073) loss_oracle 0.5147 (0.5342) kd_loss 0.8860 (0.9422) acc 96.8750 (95.0521) gate/entropy 1.0826 (1.0820) gate/usage_max 0.4139 (0.4167) gate/usage_min 0.2692 (0.2710) gate/usage_std 0.0602 (0.0613) teacher/entropy 0.1969 (0.1319) teacher/usage_max 0.6580 (0.6520) teacher/usage_min 0.0583 (0.0265) teacher/usage_std 0.2473 (0.2596) nleep/row_max_mean 1527.8348 (1535.1506) nleep/row_max_std 48.4234 (44.3403) nleep/row_min_mean 1507.5709 (1513.8582) lr 1.9511e-03 eta 0:11:16
epoch [7/50] batch [80/132] time 0.076 (0.114) data 0.000 (0.004) loss 1.2718 (1.3573) teacher_loss 0.0268 (0.1485) loss_zs_kd 0.0007 (0.0072) loss_oracle 0.4972 (0.5230) kd_loss 0.9960 (0.9437) acc 100.0000 (95.0000) gate/entropy 1.0827 (1.0822) gate/usage_max 0.4120 (0.4158) gate/usage_min 0.2672 (0.2703) gate/usage_std 0.0598 (0.0610) teacher/entropy 0.0528 (0.1287) teacher/usage_max 0.6475 (0.6601) teacher/usage_min 0.0000 (0.0231) teacher/usage_std 0.2647 (0.2647) nleep/row_max_mean 1528.2451 (1535.7182) nleep/row_max_std 53.1604 (44.6155) nleep/row_min_mean 1506.2894 (1513.8856) lr 1.9511e-03 eta 0:10:52
epoch [7/50] batch [100/132] time 0.069 (0.115) data 0.000 (0.003) loss 1.6024 (1.3691) teacher_loss 0.3635 (0.1558) loss_zs_kd 0.0163 (0.0076) loss_oracle 0.5194 (0.5213) kd_loss 0.9711 (0.9488) acc 84.3750 (94.8438) gate/entropy 1.0830 (1.0823) gate/usage_max 0.4094 (0.4147) gate/usage_min 0.2654 (0.2695) gate/usage_std 0.0591 (0.0607) teacher/entropy 0.1206 (0.1255) teacher/usage_max 0.8620 (0.6827) teacher/usage_min 0.0000 (0.0214) teacher/usage_std 0.3780 (0.2763) nleep/row_max_mean 1535.6737 (1535.5680) nleep/row_max_std 45.5215 (44.5089) nleep/row_min_mean 1510.1497 (1513.2606) lr 1.9511e-03 eta 0:10:58
epoch [7/50] batch [120/132] time 0.091 (0.116) data 0.000 (0.002) loss 1.3689 (1.3689) teacher_loss 0.1444 (0.1546) loss_zs_kd 0.0068 (0.0074) loss_oracle 0.5806 (0.5306) kd_loss 0.9307 (0.9453) acc 96.8750 (94.9219) gate/entropy 1.0835 (1.0825) gate/usage_max 0.4059 (0.4135) gate/usage_min 0.2644 (0.2688) gate/usage_std 0.0578 (0.0603) teacher/entropy 0.1281 (0.1281) teacher/usage_max 0.7431 (0.6906) teacher/usage_min 0.0063 (0.0224) teacher/usage_std 0.3064 (0.2797) nleep/row_max_mean 1530.3536 (1535.2850) nleep/row_max_std 49.4580 (44.1999) nleep/row_min_mean 1506.8005 (1512.9299) lr 1.9511e-03 eta 0:10:59
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,523
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.2%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [8/50] batch [20/132] time 0.171 (0.186) data 0.000 (0.015) loss 1.2880 (1.3911) teacher_loss 0.0912 (0.1760) loss_zs_kd 0.0016 (0.0097) loss_oracle 0.4956 (0.5240) kd_loss 0.9482 (0.9483) acc 96.8750 (93.7500) gate/entropy 1.0839 (1.0838) gate/usage_max 0.4014 (0.4026) gate/usage_min 0.2622 (0.2629) gate/usage_std 0.0568 (0.0571) teacher/entropy 0.1062 (0.1084) teacher/usage_max 0.7982 (0.7422) teacher/usage_min 0.0015 (0.0225) teacher/usage_std 0.3386 (0.3037) nleep/row_max_mean 1526.6532 (1534.9274) nleep/row_max_std 52.6691 (41.3489) nleep/row_min_mean 1504.2023 (1512.7483) lr 1.9298e-03 eta 0:17:31
epoch [8/50] batch [40/132] time 0.186 (0.185) data 0.000 (0.008) loss 1.1667 (1.3777) teacher_loss 0.0166 (0.1757) loss_zs_kd 0.0020 (0.0092) loss_oracle 0.4779 (0.5160) kd_loss 0.9102 (0.9394) acc 100.0000 (93.9062) gate/entropy 1.0840 (1.0839) gate/usage_max 0.3984 (0.4012) gate/usage_min 0.2608 (0.2622) gate/usage_std 0.0564 (0.0568) teacher/entropy 0.1267 (0.1171) teacher/usage_max 0.7263 (0.7700) teacher/usage_min 0.0073 (0.0194) teacher/usage_std 0.2973 (0.3204) nleep/row_max_mean 1538.7939 (1533.3871) nleep/row_max_std 47.3816 (44.1612) nleep/row_min_mean 1515.8130 (1511.4759) lr 1.9298e-03 eta 0:17:21
epoch [8/50] batch [60/132] time 0.154 (0.180) data 0.000 (0.005) loss 1.3635 (1.3587) teacher_loss 0.1231 (0.1604) loss_zs_kd 0.0154 (0.0085) loss_oracle 0.4913 (0.5116) kd_loss 0.9871 (0.9382) acc 93.7500 (94.4271) gate/entropy 1.0841 (1.0840) gate/usage_max 0.3950 (0.3997) gate/usage_min 0.2595 (0.2615) gate/usage_std 0.0560 (0.0566) teacher/entropy 0.0568 (0.1156) teacher/usage_max 0.8583 (0.7740) teacher/usage_min 0.0001 (0.0214) teacher/usage_std 0.3757 (0.3221) nleep/row_max_mean 1536.6552 (1533.3640) nleep/row_max_std 37.9884 (43.0130) nleep/row_min_mean 1513.7631 (1511.8768) lr 1.9298e-03 eta 0:16:48
epoch [8/50] batch [80/132] time 0.177 (0.173) data 0.000 (0.004) loss 1.5797 (1.3619) teacher_loss 0.2894 (0.1567) loss_zs_kd 0.0237 (0.0085) loss_oracle 0.5892 (0.5155) kd_loss 0.9838 (0.9432) acc 87.5000 (94.5312) gate/entropy 1.0842 (1.0840) gate/usage_max 0.3915 (0.3980) gate/usage_min 0.2581 (0.2609) gate/usage_std 0.0558 (0.0564) teacher/entropy 0.0624 (0.1093) teacher/usage_max 0.8579 (0.7826) teacher/usage_min 0.0319 (0.0248) teacher/usage_std 0.3723 (0.3269) nleep/row_max_mean 1524.5359 (1532.4313) nleep/row_max_std 38.5082 (42.7129) nleep/row_min_mean 1501.2545 (1510.8757) lr 1.9298e-03 eta 0:16:08
epoch [8/50] batch [100/132] time 0.086 (0.165) data 0.000 (0.003) loss 1.4418 (1.3682) teacher_loss 0.1910 (0.1618) loss_zs_kd 0.0128 (0.0086) loss_oracle 0.5672 (0.5159) kd_loss 0.9608 (0.9441) acc 90.6250 (94.3125) gate/entropy 1.0842 (1.0841) gate/usage_max 0.3876 (0.3963) gate/usage_min 0.2569 (0.2602) gate/usage_std 0.0556 (0.0562) teacher/entropy 0.0807 (0.1052) teacher/usage_max 0.8496 (0.7967) teacher/usage_min 0.0491 (0.0246) teacher/usage_std 0.3656 (0.3357) nleep/row_max_mean 1526.8694 (1531.1284) nleep/row_max_std 40.0347 (43.1411) nleep/row_min_mean 1506.2588 (1509.7312) lr 1.9298e-03 eta 0:15:22
epoch [8/50] batch [120/132] time 0.070 (0.157) data 0.000 (0.003) loss 1.4491 (1.3723) teacher_loss 0.1764 (0.1640) loss_zs_kd 0.0084 (0.0083) loss_oracle 0.6259 (0.5192) kd_loss 0.9556 (0.9445) acc 90.6250 (94.0365) gate/entropy 1.0839 (1.0841) gate/usage_max 0.3833 (0.3945) gate/usage_min 0.2553 (0.2595) gate/usage_std 0.0559 (0.0562) teacher/entropy 0.0744 (0.1009) teacher/usage_max 0.8054 (0.8060) teacher/usage_min 0.0589 (0.0250) teacher/usage_std 0.3353 (0.3415) nleep/row_max_mean 1532.1466 (1530.5108) nleep/row_max_std 40.1137 (42.8205) nleep/row_min_mean 1509.8906 (1509.1230) lr 1.9298e-03 eta 0:14:29
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,545
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.5%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [9/50] batch [20/132] time 0.063 (0.126) data 0.000 (0.015) loss 1.5911 (1.3696) teacher_loss 0.3699 (0.1540) loss_zs_kd 0.0147 (0.0072) loss_oracle 0.4924 (0.5623) kd_loss 0.9677 (0.9308) acc 84.3750 (95.0000) gate/entropy 1.0834 (1.0836) gate/usage_max 0.3764 (0.3785) gate/usage_min 0.2532 (0.2538) gate/usage_std 0.0567 (0.0564) teacher/entropy 0.0454 (0.0843) teacher/usage_max 0.9064 (0.8656) teacher/usage_min 0.0387 (0.0415) teacher/usage_std 0.4053 (0.3773) nleep/row_max_mean 1540.6394 (1530.3902) nleep/row_max_std 47.4658 (42.6301) nleep/row_min_mean 1519.2325 (1509.3624) lr 1.9048e-03 eta 0:11:34
epoch [9/50] batch [40/132] time 0.081 (0.118) data 0.000 (0.008) loss 1.3764 (1.3779) teacher_loss 0.1736 (0.1684) loss_zs_kd 0.0060 (0.0084) loss_oracle 0.5894 (0.5534) kd_loss 0.9051 (0.9285) acc 93.7500 (94.5312) gate/entropy 1.0831 (1.0834) gate/usage_max 0.3757 (0.3767) gate/usage_min 0.2523 (0.2532) gate/usage_std 0.0573 (0.0567) teacher/entropy 0.0982 (0.0798) teacher/usage_max 0.6414 (0.8633) teacher/usage_min 0.0553 (0.0387) teacher/usage_std 0.2402 (0.3763) nleep/row_max_mean 1534.7063 (1530.2461) nleep/row_max_std 43.8329 (43.6837) nleep/row_min_mean 1517.6742 (1509.4614) lr 1.9048e-03 eta 0:10:49
epoch [9/50] batch [60/132] time 0.094 (0.117) data 0.001 (0.005) loss 1.3487 (1.3641) teacher_loss 0.2946 (0.1610) loss_zs_kd 0.0088 (0.0082) loss_oracle 0.3960 (0.5525) kd_loss 0.8517 (0.9227) acc 90.6250 (94.7396) gate/entropy 1.0826 (1.0832) gate/usage_max 0.3807 (0.3773) gate/usage_min 0.2513 (0.2527) gate/usage_std 0.0582 (0.0571) teacher/entropy 0.1258 (0.0810) teacher/usage_max 0.7589 (0.8529) teacher/usage_min 0.0094 (0.0410) teacher/usage_std 0.3143 (0.3691) nleep/row_max_mean 1527.7114 (1531.0611) nleep/row_max_std 39.0937 (43.2826) nleep/row_min_mean 1508.0664 (1510.3985) lr 1.9048e-03 eta 0:10:43
epoch [9/50] batch [80/132] time 0.130 (0.117) data 0.000 (0.004) loss 1.3577 (1.3570) teacher_loss 0.2380 (0.1652) loss_zs_kd 0.0240 (0.0084) loss_oracle 0.4829 (0.5457) kd_loss 0.8663 (0.9147) acc 93.7500 (94.2188) gate/entropy 1.0820 (1.0830) gate/usage_max 0.3855 (0.3788) gate/usage_min 0.2503 (0.2522) gate/usage_std 0.0594 (0.0575) teacher/entropy 0.1143 (0.0843) teacher/usage_max 0.8058 (0.8491) teacher/usage_min 0.0438 (0.0428) teacher/usage_std 0.3369 (0.3663) nleep/row_max_mean 1526.0210 (1531.4169) nleep/row_max_std 33.3039 (42.8809) nleep/row_min_mean 1506.5397 (1510.8895) lr 1.9048e-03 eta 0:10:39
epoch [9/50] batch [100/132] time 0.131 (0.126) data 0.000 (0.003) loss 1.1993 (1.3464) teacher_loss 0.0890 (0.1644) loss_zs_kd 0.0119 (0.0087) loss_oracle 0.5029 (0.5412) kd_loss 0.8529 (0.9069) acc 96.8750 (94.3125) gate/entropy 1.0813 (1.0827) gate/usage_max 0.3900 (0.3806) gate/usage_min 0.2491 (0.2517) gate/usage_std 0.0608 (0.0580) teacher/entropy 0.1226 (0.0883) teacher/usage_max 0.8234 (0.8405) teacher/usage_min 0.0547 (0.0444) teacher/usage_std 0.3476 (0.3605) nleep/row_max_mean 1538.7369 (1531.3801) nleep/row_max_std 36.3060 (42.6478) nleep/row_min_mean 1518.3762 (1511.0888) lr 1.9048e-03 eta 0:11:25
epoch [9/50] batch [120/132] time 0.118 (0.129) data 0.000 (0.003) loss 1.2256 (1.3361) teacher_loss 0.1664 (0.1645) loss_zs_kd 0.0059 (0.0088) loss_oracle 0.4436 (0.5343) kd_loss 0.8344 (0.9002) acc 93.7500 (94.4271) gate/entropy 1.0804 (1.0824) gate/usage_max 0.3947 (0.3826) gate/usage_min 0.2478 (0.2512) gate/usage_std 0.0623 (0.0586) teacher/entropy 0.1234 (0.0903) teacher/usage_max 0.7854 (0.8369) teacher/usage_min 0.0193 (0.0432) teacher/usage_std 0.3276 (0.3584) nleep/row_max_mean 1532.7109 (1530.5955) nleep/row_max_std 48.1217 (43.1484) nleep/row_min_mean 1513.0857 (1510.3193) lr 1.9048e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,522
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [10/50] batch [20/132] time 0.135 (0.182) data 0.000 (0.018) loss 1.3341 (1.2249) teacher_loss 0.1873 (0.1297) loss_zs_kd 0.0101 (0.0079) loss_oracle 0.6059 (0.4998) kd_loss 0.8388 (0.8414) acc 90.6250 (95.3125) gate/entropy 1.0786 (1.0792) gate/usage_max 0.4028 (0.4003) gate/usage_min 0.2455 (0.2462) gate/usage_std 0.0655 (0.0645) teacher/entropy 0.1040 (0.1089) teacher/usage_max 0.8617 (0.8377) teacher/usage_min 0.0415 (0.0413) teacher/usage_std 0.3743 (0.3586) nleep/row_max_mean 1511.9875 (1526.6538) nleep/row_max_std 50.3525 (46.3386) nleep/row_min_mean 1491.6853 (1505.8924) lr 1.8763e-03 eta 0:16:22
epoch [10/50] batch [40/132] time 0.188 (0.172) data 0.000 (0.009) loss 1.1726 (1.2526) teacher_loss 0.0897 (0.1411) loss_zs_kd 0.0041 (0.0084) loss_oracle 0.5631 (0.5123) kd_loss 0.7993 (0.8511) acc 96.8750 (94.9219) gate/entropy 1.0772 (1.0785) gate/usage_max 0.4083 (0.4030) gate/usage_min 0.2439 (0.2454) gate/usage_std 0.0679 (0.0656) teacher/entropy 0.1366 (0.0908) teacher/usage_max 0.8373 (0.8461) teacher/usage_min 0.0392 (0.0345) teacher/usage_std 0.3580 (0.3648) nleep/row_max_mean 1532.7714 (1528.9445) nleep/row_max_std 46.6585 (45.7833) nleep/row_min_mean 1512.7000 (1507.9715) lr 1.8763e-03 eta 0:15:25
epoch [10/50] batch [60/132] time 0.096 (0.147) data 0.001 (0.006) loss 1.1968 (1.2527) teacher_loss 0.0898 (0.1434) loss_zs_kd 0.0039 (0.0082) loss_oracle 0.5211 (0.5192) kd_loss 0.8445 (0.8456) acc 96.8750 (95.1042) gate/entropy 1.0759 (1.0778) gate/usage_max 0.4134 (0.4057) gate/usage_min 0.2427 (0.2447) gate/usage_std 0.0701 (0.0668) teacher/entropy 0.0994 (0.0952) teacher/usage_max 0.7684 (0.8324) teacher/usage_min 0.0543 (0.0384) teacher/usage_std 0.3117 (0.3558) nleep/row_max_mean 1536.3094 (1528.5405) nleep/row_max_std 41.9438 (46.4288) nleep/row_min_mean 1518.2651 (1507.7385) lr 1.8763e-03 eta 0:13:07
epoch [10/50] batch [80/132] time 0.146 (0.140) data 0.000 (0.005) loss 1.4433 (1.2547) teacher_loss 0.4672 (0.1515) loss_zs_kd 0.0086 (0.0087) loss_oracle 0.4919 (0.5213) kd_loss 0.7259 (0.8382) acc 84.3750 (94.7656) gate/entropy 1.0746 (1.0772) gate/usage_max 0.4176 (0.4082) gate/usage_min 0.2414 (0.2440) gate/usage_std 0.0721 (0.0679) teacher/entropy 0.2234 (0.1041) teacher/usage_max 0.7053 (0.8113) teacher/usage_min 0.0481 (0.0429) teacher/usage_std 0.2752 (0.3424) nleep/row_max_mean 1530.9883 (1528.7172) nleep/row_max_std 46.0308 (45.7146) nleep/row_min_mean 1513.1157 (1508.2923) lr 1.8763e-03 eta 0:12:29
epoch [10/50] batch [100/132] time 0.169 (0.135) data 0.000 (0.004) loss 1.2234 (1.2572) teacher_loss 0.2183 (0.1551) loss_zs_kd 0.0129 (0.0094) loss_oracle 0.4826 (0.5249) kd_loss 0.7573 (0.8350) acc 90.6250 (94.9062) gate/entropy 1.0736 (1.0766) gate/usage_max 0.4209 (0.4103) gate/usage_min 0.2405 (0.2435) gate/usage_std 0.0737 (0.0688) teacher/entropy 0.1662 (0.1100) teacher/usage_max 0.7543 (0.7902) teacher/usage_min 0.0138 (0.0486) teacher/usage_std 0.3107 (0.3283) nleep/row_max_mean 1546.7251 (1528.8510) nleep/row_max_std 41.5129 (45.4329) nleep/row_min_mean 1524.9019 (1508.8352) lr 1.8763e-03 eta 0:11:56
epoch [10/50] batch [120/132] time 0.071 (0.130) data 0.000 (0.003) loss 1.3230 (1.2524) teacher_loss 0.1334 (0.1575) loss_zs_kd 0.0115 (0.0095) loss_oracle 0.6673 (0.5258) kd_loss 0.8503 (0.8273) acc 96.8750 (94.9219) gate/entropy 1.0727 (1.0760) gate/usage_max 0.4241 (0.4123) gate/usage_min 0.2398 (0.2429) gate/usage_std 0.0753 (0.0698) teacher/entropy 0.0724 (0.1168) teacher/usage_max 0.8101 (0.7809) teacher/usage_min 0.0632 (0.0499) teacher/usage_std 0.3381 (0.3226) nleep/row_max_mean 1540.8727 (1528.8752) nleep/row_max_std 36.9571 (45.8714) nleep/row_min_mean 1519.0815 (1509.0856) lr 1.8763e-03 eta 0:11:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,501
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.8%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [11/50] batch [20/132] time 0.096 (0.144) data 0.000 (0.015) loss 1.2035 (1.2223) teacher_loss 0.1132 (0.1573) loss_zs_kd 0.0170 (0.0091) loss_oracle 0.4869 (0.5064) kd_loss 0.8384 (0.8073) acc 93.7500 (94.5312) gate/entropy 1.0702 (1.0709) gate/usage_max 0.4316 (0.4294) gate/usage_min 0.2380 (0.2385) gate/usage_std 0.0791 (0.0779) teacher/entropy 0.0749 (0.1140) teacher/usage_max 0.8310 (0.8052) teacher/usage_min 0.0828 (0.0637) teacher/usage_std 0.3519 (0.3352) nleep/row_max_mean 1525.3175 (1527.5424) nleep/row_max_std 32.5329 (46.5627) nleep/row_min_mean 1506.3540 (1509.1709) lr 1.8443e-03 eta 0:12:35
epoch [11/50] batch [40/132] time 0.144 (0.129) data 0.000 (0.008) loss 1.5918 (1.2364) teacher_loss 0.5683 (0.1772) loss_zs_kd 0.0221 (0.0106) loss_oracle 0.4803 (0.5014) kd_loss 0.7723 (0.8031) acc 84.3750 (94.2969) gate/entropy 1.0685 (1.0701) gate/usage_max 0.4364 (0.4318) gate/usage_min 0.2369 (0.2380) gate/usage_std 0.0816 (0.0791) teacher/entropy 0.1082 (0.1056) teacher/usage_max 0.8732 (0.8258) teacher/usage_min 0.0453 (0.0581) teacher/usage_std 0.3820 (0.3495) nleep/row_max_mean 1516.3253 (1527.2769) nleep/row_max_std 45.7077 (46.0925) nleep/row_min_mean 1496.9337 (1508.1818) lr 1.8443e-03 eta 0:11:16
epoch [11/50] batch [60/132] time 0.171 (0.138) data 0.001 (0.005) loss 1.1918 (1.2312) teacher_loss 0.1461 (0.1713) loss_zs_kd 0.0120 (0.0099) loss_oracle 0.4768 (0.5008) kd_loss 0.8014 (0.8045) acc 96.8750 (94.4271) gate/entropy 1.0667 (1.0693) gate/usage_max 0.4415 (0.4342) gate/usage_min 0.2359 (0.2375) gate/usage_std 0.0843 (0.0804) teacher/entropy 0.0957 (0.0976) teacher/usage_max 0.8192 (0.8336) teacher/usage_min 0.0735 (0.0576) teacher/usage_std 0.3438 (0.3548) nleep/row_max_mean 1523.3591 (1528.0725) nleep/row_max_std 43.8794 (45.1625) nleep/row_min_mean 1504.4309 (1508.2604) lr 1.8443e-03 eta 0:12:02
epoch [11/50] batch [80/132] time 0.159 (0.144) data 0.000 (0.004) loss 1.4183 (1.2294) teacher_loss 0.3395 (0.1746) loss_zs_kd 0.0057 (0.0097) loss_oracle 0.6163 (0.5007) kd_loss 0.7678 (0.7997) acc 90.6250 (94.3359) gate/entropy 1.0648 (1.0684) gate/usage_max 0.4465 (0.4366) gate/usage_min 0.2351 (0.2370) gate/usage_std 0.0869 (0.0817) teacher/entropy 0.0859 (0.0904) teacher/usage_max 0.8633 (0.8516) teacher/usage_min 0.0033 (0.0498) teacher/usage_std 0.3785 (0.3674) nleep/row_max_mean 1536.0413 (1527.3426) nleep/row_max_std 38.4386 (44.9586) nleep/row_min_mean 1510.4365 (1506.5926) lr 1.8443e-03 eta 0:12:29
epoch [11/50] batch [100/132] time 0.169 (0.148) data 0.000 (0.003) loss 1.1841 (1.2278) teacher_loss 0.1532 (0.1735) loss_zs_kd 0.0168 (0.0096) loss_oracle 0.4807 (0.5075) kd_loss 0.7822 (0.7958) acc 93.7500 (94.4375) gate/entropy 1.0629 (1.0674) gate/usage_max 0.4513 (0.4391) gate/usage_min 0.2345 (0.2365) gate/usage_std 0.0895 (0.0831) teacher/entropy 0.0475 (0.0858) teacher/usage_max 0.9314 (0.8620) teacher/usage_min 0.0324 (0.0456) teacher/usage_std 0.4229 (0.3746) nleep/row_max_mean 1527.0999 (1526.8852) nleep/row_max_std 52.3604 (45.7939) nleep/row_min_mean 1502.0215 (1505.5174) lr 1.8443e-03 eta 0:12:44
epoch [11/50] batch [120/132] time 0.150 (0.150) data 0.000 (0.003) loss 1.3321 (1.2221) teacher_loss 0.3200 (0.1689) loss_zs_kd 0.0125 (0.0100) loss_oracle 0.5261 (0.5119) kd_loss 0.7428 (0.7922) acc 93.7500 (94.6094) gate/entropy 1.0603 (1.0665) gate/usage_max 0.4573 (0.4417) gate/usage_min 0.2332 (0.2360) gate/usage_std 0.0930 (0.0845) teacher/entropy 0.0542 (0.0822) teacher/usage_max 0.9644 (0.8688) teacher/usage_min 0.0026 (0.0431) teacher/usage_std 0.4464 (0.3794) nleep/row_max_mean 1519.2378 (1526.9596) nleep/row_max_std 59.8881 (46.5906) nleep/row_min_mean 1494.1813 (1505.0246) lr 1.8443e-03 eta 0:12:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,492
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.6%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [12/50] batch [20/132] time 0.092 (0.124) data 0.000 (0.017) loss 1.4686 (1.2173) teacher_loss 0.4022 (0.1551) loss_zs_kd 0.0117 (0.0108) loss_oracle 0.5029 (0.5183) kd_loss 0.8092 (0.7976) acc 81.2500 (95.4688) gate/entropy 1.0573 (1.0584) gate/usage_max 0.4643 (0.4619) gate/usage_min 0.2328 (0.2331) gate/usage_std 0.0969 (0.0956) teacher/entropy 0.0452 (0.0780) teacher/usage_max 0.8636 (0.8226) teacher/usage_min 0.0268 (0.0606) teacher/usage_std 0.3765 (0.3471) nleep/row_max_mean 1531.2991 (1526.5194) nleep/row_max_std 38.8944 (50.8015) nleep/row_min_mean 1506.4249 (1504.0945) lr 1.8090e-03 eta 0:10:33
epoch [12/50] batch [40/132] time 0.155 (0.119) data 0.000 (0.009) loss 1.2756 (1.2361) teacher_loss 0.2214 (0.1832) loss_zs_kd 0.0081 (0.0108) loss_oracle 0.5936 (0.5202) kd_loss 0.7534 (0.7874) acc 87.5000 (94.0625) gate/entropy 1.0553 (1.0574) gate/usage_max 0.4684 (0.4640) gate/usage_min 0.2320 (0.2328) gate/usage_std 0.0994 (0.0968) teacher/entropy 0.0512 (0.0776) teacher/usage_max 0.9143 (0.8316) teacher/usage_min 0.0310 (0.0555) teacher/usage_std 0.4109 (0.3535) nleep/row_max_mean 1534.4302 (1527.7054) nleep/row_max_std 53.6462 (49.8713) nleep/row_min_mean 1505.5807 (1504.8293) lr 1.8090e-03 eta 0:10:07
epoch [12/50] batch [60/132] time 0.094 (0.123) data 0.000 (0.006) loss 1.1540 (1.2245) teacher_loss 0.1587 (0.1811) loss_zs_kd 0.0009 (0.0100) loss_oracle 0.4803 (0.5202) kd_loss 0.7547 (0.7782) acc 93.7500 (94.3229) gate/entropy 1.0534 (1.0564) gate/usage_max 0.4723 (0.4661) gate/usage_min 0.2317 (0.2325) gate/usage_std 0.1017 (0.0980) teacher/entropy 0.0844 (0.0783) teacher/usage_max 0.8514 (0.8399) teacher/usage_min 0.0666 (0.0549) teacher/usage_std 0.3664 (0.3591) nleep/row_max_mean 1535.5510 (1529.8422) nleep/row_max_std 50.8542 (49.4093) nleep/row_min_mean 1509.5068 (1506.3940) lr 1.8090e-03 eta 0:10:27
epoch [12/50] batch [80/132] time 0.098 (0.121) data 0.000 (0.004) loss 1.0449 (1.2185) teacher_loss 0.0124 (0.1831) loss_zs_kd 0.0096 (0.0090) loss_oracle 0.5344 (0.5151) kd_loss 0.7605 (0.7734) acc 100.0000 (93.9844) gate/entropy 1.0514 (1.0554) gate/usage_max 0.4766 (0.4682) gate/usage_min 0.2315 (0.2323) gate/usage_std 0.1042 (0.0993) teacher/entropy 0.0988 (0.0770) teacher/usage_max 0.8049 (0.8443) teacher/usage_min 0.0968 (0.0537) teacher/usage_std 0.3334 (0.3621) nleep/row_max_mean 1512.8870 (1529.3191) nleep/row_max_std 42.2998 (48.8697) nleep/row_min_mean 1491.4828 (1505.6181) lr 1.8090e-03 eta 0:10:14
epoch [12/50] batch [100/132] time 0.196 (0.121) data 0.000 (0.004) loss 1.1956 (1.2126) teacher_loss 0.1619 (0.1789) loss_zs_kd 0.0056 (0.0088) loss_oracle 0.4823 (0.5174) kd_loss 0.7897 (0.7706) acc 96.8750 (94.0000) gate/entropy 1.0488 (1.0544) gate/usage_max 0.4813 (0.4703) gate/usage_min 0.2308 (0.2321) gate/usage_std 0.1072 (0.1005) teacher/entropy 0.0100 (0.0748) teacher/usage_max 0.9076 (0.8473) teacher/usage_min 0.0003 (0.0511) teacher/usage_std 0.4078 (0.3644) nleep/row_max_mean 1528.5645 (1529.3520) nleep/row_max_std 40.6912 (48.0556) nleep/row_min_mean 1502.0015 (1505.2120) lr 1.8090e-03 eta 0:10:12
epoch [12/50] batch [120/132] time 0.154 (0.120) data 0.000 (0.003) loss 1.2199 (1.2069) teacher_loss 0.1940 (0.1764) loss_zs_kd 0.0164 (0.0089) loss_oracle 0.5130 (0.5122) kd_loss 0.7611 (0.7700) acc 93.7500 (93.9844) gate/entropy 1.0462 (1.0532) gate/usage_max 0.4861 (0.4726) gate/usage_min 0.2303 (0.2318) gate/usage_std 0.1102 (0.1019) teacher/entropy 0.0332 (0.0698) teacher/usage_max 0.8999 (0.8520) teacher/usage_min 0.0076 (0.0469) teacher/usage_std 0.4021 (0.3678) nleep/row_max_mean 1529.2397 (1529.5189) nleep/row_max_std 52.3362 (47.5467) nleep/row_min_mean 1504.0848 (1504.9046) lr 1.8090e-03 eta 0:10:04
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,533
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.3%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [13/50] batch [20/132] time 0.167 (0.182) data 0.000 (0.015) loss 1.0920 (1.1701) teacher_loss 0.0978 (0.1832) loss_zs_kd 0.0022 (0.0125) loss_oracle 0.5577 (0.4956) kd_loss 0.7143 (0.7328) acc 96.8750 (93.5938) gate/entropy 1.0426 (1.0433) gate/usage_max 0.4923 (0.4911) gate/usage_min 0.2299 (0.2298) gate/usage_std 0.1141 (0.1134) teacher/entropy 0.0493 (0.0507) teacher/usage_max 0.9256 (0.8991) teacher/usage_min 0.0107 (0.0217) teacher/usage_std 0.4194 (0.4011) nleep/row_max_mean 1517.3928 (1530.0984) nleep/row_max_std 56.7499 (44.3619) nleep/row_min_mean 1489.9498 (1502.0670) lr 1.7705e-03 eta 0:15:08
epoch [13/50] batch [40/132] time 0.148 (0.171) data 0.000 (0.008) loss 1.2424 (1.1419) teacher_loss 0.2547 (0.1711) loss_zs_kd 0.0072 (0.0104) loss_oracle 0.4685 (0.4910) kd_loss 0.7498 (0.7201) acc 87.5000 (93.9844) gate/entropy 1.0391 (1.0420) gate/usage_max 0.4981 (0.4933) gate/usage_min 0.2288 (0.2295) gate/usage_std 0.1179 (0.1148) teacher/entropy 0.0168 (0.0541) teacher/usage_max 0.9010 (0.9052) teacher/usage_min 0.0364 (0.0233) teacher/usage_std 0.4015 (0.4051) nleep/row_max_mean 1544.3198 (1530.1338) nleep/row_max_std 35.9333 (44.8793) nleep/row_min_mean 1513.0745 (1501.6337) lr 1.7705e-03 eta 0:14:09
epoch [13/50] batch [60/132] time 0.156 (0.167) data 0.000 (0.005) loss 1.0541 (1.1318) teacher_loss 0.1135 (0.1633) loss_zs_kd 0.0064 (0.0097) loss_oracle 0.5216 (0.4970) kd_loss 0.6765 (0.7151) acc 93.7500 (94.1667) gate/entropy 1.0369 (1.0406) gate/usage_max 0.5017 (0.4955) gate/usage_min 0.2286 (0.2293) gate/usage_std 0.1202 (0.1162) teacher/entropy 0.0377 (0.0530) teacher/usage_max 0.9686 (0.9076) teacher/usage_min 0.0036 (0.0243) teacher/usage_std 0.4493 (0.4067) nleep/row_max_mean 1515.3394 (1529.9541) nleep/row_max_std 49.1827 (45.3439) nleep/row_min_mean 1491.4357 (1501.5614) lr 1.7705e-03 eta 0:13:48
epoch [13/50] batch [80/132] time 0.159 (0.166) data 0.000 (0.004) loss 1.0025 (1.1172) teacher_loss 0.1042 (0.1533) loss_zs_kd 0.0073 (0.0088) loss_oracle 0.4854 (0.5030) kd_loss 0.6519 (0.7080) acc 93.7500 (94.5703) gate/entropy 1.0344 (1.0394) gate/usage_max 0.5055 (0.4975) gate/usage_min 0.2281 (0.2290) gate/usage_std 0.1227 (0.1175) teacher/entropy 0.0821 (0.0568) teacher/usage_max 0.9311 (0.9069) teacher/usage_min 0.0192 (0.0256) teacher/usage_std 0.4229 (0.4061) nleep/row_max_mean 1535.1012 (1529.8077) nleep/row_max_std 33.5565 (43.7564) nleep/row_min_mean 1507.2682 (1502.0269) lr 1.7705e-03 eta 0:13:40
epoch [13/50] batch [100/132] time 0.125 (0.162) data 0.000 (0.003) loss 1.1878 (1.1238) teacher_loss 0.1548 (0.1554) loss_zs_kd 0.0120 (0.0092) loss_oracle 0.5395 (0.5089) kd_loss 0.7573 (0.7092) acc 93.7500 (94.6875) gate/entropy 1.0323 (1.0382) gate/usage_max 0.5087 (0.4995) gate/usage_min 0.2280 (0.2288) gate/usage_std 0.1248 (0.1188) teacher/entropy 0.0836 (0.0585) teacher/usage_max 0.7807 (0.8985) teacher/usage_min 0.0650 (0.0274) teacher/usage_std 0.3184 (0.4004) nleep/row_max_mean 1523.6075 (1529.8467) nleep/row_max_std 44.4229 (43.6103) nleep/row_min_mean 1500.9117 (1502.6614) lr 1.7705e-03 eta 0:13:18
epoch [13/50] batch [120/132] time 0.161 (0.160) data 0.000 (0.003) loss 1.2026 (1.1372) teacher_loss 0.1638 (0.1629) loss_zs_kd 0.0024 (0.0094) loss_oracle 0.5623 (0.5145) kd_loss 0.7564 (0.7123) acc 93.7500 (94.3750) gate/entropy 1.0302 (1.0370) gate/usage_max 0.5117 (0.5013) gate/usage_min 0.2278 (0.2287) gate/usage_std 0.1268 (0.1200) teacher/entropy 0.0240 (0.0595) teacher/usage_max 0.8429 (0.8893) teacher/usage_min 0.0375 (0.0284) teacher/usage_std 0.3619 (0.3943) nleep/row_max_mean 1546.5225 (1530.6304) nleep/row_max_std 35.0388 (43.3568) nleep/row_min_mean 1523.0100 (1503.9238) lr 1.7705e-03 eta 0:13:03
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.2%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [14/50] batch [20/132] time 0.103 (0.116) data 0.001 (0.014) loss 1.0434 (1.1511) teacher_loss 0.0480 (0.1764) loss_zs_kd 0.0069 (0.0087) loss_oracle 0.5097 (0.5321) kd_loss 0.7371 (0.7043) acc 96.8750 (94.2188) gate/entropy 1.0275 (1.0281) gate/usage_max 0.5157 (0.5148) gate/usage_min 0.2278 (0.2277) gate/usage_std 0.1295 (0.1289) teacher/entropy 0.1137 (0.0688) teacher/usage_max 0.7642 (0.8616) teacher/usage_min 0.0275 (0.0283) teacher/usage_std 0.3135 (0.3759) nleep/row_max_mean 1528.6396 (1532.5460) nleep/row_max_std 42.5502 (42.0431) nleep/row_min_mean 1506.2163 (1508.9683) lr 1.7290e-03 eta 0:09:26
epoch [14/50] batch [40/132] time 0.088 (0.111) data 0.000 (0.007) loss 1.1760 (1.1423) teacher_loss 0.2451 (0.1662) loss_zs_kd 0.0133 (0.0097) loss_oracle 0.4493 (0.5246) kd_loss 0.6996 (0.7090) acc 87.5000 (94.3750) gate/entropy 1.0253 (1.0271) gate/usage_max 0.5187 (0.5162) gate/usage_min 0.2275 (0.2276) gate/usage_std 0.1315 (0.1298) teacher/entropy 0.0724 (0.0787) teacher/usage_max 0.8550 (0.8399) teacher/usage_min 0.0278 (0.0363) teacher/usage_std 0.3707 (0.3611) nleep/row_max_mean 1539.0249 (1533.9909) nleep/row_max_std 46.4473 (43.1456) nleep/row_min_mean 1513.9819 (1510.9041) lr 1.7290e-03 eta 0:08:56
epoch [14/50] batch [60/132] time 0.093 (0.112) data 0.000 (0.005) loss 1.2493 (1.1452) teacher_loss 0.2205 (0.1649) loss_zs_kd 0.0083 (0.0096) loss_oracle 0.5310 (0.5251) kd_loss 0.7592 (0.7129) acc 93.7500 (94.6354) gate/entropy 1.0228 (1.0262) gate/usage_max 0.5221 (0.5175) gate/usage_min 0.2271 (0.2276) gate/usage_std 0.1338 (0.1307) teacher/entropy 0.0714 (0.0752) teacher/usage_max 0.7764 (0.8375) teacher/usage_min 0.0500 (0.0322) teacher/usage_std 0.3173 (0.3599) nleep/row_max_mean 1538.6498 (1534.1492) nleep/row_max_std 45.6957 (44.5992) nleep/row_min_mean 1517.9927 (1510.8649) lr 1.7290e-03 eta 0:09:02
epoch [14/50] batch [80/132] time 0.079 (0.115) data 0.000 (0.004) loss 1.0234 (1.1548) teacher_loss 0.0312 (0.1708) loss_zs_kd 0.0000 (0.0094) loss_oracle 0.4686 (0.5233) kd_loss 0.7579 (0.7177) acc 96.8750 (94.6875) gate/entropy 1.0219 (1.0252) gate/usage_max 0.5234 (0.5188) gate/usage_min 0.2275 (0.2275) gate/usage_std 0.1347 (0.1316) teacher/entropy 0.0612 (0.0726) teacher/usage_max 0.7935 (0.8333) teacher/usage_min 0.0040 (0.0279) teacher/usage_std 0.3353 (0.3576) nleep/row_max_mean 1539.3168 (1534.4252) nleep/row_max_std 32.9131 (44.9825) nleep/row_min_mean 1518.6826 (1511.1304) lr 1.7290e-03 eta 0:09:10
epoch [14/50] batch [100/132] time 0.104 (0.116) data 0.001 (0.003) loss 1.1073 (1.1619) teacher_loss 0.0306 (0.1665) loss_zs_kd 0.0040 (0.0090) loss_oracle 0.6251 (0.5338) kd_loss 0.7622 (0.7240) acc 100.0000 (94.7188) gate/entropy 1.0199 (1.0244) gate/usage_max 0.5261 (0.5200) gate/usage_min 0.2273 (0.2275) gate/usage_std 0.1365 (0.1324) teacher/entropy 0.0573 (0.0720) teacher/usage_max 0.7824 (0.8244) teacher/usage_min 0.0598 (0.0262) teacher/usage_std 0.3200 (0.3524) nleep/row_max_mean 1544.3159 (1534.1890) nleep/row_max_std 44.3398 (45.2932) nleep/row_min_mean 1520.4155 (1510.8961) lr 1.7290e-03 eta 0:09:14
epoch [14/50] batch [120/132] time 0.151 (0.120) data 0.000 (0.003) loss 1.1669 (1.1693) teacher_loss 0.1496 (0.1652) loss_zs_kd 0.0055 (0.0090) loss_oracle 0.5372 (0.5402) kd_loss 0.7459 (0.7295) acc 93.7500 (94.6615) gate/entropy 1.0184 (1.0236) gate/usage_max 0.5280 (0.5211) gate/usage_min 0.2275 (0.2275) gate/usage_std 0.1378 (0.1331) teacher/entropy 0.0880 (0.0746) teacher/usage_max 0.7664 (0.8129) teacher/usage_min 0.0145 (0.0246) teacher/usage_std 0.3174 (0.3459) nleep/row_max_mean 1536.5317 (1533.9859) nleep/row_max_std 47.7878 (45.4572) nleep/row_min_mean 1512.3762 (1510.8098) lr 1.7290e-03 eta 0:09:31
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,503
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.8%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [15/50] batch [20/132] time 0.164 (0.161) data 0.000 (0.016) loss 1.1047 (1.1891) teacher_loss 0.0427 (0.1486) loss_zs_kd 0.0081 (0.0079) loss_oracle 0.5507 (0.5364) kd_loss 0.7826 (0.7683) acc 100.0000 (94.5312) gate/entropy 1.0170 (1.0177) gate/usage_max 0.5299 (0.5290) gate/usage_min 0.2280 (0.2280) gate/usage_std 0.1391 (0.1385) teacher/entropy 0.0693 (0.0900) teacher/usage_max 0.7419 (0.7352) teacher/usage_min 0.0002 (0.0126) teacher/usage_std 0.3074 (0.3036) nleep/row_max_mean 1530.6536 (1532.2718) nleep/row_max_std 42.4106 (47.6959) nleep/row_min_mean 1506.9153 (1509.1428) lr 1.6845e-03 eta 0:12:43
epoch [15/50] batch [40/132] time 0.131 (0.155) data 0.000 (0.008) loss 1.2959 (1.1867) teacher_loss 0.2971 (0.1576) loss_zs_kd 0.0179 (0.0111) loss_oracle 0.4269 (0.5304) kd_loss 0.7765 (0.7583) acc 90.6250 (94.5312) gate/entropy 1.0159 (1.0170) gate/usage_max 0.5314 (0.5299) gate/usage_min 0.2282 (0.2281) gate/usage_std 0.1401 (0.1391) teacher/entropy 0.0766 (0.0860) teacher/usage_max 0.7383 (0.7504) teacher/usage_min 0.0114 (0.0133) teacher/usage_std 0.3025 (0.3120) nleep/row_max_mean 1533.2391 (1533.2528) nleep/row_max_std 50.7101 (45.8644) nleep/row_min_mean 1511.8601 (1510.1844) lr 1.6845e-03 eta 0:12:09
epoch [15/50] batch [60/132] time 0.162 (0.152) data 0.000 (0.005) loss 1.2961 (1.1864) teacher_loss 0.1293 (0.1526) loss_zs_kd 0.0110 (0.0115) loss_oracle 0.5598 (0.5298) kd_loss 0.8814 (0.7631) acc 96.8750 (95.0000) gate/entropy 1.0148 (1.0165) gate/usage_max 0.5327 (0.5306) gate/usage_min 0.2284 (0.2282) gate/usage_std 0.1410 (0.1396) teacher/entropy 0.0547 (0.0836) teacher/usage_max 0.6376 (0.7460) teacher/usage_min 0.0145 (0.0180) teacher/usage_std 0.2546 (0.3080) nleep/row_max_mean 1540.3318 (1533.9796) nleep/row_max_std 43.1150 (45.9964) nleep/row_min_mean 1515.5426 (1510.8044) lr 1.6845e-03 eta 0:11:55
epoch [15/50] batch [80/132] time 0.073 (0.150) data 0.000 (0.004) loss 1.0997 (1.1866) teacher_loss 0.0944 (0.1532) loss_zs_kd 0.0118 (0.0117) loss_oracle 0.4562 (0.5218) kd_loss 0.7714 (0.7666) acc 96.8750 (94.7656) gate/entropy 1.0141 (1.0159) gate/usage_max 0.5336 (0.5312) gate/usage_min 0.2287 (0.2283) gate/usage_std 0.1416 (0.1400) teacher/entropy 0.1051 (0.0846) teacher/usage_max 0.7068 (0.7395) teacher/usage_min 0.0001 (0.0180) teacher/usage_std 0.2899 (0.3044) nleep/row_max_mean 1534.6084 (1534.0872) nleep/row_max_std 38.9170 (46.4638) nleep/row_min_mean 1511.8251 (1511.0880) lr 1.6845e-03 eta 0:11:42
epoch [15/50] batch [100/132] time 0.187 (0.140) data 0.000 (0.003) loss 1.1072 (1.1932) teacher_loss 0.0316 (0.1488) loss_zs_kd 0.0064 (0.0114) loss_oracle 0.4259 (0.5180) kd_loss 0.8595 (0.7798) acc 100.0000 (95.0312) gate/entropy 1.0135 (1.0155) gate/usage_max 0.5343 (0.5318) gate/usage_min 0.2291 (0.2284) gate/usage_std 0.1422 (0.1404) teacher/entropy 0.1224 (0.0873) teacher/usage_max 0.5791 (0.7201) teacher/usage_min 0.0069 (0.0180) teacher/usage_std 0.2405 (0.2958) nleep/row_max_mean 1539.9210 (1533.6362) nleep/row_max_std 44.7393 (46.3039) nleep/row_min_mean 1513.6362 (1510.6436) lr 1.6845e-03 eta 0:10:53
epoch [15/50] batch [120/132] time 0.148 (0.135) data 0.000 (0.003) loss 1.2869 (1.1980) teacher_loss 0.0327 (0.1458) loss_zs_kd 0.0088 (0.0116) loss_oracle 0.6401 (0.5091) kd_loss 0.9298 (0.7919) acc 100.0000 (95.0781) gate/entropy 1.0129 (1.0150) gate/usage_max 0.5351 (0.5324) gate/usage_min 0.2296 (0.2285) gate/usage_std 0.1427 (0.1408) teacher/entropy 0.1255 (0.0900) teacher/usage_max 0.4915 (0.7016) teacher/usage_min 0.0312 (0.0186) teacher/usage_std 0.2137 (0.2878) nleep/row_max_mean 1540.7365 (1533.9496) nleep/row_max_std 42.7168 (45.5029) nleep/row_min_mean 1516.7725 (1511.0566) lr 1.6845e-03 eta 0:10:25
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,467
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 91.0%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 89.7%, epoch: 5 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [16/50] batch [20/132] time 0.101 (0.124) data 0.000 (0.017) loss 1.5400 (1.3082) teacher_loss 0.1906 (0.1432) loss_zs_kd 0.0208 (0.0117) loss_oracle 0.5247 (0.5229) kd_loss 1.0766 (0.8976) acc 93.7500 (94.2188) gate/entropy 1.0121 (1.0123) gate/usage_max 0.5361 (0.5359) gate/usage_min 0.2304 (0.2301) gate/usage_std 0.1434 (0.1432) teacher/entropy 0.0879 (0.0964) teacher/usage_max 0.6082 (0.5869) teacher/usage_min 0.0336 (0.0232) teacher/usage_std 0.2352 (0.2369) nleep/row_max_mean 1541.4113 (1537.0784) nleep/row_max_std 40.3472 (42.8757) nleep/row_min_mean 1518.6898 (1513.5810) lr 1.6374e-03 eta 0:09:30
epoch [16/50] batch [40/132] time 0.082 (0.123) data 0.000 (0.008) loss 1.1423 (1.2945) teacher_loss 0.0589 (0.1354) loss_zs_kd 0.0074 (0.0123) loss_oracle 0.4231 (0.5145) kd_loss 0.8681 (0.8957) acc 100.0000 (95.0781) gate/entropy 1.0115 (1.0122) gate/usage_max 0.5368 (0.5360) gate/usage_min 0.2308 (0.2304) gate/usage_std 0.1439 (0.1433) teacher/entropy 0.1281 (0.0962) teacher/usage_max 0.5554 (0.5822) teacher/usage_min 0.0543 (0.0256) teacher/usage_std 0.2085 (0.2346) nleep/row_max_mean 1531.8357 (1535.9517) nleep/row_max_std 48.7158 (42.3918) nleep/row_min_mean 1509.6398 (1512.3589) lr 1.6374e-03 eta 0:09:21
epoch [16/50] batch [60/132] time 0.087 (0.118) data 0.000 (0.006) loss 1.2697 (1.3073) teacher_loss 0.1171 (0.1342) loss_zs_kd 0.0152 (0.0131) loss_oracle 0.4563 (0.5280) kd_loss 0.9169 (0.9026) acc 96.8750 (95.3125) gate/entropy 1.0115 (1.0121) gate/usage_max 0.5368 (0.5361) gate/usage_min 0.2316 (0.2307) gate/usage_std 0.1439 (0.1434) teacher/entropy 0.0515 (0.0955) teacher/usage_max 0.5869 (0.5756) teacher/usage_min 0.0287 (0.0243) teacher/usage_std 0.2307 (0.2349) nleep/row_max_mean 1550.0745 (1535.7835) nleep/row_max_std 42.1714 (42.9015) nleep/row_min_mean 1523.5209 (1512.0741) lr 1.6374e-03 eta 0:09:00
epoch [16/50] batch [80/132] time 0.118 (0.119) data 0.001 (0.004) loss 1.4374 (1.3021) teacher_loss 0.1978 (0.1333) loss_zs_kd 0.0307 (0.0130) loss_oracle 0.6589 (0.5323) kd_loss 0.8949 (0.8961) acc 96.8750 (95.3906) gate/entropy 1.0114 (1.0120) gate/usage_max 0.5369 (0.5362) gate/usage_min 0.2307 (0.2309) gate/usage_std 0.1440 (0.1435) teacher/entropy 0.0676 (0.0918) teacher/usage_max 0.5914 (0.5875) teacher/usage_min 0.0004 (0.0259) teacher/usage_std 0.2470 (0.2381) nleep/row_max_mean 1535.3671 (1535.6103) nleep/row_max_std 43.9295 (42.6392) nleep/row_min_mean 1508.2826 (1511.8134) lr 1.6374e-03 eta 0:08:59
epoch [16/50] batch [100/132] time 0.159 (0.123) data 0.000 (0.003) loss 1.1469 (1.3083) teacher_loss 0.0243 (0.1321) loss_zs_kd 0.0245 (0.0130) loss_oracle 0.5190 (0.5372) kd_loss 0.8509 (0.9011) acc 100.0000 (95.4062) gate/entropy 1.0116 (1.0119) gate/usage_max 0.5367 (0.5364) gate/usage_min 0.2301 (0.2308) gate/usage_std 0.1438 (0.1436) teacher/entropy 0.0333 (0.0886) teacher/usage_max 0.6873 (0.5904) teacher/usage_min 0.0753 (0.0252) teacher/usage_std 0.2589 (0.2398) nleep/row_max_mean 1522.6853 (1535.6861) nleep/row_max_std 44.5085 (41.9066) nleep/row_min_mean 1499.9255 (1511.7369) lr 1.6374e-03 eta 0:09:17
epoch [16/50] batch [120/132] time 0.154 (0.129) data 0.000 (0.003) loss 1.3361 (1.3330) teacher_loss 0.1881 (0.1329) loss_zs_kd 0.0051 (0.0129) loss_oracle 0.4805 (0.5584) kd_loss 0.9052 (0.9143) acc 96.8750 (95.4167) gate/entropy 1.0114 (1.0118) gate/usage_max 0.5368 (0.5364) gate/usage_min 0.2291 (0.2306) gate/usage_std 0.1439 (0.1436) teacher/entropy 0.0688 (0.0862) teacher/usage_max 0.5757 (0.5867) teacher/usage_min 0.0310 (0.0252) teacher/usage_std 0.2264 (0.2385) nleep/row_max_mean 1539.6697 (1535.8923) nleep/row_max_std 41.4240 (41.5745) nleep/row_min_mean 1516.4565 (1511.7270) lr 1.6374e-03 eta 0:09:39
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,485
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.4%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [17/50] batch [20/132] time 0.143 (0.162) data 0.000 (0.014) loss 1.1905 (1.4722) teacher_loss 0.1154 (0.1407) loss_zs_kd 0.0207 (0.0163) loss_oracle 0.4710 (0.6493) kd_loss 0.8293 (0.9986) acc 96.8750 (94.6875) gate/entropy 1.0122 (1.0125) gate/usage_max 0.5359 (0.5356) gate/usage_min 0.2278 (0.2285) gate/usage_std 0.1432 (0.1430) teacher/entropy 0.0661 (0.0568) teacher/usage_max 0.6683 (0.5540) teacher/usage_min 0.0037 (0.0251) teacher/usage_std 0.2713 (0.2284) nleep/row_max_mean 1537.3479 (1536.0609) nleep/row_max_std 44.0379 (43.1219) nleep/row_min_mean 1515.9287 (1510.7294) lr 1.5878e-03 eta 0:12:04
epoch [17/50] batch [40/132] time 0.135 (0.158) data 0.000 (0.007) loss 1.4394 (1.4457) teacher_loss 0.0427 (0.1225) loss_zs_kd 0.0051 (0.0149) loss_oracle 0.6808 (0.6415) kd_loss 1.0537 (0.9950) acc 96.8750 (95.3125) gate/entropy 1.0137 (1.0128) gate/usage_max 0.5340 (0.5352) gate/usage_min 0.2278 (0.2282) gate/usage_std 0.1419 (0.1428) teacher/entropy 0.0289 (0.0574) teacher/usage_max 0.5649 (0.5473) teacher/usage_min 0.0001 (0.0318) teacher/usage_std 0.2415 (0.2224) nleep/row_max_mean 1548.0918 (1535.0081) nleep/row_max_std 44.9573 (44.5662) nleep/row_min_mean 1520.6794 (1509.9811) lr 1.5878e-03 eta 0:11:41
epoch [17/50] batch [60/132] time 0.095 (0.147) data 0.000 (0.005) loss 1.3199 (1.4496) teacher_loss 0.0189 (0.1220) loss_zs_kd 0.0192 (0.0144) loss_oracle 0.6213 (0.6495) kd_loss 0.9807 (0.9957) acc 100.0000 (95.3125) gate/entropy 1.0141 (1.0131) gate/usage_max 0.5335 (0.5348) gate/usage_min 0.2269 (0.2278) gate/usage_std 0.1416 (0.1425) teacher/entropy 0.0660 (0.0627) teacher/usage_max 0.4803 (0.5440) teacher/usage_min 0.0536 (0.0366) teacher/usage_std 0.1979 (0.2189) nleep/row_max_mean 1514.9110 (1534.3264) nleep/row_max_std 53.2837 (44.9848) nleep/row_min_mean 1493.3887 (1509.3488) lr 1.5878e-03 eta 0:10:51
epoch [17/50] batch [80/132] time 0.174 (0.139) data 0.000 (0.004) loss 1.6966 (1.4410) teacher_loss 0.1291 (0.1131) loss_zs_kd 0.0129 (0.0143) loss_oracle 0.7519 (0.6454) kd_loss 1.1851 (0.9980) acc 93.7500 (95.6250) gate/entropy 1.0148 (1.0135) gate/usage_max 0.5325 (0.5343) gate/usage_min 0.2262 (0.2275) gate/usage_std 0.1410 (0.1422) teacher/entropy 0.0330 (0.0642) teacher/usage_max 0.6749 (0.5444) teacher/usage_min 0.0624 (0.0399) teacher/usage_std 0.2550 (0.2173) nleep/row_max_mean 1533.2402 (1533.3105) nleep/row_max_std 36.1575 (44.3267) nleep/row_min_mean 1506.9844 (1508.3855) lr 1.5878e-03 eta 0:10:11
epoch [17/50] batch [100/132] time 0.087 (0.133) data 0.000 (0.003) loss 1.3919 (1.4499) teacher_loss 0.0120 (0.1145) loss_zs_kd 0.0055 (0.0142) loss_oracle 0.7554 (0.6564) kd_loss 0.9994 (1.0001) acc 100.0000 (95.5938) gate/entropy 1.0160 (1.0138) gate/usage_max 0.5310 (0.5338) gate/usage_min 0.2257 (0.2272) gate/usage_std 0.1400 (0.1418) teacher/entropy 0.0645 (0.0639) teacher/usage_max 0.5362 (0.5446) teacher/usage_min 0.0137 (0.0408) teacher/usage_std 0.2287 (0.2168) nleep/row_max_mean 1526.2228 (1533.5712) nleep/row_max_std 47.9465 (44.0736) nleep/row_min_mean 1502.9829 (1508.5325) lr 1.5878e-03 eta 0:09:43
epoch [17/50] batch [120/132] time 0.084 (0.130) data 0.000 (0.003) loss 1.2870 (1.4496) teacher_loss 0.0440 (0.1124) loss_zs_kd 0.0195 (0.0150) loss_oracle 0.4906 (0.6593) kd_loss 0.9879 (1.0000) acc 100.0000 (95.6250) gate/entropy 1.0163 (1.0143) gate/usage_max 0.5304 (0.5332) gate/usage_min 0.2244 (0.2268) gate/usage_std 0.1396 (0.1415) teacher/entropy 0.1029 (0.0632) teacher/usage_max 0.5336 (0.5438) teacher/usage_min 0.0516 (0.0420) teacher/usage_std 0.2050 (0.2160) nleep/row_max_mean 1534.1312 (1533.6815) nleep/row_max_std 51.1975 (43.7615) nleep/row_min_mean 1512.1677 (1508.7793) lr 1.5878e-03 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,477
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 91.1%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [18/50] batch [20/132] time 0.096 (0.130) data 0.000 (0.017) loss 1.5322 (1.4366) teacher_loss 0.2753 (0.1227) loss_zs_kd 0.0410 (0.0186) loss_oracle 0.6484 (0.6620) kd_loss 0.9123 (0.9736) acc 90.6250 (95.9375) gate/entropy 1.0184 (1.0177) gate/usage_max 0.5277 (0.5286) gate/usage_min 0.2240 (0.2241) gate/usage_std 0.1378 (0.1384) teacher/entropy 0.0581 (0.0720) teacher/usage_max 0.5645 (0.5253) teacher/usage_min 0.0313 (0.0808) teacher/usage_std 0.2233 (0.1895) nleep/row_max_mean 1530.8760 (1529.6225) nleep/row_max_std 36.8656 (42.6857) nleep/row_min_mean 1505.7388 (1505.8210) lr 1.5358e-03 eta 0:09:22
epoch [18/50] batch [40/132] time 0.122 (0.117) data 0.000 (0.008) loss 1.3653 (1.3948) teacher_loss 0.0885 (0.1048) loss_zs_kd 0.0080 (0.0182) loss_oracle 0.6816 (0.6650) kd_loss 0.9320 (0.9484) acc 96.8750 (96.7188) gate/entropy 1.0185 (1.0180) gate/usage_max 0.5274 (0.5282) gate/usage_min 0.2229 (0.2237) gate/usage_std 0.1376 (0.1381) teacher/entropy 0.0935 (0.0775) teacher/usage_max 0.5029 (0.5270) teacher/usage_min 0.1225 (0.0808) teacher/usage_std 0.1580 (0.1907) nleep/row_max_mean 1542.6514 (1529.3059) nleep/row_max_std 43.3412 (43.2570) nleep/row_min_mean 1517.5110 (1505.3534) lr 1.5358e-03 eta 0:08:25
epoch [18/50] batch [60/132] time 0.136 (0.124) data 0.000 (0.006) loss 1.4811 (1.3784) teacher_loss 0.1898 (0.0988) loss_zs_kd 0.0363 (0.0193) loss_oracle 0.6450 (0.6615) kd_loss 0.9506 (0.9392) acc 90.6250 (96.8750) gate/entropy 1.0187 (1.0183) gate/usage_max 0.5269 (0.5277) gate/usage_min 0.2220 (0.2233) gate/usage_std 0.1374 (0.1378) teacher/entropy 0.0623 (0.0771) teacher/usage_max 0.5011 (0.5327) teacher/usage_min 0.0165 (0.0852) teacher/usage_std 0.2242 (0.1903) nleep/row_max_mean 1543.0775 (1529.6828) nleep/row_max_std 44.9569 (43.9453) nleep/row_min_mean 1516.7869 (1505.5381) lr 1.5358e-03 eta 0:08:54
epoch [18/50] batch [80/132] time 0.148 (0.131) data 0.000 (0.004) loss 1.2937 (1.3656) teacher_loss 0.0092 (0.1003) loss_zs_kd 0.0075 (0.0200) loss_oracle 0.6769 (0.6490) kd_loss 0.9423 (0.9308) acc 100.0000 (96.6406) gate/entropy 1.0199 (1.0185) gate/usage_max 0.5253 (0.5273) gate/usage_min 0.2220 (0.2230) gate/usage_std 0.1363 (0.1376) teacher/entropy 0.0856 (0.0756) teacher/usage_max 0.5119 (0.5432) teacher/usage_min 0.2015 (0.0901) teacher/usage_std 0.1310 (0.1919) nleep/row_max_mean 1527.6140 (1530.2310) nleep/row_max_std 43.3156 (44.3794) nleep/row_min_mean 1503.4714 (1505.9021) lr 1.5358e-03 eta 0:09:20
epoch [18/50] batch [100/132] time 0.166 (0.136) data 0.000 (0.003) loss 1.3426 (1.3553) teacher_loss 0.0820 (0.0937) loss_zs_kd 0.0361 (0.0189) loss_oracle 0.6163 (0.6455) kd_loss 0.9344 (0.9293) acc 93.7500 (96.9688) gate/entropy 1.0199 (1.0188) gate/usage_max 0.5251 (0.5269) gate/usage_min 0.2211 (0.2227) gate/usage_std 0.1362 (0.1373) teacher/entropy 0.0355 (0.0756) teacher/usage_max 0.5882 (0.5435) teacher/usage_min 0.1872 (0.0960) teacher/usage_std 0.1809 (0.1896) nleep/row_max_mean 1527.0747 (1531.5658) nleep/row_max_std 46.6870 (44.1296) nleep/row_min_mean 1500.1560 (1507.1867) lr 1.5358e-03 eta 0:09:40
epoch [18/50] batch [120/132] time 0.149 (0.140) data 0.000 (0.003) loss 1.5354 (1.3599) teacher_loss 0.1728 (0.0951) loss_zs_kd 0.0316 (0.0193) loss_oracle 0.6257 (0.6472) kd_loss 1.0340 (0.9316) acc 93.7500 (96.8750) gate/entropy 1.0203 (1.0191) gate/usage_max 0.5244 (0.5265) gate/usage_min 0.2205 (0.2224) gate/usage_std 0.1359 (0.1371) teacher/entropy 0.0361 (0.0750) teacher/usage_max 0.4408 (0.5415) teacher/usage_min 0.1418 (0.1009) teacher/usage_std 0.1358 (0.1866) nleep/row_max_mean 1535.5818 (1532.1243) nleep/row_max_std 41.5713 (43.8572) nleep/row_min_mean 1513.3628 (1507.6825) lr 1.5358e-03 eta 0:09:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.9%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [19/50] batch [20/132] time 0.080 (0.127) data 0.000 (0.015) loss 1.3321 (1.3857) teacher_loss 0.0129 (0.0892) loss_zs_kd 0.0139 (0.0259) loss_oracle 0.7160 (0.6460) kd_loss 0.9543 (0.9606) acc 100.0000 (96.8750) gate/entropy 1.0219 (1.0212) gate/usage_max 0.5221 (0.5231) gate/usage_min 0.2200 (0.2200) gate/usage_std 0.1344 (0.1350) teacher/entropy 0.0410 (0.0604) teacher/usage_max 0.5343 (0.5145) teacher/usage_min 0.0954 (0.1333) teacher/usage_std 0.1811 (0.1600) nleep/row_max_mean 1528.7883 (1531.7971) nleep/row_max_std 33.5838 (41.6278) nleep/row_min_mean 1504.5071 (1507.0708) lr 1.4818e-03 eta 0:08:53
epoch [19/50] batch [40/132] time 0.157 (0.116) data 0.000 (0.007) loss 1.4171 (1.4265) teacher_loss 0.0585 (0.0966) loss_zs_kd 0.0180 (0.0283) loss_oracle 0.7419 (0.6575) kd_loss 0.9786 (0.9870) acc 100.0000 (96.7969) gate/entropy 1.0225 (1.0216) gate/usage_max 0.5211 (0.5225) gate/usage_min 0.2193 (0.2197) gate/usage_std 0.1338 (0.1347) teacher/entropy 0.0364 (0.0561) teacher/usage_max 0.5270 (0.5037) teacher/usage_min 0.1914 (0.1377) teacher/usage_std 0.1418 (0.1552) nleep/row_max_mean 1522.9214 (1532.6534) nleep/row_max_std 47.7736 (41.4052) nleep/row_min_mean 1499.2343 (1507.5538) lr 1.4818e-03 eta 0:08:06
epoch [19/50] batch [60/132] time 0.085 (0.115) data 0.000 (0.005) loss 1.6096 (1.4347) teacher_loss 0.1304 (0.1010) loss_zs_kd 0.0282 (0.0279) loss_oracle 0.7348 (0.6593) kd_loss 1.0977 (0.9901) acc 96.8750 (96.8229) gate/entropy 1.0232 (1.0220) gate/usage_max 0.5199 (0.5218) gate/usage_min 0.2186 (0.2195) gate/usage_std 0.1331 (0.1342) teacher/entropy 0.0362 (0.0570) teacher/usage_max 0.5267 (0.5036) teacher/usage_min 0.1358 (0.1337) teacher/usage_std 0.1596 (0.1570) nleep/row_max_mean 1537.7764 (1532.0022) nleep/row_max_std 37.1940 (41.3304) nleep/row_min_mean 1512.4720 (1506.8269) lr 1.4818e-03 eta 0:07:59
epoch [19/50] batch [80/132] time 0.090 (0.112) data 0.000 (0.004) loss 1.4462 (1.4290) teacher_loss 0.0756 (0.0976) loss_zs_kd 0.0095 (0.0248) loss_oracle 0.8090 (0.6564) kd_loss 0.9613 (0.9908) acc 100.0000 (96.8359) gate/entropy 1.0248 (1.0225) gate/usage_max 0.5175 (0.5211) gate/usage_min 0.2184 (0.2192) gate/usage_std 0.1316 (0.1338) teacher/entropy 0.0609 (0.0543) teacher/usage_max 0.4775 (0.5155) teacher/usage_min 0.0625 (0.1235) teacher/usage_std 0.1916 (0.1660) nleep/row_max_mean 1526.7820 (1532.2044) nleep/row_max_std 39.2959 (41.0773) nleep/row_min_mean 1500.6030 (1506.8393) lr 1.4818e-03 eta 0:07:42
epoch [19/50] batch [100/132] time 0.064 (0.112) data 0.000 (0.003) loss 1.4697 (1.4213) teacher_loss 0.0158 (0.0914) loss_zs_kd 0.0207 (0.0236) loss_oracle 0.6867 (0.6521) kd_loss 1.1002 (0.9921) acc 100.0000 (97.1562) gate/entropy 1.0252 (1.0229) gate/usage_max 0.5166 (0.5203) gate/usage_min 0.2173 (0.2189) gate/usage_std 0.1311 (0.1333) teacher/entropy 0.0096 (0.0506) teacher/usage_max 0.5953 (0.5215) teacher/usage_min 0.0629 (0.1212) teacher/usage_std 0.2174 (0.1693) nleep/row_max_mean 1543.5859 (1532.0549) nleep/row_max_std 36.3102 (40.5459) nleep/row_min_mean 1516.6260 (1506.6328) lr 1.4818e-03 eta 0:07:42
epoch [19/50] batch [120/132] time 0.080 (0.108) data 0.000 (0.003) loss 1.3810 (1.4279) teacher_loss 0.0333 (0.0936) loss_zs_kd 0.0289 (0.0226) loss_oracle 0.6509 (0.6559) kd_loss 1.0078 (0.9951) acc 100.0000 (97.0052) gate/entropy 1.0264 (1.0234) gate/usage_max 0.5145 (0.5195) gate/usage_min 0.2165 (0.2185) gate/usage_std 0.1299 (0.1329) teacher/entropy 0.0311 (0.0484) teacher/usage_max 0.4547 (0.5223) teacher/usage_min 0.0956 (0.1184) teacher/usage_std 0.1681 (0.1709) nleep/row_max_mean 1543.5835 (1532.1465) nleep/row_max_std 36.2221 (40.3169) nleep/row_min_mean 1516.5251 (1506.4527) lr 1.4818e-03 eta 0:07:22
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,521
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.6%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [20/50] batch [20/132] time 0.140 (0.144) data 0.000 (0.016) loss 1.4352 (1.4533) teacher_loss 0.0088 (0.0965) loss_zs_kd 0.0078 (0.0243) loss_oracle 0.7373 (0.6568) kd_loss 1.0538 (1.0162) acc 100.0000 (96.7188) gate/entropy 1.0284 (1.0277) gate/usage_max 0.5108 (0.5121) gate/usage_min 0.2150 (0.2154) gate/usage_std 0.1278 (0.1285) teacher/entropy 0.0141 (0.0303) teacher/usage_max 0.5049 (0.5007) teacher/usage_min 0.0938 (0.0946) teacher/usage_std 0.1746 (0.1772) nleep/row_max_mean 1539.4854 (1534.6407) nleep/row_max_std 39.8914 (42.5149) nleep/row_min_mean 1506.3640 (1504.4279) lr 1.4258e-03 eta 0:09:47
epoch [20/50] batch [40/132] time 0.119 (0.137) data 0.000 (0.008) loss 1.3756 (1.4324) teacher_loss 0.0548 (0.0894) loss_zs_kd 0.0294 (0.0254) loss_oracle 0.6778 (0.6529) kd_loss 0.9672 (1.0039) acc 100.0000 (97.1875) gate/entropy 1.0291 (1.0281) gate/usage_max 0.5092 (0.5112) gate/usage_min 0.2140 (0.2148) gate/usage_std 0.1270 (0.1281) teacher/entropy 0.0422 (0.0296) teacher/usage_max 0.5125 (0.5099) teacher/usage_min 0.0253 (0.0968) teacher/usage_std 0.2188 (0.1781) nleep/row_max_mean 1538.7715 (1533.0829) nleep/row_max_std 31.1008 (41.4086) nleep/row_min_mean 1505.6102 (1502.8541) lr 1.4258e-03 eta 0:09:16
epoch [20/50] batch [60/132] time 0.149 (0.142) data 0.001 (0.005) loss 1.3805 (1.4342) teacher_loss 0.0895 (0.0929) loss_zs_kd 0.0214 (0.0243) loss_oracle 0.5081 (0.6516) kd_loss 1.0263 (1.0033) acc 96.8750 (96.8750) gate/entropy 1.0297 (1.0286) gate/usage_max 0.5078 (0.5103) gate/usage_min 0.2128 (0.2144) gate/usage_std 0.1263 (0.1276) teacher/entropy 0.0211 (0.0315) teacher/usage_max 0.4390 (0.5096) teacher/usage_min 0.1255 (0.0998) teacher/usage_std 0.1470 (0.1757) nleep/row_max_mean 1528.0693 (1532.4042) nleep/row_max_std 50.3477 (41.2180) nleep/row_min_mean 1501.6682 (1502.3863) lr 1.4258e-03 eta 0:09:30
epoch [20/50] batch [80/132] time 0.164 (0.145) data 0.000 (0.004) loss 1.3825 (1.4302) teacher_loss 0.0529 (0.0838) loss_zs_kd 0.0176 (0.0239) loss_oracle 0.6613 (0.6469) kd_loss 0.9902 (1.0109) acc 96.8750 (97.1484) gate/entropy 1.0308 (1.0291) gate/usage_max 0.5053 (0.5092) gate/usage_min 0.2118 (0.2139) gate/usage_std 0.1250 (0.1270) teacher/entropy 0.0374 (0.0306) teacher/usage_max 0.4663 (0.5059) teacher/usage_min 0.1248 (0.1048) teacher/usage_std 0.1493 (0.1720) nleep/row_max_mean 1532.8627 (1531.3470) nleep/row_max_std 38.7863 (41.2157) nleep/row_min_mean 1503.4875 (1501.6057) lr 1.4258e-03 eta 0:09:41
epoch [20/50] batch [100/132] time 0.147 (0.147) data 0.000 (0.003) loss 1.5508 (1.4327) teacher_loss 0.1345 (0.0844) loss_zs_kd 0.0272 (0.0249) loss_oracle 0.6842 (0.6440) kd_loss 1.0606 (1.0139) acc 93.7500 (96.9688) gate/entropy 1.0319 (1.0295) gate/usage_max 0.5032 (0.5082) gate/usage_min 0.2111 (0.2134) gate/usage_std 0.1239 (0.1265) teacher/entropy 0.0235 (0.0287) teacher/usage_max 0.4083 (0.5028) teacher/usage_min 0.1912 (0.1083) teacher/usage_std 0.1005 (0.1695) nleep/row_max_mean 1514.1654 (1530.4440) nleep/row_max_std 44.7092 (41.6658) nleep/row_min_mean 1486.2994 (1500.9117) lr 1.4258e-03 eta 0:09:45
epoch [20/50] batch [120/132] time 0.170 (0.149) data 0.000 (0.003) loss 1.3782 (1.4321) teacher_loss 0.0910 (0.0822) loss_zs_kd 0.0143 (0.0253) loss_oracle 0.7316 (0.6494) kd_loss 0.9142 (1.0126) acc 96.8750 (97.1094) gate/entropy 1.0329 (1.0300) gate/usage_max 0.5008 (0.5072) gate/usage_min 0.2102 (0.2130) gate/usage_std 0.1227 (0.1260) teacher/entropy 0.0120 (0.0276) teacher/usage_max 0.5908 (0.5020) teacher/usage_min 0.0312 (0.1086) teacher/usage_std 0.2306 (0.1690) nleep/row_max_mean 1518.9581 (1530.1779) nleep/row_max_std 42.2404 (41.5872) nleep/row_min_mean 1487.5994 (1500.6287) lr 1.4258e-03 eta 0:09:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,528
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.8%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.3%, epoch: 4 *******
epoch [21/50] batch [20/132] time 0.157 (0.135) data 0.000 (0.016) loss 1.3400 (1.4152) teacher_loss 0.0275 (0.0637) loss_zs_kd 0.0340 (0.0229) loss_oracle 0.6946 (0.6679) kd_loss 0.9482 (1.0061) acc 100.0000 (97.8125) gate/entropy 1.0343 (1.0337) gate/usage_max 0.4972 (0.4985) gate/usage_min 0.2085 (0.2089) gate/usage_std 0.1210 (0.1217) teacher/entropy 0.0081 (0.0255) teacher/usage_max 0.5295 (0.5099) teacher/usage_min 0.0313 (0.1081) teacher/usage_std 0.2168 (0.1712) nleep/row_max_mean 1532.3894 (1529.1989) nleep/row_max_std 52.5844 (43.1356) nleep/row_min_mean 1498.7183 (1499.2432) lr 1.3681e-03 eta 0:08:51
epoch [21/50] batch [40/132] time 0.068 (0.126) data 0.000 (0.008) loss 1.3415 (1.4179) teacher_loss 0.0794 (0.0705) loss_zs_kd 0.0168 (0.0230) loss_oracle 0.5107 (0.6620) kd_loss 0.9983 (1.0049) acc 96.8750 (97.4219) gate/entropy 1.0348 (1.0342) gate/usage_max 0.4953 (0.4973) gate/usage_min 0.2073 (0.2084) gate/usage_std 0.1203 (0.1212) teacher/entropy 0.0179 (0.0228) teacher/usage_max 0.4737 (0.5063) teacher/usage_min 0.1244 (0.1127) teacher/usage_std 0.1506 (0.1673) nleep/row_max_mean 1533.9414 (1528.5020) nleep/row_max_std 41.0396 (41.3498) nleep/row_min_mean 1504.6014 (1498.8592) lr 1.3681e-03 eta 0:08:12
epoch [21/50] batch [60/132] time 0.083 (0.126) data 0.000 (0.005) loss 1.2235 (1.4097) teacher_loss 0.0197 (0.0734) loss_zs_kd 0.0124 (0.0232) loss_oracle 0.5037 (0.6439) kd_loss 0.9457 (1.0028) acc 100.0000 (97.2917) gate/entropy 1.0355 (1.0345) gate/usage_max 0.4931 (0.4962) gate/usage_min 0.2062 (0.2079) gate/usage_std 0.1194 (0.1207) teacher/entropy 0.0169 (0.0233) teacher/usage_max 0.5285 (0.5129) teacher/usage_min 0.0614 (0.1034) teacher/usage_std 0.1983 (0.1744) nleep/row_max_mean 1518.8799 (1528.8037) nleep/row_max_std 51.8585 (41.7538) nleep/row_min_mean 1489.9418 (1498.9249) lr 1.3681e-03 eta 0:08:10
epoch [21/50] batch [80/132] time 0.146 (0.117) data 0.000 (0.004) loss 1.3845 (1.4091) teacher_loss 0.0607 (0.0722) loss_zs_kd 0.0329 (0.0223) loss_oracle 0.6218 (0.6448) kd_loss 0.9965 (1.0033) acc 96.8750 (97.3438) gate/entropy 1.0362 (1.0349) gate/usage_max 0.4907 (0.4951) gate/usage_min 0.2048 (0.2073) gate/usage_std 0.1185 (0.1202) teacher/entropy 0.0211 (0.0246) teacher/usage_max 0.4630 (0.5097) teacher/usage_min 0.1240 (0.1040) teacher/usage_std 0.1494 (0.1731) nleep/row_max_mean 1522.1226 (1528.2754) nleep/row_max_std 52.9245 (42.4146) nleep/row_min_mean 1491.1819 (1498.0382) lr 1.3681e-03 eta 0:07:35
epoch [21/50] batch [100/132] time 0.066 (0.120) data 0.000 (0.003) loss 1.4573 (1.4068) teacher_loss 0.1293 (0.0708) loss_zs_kd 0.0353 (0.0225) loss_oracle 0.5976 (0.6477) kd_loss 1.0116 (1.0009) acc 93.7500 (97.3438) gate/entropy 1.0368 (1.0353) gate/usage_max 0.4882 (0.4939) gate/usage_min 0.2035 (0.2067) gate/usage_std 0.1176 (0.1197) teacher/entropy 0.0145 (0.0273) teacher/usage_max 0.4385 (0.5091) teacher/usage_min 0.1233 (0.1070) teacher/usage_std 0.1485 (0.1721) nleep/row_max_mean 1534.4514 (1527.9913) nleep/row_max_std 44.8394 (42.2562) nleep/row_min_mean 1505.4045 (1497.6130) lr 1.3681e-03 eta 0:07:41
epoch [21/50] batch [120/132] time 0.080 (0.117) data 0.000 (0.003) loss 1.2777 (1.4058) teacher_loss 0.0275 (0.0742) loss_zs_kd 0.0104 (0.0226) loss_oracle 0.6165 (0.6508) kd_loss 0.9367 (0.9949) acc 100.0000 (97.3177) gate/entropy 1.0377 (1.0356) gate/usage_max 0.4855 (0.4927) gate/usage_min 0.2028 (0.2061) gate/usage_std 0.1164 (0.1192) teacher/entropy 0.0436 (0.0285) teacher/usage_max 0.4932 (0.5111) teacher/usage_min 0.0785 (0.1045) teacher/usage_std 0.1821 (0.1745) nleep/row_max_mean 1522.6663 (1527.3149) nleep/row_max_std 50.0214 (42.6839) nleep/row_min_mean 1491.7411 (1496.6961) lr 1.3681e-03 eta 0:07:29
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,560
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     90.6%, epoch: 21 *******
epoch [22/50] batch [20/132] time 0.075 (0.149) data 0.000 (0.016) loss 1.4333 (1.4000) teacher_loss 0.0616 (0.0866) loss_zs_kd 0.0212 (0.0266) loss_oracle 0.6812 (0.6326) kd_loss 1.0205 (0.9837) acc 96.8750 (97.1875) gate/entropy 1.0385 (1.0383) gate/usage_max 0.4815 (0.4826) gate/usage_min 0.2007 (0.2012) gate/usage_std 0.1152 (0.1155) teacher/entropy 0.0001 (0.0314) teacher/usage_max 0.5000 (0.5073) teacher/usage_min 0.0938 (0.0928) teacher/usage_std 0.1737 (0.1781) nleep/row_max_mean 1535.9757 (1526.5498) nleep/row_max_std 50.6806 (45.1999) nleep/row_min_mean 1500.8920 (1493.6632) lr 1.3090e-03 eta 0:09:28
epoch [22/50] batch [40/132] time 0.096 (0.130) data 0.000 (0.008) loss 1.5235 (1.3958) teacher_loss 0.1125 (0.0807) loss_zs_kd 0.0251 (0.0239) loss_oracle 0.6693 (0.6358) kd_loss 1.0638 (0.9852) acc 96.8750 (97.4219) gate/entropy 1.0387 (1.0385) gate/usage_max 0.4794 (0.4815) gate/usage_min 0.1993 (0.2006) gate/usage_std 0.1147 (0.1152) teacher/entropy 0.0448 (0.0269) teacher/usage_max 0.4051 (0.5131) teacher/usage_min 0.2400 (0.0971) teacher/usage_std 0.0691 (0.1777) nleep/row_max_mean 1521.9053 (1526.4045) nleep/row_max_std 42.3285 (43.1539) nleep/row_min_mean 1490.9200 (1493.8223) lr 1.3090e-03 eta 0:08:14
epoch [22/50] batch [60/132] time 0.056 (0.118) data 0.001 (0.005) loss 1.4282 (1.4052) teacher_loss 0.0119 (0.0782) loss_zs_kd 0.0132 (0.0248) loss_oracle 0.7754 (0.6447) kd_loss 1.0220 (0.9923) acc 100.0000 (97.2917) gate/entropy 1.0392 (1.0386) gate/usage_max 0.4769 (0.4804) gate/usage_min 0.1983 (0.2000) gate/usage_std 0.1139 (0.1149) teacher/entropy 0.0018 (0.0231) teacher/usage_max 0.5941 (0.5137) teacher/usage_min 0.0625 (0.1048) teacher/usage_std 0.2171 (0.1740) nleep/row_max_mean 1538.8225 (1527.3195) nleep/row_max_std 35.4922 (42.0876) nleep/row_min_mean 1505.8572 (1494.9140) lr 1.3090e-03 eta 0:07:24
epoch [22/50] batch [80/132] time 0.091 (0.109) data 0.000 (0.004) loss 1.2709 (1.4018) teacher_loss 0.0237 (0.0736) loss_zs_kd 0.0096 (0.0246) loss_oracle 0.6105 (0.6506) kd_loss 0.9371 (0.9906) acc 100.0000 (97.4219) gate/entropy 1.0393 (1.0388) gate/usage_max 0.4749 (0.4792) gate/usage_min 0.1971 (0.1994) gate/usage_std 0.1135 (0.1146) teacher/entropy 0.0001 (0.0206) teacher/usage_max 0.5625 (0.5110) teacher/usage_min 0.0625 (0.1056) teacher/usage_std 0.2062 (0.1731) nleep/row_max_mean 1529.1494 (1527.8263) nleep/row_max_std 46.4243 (41.6935) nleep/row_min_mean 1497.0588 (1495.3488) lr 1.3090e-03 eta 0:06:48
epoch [22/50] batch [100/132] time 0.078 (0.105) data 0.000 (0.003) loss 1.3092 (1.4033) teacher_loss 0.0227 (0.0753) loss_zs_kd 0.0220 (0.0252) loss_oracle 0.6458 (0.6517) kd_loss 0.9526 (0.9896) acc 100.0000 (97.1875) gate/entropy 1.0397 (1.0389) gate/usage_max 0.4732 (0.4782) gate/usage_min 0.1966 (0.1989) gate/usage_std 0.1129 (0.1143) teacher/entropy 0.0031 (0.0195) teacher/usage_max 0.4997 (0.5099) teacher/usage_min 0.0317 (0.1085) teacher/usage_std 0.2137 (0.1714) nleep/row_max_mean 1538.1182 (1528.3108) nleep/row_max_std 32.7762 (41.3244) nleep/row_min_mean 1504.3593 (1495.9121) lr 1.3090e-03 eta 0:06:31
epoch [22/50] batch [120/132] time 0.142 (0.109) data 0.000 (0.003) loss 1.4259 (1.4069) teacher_loss 0.0454 (0.0746) loss_zs_kd 0.0141 (0.0253) loss_oracle 0.7245 (0.6555) kd_loss 1.0111 (0.9919) acc 96.8750 (97.2396) gate/entropy 1.0401 (1.0391) gate/usage_max 0.4709 (0.4772) gate/usage_min 0.1957 (0.1984) gate/usage_std 0.1124 (0.1141) teacher/entropy 0.0031 (0.0183) teacher/usage_max 0.4380 (0.5104) teacher/usage_min 0.1249 (0.1092) teacher/usage_std 0.1474 (0.1707) nleep/row_max_mean 1517.8809 (1528.2936) nleep/row_max_std 38.4188 (40.6203) nleep/row_min_mean 1486.5029 (1496.0371) lr 1.3090e-03 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,584
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 92.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.2%, epoch: 22 *******
epoch [23/50] batch [20/132] time 0.144 (0.181) data 0.000 (0.019) loss 1.1845 (1.3867) teacher_loss 0.0096 (0.0696) loss_zs_kd 0.0126 (0.0224) loss_oracle 0.5663 (0.6315) kd_loss 0.8855 (0.9902) acc 100.0000 (97.5000) gate/entropy 1.0400 (1.0399) gate/usage_max 0.4682 (0.4690) gate/usage_min 0.1940 (0.1942) gate/usage_std 0.1120 (0.1122) teacher/entropy 0.0199 (0.0114) teacher/usage_max 0.7128 (0.5193) teacher/usage_min 0.0938 (0.1155) teacher/usage_std 0.2714 (0.1733) nleep/row_max_mean 1522.8901 (1526.4300) nleep/row_max_std 40.4058 (37.5455) nleep/row_min_mean 1493.5962 (1495.4941) lr 1.2487e-03 eta 0:11:05
epoch [23/50] batch [40/132] time 0.168 (0.174) data 0.000 (0.009) loss 1.4256 (1.3827) teacher_loss 0.0405 (0.0710) loss_zs_kd 0.0215 (0.0228) loss_oracle 0.6902 (0.6321) kd_loss 1.0292 (0.9843) acc 100.0000 (97.5781) gate/entropy 1.0400 (1.0400) gate/usage_max 0.4669 (0.4683) gate/usage_min 0.1931 (0.1939) gate/usage_std 0.1119 (0.1121) teacher/entropy 0.0043 (0.0136) teacher/usage_max 0.5946 (0.5215) teacher/usage_min 0.0938 (0.1146) teacher/usage_std 0.2050 (0.1734) nleep/row_max_mean 1518.2251 (1523.8234) nleep/row_max_std 45.0813 (39.6238) nleep/row_min_mean 1487.0708 (1493.2869) lr 1.2487e-03 eta 0:10:37
epoch [23/50] batch [60/132] time 0.160 (0.170) data 0.000 (0.006) loss 1.3326 (1.3719) teacher_loss 0.0495 (0.0669) loss_zs_kd 0.0232 (0.0214) loss_oracle 0.6019 (0.6288) kd_loss 0.9705 (0.9799) acc 100.0000 (97.5521) gate/entropy 1.0399 (1.0400) gate/usage_max 0.4653 (0.4675) gate/usage_min 0.1921 (0.1935) gate/usage_std 0.1117 (0.1119) teacher/entropy 0.0012 (0.0144) teacher/usage_max 0.5623 (0.5288) teacher/usage_min 0.1250 (0.1082) teacher/usage_std 0.1791 (0.1781) nleep/row_max_mean 1526.0024 (1523.7591) nleep/row_max_std 45.4037 (40.3990) nleep/row_min_mean 1497.0531 (1493.6464) lr 1.2487e-03 eta 0:10:19
epoch [23/50] batch [80/132] time 0.094 (0.165) data 0.000 (0.005) loss 1.2655 (1.3791) teacher_loss 0.0375 (0.0684) loss_zs_kd 0.0177 (0.0214) loss_oracle 0.5864 (0.6322) kd_loss 0.9259 (0.9839) acc 96.8750 (97.4609) gate/entropy 1.0403 (1.0400) gate/usage_max 0.4638 (0.4668) gate/usage_min 0.1920 (0.1931) gate/usage_std 0.1112 (0.1118) teacher/entropy 0.0194 (0.0129) teacher/usage_max 0.5053 (0.5202) teacher/usage_min 0.0313 (0.1092) teacher/usage_std 0.2143 (0.1746) nleep/row_max_mean 1514.2346 (1524.4192) nleep/row_max_std 40.8869 (39.9615) nleep/row_min_mean 1487.3202 (1494.4732) lr 1.2487e-03 eta 0:09:57
epoch [23/50] batch [100/132] time 0.113 (0.154) data 0.000 (0.004) loss 1.4456 (1.3825) teacher_loss 0.0586 (0.0681) loss_zs_kd 0.0102 (0.0217) loss_oracle 0.7349 (0.6328) kd_loss 1.0145 (0.9872) acc 96.8750 (97.4375) gate/entropy 1.0397 (1.0400) gate/usage_max 0.4622 (0.4660) gate/usage_min 0.1902 (0.1927) gate/usage_std 0.1115 (0.1117) teacher/entropy 0.0024 (0.0131) teacher/usage_max 0.4692 (0.5151) teacher/usage_min 0.1250 (0.1127) teacher/usage_std 0.1496 (0.1711) nleep/row_max_mean 1546.1155 (1524.6119) nleep/row_max_std 40.7111 (40.2721) nleep/row_min_mean 1515.6953 (1494.7937) lr 1.2487e-03 eta 0:09:13
epoch [23/50] batch [120/132] time 0.125 (0.148) data 0.000 (0.003) loss 1.3762 (1.3765) teacher_loss 0.0440 (0.0658) loss_zs_kd 0.0325 (0.0220) loss_oracle 0.6241 (0.6300) kd_loss 1.0039 (0.9847) acc 96.8750 (97.5521) gate/entropy 1.0399 (1.0400) gate/usage_max 0.4607 (0.4652) gate/usage_min 0.1899 (0.1923) gate/usage_std 0.1111 (0.1116) teacher/entropy 0.0170 (0.0131) teacher/usage_max 0.5045 (0.5134) teacher/usage_min 0.1203 (0.1109) teacher/usage_std 0.1596 (0.1715) nleep/row_max_mean 1526.4861 (1524.7648) nleep/row_max_std 43.0208 (40.4881) nleep/row_min_mean 1496.7284 (1494.8418) lr 1.2487e-03 eta 0:08:47
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,602
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 93.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [24/50] batch [20/132] time 0.141 (0.143) data 0.000 (0.019) loss 1.4376 (1.3892) teacher_loss 0.1443 (0.0585) loss_zs_kd 0.0188 (0.0231) loss_oracle 0.7040 (0.6658) kd_loss 0.9319 (0.9862) acc 93.7500 (98.1250) gate/entropy 1.0399 (1.0399) gate/usage_max 0.4594 (0.4597) gate/usage_min 0.1893 (0.1895) gate/usage_std 0.1110 (0.1110) teacher/entropy 0.0467 (0.0146) teacher/usage_max 0.4664 (0.5154) teacher/usage_min 0.0937 (0.1362) teacher/usage_std 0.1698 (0.1640) nleep/row_max_mean 1527.4861 (1517.0777) nleep/row_max_std 40.2468 (44.0188) nleep/row_min_mean 1496.1541 (1488.6316) lr 1.1874e-03 eta 0:08:25
epoch [24/50] batch [40/132] time 0.082 (0.128) data 0.000 (0.010) loss 1.4556 (1.4069) teacher_loss 0.1679 (0.0749) loss_zs_kd 0.0386 (0.0239) loss_oracle 0.6438 (0.6711) kd_loss 0.9465 (0.9844) acc 90.6250 (97.2656) gate/entropy 1.0399 (1.0399) gate/usage_max 0.4582 (0.4593) gate/usage_min 0.1887 (0.1892) gate/usage_std 0.1109 (0.1110) teacher/entropy 0.0207 (0.0140) teacher/usage_max 0.5835 (0.5201) teacher/usage_min 0.1250 (0.1268) teacher/usage_std 0.1895 (0.1676) nleep/row_max_mean 1515.5588 (1518.9159) nleep/row_max_std 41.4129 (40.4806) nleep/row_min_mean 1489.1713 (1491.0659) lr 1.1874e-03 eta 0:07:32
epoch [24/50] batch [60/132] time 0.090 (0.118) data 0.001 (0.007) loss 1.3913 (1.4029) teacher_loss 0.0646 (0.0709) loss_zs_kd 0.0266 (0.0235) loss_oracle 0.6469 (0.6705) kd_loss 0.9901 (0.9850) acc 96.8750 (97.5521) gate/entropy 1.0397 (1.0399) gate/usage_max 0.4568 (0.4587) gate/usage_min 0.1879 (0.1889) gate/usage_std 0.1109 (0.1110) teacher/entropy 0.0016 (0.0141) teacher/usage_max 0.5002 (0.5145) teacher/usage_min 0.0938 (0.1232) teacher/usage_std 0.1737 (0.1673) nleep/row_max_mean 1526.3840 (1519.1412) nleep/row_max_std 36.9728 (39.5631) nleep/row_min_mean 1497.8528 (1491.5432) lr 1.1874e-03 eta 0:06:52
epoch [24/50] batch [80/132] time 0.151 (0.121) data 0.000 (0.005) loss 1.4154 (1.4052) teacher_loss 0.0979 (0.0739) loss_zs_kd 0.0149 (0.0232) loss_oracle 0.6214 (0.6656) kd_loss 0.9994 (0.9869) acc 96.8750 (97.5781) gate/entropy 1.0398 (1.0398) gate/usage_max 0.4553 (0.4580) gate/usage_min 0.1875 (0.1886) gate/usage_std 0.1106 (0.1109) teacher/entropy 0.0111 (0.0162) teacher/usage_max 0.5625 (0.5125) teacher/usage_min 0.0973 (0.1239) teacher/usage_std 0.1900 (0.1656) nleep/row_max_mean 1531.8022 (1520.4262) nleep/row_max_std 32.5494 (38.7927) nleep/row_min_mean 1503.5791 (1492.9707) lr 1.1874e-03 eta 0:07:02
epoch [24/50] batch [100/132] time 0.159 (0.127) data 0.000 (0.004) loss 1.4105 (1.4022) teacher_loss 0.0641 (0.0731) loss_zs_kd 0.0315 (0.0236) loss_oracle 0.6071 (0.6615) kd_loss 1.0270 (0.9865) acc 93.7500 (97.5625) gate/entropy 1.0394 (1.0398) gate/usage_max 0.4543 (0.4574) gate/usage_min 0.1865 (0.1883) gate/usage_std 0.1108 (0.1109) teacher/entropy 0.0047 (0.0172) teacher/usage_max 0.4376 (0.5113) teacher/usage_min 0.1572 (0.1246) teacher/usage_std 0.1253 (0.1649) nleep/row_max_mean 1517.4648 (1521.2288) nleep/row_max_std 40.0279 (38.9668) nleep/row_min_mean 1491.5076 (1493.8238) lr 1.1874e-03 eta 0:07:19
epoch [24/50] batch [120/132] time 0.133 (0.130) data 0.000 (0.003) loss 1.3249 (1.3972) teacher_loss 0.0032 (0.0747) loss_zs_kd 0.0200 (0.0234) loss_oracle 0.6364 (0.6509) kd_loss 0.9936 (0.9854) acc 100.0000 (97.3958) gate/entropy 1.0396 (1.0397) gate/usage_max 0.4537 (0.4568) gate/usage_min 0.1866 (0.1880) gate/usage_std 0.1106 (0.1109) teacher/entropy 0.0396 (0.0174) teacher/usage_max 0.4223 (0.5103) teacher/usage_min 0.1666 (0.1260) teacher/usage_std 0.1180 (0.1640) nleep/row_max_mean 1502.7825 (1522.0030) nleep/row_max_std 48.3282 (38.8758) nleep/row_min_mean 1478.7679 (1494.6150) lr 1.1874e-03 eta 0:07:26
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,575
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 92.7%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [25/50] batch [20/132] time 0.161 (0.177) data 0.000 (0.013) loss 1.2709 (1.4130) teacher_loss 0.0345 (0.0918) loss_zs_kd 0.0115 (0.0240) loss_oracle 0.6067 (0.6404) kd_loss 0.9273 (0.9890) acc 96.8750 (96.7188) gate/entropy 1.0393 (1.0393) gate/usage_max 0.4518 (0.4524) gate/usage_min 0.1855 (0.1857) gate/usage_std 0.1107 (0.1107) teacher/entropy 0.0213 (0.0200) teacher/usage_max 0.5836 (0.5272) teacher/usage_min 0.0939 (0.1276) teacher/usage_std 0.2001 (0.1679) nleep/row_max_mean 1527.0508 (1524.2288) nleep/row_max_std 51.4379 (41.3347) nleep/row_min_mean 1497.7130 (1496.5560) lr 1.1253e-03 eta 0:10:02
epoch [25/50] batch [40/132] time 0.149 (0.168) data 0.000 (0.007) loss 1.3534 (1.3903) teacher_loss 0.0861 (0.0863) loss_zs_kd 0.0026 (0.0221) loss_oracle 0.6485 (0.6314) kd_loss 0.9418 (0.9773) acc 96.8750 (97.0312) gate/entropy 1.0390 (1.0392) gate/usage_max 0.4508 (0.4518) gate/usage_min 0.1846 (0.1854) gate/usage_std 0.1109 (0.1108) teacher/entropy 0.0084 (0.0211) teacher/usage_max 0.5931 (0.5163) teacher/usage_min 0.0313 (0.1193) teacher/usage_std 0.2313 (0.1683) nleep/row_max_mean 1533.4989 (1524.6740) nleep/row_max_std 47.3543 (41.5881) nleep/row_min_mean 1503.4648 (1496.8194) lr 1.1253e-03 eta 0:09:28
epoch [25/50] batch [60/132] time 0.095 (0.151) data 0.001 (0.004) loss 1.4711 (1.3910) teacher_loss 0.1633 (0.0837) loss_zs_kd 0.0290 (0.0243) loss_oracle 0.6388 (0.6314) kd_loss 0.9739 (0.9795) acc 93.7500 (96.9792) gate/entropy 1.0391 (1.0392) gate/usage_max 0.4500 (0.4514) gate/usage_min 0.1845 (0.1851) gate/usage_std 0.1107 (0.1108) teacher/entropy 0.0075 (0.0197) teacher/usage_max 0.4670 (0.5080) teacher/usage_min 0.0954 (0.1235) teacher/usage_std 0.1687 (0.1648) nleep/row_max_mean 1534.7098 (1524.5467) nleep/row_max_std 31.0151 (41.1841) nleep/row_min_mean 1504.7466 (1496.6898) lr 1.1253e-03 eta 0:08:29
epoch [25/50] batch [80/132] time 0.162 (0.144) data 0.000 (0.003) loss 1.3443 (1.3792) teacher_loss 0.0654 (0.0751) loss_zs_kd 0.0340 (0.0237) loss_oracle 0.6257 (0.6330) kd_loss 0.9491 (0.9758) acc 96.8750 (97.2266) gate/entropy 1.0386 (1.0391) gate/usage_max 0.4492 (0.4509) gate/usage_min 0.1836 (0.1849) gate/usage_std 0.1110 (0.1108) teacher/entropy 0.0481 (0.0204) teacher/usage_max 0.4726 (0.5059) teacher/usage_min 0.1302 (0.1209) teacher/usage_std 0.1469 (0.1653) nleep/row_max_mean 1516.7393 (1523.3957) nleep/row_max_std 39.2282 (40.6799) nleep/row_min_mean 1490.5044 (1495.4173) lr 1.1253e-03 eta 0:08:04
epoch [25/50] batch [100/132] time 0.088 (0.140) data 0.000 (0.003) loss 1.2481 (1.3738) teacher_loss 0.0174 (0.0736) loss_zs_kd 0.0144 (0.0233) loss_oracle 0.6559 (0.6336) kd_loss 0.8955 (0.9718) acc 100.0000 (97.3125) gate/entropy 1.0389 (1.0390) gate/usage_max 0.4482 (0.4505) gate/usage_min 0.1838 (0.1847) gate/usage_std 0.1107 (0.1108) teacher/entropy 0.0592 (0.0224) teacher/usage_max 0.5592 (0.5130) teacher/usage_min 0.0937 (0.1181) teacher/usage_std 0.1903 (0.1692) nleep/row_max_mean 1516.3120 (1524.2218) nleep/row_max_std 46.7108 (40.4220) nleep/row_min_mean 1485.4263 (1496.0081) lr 1.1253e-03 eta 0:07:47
epoch [25/50] batch [120/132] time 0.169 (0.137) data 0.000 (0.002) loss 1.2565 (1.3703) teacher_loss 0.0496 (0.0707) loss_zs_kd 0.0381 (0.0225) loss_oracle 0.5448 (0.6327) kd_loss 0.9154 (0.9720) acc 100.0000 (97.3958) gate/entropy 1.0384 (1.0390) gate/usage_max 0.4469 (0.4500) gate/usage_min 0.1827 (0.1844) gate/usage_std 0.1110 (0.1108) teacher/entropy 0.0096 (0.0228) teacher/usage_max 0.5959 (0.5144) teacher/usage_min 0.0625 (0.1187) teacher/usage_std 0.2178 (0.1693) nleep/row_max_mean 1528.0879 (1524.4428) nleep/row_max_std 40.6438 (40.9106) nleep/row_min_mean 1498.5278 (1496.2586) lr 1.1253e-03 eta 0:07:33
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,587
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 93.0%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [26/50] batch [20/132] time 0.092 (0.127) data 0.000 (0.016) loss 1.2861 (1.3385) teacher_loss 0.0852 (0.0633) loss_zs_kd 0.0243 (0.0256) loss_oracle 0.6271 (0.6303) kd_loss 0.8752 (0.9472) acc 96.8750 (97.9688) gate/entropy 1.0379 (1.0382) gate/usage_max 0.4456 (0.4459) gate/usage_min 0.1817 (0.1821) gate/usage_std 0.1112 (0.1111) teacher/entropy 0.0687 (0.0344) teacher/usage_max 0.4962 (0.5104) teacher/usage_min 0.0626 (0.1078) teacher/usage_std 0.1927 (0.1722) nleep/row_max_mean 1526.6917 (1526.7899) nleep/row_max_std 51.0686 (45.2493) nleep/row_min_mean 1496.5769 (1497.3432) lr 1.0628e-03 eta 0:06:55
epoch [26/50] batch [40/132] time 0.163 (0.141) data 0.000 (0.008) loss 1.2885 (1.3367) teacher_loss 0.0512 (0.0709) loss_zs_kd 0.0207 (0.0273) loss_oracle 0.5368 (0.6096) kd_loss 0.9585 (0.9473) acc 100.0000 (97.9688) gate/entropy 1.0378 (1.0381) gate/usage_max 0.4450 (0.4456) gate/usage_min 0.1814 (0.1819) gate/usage_std 0.1113 (0.1112) teacher/entropy 0.0151 (0.0348) teacher/usage_max 0.5931 (0.5177) teacher/usage_min 0.1276 (0.1097) teacher/usage_std 0.1939 (0.1736) nleep/row_max_mean 1528.8816 (1524.9774) nleep/row_max_std 51.8578 (45.0716) nleep/row_min_mean 1500.9492 (1496.0137) lr 1.0628e-03 eta 0:07:40
epoch [26/50] batch [60/132] time 0.139 (0.146) data 0.000 (0.006) loss 1.4427 (1.3402) teacher_loss 0.0285 (0.0693) loss_zs_kd 0.0347 (0.0266) loss_oracle 0.5917 (0.6048) kd_loss 1.1010 (0.9552) acc 100.0000 (97.9167) gate/entropy 1.0377 (1.0380) gate/usage_max 0.4445 (0.4453) gate/usage_min 0.1812 (0.1818) gate/usage_std 0.1114 (0.1112) teacher/entropy 0.0267 (0.0338) teacher/usage_max 0.3618 (0.5179) teacher/usage_min 0.2825 (0.1184) teacher/usage_std 0.0360 (0.1694) nleep/row_max_mean 1520.0190 (1525.5297) nleep/row_max_std 36.4275 (43.9136) nleep/row_min_mean 1493.3210 (1496.3325) lr 1.0628e-03 eta 0:07:52
epoch [26/50] batch [80/132] time 0.150 (0.145) data 0.000 (0.004) loss 1.3161 (1.3289) teacher_loss 0.0759 (0.0693) loss_zs_kd 0.0346 (0.0249) loss_oracle 0.5694 (0.5929) kd_loss 0.9382 (0.9507) acc 96.8750 (97.9688) gate/entropy 1.0377 (1.0380) gate/usage_max 0.4440 (0.4451) gate/usage_min 0.1810 (0.1816) gate/usage_std 0.1113 (0.1112) teacher/entropy 0.0578 (0.0329) teacher/usage_max 0.4675 (0.5168) teacher/usage_min 0.1294 (0.1119) teacher/usage_std 0.1466 (0.1722) nleep/row_max_mean 1514.9827 (1525.8154) nleep/row_max_std 39.5232 (43.4665) nleep/row_min_mean 1489.3966 (1496.4831) lr 1.0628e-03 eta 0:07:46
epoch [26/50] batch [100/132] time 0.147 (0.144) data 0.000 (0.003) loss 1.3356 (1.3308) teacher_loss 0.1126 (0.0720) loss_zs_kd 0.0085 (0.0245) loss_oracle 0.5382 (0.5890) kd_loss 0.9496 (0.9520) acc 90.6250 (97.7812) gate/entropy 1.0376 (1.0379) gate/usage_max 0.4436 (0.4448) gate/usage_min 0.1809 (0.1815) gate/usage_std 0.1113 (0.1112) teacher/entropy 0.0535 (0.0337) teacher/usage_max 0.4648 (0.5141) teacher/usage_min 0.1249 (0.1151) teacher/usage_std 0.1491 (0.1698) nleep/row_max_mean 1515.0005 (1524.9312) nleep/row_max_std 49.3703 (42.9820) nleep/row_min_mean 1487.9692 (1495.9141) lr 1.0628e-03 eta 0:07:41
epoch [26/50] batch [120/132] time 0.135 (0.145) data 0.000 (0.003) loss 1.3884 (1.3280) teacher_loss 0.0519 (0.0700) loss_zs_kd 0.0140 (0.0237) loss_oracle 0.5929 (0.5897) kd_loss 1.0331 (0.9513) acc 96.8750 (97.8385) gate/entropy 1.0373 (1.0378) gate/usage_max 0.4433 (0.4446) gate/usage_min 0.1804 (0.1813) gate/usage_std 0.1115 (0.1113) teacher/entropy 0.0103 (0.0341) teacher/usage_max 0.4379 (0.5136) teacher/usage_min 0.1875 (0.1153) teacher/usage_std 0.1063 (0.1694) nleep/row_max_mean 1544.6764 (1525.3004) nleep/row_max_std 27.8168 (42.1725) nleep/row_min_mean 1516.4460 (1496.5310) lr 1.0628e-03 eta 0:07:40
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,602
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 93.1%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [27/50] batch [20/132] time 0.088 (0.111) data 0.000 (0.014) loss 1.3133 (1.3370) teacher_loss 0.0236 (0.0573) loss_zs_kd 0.0137 (0.0229) loss_oracle 0.6525 (0.6193) kd_loss 0.9566 (0.9586) acc 100.0000 (97.8125) gate/entropy 1.0372 (1.0372) gate/usage_max 0.4429 (0.4431) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1116 (0.1116) teacher/entropy 0.0372 (0.0298) teacher/usage_max 0.4505 (0.5183) teacher/usage_min 0.1194 (0.1256) teacher/usage_std 0.1515 (0.1667) nleep/row_max_mean 1530.5674 (1528.1376) nleep/row_max_std 38.2811 (39.3808) nleep/row_min_mean 1504.7347 (1501.3191) lr 1.0000e-03 eta 0:05:48
epoch [27/50] batch [40/132] time 0.073 (0.105) data 0.000 (0.007) loss 1.4229 (1.3515) teacher_loss 0.0480 (0.0571) loss_zs_kd 0.0276 (0.0251) loss_oracle 0.6273 (0.6275) kd_loss 1.0474 (0.9681) acc 96.8750 (97.7344) gate/entropy 1.0372 (1.0372) gate/usage_max 0.4427 (0.4429) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1117 (0.1116) teacher/entropy 0.0225 (0.0278) teacher/usage_max 0.4129 (0.5126) teacher/usage_min 0.2189 (0.1334) teacher/usage_std 0.0830 (0.1602) nleep/row_max_mean 1530.4182 (1529.3306) nleep/row_max_std 34.8862 (38.3304) nleep/row_min_mean 1500.7036 (1502.0022) lr 1.0000e-03 eta 0:05:27
epoch [27/50] batch [60/132] time 0.075 (0.102) data 0.000 (0.005) loss 1.4634 (1.3604) teacher_loss 0.2043 (0.0581) loss_zs_kd 0.0182 (0.0253) loss_oracle 0.6096 (0.6313) kd_loss 0.9451 (0.9740) acc 90.6250 (97.7604) gate/entropy 1.0367 (1.0372) gate/usage_max 0.4422 (0.4428) gate/usage_min 0.1793 (0.1801) gate/usage_std 0.1120 (0.1116) teacher/entropy 0.0228 (0.0273) teacher/usage_max 0.4743 (0.4989) teacher/usage_min 0.0941 (0.1367) teacher/usage_std 0.1701 (0.1545) nleep/row_max_mean 1533.3411 (1528.6541) nleep/row_max_std 38.2623 (37.5812) nleep/row_min_mean 1505.1221 (1501.4484) lr 1.0000e-03 eta 0:05:17
epoch [27/50] batch [80/132] time 0.074 (0.105) data 0.000 (0.004) loss 1.3141 (1.3589) teacher_loss 0.0767 (0.0666) loss_zs_kd 0.0200 (0.0239) loss_oracle 0.5927 (0.6212) kd_loss 0.9310 (0.9697) acc 96.8750 (97.6172) gate/entropy 1.0369 (1.0372) gate/usage_max 0.4416 (0.4426) gate/usage_min 0.1794 (0.1800) gate/usage_std 0.1118 (0.1116) teacher/entropy 0.0552 (0.0281) teacher/usage_max 0.4657 (0.4989) teacher/usage_min 0.1078 (0.1301) teacher/usage_std 0.1602 (0.1578) nleep/row_max_mean 1529.5413 (1528.6649) nleep/row_max_std 40.5033 (37.8379) nleep/row_min_mean 1501.8263 (1501.5642) lr 1.0000e-03 eta 0:05:23
epoch [27/50] batch [100/132] time 0.082 (0.106) data 0.000 (0.003) loss 1.3004 (1.3527) teacher_loss 0.0013 (0.0644) loss_zs_kd 0.0028 (0.0235) loss_oracle 0.5922 (0.6173) kd_loss 1.0016 (0.9678) acc 100.0000 (97.6875) gate/entropy 1.0368 (1.0371) gate/usage_max 0.4410 (0.4423) gate/usage_min 0.1791 (0.1799) gate/usage_std 0.1119 (0.1117) teacher/entropy 0.0335 (0.0288) teacher/usage_max 0.4358 (0.4992) teacher/usage_min 0.1770 (0.1284) teacher/usage_std 0.1123 (0.1592) nleep/row_max_mean 1528.7708 (1528.2682) nleep/row_max_std 33.1914 (37.8546) nleep/row_min_mean 1501.6277 (1501.1687) lr 1.0000e-03 eta 0:05:24
epoch [27/50] batch [120/132] time 0.128 (0.105) data 0.000 (0.002) loss 1.3579 (1.3473) teacher_loss 0.0745 (0.0614) loss_zs_kd 0.0491 (0.0232) loss_oracle 0.6352 (0.6148) kd_loss 0.9412 (0.9669) acc 96.8750 (97.7865) gate/entropy 1.0364 (1.0370) gate/usage_max 0.4404 (0.4421) gate/usage_min 0.1785 (0.1797) gate/usage_std 0.1121 (0.1117) teacher/entropy 0.0290 (0.0280) teacher/usage_max 0.6457 (0.5038) teacher/usage_min 0.0625 (0.1255) teacher/usage_std 0.2399 (0.1619) nleep/row_max_mean 1541.4248 (1528.0434) nleep/row_max_std 30.5109 (37.5159) nleep/row_min_mean 1510.5746 (1500.8236) lr 1.0000e-03 eta 0:05:19
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,569
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 92.5%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [28/50] batch [20/132] time 0.134 (0.158) data 0.000 (0.015) loss 1.4707 (1.3365) teacher_loss 0.0590 (0.0538) loss_zs_kd 0.0389 (0.0253) loss_oracle 0.6855 (0.6033) kd_loss 1.0495 (0.9683) acc 100.0000 (97.9688) gate/entropy 1.0365 (1.0365) gate/usage_max 0.4397 (0.4399) gate/usage_min 0.1785 (0.1786) gate/usage_std 0.1120 (0.1120) teacher/entropy 0.0210 (0.0284) teacher/usage_max 0.4168 (0.5034) teacher/usage_min 0.2188 (0.1258) teacher/usage_std 0.0837 (0.1610) nleep/row_max_mean 1523.6057 (1529.5278) nleep/row_max_std 31.3179 (32.7954) nleep/row_min_mean 1493.7959 (1501.1958) lr 9.3721e-04 eta 0:07:57
epoch [28/50] batch [40/132] time 0.133 (0.150) data 0.000 (0.007) loss 1.2856 (1.3482) teacher_loss 0.0293 (0.0691) loss_zs_kd 0.0253 (0.0260) loss_oracle 0.6115 (0.6154) kd_loss 0.9380 (0.9584) acc 100.0000 (97.7344) gate/entropy 1.0363 (1.0364) gate/usage_max 0.4392 (0.4397) gate/usage_min 0.1781 (0.1784) gate/usage_std 0.1121 (0.1121) teacher/entropy 0.0688 (0.0339) teacher/usage_max 0.4608 (0.5034) teacher/usage_min 0.1335 (0.1180) teacher/usage_std 0.1431 (0.1643) nleep/row_max_mean 1524.1648 (1531.7624) nleep/row_max_std 46.0989 (35.0273) nleep/row_min_mean 1493.8672 (1503.0232) lr 9.3721e-04 eta 0:07:29
epoch [28/50] batch [60/132] time 0.122 (0.146) data 0.000 (0.005) loss 1.3109 (1.3477) teacher_loss 0.0593 (0.0699) loss_zs_kd 0.0064 (0.0247) loss_oracle 0.5480 (0.6067) kd_loss 0.9744 (0.9621) acc 96.8750 (97.6562) gate/entropy 1.0359 (1.0363) gate/usage_max 0.4386 (0.4394) gate/usage_min 0.1775 (0.1782) gate/usage_std 0.1124 (0.1121) teacher/entropy 0.0166 (0.0318) teacher/usage_max 0.4660 (0.5064) teacher/usage_min 0.1250 (0.1197) teacher/usage_std 0.1492 (0.1642) nleep/row_max_mean 1544.7666 (1531.2446) nleep/row_max_std 41.6840 (35.7280) nleep/row_min_mean 1513.9846 (1502.5735) lr 9.3721e-04 eta 0:07:14
epoch [28/50] batch [80/132] time 0.131 (0.145) data 0.000 (0.004) loss 1.2845 (1.3450) teacher_loss 0.0271 (0.0693) loss_zs_kd 0.0272 (0.0250) loss_oracle 0.5886 (0.6019) kd_loss 0.9495 (0.9623) acc 100.0000 (97.8125) gate/entropy 1.0358 (1.0362) gate/usage_max 0.4381 (0.4391) gate/usage_min 0.1773 (0.1780) gate/usage_std 0.1125 (0.1122) teacher/entropy 0.0050 (0.0311) teacher/usage_max 0.5627 (0.5078) teacher/usage_min 0.0937 (0.1193) teacher/usage_std 0.1916 (0.1653) nleep/row_max_mean 1530.1176 (1529.8483) nleep/row_max_std 42.3257 (37.0843) nleep/row_min_mean 1500.3868 (1501.4311) lr 9.3721e-04 eta 0:07:07
epoch [28/50] batch [100/132] time 0.135 (0.145) data 0.000 (0.003) loss 1.2427 (1.3364) teacher_loss 0.0647 (0.0654) loss_zs_kd 0.0291 (0.0232) loss_oracle 0.5539 (0.6001) kd_loss 0.8865 (0.9594) acc 100.0000 (98.0312) gate/entropy 1.0358 (1.0361) gate/usage_max 0.4376 (0.4389) gate/usage_min 0.1772 (0.1779) gate/usage_std 0.1125 (0.1122) teacher/entropy 0.0258 (0.0324) teacher/usage_max 0.5186 (0.5055) teacher/usage_min 0.0323 (0.1175) teacher/usage_std 0.2148 (0.1655) nleep/row_max_mean 1532.0818 (1528.8045) nleep/row_max_std 40.3608 (37.4457) nleep/row_min_mean 1502.2949 (1500.5977) lr 9.3721e-04 eta 0:07:04
epoch [28/50] batch [120/132] time 0.151 (0.145) data 0.000 (0.003) loss 1.2218 (1.3378) teacher_loss 0.0493 (0.0661) loss_zs_kd 0.0323 (0.0227) loss_oracle 0.5584 (0.6004) kd_loss 0.8771 (0.9601) acc 96.8750 (97.9427) gate/entropy 1.0354 (1.0361) gate/usage_max 0.4370 (0.4386) gate/usage_min 0.1766 (0.1778) gate/usage_std 0.1128 (0.1123) teacher/entropy 0.0326 (0.0336) teacher/usage_max 0.5546 (0.5045) teacher/usage_min 0.0348 (0.1199) teacher/usage_std 0.2191 (0.1639) nleep/row_max_mean 1529.3319 (1527.6474) nleep/row_max_std 41.5876 (37.6670) nleep/row_min_mean 1502.5869 (1499.7692) lr 9.3721e-04 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,577
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 92.6%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [29/50] batch [20/132] time 0.164 (0.142) data 0.000 (0.016) loss 1.3491 (1.3405) teacher_loss 0.0761 (0.0563) loss_zs_kd 0.0134 (0.0185) loss_oracle 0.5374 (0.6263) kd_loss 0.9977 (0.9618) acc 96.8750 (98.4375) gate/entropy 1.0356 (1.0355) gate/usage_max 0.4365 (0.4366) gate/usage_min 0.1768 (0.1767) gate/usage_std 0.1125 (0.1126) teacher/entropy 0.0566 (0.0370) teacher/usage_max 0.4458 (0.5080) teacher/usage_min 0.1892 (0.1267) teacher/usage_std 0.1071 (0.1606) nleep/row_max_mean 1519.8435 (1523.3159) nleep/row_max_std 39.9526 (37.2737) nleep/row_min_mean 1493.8727 (1496.5725) lr 8.7467e-04 eta 0:06:50
epoch [29/50] batch [40/132] time 0.094 (0.130) data 0.000 (0.008) loss 1.3467 (1.3474) teacher_loss 0.1238 (0.0704) loss_zs_kd 0.0139 (0.0185) loss_oracle 0.5816 (0.6147) kd_loss 0.9252 (0.9604) acc 96.8750 (97.2656) gate/entropy 1.0351 (1.0354) gate/usage_max 0.4359 (0.4364) gate/usage_min 0.1761 (0.1766) gate/usage_std 0.1129 (0.1127) teacher/entropy 0.0860 (0.0376) teacher/usage_max 0.4721 (0.5093) teacher/usage_min 0.1389 (0.1258) teacher/usage_std 0.1416 (0.1611) nleep/row_max_mean 1526.1184 (1523.6335) nleep/row_max_std 38.1463 (38.3659) nleep/row_min_mean 1497.2949 (1497.0164) lr 8.7467e-04 eta 0:06:12
epoch [29/50] batch [60/132] time 0.161 (0.127) data 0.000 (0.005) loss 1.2408 (1.3568) teacher_loss 0.0414 (0.0670) loss_zs_kd 0.0141 (0.0219) loss_oracle 0.6039 (0.6202) kd_loss 0.8903 (0.9687) acc 100.0000 (97.5000) gate/entropy 1.0352 (1.0353) gate/usage_max 0.4356 (0.4362) gate/usage_min 0.1762 (0.1764) gate/usage_std 0.1128 (0.1127) teacher/entropy 0.0550 (0.0377) teacher/usage_max 0.4958 (0.5012) teacher/usage_min 0.0711 (0.1364) teacher/usage_std 0.1872 (0.1543) nleep/row_max_mean 1529.7570 (1523.6167) nleep/row_max_std 43.1854 (37.8469) nleep/row_min_mean 1502.5835 (1497.2655) lr 8.7467e-04 eta 0:06:01
epoch [29/50] batch [80/132] time 0.090 (0.117) data 0.000 (0.004) loss 1.3809 (1.3514) teacher_loss 0.1295 (0.0658) loss_zs_kd 0.0143 (0.0211) loss_oracle 0.5766 (0.6192) kd_loss 0.9560 (0.9655) acc 93.7500 (97.5000) gate/entropy 1.0349 (1.0353) gate/usage_max 0.4352 (0.4360) gate/usage_min 0.1758 (0.1764) gate/usage_std 0.1130 (0.1127) teacher/entropy 0.0534 (0.0382) teacher/usage_max 0.6104 (0.5048) teacher/usage_min 0.1692 (0.1341) teacher/usage_std 0.1970 (0.1575) nleep/row_max_mean 1521.8394 (1522.9012) nleep/row_max_std 39.4142 (37.4056) nleep/row_min_mean 1496.4762 (1496.8393) lr 8.7467e-04 eta 0:05:31
epoch [29/50] batch [100/132] time 0.086 (0.115) data 0.000 (0.003) loss 1.4153 (1.3499) teacher_loss 0.0458 (0.0705) loss_zs_kd 0.0377 (0.0206) loss_oracle 0.6507 (0.6119) kd_loss 1.0253 (0.9631) acc 100.0000 (97.3750) gate/entropy 1.0349 (1.0352) gate/usage_max 0.4349 (0.4358) gate/usage_min 0.1757 (0.1762) gate/usage_std 0.1130 (0.1128) teacher/entropy 0.0241 (0.0398) teacher/usage_max 0.4072 (0.5025) teacher/usage_min 0.1904 (0.1336) teacher/usage_std 0.1011 (0.1572) nleep/row_max_mean 1513.1848 (1521.5149) nleep/row_max_std 42.0930 (37.1793) nleep/row_min_mean 1487.9038 (1495.7869) lr 8.7467e-04 eta 0:05:23
epoch [29/50] batch [120/132] time 0.181 (0.116) data 0.000 (0.003) loss 1.3705 (1.3528) teacher_loss 0.0796 (0.0705) loss_zs_kd 0.0328 (0.0201) loss_oracle 0.5962 (0.6137) kd_loss 0.9764 (0.9653) acc 100.0000 (97.4219) gate/entropy 1.0351 (1.0352) gate/usage_max 0.4346 (0.4356) gate/usage_min 0.1759 (0.1762) gate/usage_std 0.1128 (0.1128) teacher/entropy 0.0361 (0.0408) teacher/usage_max 0.4803 (0.4983) teacher/usage_min 0.1403 (0.1366) teacher/usage_std 0.1426 (0.1542) nleep/row_max_mean 1516.2712 (1520.4033) nleep/row_max_std 32.6920 (37.1710) nleep/row_min_mean 1491.5312 (1494.8942) lr 8.7467e-04 eta 0:05:23
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,575
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 92.7%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [30/50] batch [20/132] time 0.148 (0.161) data 0.000 (0.013) loss 1.2863 (1.3273) teacher_loss 0.0809 (0.0687) loss_zs_kd 0.0250 (0.0255) loss_oracle 0.5289 (0.6031) kd_loss 0.9284 (0.9444) acc 93.7500 (97.1875) gate/entropy 1.0345 (1.0347) gate/usage_max 0.4338 (0.4340) gate/usage_min 0.1750 (0.1753) gate/usage_std 0.1133 (0.1131) teacher/entropy 0.0746 (0.0495) teacher/usage_max 0.4894 (0.5043) teacher/usage_min 0.1430 (0.1226) teacher/usage_std 0.1435 (0.1617) nleep/row_max_mean 1519.4644 (1519.8942) nleep/row_max_std 40.5489 (39.1188) nleep/row_min_mean 1494.8246 (1494.4807) lr 8.1262e-04 eta 0:07:24
epoch [30/50] batch [40/132] time 0.145 (0.152) data 0.000 (0.007) loss 1.2787 (1.3284) teacher_loss 0.0146 (0.0670) loss_zs_kd 0.0306 (0.0240) loss_oracle 0.5753 (0.6029) kd_loss 0.9611 (0.9479) acc 100.0000 (97.3438) gate/entropy 1.0345 (1.0346) gate/usage_max 0.4334 (0.4338) gate/usage_min 0.1750 (0.1752) gate/usage_std 0.1133 (0.1132) teacher/entropy 0.0663 (0.0461) teacher/usage_max 0.4440 (0.5106) teacher/usage_min 0.1616 (0.1226) teacher/usage_std 0.1231 (0.1647) nleep/row_max_mean 1526.9084 (1520.4204) nleep/row_max_std 37.0733 (38.6926) nleep/row_min_mean 1499.0120 (1494.7665) lr 8.1262e-04 eta 0:06:56
epoch [30/50] batch [60/132] time 0.146 (0.151) data 0.000 (0.005) loss 1.2993 (1.3362) teacher_loss 0.0460 (0.0751) loss_zs_kd 0.0238 (0.0235) loss_oracle 0.5824 (0.6084) kd_loss 0.9502 (0.9452) acc 100.0000 (97.3958) gate/entropy 1.0343 (1.0346) gate/usage_max 0.4330 (0.4336) gate/usage_min 0.1748 (0.1751) gate/usage_std 0.1134 (0.1132) teacher/entropy 0.0535 (0.0499) teacher/usage_max 0.5367 (0.5096) teacher/usage_min 0.1496 (0.1244) teacher/usage_std 0.1586 (0.1640) nleep/row_max_mean 1515.5569 (1518.5495) nleep/row_max_std 34.7530 (38.5232) nleep/row_min_mean 1490.3196 (1493.1410) lr 8.1262e-04 eta 0:06:49
epoch [30/50] batch [80/132] time 0.150 (0.150) data 0.000 (0.003) loss 1.2323 (1.3410) teacher_loss 0.0117 (0.0836) loss_zs_kd 0.0169 (0.0237) loss_oracle 0.5711 (0.6063) kd_loss 0.9267 (0.9425) acc 100.0000 (97.1094) gate/entropy 1.0342 (1.0345) gate/usage_max 0.4326 (0.4334) gate/usage_min 0.1745 (0.1750) gate/usage_std 0.1135 (0.1133) teacher/entropy 0.0182 (0.0503) teacher/usage_max 0.5349 (0.5112) teacher/usage_min 0.0612 (0.1218) teacher/usage_std 0.1997 (0.1663) nleep/row_max_mean 1516.6987 (1518.3470) nleep/row_max_std 39.7031 (38.5483) nleep/row_min_mean 1492.2307 (1492.7601) lr 8.1262e-04 eta 0:06:44
epoch [30/50] batch [100/132] time 0.165 (0.151) data 0.000 (0.003) loss 1.4196 (1.3466) teacher_loss 0.2294 (0.0899) loss_zs_kd 0.0086 (0.0236) loss_oracle 0.6065 (0.6100) kd_loss 0.8827 (0.9400) acc 93.7500 (96.8750) gate/entropy 1.0343 (1.0344) gate/usage_max 0.4322 (0.4332) gate/usage_min 0.1746 (0.1749) gate/usage_std 0.1134 (0.1133) teacher/entropy 0.0725 (0.0517) teacher/usage_max 0.5070 (0.5176) teacher/usage_min 0.0753 (0.1190) teacher/usage_std 0.1861 (0.1701) nleep/row_max_mean 1509.2804 (1517.1546) nleep/row_max_std 39.3291 (38.6310) nleep/row_min_mean 1481.4868 (1491.6235) lr 8.1262e-04 eta 0:06:42
epoch [30/50] batch [120/132] time 0.148 (0.149) data 0.000 (0.002) loss 1.1660 (1.3382) teacher_loss 0.0288 (0.0853) loss_zs_kd 0.0196 (0.0233) loss_oracle 0.5337 (0.6084) kd_loss 0.8605 (0.9371) acc 100.0000 (97.1354) gate/entropy 1.0341 (1.0343) gate/usage_max 0.4317 (0.4330) gate/usage_min 0.1743 (0.1748) gate/usage_std 0.1135 (0.1134) teacher/entropy 0.0797 (0.0538) teacher/usage_max 0.4815 (0.5204) teacher/usage_min 0.0616 (0.1180) teacher/usage_std 0.1924 (0.1713) nleep/row_max_mean 1508.1238 (1517.0240) nleep/row_max_std 38.9343 (38.6956) nleep/row_min_mean 1482.9103 (1491.3711) lr 8.1262e-04 eta 0:06:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,568
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 92.5%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [31/50] batch [20/132] time 0.088 (0.135) data 0.000 (0.016) loss 1.2076 (1.2791) teacher_loss 0.0710 (0.0933) loss_zs_kd 0.0134 (0.0172) loss_oracle 0.6830 (0.6001) kd_loss 0.7884 (0.8771) acc 96.8750 (97.0312) gate/entropy 1.0337 (1.0338) gate/usage_max 0.4307 (0.4310) gate/usage_min 0.1737 (0.1738) gate/usage_std 0.1138 (0.1137) teacher/entropy 0.1376 (0.0743) teacher/usage_max 0.5761 (0.5815) teacher/usage_min 0.0381 (0.0660) teacher/usage_std 0.2227 (0.2153) nleep/row_max_mean 1522.8655 (1517.7926) nleep/row_max_std 41.2932 (37.8155) nleep/row_min_mean 1494.4595 (1490.5377) lr 7.5131e-04 eta 0:05:53
epoch [31/50] batch [40/132] time 0.097 (0.125) data 0.000 (0.008) loss 1.3089 (1.2896) teacher_loss 0.0747 (0.1002) loss_zs_kd 0.0210 (0.0177) loss_oracle 0.6609 (0.6032) kd_loss 0.8932 (0.8789) acc 96.8750 (96.6406) gate/entropy 1.0335 (1.0337) gate/usage_max 0.4301 (0.4306) gate/usage_min 0.1734 (0.1736) gate/usage_std 0.1139 (0.1138) teacher/entropy 0.0547 (0.0793) teacher/usage_max 0.5503 (0.5819) teacher/usage_min 0.0655 (0.0737) teacher/usage_std 0.2012 (0.2122) nleep/row_max_mean 1524.5851 (1520.2839) nleep/row_max_std 36.2800 (37.5755) nleep/row_min_mean 1496.9684 (1493.0665) lr 7.5131e-04 eta 0:05:25
epoch [31/50] batch [60/132] time 0.103 (0.124) data 0.000 (0.006) loss 1.1144 (1.2859) teacher_loss 0.0160 (0.0969) loss_zs_kd 0.0067 (0.0181) loss_oracle 0.5203 (0.6026) kd_loss 0.8348 (0.8787) acc 100.0000 (96.6667) gate/entropy 1.0332 (1.0335) gate/usage_max 0.4294 (0.4303) gate/usage_min 0.1730 (0.1734) gate/usage_std 0.1141 (0.1139) teacher/entropy 0.0488 (0.0734) teacher/usage_max 0.5360 (0.5848) teacher/usage_min 0.0033 (0.0676) teacher/usage_std 0.2354 (0.2165) nleep/row_max_mean 1529.2592 (1522.4636) nleep/row_max_std 37.3161 (36.0917) nleep/row_min_mean 1502.3743 (1494.9429) lr 7.5131e-04 eta 0:05:20
epoch [31/50] batch [80/132] time 0.068 (0.120) data 0.000 (0.004) loss 1.3062 (1.2946) teacher_loss 0.0928 (0.1010) loss_zs_kd 0.0236 (0.0184) loss_oracle 0.6176 (0.6046) kd_loss 0.8928 (0.8820) acc 96.8750 (96.5625) gate/entropy 1.0329 (1.0334) gate/usage_max 0.4287 (0.4300) gate/usage_min 0.1725 (0.1732) gate/usage_std 0.1144 (0.1140) teacher/entropy 0.0281 (0.0712) teacher/usage_max 0.5973 (0.5862) teacher/usage_min 0.0336 (0.0689) teacher/usage_std 0.2315 (0.2168) nleep/row_max_mean 1542.4482 (1524.2199) nleep/row_max_std 29.7224 (35.9876) nleep/row_min_mean 1512.3706 (1496.4889) lr 7.5131e-04 eta 0:05:06
epoch [31/50] batch [100/132] time 0.097 (0.120) data 0.000 (0.003) loss 1.2866 (1.2944) teacher_loss 0.0628 (0.0996) loss_zs_kd 0.0123 (0.0173) loss_oracle 0.6129 (0.6075) kd_loss 0.9113 (0.8824) acc 96.8750 (96.5938) gate/entropy 1.0327 (1.0333) gate/usage_max 0.4281 (0.4297) gate/usage_min 0.1723 (0.1731) gate/usage_std 0.1145 (0.1141) teacher/entropy 0.0255 (0.0675) teacher/usage_max 0.5070 (0.5953) teacher/usage_min 0.0585 (0.0649) teacher/usage_std 0.1966 (0.2225) nleep/row_max_mean 1538.8265 (1525.9339) nleep/row_max_std 35.9649 (36.1326) nleep/row_min_mean 1506.6093 (1497.7986) lr 7.5131e-04 eta 0:05:04
epoch [31/50] batch [120/132] time 0.079 (0.118) data 0.000 (0.003) loss 1.2637 (1.2964) teacher_loss 0.0574 (0.1013) loss_zs_kd 0.0189 (0.0167) loss_oracle 0.6212 (0.6091) kd_loss 0.8863 (0.8822) acc 96.8750 (96.5365) gate/entropy 1.0325 (1.0331) gate/usage_max 0.4273 (0.4293) gate/usage_min 0.1719 (0.1729) gate/usage_std 0.1147 (0.1142) teacher/entropy 0.0160 (0.0652) teacher/usage_max 0.8071 (0.6066) teacher/usage_min 0.0001 (0.0616) teacher/usage_std 0.3441 (0.2287) nleep/row_max_mean 1536.3544 (1527.1336) nleep/row_max_std 39.1069 (36.2019) nleep/row_min_mean 1504.0077 (1498.6154) lr 7.5131e-04 eta 0:04:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,531
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [32/50] batch [20/132] time 0.161 (0.173) data 0.000 (0.014) loss 1.2550 (1.3148) teacher_loss 0.0339 (0.1081) loss_zs_kd 0.0117 (0.0162) loss_oracle 0.6515 (0.6394) kd_loss 0.8895 (0.8789) acc 100.0000 (95.9375) gate/entropy 1.0321 (1.0321) gate/usage_max 0.4262 (0.4265) gate/usage_min 0.1714 (0.1715) gate/usage_std 0.1149 (0.1149) teacher/entropy 0.0731 (0.0494) teacher/usage_max 0.7249 (0.6798) teacher/usage_min 0.0743 (0.0394) teacher/usage_std 0.2816 (0.2674) nleep/row_max_mean 1529.0476 (1528.9326) nleep/row_max_std 39.8865 (38.5830) nleep/row_min_mean 1498.8851 (1498.7270) lr 6.9098e-04 eta 0:07:10
epoch [32/50] batch [40/132] time 0.170 (0.163) data 0.000 (0.007) loss 1.6643 (1.3125) teacher_loss 0.4914 (0.1164) loss_zs_kd 0.0218 (0.0149) loss_oracle 0.6526 (0.6300) kd_loss 0.8357 (0.8736) acc 84.3750 (95.8594) gate/entropy 1.0320 (1.0320) gate/usage_max 0.4256 (0.4262) gate/usage_min 0.1712 (0.1713) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0624 (0.0493) teacher/usage_max 0.8177 (0.6878) teacher/usage_min 0.0000 (0.0337) teacher/usage_std 0.3505 (0.2739) nleep/row_max_mean 1514.1154 (1528.3833) nleep/row_max_std 39.4675 (36.3970) nleep/row_min_mean 1487.4727 (1498.0780) lr 6.9098e-04 eta 0:06:43
epoch [32/50] batch [60/132] time 0.140 (0.161) data 0.000 (0.005) loss 1.1703 (1.3019) teacher_loss 0.0339 (0.1123) loss_zs_kd 0.0153 (0.0140) loss_oracle 0.5852 (0.6263) kd_loss 0.8361 (0.8694) acc 100.0000 (96.1979) gate/entropy 1.0315 (1.0319) gate/usage_max 0.4250 (0.4259) gate/usage_min 0.1706 (0.1712) gate/usage_std 0.1154 (0.1150) teacher/entropy 0.0855 (0.0484) teacher/usage_max 0.5994 (0.6838) teacher/usage_min 0.0399 (0.0290) teacher/usage_std 0.2293 (0.2742) nleep/row_max_mean 1531.7595 (1527.1024) nleep/row_max_std 36.4126 (36.5343) nleep/row_min_mean 1504.6106 (1497.0144) lr 6.9098e-04 eta 0:06:34
epoch [32/50] batch [80/132] time 0.144 (0.161) data 0.000 (0.004) loss 1.2170 (1.3055) teacher_loss 0.0103 (0.1125) loss_zs_kd 0.0066 (0.0137) loss_oracle 0.6687 (0.6291) kd_loss 0.8691 (0.8716) acc 100.0000 (96.1719) gate/entropy 1.0315 (1.0318) gate/usage_max 0.4244 (0.4255) gate/usage_min 0.1706 (0.1710) gate/usage_std 0.1153 (0.1151) teacher/entropy 0.0714 (0.0482) teacher/usage_max 0.6253 (0.6777) teacher/usage_min 0.0589 (0.0321) teacher/usage_std 0.2316 (0.2699) nleep/row_max_mean 1537.5454 (1527.3109) nleep/row_max_std 32.7954 (37.2565) nleep/row_min_mean 1505.3374 (1497.5017) lr 6.9098e-04 eta 0:06:31
epoch [32/50] batch [100/132] time 0.171 (0.161) data 0.000 (0.003) loss 1.3473 (1.3060) teacher_loss 0.1511 (0.1115) loss_zs_kd 0.0228 (0.0142) loss_oracle 0.5891 (0.6305) kd_loss 0.8902 (0.8722) acc 93.7500 (96.2188) gate/entropy 1.0310 (1.0317) gate/usage_max 0.4238 (0.4252) gate/usage_min 0.1699 (0.1709) gate/usage_std 0.1158 (0.1152) teacher/entropy 0.0417 (0.0470) teacher/usage_max 0.5665 (0.6786) teacher/usage_min 0.0542 (0.0318) teacher/usage_std 0.2116 (0.2702) nleep/row_max_mean 1531.5657 (1526.4135) nleep/row_max_std 41.4813 (38.4975) nleep/row_min_mean 1502.5134 (1496.8274) lr 6.9098e-04 eta 0:06:28
epoch [32/50] batch [120/132] time 0.077 (0.154) data 0.000 (0.002) loss 1.2902 (1.3101) teacher_loss 0.0677 (0.1124) loss_zs_kd 0.0299 (0.0148) loss_oracle 0.6618 (0.6322) kd_loss 0.8767 (0.8742) acc 96.8750 (96.0938) gate/entropy 1.0309 (1.0316) gate/usage_max 0.4232 (0.4250) gate/usage_min 0.1698 (0.1708) gate/usage_std 0.1158 (0.1153) teacher/entropy 0.0393 (0.0461) teacher/usage_max 0.6824 (0.6835) teacher/usage_min 0.0318 (0.0334) teacher/usage_std 0.2677 (0.2722) nleep/row_max_mean 1528.1833 (1526.4066) nleep/row_max_std 42.4834 (39.5141) nleep/row_min_mean 1498.9951 (1496.9259) lr 6.9098e-04 eta 0:06:08
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,533
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.8%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [33/50] batch [20/132] time 0.074 (0.115) data 0.000 (0.016) loss 1.3433 (1.3222) teacher_loss 0.1103 (0.1240) loss_zs_kd 0.0271 (0.0192) loss_oracle 0.6670 (0.6357) kd_loss 0.8859 (0.8707) acc 96.8750 (95.7812) gate/entropy 1.0305 (1.0308) gate/usage_max 0.4224 (0.4227) gate/usage_min 0.1694 (0.1697) gate/usage_std 0.1161 (0.1159) teacher/entropy 0.0344 (0.0382) teacher/usage_max 0.8553 (0.6967) teacher/usage_min 0.0323 (0.0248) teacher/usage_std 0.3706 (0.2816) nleep/row_max_mean 1523.7817 (1527.4465) nleep/row_max_std 45.0591 (43.6009) nleep/row_min_mean 1497.9087 (1498.8199) lr 6.3188e-04 eta 0:04:31
epoch [33/50] batch [40/132] time 0.075 (0.101) data 0.000 (0.008) loss 1.2923 (1.3192) teacher_loss 0.0648 (0.1200) loss_zs_kd 0.0145 (0.0171) loss_oracle 0.6285 (0.6295) kd_loss 0.9060 (0.8759) acc 100.0000 (95.8594) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4220 (0.4224) gate/usage_min 0.1696 (0.1696) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0066 (0.0378) teacher/usage_max 0.6555 (0.6829) teacher/usage_min 0.0312 (0.0309) teacher/usage_std 0.2553 (0.2713) nleep/row_max_mean 1534.9001 (1526.4047) nleep/row_max_std 32.2803 (41.2476) nleep/row_min_mean 1504.2681 (1498.5662) lr 6.3188e-04 eta 0:03:56
epoch [33/50] batch [60/132] time 0.059 (0.102) data 0.000 (0.006) loss 1.3559 (1.3168) teacher_loss 0.1723 (0.1125) loss_zs_kd 0.0169 (0.0171) loss_oracle 0.5744 (0.6288) kd_loss 0.8880 (0.8814) acc 96.8750 (95.9896) gate/entropy 1.0303 (1.0306) gate/usage_max 0.4216 (0.4222) gate/usage_min 0.1691 (0.1695) gate/usage_std 0.1163 (0.1160) teacher/entropy 0.0395 (0.0377) teacher/usage_max 0.7036 (0.6788) teacher/usage_min 0.0470 (0.0375) teacher/usage_std 0.2746 (0.2679) nleep/row_max_mean 1520.3984 (1527.0252) nleep/row_max_std 43.7215 (41.2764) nleep/row_min_mean 1496.5438 (1499.5527) lr 6.3188e-04 eta 0:03:56
epoch [33/50] batch [80/132] time 0.056 (0.098) data 0.000 (0.004) loss 1.3633 (1.3173) teacher_loss 0.0998 (0.1114) loss_zs_kd 0.0175 (0.0167) loss_oracle 0.6731 (0.6316) kd_loss 0.9182 (0.8818) acc 96.8750 (96.0156) gate/entropy 1.0302 (1.0306) gate/usage_max 0.4212 (0.4220) gate/usage_min 0.1690 (0.1694) gate/usage_std 0.1163 (0.1160) teacher/entropy 0.0268 (0.0395) teacher/usage_max 0.7153 (0.6707) teacher/usage_min 0.0667 (0.0404) teacher/usage_std 0.2771 (0.2635) nleep/row_max_mean 1518.8171 (1525.4552) nleep/row_max_std 37.1560 (41.0631) nleep/row_min_mean 1494.3035 (1498.4351) lr 6.3188e-04 eta 0:03:44
epoch [33/50] batch [100/132] time 0.138 (0.100) data 0.000 (0.003) loss 1.3493 (1.3151) teacher_loss 0.1664 (0.1086) loss_zs_kd 0.0066 (0.0158) loss_oracle 0.6215 (0.6339) kd_loss 0.8689 (0.8816) acc 93.7500 (96.1875) gate/entropy 1.0302 (1.0305) gate/usage_max 0.4208 (0.4218) gate/usage_min 0.1690 (0.1693) gate/usage_std 0.1163 (0.1161) teacher/entropy 0.0396 (0.0390) teacher/usage_max 0.5460 (0.6659) teacher/usage_min 0.0319 (0.0401) teacher/usage_std 0.2191 (0.2618) nleep/row_max_mean 1519.4147 (1524.4755) nleep/row_max_std 36.2386 (40.5972) nleep/row_min_mean 1493.2659 (1497.5489) lr 6.3188e-04 eta 0:03:48
epoch [33/50] batch [120/132] time 0.146 (0.108) data 0.000 (0.003) loss 1.5287 (1.3107) teacher_loss 0.2731 (0.1062) loss_zs_kd 0.0362 (0.0157) loss_oracle 0.5921 (0.6325) kd_loss 0.9414 (0.8803) acc 90.6250 (96.2500) gate/entropy 1.0297 (1.0304) gate/usage_max 0.4204 (0.4216) gate/usage_min 0.1684 (0.1693) gate/usage_std 0.1167 (0.1161) teacher/entropy 0.0289 (0.0381) teacher/usage_max 0.5555 (0.6634) teacher/usage_min 0.0994 (0.0381) teacher/usage_std 0.1864 (0.2618) nleep/row_max_mean 1526.5114 (1524.4887) nleep/row_max_std 38.3993 (40.1908) nleep/row_min_mean 1500.1973 (1497.5835) lr 6.3188e-04 eta 0:04:04
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,508
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [34/50] batch [20/132] time 0.153 (0.173) data 0.000 (0.016) loss 1.1865 (1.2819) teacher_loss 0.0059 (0.0980) loss_zs_kd 0.0000 (0.0137) loss_oracle 0.6402 (0.6287) kd_loss 0.8605 (0.8627) acc 100.0000 (96.5625) gate/entropy 1.0300 (1.0298) gate/usage_max 0.4198 (0.4200) gate/usage_min 0.1687 (0.1685) gate/usage_std 0.1164 (0.1166) teacher/entropy 0.0527 (0.0365) teacher/usage_max 0.8311 (0.6777) teacher/usage_min 0.0316 (0.0197) teacher/usage_std 0.3546 (0.2730) nleep/row_max_mean 1521.2948 (1520.0263) nleep/row_max_std 36.1504 (39.7226) nleep/row_min_mean 1497.6266 (1493.2616) lr 5.7422e-04 eta 0:06:24
epoch [34/50] batch [40/132] time 0.134 (0.167) data 0.000 (0.008) loss 1.2671 (1.2892) teacher_loss 0.0603 (0.0978) loss_zs_kd 0.0144 (0.0142) loss_oracle 0.6420 (0.6383) kd_loss 0.8786 (0.8652) acc 96.8750 (96.4844) gate/entropy 1.0297 (1.0298) gate/usage_max 0.4195 (0.4198) gate/usage_min 0.1684 (0.1685) gate/usage_std 0.1167 (0.1166) teacher/entropy 0.0269 (0.0346) teacher/usage_max 0.6919 (0.6882) teacher/usage_min 0.0267 (0.0203) teacher/usage_std 0.2741 (0.2782) nleep/row_max_mean 1521.1025 (1520.7458) nleep/row_max_std 36.0810 (39.6067) nleep/row_min_mean 1491.8185 (1493.6243) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [60/132] time 0.158 (0.163) data 0.000 (0.006) loss 1.1442 (1.2799) teacher_loss 0.0125 (0.0921) loss_zs_kd 0.0070 (0.0132) loss_oracle 0.5965 (0.6370) kd_loss 0.8299 (0.8628) acc 100.0000 (96.6667) gate/entropy 1.0297 (1.0297) gate/usage_max 0.4192 (0.4197) gate/usage_min 0.1683 (0.1684) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0543 (0.0349) teacher/usage_max 0.6065 (0.6878) teacher/usage_min 0.0056 (0.0183) teacher/usage_std 0.2484 (0.2790) nleep/row_max_mean 1530.7266 (1521.7184) nleep/row_max_std 38.1589 (40.0304) nleep/row_min_mean 1504.0651 (1494.4689) lr 5.7422e-04 eta 0:05:56
epoch [34/50] batch [80/132] time 0.071 (0.160) data 0.000 (0.004) loss 1.2300 (1.2806) teacher_loss 0.0383 (0.0922) loss_zs_kd 0.0142 (0.0133) loss_oracle 0.6449 (0.6423) kd_loss 0.8622 (0.8606) acc 100.0000 (96.6016) gate/entropy 1.0295 (1.0297) gate/usage_max 0.4188 (0.4195) gate/usage_min 0.1682 (0.1683) gate/usage_std 0.1168 (0.1167) teacher/entropy 0.0501 (0.0358) teacher/usage_max 0.7187 (0.6942) teacher/usage_min 0.0349 (0.0171) teacher/usage_std 0.2858 (0.2823) nleep/row_max_mean 1513.1198 (1521.9813) nleep/row_max_std 49.1044 (40.6195) nleep/row_min_mean 1487.7373 (1494.6430) lr 5.7422e-04 eta 0:05:47
epoch [34/50] batch [100/132] time 0.087 (0.151) data 0.000 (0.003) loss 1.1875 (1.2890) teacher_loss 0.0023 (0.0990) loss_zs_kd 0.0017 (0.0138) loss_oracle 0.6268 (0.6476) kd_loss 0.8709 (0.8593) acc 100.0000 (96.3125) gate/entropy 1.0294 (1.0296) gate/usage_max 0.4184 (0.4193) gate/usage_min 0.1681 (0.1683) gate/usage_std 0.1169 (0.1167) teacher/entropy 0.0100 (0.0377) teacher/usage_max 0.7791 (0.6982) teacher/usage_min 0.0004 (0.0180) teacher/usage_std 0.3278 (0.2836) nleep/row_max_mean 1518.7424 (1521.6333) nleep/row_max_std 51.7906 (40.3086) nleep/row_min_mean 1490.2208 (1494.2316) lr 5.7422e-04 eta 0:05:24
epoch [34/50] batch [120/132] time 0.071 (0.144) data 0.000 (0.003) loss 1.2088 (1.2911) teacher_loss 0.0339 (0.1020) loss_zs_kd 0.0262 (0.0143) loss_oracle 0.5861 (0.6466) kd_loss 0.8688 (0.8586) acc 100.0000 (96.3281) gate/entropy 1.0290 (1.0296) gate/usage_max 0.4182 (0.4191) gate/usage_min 0.1676 (0.1682) gate/usage_std 0.1172 (0.1168) teacher/entropy 0.0136 (0.0386) teacher/usage_max 0.6831 (0.6939) teacher/usage_min 0.0045 (0.0186) teacher/usage_std 0.2774 (0.2817) nleep/row_max_mean 1532.3728 (1522.0883) nleep/row_max_std 41.2215 (39.9889) nleep/row_min_mean 1503.4730 (1494.7067) lr 5.7422e-04 eta 0:05:04
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [35/50] batch [20/132] time 0.174 (0.129) data 0.000 (0.019) loss 1.1666 (1.2766) teacher_loss 0.0096 (0.0867) loss_zs_kd 0.0022 (0.0144) loss_oracle 0.6497 (0.6409) kd_loss 0.8311 (0.8622) acc 100.0000 (97.5000) gate/entropy 1.0293 (1.0292) gate/usage_max 0.4177 (0.4178) gate/usage_min 0.1679 (0.1678) gate/usage_std 0.1170 (0.1171) teacher/entropy 0.0858 (0.0380) teacher/usage_max 0.6167 (0.6851) teacher/usage_min 0.0429 (0.0242) teacher/usage_std 0.2343 (0.2747) nleep/row_max_mean 1517.7573 (1517.8322) nleep/row_max_std 36.6111 (43.8200) nleep/row_min_mean 1492.7062 (1491.1602) lr 5.1825e-04 eta 0:04:30
epoch [35/50] batch [40/132] time 0.077 (0.125) data 0.000 (0.009) loss 1.2641 (1.2919) teacher_loss 0.0780 (0.0938) loss_zs_kd 0.0233 (0.0158) loss_oracle 0.6062 (0.6524) kd_loss 0.8713 (0.8640) acc 100.0000 (96.7188) gate/entropy 1.0291 (1.0291) gate/usage_max 0.4174 (0.4177) gate/usage_min 0.1677 (0.1677) gate/usage_std 0.1171 (0.1171) teacher/entropy 0.0534 (0.0420) teacher/usage_max 0.6448 (0.6906) teacher/usage_min 0.0517 (0.0307) teacher/usage_std 0.2431 (0.2756) nleep/row_max_mean 1514.6527 (1518.1222) nleep/row_max_std 34.7662 (42.0882) nleep/row_min_mean 1486.2722 (1491.4539) lr 5.1825e-04 eta 0:04:19
epoch [35/50] batch [60/132] time 0.153 (0.119) data 0.000 (0.006) loss 1.2755 (1.2856) teacher_loss 0.0845 (0.0956) loss_zs_kd 0.0057 (0.0154) loss_oracle 0.5818 (0.6413) kd_loss 0.8973 (0.8616) acc 96.8750 (96.7188) gate/entropy 1.0289 (1.0291) gate/usage_max 0.4171 (0.4176) gate/usage_min 0.1674 (0.1677) gate/usage_std 0.1173 (0.1171) teacher/entropy 0.0084 (0.0423) teacher/usage_max 0.7504 (0.6913) teacher/usage_min 0.0318 (0.0286) teacher/usage_std 0.3046 (0.2760) nleep/row_max_mean 1530.3695 (1519.2058) nleep/row_max_std 41.1197 (42.3274) nleep/row_min_mean 1504.7666 (1492.7568) lr 5.1825e-04 eta 0:04:04
epoch [35/50] batch [80/132] time 0.165 (0.121) data 0.000 (0.005) loss 1.5071 (1.2825) teacher_loss 0.2020 (0.0943) loss_zs_kd 0.0101 (0.0143) loss_oracle 0.6807 (0.6331) kd_loss 0.9597 (0.8646) acc 93.7500 (96.8359) gate/entropy 1.0288 (1.0291) gate/usage_max 0.4169 (0.4174) gate/usage_min 0.1673 (0.1676) gate/usage_std 0.1174 (0.1172) teacher/entropy 0.0299 (0.0421) teacher/usage_max 0.5605 (0.6894) teacher/usage_min 0.1240 (0.0318) teacher/usage_std 0.1787 (0.2750) nleep/row_max_mean 1529.2577 (1519.7129) nleep/row_max_std 32.2143 (42.0703) nleep/row_min_mean 1504.8831 (1493.6198) lr 5.1825e-04 eta 0:04:05
epoch [35/50] batch [100/132] time 0.160 (0.128) data 0.000 (0.004) loss 1.2247 (1.2822) teacher_loss 0.0350 (0.0942) loss_zs_kd 0.0141 (0.0141) loss_oracle 0.5265 (0.6307) kd_loss 0.9194 (0.8656) acc 96.8750 (96.8750) gate/entropy 1.0289 (1.0290) gate/usage_max 0.4167 (0.4173) gate/usage_min 0.1675 (0.1676) gate/usage_std 0.1173 (0.1172) teacher/entropy 0.0779 (0.0442) teacher/usage_max 0.5480 (0.6851) teacher/usage_min 0.1324 (0.0355) teacher/usage_std 0.1699 (0.2717) nleep/row_max_mean 1526.6724 (1519.6969) nleep/row_max_std 33.1524 (41.8044) nleep/row_min_mean 1503.7628 (1493.8903) lr 5.1825e-04 eta 0:04:18
epoch [35/50] batch [120/132] time 0.152 (0.133) data 0.000 (0.003) loss 1.3245 (1.2887) teacher_loss 0.1240 (0.1002) loss_zs_kd 0.0274 (0.0144) loss_oracle 0.5558 (0.6281) kd_loss 0.9089 (0.8672) acc 96.8750 (96.5625) gate/entropy 1.0286 (1.0290) gate/usage_max 0.4165 (0.4172) gate/usage_min 0.1671 (0.1675) gate/usage_std 0.1175 (0.1172) teacher/entropy 0.0726 (0.0448) teacher/usage_max 0.5365 (0.6801) teacher/usage_min 0.1161 (0.0381) teacher/usage_std 0.1719 (0.2687) nleep/row_max_mean 1525.6300 (1520.0328) nleep/row_max_std 29.3233 (41.6435) nleep/row_min_mean 1501.6895 (1494.4023) lr 5.1825e-04 eta 0:04:24
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,515
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.6%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [36/50] batch [20/132] time 0.155 (0.181) data 0.000 (0.016) loss 1.2093 (1.2964) teacher_loss 0.0847 (0.0970) loss_zs_kd 0.0151 (0.0176) loss_oracle 0.5645 (0.6283) kd_loss 0.8348 (0.8765) acc 96.8750 (96.2500) gate/entropy 1.0285 (1.0287) gate/usage_max 0.4169 (0.4166) gate/usage_min 0.1670 (0.1673) gate/usage_std 0.1176 (0.1174) teacher/entropy 0.0901 (0.0585) teacher/usage_max 0.6280 (0.6659) teacher/usage_min 0.0541 (0.0649) teacher/usage_std 0.2346 (0.2549) nleep/row_max_mean 1527.9963 (1515.7665) nleep/row_max_std 31.4261 (41.8623) nleep/row_min_mean 1507.0826 (1492.1783) lr 4.6417e-04 eta 0:05:54
epoch [36/50] batch [40/132] time 0.158 (0.173) data 0.000 (0.008) loss 1.2053 (1.2779) teacher_loss 0.1355 (0.1008) loss_zs_kd 0.0267 (0.0176) loss_oracle 0.5590 (0.6178) kd_loss 0.7769 (0.8594) acc 93.7500 (96.2500) gate/entropy 1.0287 (1.0288) gate/usage_max 0.4169 (0.4166) gate/usage_min 0.1672 (0.1673) gate/usage_std 0.1175 (0.1174) teacher/entropy 0.1198 (0.0693) teacher/usage_max 0.7380 (0.6621) teacher/usage_min 0.0234 (0.0580) teacher/usage_std 0.2993 (0.2560) nleep/row_max_mean 1510.9790 (1514.1498) nleep/row_max_std 41.0203 (42.4776) nleep/row_min_mean 1490.7844 (1490.9869) lr 4.6417e-04 eta 0:05:35
epoch [36/50] batch [60/132] time 0.135 (0.150) data 0.000 (0.006) loss 1.3037 (1.2728) teacher_loss 0.0691 (0.0943) loss_zs_kd 0.0287 (0.0167) loss_oracle 0.6218 (0.6157) kd_loss 0.9093 (0.8623) acc 96.8750 (96.5104) gate/entropy 1.0286 (1.0287) gate/usage_max 0.4172 (0.4168) gate/usage_min 0.1671 (0.1673) gate/usage_std 0.1176 (0.1174) teacher/entropy 0.0399 (0.0708) teacher/usage_max 0.5128 (0.6460) teacher/usage_min 0.0809 (0.0629) teacher/usage_std 0.1837 (0.2465) nleep/row_max_mean 1523.8890 (1514.9466) nleep/row_max_std 24.7595 (42.1282) nleep/row_min_mean 1498.1201 (1491.7303) lr 4.6417e-04 eta 0:04:47
epoch [36/50] batch [80/132] time 0.098 (0.140) data 0.000 (0.004) loss 1.2114 (1.2670) teacher_loss 0.0690 (0.0889) loss_zs_kd 0.0160 (0.0154) loss_oracle 0.6608 (0.6182) kd_loss 0.8040 (0.8614) acc 96.8750 (96.7969) gate/entropy 1.0286 (1.0287) gate/usage_max 0.4173 (0.4169) gate/usage_min 0.1671 (0.1673) gate/usage_std 0.1175 (0.1174) teacher/entropy 0.1139 (0.0712) teacher/usage_max 0.6322 (0.6350) teacher/usage_min 0.0468 (0.0624) teacher/usage_std 0.2392 (0.2416) nleep/row_max_mean 1527.5850 (1516.0156) nleep/row_max_std 25.5737 (41.5384) nleep/row_min_mean 1504.0177 (1492.6474) lr 4.6417e-04 eta 0:04:26
epoch [36/50] batch [100/132] time 0.147 (0.134) data 0.000 (0.003) loss 1.4247 (1.2666) teacher_loss 0.0701 (0.0835) loss_zs_kd 0.0103 (0.0153) loss_oracle 0.7130 (0.6215) kd_loss 0.9930 (0.8647) acc 96.8750 (97.0625) gate/entropy 1.0284 (1.0287) gate/usage_max 0.4177 (0.4170) gate/usage_min 0.1669 (0.1672) gate/usage_std 0.1177 (0.1175) teacher/entropy 0.0531 (0.0704) teacher/usage_max 0.5368 (0.6347) teacher/usage_min 0.1875 (0.0653) teacher/usage_std 0.1483 (0.2395) nleep/row_max_mean 1522.7369 (1516.7831) nleep/row_max_std 42.8662 (41.2686) nleep/row_min_mean 1497.1987 (1493.3723) lr 4.6417e-04 eta 0:04:12
epoch [36/50] batch [120/132] time 0.164 (0.131) data 0.000 (0.003) loss 1.2104 (1.2722) teacher_loss 0.0705 (0.0860) loss_zs_kd 0.0102 (0.0156) loss_oracle 0.5617 (0.6211) kd_loss 0.8539 (0.8679) acc 100.0000 (96.9531) gate/entropy 1.0285 (1.0287) gate/usage_max 0.4178 (0.4171) gate/usage_min 0.1670 (0.1672) gate/usage_std 0.1176 (0.1175) teacher/entropy 0.0891 (0.0700) teacher/usage_max 0.5947 (0.6258) teacher/usage_min 0.0744 (0.0684) teacher/usage_std 0.2124 (0.2341) nleep/row_max_mean 1514.5881 (1517.7364) nleep/row_max_std 48.4127 (40.7482) nleep/row_min_mean 1489.8999 (1494.1328) lr 4.6417e-04 eta 0:04:03
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,530
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.0%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [37/50] batch [20/132] time 0.084 (0.126) data 0.000 (0.013) loss 1.2403 (1.3055) teacher_loss 0.0262 (0.0770) loss_zs_kd 0.0149 (0.0173) loss_oracle 0.6350 (0.6344) kd_loss 0.8892 (0.9027) acc 100.0000 (97.8125) gate/entropy 1.0288 (1.0285) gate/usage_max 0.4178 (0.4180) gate/usage_min 0.1674 (0.1671) gate/usage_std 0.1174 (0.1176) teacher/entropy 0.1217 (0.0827) teacher/usage_max 0.4651 (0.5589) teacher/usage_min 0.1474 (0.1208) teacher/usage_std 0.1352 (0.1866) nleep/row_max_mean 1518.0527 (1516.9040) nleep/row_max_std 34.2895 (35.1553) nleep/row_min_mean 1497.0172 (1493.6947) lr 4.1221e-04 eta 0:03:49
epoch [37/50] batch [40/132] time 0.168 (0.134) data 0.000 (0.007) loss 1.2100 (1.2946) teacher_loss 0.0631 (0.0773) loss_zs_kd 0.0219 (0.0202) loss_oracle 0.5693 (0.6268) kd_loss 0.8514 (0.8937) acc 96.8750 (97.7344) gate/entropy 1.0287 (1.0286) gate/usage_max 0.4180 (0.4180) gate/usage_min 0.1672 (0.1671) gate/usage_std 0.1175 (0.1176) teacher/entropy 0.1092 (0.0832) teacher/usage_max 0.5828 (0.5547) teacher/usage_min 0.0943 (0.1104) teacher/usage_std 0.1995 (0.1891) nleep/row_max_mean 1519.4553 (1515.8166) nleep/row_max_std 44.6606 (35.9786) nleep/row_min_mean 1493.3328 (1492.0828) lr 4.1221e-04 eta 0:04:02
epoch [37/50] batch [60/132] time 0.140 (0.143) data 0.000 (0.005) loss 1.2351 (1.2985) teacher_loss 0.0186 (0.0875) loss_zs_kd 0.0130 (0.0190) loss_oracle 0.5976 (0.6215) kd_loss 0.9112 (0.8907) acc 100.0000 (97.2396) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4184 (0.4181) gate/usage_min 0.1670 (0.1671) gate/usage_std 0.1177 (0.1176) teacher/entropy 0.0744 (0.0820) teacher/usage_max 0.4947 (0.5494) teacher/usage_min 0.1207 (0.1061) teacher/usage_std 0.1570 (0.1877) nleep/row_max_mean 1527.9664 (1516.7919) nleep/row_max_std 38.6897 (37.3947) nleep/row_min_mean 1502.3145 (1492.4491) lr 4.1221e-04 eta 0:04:16
epoch [37/50] batch [80/132] time 0.159 (0.146) data 0.000 (0.004) loss 1.3961 (1.3030) teacher_loss 0.1031 (0.0940) loss_zs_kd 0.0133 (0.0181) loss_oracle 0.6716 (0.6192) kd_loss 0.9506 (0.8903) acc 96.8750 (96.9922) gate/entropy 1.0287 (1.0285) gate/usage_max 0.4183 (0.4182) gate/usage_min 0.1672 (0.1671) gate/usage_std 0.1175 (0.1176) teacher/entropy 0.0603 (0.0798) teacher/usage_max 0.5190 (0.5560) teacher/usage_min 0.1484 (0.1036) teacher/usage_std 0.1513 (0.1913) nleep/row_max_mean 1506.7662 (1516.4283) nleep/row_max_std 48.1570 (38.3577) nleep/row_min_mean 1483.1925 (1492.0458) lr 4.1221e-04 eta 0:04:17
epoch [37/50] batch [100/132] time 0.156 (0.150) data 0.000 (0.003) loss 1.3026 (1.3019) teacher_loss 0.0751 (0.0947) loss_zs_kd 0.0262 (0.0175) loss_oracle 0.5909 (0.6188) kd_loss 0.9190 (0.8891) acc 100.0000 (96.9375) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4187 (0.4182) gate/usage_min 0.1669 (0.1670) gate/usage_std 0.1177 (0.1176) teacher/entropy 0.0759 (0.0807) teacher/usage_max 0.4552 (0.5603) teacher/usage_min 0.1312 (0.1035) teacher/usage_std 0.1439 (0.1934) nleep/row_max_mean 1525.3876 (1516.3420) nleep/row_max_std 40.4464 (38.9619) nleep/row_min_mean 1498.5959 (1491.9586) lr 4.1221e-04 eta 0:04:21
epoch [37/50] batch [120/132] time 0.162 (0.152) data 0.000 (0.002) loss 1.2393 (1.3064) teacher_loss 0.0689 (0.1009) loss_zs_kd 0.0186 (0.0181) loss_oracle 0.6690 (0.6165) kd_loss 0.8266 (0.8881) acc 96.8750 (96.7448) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4189 (0.4183) gate/usage_min 0.1670 (0.1670) gate/usage_std 0.1177 (0.1176) teacher/entropy 0.0709 (0.0800) teacher/usage_max 0.7327 (0.5655) teacher/usage_min 0.0268 (0.1019) teacher/usage_std 0.2955 (0.1964) nleep/row_max_mean 1512.0984 (1515.8866) nleep/row_max_std 41.3674 (39.1854) nleep/row_min_mean 1487.4363 (1491.4694) lr 4.1221e-04 eta 0:04:22
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,494
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 91.5%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [38/50] batch [20/132] time 0.077 (0.129) data 0.000 (0.014) loss 1.2075 (1.2900) teacher_loss 0.0463 (0.0978) loss_zs_kd 0.0132 (0.0186) loss_oracle 0.5149 (0.6015) kd_loss 0.8972 (0.8821) acc 96.8750 (96.0938) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4190 (0.4189) gate/usage_min 0.1670 (0.1670) gate/usage_std 0.1176 (0.1176) teacher/entropy 0.1030 (0.0685) teacher/usage_max 0.4852 (0.5738) teacher/usage_min 0.1358 (0.0834) teacher/usage_std 0.1462 (0.2062) nleep/row_max_mean 1520.7177 (1511.8920) nleep/row_max_std 29.8743 (38.1560) nleep/row_min_mean 1494.5430 (1486.1401) lr 3.6258e-04 eta 0:03:39
epoch [38/50] batch [40/132] time 0.075 (0.120) data 0.000 (0.007) loss 1.2437 (1.2950) teacher_loss 0.0288 (0.0971) loss_zs_kd 0.0214 (0.0201) loss_oracle 0.6256 (0.6104) kd_loss 0.8914 (0.8827) acc 100.0000 (96.5625) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4192 (0.4190) gate/usage_min 0.1669 (0.1669) gate/usage_std 0.1177 (0.1177) teacher/entropy 0.0553 (0.0598) teacher/usage_max 0.5307 (0.5934) teacher/usage_min 0.0786 (0.0749) teacher/usage_std 0.1890 (0.2176) nleep/row_max_mean 1527.3406 (1513.5211) nleep/row_max_std 33.3583 (39.2422) nleep/row_min_mean 1498.0392 (1487.6517) lr 3.6258e-04 eta 0:03:21
epoch [38/50] batch [60/132] time 0.157 (0.118) data 0.000 (0.005) loss 1.2807 (1.2928) teacher_loss 0.1442 (0.0924) loss_zs_kd 0.0057 (0.0186) loss_oracle 0.5585 (0.6076) kd_loss 0.8543 (0.8874) acc 93.7500 (96.5625) gate/entropy 1.0281 (1.0284) gate/usage_max 0.4196 (0.4191) gate/usage_min 0.1666 (0.1669) gate/usage_std 0.1179 (0.1177) teacher/entropy 0.0777 (0.0567) teacher/usage_max 0.4726 (0.5921) teacher/usage_min 0.0622 (0.0767) teacher/usage_std 0.1917 (0.2173) nleep/row_max_mean 1525.3672 (1514.3295) nleep/row_max_std 38.3542 (41.3112) nleep/row_min_mean 1496.6533 (1488.1072) lr 3.6258e-04 eta 0:03:15
epoch [38/50] batch [80/132] time 0.065 (0.117) data 0.000 (0.004) loss 1.2100 (1.2893) teacher_loss 0.0206 (0.0940) loss_zs_kd 0.0018 (0.0187) loss_oracle 0.5940 (0.6022) kd_loss 0.8915 (0.8848) acc 100.0000 (96.5234) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4194 (0.4192) gate/usage_min 0.1670 (0.1669) gate/usage_std 0.1177 (0.1177) teacher/entropy 0.0896 (0.0628) teacher/usage_max 0.5220 (0.5819) teacher/usage_min 0.1170 (0.0805) teacher/usage_std 0.1665 (0.2118) nleep/row_max_mean 1523.6306 (1515.2411) nleep/row_max_std 39.8870 (40.7846) nleep/row_min_mean 1494.9990 (1489.0313) lr 3.6258e-04 eta 0:03:10
epoch [38/50] batch [100/132] time 0.099 (0.112) data 0.000 (0.003) loss 1.2987 (1.2845) teacher_loss 0.1631 (0.0924) loss_zs_kd 0.0331 (0.0194) loss_oracle 0.5603 (0.6013) kd_loss 0.8388 (0.8818) acc 93.7500 (96.6250) gate/entropy 1.0283 (1.0284) gate/usage_max 0.4196 (0.4193) gate/usage_min 0.1668 (0.1669) gate/usage_std 0.1178 (0.1177) teacher/entropy 0.0966 (0.0682) teacher/usage_max 0.6691 (0.5773) teacher/usage_min 0.0692 (0.0831) teacher/usage_std 0.2501 (0.2089) nleep/row_max_mean 1510.3167 (1514.2024) nleep/row_max_std 43.6578 (41.1898) nleep/row_min_mean 1485.3619 (1488.1404) lr 3.6258e-04 eta 0:03:01
epoch [38/50] batch [120/132] time 0.072 (0.112) data 0.000 (0.003) loss 1.1902 (1.2822) teacher_loss 0.0172 (0.0915) loss_zs_kd 0.0213 (0.0189) loss_oracle 0.5113 (0.5974) kd_loss 0.9067 (0.8825) acc 100.0000 (96.7448) gate/entropy 1.0283 (1.0284) gate/usage_max 0.4196 (0.4193) gate/usage_min 0.1669 (0.1669) gate/usage_std 0.1177 (0.1177) teacher/entropy 0.0611 (0.0702) teacher/usage_max 0.5341 (0.5690) teacher/usage_min 0.0998 (0.0859) teacher/usage_std 0.1788 (0.2041) nleep/row_max_mean 1517.1058 (1514.2035) nleep/row_max_std 41.8649 (41.2792) nleep/row_min_mean 1488.1208 (1488.1674) lr 3.6258e-04 eta 0:02:58
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [39/50] batch [20/132] time 0.144 (0.179) data 0.000 (0.015) loss 1.2340 (1.2372) teacher_loss 0.0350 (0.0724) loss_zs_kd 0.0137 (0.0161) loss_oracle 0.6020 (0.5886) kd_loss 0.8912 (0.8625) acc 100.0000 (97.5000) gate/entropy 1.0284 (1.0283) gate/usage_max 0.4197 (0.4198) gate/usage_min 0.1669 (0.1668) gate/usage_std 0.1177 (0.1178) teacher/entropy 0.1669 (0.1091) teacher/usage_max 0.4485 (0.5205) teacher/usage_min 0.1991 (0.1060) teacher/usage_std 0.1027 (0.1757) nleep/row_max_mean 1521.7231 (1522.5314) nleep/row_max_std 44.2954 (41.1174) nleep/row_min_mean 1496.6958 (1496.0914) lr 3.1545e-04 eta 0:04:39
epoch [39/50] batch [40/132] time 0.151 (0.169) data 0.000 (0.008) loss 1.2700 (1.2620) teacher_loss 0.1299 (0.0814) loss_zs_kd 0.0191 (0.0163) loss_oracle 0.6051 (0.5901) kd_loss 0.8280 (0.8774) acc 96.8750 (97.2656) gate/entropy 1.0280 (1.0283) gate/usage_max 0.4201 (0.4198) gate/usage_min 0.1665 (0.1668) gate/usage_std 0.1180 (0.1178) teacher/entropy 0.1158 (0.0996) teacher/usage_max 0.5520 (0.5217) teacher/usage_min 0.0763 (0.1120) teacher/usage_std 0.1961 (0.1734) nleep/row_max_mean 1526.8450 (1520.6955) nleep/row_max_std 42.0668 (40.6543) nleep/row_min_mean 1497.2144 (1493.9541) lr 3.1545e-04 eta 0:04:21
epoch [39/50] batch [60/132] time 0.163 (0.165) data 0.000 (0.005) loss 1.1608 (1.2654) teacher_loss 0.0687 (0.0841) loss_zs_kd 0.0099 (0.0163) loss_oracle 0.6098 (0.5975) kd_loss 0.7823 (0.8744) acc 96.8750 (97.1354) gate/entropy 1.0285 (1.0283) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1670 (0.1668) gate/usage_std 0.1177 (0.1178) teacher/entropy 0.1561 (0.1022) teacher/usage_max 0.5154 (0.5207) teacher/usage_min 0.0694 (0.1113) teacher/usage_std 0.1911 (0.1736) nleep/row_max_mean 1518.0071 (1520.6731) nleep/row_max_std 44.9906 (41.1217) nleep/row_min_mean 1489.8199 (1493.7968) lr 3.1545e-04 eta 0:04:10
epoch [39/50] batch [80/132] time 0.157 (0.162) data 0.000 (0.004) loss 1.1921 (1.2686) teacher_loss 0.0083 (0.0833) loss_zs_kd 0.0019 (0.0163) loss_oracle 0.6221 (0.5933) kd_loss 0.8718 (0.8805) acc 100.0000 (97.1484) gate/entropy 1.0284 (1.0283) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1670 (0.1668) gate/usage_std 0.1177 (0.1178) teacher/entropy 0.1717 (0.1030) teacher/usage_max 0.4847 (0.5134) teacher/usage_min 0.1858 (0.1189) teacher/usage_std 0.1220 (0.1675) nleep/row_max_mean 1519.6786 (1520.7558) nleep/row_max_std 30.8320 (40.7641) nleep/row_min_mean 1495.6575 (1493.9012) lr 3.1545e-04 eta 0:04:04
epoch [39/50] batch [100/132] time 0.165 (0.162) data 0.000 (0.003) loss 1.1810 (1.2684) teacher_loss 0.1191 (0.0899) loss_zs_kd 0.0154 (0.0174) loss_oracle 0.4920 (0.5894) kd_loss 0.8082 (0.8751) acc 96.8750 (97.0625) gate/entropy 1.0281 (1.0283) gate/usage_max 0.4202 (0.4199) gate/usage_min 0.1666 (0.1668) gate/usage_std 0.1179 (0.1178) teacher/entropy 0.1436 (0.1066) teacher/usage_max 0.4758 (0.5149) teacher/usage_min 0.0828 (0.1168) teacher/usage_std 0.1777 (0.1691) nleep/row_max_mean 1523.9971 (1520.1376) nleep/row_max_std 38.1229 (40.6623) nleep/row_min_mean 1502.8362 (1493.4078) lr 3.1545e-04 eta 0:04:00
epoch [39/50] batch [120/132] time 0.137 (0.161) data 0.000 (0.003) loss 1.1834 (1.2725) teacher_loss 0.0685 (0.0918) loss_zs_kd 0.0078 (0.0175) loss_oracle 0.5104 (0.5858) kd_loss 0.8558 (0.8790) acc 96.8750 (96.8229) gate/entropy 1.0281 (1.0283) gate/usage_max 0.4202 (0.4199) gate/usage_min 0.1666 (0.1668) gate/usage_std 0.1179 (0.1178) teacher/entropy 0.1490 (0.1067) teacher/usage_max 0.4662 (0.5114) teacher/usage_min 0.1411 (0.1211) teacher/usage_std 0.1392 (0.1660) nleep/row_max_mean 1529.3333 (1519.4860) nleep/row_max_std 44.3877 (40.3979) nleep/row_min_mean 1503.2825 (1492.8222) lr 3.1545e-04 eta 0:03:55
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,501
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.7%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [40/50] batch [20/132] time 0.100 (0.146) data 0.000 (0.015) loss 1.2514 (1.2594) teacher_loss 0.0489 (0.0774) loss_zs_kd 0.0173 (0.0162) loss_oracle 0.6369 (0.5895) kd_loss 0.8754 (0.8792) acc 96.8750 (97.5000) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4202 (0.4202) gate/usage_min 0.1668 (0.1668) gate/usage_std 0.1178 (0.1178) teacher/entropy 0.1020 (0.1044) teacher/usage_max 0.5910 (0.5077) teacher/usage_min 0.1152 (0.1193) teacher/usage_std 0.1963 (0.1657) nleep/row_max_mean 1512.6451 (1516.4384) nleep/row_max_std 43.4151 (39.9701) nleep/row_min_mean 1485.8802 (1490.3853) lr 2.7103e-04 eta 0:03:28
epoch [40/50] batch [40/132] time 0.197 (0.129) data 0.000 (0.008) loss 1.2361 (1.2816) teacher_loss 0.0067 (0.0866) loss_zs_kd 0.0071 (0.0190) loss_oracle 0.5381 (0.5922) kd_loss 0.9568 (0.8894) acc 100.0000 (97.1875) gate/entropy 1.0283 (1.0282) gate/usage_max 0.4202 (0.4202) gate/usage_min 0.1669 (0.1668) gate/usage_std 0.1178 (0.1178) teacher/entropy 0.0938 (0.0968) teacher/usage_max 0.4323 (0.5035) teacher/usage_min 0.1915 (0.1219) teacher/usage_std 0.1029 (0.1634) nleep/row_max_mean 1528.5759 (1515.9347) nleep/row_max_std 40.6183 (40.0573) nleep/row_min_mean 1500.3005 (1489.3657) lr 2.7103e-04 eta 0:03:02
epoch [40/50] batch [60/132] time 0.169 (0.128) data 0.000 (0.005) loss 1.3332 (1.2773) teacher_loss 0.1019 (0.0852) loss_zs_kd 0.0272 (0.0182) loss_oracle 0.5583 (0.5889) kd_loss 0.9385 (0.8886) acc 96.8750 (97.1354) gate/entropy 1.0281 (1.0283) gate/usage_max 0.4204 (0.4202) gate/usage_min 0.1666 (0.1668) gate/usage_std 0.1179 (0.1178) teacher/entropy 0.1309 (0.0950) teacher/usage_max 0.4905 (0.5042) teacher/usage_min 0.2141 (0.1190) teacher/usage_std 0.1160 (0.1649) nleep/row_max_mean 1512.5988 (1516.6476) nleep/row_max_std 39.0612 (39.2683) nleep/row_min_mean 1486.5343 (1490.0765) lr 2.7103e-04 eta 0:02:57
epoch [40/50] batch [80/132] time 0.067 (0.126) data 0.000 (0.004) loss 1.3095 (1.2719) teacher_loss 0.1011 (0.0809) loss_zs_kd 0.0193 (0.0177) loss_oracle 0.5732 (0.5866) kd_loss 0.9121 (0.8888) acc 93.7500 (97.3438) gate/entropy 1.0280 (1.0282) gate/usage_max 0.4206 (0.4203) gate/usage_min 0.1665 (0.1668) gate/usage_std 0.1180 (0.1178) teacher/entropy 0.0551 (0.0906) teacher/usage_max 0.5503 (0.5076) teacher/usage_min 0.1027 (0.1146) teacher/usage_std 0.1830 (0.1676) nleep/row_max_mean 1528.3079 (1517.9464) nleep/row_max_std 35.7620 (38.8945) nleep/row_min_mean 1502.7942 (1491.0332) lr 2.7103e-04 eta 0:02:52
epoch [40/50] batch [100/132] time 0.164 (0.125) data 0.000 (0.003) loss 1.2119 (1.2649) teacher_loss 0.0113 (0.0772) loss_zs_kd 0.0235 (0.0173) loss_oracle 0.5849 (0.5846) kd_loss 0.8964 (0.8867) acc 100.0000 (97.4688) gate/entropy 1.0284 (1.0282) gate/usage_max 0.4203 (0.4203) gate/usage_min 0.1669 (0.1668) gate/usage_std 0.1177 (0.1178) teacher/entropy 0.0425 (0.0885) teacher/usage_max 0.4722 (0.5058) teacher/usage_min 0.0694 (0.1099) teacher/usage_std 0.1867 (0.1697) nleep/row_max_mean 1522.2802 (1518.8414) nleep/row_max_std 35.0583 (38.5820) nleep/row_min_mean 1493.3147 (1491.6982) lr 2.7103e-04 eta 0:02:49
epoch [40/50] batch [120/132] time 0.151 (0.131) data 0.000 (0.003) loss 1.3661 (1.2660) teacher_loss 0.0712 (0.0796) loss_zs_kd 0.0204 (0.0175) loss_oracle 0.6281 (0.5834) kd_loss 0.9707 (0.8859) acc 96.8750 (97.2656) gate/entropy 1.0285 (1.0282) gate/usage_max 0.4203 (0.4203) gate/usage_min 0.1670 (0.1668) gate/usage_std 0.1177 (0.1178) teacher/entropy 0.0466 (0.0855) teacher/usage_max 0.4241 (0.5093) teacher/usage_min 0.1555 (0.1057) teacher/usage_std 0.1258 (0.1727) nleep/row_max_mean 1518.8672 (1519.3502) nleep/row_max_std 30.7008 (38.2499) nleep/row_min_mean 1492.4236 (1491.9433) lr 2.7103e-04 eta 0:02:54
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,502
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.7%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 88.7%, epoch: 16 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [41/50] batch [20/132] time 0.165 (0.165) data 0.000 (0.015) loss 1.2641 (1.2672) teacher_loss 0.0666 (0.0719) loss_zs_kd 0.0089 (0.0174) loss_oracle 0.5391 (0.5599) kd_loss 0.9235 (0.9067) acc 96.8750 (96.8750) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4206 (0.4205) gate/usage_min 0.1666 (0.1668) gate/usage_std 0.1179 (0.1178) teacher/entropy 0.0086 (0.0562) teacher/usage_max 0.5000 (0.5183) teacher/usage_min 0.0630 (0.0964) teacher/usage_std 0.1929 (0.1805) nleep/row_max_mean 1521.6064 (1521.0749) nleep/row_max_std 36.0319 (40.0928) nleep/row_min_mean 1490.7690 (1492.2388) lr 2.2949e-04 eta 0:03:33
epoch [41/50] batch [40/132] time 0.139 (0.155) data 0.000 (0.007) loss 1.2805 (1.2676) teacher_loss 0.0620 (0.0840) loss_zs_kd 0.0103 (0.0200) loss_oracle 0.5595 (0.5567) kd_loss 0.9336 (0.8952) acc 100.0000 (96.7188) gate/entropy 1.0283 (1.0282) gate/usage_max 0.4205 (0.4205) gate/usage_min 0.1668 (0.1667) gate/usage_std 0.1178 (0.1178) teacher/entropy 0.0254 (0.0571) teacher/usage_max 0.4986 (0.5255) teacher/usage_min 0.0924 (0.0848) teacher/usage_std 0.1742 (0.1876) nleep/row_max_mean 1522.2761 (1520.9716) nleep/row_max_std 45.1717 (40.5564) nleep/row_min_mean 1493.1870 (1491.8360) lr 2.2949e-04 eta 0:03:18
epoch [41/50] batch [60/132] time 0.154 (0.153) data 0.001 (0.005) loss 1.3712 (1.2709) teacher_loss 0.1811 (0.0815) loss_zs_kd 0.0223 (0.0184) loss_oracle 0.6134 (0.5599) kd_loss 0.8723 (0.9003) acc 90.6250 (97.0312) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4207 (0.4205) gate/usage_min 0.1666 (0.1667) gate/usage_std 0.1179 (0.1178) teacher/entropy 0.0398 (0.0602) teacher/usage_max 0.5854 (0.5197) teacher/usage_min 0.0428 (0.0937) teacher/usage_std 0.2232 (0.1811) nleep/row_max_mean 1497.3176 (1520.1053) nleep/row_max_std 36.6217 (40.4220) nleep/row_min_mean 1474.1289 (1491.2878) lr 2.2949e-04 eta 0:03:13
epoch [41/50] batch [80/132] time 0.071 (0.151) data 0.000 (0.004) loss 1.1991 (1.2673) teacher_loss 0.0024 (0.0813) loss_zs_kd 0.0054 (0.0185) loss_oracle 0.5271 (0.5547) kd_loss 0.9304 (0.8994) acc 100.0000 (97.0703) gate/entropy 1.0283 (1.0282) gate/usage_max 0.4206 (0.4206) gate/usage_min 0.1668 (0.1667) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.0709 (0.0632) teacher/usage_max 0.4386 (0.5227) teacher/usage_min 0.1378 (0.0960) teacher/usage_std 0.1384 (0.1813) nleep/row_max_mean 1509.0442 (1519.1465) nleep/row_max_std 39.6618 (39.4552) nleep/row_min_mean 1482.1095 (1490.4946) lr 2.2949e-04 eta 0:03:07
epoch [41/50] batch [100/132] time 0.104 (0.137) data 0.000 (0.003) loss 1.2907 (1.2669) teacher_loss 0.1180 (0.0851) loss_zs_kd 0.0230 (0.0183) loss_oracle 0.5786 (0.5540) kd_loss 0.8719 (0.8956) acc 93.7500 (96.8750) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4206 (0.4206) gate/usage_min 0.1667 (0.1667) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0999 (0.0633) teacher/usage_max 0.5392 (0.5237) teacher/usage_min 0.1036 (0.0918) teacher/usage_std 0.1786 (0.1835) nleep/row_max_mean 1516.2489 (1517.6070) nleep/row_max_std 31.7947 (39.4875) nleep/row_min_mean 1487.1589 (1489.0139) lr 2.2949e-04 eta 0:02:47
epoch [41/50] batch [120/132] time 0.073 (0.134) data 0.000 (0.003) loss 1.2815 (1.2667) teacher_loss 0.0780 (0.0859) loss_zs_kd 0.0387 (0.0183) loss_oracle 0.5282 (0.5505) kd_loss 0.9200 (0.8963) acc 96.8750 (96.7969) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4207 (0.4206) gate/usage_min 0.1667 (0.1667) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0418 (0.0635) teacher/usage_max 0.5190 (0.5209) teacher/usage_min 0.0937 (0.0927) teacher/usage_std 0.1778 (0.1821) nleep/row_max_mean 1498.9521 (1516.7982) nleep/row_max_std 38.3224 (39.1104) nleep/row_min_mean 1470.1401 (1488.4260) lr 2.2949e-04 eta 0:02:40
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,514
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 41 *******
******* Domain s best val test acc: 89.5%, epoch: 41 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [42/50] batch [20/132] time 0.159 (0.128) data 0.000 (0.016) loss 1.4005 (1.3157) teacher_loss 0.1172 (0.1181) loss_zs_kd 0.0291 (0.0218) loss_oracle 0.5637 (0.5475) kd_loss 0.9869 (0.9130) acc 96.8750 (95.6250) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4207 (0.4208) gate/usage_min 0.1668 (0.1666) gate/usage_std 0.1178 (0.1180) teacher/entropy 0.0033 (0.0566) teacher/usage_max 0.4692 (0.5045) teacher/usage_min 0.1248 (0.1014) teacher/usage_std 0.1497 (0.1748) nleep/row_max_mean 1516.3582 (1518.9296) nleep/row_max_std 35.1315 (36.7000) nleep/row_min_mean 1486.2952 (1490.1004) lr 1.9098e-04 eta 0:02:29
epoch [42/50] batch [40/132] time 0.168 (0.120) data 0.000 (0.008) loss 1.2920 (1.2726) teacher_loss 0.1013 (0.0899) loss_zs_kd 0.0324 (0.0202) loss_oracle 0.6143 (0.5440) kd_loss 0.8674 (0.9007) acc 96.8750 (96.6406) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4208 (0.4208) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0410 (0.0610) teacher/usage_max 0.5865 (0.5236) teacher/usage_min 0.0383 (0.0939) teacher/usage_std 0.2257 (0.1842) nleep/row_max_mean 1504.9978 (1516.5653) nleep/row_max_std 36.4241 (37.2981) nleep/row_min_mean 1478.6733 (1488.2385) lr 1.9098e-04 eta 0:02:17
epoch [42/50] batch [60/132] time 0.083 (0.112) data 0.000 (0.005) loss 1.2266 (1.2692) teacher_loss 0.0532 (0.0846) loss_zs_kd 0.0084 (0.0180) loss_oracle 0.6027 (0.5458) kd_loss 0.8678 (0.9027) acc 96.8750 (96.9792) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4207 (0.4208) gate/usage_min 0.1668 (0.1666) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.0558 (0.0603) teacher/usage_max 0.5073 (0.5210) teacher/usage_min 0.0521 (0.0957) teacher/usage_std 0.2007 (0.1828) nleep/row_max_mean 1510.2983 (1516.6023) nleep/row_max_std 39.5779 (37.1957) nleep/row_min_mean 1480.9189 (1488.1033) lr 1.9098e-04 eta 0:02:05
epoch [42/50] batch [80/132] time 0.171 (0.116) data 0.000 (0.004) loss 1.1408 (1.2743) teacher_loss 0.0069 (0.0850) loss_zs_kd 0.0094 (0.0181) loss_oracle 0.5264 (0.5516) kd_loss 0.8660 (0.9045) acc 100.0000 (96.9531) gate/entropy 1.0283 (1.0281) gate/usage_max 0.4207 (0.4208) gate/usage_min 0.1668 (0.1667) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.0510 (0.0586) teacher/usage_max 0.4931 (0.5163) teacher/usage_min 0.0456 (0.0960) teacher/usage_std 0.2039 (0.1814) nleep/row_max_mean 1510.9634 (1515.1808) nleep/row_max_std 42.2210 (37.6981) nleep/row_min_mean 1485.2064 (1486.5971) lr 1.9098e-04 eta 0:02:08
epoch [42/50] batch [100/132] time 0.167 (0.123) data 0.000 (0.003) loss 1.2394 (1.2773) teacher_loss 0.1610 (0.0881) loss_zs_kd 0.0133 (0.0182) loss_oracle 0.4125 (0.5495) kd_loss 0.8655 (0.9054) acc 96.8750 (96.9375) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4209 (0.4208) gate/usage_min 0.1666 (0.1667) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0543 (0.0591) teacher/usage_max 0.5516 (0.5144) teacher/usage_min 0.0509 (0.0975) teacher/usage_std 0.2094 (0.1794) nleep/row_max_mean 1508.6959 (1515.5220) nleep/row_max_std 49.7531 (37.6516) nleep/row_min_mean 1483.2637 (1486.7933) lr 1.9098e-04 eta 0:02:13
epoch [42/50] batch [120/132] time 0.160 (0.130) data 0.000 (0.003) loss 1.4542 (1.2767) teacher_loss 0.1463 (0.0865) loss_zs_kd 0.0350 (0.0192) loss_oracle 0.6370 (0.5520) kd_loss 0.9719 (0.9046) acc 96.8750 (96.9792) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4209 (0.4208) gate/usage_min 0.1667 (0.1667) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0716 (0.0623) teacher/usage_max 0.4193 (0.5167) teacher/usage_min 0.1848 (0.1003) teacher/usage_std 0.1055 (0.1785) nleep/row_max_mean 1528.0593 (1515.4099) nleep/row_max_std 20.3088 (37.4765) nleep/row_min_mean 1494.9684 (1486.7188) lr 1.9098e-04 eta 0:02:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,814
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,498
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.7%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [43/50] batch [20/132] time 0.131 (0.160) data 0.000 (0.014) loss 1.3998 (1.2993) teacher_loss 0.1682 (0.1092) loss_zs_kd 0.0220 (0.0193) loss_oracle 0.5608 (0.5515) kd_loss 0.9403 (0.9046) acc 93.7500 (95.7812) gate/entropy 1.0278 (1.0281) gate/usage_max 0.4212 (0.4209) gate/usage_min 0.1663 (0.1666) gate/usage_std 0.1182 (0.1180) teacher/entropy 0.0842 (0.0809) teacher/usage_max 0.4406 (0.5132) teacher/usage_min 0.1633 (0.1207) teacher/usage_std 0.1216 (0.1656) nleep/row_max_mean 1519.2175 (1518.6079) nleep/row_max_std 51.1497 (39.4979) nleep/row_min_mean 1485.5645 (1488.9331) lr 1.5567e-04 eta 0:02:45
epoch [43/50] batch [40/132] time 0.153 (0.155) data 0.000 (0.007) loss 1.3269 (1.2903) teacher_loss 0.0603 (0.0953) loss_zs_kd 0.0184 (0.0191) loss_oracle 0.5839 (0.5612) kd_loss 0.9655 (0.9049) acc 100.0000 (96.6406) gate/entropy 1.0283 (1.0281) gate/usage_max 0.4207 (0.4209) gate/usage_min 0.1669 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.0610 (0.0797) teacher/usage_max 0.4355 (0.5073) teacher/usage_min 0.1650 (0.1195) teacher/usage_std 0.1200 (0.1647) nleep/row_max_mean 1493.7731 (1517.1329) nleep/row_max_std 46.8752 (40.9456) nleep/row_min_mean 1464.3556 (1487.0899) lr 1.5567e-04 eta 0:02:37
epoch [43/50] batch [60/132] time 0.101 (0.134) data 0.000 (0.005) loss 1.2075 (1.2780) teacher_loss 0.0266 (0.0851) loss_zs_kd 0.0075 (0.0194) loss_oracle 0.6102 (0.5625) kd_loss 0.8719 (0.9019) acc 96.8750 (96.9271) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4208 (0.4209) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0520 (0.0802) teacher/usage_max 0.4844 (0.5085) teacher/usage_min 0.0533 (0.1166) teacher/usage_std 0.1982 (0.1665) nleep/row_max_mean 1518.9832 (1517.3191) nleep/row_max_std 42.2054 (40.9204) nleep/row_min_mean 1489.4155 (1486.9871) lr 1.5567e-04 eta 0:02:13
epoch [43/50] batch [80/132] time 0.091 (0.130) data 0.000 (0.004) loss 1.1317 (1.2776) teacher_loss 0.0131 (0.0849) loss_zs_kd 0.0135 (0.0194) loss_oracle 0.4448 (0.5582) kd_loss 0.8894 (0.9040) acc 100.0000 (97.1094) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4208 (0.4209) gate/usage_min 0.1668 (0.1666) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.0701 (0.0780) teacher/usage_max 0.5372 (0.5032) teacher/usage_min 0.0895 (0.1160) teacher/usage_std 0.1849 (0.1659) nleep/row_max_mean 1520.1416 (1517.0089) nleep/row_max_std 44.7564 (41.4114) nleep/row_min_mean 1488.6013 (1486.4947) lr 1.5567e-04 eta 0:02:07
epoch [43/50] batch [100/132] time 0.091 (0.126) data 0.000 (0.003) loss 1.1148 (1.2692) teacher_loss 0.0297 (0.0834) loss_zs_kd 0.0060 (0.0192) loss_oracle 0.5260 (0.5533) kd_loss 0.8191 (0.8996) acc 100.0000 (97.1562) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4209) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0758 (0.0800) teacher/usage_max 0.5466 (0.5060) teacher/usage_min 0.0229 (0.1135) teacher/usage_std 0.2246 (0.1679) nleep/row_max_mean 1511.4624 (1517.5353) nleep/row_max_std 40.0202 (41.4594) nleep/row_min_mean 1483.9050 (1486.8826) lr 1.5567e-04 eta 0:02:00
epoch [43/50] batch [120/132] time 0.075 (0.125) data 0.000 (0.002) loss 1.2325 (1.2740) teacher_loss 0.1005 (0.0845) loss_zs_kd 0.0207 (0.0194) loss_oracle 0.4882 (0.5515) kd_loss 0.8776 (0.9040) acc 96.8750 (97.1094) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4208 (0.4209) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0702 (0.0794) teacher/usage_max 0.6110 (0.5078) teacher/usage_min 0.0764 (0.1173) teacher/usage_std 0.2187 (0.1672) nleep/row_max_mean 1514.2028 (1517.1757) nleep/row_max_std 43.6657 (41.0952) nleep/row_min_mean 1480.6714 (1486.2930) lr 1.5567e-04 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,503
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [44/50] batch [20/132] time 0.134 (0.141) data 0.000 (0.018) loss 1.2848 (1.2712) teacher_loss 0.1177 (0.0989) loss_zs_kd 0.0312 (0.0184) loss_oracle 0.4880 (0.5277) kd_loss 0.9075 (0.8993) acc 93.7500 (96.5625) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4211 (0.4209) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.0758 (0.0781) teacher/usage_max 0.4592 (0.5061) teacher/usage_min 0.1183 (0.1112) teacher/usage_std 0.1528 (0.1701) nleep/row_max_mean 1519.7507 (1516.0970) nleep/row_max_std 33.8142 (37.8520) nleep/row_min_mean 1488.6687 (1485.9990) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [40/132] time 0.166 (0.148) data 0.000 (0.009) loss 1.3358 (1.2820) teacher_loss 0.0876 (0.0897) loss_zs_kd 0.0113 (0.0188) loss_oracle 0.5836 (0.5312) kd_loss 0.9508 (0.9173) acc 93.7500 (96.7969) gate/entropy 1.0284 (1.0281) gate/usage_max 0.4207 (0.4209) gate/usage_min 0.1669 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.0499 (0.0790) teacher/usage_max 0.5216 (0.5044) teacher/usage_min 0.1351 (0.1317) teacher/usage_std 0.1579 (0.1600) nleep/row_max_mean 1511.2981 (1517.5031) nleep/row_max_std 39.1659 (37.3907) nleep/row_min_mean 1478.9141 (1486.4529) lr 1.2369e-04 eta 0:02:10
epoch [44/50] batch [60/132] time 0.163 (0.154) data 0.000 (0.006) loss 1.2551 (1.2735) teacher_loss 0.0489 (0.0824) loss_zs_kd 0.0040 (0.0185) loss_oracle 0.5509 (0.5355) kd_loss 0.9288 (0.9141) acc 100.0000 (97.0833) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4209) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0611 (0.0809) teacher/usage_max 0.5801 (0.5125) teacher/usage_min 0.1288 (0.1302) teacher/usage_std 0.1866 (0.1633) nleep/row_max_mean 1512.7727 (1517.4622) nleep/row_max_std 45.4980 (37.6557) nleep/row_min_mean 1485.3726 (1486.5730) lr 1.2369e-04 eta 0:02:12
epoch [44/50] batch [80/132] time 0.154 (0.155) data 0.000 (0.005) loss 1.2648 (1.2736) teacher_loss 0.0901 (0.0852) loss_zs_kd 0.0267 (0.0195) loss_oracle 0.5143 (0.5362) kd_loss 0.9042 (0.9106) acc 93.7500 (96.9922) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4210 (0.4209) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0908 (0.0824) teacher/usage_max 0.5365 (0.5148) teacher/usage_min 0.1286 (0.1281) teacher/usage_std 0.1665 (0.1646) nleep/row_max_mean 1517.3318 (1517.2003) nleep/row_max_std 34.8031 (37.6464) nleep/row_min_mean 1486.4618 (1486.2613) lr 1.2369e-04 eta 0:02:11
epoch [44/50] batch [100/132] time 0.132 (0.154) data 0.000 (0.004) loss 1.3216 (1.2757) teacher_loss 0.0424 (0.0842) loss_zs_kd 0.0140 (0.0200) loss_oracle 0.5201 (0.5378) kd_loss 1.0122 (0.9125) acc 96.8750 (97.0000) gate/entropy 1.0285 (1.0281) gate/usage_max 0.4206 (0.4209) gate/usage_min 0.1670 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.0763 (0.0806) teacher/usage_max 0.3855 (0.5126) teacher/usage_min 0.2339 (0.1285) teacher/usage_std 0.0703 (0.1630) nleep/row_max_mean 1509.4313 (1517.3111) nleep/row_max_std 36.1310 (37.4011) nleep/row_min_mean 1482.0857 (1486.4558) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [120/132] time 0.148 (0.153) data 0.000 (0.003) loss 1.4140 (1.2803) teacher_loss 0.1424 (0.0853) loss_zs_kd 0.0030 (0.0195) loss_oracle 0.5279 (0.5398) kd_loss 1.0062 (0.9154) acc 96.8750 (96.9792) gate/entropy 1.0283 (1.0281) gate/usage_max 0.4208 (0.4209) gate/usage_min 0.1669 (0.1666) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.1014 (0.0813) teacher/usage_max 0.4352 (0.5082) teacher/usage_min 0.2531 (0.1316) teacher/usage_std 0.0759 (0.1599) nleep/row_max_mean 1521.2755 (1517.3502) nleep/row_max_std 25.9352 (37.4792) nleep/row_min_mean 1488.0679 (1486.5907) lr 1.2369e-04 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,814
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,499
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.8%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [45/50] batch [20/132] time 0.172 (0.131) data 0.000 (0.017) loss 1.4980 (1.3021) teacher_loss 0.1857 (0.1012) loss_zs_kd 0.0325 (0.0212) loss_oracle 0.5519 (0.5418) kd_loss 1.0202 (0.9194) acc 90.6250 (95.9375) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.1217 (0.0792) teacher/usage_max 0.3881 (0.5067) teacher/usage_min 0.2901 (0.1351) teacher/usage_std 0.0408 (0.1555) nleep/row_max_mean 1518.8180 (1512.9995) nleep/row_max_std 47.3975 (40.1627) nleep/row_min_mean 1484.1091 (1482.3139) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [40/132] time 0.180 (0.122) data 0.000 (0.008) loss 1.3899 (1.3002) teacher_loss 0.0090 (0.0853) loss_zs_kd 0.0099 (0.0189) loss_oracle 0.6792 (0.5451) kd_loss 1.0363 (0.9329) acc 100.0000 (96.6406) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0758 (0.0778) teacher/usage_max 0.3873 (0.5009) teacher/usage_min 0.2594 (0.1485) teacher/usage_std 0.0541 (0.1484) nleep/row_max_mean 1515.1233 (1514.5970) nleep/row_max_std 43.8590 (39.6982) nleep/row_min_mean 1479.9257 (1483.6479) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [60/132] time 0.193 (0.125) data 0.000 (0.006) loss 1.2719 (1.2929) teacher_loss 0.1212 (0.0867) loss_zs_kd 0.0231 (0.0190) loss_oracle 0.5162 (0.5405) kd_loss 0.8810 (0.9264) acc 93.7500 (96.7188) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.1116 (0.0793) teacher/usage_max 0.5088 (0.5000) teacher/usage_min 0.1302 (0.1431) teacher/usage_std 0.1558 (0.1511) nleep/row_max_mean 1504.8677 (1515.2407) nleep/row_max_std 56.5973 (39.7636) nleep/row_min_mean 1475.5850 (1484.6415) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [80/132] time 0.095 (0.123) data 0.000 (0.004) loss 1.2371 (1.2896) teacher_loss 0.0471 (0.0869) loss_zs_kd 0.0095 (0.0197) loss_oracle 0.5751 (0.5387) kd_loss 0.8977 (0.9234) acc 100.0000 (96.6797) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0767 (0.0849) teacher/usage_max 0.4768 (0.4971) teacher/usage_min 0.1093 (0.1435) teacher/usage_std 0.1605 (0.1503) nleep/row_max_mean 1507.9347 (1514.9567) nleep/row_max_std 51.9901 (41.0486) nleep/row_min_mean 1481.2336 (1484.5604) lr 9.5173e-05 eta 0:01:27
epoch [45/50] batch [100/132] time 0.097 (0.117) data 0.000 (0.004) loss 1.2827 (1.3002) teacher_loss 0.0506 (0.0865) loss_zs_kd 0.0088 (0.0200) loss_oracle 0.4763 (0.5409) kd_loss 0.9896 (0.9332) acc 96.8750 (96.5625) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1237 (0.0858) teacher/usage_max 0.4877 (0.4891) teacher/usage_min 0.2552 (0.1548) teacher/usage_std 0.1091 (0.1420) nleep/row_max_mean 1518.7644 (1514.6573) nleep/row_max_std 40.1696 (41.0727) nleep/row_min_mean 1486.3792 (1484.3173) lr 9.5173e-05 eta 0:01:20
epoch [45/50] batch [120/132] time 0.074 (0.116) data 0.000 (0.003) loss 1.1749 (1.3011) teacher_loss 0.0570 (0.0870) loss_zs_kd 0.0190 (0.0203) loss_oracle 0.5309 (0.5412) kd_loss 0.8429 (0.9334) acc 96.8750 (96.6406) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1181 (0.1180) teacher/entropy 0.0696 (0.0871) teacher/usage_max 0.5831 (0.4874) teacher/usage_min 0.0384 (0.1558) teacher/usage_std 0.2247 (0.1409) nleep/row_max_mean 1525.8463 (1515.5175) nleep/row_max_std 34.2552 (40.8516) nleep/row_min_mean 1491.5347 (1484.9284) lr 9.5173e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,814
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,505
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [46/50] batch [20/132] time 0.124 (0.159) data 0.000 (0.013) loss 1.2157 (1.2857) teacher_loss 0.0294 (0.0835) loss_zs_kd 0.0028 (0.0191) loss_oracle 0.5027 (0.5355) kd_loss 0.9335 (0.9248) acc 96.8750 (97.1875) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.1098 (0.1067) teacher/usage_max 0.4202 (0.4745) teacher/usage_min 0.1835 (0.1702) teacher/usage_std 0.1064 (0.1307) nleep/row_max_mean 1515.6138 (1518.5224) nleep/row_max_std 36.9032 (36.9289) nleep/row_min_mean 1486.2207 (1488.2169) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [40/132] time 0.144 (0.151) data 0.000 (0.006) loss 1.1255 (1.2934) teacher_loss 0.1502 (0.0895) loss_zs_kd 0.0036 (0.0195) loss_oracle 0.4687 (0.5392) kd_loss 0.7392 (0.9245) acc 96.8750 (97.2656) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.1830 (0.1067) teacher/usage_max 0.5707 (0.4776) teacher/usage_min 0.0491 (0.1677) teacher/usage_std 0.2155 (0.1330) nleep/row_max_mean 1517.5087 (1516.7249) nleep/row_max_std 33.8509 (37.3513) nleep/row_min_mean 1490.6460 (1486.0810) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [60/132] time 0.133 (0.147) data 0.000 (0.004) loss 1.3674 (1.3017) teacher_loss 0.0462 (0.0830) loss_zs_kd 0.0107 (0.0176) loss_oracle 0.5863 (0.5472) kd_loss 1.0227 (0.9363) acc 96.8750 (97.3438) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.0306 (0.0995) teacher/usage_max 0.5003 (0.4764) teacher/usage_min 0.1927 (0.1721) teacher/usage_std 0.1269 (0.1303) nleep/row_max_mean 1518.0098 (1515.9759) nleep/row_max_std 40.1422 (37.4100) nleep/row_min_mean 1480.3961 (1484.8869) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [80/132] time 0.124 (0.144) data 0.000 (0.003) loss 1.3905 (1.3062) teacher_loss 0.0968 (0.0843) loss_zs_kd 0.0059 (0.0183) loss_oracle 0.5823 (0.5476) kd_loss 0.9996 (0.9390) acc 93.7500 (97.1875) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1442 (0.0998) teacher/usage_max 0.3845 (0.4710) teacher/usage_min 0.2927 (0.1750) teacher/usage_std 0.0382 (0.1263) nleep/row_max_mean 1495.6848 (1514.9408) nleep/row_max_std 40.1721 (38.2176) nleep/row_min_mean 1466.1154 (1483.8540) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [100/132] time 0.151 (0.144) data 0.000 (0.003) loss 1.1308 (1.3124) teacher_loss 0.0474 (0.0905) loss_zs_kd 0.0278 (0.0196) loss_oracle 0.5082 (0.5480) kd_loss 0.8154 (0.9381) acc 100.0000 (97.0000) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.1574 (0.1032) teacher/usage_max 0.4500 (0.4722) teacher/usage_min 0.1068 (0.1766) teacher/usage_std 0.1602 (0.1262) nleep/row_max_mean 1504.3212 (1513.8471) nleep/row_max_std 38.6011 (38.5842) nleep/row_min_mean 1474.4604 (1482.9700) lr 7.0224e-05 eta 0:01:20
epoch [46/50] batch [120/132] time 0.142 (0.145) data 0.000 (0.002) loss 1.4502 (1.3144) teacher_loss 0.1731 (0.0910) loss_zs_kd 0.0158 (0.0193) loss_oracle 0.5359 (0.5475) kd_loss 1.0013 (0.9400) acc 96.8750 (96.9531) gate/entropy 1.0278 (1.0281) gate/usage_max 0.4212 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.0824 (0.1054) teacher/usage_max 0.4340 (0.4705) teacher/usage_min 0.2257 (0.1808) teacher/usage_std 0.0852 (0.1236) nleep/row_max_mean 1528.5936 (1513.2689) nleep/row_max_std 47.7104 (38.4057) nleep/row_min_mean 1489.2769 (1482.5270) lr 7.0224e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,510
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [47/50] batch [20/132] time 0.090 (0.122) data 0.000 (0.017) loss 1.3081 (1.3582) teacher_loss 0.0386 (0.0956) loss_zs_kd 0.0091 (0.0194) loss_oracle 0.5673 (0.5411) kd_loss 0.9812 (0.9823) acc 96.8750 (97.5000) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0668 (0.1091) teacher/usage_max 0.4202 (0.4339) teacher/usage_min 0.1888 (0.2155) teacher/usage_std 0.1029 (0.0941) nleep/row_max_mean 1515.6871 (1512.7647) nleep/row_max_std 35.1002 (37.8508) nleep/row_min_mean 1486.0284 (1481.7288) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [40/132] time 0.084 (0.124) data 0.000 (0.009) loss 1.5373 (1.3366) teacher_loss 0.2826 (0.1026) loss_zs_kd 0.0402 (0.0200) loss_oracle 0.5365 (0.5447) kd_loss 0.9664 (0.9515) acc 90.6250 (96.8750) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0558 (0.1108) teacher/usage_max 0.4404 (0.4537) teacher/usage_min 0.1594 (0.1911) teacher/usage_std 0.1241 (0.1122) nleep/row_max_mean 1513.9160 (1509.9034) nleep/row_max_std 41.3388 (37.9093) nleep/row_min_mean 1481.7812 (1479.5602) lr 4.8943e-05 eta 0:01:00
epoch [47/50] batch [60/132] time 0.090 (0.119) data 0.000 (0.006) loss 1.2359 (1.3135) teacher_loss 0.1001 (0.0927) loss_zs_kd 0.0218 (0.0195) loss_oracle 0.4455 (0.5427) kd_loss 0.9022 (0.9397) acc 96.8750 (97.1354) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1135 (0.1078) teacher/usage_max 0.4778 (0.4624) teacher/usage_min 0.1524 (0.1793) teacher/usage_std 0.1353 (0.1205) nleep/row_max_mean 1501.9771 (1509.6802) nleep/row_max_std 36.5156 (38.7759) nleep/row_min_mean 1474.2280 (1479.5674) lr 4.8943e-05 eta 0:00:55
epoch [47/50] batch [80/132] time 0.086 (0.115) data 0.000 (0.004) loss 1.3357 (1.3125) teacher_loss 0.0933 (0.0917) loss_zs_kd 0.0117 (0.0182) loss_oracle 0.4937 (0.5393) kd_loss 0.9897 (0.9420) acc 96.8750 (97.1875) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.2086 (0.1131) teacher/usage_max 0.3672 (0.4612) teacher/usage_min 0.2798 (0.1881) teacher/usage_std 0.0383 (0.1166) nleep/row_max_mean 1501.1989 (1508.8708) nleep/row_max_std 45.9774 (39.6347) nleep/row_min_mean 1474.8577 (1478.7842) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [100/132] time 0.075 (0.116) data 0.000 (0.004) loss 1.4251 (1.3060) teacher_loss 0.0869 (0.0910) loss_zs_kd 0.0084 (0.0189) loss_oracle 0.5907 (0.5354) kd_loss 1.0386 (0.9379) acc 96.8750 (97.1562) gate/entropy 1.0284 (1.0281) gate/usage_max 0.4208 (0.4210) gate/usage_min 0.1669 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.0883 (0.1160) teacher/usage_max 0.4760 (0.4626) teacher/usage_min 0.2509 (0.1875) teacher/usage_std 0.1013 (0.1174) nleep/row_max_mean 1511.8917 (1509.1219) nleep/row_max_std 34.7558 (39.4483) nleep/row_min_mean 1477.4104 (1479.2271) lr 4.8943e-05 eta 0:00:49
epoch [47/50] batch [120/132] time 0.065 (0.115) data 0.000 (0.003) loss 1.4053 (1.3081) teacher_loss 0.2387 (0.0906) loss_zs_kd 0.0279 (0.0184) loss_oracle 0.5138 (0.5406) kd_loss 0.8958 (0.9380) acc 93.7500 (97.1615) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.1583 (0.1176) teacher/usage_max 0.4608 (0.4632) teacher/usage_min 0.1940 (0.1879) teacher/usage_std 0.1093 (0.1175) nleep/row_max_mean 1508.8047 (1508.6656) nleep/row_max_std 40.2950 (39.6899) nleep/row_min_mean 1480.4003 (1478.6889) lr 4.8943e-05 eta 0:00:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [48/50] batch [20/132] time 0.164 (0.180) data 0.000 (0.016) loss 1.3770 (1.3191) teacher_loss 0.1052 (0.1080) loss_zs_kd 0.0242 (0.0171) loss_oracle 0.5248 (0.5307) kd_loss 0.9973 (0.9372) acc 96.8750 (95.9375) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1393 (0.1125) teacher/usage_max 0.3746 (0.4748) teacher/usage_min 0.2873 (0.1869) teacher/usage_std 0.0358 (0.1230) nleep/row_max_mean 1506.6086 (1516.5504) nleep/row_max_std 46.5334 (41.9626) nleep/row_min_mean 1474.2366 (1485.5297) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [40/132] time 0.191 (0.171) data 0.000 (0.008) loss 1.2982 (1.3083) teacher_loss 0.0636 (0.0904) loss_zs_kd 0.0300 (0.0171) loss_oracle 0.5009 (0.5359) kd_loss 0.9692 (0.9415) acc 96.8750 (97.0312) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4212 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.1433 (0.1180) teacher/usage_max 0.4976 (0.4752) teacher/usage_min 0.2409 (0.1971) teacher/usage_std 0.1165 (0.1185) nleep/row_max_mean 1504.7046 (1515.0203) nleep/row_max_std 49.6983 (43.7737) nleep/row_min_mean 1481.2737 (1484.6981) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [60/132] time 0.151 (0.166) data 0.000 (0.006) loss 1.1717 (1.3179) teacher_loss 0.1245 (0.0958) loss_zs_kd 0.0384 (0.0181) loss_oracle 0.4752 (0.5342) kd_loss 0.7904 (0.9460) acc 96.8750 (96.9792) gate/entropy 1.0278 (1.0281) gate/usage_max 0.4212 (0.4210) gate/usage_min 0.1663 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.2198 (0.1225) teacher/usage_max 0.5328 (0.4666) teacher/usage_min 0.1447 (0.2011) teacher/usage_std 0.1586 (0.1133) nleep/row_max_mean 1524.9614 (1515.5168) nleep/row_max_std 31.5653 (43.0925) nleep/row_min_mean 1496.6890 (1484.9730) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [80/132] time 0.141 (0.162) data 0.000 (0.004) loss 1.5291 (1.3201) teacher_loss 0.0294 (0.0954) loss_zs_kd 0.0096 (0.0182) loss_oracle 0.6897 (0.5342) kd_loss 1.1500 (0.9486) acc 100.0000 (96.7578) gate/entropy 1.0284 (1.0281) gate/usage_max 0.4207 (0.4210) gate/usage_min 0.1670 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.0848 (0.1231) teacher/usage_max 0.4126 (0.4655) teacher/usage_min 0.1967 (0.2011) teacher/usage_std 0.0971 (0.1129) nleep/row_max_mean 1512.0244 (1515.9516) nleep/row_max_std 44.1791 (43.3368) nleep/row_min_mean 1474.6721 (1485.3632) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [100/132] time 0.168 (0.159) data 0.000 (0.003) loss 1.2705 (1.3189) teacher_loss 0.0339 (0.0974) loss_zs_kd 0.0169 (0.0189) loss_oracle 0.5458 (0.5334) kd_loss 0.9552 (0.9453) acc 100.0000 (96.8750) gate/entropy 1.0279 (1.0281) gate/usage_max 0.4212 (0.4210) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1181 (0.1179) teacher/entropy 0.1153 (0.1240) teacher/usage_max 0.4030 (0.4611) teacher/usage_min 0.2131 (0.2000) teacher/usage_std 0.0854 (0.1115) nleep/row_max_mean 1511.2009 (1515.9671) nleep/row_max_std 44.5349 (43.1116) nleep/row_min_mean 1483.1652 (1485.3731) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [120/132] time 0.090 (0.155) data 0.000 (0.003) loss 1.1469 (1.3225) teacher_loss 0.0581 (0.0939) loss_zs_kd 0.0238 (0.0189) loss_oracle 0.5241 (0.5376) kd_loss 0.8148 (0.9504) acc 96.8750 (96.9271) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1267 (0.1241) teacher/usage_max 0.5678 (0.4604) teacher/usage_min 0.0701 (0.2030) teacher/usage_std 0.2042 (0.1099) nleep/row_max_mean 1512.2689 (1515.2956) nleep/row_max_std 44.8585 (42.9295) nleep/row_min_mean 1478.7300 (1484.5602) lr 3.1417e-05 eta 0:00:42
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [49/50] batch [20/132] time 0.099 (0.123) data 0.000 (0.016) loss 1.4776 (1.3449) teacher_loss 0.2541 (0.0829) loss_zs_kd 0.0219 (0.0200) loss_oracle 0.5460 (0.5544) kd_loss 0.9395 (0.9748) acc 87.5000 (97.1875) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1668 (0.1666) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.1668 (0.1134) teacher/usage_max 0.4041 (0.4385) teacher/usage_min 0.2528 (0.2187) teacher/usage_std 0.0622 (0.0955) nleep/row_max_mean 1506.7563 (1513.8792) nleep/row_max_std 50.4694 (42.6984) nleep/row_min_mean 1474.9778 (1482.9491) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [40/132] time 0.094 (0.115) data 0.000 (0.008) loss 1.3773 (1.3009) teacher_loss 0.0055 (0.0741) loss_zs_kd 0.0146 (0.0200) loss_oracle 0.5104 (0.5364) kd_loss 1.1093 (0.9485) acc 100.0000 (97.8906) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4211) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1180) teacher/entropy 0.0486 (0.1238) teacher/usage_max 0.5366 (0.4576) teacher/usage_min 0.1592 (0.2039) teacher/usage_std 0.1555 (0.1092) nleep/row_max_mean 1518.8839 (1514.3999) nleep/row_max_std 38.1291 (41.8815) nleep/row_min_mean 1482.8529 (1483.7355) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [60/132] time 0.181 (0.121) data 0.000 (0.006) loss 1.0722 (1.2999) teacher_loss 0.0178 (0.0764) loss_zs_kd 0.0156 (0.0193) loss_oracle 0.4425 (0.5370) kd_loss 0.8254 (0.9453) acc 100.0000 (97.7083) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1959 (0.1271) teacher/usage_max 0.5147 (0.4587) teacher/usage_min 0.1574 (0.2068) teacher/usage_std 0.1459 (0.1086) nleep/row_max_mean 1506.0195 (1513.1931) nleep/row_max_std 41.2991 (42.2449) nleep/row_min_mean 1478.4937 (1482.6387) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [80/132] time 0.183 (0.121) data 0.000 (0.004) loss 1.3402 (1.3073) teacher_loss 0.0549 (0.0790) loss_zs_kd 0.0058 (0.0188) loss_oracle 0.5483 (0.5353) kd_loss 1.0082 (0.9513) acc 96.8750 (97.6562) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1668 (0.1666) gate/usage_std 0.1178 (0.1179) teacher/entropy 0.1526 (0.1277) teacher/usage_max 0.4818 (0.4569) teacher/usage_min 0.2092 (0.2112) teacher/usage_std 0.1126 (0.1060) nleep/row_max_mean 1512.6509 (1512.9230) nleep/row_max_std 36.1848 (41.8849) nleep/row_min_mean 1480.7878 (1482.4024) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [100/132] time 0.162 (0.124) data 0.000 (0.003) loss 1.7407 (1.3135) teacher_loss 0.3974 (0.0795) loss_zs_kd 0.0445 (0.0185) loss_oracle 0.5487 (0.5399) kd_loss 1.0467 (0.9548) acc 87.5000 (97.6250) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.0928 (0.1257) teacher/usage_max 0.3967 (0.4542) teacher/usage_min 0.2892 (0.2112) teacher/usage_std 0.0459 (0.1046) nleep/row_max_mean 1498.3706 (1513.0638) nleep/row_max_std 43.5851 (41.5874) nleep/row_min_mean 1472.6647 (1482.6555) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [120/132] time 0.159 (0.128) data 0.000 (0.003) loss 1.2442 (1.3168) teacher_loss 0.0102 (0.0806) loss_zs_kd 0.0028 (0.0181) loss_oracle 0.5678 (0.5403) kd_loss 0.9486 (0.9571) acc 100.0000 (97.5260) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.1353 (0.1262) teacher/usage_max 0.4736 (0.4537) teacher/usage_min 0.2257 (0.2121) teacher/usage_std 0.1038 (0.1039) nleep/row_max_mean 1520.5476 (1512.1855) nleep/row_max_std 33.6668 (41.3517) nleep/row_min_mean 1487.8140 (1481.8719) lr 1.7713e-05 eta 0:00:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
epoch [50/50] batch [20/132] time 0.145 (0.161) data 0.000 (0.016) loss 1.2812 (1.3338) teacher_loss 0.0954 (0.0828) loss_zs_kd 0.0245 (0.0183) loss_oracle 0.5918 (0.5526) kd_loss 0.8777 (0.9655) acc 96.8750 (97.3438) gate/entropy 1.0284 (1.0281) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1669 (0.1666) gate/usage_std 0.1177 (0.1179) teacher/entropy 0.1540 (0.1358) teacher/usage_max 0.4333 (0.4520) teacher/usage_min 0.1710 (0.2334) teacher/usage_std 0.1158 (0.0944) nleep/row_max_mean 1496.8260 (1511.3954) nleep/row_max_std 45.4202 (37.9273) nleep/row_min_mean 1474.4790 (1480.9016) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [40/132] time 0.124 (0.151) data 0.000 (0.008) loss 1.2898 (1.3274) teacher_loss 0.0143 (0.0949) loss_zs_kd 0.0108 (0.0187) loss_oracle 0.5826 (0.5427) kd_loss 0.9788 (0.9518) acc 100.0000 (96.7188) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1556 (0.1412) teacher/usage_max 0.5068 (0.4531) teacher/usage_min 0.2139 (0.2243) teacher/usage_std 0.1255 (0.0978) nleep/row_max_mean 1527.2219 (1513.1453) nleep/row_max_std 26.4880 (37.3142) nleep/row_min_mean 1491.5428 (1483.7000) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [60/132] time 0.130 (0.146) data 0.000 (0.006) loss 1.2826 (1.3277) teacher_loss 0.0070 (0.0936) loss_zs_kd 0.0009 (0.0175) loss_oracle 0.5312 (0.5392) kd_loss 1.0096 (0.9558) acc 100.0000 (96.8229) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1641 (0.1409) teacher/usage_max 0.4008 (0.4472) teacher/usage_min 0.2712 (0.2240) teacher/usage_std 0.0530 (0.0951) nleep/row_max_mean 1511.8224 (1513.5759) nleep/row_max_std 42.3907 (37.6353) nleep/row_min_mean 1485.2340 (1484.1593) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [80/132] time 0.082 (0.142) data 0.000 (0.004) loss 1.4390 (1.3344) teacher_loss 0.1059 (0.0981) loss_zs_kd 0.0242 (0.0182) loss_oracle 0.5910 (0.5386) kd_loss 1.0254 (0.9579) acc 96.8750 (96.6406) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1180 (0.1179) teacher/entropy 0.1342 (0.1369) teacher/usage_max 0.3718 (0.4482) teacher/usage_min 0.3112 (0.2198) teacher/usage_std 0.0273 (0.0976) nleep/row_max_mean 1513.6270 (1514.7500) nleep/row_max_std 39.7187 (37.1212) nleep/row_min_mean 1482.3201 (1485.2163) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/132] time 0.104 (0.129) data 0.000 (0.003) loss 1.5071 (1.3421) teacher_loss 0.1714 (0.1060) loss_zs_kd 0.0240 (0.0191) loss_oracle 0.6248 (0.5395) kd_loss 1.0113 (0.9568) acc 87.5000 (96.1875) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1666 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1497 (0.1376) teacher/usage_max 0.3999 (0.4470) teacher/usage_min 0.2858 (0.2204) teacher/usage_std 0.0485 (0.0969) nleep/row_max_mean 1498.2683 (1514.4873) nleep/row_max_std 44.3584 (37.6198) nleep/row_min_mean 1469.4061 (1484.9387) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [120/132] time 0.163 (0.127) data 0.000 (0.003) loss 1.1753 (1.3425) teacher_loss 0.0029 (0.1027) loss_zs_kd 0.0004 (0.0187) loss_oracle 0.4365 (0.5370) kd_loss 0.9539 (0.9620) acc 100.0000 (96.3802) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4210 (0.4210) gate/usage_min 0.1667 (0.1666) gate/usage_std 0.1179 (0.1179) teacher/entropy 0.1101 (0.1364) teacher/usage_max 0.5410 (0.4455) teacher/usage_min 0.2032 (0.2249) teacher/usage_std 0.1484 (0.0943) nleep/row_max_mean 1521.1777 (1514.5878) nleep/row_max_std 38.4302 (37.6484) nleep/row_min_mean 1489.2419 (1484.7974) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 42 *******
******* Domain s best val test acc: 89.1%, epoch: 42 *******
******* Domain s best test acc:     91.7%, epoch: 23 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:14

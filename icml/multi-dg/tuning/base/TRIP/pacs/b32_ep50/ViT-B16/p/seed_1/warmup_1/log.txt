Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'sketch']
Target     ['photo']
# classes  7
# train_x  5,823
# val      2,497
# test     1,670
---------  -------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/181] time 0.169 (0.198) data 0.000 (0.016) loss 1.4185 (1.3314) teacher_loss 0.6374 (0.5718) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.7812 (0.7596) acc 71.8750 (79.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3347) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.3170 (0.3389) teacher/usage_max 0.4024 (0.4209) teacher/usage_min 0.2950 (0.2485) teacher/usage_std 0.0489 (0.0729) nleep/row_max_mean 1610.0032 (1597.8525) nleep/row_max_std 62.0741 (71.8883) nleep/row_min_mean 1601.2437 (1587.2269) lr 1.0000e-05 eta 0:29:52
epoch [1/50] batch [40/181] time 0.158 (0.175) data 0.000 (0.008) loss 1.3323 (1.2587) teacher_loss 0.8179 (0.5682) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0003 (0.0000) kd_loss 0.5142 (0.6905) acc 78.1250 (79.6875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3347) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.5844 (0.4080) teacher/usage_max 0.3812 (0.4101) teacher/usage_min 0.2819 (0.2567) teacher/usage_std 0.0406 (0.0650) nleep/row_max_mean 1588.4408 (1596.1799) nleep/row_max_std 47.1591 (67.2832) nleep/row_min_mean 1583.6608 (1587.7578) lr 1.0000e-05 eta 0:26:16
epoch [1/50] batch [60/181] time 0.147 (0.167) data 0.000 (0.005) loss 1.1931 (1.1839) teacher_loss 0.7243 (0.5571) loss_zs_kd 0.0009 (0.0001) loss_oracle 0.0006 (0.0001) kd_loss 0.4681 (0.6268) acc 78.1250 (80.2604) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3347) gate/usage_min 0.3318 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.6307 (0.4717) teacher/usage_max 0.3540 (0.4051) teacher/usage_min 0.2938 (0.2622) teacher/usage_std 0.0279 (0.0608) nleep/row_max_mean 1591.6931 (1597.5384) nleep/row_max_std 62.1432 (63.5534) nleep/row_min_mean 1586.9519 (1590.4694) lr 1.0000e-05 eta 0:24:59
epoch [1/50] batch [80/181] time 0.099 (0.156) data 0.000 (0.004) loss 0.8130 (1.1203) teacher_loss 0.4261 (0.5475) loss_zs_kd 0.0010 (0.0001) loss_oracle 0.0011 (0.0003) kd_loss 0.3860 (0.5727) acc 84.3750 (80.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3347) gate/usage_min 0.3316 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.7123 (0.5258) teacher/usage_max 0.4650 (0.4007) teacher/usage_min 0.1822 (0.2663) teacher/usage_std 0.1163 (0.0570) nleep/row_max_mean 1603.6892 (1598.8214) nleep/row_max_std 57.6405 (60.5671) nleep/row_min_mean 1600.8624 (1592.6688) lr 1.0000e-05 eta 0:23:23
epoch [1/50] batch [100/181] time 0.138 (0.149) data 0.000 (0.003) loss 0.8331 (1.0620) teacher_loss 0.4647 (0.5348) loss_zs_kd 0.0014 (0.0002) loss_oracle 0.0022 (0.0006) kd_loss 0.3666 (0.5268) acc 87.5000 (80.8438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3347) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.7319 (0.5716) teacher/usage_max 0.3610 (0.4003) teacher/usage_min 0.2895 (0.2672) teacher/usage_std 0.0313 (0.0564) nleep/row_max_mean 1602.4343 (1598.8375) nleep/row_max_std 41.2698 (59.4285) nleep/row_min_mean 1599.7600 (1593.3639) lr 1.0000e-05 eta 0:22:14
epoch [1/50] batch [120/181] time 0.096 (0.143) data 0.000 (0.003) loss 0.7991 (1.0030) teacher_loss 0.5482 (0.5182) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0029 (0.0009) kd_loss 0.2490 (0.4842) acc 81.2500 (81.7708) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3347) gate/usage_min 0.3318 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.8490 (0.6142) teacher/usage_max 0.4573 (0.4015) teacher/usage_min 0.2337 (0.2686) teacher/usage_std 0.0929 (0.0566) nleep/row_max_mean 1597.4714 (1598.3482) nleep/row_max_std 55.0480 (58.0926) nleep/row_min_mean 1595.4147 (1593.4309) lr 1.0000e-05 eta 0:21:18
epoch [1/50] batch [140/181] time 0.164 (0.140) data 0.000 (0.002) loss 0.4951 (0.9620) teacher_loss 0.3056 (0.5127) loss_zs_kd 0.0017 (0.0004) loss_oracle 0.0039 (0.0013) kd_loss 0.1867 (0.4485) acc 87.5000 (82.0982) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3347) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.9116 (0.6500) teacher/usage_max 0.3664 (0.4023) teacher/usage_min 0.3127 (0.2689) teacher/usage_std 0.0236 (0.0567) nleep/row_max_mean 1606.7269 (1597.8985) nleep/row_max_std 38.6000 (57.4143) nleep/row_min_mean 1605.0687 (1593.4127) lr 1.0000e-05 eta 0:20:50
epoch [1/50] batch [160/181] time 0.086 (0.137) data 0.000 (0.002) loss 0.5399 (0.9219) teacher_loss 0.3358 (0.5022) loss_zs_kd 0.0004 (0.0005) loss_oracle 0.0046 (0.0017) kd_loss 0.2017 (0.4186) acc 90.6250 (82.4609) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3347) gate/usage_min 0.3317 (0.3317) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.8966 (0.6798) teacher/usage_max 0.3742 (0.4050) teacher/usage_min 0.3023 (0.2685) teacher/usage_std 0.0301 (0.0582) nleep/row_max_mean 1602.6715 (1597.2982) nleep/row_max_std 42.4377 (57.2589) nleep/row_min_mean 1601.0858 (1593.1619) lr 1.0000e-05 eta 0:20:20
epoch [1/50] batch [180/181] time 0.176 (0.133) data 0.000 (0.002) loss 0.7657 (0.8944) teacher_loss 0.5973 (0.5004) loss_zs_kd 0.0014 (0.0006) loss_oracle 0.0092 (0.0021) kd_loss 0.1632 (0.3927) acc 81.2500 (82.5174) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3347) gate/usage_min 0.3318 (0.3317) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.9352 (0.7057) teacher/usage_max 0.4003 (0.4072) teacher/usage_min 0.2615 (0.2671) teacher/usage_std 0.0568 (0.0596) nleep/row_max_mean 1597.0874 (1596.4589) nleep/row_max_std 56.6652 (56.9377) nleep/row_min_mean 1595.6809 (1592.6135) lr 1.0000e-05 eta 0:19:35
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,368
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      94.8%, epoch: 1 *******
******* Domain p best val test acc: 99.9%, epoch: 1 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [2/50] batch [20/181] time 0.156 (0.157) data 0.000 (0.011) loss 0.9847 (0.8210) teacher_loss 0.4106 (0.4944) loss_zs_kd 0.0124 (0.0117) loss_oracle 0.3338 (0.1416) kd_loss 0.4009 (0.2500) acc 84.3750 (84.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3357 (0.3351) gate/usage_min 0.3315 (0.3317) gate/usage_std 0.0017 (0.0014) teacher/entropy 0.6952 (0.8473) teacher/usage_max 0.5408 (0.4771) teacher/usage_min 0.1444 (0.2264) teacher/usage_std 0.1624 (0.1068) nleep/row_max_mean 1612.2841 (1593.4014) nleep/row_max_std 46.0652 (57.2693) nleep/row_min_mean 1609.3972 (1591.5170) lr 2.0000e-03 eta 0:23:13
epoch [2/50] batch [40/181] time 0.167 (0.157) data 0.000 (0.006) loss 1.0436 (0.9028) teacher_loss 0.2809 (0.4144) loss_zs_kd 0.0155 (0.0118) loss_oracle 0.3809 (0.2083) kd_loss 0.5644 (0.3783) acc 90.6250 (86.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3377 (0.3359) gate/usage_min 0.3303 (0.3313) gate/usage_std 0.0031 (0.0019) teacher/entropy 0.5284 (0.7177) teacher/usage_max 0.6217 (0.5181) teacher/usage_min 0.0967 (0.1712) teacher/usage_std 0.2174 (0.1458) nleep/row_max_mean 1600.0228 (1597.3223) nleep/row_max_std 71.1475 (58.6404) nleep/row_min_mean 1595.2856 (1594.2838) lr 2.0000e-03 eta 0:23:05
epoch [2/50] batch [60/181] time 0.143 (0.156) data 0.000 (0.004) loss 1.2137 (1.0033) teacher_loss 0.3355 (0.3911) loss_zs_kd 0.0313 (0.0131) loss_oracle 0.4118 (0.2725) kd_loss 0.6566 (0.4694) acc 93.7500 (87.2917) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3398 (0.3368) gate/usage_min 0.3289 (0.3307) gate/usage_std 0.0046 (0.0026) teacher/entropy 0.4332 (0.6256) teacher/usage_max 0.6273 (0.5273) teacher/usage_min 0.1406 (0.1578) teacher/usage_std 0.2112 (0.1550) nleep/row_max_mean 1596.7268 (1597.0789) nleep/row_max_std 57.6807 (59.7260) nleep/row_min_mean 1589.8455 (1592.8853) lr 2.0000e-03 eta 0:22:57
epoch [2/50] batch [80/181] time 0.147 (0.156) data 0.000 (0.003) loss 1.4330 (1.0842) teacher_loss 0.4175 (0.3785) loss_zs_kd 0.0137 (0.0148) loss_oracle 0.4134 (0.3185) kd_loss 0.8019 (0.5391) acc 87.5000 (87.5000) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3412 (0.3378) gate/usage_min 0.3282 (0.3301) gate/usage_std 0.0056 (0.0033) teacher/entropy 0.3026 (0.5566) teacher/usage_max 0.4228 (0.5090) teacher/usage_min 0.1615 (0.1707) teacher/usage_std 0.1216 (0.1426) nleep/row_max_mean 1578.9832 (1596.2016) nleep/row_max_std 59.5460 (59.2382) nleep/row_min_mean 1570.9131 (1590.9758) lr 2.0000e-03 eta 0:22:55
epoch [2/50] batch [100/181] time 0.159 (0.157) data 0.000 (0.002) loss 1.2876 (1.1388) teacher_loss 0.1584 (0.3600) loss_zs_kd 0.0158 (0.0165) loss_oracle 0.5282 (0.3514) kd_loss 0.8573 (0.5949) acc 93.7500 (88.0938) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3407 (0.3384) gate/usage_min 0.3293 (0.3299) gate/usage_std 0.0052 (0.0037) teacher/entropy 0.2456 (0.5024) teacher/usage_max 0.4335 (0.5022) teacher/usage_min 0.2046 (0.1738) teacher/usage_std 0.0956 (0.1388) nleep/row_max_mean 1583.2249 (1594.4121) nleep/row_max_std 50.9490 (58.7940) nleep/row_min_mean 1575.1372 (1588.5210) lr 2.0000e-03 eta 0:22:54
epoch [2/50] batch [120/181] time 0.163 (0.158) data 0.000 (0.002) loss 1.3535 (1.1830) teacher_loss 0.2525 (0.3496) loss_zs_kd 0.0236 (0.0180) loss_oracle 0.4868 (0.3692) kd_loss 0.8458 (0.6398) acc 96.8750 (88.3333) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3398 (0.3387) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0046 (0.0039) teacher/entropy 0.2561 (0.4584) teacher/usage_max 0.5354 (0.4968) teacher/usage_min 0.2023 (0.1794) teacher/usage_std 0.1450 (0.1341) nleep/row_max_mean 1595.8010 (1593.0055) nleep/row_max_std 51.7121 (58.3416) nleep/row_min_mean 1585.6136 (1586.4245) lr 2.0000e-03 eta 0:22:59
epoch [2/50] batch [140/181] time 0.165 (0.157) data 0.000 (0.002) loss 1.6718 (1.2235) teacher_loss 0.5081 (0.3387) loss_zs_kd 0.0432 (0.0193) loss_oracle 0.4830 (0.3875) kd_loss 0.9006 (0.6814) acc 81.2500 (88.6830) gate/entropy 1.0986 (1.0985) gate/usage_max 0.3379 (0.3388) gate/usage_min 0.3301 (0.3299) gate/usage_std 0.0033 (0.0039) teacher/entropy 0.2009 (0.4173) teacher/usage_max 0.4096 (0.4968) teacher/usage_min 0.1843 (0.1769) teacher/usage_std 0.1054 (0.1356) nleep/row_max_mean 1591.4812 (1591.2010) nleep/row_max_std 55.8146 (58.5176) nleep/row_min_mean 1577.8755 (1583.8496) lr 2.0000e-03 eta 0:22:51
epoch [2/50] batch [160/181] time 0.091 (0.156) data 0.000 (0.002) loss 1.4687 (1.2597) teacher_loss 0.2226 (0.3322) loss_zs_kd 0.0393 (0.0218) loss_oracle 0.4556 (0.4028) kd_loss 0.9987 (0.7152) acc 93.7500 (88.8477) gate/entropy 1.0986 (1.0985) gate/usage_max 0.3365 (0.3386) gate/usage_min 0.3301 (0.3299) gate/usage_std 0.0026 (0.0038) teacher/entropy 0.1035 (0.3838) teacher/usage_max 0.4946 (0.4943) teacher/usage_min 0.0683 (0.1761) teacher/usage_std 0.1889 (0.1351) nleep/row_max_mean 1575.3196 (1589.9924) nleep/row_max_std 59.4477 (58.3703) nleep/row_min_mean 1562.6995 (1581.7206) lr 2.0000e-03 eta 0:22:36
epoch [2/50] batch [180/181] time 0.169 (0.149) data 0.000 (0.001) loss 1.5532 (1.2970) teacher_loss 0.2517 (0.3306) loss_zs_kd 0.0300 (0.0232) loss_oracle 0.6377 (0.4234) kd_loss 0.9677 (0.7431) acc 90.6250 (88.8021) gate/entropy 1.0986 (1.0985) gate/usage_max 0.3360 (0.3383) gate/usage_min 0.3291 (0.3299) gate/usage_std 0.0030 (0.0037) teacher/entropy 0.1310 (0.3559) teacher/usage_max 0.5037 (0.5041) teacher/usage_min 0.1832 (0.1742) teacher/usage_std 0.1317 (0.1406) nleep/row_max_mean 1584.0754 (1588.7861) nleep/row_max_std 60.4686 (58.3277) nleep/row_min_mean 1567.1228 (1579.5588) lr 2.0000e-03 eta 0:21:33
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [3/50] batch [20/181] time 0.107 (0.119) data 0.000 (0.018) loss 1.5843 (1.5209) teacher_loss 0.2326 (0.2193) loss_zs_kd 0.0351 (0.0384) loss_oracle 0.5980 (0.5810) kd_loss 1.0352 (0.9919) acc 90.6250 (93.1250) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3367 (0.3362) gate/usage_min 0.3273 (0.3281) gate/usage_std 0.0043 (0.0037) teacher/entropy 0.0572 (0.1048) teacher/usage_max 0.6904 (0.5837) teacher/usage_min 0.1142 (0.1464) teacher/usage_std 0.2547 (0.1899) nleep/row_max_mean 1567.9812 (1579.9328) nleep/row_max_std 58.6088 (55.7889) nleep/row_min_mean 1548.1472 (1561.1565) lr 1.9980e-03 eta 0:17:13
epoch [3/50] batch [40/181] time 0.125 (0.119) data 0.000 (0.009) loss 1.6964 (1.5491) teacher_loss 0.3585 (0.2526) loss_zs_kd 0.0325 (0.0355) loss_oracle 0.6239 (0.5747) kd_loss 1.0096 (0.9914) acc 84.3750 (91.7969) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3388 (0.3370) gate/usage_min 0.3251 (0.3271) gate/usage_std 0.0059 (0.0044) teacher/entropy 0.0780 (0.1030) teacher/usage_max 0.6295 (0.5967) teacher/usage_min 0.0752 (0.1464) teacher/usage_std 0.2279 (0.1956) nleep/row_max_mean 1573.4485 (1579.6499) nleep/row_max_std 51.6314 (55.5832) nleep/row_min_mean 1551.0845 (1559.6502) lr 1.9980e-03 eta 0:17:06
epoch [3/50] batch [60/181] time 0.087 (0.112) data 0.001 (0.006) loss 1.7717 (1.5857) teacher_loss 0.4819 (0.2729) loss_zs_kd 0.0453 (0.0368) loss_oracle 0.7203 (0.6175) kd_loss 0.9071 (0.9856) acc 84.3750 (90.9896) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3401 (0.3379) gate/usage_min 0.3225 (0.3260) gate/usage_std 0.0078 (0.0052) teacher/entropy 0.1774 (0.1073) teacher/usage_max 0.5158 (0.5678) teacher/usage_min 0.0474 (0.1442) teacher/usage_std 0.2048 (0.1830) nleep/row_max_mean 1578.8778 (1578.7992) nleep/row_max_std 42.6707 (56.2386) nleep/row_min_mean 1557.8059 (1557.6039) lr 1.9980e-03 eta 0:16:07
epoch [3/50] batch [80/181] time 0.124 (0.114) data 0.000 (0.005) loss 1.7549 (1.6106) teacher_loss 0.3949 (0.2878) loss_zs_kd 0.0331 (0.0351) loss_oracle 0.7582 (0.6372) kd_loss 0.9644 (0.9867) acc 84.3750 (90.0000) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3408 (0.3385) gate/usage_min 0.3189 (0.3247) gate/usage_std 0.0102 (0.0062) teacher/entropy 0.1147 (0.1037) teacher/usage_max 0.4891 (0.5606) teacher/usage_min 0.0308 (0.1226) teacher/usage_std 0.2139 (0.1891) nleep/row_max_mean 1571.0122 (1576.3154) nleep/row_max_std 71.0282 (57.5916) nleep/row_min_mean 1539.1963 (1553.1401) lr 1.9980e-03 eta 0:16:21
epoch [3/50] batch [100/181] time 0.145 (0.113) data 0.000 (0.004) loss 1.5150 (1.6324) teacher_loss 0.1507 (0.2959) loss_zs_kd 0.0201 (0.0326) loss_oracle 0.6330 (0.6574) kd_loss 1.0378 (0.9916) acc 90.6250 (89.5625) gate/entropy 1.0979 (1.0983) gate/usage_max 0.3442 (0.3393) gate/usage_min 0.3152 (0.3231) gate/usage_std 0.0129 (0.0073) teacher/entropy 0.0337 (0.0959) teacher/usage_max 0.5201 (0.5640) teacher/usage_min 0.0000 (0.1033) teacher/usage_std 0.2363 (0.1983) nleep/row_max_mean 1568.8340 (1576.2811) nleep/row_max_std 63.6392 (57.6791) nleep/row_min_mean 1531.6589 (1550.7211) lr 1.9980e-03 eta 0:16:09
epoch [3/50] batch [120/181] time 0.142 (0.118) data 0.000 (0.003) loss 1.7436 (1.6524) teacher_loss 0.3350 (0.3040) loss_zs_kd 0.0077 (0.0306) loss_oracle 0.8553 (0.6778) kd_loss 0.9771 (0.9943) acc 87.5000 (89.3490) gate/entropy 1.0974 (1.0982) gate/usage_max 0.3491 (0.3405) gate/usage_min 0.3110 (0.3214) gate/usage_std 0.0162 (0.0085) teacher/entropy 0.0865 (0.0898) teacher/usage_max 0.6764 (0.5722) teacher/usage_min 0.0321 (0.0882) teacher/usage_std 0.2647 (0.2074) nleep/row_max_mean 1580.7483 (1576.5648) nleep/row_max_std 55.3051 (57.4345) nleep/row_min_mean 1538.3804 (1548.6012) lr 1.9980e-03 eta 0:16:53
epoch [3/50] batch [140/181] time 0.144 (0.123) data 0.000 (0.003) loss 1.6693 (1.6663) teacher_loss 0.3070 (0.3107) loss_zs_kd 0.0124 (0.0285) loss_oracle 0.7928 (0.6924) kd_loss 0.9597 (0.9952) acc 90.6250 (88.9286) gate/entropy 1.0968 (1.0981) gate/usage_max 0.3549 (0.3421) gate/usage_min 0.3069 (0.3196) gate/usage_std 0.0199 (0.0099) teacher/entropy 0.0871 (0.0847) teacher/usage_max 0.7679 (0.5926) teacher/usage_min 0.0000 (0.0766) teacher/usage_std 0.3215 (0.2200) nleep/row_max_mean 1580.7214 (1577.2461) nleep/row_max_std 52.3214 (57.0283) nleep/row_min_mean 1533.5693 (1546.9491) lr 1.9980e-03 eta 0:17:28
epoch [3/50] batch [160/181] time 0.145 (0.126) data 0.000 (0.002) loss 1.8311 (1.6735) teacher_loss 0.4412 (0.3153) loss_zs_kd 0.0141 (0.0269) loss_oracle 0.7262 (0.6986) kd_loss 1.0198 (0.9954) acc 78.1250 (88.6719) gate/entropy 1.0960 (1.0979) gate/usage_max 0.3612 (0.3441) gate/usage_min 0.3028 (0.3178) gate/usage_std 0.0239 (0.0114) teacher/entropy 0.0189 (0.0800) teacher/usage_max 0.7187 (0.6105) teacher/usage_min 0.0011 (0.0679) teacher/usage_std 0.2953 (0.2306) nleep/row_max_mean 1575.2295 (1577.1058) nleep/row_max_std 68.1591 (56.8499) nleep/row_min_mean 1527.5923 (1544.8545) lr 1.9980e-03 eta 0:17:56
epoch [3/50] batch [180/181] time 0.140 (0.127) data 0.000 (0.002) loss 1.6605 (1.6809) teacher_loss 0.2277 (0.3220) loss_zs_kd 0.0101 (0.0259) loss_oracle 0.8268 (0.7028) kd_loss 1.0144 (0.9946) acc 90.6250 (88.3333) gate/entropy 1.0951 (1.0976) gate/usage_max 0.3672 (0.3464) gate/usage_min 0.2989 (0.3159) gate/usage_std 0.0279 (0.0130) teacher/entropy 0.0078 (0.0759) teacher/usage_max 0.7825 (0.6254) teacher/usage_min 0.0000 (0.0610) teacher/usage_std 0.3298 (0.2395) nleep/row_max_mean 1587.1372 (1576.9433) nleep/row_max_std 51.7704 (57.0541) nleep/row_min_mean 1535.9352 (1543.0843) lr 1.9980e-03 eta 0:18:01
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,385
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [4/50] batch [20/181] time 0.150 (0.171) data 0.000 (0.013) loss 1.4538 (1.6852) teacher_loss 0.1182 (0.3357) loss_zs_kd 0.0141 (0.0152) loss_oracle 0.6612 (0.7539) kd_loss 0.9980 (0.9650) acc 96.8750 (86.0938) gate/entropy 1.0940 (1.0945) gate/usage_max 0.3733 (0.3706) gate/usage_min 0.2950 (0.2967) gate/usage_std 0.0320 (0.0301) teacher/entropy 0.0383 (0.0605) teacher/usage_max 0.5670 (0.6952) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2420 (0.2891) nleep/row_max_mean 1573.3180 (1573.1959) nleep/row_max_std 60.9167 (60.1701) nleep/row_min_mean 1525.3635 (1524.4689) lr 1.9921e-03 eta 0:24:10
epoch [4/50] batch [40/181] time 0.165 (0.164) data 0.000 (0.007) loss 1.9138 (1.7017) teacher_loss 0.5508 (0.3612) loss_zs_kd 0.0253 (0.0151) loss_oracle 0.8416 (0.7533) kd_loss 0.9295 (0.9563) acc 78.1250 (85.6250) gate/entropy 1.0927 (1.0939) gate/usage_max 0.3797 (0.3736) gate/usage_min 0.2909 (0.2948) gate/usage_std 0.0364 (0.0322) teacher/entropy 0.0549 (0.0607) teacher/usage_max 0.8852 (0.7259) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.3930 (0.3031) nleep/row_max_mean 1579.3193 (1571.7982) nleep/row_max_std 53.5904 (60.1124) nleep/row_min_mean 1525.8782 (1522.7912) lr 1.9921e-03 eta 0:23:12
epoch [4/50] batch [60/181] time 0.081 (0.142) data 0.000 (0.005) loss 1.7216 (1.6960) teacher_loss 0.4896 (0.3637) loss_zs_kd 0.0172 (0.0139) loss_oracle 0.6874 (0.7659) kd_loss 0.8797 (0.9424) acc 78.1250 (85.6771) gate/entropy 1.0911 (1.0932) gate/usage_max 0.3866 (0.3768) gate/usage_min 0.2871 (0.2929) gate/usage_std 0.0409 (0.0344) teacher/entropy 0.1013 (0.0641) teacher/usage_max 0.8167 (0.7615) teacher/usage_min 0.0005 (0.0035) teacher/usage_std 0.3498 (0.3223) nleep/row_max_mean 1564.9548 (1571.6377) nleep/row_max_std 61.4558 (60.7068) nleep/row_min_mean 1519.3818 (1522.1005) lr 1.9921e-03 eta 0:19:57
epoch [4/50] batch [80/181] time 0.096 (0.138) data 0.000 (0.003) loss 1.5288 (1.6833) teacher_loss 0.2840 (0.3657) loss_zs_kd 0.0046 (0.0139) loss_oracle 0.6739 (0.7636) kd_loss 0.9056 (0.9289) acc 87.5000 (85.7422) gate/entropy 1.0892 (1.0925) gate/usage_max 0.3943 (0.3803) gate/usage_min 0.2834 (0.2909) gate/usage_std 0.0460 (0.0367) teacher/entropy 0.0451 (0.0663) teacher/usage_max 0.9000 (0.7921) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.4028 (0.3400) nleep/row_max_mean 1572.5974 (1571.4067) nleep/row_max_std 52.7905 (61.0886) nleep/row_min_mean 1524.4294 (1521.2782) lr 1.9921e-03 eta 0:19:21
epoch [4/50] batch [100/181] time 0.117 (0.135) data 0.000 (0.003) loss 1.7327 (1.6734) teacher_loss 0.4908 (0.3737) loss_zs_kd 0.0220 (0.0145) loss_oracle 0.7013 (0.7476) kd_loss 0.8803 (0.9187) acc 81.2500 (85.5625) gate/entropy 1.0870 (1.0916) gate/usage_max 0.4021 (0.3839) gate/usage_min 0.2797 (0.2890) gate/usage_std 0.0511 (0.0391) teacher/entropy 0.0595 (0.0660) teacher/usage_max 0.8767 (0.8136) teacher/usage_min 0.0001 (0.0036) teacher/usage_std 0.3875 (0.3525) nleep/row_max_mean 1560.6559 (1571.1535) nleep/row_max_std 63.3376 (60.9930) nleep/row_min_mean 1511.2603 (1520.8190) lr 1.9921e-03 eta 0:18:52
epoch [4/50] batch [120/181] time 0.096 (0.130) data 0.000 (0.002) loss 1.6211 (1.6750) teacher_loss 0.3397 (0.3858) loss_zs_kd 0.0115 (0.0154) loss_oracle 0.7502 (0.7432) kd_loss 0.9006 (0.9099) acc 87.5000 (85.0000) gate/entropy 1.0846 (1.0906) gate/usage_max 0.4101 (0.3877) gate/usage_min 0.2759 (0.2871) gate/usage_std 0.0565 (0.0416) teacher/entropy 0.0295 (0.0653) teacher/usage_max 0.8524 (0.8270) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.3719 (0.3603) nleep/row_max_mean 1575.2253 (1570.3879) nleep/row_max_std 60.7575 (60.6330) nleep/row_min_mean 1520.9669 (1520.0317) lr 1.9921e-03 eta 0:18:11
epoch [4/50] batch [140/181] time 0.090 (0.127) data 0.000 (0.002) loss 1.5494 (1.6577) teacher_loss 0.3688 (0.3764) loss_zs_kd 0.0142 (0.0152) loss_oracle 0.7166 (0.7415) kd_loss 0.8152 (0.9028) acc 81.2500 (85.4018) gate/entropy 1.0820 (1.0896) gate/usage_max 0.4176 (0.3914) gate/usage_min 0.2726 (0.2853) gate/usage_std 0.0615 (0.0441) teacher/entropy 0.0807 (0.0631) teacher/usage_max 0.9230 (0.8376) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4181 (0.3666) nleep/row_max_mean 1560.8882 (1569.4846) nleep/row_max_std 63.7112 (60.6327) nleep/row_min_mean 1511.7324 (1519.0916) lr 1.9921e-03 eta 0:17:45
epoch [4/50] batch [160/181] time 0.123 (0.126) data 0.000 (0.002) loss 1.6515 (1.6457) teacher_loss 0.4294 (0.3723) loss_zs_kd 0.0216 (0.0155) loss_oracle 0.7462 (0.7380) kd_loss 0.8383 (0.8967) acc 81.2500 (85.6641) gate/entropy 1.0793 (1.0884) gate/usage_max 0.4248 (0.3952) gate/usage_min 0.2695 (0.2835) gate/usage_std 0.0664 (0.0466) teacher/entropy 0.0309 (0.0607) teacher/usage_max 0.9594 (0.8444) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4430 (0.3706) nleep/row_max_mean 1551.1224 (1568.3786) nleep/row_max_std 68.4429 (60.5807) nleep/row_min_mean 1504.7734 (1518.2092) lr 1.9921e-03 eta 0:17:30
epoch [4/50] batch [180/181] time 0.154 (0.125) data 0.000 (0.002) loss 1.7892 (1.6375) teacher_loss 0.6116 (0.3719) loss_zs_kd 0.0108 (0.0154) loss_oracle 0.6566 (0.7337) kd_loss 0.8439 (0.8911) acc 78.1250 (85.5208) gate/entropy 1.0761 (1.0872) gate/usage_max 0.4328 (0.3990) gate/usage_min 0.2659 (0.2817) gate/usage_std 0.0718 (0.0491) teacher/entropy 0.0178 (0.0589) teacher/usage_max 0.9327 (0.8476) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.4247 (0.3722) nleep/row_max_mean 1569.9731 (1567.3081) nleep/row_max_std 56.6314 (60.6314) nleep/row_min_mean 1515.2540 (1517.3330) lr 1.9921e-03 eta 0:17:17
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [5/50] batch [20/181] time 0.134 (0.165) data 0.000 (0.017) loss 1.4750 (1.5345) teacher_loss 0.2991 (0.3825) loss_zs_kd 0.0107 (0.0148) loss_oracle 0.6628 (0.6434) kd_loss 0.8391 (0.8229) acc 90.6250 (85.4688) gate/entropy 1.0732 (1.0745) gate/usage_max 0.4396 (0.4367) gate/usage_min 0.2629 (0.2641) gate/usage_std 0.0765 (0.0745) teacher/entropy 0.0071 (0.0459) teacher/usage_max 0.9370 (0.8939) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4276 (0.3996) nleep/row_max_mean 1545.9020 (1559.7471) nleep/row_max_std 57.5374 (58.3196) nleep/row_min_mean 1505.2056 (1512.3325) lr 1.9823e-03 eta 0:22:53
epoch [5/50] batch [40/181] time 0.125 (0.154) data 0.000 (0.008) loss 1.4679 (1.4971) teacher_loss 0.3389 (0.3452) loss_zs_kd 0.0281 (0.0147) loss_oracle 0.5983 (0.6425) kd_loss 0.8158 (0.8233) acc 81.2500 (86.9531) gate/entropy 1.0700 (1.0730) gate/usage_max 0.4466 (0.4401) gate/usage_min 0.2599 (0.2627) gate/usage_std 0.0812 (0.0768) teacher/entropy 0.0335 (0.0388) teacher/usage_max 0.8974 (0.8956) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4011 (0.4006) nleep/row_max_mean 1554.5160 (1558.2818) nleep/row_max_std 48.4968 (57.2786) nleep/row_min_mean 1515.8542 (1511.3380) lr 1.9823e-03 eta 0:21:13
epoch [5/50] batch [60/181] time 0.150 (0.150) data 0.000 (0.006) loss 1.4354 (1.5028) teacher_loss 0.2705 (0.3529) loss_zs_kd 0.0225 (0.0169) loss_oracle 0.6720 (0.6406) kd_loss 0.8177 (0.8211) acc 93.7500 (86.8750) gate/entropy 1.0669 (1.0714) gate/usage_max 0.4529 (0.4434) gate/usage_min 0.2573 (0.2613) gate/usage_std 0.0856 (0.0791) teacher/entropy 0.0247 (0.0367) teacher/usage_max 0.8916 (0.8922) teacher/usage_min 0.0148 (0.0062) teacher/usage_std 0.3961 (0.3980) nleep/row_max_mean 1554.4280 (1554.2431) nleep/row_max_std 62.4695 (58.7499) nleep/row_min_mean 1509.4585 (1507.9783) lr 1.9823e-03 eta 0:20:40
epoch [5/50] batch [80/181] time 0.164 (0.151) data 0.000 (0.004) loss 1.5048 (1.5009) teacher_loss 0.3523 (0.3525) loss_zs_kd 0.0236 (0.0171) loss_oracle 0.6402 (0.6395) kd_loss 0.8206 (0.8201) acc 81.2500 (86.7578) gate/entropy 1.0637 (1.0698) gate/usage_max 0.4593 (0.4467) gate/usage_min 0.2546 (0.2599) gate/usage_std 0.0900 (0.0813) teacher/entropy 0.0020 (0.0339) teacher/usage_max 0.9059 (0.8882) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.4067 (0.3951) nleep/row_max_mean 1548.9500 (1554.3995) nleep/row_max_std 71.2068 (59.1224) nleep/row_min_mean 1502.7561 (1507.9641) lr 1.9823e-03 eta 0:20:42
epoch [5/50] batch [100/181] time 0.121 (0.149) data 0.000 (0.003) loss 1.4868 (1.5021) teacher_loss 0.3342 (0.3527) loss_zs_kd 0.0340 (0.0177) loss_oracle 0.7103 (0.6467) kd_loss 0.7804 (0.8172) acc 84.3750 (86.5625) gate/entropy 1.0605 (1.0682) gate/usage_max 0.4654 (0.4499) gate/usage_min 0.2522 (0.2585) gate/usage_std 0.0942 (0.0835) teacher/entropy 0.0166 (0.0317) teacher/usage_max 0.9350 (0.8868) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.4263 (0.3943) nleep/row_max_mean 1538.4185 (1555.0113) nleep/row_max_std 75.7898 (59.8490) nleep/row_min_mean 1493.5541 (1508.3862) lr 1.9823e-03 eta 0:20:25
epoch [5/50] batch [120/181] time 0.157 (0.149) data 0.001 (0.003) loss 1.4060 (1.5014) teacher_loss 0.3465 (0.3551) loss_zs_kd 0.0088 (0.0178) loss_oracle 0.5959 (0.6475) kd_loss 0.7571 (0.8136) acc 87.5000 (86.4583) gate/entropy 1.0571 (1.0667) gate/usage_max 0.4715 (0.4530) gate/usage_min 0.2499 (0.2573) gate/usage_std 0.0984 (0.0857) teacher/entropy 0.0122 (0.0302) teacher/usage_max 0.9662 (0.8867) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.4477 (0.3941) nleep/row_max_mean 1561.1531 (1554.4080) nleep/row_max_std 55.2483 (60.8708) nleep/row_min_mean 1511.8009 (1507.8755) lr 1.9823e-03 eta 0:20:20
epoch [5/50] batch [140/181] time 0.125 (0.149) data 0.000 (0.003) loss 1.3689 (1.4960) teacher_loss 0.2426 (0.3556) loss_zs_kd 0.0097 (0.0177) loss_oracle 0.6825 (0.6432) kd_loss 0.7802 (0.8099) acc 93.7500 (86.4286) gate/entropy 1.0536 (1.0651) gate/usage_max 0.4775 (0.4560) gate/usage_min 0.2475 (0.2561) gate/usage_std 0.1025 (0.0878) teacher/entropy 0.0127 (0.0292) teacher/usage_max 0.9021 (0.8857) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.4042 (0.3935) nleep/row_max_mean 1575.0422 (1554.2567) nleep/row_max_std 59.7687 (60.9404) nleep/row_min_mean 1522.7402 (1507.6267) lr 1.9823e-03 eta 0:20:23
epoch [5/50] batch [160/181] time 0.140 (0.150) data 0.000 (0.002) loss 1.3024 (1.4906) teacher_loss 0.2527 (0.3575) loss_zs_kd 0.0101 (0.0178) loss_oracle 0.5937 (0.6395) kd_loss 0.7478 (0.8044) acc 87.5000 (86.3477) gate/entropy 1.0505 (1.0634) gate/usage_max 0.4825 (0.4590) gate/usage_min 0.2456 (0.2549) gate/usage_std 0.1060 (0.0898) teacher/entropy 0.0139 (0.0288) teacher/usage_max 0.9421 (0.8871) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.4311 (0.3945) nleep/row_max_mean 1548.0540 (1554.3699) nleep/row_max_std 67.1777 (61.0037) nleep/row_min_mean 1502.8962 (1507.5805) lr 1.9823e-03 eta 0:20:21
epoch [5/50] batch [180/181] time 0.073 (0.145) data 0.000 (0.002) loss 1.3126 (1.4797) teacher_loss 0.2949 (0.3555) loss_zs_kd 0.0152 (0.0172) loss_oracle 0.5670 (0.6340) kd_loss 0.7266 (0.7986) acc 90.6250 (86.4410) gate/entropy 1.0467 (1.0618) gate/usage_max 0.4886 (0.4620) gate/usage_min 0.2432 (0.2537) gate/usage_std 0.1103 (0.0919) teacher/entropy 0.0418 (0.0292) teacher/usage_max 0.9135 (0.8880) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.4118 (0.3952) nleep/row_max_mean 1566.1433 (1554.1005) nleep/row_max_std 59.8961 (61.1482) nleep/row_min_mean 1513.7408 (1507.4505) lr 1.9823e-03 eta 0:19:43
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [6/50] batch [20/181] time 0.077 (0.126) data 0.000 (0.013) loss 1.2634 (1.3646) teacher_loss 0.2407 (0.3127) loss_zs_kd 0.0136 (0.0176) loss_oracle 0.5231 (0.5951) kd_loss 0.7543 (0.7456) acc 93.7500 (89.5312) gate/entropy 1.0434 (1.0451) gate/usage_max 0.4938 (0.4912) gate/usage_min 0.2413 (0.2422) gate/usage_std 0.1139 (0.1121) teacher/entropy 0.0451 (0.0261) teacher/usage_max 0.8489 (0.9012) teacher/usage_min 0.0000 (0.0064) teacher/usage_std 0.3697 (0.4036) nleep/row_max_mean 1560.8813 (1560.6858) nleep/row_max_std 56.0280 (59.1644) nleep/row_min_mean 1510.4797 (1511.7975) lr 1.9686e-03 eta 0:17:02
epoch [6/50] batch [40/181] time 0.104 (0.109) data 0.000 (0.007) loss 1.1836 (1.3621) teacher_loss 0.1385 (0.3105) loss_zs_kd 0.0084 (0.0173) loss_oracle 0.5982 (0.6063) kd_loss 0.7419 (0.7399) acc 93.7500 (88.8281) gate/entropy 1.0402 (1.0434) gate/usage_max 0.4986 (0.4937) gate/usage_min 0.2396 (0.2413) gate/usage_std 0.1172 (0.1138) teacher/entropy 0.0277 (0.0253) teacher/usage_max 0.8848 (0.9051) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3928 (0.4064) nleep/row_max_mean 1570.9677 (1560.7610) nleep/row_max_std 39.9988 (58.5943) nleep/row_min_mean 1522.6991 (1512.0441) lr 1.9686e-03 eta 0:14:40
epoch [6/50] batch [60/181] time 0.070 (0.113) data 0.000 (0.005) loss 1.4909 (1.3618) teacher_loss 0.4595 (0.3127) loss_zs_kd 0.0115 (0.0167) loss_oracle 0.5707 (0.5978) kd_loss 0.7402 (0.7419) acc 84.3750 (88.4375) gate/entropy 1.0374 (1.0418) gate/usage_max 0.5027 (0.4962) gate/usage_min 0.2382 (0.2405) gate/usage_std 0.1201 (0.1155) teacher/entropy 0.0086 (0.0239) teacher/usage_max 0.9063 (0.8981) teacher/usage_min 0.0021 (0.0049) teacher/usage_std 0.4068 (0.4018) nleep/row_max_mean 1552.1877 (1558.8912) nleep/row_max_std 60.9856 (58.0418) nleep/row_min_mean 1506.0842 (1510.5478) lr 1.9686e-03 eta 0:15:09
epoch [6/50] batch [80/181] time 0.173 (0.114) data 0.000 (0.003) loss 1.3988 (1.3585) teacher_loss 0.3437 (0.3136) loss_zs_kd 0.0297 (0.0161) loss_oracle 0.5517 (0.5939) kd_loss 0.7644 (0.7399) acc 90.6250 (88.7500) gate/entropy 1.0343 (1.0402) gate/usage_max 0.5072 (0.4985) gate/usage_min 0.2365 (0.2396) gate/usage_std 0.1232 (0.1171) teacher/entropy 0.0174 (0.0237) teacher/usage_max 0.8489 (0.8961) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.3698 (0.4004) nleep/row_max_mean 1538.4731 (1558.7893) nleep/row_max_std 55.8989 (57.3237) nleep/row_min_mean 1498.4491 (1510.9199) lr 1.9686e-03 eta 0:15:19
epoch [6/50] batch [100/181] time 0.083 (0.112) data 0.000 (0.003) loss 1.3450 (1.3616) teacher_loss 0.4144 (0.3208) loss_zs_kd 0.0225 (0.0166) loss_oracle 0.4840 (0.5883) kd_loss 0.6773 (0.7384) acc 81.2500 (88.4688) gate/entropy 1.0313 (1.0387) gate/usage_max 0.5113 (0.5007) gate/usage_min 0.2349 (0.2388) gate/usage_std 0.1261 (0.1187) teacher/entropy 0.0620 (0.0220) teacher/usage_max 0.9075 (0.8959) teacher/usage_min 0.0405 (0.0071) teacher/usage_std 0.4060 (0.4002) nleep/row_max_mean 1543.3082 (1558.1193) nleep/row_max_std 60.1767 (56.5681) nleep/row_min_mean 1499.8740 (1510.8629) lr 1.9686e-03 eta 0:15:00
epoch [6/50] batch [120/181] time 0.142 (0.112) data 0.000 (0.002) loss 1.5111 (1.3592) teacher_loss 0.5300 (0.3246) loss_zs_kd 0.0163 (0.0165) loss_oracle 0.5161 (0.5766) kd_loss 0.7150 (0.7381) acc 84.3750 (88.2292) gate/entropy 1.0284 (1.0372) gate/usage_max 0.5151 (0.5028) gate/usage_min 0.2334 (0.2380) gate/usage_std 0.1288 (0.1201) teacher/entropy 0.0202 (0.0204) teacher/usage_max 0.8994 (0.8940) teacher/usage_min 0.0003 (0.0063) teacher/usage_std 0.4023 (0.3991) nleep/row_max_mean 1560.4249 (1557.9952) nleep/row_max_std 58.8122 (56.3763) nleep/row_min_mean 1512.7075 (1510.8584) lr 1.9686e-03 eta 0:14:58
epoch [6/50] batch [140/181] time 0.129 (0.116) data 0.000 (0.002) loss 1.4162 (1.3650) teacher_loss 0.3894 (0.3347) loss_zs_kd 0.0279 (0.0171) loss_oracle 0.5362 (0.5724) kd_loss 0.7447 (0.7355) acc 84.3750 (87.7902) gate/entropy 1.0261 (1.0358) gate/usage_max 0.5182 (0.5048) gate/usage_min 0.2323 (0.2373) gate/usage_std 0.1309 (0.1215) teacher/entropy 0.0236 (0.0189) teacher/usage_max 0.8483 (0.8955) teacher/usage_min 0.0001 (0.0065) teacher/usage_std 0.3694 (0.4001) nleep/row_max_mean 1556.8688 (1558.2110) nleep/row_max_std 58.6208 (56.2001) nleep/row_min_mean 1510.6381 (1511.1086) lr 1.9686e-03 eta 0:15:29
epoch [6/50] batch [160/181] time 0.166 (0.121) data 0.000 (0.002) loss 1.2764 (1.3639) teacher_loss 0.2904 (0.3372) loss_zs_kd 0.0126 (0.0171) loss_oracle 0.5638 (0.5691) kd_loss 0.6978 (0.7336) acc 87.5000 (87.7344) gate/entropy 1.0236 (1.0344) gate/usage_max 0.5215 (0.5067) gate/usage_min 0.2312 (0.2366) gate/usage_std 0.1332 (0.1229) teacher/entropy 0.0001 (0.0185) teacher/usage_max 0.9375 (0.8948) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.4280 (0.3997) nleep/row_max_mean 1561.8088 (1558.2121) nleep/row_max_std 61.9921 (55.9337) nleep/row_min_mean 1506.7505 (1511.0913) lr 1.9686e-03 eta 0:16:03
epoch [6/50] batch [180/181] time 0.139 (0.124) data 0.000 (0.002) loss 1.2842 (1.3622) teacher_loss 0.2069 (0.3386) loss_zs_kd 0.0193 (0.0170) loss_oracle 0.5863 (0.5685) kd_loss 0.7744 (0.7309) acc 90.6250 (87.5868) gate/entropy 1.0209 (1.0330) gate/usage_max 0.5250 (0.5085) gate/usage_min 0.2298 (0.2359) gate/usage_std 0.1357 (0.1241) teacher/entropy 0.0106 (0.0177) teacher/usage_max 0.8154 (0.8958) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.3491 (0.4003) nleep/row_max_mean 1568.9688 (1558.7979) nleep/row_max_std 58.0147 (55.4818) nleep/row_min_mean 1513.9535 (1511.1644) lr 1.9686e-03 eta 0:16:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,400
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [7/50] batch [20/181] time 0.164 (0.175) data 0.000 (0.018) loss 1.2258 (1.2894) teacher_loss 0.2514 (0.3201) loss_zs_kd 0.0214 (0.0208) loss_oracle 0.5271 (0.5385) kd_loss 0.7002 (0.6897) acc 93.7500 (88.9062) gate/entropy 1.0184 (1.0197) gate/usage_max 0.5281 (0.5266) gate/usage_min 0.2288 (0.2293) gate/usage_std 0.1378 (0.1368) teacher/entropy 0.0239 (0.0227) teacher/usage_max 0.8895 (0.9078) teacher/usage_min 0.0003 (0.0036) teacher/usage_std 0.3958 (0.4082) nleep/row_max_mean 1565.0928 (1559.5389) nleep/row_max_std 51.5876 (53.4268) nleep/row_min_mean 1514.3256 (1507.7095) lr 1.9511e-03 eta 0:23:09
epoch [7/50] batch [40/181] time 0.160 (0.163) data 0.000 (0.009) loss 1.3052 (1.2951) teacher_loss 0.3509 (0.3266) loss_zs_kd 0.0064 (0.0190) loss_oracle 0.5419 (0.5390) kd_loss 0.6802 (0.6895) acc 87.5000 (88.4375) gate/entropy 1.0164 (1.0184) gate/usage_max 0.5306 (0.5281) gate/usage_min 0.2279 (0.2287) gate/usage_std 0.1396 (0.1379) teacher/entropy 0.0023 (0.0177) teacher/usage_max 0.9379 (0.9115) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.4283 (0.4106) nleep/row_max_mean 1555.7439 (1562.9779) nleep/row_max_std 62.5063 (54.0248) nleep/row_min_mean 1502.9999 (1510.2181) lr 1.9511e-03 eta 0:21:30
epoch [7/50] batch [60/181] time 0.080 (0.154) data 0.001 (0.006) loss 1.3171 (1.2840) teacher_loss 0.4111 (0.3232) loss_zs_kd 0.0280 (0.0180) loss_oracle 0.4870 (0.5286) kd_loss 0.6484 (0.6875) acc 81.2500 (88.2812) gate/entropy 1.0140 (1.0173) gate/usage_max 0.5336 (0.5295) gate/usage_min 0.2268 (0.2283) gate/usage_std 0.1417 (0.1388) teacher/entropy 0.0313 (0.0175) teacher/usage_max 0.9358 (0.9116) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.4268 (0.4108) nleep/row_max_mean 1558.7423 (1560.6696) nleep/row_max_std 50.6242 (54.7476) nleep/row_min_mean 1508.8480 (1509.0137) lr 1.9511e-03 eta 0:20:17
epoch [7/50] batch [80/181] time 0.078 (0.141) data 0.000 (0.005) loss 1.1796 (1.2758) teacher_loss 0.2320 (0.3215) loss_zs_kd 0.0244 (0.0172) loss_oracle 0.4953 (0.5253) kd_loss 0.6877 (0.6830) acc 93.7500 (88.2422) gate/entropy 1.0120 (1.0163) gate/usage_max 0.5360 (0.5308) gate/usage_min 0.2260 (0.2278) gate/usage_std 0.1434 (0.1397) teacher/entropy 0.0417 (0.0177) teacher/usage_max 0.8710 (0.9148) teacher/usage_min 0.0261 (0.0030) teacher/usage_std 0.3815 (0.4129) nleep/row_max_mean 1547.1414 (1558.6291) nleep/row_max_std 63.2065 (54.5308) nleep/row_min_mean 1504.5999 (1507.8062) lr 1.9511e-03 eta 0:18:30
epoch [7/50] batch [100/181] time 0.082 (0.135) data 0.000 (0.004) loss 1.3748 (1.2618) teacher_loss 0.4692 (0.3204) loss_zs_kd 0.0175 (0.0167) loss_oracle 0.4655 (0.5183) kd_loss 0.6641 (0.6739) acc 84.3750 (88.3125) gate/entropy 1.0099 (1.0152) gate/usage_max 0.5385 (0.5321) gate/usage_min 0.2251 (0.2274) gate/usage_std 0.1452 (0.1406) teacher/entropy 0.0432 (0.0207) teacher/usage_max 0.8944 (0.9199) teacher/usage_min 0.0300 (0.0031) teacher/usage_std 0.3971 (0.4163) nleep/row_max_mean 1551.6788 (1557.8257) nleep/row_max_std 49.4512 (54.1512) nleep/row_min_mean 1509.2599 (1507.6204) lr 1.9511e-03 eta 0:17:38
epoch [7/50] batch [120/181] time 0.076 (0.132) data 0.000 (0.003) loss 1.2359 (1.2561) teacher_loss 0.3175 (0.3241) loss_zs_kd 0.0192 (0.0163) loss_oracle 0.5352 (0.5125) kd_loss 0.6412 (0.6675) acc 87.5000 (88.0208) gate/entropy 1.0084 (1.0142) gate/usage_max 0.5403 (0.5333) gate/usage_min 0.2246 (0.2270) gate/usage_std 0.1464 (0.1415) teacher/entropy 0.0007 (0.0233) teacher/usage_max 0.9687 (0.9224) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.4494 (0.4180) nleep/row_max_mean 1537.4895 (1555.7400) nleep/row_max_std 68.6605 (53.7675) nleep/row_min_mean 1492.7495 (1506.1868) lr 1.9511e-03 eta 0:17:13
epoch [7/50] batch [140/181] time 0.078 (0.129) data 0.000 (0.003) loss 1.2140 (1.2556) teacher_loss 0.3889 (0.3297) loss_zs_kd 0.0125 (0.0166) loss_oracle 0.4557 (0.5102) kd_loss 0.5910 (0.6625) acc 81.2500 (87.7232) gate/entropy 1.0064 (1.0132) gate/usage_max 0.5426 (0.5344) gate/usage_min 0.2238 (0.2266) gate/usage_std 0.1480 (0.1423) teacher/entropy 0.0309 (0.0241) teacher/usage_max 0.9875 (0.9252) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.4626 (0.4199) nleep/row_max_mean 1555.9685 (1555.0800) nleep/row_max_std 47.4899 (53.5403) nleep/row_min_mean 1510.8040 (1505.8736) lr 1.9511e-03 eta 0:16:49
epoch [7/50] batch [160/181] time 0.099 (0.126) data 0.000 (0.003) loss 1.1280 (1.2503) teacher_loss 0.2524 (0.3295) loss_zs_kd 0.0094 (0.0161) loss_oracle 0.4490 (0.5060) kd_loss 0.6464 (0.6597) acc 90.6250 (87.6953) gate/entropy 1.0054 (1.0123) gate/usage_max 0.5438 (0.5356) gate/usage_min 0.2235 (0.2262) gate/usage_std 0.1489 (0.1431) teacher/entropy 0.0181 (0.0243) teacher/usage_max 0.9353 (0.9262) teacher/usage_min 0.0005 (0.0029) teacher/usage_std 0.4265 (0.4206) nleep/row_max_mean 1528.1238 (1554.0246) nleep/row_max_std 49.1583 (53.1866) nleep/row_min_mean 1488.3636 (1505.3036) lr 1.9511e-03 eta 0:16:26
epoch [7/50] batch [180/181] time 0.151 (0.124) data 0.000 (0.002) loss 1.0598 (1.2456) teacher_loss 0.1792 (0.3291) loss_zs_kd 0.0075 (0.0158) loss_oracle 0.4768 (0.5041) kd_loss 0.6385 (0.6565) acc 90.6250 (87.7083) gate/entropy 1.0033 (1.0114) gate/usage_max 0.5463 (0.5367) gate/usage_min 0.2226 (0.2258) gate/usage_std 0.1506 (0.1439) teacher/entropy 0.0481 (0.0262) teacher/usage_max 0.9047 (0.9259) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.4059 (0.4204) nleep/row_max_mean 1543.2302 (1553.6619) nleep/row_max_std 51.8878 (52.6181) nleep/row_min_mean 1507.4656 (1505.6491) lr 1.9511e-03 eta 0:16:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,406
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [8/50] batch [20/181] time 0.108 (0.150) data 0.000 (0.014) loss 1.4351 (1.2490) teacher_loss 0.6197 (0.3578) loss_zs_kd 0.0130 (0.0206) loss_oracle 0.4723 (0.5047) kd_loss 0.5727 (0.6285) acc 87.5000 (87.3438) gate/entropy 1.0026 (1.0027) gate/usage_max 0.5471 (0.5470) gate/usage_min 0.2224 (0.2224) gate/usage_std 0.1512 (0.1511) teacher/entropy 0.0844 (0.0414) teacher/usage_max 0.9378 (0.9232) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.4282 (0.4182) nleep/row_max_mean 1531.6431 (1545.3671) nleep/row_max_std 57.3437 (47.4493) nleep/row_min_mean 1493.7344 (1502.7091) lr 1.9298e-03 eta 0:19:20
epoch [8/50] batch [40/181] time 0.151 (0.147) data 0.000 (0.007) loss 1.0049 (1.2153) teacher_loss 0.2217 (0.3502) loss_zs_kd 0.0085 (0.0165) loss_oracle 0.4153 (0.4877) kd_loss 0.5713 (0.6130) acc 96.8750 (87.6562) gate/entropy 1.0003 (1.0020) gate/usage_max 0.5496 (0.5477) gate/usage_min 0.2215 (0.2221) gate/usage_std 0.1530 (0.1516) teacher/entropy 0.0430 (0.0340) teacher/usage_max 0.9820 (0.9481) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4587 (0.4354) nleep/row_max_mean 1568.2703 (1545.8658) nleep/row_max_std 46.6583 (49.5526) nleep/row_min_mean 1519.9705 (1502.7920) lr 1.9298e-03 eta 0:18:55
epoch [8/50] batch [60/181] time 0.161 (0.148) data 0.000 (0.005) loss 1.1785 (1.2252) teacher_loss 0.3578 (0.3708) loss_zs_kd 0.0155 (0.0166) loss_oracle 0.4520 (0.4770) kd_loss 0.5869 (0.6076) acc 87.5000 (86.4062) gate/entropy 0.9997 (1.0013) gate/usage_max 0.5503 (0.5485) gate/usage_min 0.2214 (0.2219) gate/usage_std 0.1535 (0.1522) teacher/entropy 0.0130 (0.0292) teacher/usage_max 0.9970 (0.9583) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.4693 (0.4424) nleep/row_max_mean 1543.1763 (1547.5444) nleep/row_max_std 56.1007 (50.4929) nleep/row_min_mean 1496.3743 (1503.9755) lr 1.9298e-03 eta 0:19:00
epoch [8/50] batch [80/181] time 0.158 (0.148) data 0.000 (0.004) loss 1.2025 (1.2120) teacher_loss 0.3521 (0.3615) loss_zs_kd 0.0093 (0.0158) loss_oracle 0.5109 (0.4762) kd_loss 0.5903 (0.6045) acc 81.2500 (86.6016) gate/entropy 0.9976 (1.0007) gate/usage_max 0.5526 (0.5492) gate/usage_min 0.2206 (0.2217) gate/usage_std 0.1551 (0.1527) teacher/entropy 0.0034 (0.0236) teacher/usage_max 0.9994 (0.9669) teacher/usage_min 0.0001 (0.0027) teacher/usage_std 0.4709 (0.4484) nleep/row_max_mean 1572.2290 (1548.1433) nleep/row_max_std 47.4798 (51.0422) nleep/row_min_mean 1526.6418 (1504.3433) lr 1.9298e-03 eta 0:19:01
epoch [8/50] batch [100/181] time 0.155 (0.148) data 0.000 (0.003) loss 1.3799 (1.2092) teacher_loss 0.5536 (0.3587) loss_zs_kd 0.0134 (0.0151) loss_oracle 0.4590 (0.4798) kd_loss 0.5901 (0.6030) acc 78.1250 (86.6562) gate/entropy 0.9971 (1.0000) gate/usage_max 0.5533 (0.5499) gate/usage_min 0.2205 (0.2215) gate/usage_std 0.1556 (0.1532) teacher/entropy 0.0021 (0.0205) teacher/usage_max 0.9997 (0.9707) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4712 (0.4510) nleep/row_max_mean 1538.2999 (1548.6347) nleep/row_max_std 51.5384 (51.9786) nleep/row_min_mean 1497.8230 (1504.5598) lr 1.9298e-03 eta 0:18:56
epoch [8/50] batch [120/181] time 0.152 (0.149) data 0.000 (0.002) loss 1.2958 (1.2009) teacher_loss 0.4735 (0.3533) loss_zs_kd 0.0064 (0.0142) loss_oracle 0.4599 (0.4794) kd_loss 0.5892 (0.6009) acc 84.3750 (86.7448) gate/entropy 0.9961 (0.9995) gate/usage_max 0.5544 (0.5506) gate/usage_min 0.2201 (0.2213) gate/usage_std 0.1563 (0.1537) teacher/entropy 0.0248 (0.0180) teacher/usage_max 0.9738 (0.9748) teacher/usage_min 0.0019 (0.0018) teacher/usage_std 0.4530 (0.4538) nleep/row_max_mean 1547.7507 (1549.3957) nleep/row_max_std 52.0344 (52.1848) nleep/row_min_mean 1504.2378 (1504.9217) lr 1.9298e-03 eta 0:19:00
epoch [8/50] batch [140/181] time 0.140 (0.150) data 0.000 (0.002) loss 1.1272 (1.1970) teacher_loss 0.3140 (0.3521) loss_zs_kd 0.0104 (0.0139) loss_oracle 0.4411 (0.4757) kd_loss 0.5874 (0.6001) acc 90.6250 (86.7188) gate/entropy 0.9948 (0.9989) gate/usage_max 0.5558 (0.5512) gate/usage_min 0.2197 (0.2211) gate/usage_std 0.1573 (0.1541) teacher/entropy 0.0000 (0.0166) teacher/usage_max 1.0000 (0.9760) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4714 (0.4547) nleep/row_max_mean 1553.3634 (1550.1288) nleep/row_max_std 50.4553 (51.9241) nleep/row_min_mean 1511.6501 (1505.7153) lr 1.9298e-03 eta 0:19:05
epoch [8/50] batch [160/181] time 0.137 (0.150) data 0.000 (0.002) loss 1.4422 (1.1971) teacher_loss 0.5928 (0.3538) loss_zs_kd 0.0320 (0.0138) loss_oracle 0.4969 (0.4748) kd_loss 0.5850 (0.5990) acc 75.0000 (86.6016) gate/entropy 0.9936 (0.9983) gate/usage_max 0.5571 (0.5519) gate/usage_min 0.2192 (0.2209) gate/usage_std 0.1582 (0.1546) teacher/entropy 0.0000 (0.0160) teacher/usage_max 1.0000 (0.9767) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4714 (0.4552) nleep/row_max_mean 1560.3790 (1551.4432) nleep/row_max_std 56.2962 (52.1512) nleep/row_min_mean 1511.0947 (1506.6825) lr 1.9298e-03 eta 0:19:00
epoch [8/50] batch [180/181] time 0.081 (0.143) data 0.000 (0.002) loss 1.2027 (1.2003) teacher_loss 0.4013 (0.3586) loss_zs_kd 0.0037 (0.0141) loss_oracle 0.4322 (0.4731) kd_loss 0.5835 (0.5981) acc 87.5000 (86.2847) gate/entropy 0.9931 (0.9978) gate/usage_max 0.5576 (0.5525) gate/usage_min 0.2191 (0.2207) gate/usage_std 0.1586 (0.1550) teacher/entropy 0.0006 (0.0146) teacher/usage_max 0.9999 (0.9781) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4713 (0.4561) nleep/row_max_mean 1569.9050 (1552.0065) nleep/row_max_std 43.9084 (52.5532) nleep/row_min_mean 1519.3760 (1507.0556) lr 1.9298e-03 eta 0:18:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [9/50] batch [20/181] time 0.142 (0.141) data 0.000 (0.015) loss 1.2319 (1.1837) teacher_loss 0.3857 (0.3417) loss_zs_kd 0.0254 (0.0170) loss_oracle 0.5017 (0.4760) kd_loss 0.5827 (0.5955) acc 87.5000 (86.8750) gate/entropy 0.9924 (0.9927) gate/usage_max 0.5584 (0.5581) gate/usage_min 0.2189 (0.2190) gate/usage_std 0.1591 (0.1589) teacher/entropy 0.0000 (0.0033) teacher/usage_max 1.0000 (0.9831) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4714 (0.4596) nleep/row_max_mean 1555.3938 (1558.7588) nleep/row_max_std 60.2314 (58.2964) nleep/row_min_mean 1505.1412 (1510.2474) lr 1.9048e-03 eta 0:17:48
epoch [9/50] batch [40/181] time 0.096 (0.116) data 0.000 (0.008) loss 1.1868 (1.1973) teacher_loss 0.3386 (0.3563) loss_zs_kd 0.0183 (0.0181) loss_oracle 0.5203 (0.4801) kd_loss 0.5789 (0.5919) acc 87.5000 (86.5625) gate/entropy 0.9915 (0.9922) gate/usage_max 0.5594 (0.5586) gate/usage_min 0.2185 (0.2188) gate/usage_std 0.1598 (0.1593) teacher/entropy 0.0026 (0.0047) teacher/usage_max 0.9995 (0.9847) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4711 (0.4606) nleep/row_max_mean 1551.6057 (1559.5208) nleep/row_max_std 53.3384 (57.3072) nleep/row_min_mean 1505.6418 (1510.4315) lr 1.9048e-03 eta 0:14:35
epoch [9/50] batch [60/181] time 0.076 (0.119) data 0.000 (0.005) loss 1.1601 (1.2091) teacher_loss 0.3343 (0.3696) loss_zs_kd 0.0059 (0.0164) loss_oracle 0.4897 (0.4863) kd_loss 0.5779 (0.5882) acc 87.5000 (85.8333) gate/entropy 0.9907 (0.9919) gate/usage_max 0.5602 (0.5590) gate/usage_min 0.2183 (0.2187) gate/usage_std 0.1604 (0.1596) teacher/entropy 0.0018 (0.0047) teacher/usage_max 0.9997 (0.9878) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4712 (0.4628) nleep/row_max_mean 1567.8453 (1560.4151) nleep/row_max_std 54.0822 (58.2144) nleep/row_min_mean 1517.1456 (1510.6718) lr 1.9048e-03 eta 0:14:54
epoch [9/50] batch [80/181] time 0.094 (0.117) data 0.000 (0.004) loss 1.1495 (1.2061) teacher_loss 0.3405 (0.3693) loss_zs_kd 0.0120 (0.0151) loss_oracle 0.4485 (0.4840) kd_loss 0.5788 (0.5873) acc 87.5000 (85.7812) gate/entropy 0.9903 (0.9915) gate/usage_max 0.5606 (0.5594) gate/usage_min 0.2182 (0.2185) gate/usage_std 0.1607 (0.1598) teacher/entropy 0.0000 (0.0041) teacher/usage_max 1.0000 (0.9888) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4714 (0.4636) nleep/row_max_mean 1541.4043 (1560.3274) nleep/row_max_std 69.7715 (58.3693) nleep/row_min_mean 1493.8430 (1510.4688) lr 1.9048e-03 eta 0:14:40
epoch [9/50] batch [100/181] time 0.174 (0.117) data 0.000 (0.003) loss 1.0844 (1.1989) teacher_loss 0.2942 (0.3636) loss_zs_kd 0.0089 (0.0149) loss_oracle 0.4184 (0.4805) kd_loss 0.5765 (0.5876) acc 87.5000 (86.2188) gate/entropy 0.9896 (0.9912) gate/usage_max 0.5614 (0.5597) gate/usage_min 0.2179 (0.2184) gate/usage_std 0.1613 (0.1601) teacher/entropy 0.0009 (0.0035) teacher/usage_max 0.9999 (0.9885) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4713 (0.4633) nleep/row_max_mean 1560.0481 (1560.0671) nleep/row_max_std 63.3667 (59.2500) nleep/row_min_mean 1511.8812 (1510.0913) lr 1.9048e-03 eta 0:14:37
epoch [9/50] batch [120/181] time 0.159 (0.120) data 0.000 (0.003) loss 1.2145 (1.1998) teacher_loss 0.3914 (0.3682) loss_zs_kd 0.0131 (0.0153) loss_oracle 0.4759 (0.4738) kd_loss 0.5786 (0.5871) acc 87.5000 (86.0417) gate/entropy 0.9890 (0.9908) gate/usage_max 0.5620 (0.5601) gate/usage_min 0.2177 (0.2183) gate/usage_std 0.1617 (0.1603) teacher/entropy 0.0186 (0.0036) teacher/usage_max 0.9775 (0.9882) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4556 (0.4632) nleep/row_max_mean 1549.5249 (1558.7546) nleep/row_max_std 66.7747 (59.3580) nleep/row_min_mean 1499.8379 (1508.9706) lr 1.9048e-03 eta 0:14:54
epoch [9/50] batch [140/181] time 0.137 (0.126) data 0.000 (0.002) loss 1.0850 (1.2045) teacher_loss 0.2871 (0.3714) loss_zs_kd 0.0066 (0.0148) loss_oracle 0.4392 (0.4777) kd_loss 0.5749 (0.5868) acc 90.6250 (86.0491) gate/entropy 0.9885 (0.9905) gate/usage_max 0.5626 (0.5604) gate/usage_min 0.2175 (0.2182) gate/usage_std 0.1621 (0.1606) teacher/entropy 0.0003 (0.0036) teacher/usage_max 1.0000 (0.9881) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4714 (0.4630) nleep/row_max_mean 1554.4658 (1558.1530) nleep/row_max_std 53.0503 (59.0017) nleep/row_min_mean 1510.0715 (1508.4189) lr 1.9048e-03 eta 0:15:39
epoch [9/50] batch [160/181] time 0.160 (0.131) data 0.000 (0.002) loss 1.2726 (1.2043) teacher_loss 0.4317 (0.3695) loss_zs_kd 0.0217 (0.0149) loss_oracle 0.5116 (0.4820) kd_loss 0.5742 (0.5864) acc 87.5000 (86.1719) gate/entropy 0.9880 (0.9902) gate/usage_max 0.5631 (0.5607) gate/usage_min 0.2173 (0.2181) gate/usage_std 0.1625 (0.1608) teacher/entropy 0.0000 (0.0038) teacher/usage_max 1.0000 (0.9877) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4714 (0.4627) nleep/row_max_mean 1560.2449 (1557.5484) nleep/row_max_std 40.1992 (58.3158) nleep/row_min_mean 1511.5701 (1507.9822) lr 1.9048e-03 eta 0:16:13
epoch [9/50] batch [180/181] time 0.163 (0.134) data 0.000 (0.002) loss 1.2395 (1.1932) teacher_loss 0.4244 (0.3594) loss_zs_kd 0.0145 (0.0147) loss_oracle 0.4697 (0.4806) kd_loss 0.5729 (0.5861) acc 84.3750 (86.5278) gate/entropy 0.9873 (0.9900) gate/usage_max 0.5639 (0.5610) gate/usage_min 0.2171 (0.2180) gate/usage_std 0.1630 (0.1610) teacher/entropy 0.0000 (0.0039) teacher/usage_max 1.0000 (0.9874) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4714 (0.4625) nleep/row_max_mean 1571.4890 (1556.9010) nleep/row_max_std 50.5392 (57.7067) nleep/row_min_mean 1518.6481 (1507.4825) lr 1.9048e-03 eta 0:16:36
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,403
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [10/50] batch [20/181] time 0.173 (0.164) data 0.000 (0.014) loss 1.1670 (1.2135) teacher_loss 0.3109 (0.3974) loss_zs_kd 0.0151 (0.0142) loss_oracle 0.4941 (0.4554) kd_loss 0.6016 (0.5813) acc 87.5000 (84.5312) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2169 (0.2171) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0003 (0.0036) teacher/usage_max 0.9688 (0.9874) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4495 (0.4625) nleep/row_max_mean 1567.4569 (1556.0006) nleep/row_max_std 40.0642 (48.9833) nleep/row_min_mean 1515.0815 (1507.9271) lr 1.8763e-03 eta 0:20:14
epoch [10/50] batch [40/181] time 0.151 (0.159) data 0.000 (0.007) loss 1.0991 (1.1738) teacher_loss 0.2564 (0.3544) loss_zs_kd 0.0182 (0.0143) loss_oracle 0.4646 (0.4562) kd_loss 0.6013 (0.5841) acc 90.6250 (86.4062) gate/entropy 0.9868 (0.9871) gate/usage_max 0.5644 (0.5641) gate/usage_min 0.2169 (0.2170) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0007 (0.0036) teacher/usage_max 0.9687 (0.9841) teacher/usage_min 0.0001 (0.0002) teacher/usage_std 0.4494 (0.4603) nleep/row_max_mean 1560.3098 (1556.5775) nleep/row_max_std 47.0000 (51.1037) nleep/row_min_mean 1511.4165 (1508.2580) lr 1.8763e-03 eta 0:19:34
epoch [10/50] batch [60/181] time 0.127 (0.141) data 0.001 (0.005) loss 1.1205 (1.1679) teacher_loss 0.3079 (0.3497) loss_zs_kd 0.0086 (0.0137) loss_oracle 0.4739 (0.4564) kd_loss 0.5714 (0.5832) acc 90.6250 (86.7188) gate/entropy 0.9864 (0.9869) gate/usage_max 0.5647 (0.5643) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0000 (0.0044) teacher/usage_max 1.0000 (0.9839) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4714 (0.4601) nleep/row_max_mean 1546.4424 (1554.6303) nleep/row_max_std 55.1407 (53.1500) nleep/row_min_mean 1504.1704 (1507.1316) lr 1.8763e-03 eta 0:17:19
epoch [10/50] batch [80/181] time 0.104 (0.135) data 0.000 (0.004) loss 1.0689 (1.1748) teacher_loss 0.2454 (0.3564) loss_zs_kd 0.0214 (0.0135) loss_oracle 0.4850 (0.4554) kd_loss 0.5703 (0.5838) acc 87.5000 (86.6016) gate/entropy 0.9858 (0.9867) gate/usage_max 0.5654 (0.5645) gate/usage_min 0.2166 (0.2169) gate/usage_std 0.1641 (0.1635) teacher/entropy 0.0000 (0.0046) teacher/usage_max 1.0000 (0.9827) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4714 (0.4593) nleep/row_max_mean 1563.9077 (1553.8796) nleep/row_max_std 51.6012 (52.9729) nleep/row_min_mean 1516.3663 (1507.2211) lr 1.8763e-03 eta 0:16:34
epoch [10/50] batch [100/181] time 0.093 (0.132) data 0.000 (0.003) loss 1.1923 (1.1747) teacher_loss 0.3492 (0.3527) loss_zs_kd 0.0224 (0.0142) loss_oracle 0.4659 (0.4585) kd_loss 0.5989 (0.5856) acc 90.6250 (87.0000) gate/entropy 0.9855 (0.9865) gate/usage_max 0.5657 (0.5647) gate/usage_min 0.2164 (0.2168) gate/usage_std 0.1643 (0.1636) teacher/entropy 0.0008 (0.0051) teacher/usage_max 0.9686 (0.9799) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4494 (0.4574) nleep/row_max_mean 1551.7003 (1552.8563) nleep/row_max_std 59.1010 (52.7199) nleep/row_min_mean 1506.3546 (1506.6160) lr 1.8763e-03 eta 0:16:06
epoch [10/50] batch [120/181] time 0.163 (0.130) data 0.000 (0.003) loss 1.1531 (1.1758) teacher_loss 0.3167 (0.3540) loss_zs_kd 0.0255 (0.0143) loss_oracle 0.4529 (0.4587) kd_loss 0.5972 (0.5852) acc 84.3750 (86.7969) gate/entropy 0.9855 (0.9863) gate/usage_max 0.5657 (0.5649) gate/usage_min 0.2165 (0.2168) gate/usage_std 0.1643 (0.1637) teacher/entropy 0.0030 (0.0059) teacher/usage_max 0.9682 (0.9791) teacher/usage_min 0.0006 (0.0005) teacher/usage_std 0.4491 (0.4568) nleep/row_max_mean 1536.8921 (1552.5292) nleep/row_max_std 50.9493 (52.5375) nleep/row_min_mean 1494.3409 (1506.6004) lr 1.8763e-03 eta 0:15:50
epoch [10/50] batch [140/181] time 0.092 (0.127) data 0.000 (0.002) loss 1.1579 (1.1760) teacher_loss 0.3246 (0.3542) loss_zs_kd 0.0198 (0.0143) loss_oracle 0.4383 (0.4578) kd_loss 0.6042 (0.5857) acc 84.3750 (86.7411) gate/entropy 0.9849 (0.9861) gate/usage_max 0.5664 (0.5651) gate/usage_min 0.2162 (0.2167) gate/usage_std 0.1648 (0.1639) teacher/entropy 0.0389 (0.0068) teacher/usage_max 0.9221 (0.9774) teacher/usage_min 0.0296 (0.0010) teacher/usage_std 0.4164 (0.4556) nleep/row_max_mean 1558.0867 (1551.5795) nleep/row_max_std 47.0041 (52.7025) nleep/row_min_mean 1518.6376 (1506.2534) lr 1.8763e-03 eta 0:15:21
epoch [10/50] batch [160/181] time 0.155 (0.126) data 0.000 (0.002) loss 1.2526 (1.1675) teacher_loss 0.4426 (0.3456) loss_zs_kd 0.0153 (0.0144) loss_oracle 0.4454 (0.4569) kd_loss 0.5797 (0.5862) acc 84.3750 (87.0898) gate/entropy 0.9846 (0.9860) gate/usage_max 0.5666 (0.5652) gate/usage_min 0.2161 (0.2166) gate/usage_std 0.1650 (0.1640) teacher/entropy 0.0139 (0.0077) teacher/usage_max 0.9735 (0.9756) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4528 (0.4543) nleep/row_max_mean 1540.0701 (1550.7771) nleep/row_max_std 55.3985 (52.8235) nleep/row_min_mean 1503.3657 (1506.0339) lr 1.8763e-03 eta 0:15:12
epoch [10/50] batch [180/181] time 0.075 (0.123) data 0.000 (0.002) loss 1.0267 (1.1647) teacher_loss 0.2331 (0.3434) loss_zs_kd 0.0186 (0.0146) loss_oracle 0.4463 (0.4572) kd_loss 0.5613 (0.5854) acc 90.6250 (87.2569) gate/entropy 0.9844 (0.9858) gate/usage_max 0.5668 (0.5654) gate/usage_min 0.2160 (0.2166) gate/usage_std 0.1651 (0.1641) teacher/entropy 0.0431 (0.0085) teacher/usage_max 0.9619 (0.9753) teacher/usage_min 0.0015 (0.0017) teacher/usage_std 0.4447 (0.4541) nleep/row_max_mean 1542.5078 (1549.6940) nleep/row_max_std 53.0794 (52.7756) nleep/row_min_mean 1509.3533 (1505.5571) lr 1.8763e-03 eta 0:14:52
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [11/50] batch [20/181] time 0.137 (0.167) data 0.000 (0.015) loss 1.3734 (1.1662) teacher_loss 0.5518 (0.3434) loss_zs_kd 0.0236 (0.0136) loss_oracle 0.4456 (0.4656) kd_loss 0.5870 (0.5832) acc 84.3750 (87.5000) gate/entropy 0.9838 (0.9842) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0313 (0.0156) teacher/usage_max 0.9465 (0.9673) teacher/usage_min 0.0187 (0.0059) teacher/usage_std 0.4336 (0.4485) nleep/row_max_mean 1549.5787 (1544.5882) nleep/row_max_std 41.0529 (54.1782) nleep/row_min_mean 1512.7024 (1504.3316) lr 1.8443e-03 eta 0:20:06
epoch [11/50] batch [40/181] time 0.143 (0.158) data 0.000 (0.008) loss 1.0386 (1.1457) teacher_loss 0.2301 (0.3271) loss_zs_kd 0.0130 (0.0137) loss_oracle 0.4477 (0.4617) kd_loss 0.5782 (0.5809) acc 90.6250 (88.0469) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5672) gate/usage_min 0.2159 (0.2159) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0227 (0.0151) teacher/usage_max 0.9647 (0.9700) teacher/usage_min 0.0064 (0.0046) teacher/usage_std 0.4466 (0.4503) nleep/row_max_mean 1536.9966 (1544.2191) nleep/row_max_std 49.5050 (53.4754) nleep/row_min_mean 1504.5356 (1504.1668) lr 1.8443e-03 eta 0:18:57
epoch [11/50] batch [60/181] time 0.167 (0.157) data 0.000 (0.005) loss 1.4058 (1.1720) teacher_loss 0.4982 (0.3412) loss_zs_kd 0.0200 (0.0148) loss_oracle 0.5435 (0.4668) kd_loss 0.6259 (0.5899) acc 84.3750 (87.5521) gate/entropy 0.9837 (0.9840) gate/usage_max 0.5675 (0.5673) gate/usage_min 0.2158 (0.2158) gate/usage_std 0.1656 (0.1655) teacher/entropy 0.0489 (0.0146) teacher/usage_max 0.8879 (0.9609) teacher/usage_min 0.0179 (0.0068) teacher/usage_std 0.3934 (0.4440) nleep/row_max_mean 1536.0642 (1544.8416) nleep/row_max_std 51.7142 (52.1089) nleep/row_min_mean 1493.8157 (1504.7935) lr 1.8443e-03 eta 0:18:45
epoch [11/50] batch [80/181] time 0.140 (0.156) data 0.000 (0.004) loss 1.1795 (1.1546) teacher_loss 0.3647 (0.3282) loss_zs_kd 0.0094 (0.0160) loss_oracle 0.4309 (0.4577) kd_loss 0.5946 (0.5896) acc 90.6250 (88.3203) gate/entropy 0.9835 (0.9838) gate/usage_max 0.5678 (0.5674) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1658 (0.1655) teacher/entropy 0.0018 (0.0156) teacher/usage_max 0.9685 (0.9601) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.4493 (0.4434) nleep/row_max_mean 1529.4451 (1544.8312) nleep/row_max_std 52.3859 (51.6386) nleep/row_min_mean 1488.4453 (1504.7013) lr 1.8443e-03 eta 0:18:35
epoch [11/50] batch [100/181] time 0.155 (0.155) data 0.000 (0.003) loss 1.0462 (1.1440) teacher_loss 0.2105 (0.3218) loss_zs_kd 0.0053 (0.0160) loss_oracle 0.4677 (0.4540) kd_loss 0.5993 (0.5872) acc 93.7500 (88.5000) gate/entropy 0.9831 (0.9837) gate/usage_max 0.5682 (0.5676) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1661 (0.1656) teacher/entropy 0.0194 (0.0153) teacher/usage_max 0.9448 (0.9626) teacher/usage_min 0.0004 (0.0068) teacher/usage_std 0.4330 (0.4452) nleep/row_max_mean 1548.5281 (1544.0470) nleep/row_max_std 42.8777 (51.6565) nleep/row_min_mean 1511.8831 (1503.9888) lr 1.8443e-03 eta 0:18:28
epoch [11/50] batch [120/181] time 0.151 (0.154) data 0.000 (0.003) loss 1.2079 (1.1393) teacher_loss 0.3613 (0.3169) loss_zs_kd 0.0255 (0.0156) loss_oracle 0.4769 (0.4570) kd_loss 0.5954 (0.5862) acc 93.7500 (88.6979) gate/entropy 0.9830 (0.9836) gate/usage_max 0.5683 (0.5677) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1661 (0.1657) teacher/entropy 0.0000 (0.0153) teacher/usage_max 0.9688 (0.9635) teacher/usage_min 0.0000 (0.0067) teacher/usage_std 0.4495 (0.4458) nleep/row_max_mean 1539.8728 (1543.6642) nleep/row_max_std 50.1420 (50.9575) nleep/row_min_mean 1494.5840 (1503.3829) lr 1.8443e-03 eta 0:18:17
epoch [11/50] batch [140/181] time 0.126 (0.153) data 0.000 (0.002) loss 1.2054 (1.1433) teacher_loss 0.3789 (0.3184) loss_zs_kd 0.0119 (0.0156) loss_oracle 0.4468 (0.4564) kd_loss 0.5972 (0.5889) acc 87.5000 (88.6384) gate/entropy 0.9825 (0.9835) gate/usage_max 0.5689 (0.5678) gate/usage_min 0.2152 (0.2157) gate/usage_std 0.1665 (0.1658) teacher/entropy 0.0191 (0.0150) teacher/usage_max 0.9463 (0.9608) teacher/usage_min 0.0001 (0.0079) teacher/usage_std 0.4340 (0.4439) nleep/row_max_mean 1557.7925 (1543.1315) nleep/row_max_std 41.3036 (50.4040) nleep/row_min_mean 1517.4342 (1503.0424) lr 1.8443e-03 eta 0:18:04
epoch [11/50] batch [160/181] time 0.098 (0.149) data 0.000 (0.002) loss 0.9942 (1.1446) teacher_loss 0.1876 (0.3203) loss_zs_kd 0.0101 (0.0154) loss_oracle 0.4750 (0.4568) kd_loss 0.5641 (0.5882) acc 93.7500 (88.5547) gate/entropy 0.9826 (0.9834) gate/usage_max 0.5687 (0.5679) gate/usage_min 0.2153 (0.2156) gate/usage_std 0.1665 (0.1659) teacher/entropy 0.0002 (0.0150) teacher/usage_max 1.0000 (0.9613) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.4714 (0.4443) nleep/row_max_mean 1543.5186 (1542.6261) nleep/row_max_std 44.9119 (50.2619) nleep/row_min_mean 1502.4785 (1502.4207) lr 1.8443e-03 eta 0:17:36
epoch [11/50] batch [180/181] time 0.073 (0.144) data 0.000 (0.002) loss 1.1636 (1.1473) teacher_loss 0.3595 (0.3244) loss_zs_kd 0.0179 (0.0156) loss_oracle 0.3954 (0.4548) kd_loss 0.5975 (0.5878) acc 87.5000 (88.4028) gate/entropy 0.9824 (0.9833) gate/usage_max 0.5690 (0.5680) gate/usage_min 0.2152 (0.2156) gate/usage_std 0.1666 (0.1659) teacher/entropy 0.0265 (0.0147) teacher/usage_max 0.9381 (0.9618) teacher/usage_min 0.0076 (0.0071) teacher/usage_std 0.4281 (0.4446) nleep/row_max_mean 1527.5996 (1542.2573) nleep/row_max_std 52.4553 (50.5474) nleep/row_min_mean 1490.7417 (1501.7608) lr 1.8443e-03 eta 0:16:56
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,400
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [12/50] batch [20/181] time 0.081 (0.131) data 0.000 (0.017) loss 1.1431 (1.1557) teacher_loss 0.3063 (0.3474) loss_zs_kd 0.0243 (0.0172) loss_oracle 0.4563 (0.4255) kd_loss 0.5965 (0.5869) acc 84.3750 (85.6250) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0639 (0.0164) teacher/usage_max 0.9007 (0.9593) teacher/usage_min 0.0367 (0.0088) teacher/usage_std 0.4014 (0.4428) nleep/row_max_mean 1528.9761 (1539.7288) nleep/row_max_std 53.7274 (53.5157) nleep/row_min_mean 1493.6873 (1497.3466) lr 1.8090e-03 eta 0:15:20
epoch [12/50] batch [40/181] time 0.130 (0.117) data 0.000 (0.008) loss 1.3489 (1.1315) teacher_loss 0.5378 (0.3226) loss_zs_kd 0.0148 (0.0186) loss_oracle 0.4228 (0.4299) kd_loss 0.5923 (0.5846) acc 81.2500 (88.0469) gate/entropy 0.9819 (0.9822) gate/usage_max 0.5695 (0.5691) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1670 (0.1667) teacher/entropy 0.0010 (0.0158) teacher/usage_max 0.9689 (0.9622) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.4496 (0.4449) nleep/row_max_mean 1561.1501 (1538.1673) nleep/row_max_std 47.8041 (53.7100) nleep/row_min_mean 1512.4153 (1495.7923) lr 1.8090e-03 eta 0:13:42
epoch [12/50] batch [60/181] time 0.176 (0.118) data 0.001 (0.006) loss 1.0963 (1.1300) teacher_loss 0.3058 (0.3222) loss_zs_kd 0.0148 (0.0171) loss_oracle 0.4106 (0.4281) kd_loss 0.5778 (0.5852) acc 90.6250 (88.2292) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5695 (0.5692) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0156 (0.0148) teacher/usage_max 0.9688 (0.9625) teacher/usage_min 0.0062 (0.0076) teacher/usage_std 0.4494 (0.4451) nleep/row_max_mean 1534.9646 (1537.7923) nleep/row_max_std 61.7012 (54.6439) nleep/row_min_mean 1494.8472 (1495.2425) lr 1.8090e-03 eta 0:13:45
epoch [12/50] batch [80/181] time 0.195 (0.119) data 0.000 (0.004) loss 1.0673 (1.1326) teacher_loss 0.2083 (0.3219) loss_zs_kd 0.0321 (0.0182) loss_oracle 0.4812 (0.4307) kd_loss 0.6023 (0.5863) acc 90.6250 (88.2812) gate/entropy 0.9816 (0.9821) gate/usage_max 0.5698 (0.5693) gate/usage_min 0.2149 (0.2151) gate/usage_std 0.1672 (0.1668) teacher/entropy 0.0209 (0.0157) teacher/usage_max 0.9375 (0.9603) teacher/usage_min 0.0192 (0.0071) teacher/usage_std 0.4273 (0.4436) nleep/row_max_mean 1545.7925 (1537.7874) nleep/row_max_std 55.9418 (54.9669) nleep/row_min_mean 1505.2166 (1495.3741) lr 1.8090e-03 eta 0:13:50
epoch [12/50] batch [100/181] time 0.089 (0.118) data 0.000 (0.004) loss 1.0685 (1.1326) teacher_loss 0.1999 (0.3196) loss_zs_kd 0.0173 (0.0196) loss_oracle 0.4942 (0.4292) kd_loss 0.6128 (0.5887) acc 93.7500 (88.2188) gate/entropy 0.9818 (0.9820) gate/usage_max 0.5696 (0.5694) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1671 (0.1669) teacher/entropy 0.0203 (0.0160) teacher/usage_max 0.9279 (0.9574) teacher/usage_min 0.0001 (0.0074) teacher/usage_std 0.4214 (0.4416) nleep/row_max_mean 1540.5657 (1538.1302) nleep/row_max_std 65.0322 (54.8857) nleep/row_min_mean 1492.4023 (1495.8221) lr 1.8090e-03 eta 0:13:40
epoch [12/50] batch [120/181] time 0.157 (0.123) data 0.000 (0.003) loss 1.2540 (1.1375) teacher_loss 0.3723 (0.3233) loss_zs_kd 0.0155 (0.0198) loss_oracle 0.5020 (0.4288) kd_loss 0.6230 (0.5900) acc 81.2500 (88.2812) gate/entropy 0.9815 (0.9819) gate/usage_max 0.5699 (0.5694) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1673 (0.1670) teacher/entropy 0.0002 (0.0171) teacher/usage_max 0.9375 (0.9548) teacher/usage_min 0.0000 (0.0077) teacher/usage_std 0.4280 (0.4398) nleep/row_max_mean 1538.5420 (1539.0044) nleep/row_max_std 59.1765 (54.6667) nleep/row_min_mean 1494.8414 (1496.5098) lr 1.8090e-03 eta 0:14:13
epoch [12/50] batch [140/181] time 0.160 (0.127) data 0.000 (0.003) loss 1.0799 (1.1417) teacher_loss 0.3161 (0.3264) loss_zs_kd 0.0209 (0.0202) loss_oracle 0.3841 (0.4294) kd_loss 0.5613 (0.5905) acc 84.3750 (87.9911) gate/entropy 0.9813 (0.9818) gate/usage_max 0.5701 (0.5695) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1674 (0.1670) teacher/entropy 0.0008 (0.0172) teacher/usage_max 0.9999 (0.9541) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.4713 (0.4393) nleep/row_max_mean 1556.1001 (1539.7113) nleep/row_max_std 47.1509 (54.5361) nleep/row_min_mean 1508.6423 (1496.9017) lr 1.8090e-03 eta 0:14:39
epoch [12/50] batch [160/181] time 0.159 (0.130) data 0.000 (0.002) loss 1.2089 (1.1363) teacher_loss 0.4447 (0.3220) loss_zs_kd 0.0186 (0.0198) loss_oracle 0.4181 (0.4297) kd_loss 0.5459 (0.5895) acc 81.2500 (88.0469) gate/entropy 0.9814 (0.9818) gate/usage_max 0.5700 (0.5696) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1673 (0.1670) teacher/entropy 0.0249 (0.0176) teacher/usage_max 0.9911 (0.9546) teacher/usage_min 0.0002 (0.0072) teacher/usage_std 0.4651 (0.4396) nleep/row_max_mean 1541.6013 (1540.5740) nleep/row_max_std 60.4841 (54.4534) nleep/row_min_mean 1495.5261 (1497.5073) lr 1.8090e-03 eta 0:14:58
epoch [12/50] batch [180/181] time 0.118 (0.131) data 0.000 (0.002) loss 1.1424 (1.1360) teacher_loss 0.3424 (0.3214) loss_zs_kd 0.0171 (0.0195) loss_oracle 0.3772 (0.4287) kd_loss 0.6029 (0.5905) acc 84.3750 (88.0208) gate/entropy 0.9810 (0.9817) gate/usage_max 0.5703 (0.5696) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1676 (0.1671) teacher/entropy 0.0305 (0.0171) teacher/usage_max 0.9265 (0.9539) teacher/usage_min 0.0134 (0.0071) teacher/usage_std 0.4199 (0.4392) nleep/row_max_mean 1558.3259 (1541.5525) nleep/row_max_std 51.7823 (54.1623) nleep/row_min_mean 1513.7584 (1498.2887) lr 1.8090e-03 eta 0:15:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,401
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [13/50] batch [20/181] time 0.116 (0.157) data 0.000 (0.015) loss 1.1015 (1.1589) teacher_loss 0.1932 (0.3202) loss_zs_kd 0.0220 (0.0226) loss_oracle 0.5098 (0.4383) kd_loss 0.6423 (0.6082) acc 93.7500 (89.2188) gate/entropy 0.9811 (0.9811) gate/usage_max 0.5703 (0.5703) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1676 (0.1675) teacher/entropy 0.0294 (0.0229) teacher/usage_max 0.8873 (0.9288) teacher/usage_min 0.0010 (0.0116) teacher/usage_std 0.3943 (0.4219) nleep/row_max_mean 1548.1492 (1545.6064) nleep/row_max_std 58.1344 (52.5613) nleep/row_min_mean 1506.8577 (1503.2991) lr 1.7705e-03 eta 0:17:56
epoch [13/50] batch [40/181] time 0.142 (0.143) data 0.000 (0.008) loss 1.0430 (1.1408) teacher_loss 0.1963 (0.3035) loss_zs_kd 0.0150 (0.0200) loss_oracle 0.4611 (0.4451) kd_loss 0.6086 (0.6047) acc 93.7500 (89.4531) gate/entropy 0.9810 (0.9810) gate/usage_max 0.5703 (0.5703) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1676 (0.1676) teacher/entropy 0.0134 (0.0181) teacher/usage_max 0.9380 (0.9372) teacher/usage_min 0.0293 (0.0098) teacher/usage_std 0.4276 (0.4277) nleep/row_max_mean 1533.2310 (1545.8071) nleep/row_max_std 56.9009 (52.1045) nleep/row_min_mean 1495.3337 (1503.7307) lr 1.7705e-03 eta 0:16:18
epoch [13/50] batch [60/181] time 0.090 (0.135) data 0.000 (0.005) loss 1.2974 (1.1438) teacher_loss 0.4475 (0.3074) loss_zs_kd 0.0160 (0.0197) loss_oracle 0.4576 (0.4481) kd_loss 0.6131 (0.6025) acc 84.3750 (88.9062) gate/entropy 0.9808 (0.9810) gate/usage_max 0.5706 (0.5704) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1677 (0.1676) teacher/entropy 0.0132 (0.0201) teacher/usage_max 0.9333 (0.9374) teacher/usage_min 0.0314 (0.0120) teacher/usage_std 0.4243 (0.4276) nleep/row_max_mean 1544.4995 (1543.6586) nleep/row_max_std 51.5693 (51.9583) nleep/row_min_mean 1501.5015 (1502.7445) lr 1.7705e-03 eta 0:15:23
epoch [13/50] batch [80/181] time 0.122 (0.129) data 0.000 (0.004) loss 1.2316 (1.1423) teacher_loss 0.3454 (0.3074) loss_zs_kd 0.0327 (0.0194) loss_oracle 0.4446 (0.4451) kd_loss 0.6476 (0.6026) acc 93.7500 (89.0234) gate/entropy 0.9806 (0.9809) gate/usage_max 0.5707 (0.5704) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1679 (0.1677) teacher/entropy 0.0064 (0.0197) teacher/usage_max 0.9047 (0.9376) teacher/usage_min 0.0313 (0.0118) teacher/usage_std 0.4042 (0.4278) nleep/row_max_mean 1551.8745 (1543.2894) nleep/row_max_std 44.1296 (51.8153) nleep/row_min_mean 1508.1138 (1502.9115) lr 1.7705e-03 eta 0:14:36
epoch [13/50] batch [100/181] time 0.151 (0.127) data 0.000 (0.003) loss 1.1851 (1.1454) teacher_loss 0.3856 (0.3132) loss_zs_kd 0.0252 (0.0198) loss_oracle 0.4214 (0.4435) kd_loss 0.5762 (0.6005) acc 90.6250 (88.5625) gate/entropy 0.9807 (0.9809) gate/usage_max 0.5707 (0.5705) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1678 (0.1677) teacher/entropy 0.0430 (0.0195) teacher/usage_max 0.9401 (0.9398) teacher/usage_min 0.0088 (0.0124) teacher/usage_std 0.4294 (0.4293) nleep/row_max_mean 1532.1250 (1543.6029) nleep/row_max_std 62.5330 (52.0789) nleep/row_min_mean 1495.2128 (1503.2924) lr 1.7705e-03 eta 0:14:17
epoch [13/50] batch [120/181] time 0.095 (0.125) data 0.000 (0.003) loss 1.0479 (1.1456) teacher_loss 0.1671 (0.3135) loss_zs_kd 0.0113 (0.0198) loss_oracle 0.4873 (0.4468) kd_loss 0.6315 (0.5988) acc 93.7500 (88.4896) gate/entropy 0.9806 (0.9808) gate/usage_max 0.5707 (0.5706) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1679 (0.1677) teacher/entropy 0.0203 (0.0189) teacher/usage_max 0.9069 (0.9421) teacher/usage_min 0.0381 (0.0124) teacher/usage_std 0.4056 (0.4309) nleep/row_max_mean 1536.0427 (1542.6066) nleep/row_max_std 67.1469 (52.4545) nleep/row_min_mean 1494.1584 (1502.4696) lr 1.7705e-03 eta 0:14:05
epoch [13/50] batch [140/181] time 0.101 (0.126) data 0.000 (0.002) loss 0.9868 (1.1511) teacher_loss 0.1090 (0.3197) loss_zs_kd 0.0290 (0.0200) loss_oracle 0.4366 (0.4472) kd_loss 0.6450 (0.5977) acc 96.8750 (88.3259) gate/entropy 0.9806 (0.9808) gate/usage_max 0.5708 (0.5706) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1679 (0.1678) teacher/entropy 0.0273 (0.0198) teacher/usage_max 0.8860 (0.9422) teacher/usage_min 0.0527 (0.0127) teacher/usage_std 0.3908 (0.4310) nleep/row_max_mean 1519.5326 (1541.8050) nleep/row_max_std 49.9226 (52.6768) nleep/row_min_mean 1487.3967 (1501.9296) lr 1.7705e-03 eta 0:14:05
epoch [13/50] batch [160/181] time 0.132 (0.122) data 0.000 (0.002) loss 1.1437 (1.1415) teacher_loss 0.2723 (0.3131) loss_zs_kd 0.0139 (0.0198) loss_oracle 0.4519 (0.4451) kd_loss 0.6385 (0.5960) acc 90.6250 (88.5547) gate/entropy 0.9803 (0.9807) gate/usage_max 0.5711 (0.5707) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1681 (0.1678) teacher/entropy 0.0280 (0.0197) teacher/usage_max 0.8916 (0.9441) teacher/usage_min 0.0457 (0.0121) teacher/usage_std 0.3948 (0.4322) nleep/row_max_mean 1543.6277 (1541.8560) nleep/row_max_std 50.8868 (52.8161) nleep/row_min_mean 1508.9264 (1502.3078) lr 1.7705e-03 eta 0:13:41
epoch [13/50] batch [180/181] time 0.075 (0.120) data 0.000 (0.002) loss 1.0634 (1.1387) teacher_loss 0.3313 (0.3104) loss_zs_kd 0.0334 (0.0195) loss_oracle 0.3851 (0.4443) kd_loss 0.5228 (0.5964) acc 93.7500 (88.6458) gate/entropy 0.9801 (0.9807) gate/usage_max 0.5713 (0.5707) gate/usage_min 0.2143 (0.2145) gate/usage_std 0.1683 (0.1679) teacher/entropy 0.0785 (0.0208) teacher/usage_max 0.9577 (0.9424) teacher/usage_min 0.0117 (0.0130) teacher/usage_std 0.4416 (0.4311) nleep/row_max_mean 1531.6642 (1541.4194) nleep/row_max_std 51.0460 (53.1185) nleep/row_min_mean 1501.7710 (1502.4382) lr 1.7705e-03 eta 0:13:23
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,410
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.5%, epoch: 13 *******
******* Domain p best val test acc: 99.8%, epoch: 13 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [14/50] batch [20/181] time 0.162 (0.162) data 0.000 (0.012) loss 1.0146 (1.1323) teacher_loss 0.1982 (0.3179) loss_zs_kd 0.0098 (0.0224) loss_oracle 0.3622 (0.4044) kd_loss 0.6304 (0.6010) acc 90.6250 (87.9688) gate/entropy 0.9803 (0.9802) gate/usage_max 0.5711 (0.5712) gate/usage_min 0.2144 (0.2143) gate/usage_std 0.1681 (0.1682) teacher/entropy 0.0533 (0.0281) teacher/usage_max 0.8739 (0.9296) teacher/usage_min 0.0383 (0.0163) teacher/usage_std 0.3828 (0.4220) nleep/row_max_mean 1526.9974 (1534.4119) nleep/row_max_std 58.7779 (58.4117) nleep/row_min_mean 1499.1058 (1501.3326) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [40/181] time 0.150 (0.157) data 0.000 (0.006) loss 0.9181 (1.1499) teacher_loss 0.0897 (0.3078) loss_zs_kd 0.0139 (0.0235) loss_oracle 0.4159 (0.4165) kd_loss 0.6135 (0.6221) acc 96.8750 (88.2812) gate/entropy 0.9799 (0.9801) gate/usage_max 0.5715 (0.5712) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1684 (0.1682) teacher/entropy 0.0664 (0.0369) teacher/usage_max 0.8774 (0.8990) teacher/usage_min 0.0000 (0.0193) teacher/usage_std 0.3880 (0.4014) nleep/row_max_mean 1545.3707 (1534.1138) nleep/row_max_std 59.2376 (56.1720) nleep/row_min_mean 1511.9026 (1502.1060) lr 1.7290e-03 eta 0:17:22
epoch [14/50] batch [60/181] time 0.080 (0.152) data 0.000 (0.004) loss 1.0536 (1.1598) teacher_loss 0.1081 (0.3068) loss_zs_kd 0.0207 (0.0261) loss_oracle 0.4281 (0.4238) kd_loss 0.7211 (0.6281) acc 96.8750 (88.2812) gate/entropy 0.9800 (0.9801) gate/usage_max 0.5714 (0.5713) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0231 (0.0407) teacher/usage_max 0.8121 (0.8890) teacher/usage_min 0.0015 (0.0182) teacher/usage_std 0.3469 (0.3948) nleep/row_max_mean 1543.7742 (1534.5943) nleep/row_max_std 55.4957 (56.3426) nleep/row_min_mean 1510.8997 (1503.2472) lr 1.7290e-03 eta 0:16:49
epoch [14/50] batch [80/181] time 0.140 (0.150) data 0.000 (0.003) loss 1.3193 (1.1736) teacher_loss 0.3148 (0.3046) loss_zs_kd 0.0284 (0.0264) loss_oracle 0.4930 (0.4373) kd_loss 0.7438 (0.6371) acc 90.6250 (88.1641) gate/entropy 0.9801 (0.9801) gate/usage_max 0.5713 (0.5713) gate/usage_min 0.2143 (0.2143) gate/usage_std 0.1683 (0.1683) teacher/entropy 0.0876 (0.0408) teacher/usage_max 0.7230 (0.8796) teacher/usage_min 0.0178 (0.0159) teacher/usage_std 0.2926 (0.3891) nleep/row_max_mean 1517.1355 (1534.2241) nleep/row_max_std 60.5064 (56.8824) nleep/row_min_mean 1489.2043 (1503.2104) lr 1.7290e-03 eta 0:16:33
epoch [14/50] batch [100/181] time 0.143 (0.150) data 0.000 (0.002) loss 1.2533 (1.1769) teacher_loss 0.4064 (0.2969) loss_zs_kd 0.0269 (0.0262) loss_oracle 0.4097 (0.4412) kd_loss 0.6287 (0.6462) acc 81.2500 (88.5000) gate/entropy 0.9799 (0.9801) gate/usage_max 0.5715 (0.5713) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0400 (0.0434) teacher/usage_max 0.8888 (0.8676) teacher/usage_min 0.0001 (0.0146) teacher/usage_std 0.3954 (0.3817) nleep/row_max_mean 1535.6318 (1533.4911) nleep/row_max_std 43.8638 (56.9080) nleep/row_min_mean 1504.5037 (1502.7896) lr 1.7290e-03 eta 0:16:31
epoch [14/50] batch [120/181] time 0.176 (0.153) data 0.000 (0.002) loss 1.4289 (1.1853) teacher_loss 0.3524 (0.2927) loss_zs_kd 0.0105 (0.0263) loss_oracle 0.4488 (0.4478) kd_loss 0.8468 (0.6555) acc 90.6250 (88.9062) gate/entropy 0.9799 (0.9800) gate/usage_max 0.5715 (0.5714) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0544 (0.0453) teacher/usage_max 0.6518 (0.8562) teacher/usage_min 0.0000 (0.0137) teacher/usage_std 0.2663 (0.3747) nleep/row_max_mean 1526.4158 (1533.7304) nleep/row_max_std 57.5388 (56.6830) nleep/row_min_mean 1498.3557 (1502.8679) lr 1.7290e-03 eta 0:16:43
epoch [14/50] batch [140/181] time 0.162 (0.153) data 0.000 (0.002) loss 1.4995 (1.2012) teacher_loss 0.3615 (0.2907) loss_zs_kd 0.0446 (0.0273) loss_oracle 0.4314 (0.4510) kd_loss 0.9000 (0.6714) acc 90.6250 (89.0848) gate/entropy 0.9797 (0.9800) gate/usage_max 0.5717 (0.5714) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1685 (0.1683) teacher/entropy 0.0677 (0.0489) teacher/usage_max 0.5842 (0.8363) teacher/usage_min 0.0000 (0.0122) teacher/usage_std 0.2455 (0.3635) nleep/row_max_mean 1536.7639 (1533.6008) nleep/row_max_std 55.2516 (56.5873) nleep/row_min_mean 1507.3101 (1502.7654) lr 1.7290e-03 eta 0:16:44
epoch [14/50] batch [160/181] time 0.097 (0.150) data 0.000 (0.002) loss 1.4402 (1.2263) teacher_loss 0.2991 (0.2910) loss_zs_kd 0.0175 (0.0269) loss_oracle 0.4633 (0.4522) kd_loss 0.9007 (0.6957) acc 90.6250 (89.0430) gate/entropy 0.9798 (0.9800) gate/usage_max 0.5716 (0.5714) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0742 (0.0512) teacher/usage_max 0.5764 (0.8091) teacher/usage_min 0.0000 (0.0108) teacher/usage_std 0.2438 (0.3508) nleep/row_max_mean 1534.8541 (1533.7860) nleep/row_max_std 57.0380 (56.1383) nleep/row_min_mean 1501.4130 (1502.6521) lr 1.7290e-03 eta 0:16:19
epoch [14/50] batch [180/181] time 0.067 (0.144) data 0.000 (0.001) loss 1.5319 (1.2563) teacher_loss 0.2562 (0.2878) loss_zs_kd 0.0121 (0.0262) loss_oracle 0.4732 (0.4565) kd_loss 1.0331 (0.7271) acc 93.7500 (89.2535) gate/entropy 0.9798 (0.9799) gate/usage_max 0.5716 (0.5715) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.1049 (0.0532) teacher/usage_max 0.5900 (0.7831) teacher/usage_min 0.0000 (0.0096) teacher/usage_std 0.2469 (0.3391) nleep/row_max_mean 1537.4585 (1534.5941) nleep/row_max_std 51.3474 (55.6913) nleep/row_min_mean 1504.0702 (1503.0980) lr 1.7290e-03 eta 0:15:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,384
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.5%, epoch: 13 *******
******* Domain p best val test acc: 99.8%, epoch: 13 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [15/50] batch [20/181] time 0.099 (0.118) data 0.000 (0.013) loss 1.6437 (1.5499) teacher_loss 0.3704 (0.2914) loss_zs_kd 0.0317 (0.0233) loss_oracle 0.4588 (0.4846) kd_loss 1.0280 (1.0046) acc 81.2500 (89.0625) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.1447 (0.0756) teacher/usage_max 0.6253 (0.5626) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2570 (0.2444) nleep/row_max_mean 1544.7690 (1542.3953) nleep/row_max_std 52.3540 (53.5350) nleep/row_min_mean 1509.1211 (1505.5316) lr 1.6845e-03 eta 0:12:48
epoch [15/50] batch [40/181] time 0.096 (0.112) data 0.000 (0.007) loss 1.3176 (1.5759) teacher_loss 0.2463 (0.3050) loss_zs_kd 0.0259 (0.0231) loss_oracle 0.5125 (0.4951) kd_loss 0.8022 (1.0118) acc 90.6250 (88.5156) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0987 (0.0703) teacher/usage_max 0.6518 (0.5886) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2663 (0.2510) nleep/row_max_mean 1548.7275 (1544.1686) nleep/row_max_std 56.7341 (51.9876) nleep/row_min_mean 1509.9158 (1507.2269) lr 1.6845e-03 eta 0:12:05
epoch [15/50] batch [60/181] time 0.121 (0.121) data 0.000 (0.005) loss 1.5427 (1.5568) teacher_loss 0.3125 (0.2898) loss_zs_kd 0.0121 (0.0216) loss_oracle 0.5438 (0.5072) kd_loss 0.9523 (1.0027) acc 87.5000 (89.0625) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0892 (0.0666) teacher/usage_max 0.5082 (0.5752) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2358 (0.2473) nleep/row_max_mean 1543.6296 (1543.1992) nleep/row_max_std 54.5897 (52.1684) nleep/row_min_mean 1510.0142 (1507.0411) lr 1.6845e-03 eta 0:13:01
epoch [15/50] batch [80/181] time 0.067 (0.120) data 0.000 (0.004) loss 1.3874 (1.5361) teacher_loss 0.2695 (0.2864) loss_zs_kd 0.0289 (0.0222) loss_oracle 0.4495 (0.4978) kd_loss 0.8786 (0.9897) acc 90.6250 (89.4531) gate/entropy 0.9799 (0.9798) gate/usage_max 0.5715 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1684 (0.1685) teacher/entropy 0.1299 (0.0660) teacher/usage_max 0.5420 (0.5777) teacher/usage_min 0.0175 (0.0015) teacher/usage_std 0.2271 (0.2473) nleep/row_max_mean 1531.5481 (1543.1537) nleep/row_max_std 44.1443 (50.8490) nleep/row_min_mean 1501.1846 (1507.9234) lr 1.6845e-03 eta 0:12:52
epoch [15/50] batch [100/181] time 0.117 (0.119) data 0.000 (0.003) loss 1.3381 (1.5260) teacher_loss 0.1757 (0.2795) loss_zs_kd 0.0118 (0.0221) loss_oracle 0.4644 (0.4905) kd_loss 0.9243 (0.9901) acc 96.8750 (89.8438) gate/entropy 0.9800 (0.9798) gate/usage_max 0.5714 (0.5716) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1683 (0.1685) teacher/entropy 0.0953 (0.0638) teacher/usage_max 0.5304 (0.5726) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2370 (0.2455) nleep/row_max_mean 1531.8164 (1543.6141) nleep/row_max_std 53.1436 (50.0604) nleep/row_min_mean 1501.7841 (1508.9983) lr 1.6845e-03 eta 0:12:40
epoch [15/50] batch [120/181] time 0.166 (0.125) data 0.000 (0.002) loss 1.5742 (1.5039) teacher_loss 0.3555 (0.2712) loss_zs_kd 0.0283 (0.0213) loss_oracle 0.5268 (0.4928) kd_loss 0.9412 (0.9757) acc 84.3750 (90.2083) gate/entropy 0.9799 (0.9798) gate/usage_max 0.5715 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1684 (0.1685) teacher/entropy 0.1188 (0.0650) teacher/usage_max 0.4894 (0.5745) teacher/usage_min 0.0615 (0.0027) teacher/usage_std 0.1929 (0.2461) nleep/row_max_mean 1523.7395 (1543.3342) nleep/row_max_std 54.7828 (50.0834) nleep/row_min_mean 1495.3162 (1509.2380) lr 1.6845e-03 eta 0:13:18
epoch [15/50] batch [140/181] time 0.152 (0.130) data 0.000 (0.002) loss 1.3841 (1.4917) teacher_loss 0.2488 (0.2726) loss_zs_kd 0.0339 (0.0213) loss_oracle 0.5014 (0.4921) kd_loss 0.8676 (0.9624) acc 87.5000 (90.0893) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0280 (0.0650) teacher/usage_max 0.6568 (0.5791) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2682 (0.2468) nleep/row_max_mean 1552.9941 (1543.4641) nleep/row_max_std 43.7947 (49.8853) nleep/row_min_mean 1517.1770 (1509.9560) lr 1.6845e-03 eta 0:13:49
epoch [15/50] batch [160/181] time 0.165 (0.132) data 0.000 (0.002) loss 1.4002 (1.4817) teacher_loss 0.2850 (0.2726) loss_zs_kd 0.0277 (0.0217) loss_oracle 0.5045 (0.4914) kd_loss 0.8491 (0.9526) acc 90.6250 (89.9805) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0187 (0.0650) teacher/usage_max 0.6849 (0.5832) teacher/usage_min 0.0000 (0.0050) teacher/usage_std 0.2799 (0.2470) nleep/row_max_mean 1554.4600 (1543.5943) nleep/row_max_std 45.5414 (49.7365) nleep/row_min_mean 1520.5637 (1510.4456) lr 1.6845e-03 eta 0:14:00
epoch [15/50] batch [180/181] time 0.121 (0.134) data 0.000 (0.002) loss 1.6220 (1.4745) teacher_loss 0.4524 (0.2728) loss_zs_kd 0.0649 (0.0228) loss_oracle 0.4906 (0.4912) kd_loss 0.8918 (0.9447) acc 84.3750 (90.0868) gate/entropy 0.9796 (0.9798) gate/usage_max 0.5718 (0.5716) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0497 (0.0651) teacher/usage_max 0.6102 (0.5855) teacher/usage_min 0.0624 (0.0063) teacher/usage_std 0.2237 (0.2471) nleep/row_max_mean 1534.8545 (1543.1738) nleep/row_max_std 41.7066 (49.8442) nleep/row_min_mean 1505.8374 (1510.4993) lr 1.6845e-03 eta 0:14:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [16/50] batch [20/181] time 0.123 (0.160) data 0.000 (0.014) loss 1.4374 (1.4182) teacher_loss 0.2580 (0.2783) loss_zs_kd 0.0373 (0.0368) loss_oracle 0.5349 (0.4989) kd_loss 0.8933 (0.8720) acc 87.5000 (89.5312) gate/entropy 0.9797 (0.9797) gate/usage_max 0.5717 (0.5717) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1686 (0.1686) teacher/entropy 0.0737 (0.0598) teacher/usage_max 0.5840 (0.6225) teacher/usage_min 0.0001 (0.0100) teacher/usage_std 0.2454 (0.2584) nleep/row_max_mean 1542.9290 (1544.5067) nleep/row_max_std 65.3484 (51.6106) nleep/row_min_mean 1512.1547 (1513.5914) lr 1.6374e-03 eta 0:16:53
epoch [16/50] batch [40/181] time 0.099 (0.140) data 0.000 (0.007) loss 1.5084 (1.4271) teacher_loss 0.3873 (0.2812) loss_zs_kd 0.0345 (0.0313) loss_oracle 0.4453 (0.5118) kd_loss 0.8812 (0.8744) acc 84.3750 (89.2969) gate/entropy 0.9796 (0.9797) gate/usage_max 0.5718 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.1082 (0.0601) teacher/usage_max 0.5610 (0.6185) teacher/usage_min 0.0182 (0.0162) teacher/usage_std 0.2301 (0.2541) nleep/row_max_mean 1543.6796 (1541.8323) nleep/row_max_std 48.5675 (53.7538) nleep/row_min_mean 1515.5791 (1510.9723) lr 1.6374e-03 eta 0:14:42
epoch [16/50] batch [60/181] time 0.130 (0.131) data 0.000 (0.005) loss 1.3299 (1.4253) teacher_loss 0.2656 (0.2725) loss_zs_kd 0.0221 (0.0309) loss_oracle 0.4783 (0.5164) kd_loss 0.8141 (0.8792) acc 93.7500 (89.8438) gate/entropy 0.9798 (0.9797) gate/usage_max 0.5716 (0.5717) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0606 (0.0593) teacher/usage_max 0.6783 (0.6141) teacher/usage_min 0.0318 (0.0151) teacher/usage_std 0.2657 (0.2529) nleep/row_max_mean 1540.8232 (1542.3805) nleep/row_max_std 65.1300 (54.6283) nleep/row_min_mean 1508.0492 (1511.4470) lr 1.6374e-03 eta 0:13:40
epoch [16/50] batch [80/181] time 0.072 (0.126) data 0.000 (0.004) loss 1.5536 (1.4437) teacher_loss 0.2674 (0.2702) loss_zs_kd 0.0253 (0.0305) loss_oracle 0.6578 (0.5285) kd_loss 0.9447 (0.8940) acc 84.3750 (90.0391) gate/entropy 0.9798 (0.9797) gate/usage_max 0.5716 (0.5717) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0123 (0.0594) teacher/usage_max 0.5940 (0.6054) teacher/usage_min 0.0000 (0.0131) teacher/usage_std 0.2479 (0.2514) nleep/row_max_mean 1541.3468 (1540.9386) nleep/row_max_std 51.4274 (53.7561) nleep/row_min_mean 1507.5356 (1509.9246) lr 1.6374e-03 eta 0:13:06
epoch [16/50] batch [100/181] time 0.209 (0.125) data 0.000 (0.003) loss 1.2338 (1.4654) teacher_loss 0.2025 (0.2785) loss_zs_kd 0.0226 (0.0305) loss_oracle 0.5102 (0.5350) kd_loss 0.7649 (0.9041) acc 90.6250 (89.6875) gate/entropy 0.9797 (0.9797) gate/usage_max 0.5717 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0818 (0.0583) teacher/usage_max 0.7065 (0.6008) teacher/usage_min 0.0000 (0.0126) teacher/usage_std 0.2898 (0.2498) nleep/row_max_mean 1553.2195 (1541.4465) nleep/row_max_std 44.9269 (52.5911) nleep/row_min_mean 1519.5901 (1510.4494) lr 1.6374e-03 eta 0:12:57
epoch [16/50] batch [120/181] time 0.190 (0.122) data 0.000 (0.002) loss 1.7721 (1.4775) teacher_loss 0.4064 (0.2769) loss_zs_kd 0.0291 (0.0304) loss_oracle 0.6422 (0.5392) kd_loss 1.0300 (0.9158) acc 81.2500 (90.0000) gate/entropy 0.9798 (0.9797) gate/usage_max 0.5716 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0819 (0.0595) teacher/usage_max 0.5648 (0.5952) teacher/usage_min 0.0000 (0.0113) teacher/usage_std 0.2416 (0.2486) nleep/row_max_mean 1537.6951 (1542.2060) nleep/row_max_std 67.2343 (52.7153) nleep/row_min_mean 1510.6624 (1511.2015) lr 1.6374e-03 eta 0:12:37
epoch [16/50] batch [140/181] time 0.104 (0.118) data 0.000 (0.002) loss 1.8151 (1.5044) teacher_loss 0.2687 (0.2750) loss_zs_kd 0.0300 (0.0295) loss_oracle 0.5850 (0.5529) kd_loss 1.2389 (0.9381) acc 87.5000 (90.1116) gate/entropy 0.9798 (0.9797) gate/usage_max 0.5716 (0.5717) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0411 (0.0606) teacher/usage_max 0.7360 (0.5972) teacher/usage_min 0.0001 (0.0097) teacher/usage_std 0.3044 (0.2499) nleep/row_max_mean 1544.4739 (1542.4189) nleep/row_max_std 53.4069 (52.9663) nleep/row_min_mean 1512.0643 (1511.3015) lr 1.6374e-03 eta 0:12:12
epoch [16/50] batch [160/181] time 0.087 (0.117) data 0.000 (0.002) loss 1.8122 (1.5396) teacher_loss 0.2092 (0.2780) loss_zs_kd 0.0118 (0.0289) loss_oracle 0.7427 (0.5592) kd_loss 1.2257 (0.9676) acc 90.6250 (89.9805) gate/entropy 0.9798 (0.9797) gate/usage_max 0.5716 (0.5717) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0405 (0.0605) teacher/usage_max 0.7223 (0.6081) teacher/usage_min 0.0000 (0.0091) teacher/usage_std 0.2975 (0.2543) nleep/row_max_mean 1549.2114 (1542.8383) nleep/row_max_std 46.7730 (52.7745) nleep/row_min_mean 1512.2585 (1511.5026) lr 1.6374e-03 eta 0:12:02
epoch [16/50] batch [180/181] time 0.112 (0.116) data 0.000 (0.002) loss 1.9457 (1.5875) teacher_loss 0.2084 (0.2797) loss_zs_kd 0.0150 (0.0276) loss_oracle 0.5918 (0.5710) kd_loss 1.4338 (1.0085) acc 90.6250 (90.0000) gate/entropy 0.9800 (0.9798) gate/usage_max 0.5714 (0.5716) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1684 (0.1685) teacher/entropy 0.0190 (0.0582) teacher/usage_max 0.9131 (0.6330) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.4115 (0.2661) nleep/row_max_mean 1541.0107 (1542.7138) nleep/row_max_std 57.3668 (52.6935) nleep/row_min_mean 1508.6102 (1511.0844) lr 1.6374e-03 eta 0:11:52
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,390
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [17/50] batch [20/181] time 0.118 (0.147) data 0.000 (0.011) loss 2.0173 (2.0751) teacher_loss 0.2900 (0.3388) loss_zs_kd 0.0394 (0.0267) loss_oracle 0.7397 (0.6667) kd_loss 1.3378 (1.3896) acc 93.7500 (88.2812) gate/entropy 0.9800 (0.9800) gate/usage_max 0.5714 (0.5714) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1684 (0.1684) teacher/entropy 0.0268 (0.0338) teacher/usage_max 0.8231 (0.8801) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.3537 (0.3907) nleep/row_max_mean 1552.3689 (1545.1845) nleep/row_max_std 59.6949 (55.1352) nleep/row_min_mean 1513.1395 (1508.2081) lr 1.5878e-03 eta 0:14:59
epoch [17/50] batch [40/181] time 0.142 (0.141) data 0.000 (0.006) loss 1.9678 (2.1131) teacher_loss 0.2235 (0.3354) loss_zs_kd 0.0236 (0.0263) loss_oracle 0.8483 (0.7121) kd_loss 1.3084 (1.4085) acc 93.7500 (88.2031) gate/entropy 0.9801 (0.9800) gate/usage_max 0.5713 (0.5714) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1682 (0.1683) teacher/entropy 0.0719 (0.0342) teacher/usage_max 0.8396 (0.9000) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3639 (0.4036) nleep/row_max_mean 1557.9714 (1547.2384) nleep/row_max_std 53.5633 (54.8399) nleep/row_min_mean 1514.8917 (1509.5792) lr 1.5878e-03 eta 0:14:19
epoch [17/50] batch [60/181] time 0.122 (0.138) data 0.000 (0.004) loss 2.1721 (2.1390) teacher_loss 0.1782 (0.3266) loss_zs_kd 0.0140 (0.0276) loss_oracle 0.9844 (0.7431) kd_loss 1.4947 (1.4270) acc 93.7500 (88.4896) gate/entropy 0.9805 (0.9801) gate/usage_max 0.5709 (0.5713) gate/usage_min 0.2138 (0.2137) gate/usage_std 0.1680 (0.1683) teacher/entropy 0.0212 (0.0317) teacher/usage_max 0.9797 (0.9174) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.4571 (0.4151) nleep/row_max_mean 1538.6387 (1549.3454) nleep/row_max_std 66.5214 (55.9477) nleep/row_min_mean 1500.4624 (1510.5821) lr 1.5878e-03 eta 0:14:01
epoch [17/50] batch [80/181] time 0.163 (0.138) data 0.000 (0.003) loss 2.4738 (2.2168) teacher_loss 0.3796 (0.3444) loss_zs_kd 0.0240 (0.0274) loss_oracle 1.1670 (0.8252) kd_loss 1.4987 (1.4461) acc 87.5000 (87.8516) gate/entropy 0.9804 (0.9801) gate/usage_max 0.5710 (0.5712) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1681 (0.1682) teacher/entropy 0.0092 (0.0274) teacher/usage_max 0.9714 (0.9334) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.4514 (0.4260) nleep/row_max_mean 1560.2391 (1550.5631) nleep/row_max_std 67.8560 (57.8038) nleep/row_min_mean 1516.2886 (1510.5406) lr 1.5878e-03 eta 0:13:55
epoch [17/50] batch [100/181] time 0.152 (0.138) data 0.000 (0.002) loss 2.5391 (2.2668) teacher_loss 0.3709 (0.3468) loss_zs_kd 0.0203 (0.0264) loss_oracle 1.2817 (0.8933) kd_loss 1.5172 (1.4602) acc 87.5000 (87.5938) gate/entropy 0.9804 (0.9802) gate/usage_max 0.5710 (0.5712) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1680 (0.1682) teacher/entropy 0.0179 (0.0237) teacher/usage_max 0.9919 (0.9443) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4657 (0.4334) nleep/row_max_mean 1576.3054 (1552.4889) nleep/row_max_std 51.8614 (57.6140) nleep/row_min_mean 1525.3839 (1510.9832) lr 1.5878e-03 eta 0:13:54
epoch [17/50] batch [120/181] time 0.135 (0.137) data 0.000 (0.002) loss 2.4210 (2.3057) teacher_loss 0.3086 (0.3484) loss_zs_kd 0.0115 (0.0252) loss_oracle 1.1470 (0.9452) kd_loss 1.5332 (1.4722) acc 84.3750 (87.4479) gate/entropy 0.9809 (0.9803) gate/usage_max 0.5705 (0.5711) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1677 (0.1681) teacher/entropy 0.0000 (0.0200) teacher/usage_max 1.0000 (0.9535) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4714 (0.4396) nleep/row_max_mean 1561.9861 (1554.5104) nleep/row_max_std 63.1693 (58.2446) nleep/row_min_mean 1509.1875 (1511.4213) lr 1.5878e-03 eta 0:13:47
epoch [17/50] batch [140/181] time 0.165 (0.138) data 0.000 (0.002) loss 2.5941 (2.3391) teacher_loss 0.6769 (0.3646) loss_zs_kd 0.0132 (0.0244) loss_oracle 0.7578 (0.9630) kd_loss 1.5317 (1.4807) acc 84.3750 (86.7188) gate/entropy 0.9812 (0.9804) gate/usage_max 0.5702 (0.5710) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1675 (0.1681) teacher/entropy 0.0000 (0.0172) teacher/usage_max 1.0000 (0.9599) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4714 (0.4440) nleep/row_max_mean 1556.7999 (1556.3084) nleep/row_max_std 68.2829 (58.6125) nleep/row_min_mean 1503.3547 (1511.7000) lr 1.5878e-03 eta 0:13:51
epoch [17/50] batch [160/181] time 0.151 (0.138) data 0.000 (0.002) loss 2.4838 (2.3473) teacher_loss 0.4264 (0.3677) loss_zs_kd 0.0255 (0.0235) loss_oracle 1.0260 (0.9619) kd_loss 1.5316 (1.4868) acc 87.5000 (86.5234) gate/entropy 0.9810 (0.9805) gate/usage_max 0.5703 (0.5709) gate/usage_min 0.2135 (0.2137) gate/usage_std 0.1676 (0.1680) teacher/entropy 0.0000 (0.0153) teacher/usage_max 1.0000 (0.9647) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4714 (0.4473) nleep/row_max_mean 1572.7622 (1557.6881) nleep/row_max_std 51.8588 (59.0624) nleep/row_min_mean 1518.5280 (1511.9590) lr 1.5878e-03 eta 0:13:47
epoch [17/50] batch [180/181] time 0.078 (0.135) data 0.000 (0.001) loss 2.5188 (2.3553) teacher_loss 0.4374 (0.3708) loss_zs_kd 0.0158 (0.0226) loss_oracle 1.0871 (0.9644) kd_loss 1.5300 (1.4910) acc 84.3750 (86.4583) gate/entropy 0.9814 (0.9806) gate/usage_max 0.5700 (0.5708) gate/usage_min 0.2135 (0.2137) gate/usage_std 0.1673 (0.1679) teacher/entropy 0.0000 (0.0140) teacher/usage_max 1.0000 (0.9681) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4714 (0.4496) nleep/row_max_mean 1575.6411 (1558.9056) nleep/row_max_std 45.4272 (59.0698) nleep/row_min_mean 1521.8953 (1512.3700) lr 1.5878e-03 eta 0:13:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,390
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,662
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [18/50] batch [20/181] time 0.127 (0.128) data 0.000 (0.014) loss 2.4877 (2.4670) teacher_loss 0.3818 (0.4080) loss_zs_kd 0.0135 (0.0139) loss_oracle 1.1847 (1.0514) kd_loss 1.5068 (1.5264) acc 90.6250 (85.0000) gate/entropy 0.9818 (0.9817) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0215 (0.0022) teacher/usage_max 0.9827 (0.9966) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4592 (0.4690) nleep/row_max_mean 1582.2206 (1568.8975) nleep/row_max_std 51.0246 (60.0356) nleep/row_min_mean 1526.8732 (1514.4430) lr 1.5358e-03 eta 0:12:43
epoch [18/50] batch [40/181] time 0.090 (0.113) data 0.000 (0.007) loss 2.5027 (2.4616) teacher_loss 0.4171 (0.3996) loss_zs_kd 0.0140 (0.0145) loss_oracle 1.1092 (1.0589) kd_loss 1.5241 (1.5253) acc 84.3750 (85.2344) gate/entropy 0.9822 (0.9818) gate/usage_max 0.5691 (0.5695) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1667 (0.1670) teacher/entropy 0.0018 (0.0025) teacher/usage_max 0.9997 (0.9974) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4712 (0.4695) nleep/row_max_mean 1572.9407 (1573.0785) nleep/row_max_std 74.1709 (60.6480) nleep/row_min_mean 1514.7120 (1517.1827) lr 1.5358e-03 eta 0:11:10
epoch [18/50] batch [60/181] time 0.079 (0.109) data 0.001 (0.005) loss 2.3391 (2.4574) teacher_loss 0.2890 (0.3921) loss_zs_kd 0.0224 (0.0139) loss_oracle 1.0371 (1.0684) kd_loss 1.5204 (1.5241) acc 87.5000 (85.4688) gate/entropy 0.9829 (0.9820) gate/usage_max 0.5684 (0.5693) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1662 (0.1669) teacher/entropy 0.0021 (0.0022) teacher/usage_max 0.9996 (0.9975) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4711 (0.4696) nleep/row_max_mean 1549.3921 (1573.5600) nleep/row_max_std 67.2811 (61.0462) nleep/row_min_mean 1495.2744 (1516.8173) lr 1.5358e-03 eta 0:10:44
epoch [18/50] batch [80/181] time 0.081 (0.113) data 0.000 (0.004) loss 2.8002 (2.4428) teacher_loss 0.7386 (0.3885) loss_zs_kd 0.0241 (0.0138) loss_oracle 1.0538 (1.0480) kd_loss 1.5227 (1.5234) acc 71.8750 (85.1562) gate/entropy 0.9826 (0.9822) gate/usage_max 0.5687 (0.5692) gate/usage_min 0.2132 (0.2134) gate/usage_std 0.1664 (0.1668) teacher/entropy 0.0000 (0.0020) teacher/usage_max 1.0000 (0.9977) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4698) nleep/row_max_mean 1571.5388 (1572.4156) nleep/row_max_std 72.8948 (61.9756) nleep/row_min_mean 1516.7795 (1515.6180) lr 1.5358e-03 eta 0:11:03
epoch [18/50] batch [100/181] time 0.083 (0.114) data 0.000 (0.003) loss 2.3425 (2.4321) teacher_loss 0.3660 (0.3866) loss_zs_kd 0.0082 (0.0140) loss_oracle 0.9070 (1.0327) kd_loss 1.5188 (1.5222) acc 87.5000 (85.5312) gate/entropy 0.9834 (0.9824) gate/usage_max 0.5678 (0.5690) gate/usage_min 0.2132 (0.2134) gate/usage_std 0.1658 (0.1666) teacher/entropy 0.0000 (0.0019) teacher/usage_max 1.0000 (0.9977) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4698) nleep/row_max_mean 1550.5927 (1571.8250) nleep/row_max_std 57.7221 (62.1930) nleep/row_min_mean 1498.5073 (1515.1633) lr 1.5358e-03 eta 0:11:08
epoch [18/50] batch [120/181] time 0.196 (0.114) data 0.000 (0.002) loss 2.5993 (2.4239) teacher_loss 0.5609 (0.3877) loss_zs_kd 0.0121 (0.0138) loss_oracle 1.0330 (1.0170) kd_loss 1.5158 (1.5208) acc 84.3750 (85.4948) gate/entropy 0.9839 (0.9826) gate/usage_max 0.5673 (0.5687) gate/usage_min 0.2131 (0.2133) gate/usage_std 0.1655 (0.1665) teacher/entropy 0.0001 (0.0020) teacher/usage_max 1.0000 (0.9973) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4695) nleep/row_max_mean 1559.3374 (1571.0785) nleep/row_max_std 57.4241 (61.7646) nleep/row_min_mean 1507.2341 (1514.6343) lr 1.5358e-03 eta 0:11:07
epoch [18/50] batch [140/181] time 0.182 (0.121) data 0.000 (0.002) loss 2.4124 (2.4045) teacher_loss 0.4511 (0.3807) loss_zs_kd 0.0130 (0.0132) loss_oracle 0.9273 (0.9962) kd_loss 1.4911 (1.5191) acc 81.2500 (85.6696) gate/entropy 0.9845 (0.9828) gate/usage_max 0.5667 (0.5685) gate/usage_min 0.2129 (0.2133) gate/usage_std 0.1651 (0.1663) teacher/entropy 0.0219 (0.0023) teacher/usage_max 0.9867 (0.9973) teacher/usage_min 0.0001 (0.0000) teacher/usage_std 0.4620 (0.4695) nleep/row_max_mean 1570.0692 (1570.8275) nleep/row_max_std 60.7241 (61.4320) nleep/row_min_mean 1511.9386 (1514.5628) lr 1.5358e-03 eta 0:11:44
epoch [18/50] batch [160/181] time 0.163 (0.126) data 0.000 (0.002) loss 2.2991 (2.4017) teacher_loss 0.2686 (0.3820) loss_zs_kd 0.0082 (0.0132) loss_oracle 1.0369 (0.9907) kd_loss 1.5079 (1.5177) acc 93.7500 (85.6250) gate/entropy 0.9851 (0.9831) gate/usage_max 0.5660 (0.5682) gate/usage_min 0.2128 (0.2132) gate/usage_std 0.1646 (0.1661) teacher/entropy 0.0007 (0.0023) teacher/usage_max 0.9999 (0.9975) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4713 (0.4697) nleep/row_max_mean 1568.5442 (1571.1531) nleep/row_max_std 68.7368 (61.1209) nleep/row_min_mean 1515.4333 (1514.8476) lr 1.5358e-03 eta 0:12:11
epoch [18/50] batch [180/181] time 0.152 (0.129) data 0.000 (0.002) loss 2.4460 (2.3973) teacher_loss 0.5310 (0.3830) loss_zs_kd 0.0008 (0.0131) loss_oracle 0.8217 (0.9839) kd_loss 1.5037 (1.5158) acc 81.2500 (85.6424) gate/entropy 0.9859 (0.9833) gate/usage_max 0.5652 (0.5679) gate/usage_min 0.2126 (0.2132) gate/usage_std 0.1640 (0.1659) teacher/entropy 0.0000 (0.0024) teacher/usage_max 1.0000 (0.9975) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4697) nleep/row_max_mean 1574.9763 (1570.7225) nleep/row_max_std 56.8274 (60.5134) nleep/row_min_mean 1518.5415 (1514.6075) lr 1.5358e-03 eta 0:12:28
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,383
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [19/50] batch [20/181] time 0.164 (0.158) data 0.000 (0.014) loss 2.3440 (2.2873) teacher_loss 0.3395 (0.3171) loss_zs_kd 0.0109 (0.0111) loss_oracle 1.0062 (0.9438) kd_loss 1.4959 (1.4929) acc 87.5000 (89.5312) gate/entropy 0.9868 (0.9865) gate/usage_max 0.5643 (0.5645) gate/usage_min 0.2122 (0.2124) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0020 (0.0035) teacher/usage_max 0.9996 (0.9930) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4711 (0.4665) nleep/row_max_mean 1577.4197 (1569.6396) nleep/row_max_std 55.1394 (55.7781) nleep/row_min_mean 1518.5206 (1514.1749) lr 1.4818e-03 eta 0:15:13
epoch [19/50] batch [40/181] time 0.168 (0.155) data 0.000 (0.007) loss 2.0736 (2.2928) teacher_loss 0.1796 (0.3352) loss_zs_kd 0.0146 (0.0124) loss_oracle 0.8769 (0.9261) kd_loss 1.4483 (1.4883) acc 90.6250 (87.7344) gate/entropy 0.9881 (0.9870) gate/usage_max 0.5628 (0.5640) gate/usage_min 0.2120 (0.2123) gate/usage_std 0.1623 (0.1631) teacher/entropy 0.0173 (0.0046) teacher/usage_max 0.9727 (0.9925) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4523 (0.4661) nleep/row_max_mean 1562.3896 (1567.5315) nleep/row_max_std 52.3214 (56.2483) nleep/row_min_mean 1510.8616 (1512.5261) lr 1.4818e-03 eta 0:14:52
epoch [19/50] batch [60/181] time 0.093 (0.147) data 0.000 (0.005) loss 2.1849 (2.2862) teacher_loss 0.3006 (0.3537) loss_zs_kd 0.0100 (0.0122) loss_oracle 0.7942 (0.8793) kd_loss 1.4822 (1.4868) acc 90.6250 (87.3958) gate/entropy 0.9893 (0.9876) gate/usage_max 0.5615 (0.5633) gate/usage_min 0.2116 (0.2121) gate/usage_std 0.1614 (0.1627) teacher/entropy 0.0006 (0.0037) teacher/usage_max 0.9999 (0.9935) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4713 (0.4668) nleep/row_max_mean 1561.5837 (1564.8961) nleep/row_max_std 52.8957 (56.7254) nleep/row_min_mean 1509.4673 (1510.9047) lr 1.4818e-03 eta 0:14:05
epoch [19/50] batch [80/181] time 0.089 (0.138) data 0.000 (0.004) loss 2.2715 (2.2788) teacher_loss 0.3681 (0.3589) loss_zs_kd 0.0070 (0.0124) loss_oracle 0.8553 (0.8656) kd_loss 1.4722 (1.4810) acc 87.5000 (87.1875) gate/entropy 0.9910 (0.9882) gate/usage_max 0.5595 (0.5626) gate/usage_min 0.2111 (0.2119) gate/usage_std 0.1601 (0.1622) teacher/entropy 0.0000 (0.0041) teacher/usage_max 1.0000 (0.9922) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4659) nleep/row_max_mean 1556.0533 (1562.6811) nleep/row_max_std 67.8223 (57.4284) nleep/row_min_mean 1504.2928 (1509.6389) lr 1.4818e-03 eta 0:13:05
epoch [19/50] batch [100/181] time 0.130 (0.137) data 0.000 (0.003) loss 2.1548 (2.2809) teacher_loss 0.3418 (0.3735) loss_zs_kd 0.0157 (0.0130) loss_oracle 0.6912 (0.8486) kd_loss 1.4595 (1.4766) acc 87.5000 (86.3125) gate/entropy 0.9928 (0.9889) gate/usage_max 0.5574 (0.5618) gate/usage_min 0.2104 (0.2117) gate/usage_std 0.1587 (0.1617) teacher/entropy 0.0005 (0.0040) teacher/usage_max 0.9999 (0.9926) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4662) nleep/row_max_mean 1541.6476 (1560.8289) nleep/row_max_std 77.3829 (58.9336) nleep/row_min_mean 1492.9647 (1508.3494) lr 1.4818e-03 eta 0:12:58
epoch [19/50] batch [120/181] time 0.184 (0.133) data 0.000 (0.002) loss 2.1056 (2.2644) teacher_loss 0.4443 (0.3795) loss_zs_kd 0.0083 (0.0132) loss_oracle 0.4324 (0.8152) kd_loss 1.4409 (1.4707) acc 84.3750 (85.9375) gate/entropy 0.9953 (0.9898) gate/usage_max 0.5544 (0.5609) gate/usage_min 0.2096 (0.2114) gate/usage_std 0.1567 (0.1610) teacher/entropy 0.0027 (0.0046) teacher/usage_max 0.9995 (0.9922) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4711 (0.4659) nleep/row_max_mean 1535.4048 (1559.2168) nleep/row_max_std 70.7309 (59.6267) nleep/row_min_mean 1488.4985 (1507.3325) lr 1.4818e-03 eta 0:12:32
epoch [19/50] batch [140/181] time 0.080 (0.130) data 0.000 (0.002) loss 2.2736 (2.2353) teacher_loss 0.5172 (0.3788) loss_zs_kd 0.0088 (0.0130) loss_oracle 0.6535 (0.7767) kd_loss 1.4253 (1.4617) acc 87.5000 (85.7589) gate/entropy 0.9974 (0.9907) gate/usage_max 0.5517 (0.5597) gate/usage_min 0.2084 (0.2110) gate/usage_std 0.1549 (0.1603) teacher/entropy 0.0020 (0.0060) teacher/usage_max 0.9997 (0.9904) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4712 (0.4646) nleep/row_max_mean 1556.7937 (1557.9325) nleep/row_max_std 59.4299 (60.7066) nleep/row_min_mean 1506.2117 (1506.5599) lr 1.4818e-03 eta 0:12:12
epoch [19/50] batch [160/181] time 0.077 (0.127) data 0.000 (0.002) loss 1.9401 (2.2170) teacher_loss 0.2875 (0.3801) loss_zs_kd 0.0118 (0.0128) loss_oracle 0.6021 (0.7578) kd_loss 1.3457 (1.4516) acc 87.5000 (85.6641) gate/entropy 1.0010 (0.9918) gate/usage_max 0.5471 (0.5585) gate/usage_min 0.2071 (0.2106) gate/usage_std 0.1520 (0.1594) teacher/entropy 0.0103 (0.0075) teacher/usage_max 0.9406 (0.9882) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4301 (0.4631) nleep/row_max_mean 1549.8801 (1557.4013) nleep/row_max_std 62.8158 (61.1386) nleep/row_min_mean 1499.6409 (1506.3073) lr 1.4818e-03 eta 0:11:55
epoch [19/50] batch [180/181] time 0.073 (0.125) data 0.000 (0.002) loss 2.1522 (2.1961) teacher_loss 0.4761 (0.3780) loss_zs_kd 0.0132 (0.0127) loss_oracle 0.6562 (0.7432) kd_loss 1.3413 (1.4402) acc 78.1250 (85.8681) gate/entropy 1.0048 (0.9930) gate/usage_max 0.5417 (0.5569) gate/usage_min 0.2052 (0.2101) gate/usage_std 0.1486 (0.1584) teacher/entropy 0.0253 (0.0087) teacher/usage_max 0.9901 (0.9859) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4644 (0.4615) nleep/row_max_mean 1533.6250 (1556.6657) nleep/row_max_std 74.4528 (61.5508) nleep/row_min_mean 1488.6919 (1505.8208) lr 1.4818e-03 eta 0:11:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [20/50] batch [20/181] time 0.129 (0.158) data 0.000 (0.012) loss 2.1043 (2.0168) teacher_loss 0.5318 (0.3656) loss_zs_kd 0.0087 (0.0147) loss_oracle 0.5448 (0.6368) kd_loss 1.2958 (1.3255) acc 81.2500 (87.6562) gate/entropy 1.0093 (1.0070) gate/usage_max 0.5348 (0.5383) gate/usage_min 0.2025 (0.2038) gate/usage_std 0.1446 (0.1466) teacher/entropy 0.0224 (0.0138) teacher/usage_max 0.9737 (0.9786) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4529 (0.4564) nleep/row_max_mean 1562.9304 (1558.1008) nleep/row_max_std 66.1843 (61.6075) nleep/row_min_mean 1507.4500 (1506.3869) lr 1.4258e-03 eta 0:14:44
epoch [20/50] batch [40/181] time 0.129 (0.147) data 0.000 (0.006) loss 1.6041 (1.9256) teacher_loss 0.1762 (0.3390) loss_zs_kd 0.0039 (0.0140) loss_oracle 0.3802 (0.5638) kd_loss 1.2359 (1.2977) acc 96.8750 (87.8906) gate/entropy 1.0142 (1.0094) gate/usage_max 0.5263 (0.5345) gate/usage_min 0.1996 (0.2024) gate/usage_std 0.1398 (0.1444) teacher/entropy 0.0254 (0.0177) teacher/usage_max 0.9495 (0.9707) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4362 (0.4509) nleep/row_max_mean 1537.8286 (1556.3869) nleep/row_max_std 74.4733 (60.4667) nleep/row_min_mean 1490.3506 (1505.7287) lr 1.4258e-03 eta 0:13:40
epoch [20/50] batch [60/181] time 0.130 (0.145) data 0.000 (0.004) loss 1.6980 (1.8669) teacher_loss 0.3722 (0.3389) loss_zs_kd 0.0165 (0.0134) loss_oracle 0.5644 (0.5187) kd_loss 1.0354 (1.2620) acc 81.2500 (87.7083) gate/entropy 1.0186 (1.0117) gate/usage_max 0.5172 (0.5302) gate/usage_min 0.1960 (0.2008) gate/usage_std 0.1352 (0.1421) teacher/entropy 0.0777 (0.0229) teacher/usage_max 0.7696 (0.9550) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.3225 (0.4404) nleep/row_max_mean 1536.5602 (1553.7961) nleep/row_max_std 58.5091 (60.0207) nleep/row_min_mean 1490.6357 (1504.0654) lr 1.4258e-03 eta 0:13:23
epoch [20/50] batch [80/181] time 0.131 (0.144) data 0.000 (0.003) loss 1.5549 (1.8243) teacher_loss 0.1220 (0.3310) loss_zs_kd 0.0118 (0.0141) loss_oracle 0.5818 (0.5278) kd_loss 1.1361 (1.2223) acc 100.0000 (87.9688) gate/entropy 1.0224 (1.0140) gate/usage_max 0.5075 (0.5257) gate/usage_min 0.1920 (0.1991) gate/usage_std 0.1308 (0.1398) teacher/entropy 0.0272 (0.0304) teacher/usage_max 0.9257 (0.9342) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4199 (0.4266) nleep/row_max_mean 1560.8143 (1552.8737) nleep/row_max_std 55.7828 (59.2661) nleep/row_min_mean 1513.1039 (1503.8497) lr 1.4258e-03 eta 0:13:13
epoch [20/50] batch [100/181] time 0.146 (0.142) data 0.000 (0.003) loss 1.6797 (1.7810) teacher_loss 0.4368 (0.3235) loss_zs_kd 0.0403 (0.0152) loss_oracle 0.5259 (0.5247) kd_loss 0.9598 (1.1876) acc 84.3750 (88.3750) gate/entropy 1.0256 (1.0160) gate/usage_max 0.4969 (0.5209) gate/usage_min 0.1881 (0.1973) gate/usage_std 0.1267 (0.1376) teacher/entropy 0.0954 (0.0362) teacher/usage_max 0.7816 (0.9180) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3293 (0.4160) nleep/row_max_mean 1548.9615 (1551.3867) nleep/row_max_std 54.7453 (58.1411) nleep/row_min_mean 1503.5310 (1503.1124) lr 1.4258e-03 eta 0:13:04
epoch [20/50] batch [120/181] time 0.124 (0.141) data 0.000 (0.002) loss 1.3431 (1.7407) teacher_loss 0.1403 (0.3197) loss_zs_kd 0.0028 (0.0158) loss_oracle 0.5139 (0.5134) kd_loss 0.9445 (1.1564) acc 96.8750 (88.4896) gate/entropy 1.0277 (1.0178) gate/usage_max 0.4875 (0.5161) gate/usage_min 0.1844 (0.1954) gate/usage_std 0.1238 (0.1355) teacher/entropy 0.0773 (0.0393) teacher/usage_max 0.7676 (0.9000) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.3214 (0.4045) nleep/row_max_mean 1550.5349 (1551.4729) nleep/row_max_std 53.7038 (56.7852) nleep/row_min_mean 1503.3368 (1503.5961) lr 1.4258e-03 eta 0:12:51
epoch [20/50] batch [140/181] time 0.126 (0.140) data 0.000 (0.002) loss 1.4337 (1.7135) teacher_loss 0.2441 (0.3259) loss_zs_kd 0.0166 (0.0165) loss_oracle 0.4020 (0.5011) kd_loss 0.9803 (1.1287) acc 93.7500 (88.4821) gate/entropy 1.0287 (1.0193) gate/usage_max 0.4790 (0.5114) gate/usage_min 0.1809 (0.1936) gate/usage_std 0.1218 (0.1337) teacher/entropy 0.0441 (0.0436) teacher/usage_max 0.8431 (0.8856) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3661 (0.3952) nleep/row_max_mean 1552.1619 (1550.7391) nleep/row_max_std 45.2849 (55.3439) nleep/row_min_mean 1509.7579 (1503.5003) lr 1.4258e-03 eta 0:12:46
epoch [20/50] batch [160/181] time 0.156 (0.140) data 0.000 (0.002) loss 1.3402 (1.6811) teacher_loss 0.2638 (0.3265) loss_zs_kd 0.0197 (0.0177) loss_oracle 0.3998 (0.4902) kd_loss 0.8667 (1.1006) acc 90.6250 (88.4375) gate/entropy 1.0290 (1.0205) gate/usage_max 0.4722 (0.5069) gate/usage_min 0.1781 (0.1918) gate/usage_std 0.1206 (0.1321) teacher/entropy 0.0992 (0.0474) teacher/usage_max 0.7199 (0.8647) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.2963 (0.3832) nleep/row_max_mean 1562.1165 (1549.4872) nleep/row_max_std 40.8585 (54.7718) nleep/row_min_mean 1517.7280 (1502.7606) lr 1.4258e-03 eta 0:12:44
epoch [20/50] batch [180/181] time 0.133 (0.140) data 0.000 (0.002) loss 1.3815 (1.6489) teacher_loss 0.1951 (0.3193) loss_zs_kd 0.0296 (0.0178) loss_oracle 0.5087 (0.4852) kd_loss 0.9172 (1.0781) acc 96.8750 (88.7674) gate/entropy 1.0291 (1.0215) gate/usage_max 0.4669 (0.5028) gate/usage_min 0.1761 (0.1902) gate/usage_std 0.1199 (0.1308) teacher/entropy 0.0652 (0.0504) teacher/usage_max 0.8245 (0.8529) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3546 (0.3761) nleep/row_max_mean 1544.1614 (1548.0239) nleep/row_max_std 45.9258 (54.5767) nleep/row_min_mean 1503.6589 (1501.8920) lr 1.4258e-03 eta 0:12:38
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [21/50] batch [20/181] time 0.080 (0.128) data 0.000 (0.016) loss 1.4859 (1.4703) teacher_loss 0.2743 (0.3128) loss_zs_kd 0.0124 (0.0204) loss_oracle 0.5261 (0.4644) kd_loss 0.9424 (0.9151) acc 87.5000 (89.5312) gate/entropy 1.0290 (1.0291) gate/usage_max 0.4614 (0.4640) gate/usage_min 0.1740 (0.1750) gate/usage_std 0.1194 (0.1196) teacher/entropy 0.0431 (0.0599) teacher/usage_max 0.9075 (0.8224) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4078 (0.3551) nleep/row_max_mean 1529.5598 (1537.2585) nleep/row_max_std 61.9658 (52.8240) nleep/row_min_mean 1493.2242 (1496.6226) lr 1.3681e-03 eta 0:11:33
epoch [21/50] batch [40/181] time 0.181 (0.127) data 0.000 (0.008) loss 1.4863 (1.4872) teacher_loss 0.3783 (0.3175) loss_zs_kd 0.0150 (0.0218) loss_oracle 0.4274 (0.4842) kd_loss 0.8868 (0.9167) acc 84.3750 (88.6719) gate/entropy 1.0286 (1.0289) gate/usage_max 0.4561 (0.4612) gate/usage_min 0.1719 (0.1739) gate/usage_std 0.1192 (0.1194) teacher/entropy 0.0736 (0.0537) teacher/usage_max 0.8615 (0.8320) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.3777 (0.3611) nleep/row_max_mean 1532.4221 (1536.9261) nleep/row_max_std 51.6830 (50.7036) nleep/row_min_mean 1492.4739 (1496.1090) lr 1.3681e-03 eta 0:11:24
epoch [21/50] batch [60/181] time 0.089 (0.118) data 0.000 (0.005) loss 1.3687 (1.4676) teacher_loss 0.2471 (0.3097) loss_zs_kd 0.0100 (0.0217) loss_oracle 0.4472 (0.4755) kd_loss 0.8930 (0.9093) acc 93.7500 (88.8542) gate/entropy 1.0278 (1.0287) gate/usage_max 0.4509 (0.4585) gate/usage_min 0.1697 (0.1728) gate/usage_std 0.1193 (0.1194) teacher/entropy 0.0512 (0.0560) teacher/usage_max 0.8614 (0.8416) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.3777 (0.3667) nleep/row_max_mean 1545.9282 (1537.9930) nleep/row_max_std 53.0462 (50.2934) nleep/row_min_mean 1505.4974 (1497.2742) lr 1.3681e-03 eta 0:10:33
epoch [21/50] batch [80/181] time 0.129 (0.116) data 0.000 (0.004) loss 1.3674 (1.4659) teacher_loss 0.2703 (0.3152) loss_zs_kd 0.0326 (0.0211) loss_oracle 0.3589 (0.4614) kd_loss 0.9014 (0.9094) acc 90.6250 (88.5547) gate/entropy 1.0270 (1.0284) gate/usage_max 0.4467 (0.4561) gate/usage_min 0.1679 (0.1718) gate/usage_std 0.1196 (0.1194) teacher/entropy 0.0473 (0.0521) teacher/usage_max 0.9680 (0.8532) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4490 (0.3738) nleep/row_max_mean 1543.2007 (1538.6824) nleep/row_max_std 57.2208 (51.1249) nleep/row_min_mean 1503.2100 (1497.8905) lr 1.3681e-03 eta 0:10:19
epoch [21/50] batch [100/181] time 0.074 (0.114) data 0.000 (0.003) loss 1.5119 (1.4675) teacher_loss 0.3240 (0.3213) loss_zs_kd 0.0213 (0.0208) loss_oracle 0.4544 (0.4553) kd_loss 0.9501 (0.9081) acc 87.5000 (88.1875) gate/entropy 1.0265 (1.0281) gate/usage_max 0.4436 (0.4539) gate/usage_min 0.1667 (0.1709) gate/usage_std 0.1199 (0.1195) teacher/entropy 0.0097 (0.0494) teacher/usage_max 0.9051 (0.8567) teacher/usage_min 0.0312 (0.0055) teacher/usage_std 0.4045 (0.3757) nleep/row_max_mean 1552.8450 (1538.2700) nleep/row_max_std 54.4213 (51.4084) nleep/row_min_mean 1510.5912 (1497.6331) lr 1.3681e-03 eta 0:10:09
epoch [21/50] batch [120/181] time 0.097 (0.116) data 0.000 (0.003) loss 1.3107 (1.4588) teacher_loss 0.2225 (0.3215) loss_zs_kd 0.0233 (0.0206) loss_oracle 0.3765 (0.4459) kd_loss 0.8883 (0.9041) acc 93.7500 (88.3333) gate/entropy 1.0260 (1.0278) gate/usage_max 0.4413 (0.4520) gate/usage_min 0.1659 (0.1702) gate/usage_std 0.1201 (0.1195) teacher/entropy 0.0365 (0.0487) teacher/usage_max 0.9234 (0.8620) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.4184 (0.3790) nleep/row_max_mean 1531.6973 (1537.4366) nleep/row_max_std 49.3299 (51.6722) nleep/row_min_mean 1492.5833 (1497.1106) lr 1.3681e-03 eta 0:10:15
epoch [21/50] batch [140/181] time 0.152 (0.116) data 0.000 (0.002) loss 1.4547 (1.4645) teacher_loss 0.4130 (0.3312) loss_zs_kd 0.0140 (0.0204) loss_oracle 0.3699 (0.4416) kd_loss 0.8497 (0.9023) acc 81.2500 (87.9688) gate/entropy 1.0252 (1.0274) gate/usage_max 0.4386 (0.4502) gate/usage_min 0.1646 (0.1694) gate/usage_std 0.1205 (0.1197) teacher/entropy 0.0536 (0.0463) teacher/usage_max 0.7988 (0.8686) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3392 (0.3832) nleep/row_max_mean 1552.0815 (1537.9736) nleep/row_max_std 38.6001 (51.2929) nleep/row_min_mean 1511.2947 (1497.6768) lr 1.3681e-03 eta 0:10:15
epoch [21/50] batch [160/181] time 0.157 (0.120) data 0.000 (0.002) loss 1.4239 (1.4598) teacher_loss 0.3355 (0.3310) loss_zs_kd 0.0157 (0.0207) loss_oracle 0.4087 (0.4356) kd_loss 0.8762 (0.9007) acc 87.5000 (87.8711) gate/entropy 1.0249 (1.0271) gate/usage_max 0.4370 (0.4487) gate/usage_min 0.1640 (0.1688) gate/usage_std 0.1207 (0.1198) teacher/entropy 0.0568 (0.0443) teacher/usage_max 0.8616 (0.8744) teacher/usage_min 0.0277 (0.0056) teacher/usage_std 0.3751 (0.3869) nleep/row_max_mean 1525.3062 (1537.7177) nleep/row_max_std 62.4026 (51.7264) nleep/row_min_mean 1488.3895 (1497.5565) lr 1.3681e-03 eta 0:10:33
epoch [21/50] batch [180/181] time 0.138 (0.123) data 0.000 (0.002) loss 1.4597 (1.4612) teacher_loss 0.3929 (0.3362) loss_zs_kd 0.0195 (0.0206) loss_oracle 0.3088 (0.4307) kd_loss 0.9026 (0.8993) acc 87.5000 (87.6562) gate/entropy 1.0242 (1.0269) gate/usage_max 0.4350 (0.4473) gate/usage_min 0.1631 (0.1682) gate/usage_std 0.1211 (0.1199) teacher/entropy 0.0038 (0.0417) teacher/usage_max 0.9370 (0.8821) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.4277 (0.3919) nleep/row_max_mean 1542.4016 (1537.9107) nleep/row_max_std 54.6730 (51.9467) nleep/row_min_mean 1502.9961 (1497.7745) lr 1.3681e-03 eta 0:10:48
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,402
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [22/50] batch [20/181] time 0.166 (0.171) data 0.000 (0.016) loss 1.4789 (1.4041) teacher_loss 0.3989 (0.3284) loss_zs_kd 0.0077 (0.0146) loss_oracle 0.3748 (0.3732) kd_loss 0.8888 (0.8818) acc 87.5000 (88.1250) gate/entropy 1.0238 (1.0241) gate/usage_max 0.4336 (0.4343) gate/usage_min 0.1625 (0.1629) gate/usage_std 0.1214 (0.1212) teacher/entropy 0.0172 (0.0276) teacher/usage_max 0.9926 (0.9277) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.4662 (0.4215) nleep/row_max_mean 1542.4282 (1530.9689) nleep/row_max_std 45.8731 (50.4081) nleep/row_min_mean 1502.2434 (1492.9920) lr 1.3090e-03 eta 0:14:55
epoch [22/50] batch [40/181] time 0.168 (0.164) data 0.000 (0.008) loss 1.3815 (1.4169) teacher_loss 0.3156 (0.3465) loss_zs_kd 0.0221 (0.0171) loss_oracle 0.3810 (0.3740) kd_loss 0.8643 (0.8749) acc 87.5000 (86.7969) gate/entropy 1.0237 (1.0238) gate/usage_max 0.4328 (0.4337) gate/usage_min 0.1623 (0.1626) gate/usage_std 0.1215 (0.1214) teacher/entropy 0.0358 (0.0323) teacher/usage_max 0.9374 (0.9266) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.4279 (0.4209) nleep/row_max_mean 1512.6530 (1535.5116) nleep/row_max_std 60.2180 (50.8349) nleep/row_min_mean 1479.0370 (1497.0652) lr 1.3090e-03 eta 0:14:13
epoch [22/50] batch [60/181] time 0.140 (0.156) data 0.000 (0.006) loss 1.3242 (1.4037) teacher_loss 0.1904 (0.3333) loss_zs_kd 0.0047 (0.0170) loss_oracle 0.4181 (0.3774) kd_loss 0.9225 (0.8732) acc 93.7500 (87.7604) gate/entropy 1.0232 (1.0236) gate/usage_max 0.4317 (0.4331) gate/usage_min 0.1618 (0.1623) gate/usage_std 0.1217 (0.1215) teacher/entropy 0.0024 (0.0321) teacher/usage_max 0.9059 (0.9335) teacher/usage_min 0.0312 (0.0048) teacher/usage_std 0.4050 (0.4255) nleep/row_max_mean 1538.1140 (1537.9305) nleep/row_max_std 53.1824 (50.7851) nleep/row_min_mean 1496.8263 (1499.4426) lr 1.3090e-03 eta 0:13:30
epoch [22/50] batch [80/181] time 0.073 (0.148) data 0.000 (0.004) loss 1.4362 (1.4032) teacher_loss 0.3458 (0.3312) loss_zs_kd 0.0154 (0.0174) loss_oracle 0.4549 (0.3798) kd_loss 0.8553 (0.8734) acc 87.5000 (88.0078) gate/entropy 1.0228 (1.0235) gate/usage_max 0.4307 (0.4326) gate/usage_min 0.1613 (0.1621) gate/usage_std 0.1220 (0.1216) teacher/entropy 0.0348 (0.0298) teacher/usage_max 0.8897 (0.9355) teacher/usage_min 0.0000 (0.0043) teacher/usage_std 0.3960 (0.4268) nleep/row_max_mean 1539.2216 (1537.6847) nleep/row_max_std 39.9714 (51.6813) nleep/row_min_mean 1501.6924 (1499.0735) lr 1.3090e-03 eta 0:12:43
epoch [22/50] batch [100/181] time 0.175 (0.137) data 0.000 (0.003) loss 1.3191 (1.4023) teacher_loss 0.1523 (0.3260) loss_zs_kd 0.0177 (0.0180) loss_oracle 0.5171 (0.3868) kd_loss 0.8994 (0.8738) acc 96.8750 (88.4375) gate/entropy 1.0226 (1.0233) gate/usage_max 0.4300 (0.4321) gate/usage_min 0.1610 (0.1619) gate/usage_std 0.1222 (0.1217) teacher/entropy 0.0193 (0.0280) teacher/usage_max 0.8832 (0.9377) teacher/usage_min 0.0312 (0.0044) teacher/usage_std 0.3895 (0.4283) nleep/row_max_mean 1537.0425 (1538.2508) nleep/row_max_std 51.6714 (52.6334) nleep/row_min_mean 1498.4565 (1499.6116) lr 1.3090e-03 eta 0:11:46
epoch [22/50] batch [120/181] time 0.144 (0.135) data 0.000 (0.003) loss 1.3690 (1.4055) teacher_loss 0.3025 (0.3311) loss_zs_kd 0.0083 (0.0178) loss_oracle 0.3779 (0.3876) kd_loss 0.8735 (0.8717) acc 87.5000 (88.2292) gate/entropy 1.0223 (1.0232) gate/usage_max 0.4292 (0.4317) gate/usage_min 0.1606 (0.1617) gate/usage_std 0.1224 (0.1218) teacher/entropy 0.0148 (0.0289) teacher/usage_max 0.9387 (0.9359) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.4288 (0.4271) nleep/row_max_mean 1529.2567 (1537.8255) nleep/row_max_std 58.4811 (53.6670) nleep/row_min_mean 1494.4083 (1499.4616) lr 1.3090e-03 eta 0:11:31
epoch [22/50] batch [140/181] time 0.134 (0.132) data 0.000 (0.002) loss 1.5729 (1.4010) teacher_loss 0.4980 (0.3263) loss_zs_kd 0.0217 (0.0175) loss_oracle 0.4133 (0.3906) kd_loss 0.8574 (0.8706) acc 78.1250 (88.2589) gate/entropy 1.0220 (1.0230) gate/usage_max 0.4285 (0.4313) gate/usage_min 0.1603 (0.1615) gate/usage_std 0.1226 (0.1219) teacher/entropy 0.0327 (0.0289) teacher/usage_max 0.9777 (0.9330) teacher/usage_min 0.0026 (0.0049) teacher/usage_std 0.4557 (0.4251) nleep/row_max_mean 1538.4390 (1537.2041) nleep/row_max_std 69.7580 (54.4021) nleep/row_min_mean 1500.2695 (1499.1400) lr 1.3090e-03 eta 0:11:15
epoch [22/50] batch [160/181] time 0.081 (0.131) data 0.000 (0.002) loss 1.3541 (1.4029) teacher_loss 0.2916 (0.3299) loss_zs_kd 0.0139 (0.0176) loss_oracle 0.4074 (0.3897) kd_loss 0.8518 (0.8694) acc 87.5000 (88.0273) gate/entropy 1.0219 (1.0229) gate/usage_max 0.4281 (0.4309) gate/usage_min 0.1602 (0.1614) gate/usage_std 0.1226 (0.1220) teacher/entropy 0.0310 (0.0296) teacher/usage_max 0.8902 (0.9303) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.3963 (0.4232) nleep/row_max_mean 1543.7898 (1536.9740) nleep/row_max_std 63.3093 (55.2494) nleep/row_min_mean 1502.0327 (1499.1045) lr 1.3090e-03 eta 0:11:07
epoch [22/50] batch [180/181] time 0.083 (0.126) data 0.000 (0.002) loss 1.3928 (1.4023) teacher_loss 0.3525 (0.3335) loss_zs_kd 0.0134 (0.0175) loss_oracle 0.3499 (0.3875) kd_loss 0.8587 (0.8663) acc 84.3750 (87.7951) gate/entropy 1.0217 (1.0228) gate/usage_max 0.4277 (0.4306) gate/usage_min 0.1600 (0.1612) gate/usage_std 0.1227 (0.1221) teacher/entropy 0.0267 (0.0311) teacher/usage_max 0.9887 (0.9265) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4634 (0.4207) nleep/row_max_mean 1548.7715 (1537.5753) nleep/row_max_std 61.2827 (55.5688) nleep/row_min_mean 1510.7500 (1499.8358) lr 1.3090e-03 eta 0:10:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,403
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [23/50] batch [20/181] time 0.142 (0.135) data 0.000 (0.014) loss 1.8321 (1.4479) teacher_loss 0.7401 (0.3760) loss_zs_kd 0.0225 (0.0195) loss_oracle 0.4186 (0.3827) kd_loss 0.8714 (0.8709) acc 65.6250 (87.0312) gate/entropy 1.0215 (1.0216) gate/usage_max 0.4272 (0.4274) gate/usage_min 0.1597 (0.1598) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0114 (0.0204) teacher/usage_max 0.9660 (0.9223) teacher/usage_min 0.0000 (0.0067) teacher/usage_std 0.4476 (0.4177) nleep/row_max_mean 1529.7399 (1540.3034) nleep/row_max_std 60.4361 (56.3085) nleep/row_min_mean 1491.2010 (1503.1687) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [40/181] time 0.161 (0.145) data 0.000 (0.007) loss 1.4649 (1.4458) teacher_loss 0.4591 (0.3804) loss_zs_kd 0.0103 (0.0194) loss_oracle 0.3916 (0.3893) kd_loss 0.8048 (0.8611) acc 87.5000 (86.9531) gate/entropy 1.0214 (1.0215) gate/usage_max 0.4268 (0.4272) gate/usage_min 0.1596 (0.1597) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0755 (0.0280) teacher/usage_max 0.9252 (0.9260) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.4197 (0.4203) nleep/row_max_mean 1548.4636 (1542.3673) nleep/row_max_std 53.2451 (57.0221) nleep/row_min_mean 1508.8719 (1504.6979) lr 1.2487e-03 eta 0:12:08
epoch [23/50] batch [60/181] time 0.155 (0.153) data 0.000 (0.005) loss 1.2044 (1.4144) teacher_loss 0.2131 (0.3567) loss_zs_kd 0.0113 (0.0182) loss_oracle 0.2808 (0.3773) kd_loss 0.8453 (0.8600) acc 93.7500 (87.6042) gate/entropy 1.0212 (1.0215) gate/usage_max 0.4264 (0.4270) gate/usage_min 0.1593 (0.1597) gate/usage_std 0.1231 (0.1229) teacher/entropy 0.0351 (0.0280) teacher/usage_max 0.9747 (0.9281) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.4536 (0.4217) nleep/row_max_mean 1564.2292 (1542.6693) nleep/row_max_std 49.1897 (56.8982) nleep/row_min_mean 1521.2830 (1504.8411) lr 1.2487e-03 eta 0:12:45
epoch [23/50] batch [80/181] time 0.175 (0.158) data 0.000 (0.004) loss 1.2309 (1.4001) teacher_loss 0.1981 (0.3525) loss_zs_kd 0.0112 (0.0180) loss_oracle 0.2967 (0.3659) kd_loss 0.8789 (0.8557) acc 96.8750 (87.6172) gate/entropy 1.0211 (1.0214) gate/usage_max 0.4262 (0.4269) gate/usage_min 0.1593 (0.1596) gate/usage_std 0.1232 (0.1230) teacher/entropy 0.0016 (0.0307) teacher/usage_max 0.9998 (0.9268) teacher/usage_min 0.0000 (0.0050) teacher/usage_std 0.4712 (0.4210) nleep/row_max_mean 1538.7294 (1543.4470) nleep/row_max_std 60.0580 (56.4717) nleep/row_min_mean 1502.8718 (1505.6024) lr 1.2487e-03 eta 0:13:07
epoch [23/50] batch [100/181] time 0.142 (0.158) data 0.000 (0.003) loss 1.3377 (1.3920) teacher_loss 0.3286 (0.3485) loss_zs_kd 0.0168 (0.0174) loss_oracle 0.3542 (0.3625) kd_loss 0.8236 (0.8535) acc 84.3750 (87.4688) gate/entropy 1.0211 (1.0213) gate/usage_max 0.4260 (0.4267) gate/usage_min 0.1592 (0.1595) gate/usage_std 0.1232 (0.1230) teacher/entropy 0.0689 (0.0323) teacher/usage_max 0.7872 (0.9230) teacher/usage_min 0.0187 (0.0051) teacher/usage_std 0.3288 (0.4184) nleep/row_max_mean 1540.1455 (1542.3919) nleep/row_max_std 58.4451 (56.6166) nleep/row_min_mean 1502.2600 (1504.6887) lr 1.2487e-03 eta 0:13:05
epoch [23/50] batch [120/181] time 0.135 (0.156) data 0.000 (0.002) loss 1.2451 (1.3819) teacher_loss 0.2749 (0.3411) loss_zs_kd 0.0178 (0.0170) loss_oracle 0.2985 (0.3630) kd_loss 0.8121 (0.8508) acc 84.3750 (87.7604) gate/entropy 1.0210 (1.0213) gate/usage_max 0.4258 (0.4266) gate/usage_min 0.1592 (0.1595) gate/usage_std 0.1232 (0.1231) teacher/entropy 0.0656 (0.0348) teacher/usage_max 0.9272 (0.9183) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4210 (0.4152) nleep/row_max_mean 1539.5078 (1541.4853) nleep/row_max_std 55.8780 (56.5810) nleep/row_min_mean 1503.7208 (1503.9658) lr 1.2487e-03 eta 0:12:54
epoch [23/50] batch [140/181] time 0.160 (0.157) data 0.000 (0.002) loss 1.3306 (1.3806) teacher_loss 0.2877 (0.3425) loss_zs_kd 0.0132 (0.0173) loss_oracle 0.3572 (0.3625) kd_loss 0.8577 (0.8483) acc 87.5000 (87.5446) gate/entropy 1.0208 (1.0212) gate/usage_max 0.4255 (0.4264) gate/usage_min 0.1590 (0.1594) gate/usage_std 0.1234 (0.1231) teacher/entropy 0.0181 (0.0370) teacher/usage_max 0.9031 (0.9120) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4048 (0.4110) nleep/row_max_mean 1543.8928 (1541.0950) nleep/row_max_std 59.2886 (56.5791) nleep/row_min_mean 1506.9545 (1503.7375) lr 1.2487e-03 eta 0:12:51
epoch [23/50] batch [160/181] time 0.129 (0.155) data 0.000 (0.002) loss 1.4111 (1.3830) teacher_loss 0.3347 (0.3457) loss_zs_kd 0.0248 (0.0181) loss_oracle 0.4372 (0.3653) kd_loss 0.8454 (0.8457) acc 84.3750 (87.4805) gate/entropy 1.0208 (1.0212) gate/usage_max 0.4253 (0.4263) gate/usage_min 0.1589 (0.1593) gate/usage_std 0.1234 (0.1231) teacher/entropy 0.0307 (0.0390) teacher/usage_max 0.9037 (0.9064) teacher/usage_min 0.0008 (0.0057) teacher/usage_std 0.4051 (0.4073) nleep/row_max_mean 1549.3250 (1540.9923) nleep/row_max_std 57.3782 (56.7983) nleep/row_min_mean 1511.8218 (1503.7065) lr 1.2487e-03 eta 0:12:43
epoch [23/50] batch [180/181] time 0.086 (0.149) data 0.000 (0.002) loss 1.4424 (1.3795) teacher_loss 0.3336 (0.3388) loss_zs_kd 0.0353 (0.0184) loss_oracle 0.4938 (0.3729) kd_loss 0.8442 (0.8450) acc 84.3750 (87.5694) gate/entropy 1.0207 (1.0211) gate/usage_max 0.4251 (0.4262) gate/usage_min 0.1589 (0.1593) gate/usage_std 0.1234 (0.1232) teacher/entropy 0.0407 (0.0390) teacher/usage_max 0.8031 (0.9045) teacher/usage_min 0.0124 (0.0056) teacher/usage_std 0.3396 (0.4061) nleep/row_max_mean 1533.9463 (1540.4603) nleep/row_max_std 54.2909 (56.8940) nleep/row_min_mean 1495.3354 (1503.1860) lr 1.2487e-03 eta 0:12:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,402
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [24/50] batch [20/181] time 0.079 (0.134) data 0.000 (0.019) loss 1.5231 (1.3432) teacher_loss 0.3574 (0.2871) loss_zs_kd 0.0241 (0.0185) loss_oracle 0.4627 (0.3981) kd_loss 0.9222 (0.8479) acc 87.5000 (89.2188) gate/entropy 1.0205 (1.0206) gate/usage_max 0.4248 (0.4250) gate/usage_min 0.1585 (0.1587) gate/usage_std 0.1236 (0.1235) teacher/entropy 0.0130 (0.0331) teacher/usage_max 0.9351 (0.9148) teacher/usage_min 0.0028 (0.0037) teacher/usage_std 0.4262 (0.4131) nleep/row_max_mean 1547.3291 (1537.5749) nleep/row_max_std 51.7341 (55.1471) nleep/row_min_mean 1511.2389 (1500.3081) lr 1.1874e-03 eta 0:10:53
epoch [24/50] batch [40/181] time 0.089 (0.113) data 0.000 (0.009) loss 1.5359 (1.4003) teacher_loss 0.5247 (0.3461) loss_zs_kd 0.0144 (0.0180) loss_oracle 0.3557 (0.3979) kd_loss 0.8262 (0.8462) acc 87.5000 (87.6562) gate/entropy 1.0205 (1.0206) gate/usage_max 0.4247 (0.4249) gate/usage_min 0.1586 (0.1587) gate/usage_std 0.1236 (0.1236) teacher/entropy 0.0476 (0.0339) teacher/usage_max 0.9319 (0.9134) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.4241 (0.4120) nleep/row_max_mean 1535.4272 (1536.6862) nleep/row_max_std 43.4593 (52.6919) nleep/row_min_mean 1500.8574 (1499.6926) lr 1.1874e-03 eta 0:09:06
epoch [24/50] batch [60/181] time 0.093 (0.114) data 0.000 (0.006) loss 1.4873 (1.3911) teacher_loss 0.5164 (0.3441) loss_zs_kd 0.0235 (0.0181) loss_oracle 0.4002 (0.3909) kd_loss 0.7591 (0.8426) acc 81.2500 (87.7083) gate/entropy 1.0203 (1.0205) gate/usage_max 0.4245 (0.4248) gate/usage_min 0.1584 (0.1586) gate/usage_std 0.1237 (0.1236) teacher/entropy 0.1206 (0.0363) teacher/usage_max 0.8845 (0.9165) teacher/usage_min 0.0075 (0.0040) teacher/usage_std 0.3919 (0.4141) nleep/row_max_mean 1539.2878 (1536.5403) nleep/row_max_std 40.0998 (50.7836) nleep/row_min_mean 1500.9315 (1499.2471) lr 1.1874e-03 eta 0:09:07
epoch [24/50] batch [80/181] time 0.068 (0.114) data 0.000 (0.005) loss 1.3178 (1.3871) teacher_loss 0.2725 (0.3415) loss_zs_kd 0.0339 (0.0184) loss_oracle 0.3734 (0.3855) kd_loss 0.8416 (0.8436) acc 93.7500 (87.9688) gate/entropy 1.0204 (1.0205) gate/usage_max 0.4244 (0.4247) gate/usage_min 0.1584 (0.1586) gate/usage_std 0.1237 (0.1236) teacher/entropy 0.0338 (0.0364) teacher/usage_max 0.9304 (0.9173) teacher/usage_min 0.0027 (0.0054) teacher/usage_std 0.4230 (0.4144) nleep/row_max_mean 1543.6615 (1535.0543) nleep/row_max_std 47.2277 (50.9685) nleep/row_min_mean 1503.5942 (1497.7778) lr 1.1874e-03 eta 0:09:10
epoch [24/50] batch [100/181] time 0.074 (0.114) data 0.000 (0.004) loss 1.1511 (1.3898) teacher_loss 0.1463 (0.3479) loss_zs_kd 0.0070 (0.0189) loss_oracle 0.3449 (0.3791) kd_loss 0.8289 (0.8429) acc 93.7500 (87.5625) gate/entropy 1.0202 (1.0205) gate/usage_max 0.4242 (0.4246) gate/usage_min 0.1583 (0.1585) gate/usage_std 0.1238 (0.1236) teacher/entropy 0.0442 (0.0362) teacher/usage_max 0.9763 (0.9236) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4547 (0.4187) nleep/row_max_mean 1538.2958 (1534.2333) nleep/row_max_std 61.8823 (51.9288) nleep/row_min_mean 1499.2739 (1496.9069) lr 1.1874e-03 eta 0:09:05
epoch [24/50] batch [120/181] time 0.164 (0.119) data 0.000 (0.003) loss 1.4072 (1.3806) teacher_loss 0.4129 (0.3390) loss_zs_kd 0.0294 (0.0186) loss_oracle 0.2927 (0.3770) kd_loss 0.8333 (0.8438) acc 87.5000 (87.8906) gate/entropy 1.0202 (1.0204) gate/usage_max 0.4241 (0.4245) gate/usage_min 0.1583 (0.1585) gate/usage_std 0.1238 (0.1237) teacher/entropy 0.0395 (0.0359) teacher/usage_max 0.9725 (0.9216) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4521 (0.4174) nleep/row_max_mean 1534.3433 (1533.7904) nleep/row_max_std 64.7287 (52.3847) nleep/row_min_mean 1496.2896 (1496.4800) lr 1.1874e-03 eta 0:09:26
epoch [24/50] batch [140/181] time 0.137 (0.123) data 0.000 (0.003) loss 1.2965 (1.3835) teacher_loss 0.2756 (0.3444) loss_zs_kd 0.0046 (0.0182) loss_oracle 0.3376 (0.3724) kd_loss 0.8498 (0.8438) acc 87.5000 (87.6562) gate/entropy 1.0201 (1.0204) gate/usage_max 0.4239 (0.4245) gate/usage_min 0.1582 (0.1585) gate/usage_std 0.1239 (0.1237) teacher/entropy 0.0219 (0.0349) teacher/usage_max 0.9402 (0.9250) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.4298 (0.4197) nleep/row_max_mean 1540.1743 (1533.5843) nleep/row_max_std 51.0174 (52.7686) nleep/row_min_mean 1502.8276 (1496.2674) lr 1.1874e-03 eta 0:09:45
epoch [24/50] batch [160/181] time 0.140 (0.127) data 0.000 (0.002) loss 1.3834 (1.3791) teacher_loss 0.3553 (0.3389) loss_zs_kd 0.0174 (0.0178) loss_oracle 0.4425 (0.3743) kd_loss 0.7982 (0.8443) acc 87.5000 (87.8711) gate/entropy 1.0202 (1.0204) gate/usage_max 0.4239 (0.4244) gate/usage_min 0.1582 (0.1584) gate/usage_std 0.1238 (0.1237) teacher/entropy 0.0740 (0.0341) teacher/usage_max 0.9721 (0.9292) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.4518 (0.4226) nleep/row_max_mean 1528.2644 (1533.0517) nleep/row_max_std 45.8521 (53.2073) nleep/row_min_mean 1491.6945 (1495.7494) lr 1.1874e-03 eta 0:10:01
epoch [24/50] batch [180/181] time 0.123 (0.128) data 0.000 (0.002) loss 1.4696 (1.3858) teacher_loss 0.3910 (0.3406) loss_zs_kd 0.0248 (0.0182) loss_oracle 0.4163 (0.3822) kd_loss 0.8581 (0.8451) acc 87.5000 (87.7951) gate/entropy 1.0200 (1.0203) gate/usage_max 0.4236 (0.4243) gate/usage_min 0.1580 (0.1584) gate/usage_std 0.1240 (0.1237) teacher/entropy 0.0129 (0.0331) teacher/usage_max 0.9675 (0.9321) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4486 (0.4245) nleep/row_max_mean 1546.2388 (1533.2920) nleep/row_max_std 57.1802 (53.0931) nleep/row_min_mean 1506.1643 (1495.9018) lr 1.1874e-03 eta 0:10:03
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,403
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [25/50] batch [20/181] time 0.133 (0.163) data 0.000 (0.017) loss 1.2850 (1.4533) teacher_loss 0.2248 (0.3892) loss_zs_kd 0.0133 (0.0204) loss_oracle 0.3758 (0.4107) kd_loss 0.8657 (0.8485) acc 93.7500 (85.6250) gate/entropy 1.0201 (1.0200) gate/usage_max 0.4236 (0.4236) gate/usage_min 0.1581 (0.1581) gate/usage_std 0.1239 (0.1239) teacher/entropy 0.0324 (0.0276) teacher/usage_max 0.9390 (0.9547) teacher/usage_min 0.0276 (0.0037) teacher/usage_std 0.4283 (0.4398) nleep/row_max_mean 1545.6848 (1537.2421) nleep/row_max_std 58.9944 (54.0548) nleep/row_min_mean 1508.2117 (1498.5190) lr 1.1253e-03 eta 0:12:43
epoch [25/50] batch [40/181] time 0.163 (0.156) data 0.000 (0.008) loss 1.1840 (1.4098) teacher_loss 0.1263 (0.3477) loss_zs_kd 0.0234 (0.0201) loss_oracle 0.3919 (0.4070) kd_loss 0.8501 (0.8486) acc 93.7500 (87.1875) gate/entropy 1.0201 (1.0200) gate/usage_max 0.4235 (0.4236) gate/usage_min 0.1581 (0.1581) gate/usage_std 0.1239 (0.1240) teacher/entropy 0.0210 (0.0286) teacher/usage_max 0.9626 (0.9517) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4452 (0.4377) nleep/row_max_mean 1532.2744 (1540.4198) nleep/row_max_std 52.0123 (52.2165) nleep/row_min_mean 1491.6348 (1501.5773) lr 1.1253e-03 eta 0:12:06
epoch [25/50] batch [60/181] time 0.096 (0.143) data 0.001 (0.006) loss 1.6605 (1.3922) teacher_loss 0.5911 (0.3300) loss_zs_kd 0.0361 (0.0197) loss_oracle 0.4564 (0.4116) kd_loss 0.8232 (0.8465) acc 78.1250 (88.0208) gate/entropy 1.0199 (1.0200) gate/usage_max 0.4234 (0.4235) gate/usage_min 0.1580 (0.1580) gate/usage_std 0.1240 (0.1240) teacher/entropy 0.0473 (0.0312) teacher/usage_max 0.9384 (0.9439) teacher/usage_min 0.0005 (0.0062) teacher/usage_std 0.4286 (0.4323) nleep/row_max_mean 1536.1533 (1539.5059) nleep/row_max_std 51.1120 (51.4901) nleep/row_min_mean 1500.8938 (1501.4107) lr 1.1253e-03 eta 0:11:04
epoch [25/50] batch [80/181] time 0.066 (0.138) data 0.000 (0.004) loss 1.4103 (1.3864) teacher_loss 0.3552 (0.3211) loss_zs_kd 0.0197 (0.0201) loss_oracle 0.4331 (0.4194) kd_loss 0.8287 (0.8456) acc 84.3750 (88.2031) gate/entropy 1.0198 (1.0200) gate/usage_max 0.4232 (0.4235) gate/usage_min 0.1578 (0.1580) gate/usage_std 0.1241 (0.1240) teacher/entropy 0.0403 (0.0335) teacher/usage_max 0.9185 (0.9342) teacher/usage_min 0.0000 (0.0081) teacher/usage_std 0.4151 (0.4257) nleep/row_max_mean 1564.2069 (1539.8291) nleep/row_max_std 50.9864 (52.1489) nleep/row_min_mean 1523.3414 (1501.9225) lr 1.1253e-03 eta 0:10:37
epoch [25/50] batch [100/181] time 0.093 (0.131) data 0.000 (0.003) loss 1.3772 (1.3870) teacher_loss 0.3394 (0.3219) loss_zs_kd 0.0361 (0.0204) loss_oracle 0.3554 (0.4198) kd_loss 0.8421 (0.8450) acc 84.3750 (88.0938) gate/entropy 1.0197 (1.0200) gate/usage_max 0.4231 (0.4234) gate/usage_min 0.1578 (0.1580) gate/usage_std 0.1241 (0.1240) teacher/entropy 0.0263 (0.0343) teacher/usage_max 0.8766 (0.9293) teacher/usage_min 0.0000 (0.0084) teacher/usage_std 0.3874 (0.4224) nleep/row_max_mean 1553.2738 (1539.1068) nleep/row_max_std 52.9731 (52.8673) nleep/row_min_mean 1515.7850 (1501.4230) lr 1.1253e-03 eta 0:10:03
epoch [25/50] batch [120/181] time 0.182 (0.128) data 0.000 (0.003) loss 1.3591 (1.3951) teacher_loss 0.3823 (0.3345) loss_zs_kd 0.0108 (0.0200) loss_oracle 0.2795 (0.4130) kd_loss 0.8317 (0.8442) acc 87.5000 (87.7604) gate/entropy 1.0197 (1.0199) gate/usage_max 0.4230 (0.4234) gate/usage_min 0.1578 (0.1580) gate/usage_std 0.1242 (0.1240) teacher/entropy 0.0376 (0.0343) teacher/usage_max 0.9851 (0.9303) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.4609 (0.4230) nleep/row_max_mean 1547.3960 (1539.1091) nleep/row_max_std 53.0281 (53.1474) nleep/row_min_mean 1508.7855 (1501.3878) lr 1.1253e-03 eta 0:09:47
epoch [25/50] batch [140/181] time 0.071 (0.127) data 0.000 (0.003) loss 1.5068 (1.3903) teacher_loss 0.4343 (0.3342) loss_zs_kd 0.0086 (0.0199) loss_oracle 0.4287 (0.4053) kd_loss 0.8539 (0.8436) acc 84.3750 (87.7902) gate/entropy 1.0198 (1.0199) gate/usage_max 0.4230 (0.4233) gate/usage_min 0.1578 (0.1580) gate/usage_std 0.1241 (0.1240) teacher/entropy 0.0337 (0.0338) teacher/usage_max 0.8879 (0.9306) teacher/usage_min 0.0195 (0.0070) teacher/usage_std 0.3933 (0.4233) nleep/row_max_mean 1539.6506 (1538.9400) nleep/row_max_std 60.2625 (52.8029) nleep/row_min_mean 1500.1497 (1501.1919) lr 1.1253e-03 eta 0:09:40
epoch [25/50] batch [160/181] time 0.127 (0.125) data 0.000 (0.002) loss 1.2515 (1.3915) teacher_loss 0.2223 (0.3362) loss_zs_kd 0.0097 (0.0195) loss_oracle 0.4266 (0.4041) kd_loss 0.8111 (0.8435) acc 90.6250 (87.6367) gate/entropy 1.0198 (1.0199) gate/usage_max 0.4230 (0.4233) gate/usage_min 0.1579 (0.1579) gate/usage_std 0.1241 (0.1240) teacher/entropy 0.0577 (0.0332) teacher/usage_max 0.9187 (0.9322) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.4153 (0.4244) nleep/row_max_mean 1534.4661 (1539.6369) nleep/row_max_std 49.8908 (52.5403) nleep/row_min_mean 1495.8630 (1501.6909) lr 1.1253e-03 eta 0:09:27
epoch [25/50] batch [180/181] time 0.073 (0.124) data 0.000 (0.002) loss 1.3923 (1.3868) teacher_loss 0.3527 (0.3313) loss_zs_kd 0.0077 (0.0191) loss_oracle 0.3737 (0.4036) kd_loss 0.8489 (0.8442) acc 84.3750 (87.7951) gate/entropy 1.0198 (1.0199) gate/usage_max 0.4229 (0.4232) gate/usage_min 0.1578 (0.1579) gate/usage_std 0.1241 (0.1241) teacher/entropy 0.0201 (0.0326) teacher/usage_max 0.9788 (0.9326) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.4565 (0.4247) nleep/row_max_mean 1534.7810 (1540.0743) nleep/row_max_std 55.2532 (52.3378) nleep/row_min_mean 1494.5360 (1501.8588) lr 1.1253e-03 eta 0:09:19
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,403
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [26/50] batch [20/181] time 0.155 (0.175) data 0.000 (0.016) loss 1.5046 (1.3797) teacher_loss 0.5039 (0.3362) loss_zs_kd 0.0242 (0.0168) loss_oracle 0.2974 (0.3657) kd_loss 0.8399 (0.8522) acc 81.2500 (87.1875) gate/entropy 1.0196 (1.0197) gate/usage_max 0.4227 (0.4228) gate/usage_min 0.1576 (0.1577) gate/usage_std 0.1243 (0.1242) teacher/entropy 0.0282 (0.0198) teacher/usage_max 0.9782 (0.9641) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4560 (0.4464) nleep/row_max_mean 1547.8461 (1545.8158) nleep/row_max_std 56.6803 (49.4567) nleep/row_min_mean 1505.3164 (1505.5861) lr 1.0628e-03 eta 0:13:07
epoch [26/50] batch [40/181] time 0.139 (0.165) data 0.000 (0.008) loss 1.1812 (1.3898) teacher_loss 0.1847 (0.3438) loss_zs_kd 0.0099 (0.0163) loss_oracle 0.3414 (0.3750) kd_loss 0.8208 (0.8503) acc 93.7500 (86.4062) gate/entropy 1.0196 (1.0197) gate/usage_max 0.4227 (0.4228) gate/usage_min 0.1577 (0.1577) gate/usage_std 0.1242 (0.1242) teacher/entropy 0.0522 (0.0233) teacher/usage_max 0.8900 (0.9539) teacher/usage_min 0.0054 (0.0055) teacher/usage_std 0.3957 (0.4393) nleep/row_max_mean 1558.1462 (1545.7948) nleep/row_max_std 53.5824 (51.4636) nleep/row_min_mean 1517.5342 (1505.6176) lr 1.0628e-03 eta 0:12:19
epoch [26/50] batch [60/181] time 0.149 (0.159) data 0.001 (0.006) loss 1.2587 (1.3929) teacher_loss 0.2554 (0.3517) loss_zs_kd 0.0099 (0.0169) loss_oracle 0.3386 (0.3694) kd_loss 0.8291 (0.8481) acc 90.6250 (86.3021) gate/entropy 1.0196 (1.0197) gate/usage_max 0.4227 (0.4227) gate/usage_min 0.1577 (0.1577) gate/usage_std 0.1242 (0.1242) teacher/entropy 0.0436 (0.0251) teacher/usage_max 0.9273 (0.9492) teacher/usage_min 0.0050 (0.0051) teacher/usage_std 0.4208 (0.4361) nleep/row_max_mean 1551.0178 (1545.4042) nleep/row_max_std 47.0715 (51.3853) nleep/row_min_mean 1514.0299 (1505.3548) lr 1.0628e-03 eta 0:11:49
epoch [26/50] batch [80/181] time 0.192 (0.159) data 0.000 (0.004) loss 1.4012 (1.3799) teacher_loss 0.3417 (0.3381) loss_zs_kd 0.0237 (0.0174) loss_oracle 0.3550 (0.3656) kd_loss 0.8702 (0.8502) acc 90.6250 (87.1484) gate/entropy 1.0197 (1.0197) gate/usage_max 0.4226 (0.4227) gate/usage_min 0.1577 (0.1577) gate/usage_std 0.1242 (0.1242) teacher/entropy 0.0283 (0.0235) teacher/usage_max 0.9248 (0.9449) teacher/usage_min 0.0311 (0.0054) teacher/usage_std 0.4183 (0.4332) nleep/row_max_mean 1519.2216 (1544.4280) nleep/row_max_std 52.1517 (51.6741) nleep/row_min_mean 1487.2329 (1504.9995) lr 1.0628e-03 eta 0:11:48
epoch [26/50] batch [100/181] time 0.159 (0.159) data 0.000 (0.003) loss 1.1850 (1.3889) teacher_loss 0.1565 (0.3477) loss_zs_kd 0.0102 (0.0188) loss_oracle 0.3419 (0.3662) kd_loss 0.8524 (0.8487) acc 93.7500 (86.8125) gate/entropy 1.0196 (1.0196) gate/usage_max 0.4225 (0.4227) gate/usage_min 0.1576 (0.1577) gate/usage_std 0.1243 (0.1242) teacher/entropy 0.0154 (0.0257) teacher/usage_max 0.9949 (0.9432) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.4678 (0.4320) nleep/row_max_mean 1543.1639 (1544.2576) nleep/row_max_std 56.9616 (51.8381) nleep/row_min_mean 1504.4907 (1505.1767) lr 1.0628e-03 eta 0:11:41
epoch [26/50] batch [120/181] time 0.171 (0.157) data 0.000 (0.003) loss 1.2417 (1.3795) teacher_loss 0.2274 (0.3382) loss_zs_kd 0.0214 (0.0192) loss_oracle 0.3727 (0.3663) kd_loss 0.8172 (0.8485) acc 90.6250 (87.2135) gate/entropy 1.0195 (1.0196) gate/usage_max 0.4225 (0.4227) gate/usage_min 0.1575 (0.1577) gate/usage_std 0.1243 (0.1242) teacher/entropy 0.0502 (0.0264) teacher/usage_max 0.9736 (0.9389) teacher/usage_min 0.0000 (0.0064) teacher/usage_std 0.4528 (0.4290) nleep/row_max_mean 1551.0947 (1543.7927) nleep/row_max_std 54.8165 (51.6824) nleep/row_min_mean 1515.0374 (1505.2583) lr 1.0628e-03 eta 0:11:33
epoch [26/50] batch [140/181] time 0.163 (0.158) data 0.000 (0.002) loss 1.5156 (1.3801) teacher_loss 0.4350 (0.3408) loss_zs_kd 0.0423 (0.0196) loss_oracle 0.4284 (0.3655) kd_loss 0.8452 (0.8467) acc 87.5000 (87.2098) gate/entropy 1.0195 (1.0196) gate/usage_max 0.4224 (0.4226) gate/usage_min 0.1575 (0.1576) gate/usage_std 0.1243 (0.1242) teacher/entropy 0.0219 (0.0283) teacher/usage_max 0.9623 (0.9332) teacher/usage_min 0.0000 (0.0063) teacher/usage_std 0.4450 (0.4252) nleep/row_max_mean 1547.3840 (1544.4275) nleep/row_max_std 44.5187 (51.2539) nleep/row_min_mean 1512.9187 (1506.3349) lr 1.0628e-03 eta 0:11:32
epoch [26/50] batch [160/181] time 0.089 (0.155) data 0.000 (0.002) loss 1.2132 (1.3720) teacher_loss 0.2721 (0.3358) loss_zs_kd 0.0119 (0.0193) loss_oracle 0.3692 (0.3664) kd_loss 0.7506 (0.8434) acc 90.6250 (87.4219) gate/entropy 1.0195 (1.0196) gate/usage_max 0.4224 (0.4226) gate/usage_min 0.1575 (0.1576) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.1213 (0.0324) teacher/usage_max 0.7948 (0.9261) teacher/usage_min 0.0059 (0.0070) teacher/usage_std 0.3357 (0.4204) nleep/row_max_mean 1540.0833 (1543.5810) nleep/row_max_std 57.6249 (51.1081) nleep/row_min_mean 1505.0510 (1506.0672) lr 1.0628e-03 eta 0:11:14
epoch [26/50] batch [180/181] time 0.166 (0.150) data 0.000 (0.002) loss 1.1984 (1.3649) teacher_loss 0.2003 (0.3303) loss_zs_kd 0.0050 (0.0190) loss_oracle 0.3379 (0.3680) kd_loss 0.8265 (0.8411) acc 93.7500 (87.6215) gate/entropy 1.0195 (1.0196) gate/usage_max 0.4223 (0.4226) gate/usage_min 0.1575 (0.1576) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.0420 (0.0344) teacher/usage_max 0.8714 (0.9203) teacher/usage_min 0.0021 (0.0069) teacher/usage_std 0.3839 (0.4166) nleep/row_max_mean 1546.9380 (1542.7414) nleep/row_max_std 53.6043 (50.8742) nleep/row_min_mean 1514.5745 (1505.7971) lr 1.0628e-03 eta 0:10:50
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,406
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [27/50] batch [20/181] time 0.187 (0.133) data 0.000 (0.016) loss 1.2987 (1.3241) teacher_loss 0.3339 (0.2958) loss_zs_kd 0.0074 (0.0217) loss_oracle 0.3509 (0.3737) kd_loss 0.7856 (0.8307) acc 84.3750 (88.5938) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.0803 (0.0473) teacher/usage_max 0.8002 (0.9032) teacher/usage_min 0.0000 (0.0092) teacher/usage_std 0.3400 (0.4050) nleep/row_max_mean 1540.3505 (1539.3123) nleep/row_max_std 45.4334 (47.4521) nleep/row_min_mean 1505.9037 (1505.8606) lr 1.0000e-03 eta 0:09:34
epoch [27/50] batch [40/181] time 0.091 (0.125) data 0.000 (0.008) loss 1.4846 (1.3445) teacher_loss 0.4701 (0.3177) loss_zs_kd 0.0119 (0.0204) loss_oracle 0.4368 (0.3787) kd_loss 0.7901 (0.8273) acc 84.3750 (87.9688) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.0762 (0.0509) teacher/usage_max 0.8641 (0.8925) teacher/usage_min 0.0000 (0.0103) teacher/usage_std 0.3794 (0.3979) nleep/row_max_mean 1536.7681 (1540.1052) nleep/row_max_std 39.2392 (46.4105) nleep/row_min_mean 1505.3066 (1506.8558) lr 1.0000e-03 eta 0:09:00
epoch [27/50] batch [60/181] time 0.087 (0.124) data 0.000 (0.006) loss 1.3927 (1.3492) teacher_loss 0.3803 (0.3193) loss_zs_kd 0.0170 (0.0202) loss_oracle 0.3895 (0.3896) kd_loss 0.8091 (0.8250) acc 84.3750 (88.1250) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.0573 (0.0536) teacher/usage_max 0.9230 (0.8913) teacher/usage_min 0.0000 (0.0110) teacher/usage_std 0.4182 (0.3969) nleep/row_max_mean 1545.9658 (1542.4530) nleep/row_max_std 49.8379 (46.3688) nleep/row_min_mean 1511.4021 (1508.8426) lr 1.0000e-03 eta 0:08:50
epoch [27/50] batch [80/181] time 0.167 (0.124) data 0.000 (0.004) loss 1.3162 (1.3520) teacher_loss 0.3397 (0.3231) loss_zs_kd 0.0117 (0.0197) loss_oracle 0.3788 (0.3850) kd_loss 0.7813 (0.8265) acc 87.5000 (88.1641) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1243) teacher/entropy 0.0846 (0.0526) teacher/usage_max 0.8572 (0.8965) teacher/usage_min 0.0000 (0.0108) teacher/usage_std 0.3750 (0.4004) nleep/row_max_mean 1551.7651 (1542.0621) nleep/row_max_std 45.1335 (46.9873) nleep/row_min_mean 1516.0781 (1508.3957) lr 1.0000e-03 eta 0:08:50
epoch [27/50] batch [100/181] time 0.158 (0.130) data 0.000 (0.003) loss 1.2870 (1.3578) teacher_loss 0.2088 (0.3299) loss_zs_kd 0.0140 (0.0194) loss_oracle 0.4171 (0.3829) kd_loss 0.8627 (0.8267) acc 93.7500 (88.0625) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4221 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0343 (0.0518) teacher/usage_max 0.8964 (0.8986) teacher/usage_min 0.0313 (0.0105) teacher/usage_std 0.3985 (0.4017) nleep/row_max_mean 1532.6180 (1541.8023) nleep/row_max_std 54.9741 (47.7636) nleep/row_min_mean 1498.7214 (1507.9563) lr 1.0000e-03 eta 0:09:13
epoch [27/50] batch [120/181] time 0.160 (0.134) data 0.000 (0.003) loss 1.1482 (1.3452) teacher_loss 0.1984 (0.3206) loss_zs_kd 0.0069 (0.0186) loss_oracle 0.2855 (0.3810) kd_loss 0.8036 (0.8248) acc 93.7500 (88.2031) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4221 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0624 (0.0524) teacher/usage_max 0.9224 (0.8985) teacher/usage_min 0.0000 (0.0097) teacher/usage_std 0.4178 (0.4017) nleep/row_max_mean 1539.8887 (1541.9871) nleep/row_max_std 45.4437 (48.3161) nleep/row_min_mean 1507.5238 (1508.0682) lr 1.0000e-03 eta 0:09:25
epoch [27/50] batch [140/181] time 0.162 (0.136) data 0.000 (0.003) loss 1.4028 (1.3464) teacher_loss 0.3847 (0.3228) loss_zs_kd 0.0099 (0.0180) loss_oracle 0.3881 (0.3793) kd_loss 0.8191 (0.8249) acc 84.3750 (88.1696) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4221 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0468 (0.0522) teacher/usage_max 0.8608 (0.8996) teacher/usage_min 0.0000 (0.0095) teacher/usage_std 0.3773 (0.4024) nleep/row_max_mean 1539.6604 (1542.0404) nleep/row_max_std 59.8646 (49.2609) nleep/row_min_mean 1505.6885 (1508.1502) lr 1.0000e-03 eta 0:09:33
epoch [27/50] batch [160/181] time 0.156 (0.138) data 0.000 (0.002) loss 1.4519 (1.3370) teacher_loss 0.4504 (0.3167) loss_zs_kd 0.0177 (0.0176) loss_oracle 0.3074 (0.3767) kd_loss 0.8389 (0.8231) acc 84.3750 (88.4570) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4220 (0.4222) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0270 (0.0540) teacher/usage_max 0.9573 (0.8988) teacher/usage_min 0.0001 (0.0097) teacher/usage_std 0.4415 (0.4019) nleep/row_max_mean 1554.0283 (1541.7453) nleep/row_max_std 49.0305 (49.8999) nleep/row_min_mean 1522.1882 (1508.0261) lr 1.0000e-03 eta 0:09:38
epoch [27/50] batch [180/181] time 0.144 (0.140) data 0.000 (0.002) loss 1.1523 (1.3335) teacher_loss 0.1610 (0.3140) loss_zs_kd 0.0285 (0.0180) loss_oracle 0.4291 (0.3783) kd_loss 0.7625 (0.8213) acc 93.7500 (88.5417) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1035 (0.0561) teacher/usage_max 0.8914 (0.8909) teacher/usage_min 0.0000 (0.0102) teacher/usage_std 0.3971 (0.3968) nleep/row_max_mean 1508.6830 (1541.0731) nleep/row_max_std 60.8926 (50.3925) nleep/row_min_mean 1479.8772 (1507.4660) lr 1.0000e-03 eta 0:09:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,410
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [28/50] batch [20/181] time 0.066 (0.154) data 0.000 (0.018) loss 1.4272 (1.2283) teacher_loss 0.4215 (0.2410) loss_zs_kd 0.0248 (0.0178) loss_oracle 0.4273 (0.3763) kd_loss 0.7796 (0.7903) acc 84.3750 (90.9375) gate/entropy 1.0194 (1.0193) gate/usage_max 0.4219 (0.4220) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0861 (0.0845) teacher/usage_max 0.7691 (0.8434) teacher/usage_min 0.0006 (0.0095) teacher/usage_std 0.3221 (0.3668) nleep/row_max_mean 1542.8655 (1538.3555) nleep/row_max_std 50.6798 (53.0257) nleep/row_min_mean 1509.2372 (1505.9134) lr 9.3721e-04 eta 0:10:36
epoch [28/50] batch [40/181] time 0.181 (0.126) data 0.000 (0.009) loss 1.2068 (1.2530) teacher_loss 0.2425 (0.2631) loss_zs_kd 0.0182 (0.0186) loss_oracle 0.3200 (0.3794) kd_loss 0.7952 (0.7909) acc 90.6250 (90.4688) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0726 (0.0851) teacher/usage_max 0.9189 (0.8378) teacher/usage_min 0.0024 (0.0109) teacher/usage_std 0.4152 (0.3627) nleep/row_max_mean 1539.1829 (1538.2149) nleep/row_max_std 57.6738 (52.2620) nleep/row_min_mean 1506.3719 (1505.9366) lr 9.3721e-04 eta 0:08:38
epoch [28/50] batch [60/181] time 0.122 (0.118) data 0.000 (0.006) loss 1.3354 (1.2614) teacher_loss 0.3164 (0.2619) loss_zs_kd 0.0282 (0.0197) loss_oracle 0.4452 (0.4018) kd_loss 0.7822 (0.7887) acc 90.6250 (90.5729) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0828 (0.0868) teacher/usage_max 0.8094 (0.8327) teacher/usage_min 0.0000 (0.0104) teacher/usage_std 0.3455 (0.3593) nleep/row_max_mean 1537.5723 (1537.6445) nleep/row_max_std 41.5751 (51.6852) nleep/row_min_mean 1506.0222 (1505.5702) lr 9.3721e-04 eta 0:08:05
epoch [28/50] batch [80/181] time 0.151 (0.119) data 0.000 (0.005) loss 1.3632 (1.2703) teacher_loss 0.2720 (0.2663) loss_zs_kd 0.0173 (0.0200) loss_oracle 0.4941 (0.4116) kd_loss 0.8355 (0.7882) acc 87.5000 (90.5078) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0602 (0.0892) teacher/usage_max 0.7502 (0.8177) teacher/usage_min 0.0313 (0.0123) teacher/usage_std 0.3045 (0.3505) nleep/row_max_mean 1527.4146 (1536.7091) nleep/row_max_std 45.8292 (51.7432) nleep/row_min_mean 1498.2958 (1504.8847) lr 9.3721e-04 eta 0:08:06
epoch [28/50] batch [100/181] time 0.194 (0.118) data 0.000 (0.004) loss 1.4979 (1.2681) teacher_loss 0.4833 (0.2673) loss_zs_kd 0.0360 (0.0205) loss_oracle 0.4170 (0.4118) kd_loss 0.7881 (0.7847) acc 87.5000 (90.6875) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4218 (0.4219) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.1398 (0.0934) teacher/usage_max 0.7124 (0.8107) teacher/usage_min 0.0640 (0.0132) teacher/usage_std 0.2759 (0.3461) nleep/row_max_mean 1534.0947 (1536.3045) nleep/row_max_std 64.8982 (51.8281) nleep/row_min_mean 1502.2777 (1504.7741) lr 9.3721e-04 eta 0:08:00
epoch [28/50] batch [120/181] time 0.082 (0.116) data 0.000 (0.003) loss 1.2980 (1.2735) teacher_loss 0.3301 (0.2746) loss_zs_kd 0.0269 (0.0211) loss_oracle 0.4230 (0.4100) kd_loss 0.7430 (0.7835) acc 84.3750 (90.5469) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4218 (0.4219) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1220 (0.0940) teacher/usage_max 0.7626 (0.8087) teacher/usage_min 0.0000 (0.0125) teacher/usage_std 0.3186 (0.3450) nleep/row_max_mean 1535.1882 (1536.3446) nleep/row_max_std 38.6530 (51.5782) nleep/row_min_mean 1505.0331 (1505.0544) lr 9.3721e-04 eta 0:07:49
epoch [28/50] batch [140/181] time 0.188 (0.115) data 0.000 (0.003) loss 1.1646 (1.2722) teacher_loss 0.1412 (0.2730) loss_zs_kd 0.0158 (0.0221) loss_oracle 0.3968 (0.4094) kd_loss 0.8171 (0.7835) acc 96.8750 (90.7366) gate/entropy 1.0194 (1.0193) gate/usage_max 0.4218 (0.4219) gate/usage_min 0.1574 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.0479 (0.0942) teacher/usage_max 0.7348 (0.8023) teacher/usage_min 0.0001 (0.0129) teacher/usage_std 0.3038 (0.3412) nleep/row_max_mean 1531.9728 (1535.8082) nleep/row_max_std 59.0163 (51.8776) nleep/row_min_mean 1502.6331 (1504.6895) lr 9.3721e-04 eta 0:07:42
epoch [28/50] batch [160/181] time 0.093 (0.115) data 0.000 (0.002) loss 1.2209 (1.2755) teacher_loss 0.2433 (0.2774) loss_zs_kd 0.0162 (0.0227) loss_oracle 0.4409 (0.4072) kd_loss 0.7490 (0.7831) acc 90.6250 (90.4492) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4218 (0.4219) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1177 (0.0947) teacher/usage_max 0.7914 (0.7979) teacher/usage_min 0.0018 (0.0130) teacher/usage_std 0.3345 (0.3385) nleep/row_max_mean 1531.6769 (1535.9881) nleep/row_max_std 54.5299 (52.1396) nleep/row_min_mean 1501.9935 (1504.7655) lr 9.3721e-04 eta 0:07:41
epoch [28/50] batch [180/181] time 0.073 (0.115) data 0.000 (0.002) loss 1.3339 (1.2732) teacher_loss 0.3888 (0.2766) loss_zs_kd 0.0162 (0.0226) loss_oracle 0.3525 (0.4039) kd_loss 0.7608 (0.7834) acc 84.3750 (90.5556) gate/entropy 1.0192 (1.0193) gate/usage_max 0.4217 (0.4218) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1041 (0.0949) teacher/usage_max 0.8934 (0.7987) teacher/usage_min 0.0000 (0.0133) teacher/usage_std 0.3984 (0.3389) nleep/row_max_mean 1542.2373 (1536.7793) nleep/row_max_std 36.3771 (52.2048) nleep/row_min_mean 1511.0848 (1505.4015) lr 9.3721e-04 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,410
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [29/50] batch [20/181] time 0.154 (0.167) data 0.000 (0.014) loss 1.3034 (1.2430) teacher_loss 0.2530 (0.2592) loss_zs_kd 0.0192 (0.0314) loss_oracle 0.4118 (0.3928) kd_loss 0.8349 (0.7717) acc 90.6250 (91.0938) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0606 (0.1123) teacher/usage_max 0.7812 (0.7372) teacher/usage_min 0.0313 (0.0196) teacher/usage_std 0.3230 (0.3025) nleep/row_max_mean 1536.4689 (1533.8349) nleep/row_max_std 56.6972 (57.6611) nleep/row_min_mean 1505.6050 (1502.0615) lr 8.7467e-04 eta 0:11:00
epoch [29/50] batch [40/181] time 0.130 (0.155) data 0.001 (0.007) loss 1.2619 (1.2526) teacher_loss 0.3289 (0.2690) loss_zs_kd 0.0432 (0.0304) loss_oracle 0.4365 (0.4059) kd_loss 0.6930 (0.7655) acc 90.6250 (90.1562) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1571 (0.1573) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.1713 (0.1127) teacher/usage_max 0.6182 (0.7436) teacher/usage_min 0.0000 (0.0138) teacher/usage_std 0.2547 (0.3078) nleep/row_max_mean 1554.5654 (1534.9075) nleep/row_max_std 48.7494 (57.4364) nleep/row_min_mean 1520.8735 (1502.8392) lr 8.7467e-04 eta 0:10:10
epoch [29/50] batch [60/181] time 0.154 (0.153) data 0.000 (0.005) loss 1.3015 (1.2422) teacher_loss 0.2973 (0.2598) loss_zs_kd 0.0250 (0.0286) loss_oracle 0.4328 (0.4121) kd_loss 0.7754 (0.7621) acc 90.6250 (90.4688) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0892 (0.1146) teacher/usage_max 0.7482 (0.7402) teacher/usage_min 0.0000 (0.0123) teacher/usage_std 0.3108 (0.3062) nleep/row_max_mean 1531.3871 (1534.0525) nleep/row_max_std 56.5923 (56.8952) nleep/row_min_mean 1500.0747 (1502.3830) lr 8.7467e-04 eta 0:10:01
epoch [29/50] batch [80/181] time 0.170 (0.153) data 0.000 (0.004) loss 1.0060 (1.2341) teacher_loss 0.1106 (0.2617) loss_zs_kd 0.0243 (0.0270) loss_oracle 0.3678 (0.4108) kd_loss 0.6993 (0.7535) acc 100.0000 (90.5078) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1771 (0.1234) teacher/usage_max 0.7256 (0.7304) teacher/usage_min 0.0121 (0.0126) teacher/usage_std 0.2956 (0.3010) nleep/row_max_mean 1533.9406 (1533.1286) nleep/row_max_std 59.8139 (56.8928) nleep/row_min_mean 1506.7946 (1501.8556) lr 8.7467e-04 eta 0:09:58
epoch [29/50] batch [100/181] time 0.141 (0.153) data 0.000 (0.003) loss 1.2741 (1.2224) teacher_loss 0.3026 (0.2568) loss_zs_kd 0.0342 (0.0266) loss_oracle 0.4040 (0.4062) kd_loss 0.7523 (0.7492) acc 90.6250 (90.7188) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1144 (0.1277) teacher/usage_max 0.7951 (0.7231) teacher/usage_min 0.0019 (0.0125) teacher/usage_std 0.3367 (0.2978) nleep/row_max_mean 1509.6204 (1533.3086) nleep/row_max_std 60.5972 (56.5072) nleep/row_min_mean 1483.0210 (1502.2841) lr 8.7467e-04 eta 0:09:52
epoch [29/50] batch [120/181] time 0.161 (0.153) data 0.000 (0.003) loss 1.2868 (1.2238) teacher_loss 0.2688 (0.2596) loss_zs_kd 0.0461 (0.0258) loss_oracle 0.4291 (0.4042) kd_loss 0.7805 (0.7492) acc 93.7500 (90.7031) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.1452 (0.1287) teacher/usage_max 0.7344 (0.7130) teacher/usage_min 0.0623 (0.0136) teacher/usage_std 0.2894 (0.2930) nleep/row_max_mean 1538.4993 (1533.5210) nleep/row_max_std 56.2467 (55.8503) nleep/row_min_mean 1508.6924 (1502.7217) lr 8.7467e-04 eta 0:09:50
epoch [29/50] batch [140/181] time 0.071 (0.152) data 0.000 (0.002) loss 1.5727 (1.2204) teacher_loss 0.5475 (0.2604) loss_zs_kd 0.0368 (0.0252) loss_oracle 0.3995 (0.4017) kd_loss 0.8070 (0.7465) acc 81.2500 (90.5804) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.0573 (0.1310) teacher/usage_max 0.6791 (0.7028) teacher/usage_min 0.0000 (0.0131) teacher/usage_std 0.2774 (0.2891) nleep/row_max_mean 1534.5789 (1533.2775) nleep/row_max_std 43.0566 (55.6695) nleep/row_min_mean 1504.8240 (1502.9170) lr 8.7467e-04 eta 0:09:44
epoch [29/50] batch [160/181] time 0.183 (0.145) data 0.000 (0.002) loss 1.0781 (1.2205) teacher_loss 0.0948 (0.2623) loss_zs_kd 0.0136 (0.0252) loss_oracle 0.3797 (0.4002) kd_loss 0.7866 (0.7456) acc 96.8750 (90.4688) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1070 (0.1320) teacher/usage_max 0.7316 (0.6964) teacher/usage_min 0.0296 (0.0133) teacher/usage_std 0.2943 (0.2862) nleep/row_max_mean 1525.3928 (1532.6121) nleep/row_max_std 66.0359 (56.4240) nleep/row_min_mean 1498.5732 (1502.5036) lr 8.7467e-04 eta 0:09:14
epoch [29/50] batch [180/181] time 0.077 (0.142) data 0.000 (0.002) loss 1.3374 (1.2198) teacher_loss 0.2805 (0.2604) loss_zs_kd 0.0262 (0.0248) loss_oracle 0.3790 (0.4002) kd_loss 0.8543 (0.7468) acc 90.6250 (90.6250) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.0716 (0.1305) teacher/usage_max 0.7722 (0.6957) teacher/usage_min 0.0624 (0.0130) teacher/usage_std 0.3132 (0.2859) nleep/row_max_mean 1546.9312 (1532.4771) nleep/row_max_std 37.7358 (56.6849) nleep/row_min_mean 1516.4731 (1502.3577) lr 8.7467e-04 eta 0:08:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,410
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [30/50] batch [20/181] time 0.189 (0.120) data 0.000 (0.012) loss 1.2017 (1.2096) teacher_loss 0.3532 (0.2518) loss_zs_kd 0.0153 (0.0215) loss_oracle 0.3965 (0.4061) kd_loss 0.6425 (0.7440) acc 90.6250 (92.1875) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1573 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.2222 (0.1324) teacher/usage_max 0.6893 (0.6944) teacher/usage_min 0.0003 (0.0122) teacher/usage_std 0.2818 (0.2853) nleep/row_max_mean 1513.3730 (1534.3890) nleep/row_max_std 68.8969 (55.2806) nleep/row_min_mean 1486.2927 (1504.3709) lr 8.1262e-04 eta 0:07:32
epoch [30/50] batch [40/181] time 0.175 (0.124) data 0.000 (0.006) loss 1.1708 (1.2375) teacher_loss 0.1765 (0.2653) loss_zs_kd 0.0184 (0.0235) loss_oracle 0.4036 (0.4135) kd_loss 0.7832 (0.7537) acc 90.6250 (91.1719) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.1005 (0.1257) teacher/usage_max 0.7964 (0.6867) teacher/usage_min 0.0197 (0.0152) teacher/usage_std 0.3342 (0.2798) nleep/row_max_mean 1544.7115 (1535.1882) nleep/row_max_std 60.8044 (55.9738) nleep/row_min_mean 1513.9790 (1505.0810) lr 8.1262e-04 eta 0:07:45
epoch [30/50] batch [60/181] time 0.075 (0.123) data 0.001 (0.004) loss 1.1946 (1.2416) teacher_loss 0.2531 (0.2754) loss_zs_kd 0.0257 (0.0251) loss_oracle 0.3600 (0.4004) kd_loss 0.7486 (0.7535) acc 90.6250 (90.4688) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.1155 (0.1272) teacher/usage_max 0.5653 (0.6779) teacher/usage_min 0.0000 (0.0166) teacher/usage_std 0.2417 (0.2756) nleep/row_max_mean 1555.6315 (1535.9002) nleep/row_max_std 44.9159 (55.4379) nleep/row_min_mean 1521.6740 (1505.5772) lr 8.1262e-04 eta 0:07:40
epoch [30/50] batch [80/181] time 0.140 (0.123) data 0.000 (0.003) loss 1.2207 (1.2416) teacher_loss 0.2729 (0.2669) loss_zs_kd 0.0249 (0.0260) loss_oracle 0.4322 (0.3980) kd_loss 0.7193 (0.7627) acc 93.7500 (90.7031) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.1467 (0.1218) teacher/usage_max 0.6109 (0.6681) teacher/usage_min 0.0017 (0.0205) teacher/usage_std 0.2516 (0.2692) nleep/row_max_mean 1531.1807 (1536.8015) nleep/row_max_std 60.4753 (55.4861) nleep/row_min_mean 1499.5823 (1506.4624) lr 8.1262e-04 eta 0:07:38
epoch [30/50] batch [100/181] time 0.147 (0.130) data 0.000 (0.003) loss 1.2637 (1.2432) teacher_loss 0.2870 (0.2631) loss_zs_kd 0.0177 (0.0265) loss_oracle 0.3833 (0.4034) kd_loss 0.7761 (0.7652) acc 93.7500 (90.7500) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1193 (0.1214) teacher/usage_max 0.5373 (0.6490) teacher/usage_min 0.0316 (0.0227) teacher/usage_std 0.2177 (0.2607) nleep/row_max_mean 1539.3217 (1537.3757) nleep/row_max_std 47.0669 (55.2605) nleep/row_min_mean 1508.3326 (1506.9752) lr 8.1262e-04 eta 0:08:01
epoch [30/50] batch [120/181] time 0.140 (0.134) data 0.000 (0.002) loss 1.2634 (1.2395) teacher_loss 0.2697 (0.2596) loss_zs_kd 0.0289 (0.0275) loss_oracle 0.3963 (0.4034) kd_loss 0.7811 (0.7645) acc 90.6250 (90.7812) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0839 (0.1225) teacher/usage_max 0.5362 (0.6336) teacher/usage_min 0.0008 (0.0230) teacher/usage_std 0.2370 (0.2555) nleep/row_max_mean 1546.4186 (1537.1484) nleep/row_max_std 47.1483 (54.8720) nleep/row_min_mean 1516.6034 (1506.9864) lr 8.1262e-04 eta 0:08:12
epoch [30/50] batch [140/181] time 0.162 (0.137) data 0.000 (0.002) loss 1.0140 (1.2386) teacher_loss 0.0401 (0.2554) loss_zs_kd 0.0057 (0.0276) loss_oracle 0.4025 (0.4053) kd_loss 0.7699 (0.7668) acc 100.0000 (90.7589) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.1263 (0.1204) teacher/usage_max 0.6164 (0.6207) teacher/usage_min 0.0324 (0.0232) teacher/usage_std 0.2388 (0.2512) nleep/row_max_mean 1535.6506 (1536.6899) nleep/row_max_std 44.7209 (54.5867) nleep/row_min_mean 1511.6196 (1506.7925) lr 8.1262e-04 eta 0:08:20
epoch [30/50] batch [160/181] time 0.163 (0.139) data 0.000 (0.002) loss 1.1674 (1.2416) teacher_loss 0.1994 (0.2533) loss_zs_kd 0.0187 (0.0275) loss_oracle 0.3974 (0.4095) kd_loss 0.7599 (0.7697) acc 96.8750 (90.9766) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1399 (0.1195) teacher/usage_max 0.5980 (0.6101) teacher/usage_min 0.0362 (0.0254) teacher/usage_std 0.2305 (0.2467) nleep/row_max_mean 1547.3252 (1535.8907) nleep/row_max_std 42.6866 (54.2382) nleep/row_min_mean 1525.1191 (1506.3717) lr 8.1262e-04 eta 0:08:27
epoch [30/50] batch [180/181] time 0.131 (0.140) data 0.000 (0.001) loss 1.3611 (1.2423) teacher_loss 0.2921 (0.2479) loss_zs_kd 0.0406 (0.0282) loss_oracle 0.4953 (0.4156) kd_loss 0.8010 (0.7725) acc 90.6250 (91.1806) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1573 (0.1572) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.0947 (0.1174) teacher/usage_max 0.6652 (0.6053) teacher/usage_min 0.0317 (0.0260) teacher/usage_std 0.2595 (0.2446) nleep/row_max_mean 1514.2434 (1535.3105) nleep/row_max_std 57.7615 (53.9224) nleep/row_min_mean 1489.4167 (1506.1291) lr 8.1262e-04 eta 0:08:28
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,663
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      96.9%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [31/50] batch [20/181] time 0.091 (0.146) data 0.000 (0.016) loss 1.3750 (1.2427) teacher_loss 0.2709 (0.2012) loss_zs_kd 0.0447 (0.0343) loss_oracle 0.4785 (0.4563) kd_loss 0.8425 (0.7962) acc 90.6250 (92.6562) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0526 (0.0977) teacher/usage_max 0.7175 (0.5579) teacher/usage_min 0.0313 (0.0302) teacher/usage_std 0.2861 (0.2260) nleep/row_max_mean 1549.6088 (1531.8131) nleep/row_max_std 34.9959 (54.7087) nleep/row_min_mean 1519.7047 (1504.4558) lr 7.5131e-04 eta 0:08:46
epoch [31/50] batch [40/181] time 0.164 (0.135) data 0.001 (0.008) loss 1.3757 (1.2738) teacher_loss 0.2374 (0.2379) loss_zs_kd 0.0412 (0.0343) loss_oracle 0.4522 (0.4553) kd_loss 0.8916 (0.7910) acc 90.6250 (91.2500) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0762 (0.1041) teacher/usage_max 0.6074 (0.5759) teacher/usage_min 0.1049 (0.0313) teacher/usage_std 0.2077 (0.2309) nleep/row_max_mean 1526.6553 (1529.1977) nleep/row_max_std 58.2238 (56.1651) nleep/row_min_mean 1499.9958 (1502.0602) lr 7.5131e-04 eta 0:08:02
epoch [31/50] batch [60/181] time 0.085 (0.128) data 0.001 (0.005) loss 1.3259 (1.2790) teacher_loss 0.3208 (0.2404) loss_zs_kd 0.0437 (0.0352) loss_oracle 0.4281 (0.4540) kd_loss 0.7692 (0.7941) acc 87.5000 (91.0938) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4215 (0.4216) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1321 (0.1057) teacher/usage_max 0.7927 (0.6074) teacher/usage_min 0.0374 (0.0361) teacher/usage_std 0.3293 (0.2417) nleep/row_max_mean 1528.6765 (1529.5427) nleep/row_max_std 55.1499 (56.1422) nleep/row_min_mean 1501.2140 (1502.0617) lr 7.5131e-04 eta 0:07:35
epoch [31/50] batch [80/181] time 0.082 (0.127) data 0.000 (0.004) loss 1.3846 (1.2700) teacher_loss 0.2149 (0.2342) loss_zs_kd 0.0259 (0.0337) loss_oracle 0.5335 (0.4528) kd_loss 0.8901 (0.7926) acc 96.8750 (91.5234) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4215 (0.4216) gate/usage_min 0.1573 (0.1571) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.0366 (0.1071) teacher/usage_max 0.5680 (0.6257) teacher/usage_min 0.0633 (0.0360) teacher/usage_std 0.2076 (0.2488) nleep/row_max_mean 1507.6970 (1529.6699) nleep/row_max_std 79.3034 (57.3979) nleep/row_min_mean 1480.2656 (1501.4141) lr 7.5131e-04 eta 0:07:30
epoch [31/50] batch [100/181] time 0.092 (0.125) data 0.000 (0.003) loss 1.1793 (1.2689) teacher_loss 0.1203 (0.2334) loss_zs_kd 0.0155 (0.0336) loss_oracle 0.5118 (0.4551) kd_loss 0.7954 (0.7912) acc 96.8750 (91.4375) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4215 (0.4216) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.0691 (0.1058) teacher/usage_max 0.8327 (0.6474) teacher/usage_min 0.0000 (0.0333) teacher/usage_std 0.3596 (0.2592) nleep/row_max_mean 1541.9968 (1530.6731) nleep/row_max_std 51.2042 (58.0517) nleep/row_min_mean 1505.5775 (1501.5995) lr 7.5131e-04 eta 0:07:19
epoch [31/50] batch [120/181] time 0.099 (0.122) data 0.000 (0.003) loss 1.1072 (1.2733) teacher_loss 0.0733 (0.2406) loss_zs_kd 0.0102 (0.0331) loss_oracle 0.4385 (0.4508) kd_loss 0.8095 (0.7907) acc 96.8750 (91.3021) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0856 (0.1043) teacher/usage_max 0.7705 (0.6661) teacher/usage_min 0.0313 (0.0312) teacher/usage_std 0.3166 (0.2685) nleep/row_max_mean 1535.9868 (1531.9098) nleep/row_max_std 75.5375 (58.5460) nleep/row_min_mean 1503.4908 (1502.1044) lr 7.5131e-04 eta 0:07:07
epoch [31/50] batch [140/181] time 0.177 (0.121) data 0.000 (0.002) loss 1.2818 (1.2868) teacher_loss 0.1985 (0.2532) loss_zs_kd 0.0337 (0.0334) loss_oracle 0.4650 (0.4503) kd_loss 0.8339 (0.7917) acc 90.6250 (90.7366) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0610 (0.1013) teacher/usage_max 0.7810 (0.6905) teacher/usage_min 0.0313 (0.0293) teacher/usage_std 0.3230 (0.2817) nleep/row_max_mean 1552.2109 (1533.2809) nleep/row_max_std 69.7206 (58.7853) nleep/row_min_mean 1518.0662 (1502.9152) lr 7.5131e-04 eta 0:07:00
epoch [31/50] batch [160/181] time 0.187 (0.121) data 0.000 (0.002) loss 1.3557 (1.2912) teacher_loss 0.2578 (0.2568) loss_zs_kd 0.0401 (0.0333) loss_oracle 0.4150 (0.4470) kd_loss 0.8703 (0.7943) acc 93.7500 (90.7031) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0247 (0.0981) teacher/usage_max 0.8704 (0.7111) teacher/usage_min 0.0312 (0.0285) teacher/usage_std 0.3807 (0.2931) nleep/row_max_mean 1550.3745 (1534.2115) nleep/row_max_std 58.0163 (58.4554) nleep/row_min_mean 1515.2661 (1503.4792) lr 7.5131e-04 eta 0:06:57
epoch [31/50] batch [180/181] time 0.120 (0.118) data 0.000 (0.002) loss 1.3137 (1.2933) teacher_loss 0.3206 (0.2595) loss_zs_kd 0.0308 (0.0323) loss_oracle 0.3767 (0.4426) kd_loss 0.7894 (0.7962) acc 87.5000 (90.6424) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0748 (0.0962) teacher/usage_max 0.8739 (0.7269) teacher/usage_min 0.0000 (0.0286) teacher/usage_std 0.3857 (0.3016) nleep/row_max_mean 1551.3015 (1535.3626) nleep/row_max_std 73.9641 (58.1792) nleep/row_min_mean 1514.4966 (1504.4327) lr 7.5131e-04 eta 0:06:47
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,421
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [32/50] batch [20/181] time 0.160 (0.196) data 0.000 (0.015) loss 1.3405 (1.3596) teacher_loss 0.2667 (0.2998) loss_zs_kd 0.0262 (0.0274) loss_oracle 0.4837 (0.4272) kd_loss 0.8189 (0.8325) acc 90.6250 (89.6875) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0451 (0.0630) teacher/usage_max 0.9345 (0.8793) teacher/usage_min 0.0000 (0.0275) teacher/usage_std 0.4259 (0.3874) nleep/row_max_mean 1549.4236 (1544.8436) nleep/row_max_std 57.4158 (54.8728) nleep/row_min_mean 1516.6277 (1513.0803) lr 6.9098e-04 eta 0:11:11
epoch [32/50] batch [40/181] time 0.171 (0.184) data 0.000 (0.007) loss 1.1996 (1.3684) teacher_loss 0.1428 (0.3031) loss_zs_kd 0.0271 (0.0285) loss_oracle 0.4630 (0.4320) kd_loss 0.8117 (0.8350) acc 93.7500 (88.6719) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0522 (0.0664) teacher/usage_max 0.9417 (0.8741) teacher/usage_min 0.0000 (0.0318) teacher/usage_std 0.4308 (0.3836) nleep/row_max_mean 1553.6180 (1547.2422) nleep/row_max_std 43.8389 (53.2808) nleep/row_min_mean 1520.1055 (1515.0777) lr 6.9098e-04 eta 0:10:25
epoch [32/50] batch [60/181] time 0.153 (0.175) data 0.001 (0.005) loss 1.6431 (1.3774) teacher_loss 0.5395 (0.3115) loss_zs_kd 0.0240 (0.0283) loss_oracle 0.4491 (0.4289) kd_loss 0.8670 (0.8373) acc 84.3750 (88.3854) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0382 (0.0622) teacher/usage_max 0.9527 (0.8892) teacher/usage_min 0.0056 (0.0283) teacher/usage_std 0.4382 (0.3941) nleep/row_max_mean 1540.3246 (1546.8126) nleep/row_max_std 54.2165 (53.3501) nleep/row_min_mean 1507.7915 (1514.6893) lr 6.9098e-04 eta 0:09:52
epoch [32/50] batch [80/181] time 0.190 (0.170) data 0.000 (0.004) loss 1.3991 (1.3808) teacher_loss 0.3007 (0.3110) loss_zs_kd 0.0264 (0.0287) loss_oracle 0.3686 (0.4261) kd_loss 0.9009 (0.8424) acc 90.6250 (88.4766) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4215 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0243 (0.0579) teacher/usage_max 0.9038 (0.8970) teacher/usage_min 0.0341 (0.0272) teacher/usage_std 0.4036 (0.3994) nleep/row_max_mean 1538.3011 (1546.9012) nleep/row_max_std 50.6573 (52.8853) nleep/row_min_mean 1510.6417 (1514.9945) lr 6.9098e-04 eta 0:09:30
epoch [32/50] batch [100/181] time 0.183 (0.170) data 0.000 (0.003) loss 1.2794 (1.3829) teacher_loss 0.1784 (0.3115) loss_zs_kd 0.0212 (0.0290) loss_oracle 0.4499 (0.4249) kd_loss 0.8654 (0.8445) acc 93.7500 (88.4375) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4216 (0.4215) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0458 (0.0533) teacher/usage_max 0.8938 (0.9054) teacher/usage_min 0.0481 (0.0239) teacher/usage_std 0.3963 (0.4053) nleep/row_max_mean 1564.1730 (1547.1582) nleep/row_max_std 48.9194 (53.4583) nleep/row_min_mean 1532.0933 (1515.1666) lr 6.9098e-04 eta 0:09:27
epoch [32/50] batch [120/181] time 0.100 (0.159) data 0.000 (0.003) loss 1.4238 (1.3833) teacher_loss 0.3240 (0.3111) loss_zs_kd 0.0304 (0.0293) loss_oracle 0.3728 (0.4211) kd_loss 0.8982 (0.8470) acc 87.5000 (88.4896) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4216 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0900 (0.0523) teacher/usage_max 0.8607 (0.9105) teacher/usage_min 0.0131 (0.0221) teacher/usage_std 0.3758 (0.4089) nleep/row_max_mean 1531.3710 (1546.6639) nleep/row_max_std 60.3914 (54.5973) nleep/row_min_mean 1505.7705 (1514.8107) lr 6.9098e-04 eta 0:08:47
epoch [32/50] batch [140/181] time 0.125 (0.154) data 0.000 (0.002) loss 1.2618 (1.3802) teacher_loss 0.2122 (0.3079) loss_zs_kd 0.0291 (0.0288) loss_oracle 0.3674 (0.4218) kd_loss 0.8514 (0.8470) acc 90.6250 (88.7277) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4216 (0.4215) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0169 (0.0512) teacher/usage_max 0.9949 (0.9142) teacher/usage_min 0.0005 (0.0218) teacher/usage_std 0.4678 (0.4114) nleep/row_max_mean 1530.4255 (1545.7778) nleep/row_max_std 64.4238 (55.2070) nleep/row_min_mean 1502.5259 (1514.1244) lr 6.9098e-04 eta 0:08:26
epoch [32/50] batch [160/181] time 0.073 (0.149) data 0.000 (0.002) loss 1.5041 (1.3771) teacher_loss 0.4052 (0.3052) loss_zs_kd 0.0518 (0.0286) loss_oracle 0.4201 (0.4206) kd_loss 0.8629 (0.8473) acc 87.5000 (88.9258) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4217 (0.4215) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0317 (0.0508) teacher/usage_max 0.9176 (0.9174) teacher/usage_min 0.0313 (0.0210) teacher/usage_std 0.4132 (0.4136) nleep/row_max_mean 1556.7026 (1545.3871) nleep/row_max_std 46.6000 (55.6636) nleep/row_min_mean 1522.3373 (1513.9551) lr 6.9098e-04 eta 0:08:08
epoch [32/50] batch [180/181] time 0.071 (0.145) data 0.000 (0.002) loss 1.1925 (1.3793) teacher_loss 0.1288 (0.3070) loss_zs_kd 0.0104 (0.0282) loss_oracle 0.4020 (0.4169) kd_loss 0.8575 (0.8497) acc 96.8750 (88.7326) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4217 (0.4215) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0252 (0.0500) teacher/usage_max 0.9795 (0.9190) teacher/usage_min 0.0010 (0.0201) teacher/usage_std 0.4570 (0.4147) nleep/row_max_mean 1552.3508 (1544.6621) nleep/row_max_std 52.8376 (55.6104) nleep/row_min_mean 1523.1328 (1513.5021) lr 6.9098e-04 eta 0:07:52
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,421
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [33/50] batch [20/181] time 0.171 (0.133) data 0.000 (0.015) loss 1.3801 (1.3997) teacher_loss 0.2312 (0.3086) loss_zs_kd 0.0329 (0.0279) loss_oracle 0.4413 (0.4038) kd_loss 0.9118 (0.8753) acc 93.7500 (88.2812) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0124 (0.0349) teacher/usage_max 0.9373 (0.9367) teacher/usage_min 0.0012 (0.0120) teacher/usage_std 0.4278 (0.4271) nleep/row_max_mean 1537.0662 (1536.3083) nleep/row_max_std 61.5734 (54.3682) nleep/row_min_mean 1508.1362 (1507.8304) lr 6.3188e-04 eta 0:07:10
epoch [33/50] batch [40/181] time 0.109 (0.126) data 0.000 (0.008) loss 1.4466 (1.4088) teacher_loss 0.3290 (0.3197) loss_zs_kd 0.0265 (0.0271) loss_oracle 0.4269 (0.4073) kd_loss 0.8909 (0.8719) acc 84.3750 (88.6719) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0531 (0.0367) teacher/usage_max 0.9175 (0.9376) teacher/usage_min 0.0009 (0.0124) teacher/usage_std 0.4144 (0.4277) nleep/row_max_mean 1550.2502 (1536.6911) nleep/row_max_std 58.1191 (54.2158) nleep/row_min_mean 1520.3597 (1508.2641) lr 6.3188e-04 eta 0:06:46
epoch [33/50] batch [60/181] time 0.164 (0.130) data 0.001 (0.005) loss 1.4052 (1.4257) teacher_loss 0.2521 (0.3378) loss_zs_kd 0.0467 (0.0274) loss_oracle 0.4394 (0.3983) kd_loss 0.9101 (0.8750) acc 96.8750 (88.4375) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0136 (0.0385) teacher/usage_max 0.9383 (0.9317) teacher/usage_min 0.0006 (0.0132) teacher/usage_std 0.4285 (0.4237) nleep/row_max_mean 1542.7263 (1538.4813) nleep/row_max_std 58.3808 (54.5113) nleep/row_min_mean 1516.7216 (1510.4993) lr 6.3188e-04 eta 0:06:54
epoch [33/50] batch [80/181] time 0.164 (0.137) data 0.000 (0.004) loss 1.3403 (1.4288) teacher_loss 0.2501 (0.3381) loss_zs_kd 0.0179 (0.0279) loss_oracle 0.4197 (0.4021) kd_loss 0.8714 (0.8757) acc 90.6250 (87.9297) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4217 (0.4217) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0267 (0.0410) teacher/usage_max 0.9621 (0.9289) teacher/usage_min 0.0030 (0.0133) teacher/usage_std 0.4448 (0.4218) nleep/row_max_mean 1517.2847 (1537.5667) nleep/row_max_std 58.6479 (54.4795) nleep/row_min_mean 1492.9897 (1509.9905) lr 6.3188e-04 eta 0:07:16
epoch [33/50] batch [100/181] time 0.153 (0.141) data 0.000 (0.003) loss 1.2599 (1.4308) teacher_loss 0.2092 (0.3376) loss_zs_kd 0.0135 (0.0284) loss_oracle 0.3973 (0.3992) kd_loss 0.8452 (0.8794) acc 90.6250 (87.7188) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4218 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0406 (0.0408) teacher/usage_max 0.9733 (0.9258) teacher/usage_min 0.0038 (0.0131) teacher/usage_std 0.4526 (0.4198) nleep/row_max_mean 1554.1267 (1538.1897) nleep/row_max_std 57.1010 (54.2078) nleep/row_min_mean 1524.0972 (1510.8100) lr 6.3188e-04 eta 0:07:23
epoch [33/50] batch [120/181] time 0.159 (0.141) data 0.000 (0.003) loss 1.6551 (1.4297) teacher_loss 0.4319 (0.3304) loss_zs_kd 0.0345 (0.0276) loss_oracle 0.4440 (0.4041) kd_loss 0.9839 (0.8835) acc 84.3750 (88.0469) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4218 (0.4217) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0406 (0.0412) teacher/usage_max 0.8048 (0.9224) teacher/usage_min 0.0318 (0.0125) teacher/usage_std 0.3377 (0.4175) nleep/row_max_mean 1529.4244 (1538.2654) nleep/row_max_std 58.7003 (54.0261) nleep/row_min_mean 1501.9373 (1511.0158) lr 6.3188e-04 eta 0:07:23
epoch [33/50] batch [140/181] time 0.141 (0.142) data 0.000 (0.002) loss 1.1630 (1.4407) teacher_loss 0.0634 (0.3268) loss_zs_kd 0.0091 (0.0282) loss_oracle 0.3954 (0.4092) kd_loss 0.8974 (0.8952) acc 100.0000 (88.1920) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4218 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0335 (0.0433) teacher/usage_max 0.9308 (0.9102) teacher/usage_min 0.0007 (0.0113) teacher/usage_std 0.4234 (0.4098) nleep/row_max_mean 1552.6582 (1537.9855) nleep/row_max_std 45.6460 (53.7241) nleep/row_min_mean 1526.6561 (1511.1160) lr 6.3188e-04 eta 0:07:21
epoch [33/50] batch [160/181] time 0.142 (0.142) data 0.000 (0.002) loss 1.2068 (1.4339) teacher_loss 0.1186 (0.3144) loss_zs_kd 0.0238 (0.0283) loss_oracle 0.3691 (0.4125) kd_loss 0.8917 (0.8991) acc 96.8750 (88.7500) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4219 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0740 (0.0441) teacher/usage_max 0.8953 (0.9062) teacher/usage_min 0.0009 (0.0107) teacher/usage_std 0.3996 (0.4072) nleep/row_max_mean 1536.2633 (1537.7289) nleep/row_max_std 54.3689 (53.8962) nleep/row_min_mean 1512.2703 (1510.9977) lr 6.3188e-04 eta 0:07:20
epoch [33/50] batch [180/181] time 0.144 (0.142) data 0.000 (0.002) loss 1.4693 (1.4371) teacher_loss 0.1944 (0.3101) loss_zs_kd 0.0482 (0.0292) loss_oracle 0.4869 (0.4155) kd_loss 1.0074 (0.9046) acc 93.7500 (88.9062) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4219 (0.4217) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0369 (0.0454) teacher/usage_max 0.7981 (0.8998) teacher/usage_min 0.0187 (0.0105) teacher/usage_std 0.3354 (0.4030) nleep/row_max_mean 1540.3434 (1537.0721) nleep/row_max_std 63.3960 (54.4529) nleep/row_min_mean 1514.0063 (1510.5084) lr 6.3188e-04 eta 0:07:16
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [34/50] batch [20/181] time 0.091 (0.115) data 0.000 (0.015) loss 1.4299 (1.4854) teacher_loss 0.2408 (0.2646) loss_zs_kd 0.0372 (0.0324) loss_oracle 0.4483 (0.4549) kd_loss 0.9463 (0.9771) acc 87.5000 (90.7812) gate/entropy 1.0190 (1.0190) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1028 (0.0608) teacher/usage_max 0.8112 (0.8136) teacher/usage_min 0.0006 (0.0096) teacher/usage_std 0.3465 (0.3481) nleep/row_max_mean 1526.8953 (1532.9731) nleep/row_max_std 55.2140 (58.2003) nleep/row_min_mean 1502.7886 (1508.2527) lr 5.7422e-04 eta 0:05:50
epoch [34/50] batch [40/181] time 0.098 (0.118) data 0.000 (0.007) loss 1.5318 (1.5104) teacher_loss 0.2693 (0.2752) loss_zs_kd 0.0204 (0.0343) loss_oracle 0.4928 (0.4620) kd_loss 1.0059 (0.9870) acc 87.5000 (89.7656) gate/entropy 1.0190 (1.0190) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0809 (0.0597) teacher/usage_max 0.7457 (0.8062) teacher/usage_min 0.0283 (0.0081) teacher/usage_std 0.3026 (0.3436) nleep/row_max_mean 1537.3530 (1534.4607) nleep/row_max_std 51.9459 (57.8745) nleep/row_min_mean 1511.9375 (1509.4122) lr 5.7422e-04 eta 0:05:57
epoch [34/50] batch [60/181] time 0.178 (0.124) data 0.000 (0.005) loss 1.4659 (1.5081) teacher_loss 0.2018 (0.2647) loss_zs_kd 0.0207 (0.0330) loss_oracle 0.4393 (0.4597) kd_loss 1.0341 (0.9971) acc 90.6250 (90.2083) gate/entropy 1.0190 (1.0190) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0949 (0.0592) teacher/usage_max 0.7302 (0.7967) teacher/usage_min 0.0007 (0.0079) teacher/usage_std 0.3013 (0.3386) nleep/row_max_mean 1539.6965 (1535.9939) nleep/row_max_std 56.8979 (57.9856) nleep/row_min_mean 1515.9050 (1510.9014) lr 5.7422e-04 eta 0:06:13
epoch [34/50] batch [80/181] time 0.097 (0.121) data 0.000 (0.004) loss 1.4648 (1.5219) teacher_loss 0.1535 (0.2672) loss_zs_kd 0.0210 (0.0336) loss_oracle 0.4279 (0.4618) kd_loss 1.0869 (1.0069) acc 93.7500 (90.0781) gate/entropy 1.0190 (1.0190) gate/usage_max 0.4220 (0.4219) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0744 (0.0582) teacher/usage_max 0.6980 (0.7857) teacher/usage_min 0.0001 (0.0099) teacher/usage_std 0.2858 (0.3322) nleep/row_max_mean 1540.6768 (1537.1467) nleep/row_max_std 64.8643 (57.9388) nleep/row_min_mean 1516.8313 (1512.0674) lr 5.7422e-04 eta 0:06:03
epoch [34/50] batch [100/181] time 0.082 (0.122) data 0.000 (0.003) loss 1.4935 (1.5351) teacher_loss 0.1757 (0.2684) loss_zs_kd 0.0251 (0.0328) loss_oracle 0.3780 (0.4487) kd_loss 1.1162 (1.0260) acc 100.0000 (90.0312) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4219 (0.4219) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0735 (0.0559) teacher/usage_max 0.6685 (0.7690) teacher/usage_min 0.0010 (0.0097) teacher/usage_std 0.2725 (0.3233) nleep/row_max_mean 1506.8519 (1536.7568) nleep/row_max_std 56.7647 (58.1795) nleep/row_min_mean 1485.9756 (1511.9069) lr 5.7422e-04 eta 0:06:01
epoch [34/50] batch [120/181] time 0.090 (0.121) data 0.000 (0.003) loss 1.5100 (1.5465) teacher_loss 0.1463 (0.2583) loss_zs_kd 0.0294 (0.0324) loss_oracle 0.5113 (0.4531) kd_loss 1.0934 (1.0455) acc 96.8750 (90.2865) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4220 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0327 (0.0537) teacher/usage_max 0.7337 (0.7522) teacher/usage_min 0.0002 (0.0091) teacher/usage_std 0.3032 (0.3151) nleep/row_max_mean 1548.0709 (1537.6005) nleep/row_max_std 59.3080 (57.9350) nleep/row_min_mean 1523.1051 (1512.7766) lr 5.7422e-04 eta 0:05:58
epoch [34/50] batch [140/181] time 0.199 (0.122) data 0.000 (0.002) loss 1.8605 (1.5532) teacher_loss 0.3821 (0.2564) loss_zs_kd 0.0290 (0.0309) loss_oracle 0.5225 (0.4509) kd_loss 1.2026 (1.0559) acc 81.2500 (90.2902) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0369 (0.0531) teacher/usage_max 0.6129 (0.7417) teacher/usage_min 0.0062 (0.0097) teacher/usage_std 0.2500 (0.3097) nleep/row_max_mean 1533.1044 (1538.1646) nleep/row_max_std 67.6010 (58.1994) nleep/row_min_mean 1508.7434 (1513.5178) lr 5.7422e-04 eta 0:05:59
epoch [34/50] batch [160/181] time 0.185 (0.121) data 0.000 (0.002) loss 1.8267 (1.5634) teacher_loss 0.4250 (0.2591) loss_zs_kd 0.0285 (0.0301) loss_oracle 0.4342 (0.4481) kd_loss 1.1703 (1.0652) acc 81.2500 (90.0391) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4219) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0414 (0.0558) teacher/usage_max 0.6466 (0.7275) teacher/usage_min 0.0001 (0.0116) teacher/usage_std 0.2643 (0.3025) nleep/row_max_mean 1544.8123 (1538.6667) nleep/row_max_std 53.5048 (57.9217) nleep/row_min_mean 1523.0173 (1514.3136) lr 5.7422e-04 eta 0:05:51
epoch [34/50] batch [180/181] time 0.077 (0.119) data 0.000 (0.002) loss 1.5891 (1.5749) teacher_loss 0.3019 (0.2573) loss_zs_kd 0.0139 (0.0293) loss_oracle 0.3290 (0.4455) kd_loss 1.1157 (1.0802) acc 87.5000 (90.1736) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4220 (0.4219) gate/usage_min 0.1570 (0.1571) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.1418 (0.0599) teacher/usage_max 0.5469 (0.7079) teacher/usage_min 0.0539 (0.0130) teacher/usage_std 0.2066 (0.2942) nleep/row_max_mean 1539.8674 (1538.8025) nleep/row_max_std 58.1195 (57.3445) nleep/row_min_mean 1523.1761 (1514.7187) lr 5.7422e-04 eta 0:05:46
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,402
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [35/50] batch [20/181] time 0.099 (0.111) data 0.000 (0.015) loss 1.9334 (1.7635) teacher_loss 0.5054 (0.2646) loss_zs_kd 0.0191 (0.0219) loss_oracle 0.4774 (0.4287) kd_loss 1.1797 (1.2737) acc 84.3750 (90.1562) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0947 (0.0799) teacher/usage_max 0.5342 (0.5453) teacher/usage_min 0.0498 (0.0331) teacher/usage_std 0.2062 (0.2210) nleep/row_max_mean 1532.8967 (1539.6812) nleep/row_max_std 62.9678 (55.2147) nleep/row_min_mean 1514.8698 (1517.9858) lr 5.1825e-04 eta 0:05:19
epoch [35/50] batch [40/181] time 0.097 (0.099) data 0.000 (0.008) loss 1.8946 (1.8007) teacher_loss 0.2817 (0.2689) loss_zs_kd 0.0350 (0.0274) loss_oracle 0.4723 (0.4457) kd_loss 1.3593 (1.2953) acc 87.5000 (90.2344) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1119 (0.0825) teacher/usage_max 0.6154 (0.5644) teacher/usage_min 0.0141 (0.0294) teacher/usage_std 0.2469 (0.2273) nleep/row_max_mean 1535.6467 (1539.3559) nleep/row_max_std 49.2788 (51.3721) nleep/row_min_mean 1513.1899 (1517.5822) lr 5.1825e-04 eta 0:04:42
epoch [35/50] batch [60/181] time 0.082 (0.096) data 0.000 (0.005) loss 2.0746 (1.8114) teacher_loss 0.5880 (0.2640) loss_zs_kd 0.0337 (0.0288) loss_oracle 0.3771 (0.4492) kd_loss 1.2812 (1.3084) acc 81.2500 (90.5729) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1476 (0.0791) teacher/usage_max 0.5729 (0.5642) teacher/usage_min 0.0234 (0.0287) teacher/usage_std 0.2298 (0.2280) nleep/row_max_mean 1527.8608 (1539.8983) nleep/row_max_std 48.9727 (49.9590) nleep/row_min_mean 1509.8477 (1518.2955) lr 5.1825e-04 eta 0:04:31
epoch [35/50] batch [80/181] time 0.151 (0.105) data 0.000 (0.004) loss 1.7760 (1.8193) teacher_loss 0.2495 (0.2663) loss_zs_kd 0.0247 (0.0298) loss_oracle 0.4765 (0.4591) kd_loss 1.2759 (1.3086) acc 93.7500 (90.2734) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0835 (0.0760) teacher/usage_max 0.5024 (0.5579) teacher/usage_min 0.0380 (0.0307) teacher/usage_std 0.2096 (0.2258) nleep/row_max_mean 1552.2328 (1540.2721) nleep/row_max_std 48.8223 (49.3823) nleep/row_min_mean 1530.3115 (1519.0649) lr 5.1825e-04 eta 0:04:56
epoch [35/50] batch [100/181] time 0.149 (0.114) data 0.000 (0.003) loss 1.5845 (1.8080) teacher_loss 0.1269 (0.2530) loss_zs_kd 0.0355 (0.0291) loss_oracle 0.3591 (0.4588) kd_loss 1.2602 (1.3110) acc 96.8750 (90.7188) gate/entropy 1.0190 (1.0191) gate/usage_max 0.4221 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0820 (0.0751) teacher/usage_max 0.4941 (0.5576) teacher/usage_min 0.0209 (0.0318) teacher/usage_std 0.2210 (0.2254) nleep/row_max_mean 1552.1156 (1540.3564) nleep/row_max_std 54.0773 (49.5902) nleep/row_min_mean 1532.0540 (1519.2357) lr 5.1825e-04 eta 0:05:19
epoch [35/50] batch [120/181] time 0.149 (0.121) data 0.000 (0.003) loss 1.7102 (1.7954) teacher_loss 0.1300 (0.2486) loss_zs_kd 0.0274 (0.0286) loss_oracle 0.4938 (0.4550) kd_loss 1.3196 (1.3049) acc 93.7500 (90.7292) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0839 (0.0766) teacher/usage_max 0.5470 (0.5562) teacher/usage_min 0.0802 (0.0373) teacher/usage_std 0.1926 (0.2221) nleep/row_max_mean 1550.3838 (1539.9182) nleep/row_max_std 52.1238 (50.4173) nleep/row_min_mean 1528.0548 (1519.0354) lr 5.1825e-04 eta 0:05:35
epoch [35/50] batch [140/181] time 0.154 (0.127) data 0.000 (0.002) loss 1.8408 (1.7877) teacher_loss 0.2239 (0.2480) loss_zs_kd 0.0404 (0.0300) loss_oracle 0.4673 (0.4566) kd_loss 1.3631 (1.2964) acc 90.6250 (90.4018) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0567 (0.0777) teacher/usage_max 0.5635 (0.5515) teacher/usage_min 0.0635 (0.0420) teacher/usage_std 0.2060 (0.2181) nleep/row_max_mean 1529.0343 (1539.5370) nleep/row_max_std 55.4390 (51.0298) nleep/row_min_mean 1508.0737 (1518.7778) lr 5.1825e-04 eta 0:05:49
epoch [35/50] batch [160/181] time 0.172 (0.131) data 0.000 (0.002) loss 1.6274 (1.7832) teacher_loss 0.1405 (0.2443) loss_zs_kd 0.0257 (0.0299) loss_oracle 0.5811 (0.4616) kd_loss 1.1835 (1.2931) acc 93.7500 (90.4688) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0912 (0.0784) teacher/usage_max 0.5234 (0.5486) teacher/usage_min 0.0599 (0.0439) teacher/usage_std 0.1982 (0.2165) nleep/row_max_mean 1544.0852 (1538.9311) nleep/row_max_std 66.1996 (51.6836) nleep/row_min_mean 1523.1597 (1518.2669) lr 5.1825e-04 eta 0:05:59
epoch [35/50] batch [180/181] time 0.071 (0.135) data 0.000 (0.002) loss 1.6888 (1.7782) teacher_loss 0.1874 (0.2436) loss_zs_kd 0.0287 (0.0301) loss_oracle 0.6080 (0.4678) kd_loss 1.1830 (1.2856) acc 87.5000 (90.5035) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4221 (0.4220) gate/usage_min 0.1571 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0537 (0.0794) teacher/usage_max 0.5167 (0.5474) teacher/usage_min 0.1055 (0.0456) teacher/usage_std 0.1708 (0.2154) nleep/row_max_mean 1547.3687 (1538.9372) nleep/row_max_std 46.5866 (52.3473) nleep/row_min_mean 1525.4828 (1518.3319) lr 5.1825e-04 eta 0:06:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,401
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,656
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [36/50] batch [20/181] time 0.119 (0.148) data 0.000 (0.019) loss 1.5784 (1.7581) teacher_loss 0.1642 (0.2522) loss_zs_kd 0.0295 (0.0345) loss_oracle 0.4798 (0.4886) kd_loss 1.1596 (1.2443) acc 93.7500 (90.0000) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.0659 (0.0844) teacher/usage_max 0.5633 (0.5218) teacher/usage_min 0.0700 (0.0579) teacher/usage_std 0.2028 (0.2010) nleep/row_max_mean 1534.4927 (1535.1130) nleep/row_max_std 60.1727 (59.9173) nleep/row_min_mean 1514.8751 (1514.9085) lr 4.6417e-04 eta 0:06:37
epoch [36/50] batch [40/181] time 0.094 (0.119) data 0.000 (0.010) loss 1.8531 (1.7930) teacher_loss 0.2836 (0.2550) loss_zs_kd 0.0232 (0.0344) loss_oracle 0.5700 (0.5136) kd_loss 1.2729 (1.2640) acc 87.5000 (89.8438) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1732 (0.0901) teacher/usage_max 0.5902 (0.5414) teacher/usage_min 0.0417 (0.0570) teacher/usage_std 0.2253 (0.2074) nleep/row_max_mean 1515.3684 (1535.2429) nleep/row_max_std 64.2900 (58.6857) nleep/row_min_mean 1495.6572 (1514.8417) lr 4.6417e-04 eta 0:05:19
epoch [36/50] batch [60/181] time 0.086 (0.120) data 0.000 (0.006) loss 1.7654 (1.7956) teacher_loss 0.2692 (0.2379) loss_zs_kd 0.0388 (0.0334) loss_oracle 0.4681 (0.5240) kd_loss 1.2427 (1.2790) acc 87.5000 (90.5208) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1572 (0.1571) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1087 (0.0892) teacher/usage_max 0.4951 (0.5453) teacher/usage_min 0.0548 (0.0551) teacher/usage_std 0.1978 (0.2092) nleep/row_max_mean 1518.6951 (1534.8569) nleep/row_max_std 69.5397 (58.2513) nleep/row_min_mean 1500.9547 (1514.2002) lr 4.6417e-04 eta 0:05:18
epoch [36/50] batch [80/181] time 0.079 (0.119) data 0.000 (0.005) loss 1.8385 (1.7930) teacher_loss 0.2064 (0.2269) loss_zs_kd 0.0451 (0.0326) loss_oracle 0.4822 (0.5266) kd_loss 1.3685 (1.2865) acc 93.7500 (91.1719) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1018 (0.0893) teacher/usage_max 0.6151 (0.5520) teacher/usage_min 0.0148 (0.0544) teacher/usage_std 0.2464 (0.2120) nleep/row_max_mean 1529.6099 (1534.4963) nleep/row_max_std 47.2047 (58.0011) nleep/row_min_mean 1511.9299 (1513.7217) lr 4.6417e-04 eta 0:05:13
epoch [36/50] batch [100/181] time 0.184 (0.120) data 0.000 (0.004) loss 2.0124 (1.7961) teacher_loss 0.3797 (0.2226) loss_zs_kd 0.0547 (0.0327) loss_oracle 0.5084 (0.5375) kd_loss 1.3512 (1.2883) acc 87.5000 (91.3750) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.1488 (0.0939) teacher/usage_max 0.6450 (0.5553) teacher/usage_min 0.0486 (0.0585) teacher/usage_std 0.2442 (0.2107) nleep/row_max_mean 1534.8588 (1534.4167) nleep/row_max_std 50.0549 (57.3808) nleep/row_min_mean 1513.3375 (1513.5760) lr 4.6417e-04 eta 0:05:14
epoch [36/50] batch [120/181] time 0.187 (0.120) data 0.000 (0.003) loss 1.7528 (1.8020) teacher_loss 0.1675 (0.2195) loss_zs_kd 0.0597 (0.0329) loss_oracle 0.6330 (0.5443) kd_loss 1.2390 (1.2938) acc 90.6250 (91.3542) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0980 (0.0923) teacher/usage_max 0.4797 (0.5550) teacher/usage_min 0.0679 (0.0619) teacher/usage_std 0.1880 (0.2095) nleep/row_max_mean 1546.0752 (1534.7585) nleep/row_max_std 54.7385 (56.9091) nleep/row_min_mean 1522.9392 (1513.8611) lr 4.6417e-04 eta 0:05:11
epoch [36/50] batch [140/181] time 0.189 (0.121) data 0.000 (0.003) loss 1.5997 (1.7980) teacher_loss 0.1183 (0.2192) loss_zs_kd 0.0296 (0.0337) loss_oracle 0.5278 (0.5438) kd_loss 1.2028 (1.2901) acc 100.0000 (91.3839) gate/entropy 1.0191 (1.0191) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1571 (0.1572) gate/usage_std 0.1246 (0.1246) teacher/entropy 0.0468 (0.0924) teacher/usage_max 0.5160 (0.5518) teacher/usage_min 0.0928 (0.0641) teacher/usage_std 0.1776 (0.2071) nleep/row_max_mean 1549.8329 (1535.0622) nleep/row_max_std 52.7470 (56.5757) nleep/row_min_mean 1528.4990 (1514.1273) lr 4.6417e-04 eta 0:05:12
epoch [36/50] batch [160/181] time 0.155 (0.122) data 0.000 (0.003) loss 1.5832 (1.7918) teacher_loss 0.2423 (0.2154) loss_zs_kd 0.0184 (0.0326) loss_oracle 0.5995 (0.5497) kd_loss 1.0319 (1.2852) acc 84.3750 (91.5234) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.1920 (0.0926) teacher/usage_max 0.4999 (0.5494) teacher/usage_min 0.1351 (0.0660) teacher/usage_std 0.1506 (0.2053) nleep/row_max_mean 1542.0558 (1535.3387) nleep/row_max_std 58.6893 (56.5849) nleep/row_min_mean 1521.5742 (1514.4486) lr 4.6417e-04 eta 0:05:11
epoch [36/50] batch [180/181] time 0.131 (0.125) data 0.000 (0.002) loss 1.8874 (1.7929) teacher_loss 0.2559 (0.2150) loss_zs_kd 0.0378 (0.0324) loss_oracle 0.6163 (0.5541) kd_loss 1.3045 (1.2847) acc 84.3750 (91.4410) gate/entropy 1.0192 (1.0191) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1246) teacher/entropy 0.0911 (0.0922) teacher/usage_max 0.5393 (0.5474) teacher/usage_min 0.0824 (0.0694) teacher/usage_std 0.1892 (0.2028) nleep/row_max_mean 1527.4138 (1535.4614) nleep/row_max_std 61.5370 (56.4155) nleep/row_min_mean 1505.4777 (1514.5657) lr 4.6417e-04 eta 0:05:17
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,404
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,657
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [37/50] batch [20/181] time 0.169 (0.179) data 0.000 (0.014) loss 1.4920 (1.7299) teacher_loss 0.1104 (0.2184) loss_zs_kd 0.0282 (0.0359) loss_oracle 0.3833 (0.5028) kd_loss 1.1759 (1.2421) acc 93.7500 (90.9375) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0839 (0.0967) teacher/usage_max 0.4820 (0.5113) teacher/usage_min 0.1161 (0.1023) teacher/usage_std 0.1570 (0.1756) nleep/row_max_mean 1530.1519 (1537.2133) nleep/row_max_std 46.0462 (53.3257) nleep/row_min_mean 1511.0061 (1516.1788) lr 4.1221e-04 eta 0:07:30
epoch [37/50] batch [40/181] time 0.160 (0.175) data 0.000 (0.007) loss 1.8591 (1.7544) teacher_loss 0.2623 (0.2327) loss_zs_kd 0.0216 (0.0363) loss_oracle 0.5281 (0.5081) kd_loss 1.3220 (1.2495) acc 93.7500 (90.6250) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0544 (0.0908) teacher/usage_max 0.5202 (0.5220) teacher/usage_min 0.0083 (0.1026) teacher/usage_std 0.2307 (0.1785) nleep/row_max_mean 1531.5311 (1534.8303) nleep/row_max_std 49.2318 (52.9469) nleep/row_min_mean 1510.2367 (1513.9864) lr 4.1221e-04 eta 0:07:15
epoch [37/50] batch [60/181] time 0.101 (0.158) data 0.001 (0.005) loss 1.6032 (1.7634) teacher_loss 0.1248 (0.2335) loss_zs_kd 0.0177 (0.0352) loss_oracle 0.6229 (0.5275) kd_loss 1.1581 (1.2486) acc 96.8750 (90.7812) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1367 (0.0912) teacher/usage_max 0.4830 (0.5196) teacher/usage_min 0.0794 (0.1040) teacher/usage_std 0.1805 (0.1775) nleep/row_max_mean 1530.7473 (1534.9243) nleep/row_max_std 56.4334 (52.2160) nleep/row_min_mean 1509.3563 (1514.0148) lr 4.1221e-04 eta 0:06:31
epoch [37/50] batch [80/181] time 0.179 (0.148) data 0.000 (0.004) loss 1.6872 (1.7591) teacher_loss 0.0981 (0.2304) loss_zs_kd 0.0367 (0.0356) loss_oracle 0.5202 (0.5407) kd_loss 1.3107 (1.2406) acc 100.0000 (91.2500) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1573 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0455 (0.0868) teacher/usage_max 0.4999 (0.5108) teacher/usage_min 0.1054 (0.1088) teacher/usage_std 0.1668 (0.1722) nleep/row_max_mean 1527.2549 (1535.1778) nleep/row_max_std 41.6102 (51.3453) nleep/row_min_mean 1503.3823 (1514.1502) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [100/181] time 0.095 (0.142) data 0.000 (0.003) loss 1.7321 (1.7519) teacher_loss 0.3329 (0.2322) loss_zs_kd 0.0584 (0.0357) loss_oracle 0.4416 (0.5312) kd_loss 1.1492 (1.2362) acc 87.5000 (91.1875) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0928 (0.0862) teacher/usage_max 0.5093 (0.5122) teacher/usage_min 0.1070 (0.1079) teacher/usage_std 0.1680 (0.1729) nleep/row_max_mean 1528.5822 (1535.3960) nleep/row_max_std 60.8056 (51.4732) nleep/row_min_mean 1507.9030 (1514.1820) lr 4.1221e-04 eta 0:05:45
epoch [37/50] batch [120/181] time 0.088 (0.138) data 0.000 (0.003) loss 1.6486 (1.7351) teacher_loss 0.1456 (0.2285) loss_zs_kd 0.0509 (0.0372) loss_oracle 0.5068 (0.5273) kd_loss 1.2241 (1.2243) acc 100.0000 (91.3542) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0696 (0.0851) teacher/usage_max 0.4355 (0.5118) teacher/usage_min 0.2053 (0.1115) teacher/usage_std 0.0958 (0.1706) nleep/row_max_mean 1537.1389 (1535.6802) nleep/row_max_std 57.0744 (51.6009) nleep/row_min_mean 1514.7378 (1514.2775) lr 4.1221e-04 eta 0:05:34
epoch [37/50] batch [140/181] time 0.203 (0.134) data 0.000 (0.002) loss 1.7495 (1.7380) teacher_loss 0.3299 (0.2275) loss_zs_kd 0.0549 (0.0376) loss_oracle 0.4672 (0.5344) kd_loss 1.1585 (1.2245) acc 87.5000 (91.4955) gate/entropy 1.0191 (1.0192) gate/usage_max 0.4222 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.1193 (0.0879) teacher/usage_max 0.5406 (0.5103) teacher/usage_min 0.0390 (0.1136) teacher/usage_std 0.2139 (0.1691) nleep/row_max_mean 1533.9801 (1535.9260) nleep/row_max_std 59.7688 (51.9366) nleep/row_min_mean 1513.5923 (1514.4690) lr 4.1221e-04 eta 0:05:20
epoch [37/50] batch [160/181] time 0.095 (0.132) data 0.000 (0.002) loss 1.5670 (1.7365) teacher_loss 0.1922 (0.2254) loss_zs_kd 0.0519 (0.0372) loss_oracle 0.5228 (0.5412) kd_loss 1.0875 (1.2219) acc 96.8750 (91.6211) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1256 (0.0891) teacher/usage_max 0.4715 (0.5073) teacher/usage_min 0.1744 (0.1165) teacher/usage_std 0.1222 (0.1667) nleep/row_max_mean 1537.4863 (1535.8482) nleep/row_max_std 55.5166 (51.8516) nleep/row_min_mean 1513.7999 (1514.3050) lr 4.1221e-04 eta 0:05:12
epoch [37/50] batch [180/181] time 0.070 (0.131) data 0.000 (0.002) loss 1.6545 (1.7279) teacher_loss 0.3461 (0.2237) loss_zs_kd 0.0474 (0.0372) loss_oracle 0.5191 (0.5385) kd_loss 1.0252 (1.2163) acc 84.3750 (91.7361) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1573 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0659 (0.0906) teacher/usage_max 0.6991 (0.5061) teacher/usage_min 0.0700 (0.1197) teacher/usage_std 0.2669 (0.1648) nleep/row_max_mean 1523.5388 (1535.5886) nleep/row_max_std 59.9031 (52.2297) nleep/row_min_mean 1503.3547 (1514.1496) lr 4.1221e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,413
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,658
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [38/50] batch [20/181] time 0.076 (0.128) data 0.000 (0.016) loss 1.8034 (1.7752) teacher_loss 0.3126 (0.2424) loss_zs_kd 0.0262 (0.0336) loss_oracle 0.5404 (0.5877) kd_loss 1.2075 (1.2222) acc 90.6250 (91.2500) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0911 (0.0899) teacher/usage_max 0.4584 (0.4954) teacher/usage_min 0.1002 (0.1047) teacher/usage_std 0.1650 (0.1690) nleep/row_max_mean 1520.2000 (1528.0210) nleep/row_max_std 58.1454 (49.9641) nleep/row_min_mean 1498.6450 (1506.8478) lr 3.6258e-04 eta 0:04:58
epoch [38/50] batch [40/181] time 0.170 (0.135) data 0.000 (0.008) loss 1.7336 (1.7465) teacher_loss 0.2534 (0.2264) loss_zs_kd 0.0089 (0.0334) loss_oracle 0.5338 (0.5833) kd_loss 1.2088 (1.2118) acc 93.7500 (92.2656) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4222 (0.4221) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0904 (0.0897) teacher/usage_max 0.4414 (0.5126) teacher/usage_min 0.1788 (0.1095) teacher/usage_std 0.1121 (0.1714) nleep/row_max_mean 1536.5258 (1527.5729) nleep/row_max_std 39.7118 (49.7057) nleep/row_min_mean 1515.9835 (1506.8311) lr 3.6258e-04 eta 0:05:12
epoch [38/50] batch [60/181] time 0.159 (0.144) data 0.001 (0.005) loss 1.6590 (1.7260) teacher_loss 0.1757 (0.2216) loss_zs_kd 0.0275 (0.0346) loss_oracle 0.4520 (0.5839) kd_loss 1.2435 (1.1950) acc 96.8750 (92.2917) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1509 (0.0940) teacher/usage_max 0.5377 (0.5149) teacher/usage_min 0.2052 (0.1129) teacher/usage_std 0.1461 (0.1707) nleep/row_max_mean 1519.1414 (1526.8499) nleep/row_max_std 52.4392 (49.9117) nleep/row_min_mean 1501.3291 (1506.1914) lr 3.6258e-04 eta 0:05:30
epoch [38/50] batch [80/181] time 0.159 (0.148) data 0.000 (0.004) loss 1.8805 (1.7282) teacher_loss 0.3307 (0.2204) loss_zs_kd 0.0619 (0.0358) loss_oracle 0.5591 (0.5847) kd_loss 1.2393 (1.1974) acc 84.3750 (92.1875) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1114 (0.0931) teacher/usage_max 0.4935 (0.5113) teacher/usage_min 0.1868 (0.1177) teacher/usage_std 0.1256 (0.1672) nleep/row_max_mean 1535.9125 (1527.0116) nleep/row_max_std 53.3477 (50.6100) nleep/row_min_mean 1513.8650 (1506.2282) lr 3.6258e-04 eta 0:05:35
epoch [38/50] batch [100/181] time 0.136 (0.149) data 0.000 (0.003) loss 1.8108 (1.7211) teacher_loss 0.4162 (0.2238) loss_zs_kd 0.0477 (0.0369) loss_oracle 0.5642 (0.5742) kd_loss 1.0887 (1.1917) acc 84.3750 (91.7812) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1246 (0.1245) teacher/entropy 0.0660 (0.0940) teacher/usage_max 0.5334 (0.5080) teacher/usage_min 0.1715 (0.1192) teacher/usage_std 0.1502 (0.1655) nleep/row_max_mean 1530.1422 (1526.1228) nleep/row_max_std 55.0318 (51.5924) nleep/row_min_mean 1508.3802 (1505.5854) lr 3.6258e-04 eta 0:05:34
epoch [38/50] batch [120/181] time 0.173 (0.150) data 0.000 (0.003) loss 1.8313 (1.7219) teacher_loss 0.2306 (0.2254) loss_zs_kd 0.0241 (0.0372) loss_oracle 0.6915 (0.5721) kd_loss 1.2428 (1.1919) acc 90.6250 (91.6406) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1572 (0.1572) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0845 (0.0944) teacher/usage_max 0.5012 (0.5025) teacher/usage_min 0.0280 (0.1203) teacher/usage_std 0.2162 (0.1634) nleep/row_max_mean 1536.9158 (1525.7430) nleep/row_max_std 50.7491 (52.0433) nleep/row_min_mean 1512.4797 (1505.2709) lr 3.6258e-04 eta 0:05:35
epoch [38/50] batch [140/181] time 0.091 (0.150) data 0.000 (0.002) loss 1.3818 (1.7186) teacher_loss 0.1270 (0.2209) loss_zs_kd 0.0136 (0.0372) loss_oracle 0.5416 (0.5771) kd_loss 0.9772 (1.1905) acc 96.8750 (91.8750) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1095 (0.0947) teacher/usage_max 0.6630 (0.4991) teacher/usage_min 0.1104 (0.1246) teacher/usage_std 0.2379 (0.1604) nleep/row_max_mean 1525.6934 (1525.8087) nleep/row_max_std 54.2990 (52.6748) nleep/row_min_mean 1506.2494 (1505.3105) lr 3.6258e-04 eta 0:05:32
epoch [38/50] batch [160/181] time 0.080 (0.146) data 0.000 (0.002) loss 1.7760 (1.7261) teacher_loss 0.1909 (0.2222) loss_zs_kd 0.0375 (0.0384) loss_oracle 0.6364 (0.5841) kd_loss 1.2481 (1.1927) acc 93.7500 (91.9141) gate/entropy 1.0192 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1572 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0621 (0.0947) teacher/usage_max 0.4527 (0.4962) teacher/usage_min 0.1538 (0.1285) teacher/usage_std 0.1292 (0.1577) nleep/row_max_mean 1534.9077 (1526.3258) nleep/row_max_std 58.9201 (52.8662) nleep/row_min_mean 1511.4219 (1505.7588) lr 3.6258e-04 eta 0:05:19
epoch [38/50] batch [180/181] time 0.166 (0.143) data 0.000 (0.002) loss 1.5389 (1.7279) teacher_loss 0.0643 (0.2171) loss_zs_kd 0.0243 (0.0386) loss_oracle 0.5781 (0.5874) kd_loss 1.1733 (1.1979) acc 100.0000 (92.1875) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1227 (0.0947) teacher/usage_max 0.4380 (0.4959) teacher/usage_min 0.2704 (0.1317) teacher/usage_std 0.0745 (0.1561) nleep/row_max_mean 1529.9639 (1526.3334) nleep/row_max_std 49.9661 (53.0214) nleep/row_min_mean 1510.0975 (1505.8589) lr 3.6258e-04 eta 0:05:09
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,419
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.0%, epoch: 31 *******
******* Domain p best val test acc: 99.7%, epoch: 31 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [39/50] batch [20/181] time 0.060 (0.119) data 0.000 (0.019) loss 1.8763 (1.7328) teacher_loss 0.2208 (0.1548) loss_zs_kd 0.0617 (0.0354) loss_oracle 0.6986 (0.6372) kd_loss 1.2753 (1.2417) acc 90.6250 (95.4688) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0659 (0.0986) teacher/usage_max 0.4847 (0.4972) teacher/usage_min 0.0536 (0.1790) teacher/usage_std 0.1980 (0.1341) nleep/row_max_mean 1512.1279 (1529.2424) nleep/row_max_std 65.5995 (53.2310) nleep/row_min_mean 1492.0283 (1508.9644) lr 3.1545e-04 eta 0:04:16
epoch [39/50] batch [40/181] time 0.055 (0.110) data 0.000 (0.010) loss 1.8591 (1.7765) teacher_loss 0.1794 (0.1995) loss_zs_kd 0.0642 (0.0372) loss_oracle 0.6436 (0.6279) kd_loss 1.3258 (1.2445) acc 93.7500 (94.2188) gate/entropy 1.0193 (1.0192) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0275 (0.0970) teacher/usage_max 0.4968 (0.4993) teacher/usage_min 0.0919 (0.1625) teacher/usage_std 0.1742 (0.1420) nleep/row_max_mean 1519.4821 (1527.4738) nleep/row_max_std 45.2833 (52.3490) nleep/row_min_mean 1498.7966 (1507.7005) lr 3.1545e-04 eta 0:03:53
epoch [39/50] batch [60/181] time 0.149 (0.103) data 0.000 (0.006) loss 1.8564 (1.7676) teacher_loss 0.2236 (0.1894) loss_zs_kd 0.0601 (0.0389) loss_oracle 0.6637 (0.6390) kd_loss 1.2708 (1.2393) acc 90.6250 (94.2708) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0845 (0.0938) teacher/usage_max 0.4985 (0.4960) teacher/usage_min 0.2221 (0.1698) teacher/usage_std 0.1191 (0.1377) nleep/row_max_mean 1527.8981 (1525.2230) nleep/row_max_std 50.3830 (52.7655) nleep/row_min_mean 1505.2515 (1505.3436) lr 3.1545e-04 eta 0:03:36
epoch [39/50] batch [80/181] time 0.103 (0.100) data 0.000 (0.005) loss 1.8761 (1.7767) teacher_loss 0.0908 (0.1908) loss_zs_kd 0.0329 (0.0411) loss_oracle 0.6488 (0.6429) kd_loss 1.4445 (1.2438) acc 96.8750 (94.0625) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0477 (0.0935) teacher/usage_max 0.6371 (0.4971) teacher/usage_min 0.1757 (0.1770) teacher/usage_std 0.2148 (0.1355) nleep/row_max_mean 1528.7808 (1524.9859) nleep/row_max_std 45.6145 (52.4867) nleep/row_min_mean 1507.3562 (1505.0614) lr 3.1545e-04 eta 0:03:28
epoch [39/50] batch [100/181] time 0.082 (0.103) data 0.000 (0.004) loss 1.8761 (1.7799) teacher_loss 0.1621 (0.1874) loss_zs_kd 0.0593 (0.0420) loss_oracle 0.6215 (0.6443) kd_loss 1.3737 (1.2493) acc 96.8750 (94.1875) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0900 (0.0923) teacher/usage_max 0.6082 (0.4990) teacher/usage_min 0.1704 (0.1782) teacher/usage_std 0.1955 (0.1360) nleep/row_max_mean 1519.4304 (1523.6373) nleep/row_max_std 49.0767 (53.4435) nleep/row_min_mean 1498.4667 (1503.7090) lr 3.1545e-04 eta 0:03:34
epoch [39/50] batch [120/181] time 0.175 (0.106) data 0.000 (0.003) loss 1.8196 (1.7818) teacher_loss 0.1410 (0.1870) loss_zs_kd 0.0382 (0.0427) loss_oracle 0.6712 (0.6451) kd_loss 1.3239 (1.2510) acc 96.8750 (94.2448) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1176 (0.0920) teacher/usage_max 0.5861 (0.5005) teacher/usage_min 0.1078 (0.1770) teacher/usage_std 0.1962 (0.1372) nleep/row_max_mean 1510.0327 (1523.2377) nleep/row_max_std 64.7489 (54.1752) nleep/row_min_mean 1489.6956 (1503.3187) lr 3.1545e-04 eta 0:03:37
epoch [39/50] batch [140/181] time 0.156 (0.109) data 0.000 (0.003) loss 1.9488 (1.7875) teacher_loss 0.1707 (0.1873) loss_zs_kd 0.0548 (0.0429) loss_oracle 0.7239 (0.6553) kd_loss 1.3887 (1.2511) acc 90.6250 (94.1295) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0674 (0.0919) teacher/usage_max 0.6006 (0.5016) teacher/usage_min 0.1631 (0.1752) teacher/usage_std 0.1913 (0.1385) nleep/row_max_mean 1519.2263 (1522.8088) nleep/row_max_std 60.3377 (54.7975) nleep/row_min_mean 1497.7297 (1502.8447) lr 3.1545e-04 eta 0:03:41
epoch [39/50] batch [160/181] time 0.159 (0.115) data 0.000 (0.003) loss 1.7640 (1.7970) teacher_loss 0.1588 (0.1869) loss_zs_kd 0.0646 (0.0435) loss_oracle 0.6707 (0.6668) kd_loss 1.2375 (1.2550) acc 93.7500 (94.1016) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0774 (0.0925) teacher/usage_max 0.4577 (0.5053) teacher/usage_min 0.2531 (0.1739) teacher/usage_std 0.0892 (0.1406) nleep/row_max_mean 1527.0281 (1522.4978) nleep/row_max_std 58.7051 (55.4180) nleep/row_min_mean 1506.3580 (1502.3719) lr 3.1545e-04 eta 0:03:51
epoch [39/50] batch [180/181] time 0.162 (0.120) data 0.000 (0.002) loss 1.8889 (1.8055) teacher_loss 0.1668 (0.1854) loss_zs_kd 0.0115 (0.0434) loss_oracle 0.8408 (0.6748) kd_loss 1.2959 (1.2609) acc 93.7500 (94.1319) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.0806 (0.0908) teacher/usage_max 0.5201 (0.5080) teacher/usage_min 0.1532 (0.1729) teacher/usage_std 0.1499 (0.1421) nleep/row_max_mean 1528.0852 (1523.2123) nleep/row_max_std 60.1423 (55.3653) nleep/row_min_mean 1505.3601 (1502.8314) lr 3.1545e-04 eta 0:03:59
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,426
* accuracy: 97.2%
* error: 2.8%
* macro_f1: 97.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,659
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.2%, epoch: 39 *******
******* Domain p best val test acc: 99.3%, epoch: 39 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [40/50] batch [20/181] time 0.157 (0.179) data 0.000 (0.018) loss 2.0010 (1.9544) teacher_loss 0.1799 (0.2158) loss_zs_kd 0.0260 (0.0442) loss_oracle 0.8196 (0.7628) kd_loss 1.3983 (1.3351) acc 90.6250 (93.4375) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.1150 (0.0835) teacher/usage_max 0.6590 (0.5628) teacher/usage_min 0.1322 (0.1545) teacher/usage_std 0.2324 (0.1747) nleep/row_max_mean 1532.2622 (1528.7001) nleep/row_max_std 52.6574 (55.3422) nleep/row_min_mean 1508.2434 (1505.7160) lr 2.7103e-04 eta 0:05:52
epoch [40/50] batch [40/181] time 0.173 (0.149) data 0.000 (0.009) loss 1.8948 (1.9578) teacher_loss 0.2267 (0.1986) loss_zs_kd 0.0470 (0.0467) loss_oracle 0.7349 (0.7866) kd_loss 1.2772 (1.3426) acc 90.6250 (93.9062) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0868 (0.0775) teacher/usage_max 0.5073 (0.5642) teacher/usage_min 0.2108 (0.1544) teacher/usage_std 0.1264 (0.1751) nleep/row_max_mean 1524.6797 (1531.3987) nleep/row_max_std 54.7497 (54.8670) nleep/row_min_mean 1504.0852 (1507.9027) lr 2.7103e-04 eta 0:04:51
epoch [40/50] batch [60/181] time 0.202 (0.139) data 0.000 (0.006) loss 1.9284 (1.9414) teacher_loss 0.0950 (0.1868) loss_zs_kd 0.0345 (0.0454) loss_oracle 0.8744 (0.7767) kd_loss 1.3789 (1.3435) acc 96.8750 (94.1667) gate/entropy 1.0194 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.0623 (0.0791) teacher/usage_max 0.5861 (0.5669) teacher/usage_min 0.0918 (0.1500) teacher/usage_std 0.2020 (0.1775) nleep/row_max_mean 1531.0266 (1530.9958) nleep/row_max_std 46.5606 (55.0748) nleep/row_min_mean 1501.8019 (1507.4881) lr 2.7103e-04 eta 0:04:28
epoch [40/50] batch [80/181] time 0.136 (0.133) data 0.000 (0.005) loss 2.0039 (1.9378) teacher_loss 0.2756 (0.1876) loss_zs_kd 0.0534 (0.0462) loss_oracle 0.8019 (0.7726) kd_loss 1.3007 (1.3408) acc 90.6250 (94.0625) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1182 (0.0819) teacher/usage_max 0.5628 (0.5670) teacher/usage_min 0.1935 (0.1499) teacher/usage_std 0.1636 (0.1778) nleep/row_max_mean 1539.4863 (1531.7071) nleep/row_max_std 55.8745 (55.0767) nleep/row_min_mean 1514.1829 (1507.9620) lr 2.7103e-04 eta 0:04:13
epoch [40/50] batch [100/181] time 0.094 (0.128) data 0.000 (0.004) loss 1.9910 (1.9275) teacher_loss 0.2993 (0.1799) loss_zs_kd 0.0342 (0.0456) loss_oracle 0.6360 (0.7726) kd_loss 1.3566 (1.3385) acc 90.6250 (94.2500) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.0500 (0.0800) teacher/usage_max 0.5505 (0.5640) teacher/usage_min 0.1655 (0.1504) teacher/usage_std 0.1610 (0.1762) nleep/row_max_mean 1527.6101 (1532.0946) nleep/row_max_std 63.0728 (55.4333) nleep/row_min_mean 1503.9885 (1508.1361) lr 2.7103e-04 eta 0:04:02
epoch [40/50] batch [120/181] time 0.172 (0.126) data 0.000 (0.003) loss 2.0596 (1.9263) teacher_loss 0.1806 (0.1729) loss_zs_kd 0.0420 (0.0457) loss_oracle 0.9810 (0.7824) kd_loss 1.3674 (1.3393) acc 96.8750 (94.4531) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0645 (0.0791) teacher/usage_max 0.5764 (0.5637) teacher/usage_min 0.0981 (0.1500) teacher/usage_std 0.1953 (0.1762) nleep/row_max_mean 1536.4480 (1532.5954) nleep/row_max_std 69.2242 (55.7646) nleep/row_min_mean 1509.4138 (1508.3503) lr 2.7103e-04 eta 0:03:56
epoch [40/50] batch [140/181] time 0.093 (0.125) data 0.000 (0.003) loss 2.1472 (1.9318) teacher_loss 0.1653 (0.1741) loss_zs_kd 0.0608 (0.0464) loss_oracle 0.9191 (0.7874) kd_loss 1.4920 (1.3409) acc 93.7500 (94.3973) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.0260 (0.0796) teacher/usage_max 0.6641 (0.5660) teacher/usage_min 0.0626 (0.1484) teacher/usage_std 0.2492 (0.1782) nleep/row_max_mean 1534.4532 (1532.9189) nleep/row_max_std 51.0676 (55.9909) nleep/row_min_mean 1507.6866 (1508.4058) lr 2.7103e-04 eta 0:03:51
epoch [40/50] batch [160/181] time 0.068 (0.123) data 0.000 (0.002) loss 1.9672 (1.9355) teacher_loss 0.2764 (0.1750) loss_zs_kd 0.0731 (0.0464) loss_oracle 0.7114 (0.7897) kd_loss 1.2985 (1.3425) acc 93.7500 (94.3555) gate/entropy 1.0193 (1.0193) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1573 (0.1573) gate/usage_std 0.1245 (0.1245) teacher/entropy 0.1523 (0.0806) teacher/usage_max 0.5956 (0.5685) teacher/usage_min 0.1458 (0.1492) teacher/usage_std 0.1911 (0.1790) nleep/row_max_mean 1523.8971 (1532.9808) nleep/row_max_std 49.5464 (56.0427) nleep/row_min_mean 1502.2701 (1508.3352) lr 2.7103e-04 eta 0:03:45
epoch [40/50] batch [180/181] time 0.073 (0.122) data 0.000 (0.002) loss 1.9590 (1.9381) teacher_loss 0.1711 (0.1743) loss_zs_kd 0.0403 (0.0469) loss_oracle 0.8268 (0.7954) kd_loss 1.3544 (1.3427) acc 93.7500 (94.3750) gate/entropy 1.0194 (1.0193) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1573) gate/usage_std 0.1244 (0.1245) teacher/entropy 0.0987 (0.0794) teacher/usage_max 0.5981 (0.5675) teacher/usage_min 0.1189 (0.1488) teacher/usage_std 0.1989 (0.1787) nleep/row_max_mean 1524.1384 (1533.2309) nleep/row_max_std 68.5762 (56.1345) nleep/row_min_mean 1499.9789 (1508.5512) lr 2.7103e-04 eta 0:03:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,426
* accuracy: 97.2%
* error: 2.8%
* macro_f1: 97.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,657
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain p best val acc:      97.2%, epoch: 39 *******
******* Domain p best val test acc: 99.3%, epoch: 39 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [41/50] batch [20/181] time 0.169 (0.166) data 0.000 (0.015) loss 2.1735 (1.9865) teacher_loss 0.2838 (0.1792) loss_zs_kd 0.0520 (0.0473) loss_oracle 0.7686 (0.8354) kd_loss 1.4794 (1.3660) acc 93.7500 (93.7500) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1127 (0.0752) teacher/usage_max 0.7389 (0.5859) teacher/usage_min 0.1186 (0.1440) teacher/usage_std 0.2870 (0.1895) nleep/row_max_mean 1530.5353 (1532.8443) nleep/row_max_std 64.0734 (58.1196) nleep/row_min_mean 1505.3347 (1506.8335) lr 2.2949e-04 eta 0:04:57
epoch [41/50] batch [40/181] time 0.161 (0.163) data 0.000 (0.008) loss 1.9261 (1.9839) teacher_loss 0.1129 (0.1776) loss_zs_kd 0.0416 (0.0474) loss_oracle 0.7900 (0.8292) kd_loss 1.3974 (1.3680) acc 100.0000 (94.2969) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0209 (0.0736) teacher/usage_max 0.5624 (0.5869) teacher/usage_min 0.1567 (0.1442) teacher/usage_std 0.1697 (0.1905) nleep/row_max_mean 1521.4204 (1532.0380) nleep/row_max_std 60.2610 (55.9210) nleep/row_min_mean 1496.0980 (1506.3255) lr 2.2949e-04 eta 0:04:48
epoch [41/50] batch [60/181] time 0.158 (0.159) data 0.001 (0.005) loss 1.9616 (1.9864) teacher_loss 0.0704 (0.1718) loss_zs_kd 0.0985 (0.0488) loss_oracle 0.8707 (0.8321) kd_loss 1.4066 (1.3741) acc 100.0000 (94.3750) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0544 (0.0755) teacher/usage_max 0.6055 (0.5948) teacher/usage_min 0.1875 (0.1467) teacher/usage_std 0.1926 (0.1940) nleep/row_max_mean 1532.1609 (1532.5368) nleep/row_max_std 56.7714 (55.6794) nleep/row_min_mean 1506.8506 (1506.5788) lr 2.2949e-04 eta 0:04:38
epoch [41/50] batch [80/181] time 0.165 (0.159) data 0.000 (0.004) loss 2.0280 (1.9723) teacher_loss 0.1240 (0.1609) loss_zs_kd 0.0382 (0.0479) loss_oracle 0.8791 (0.8345) kd_loss 1.4454 (1.3702) acc 93.7500 (94.8828) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0534 (0.0757) teacher/usage_max 0.6439 (0.5910) teacher/usage_min 0.1314 (0.1462) teacher/usage_std 0.2229 (0.1922) nleep/row_max_mean 1539.1599 (1532.7889) nleep/row_max_std 56.8163 (54.6961) nleep/row_min_mean 1511.4617 (1506.8390) lr 2.2949e-04 eta 0:04:34
epoch [41/50] batch [100/181] time 0.139 (0.159) data 0.000 (0.003) loss 2.1216 (1.9805) teacher_loss 0.2996 (0.1720) loss_zs_kd 0.0387 (0.0489) loss_oracle 0.7569 (0.8306) kd_loss 1.4242 (1.3687) acc 93.7500 (94.3125) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0723 (0.0761) teacher/usage_max 0.6428 (0.5900) teacher/usage_min 0.0166 (0.1428) teacher/usage_std 0.2557 (0.1929) nleep/row_max_mean 1525.2593 (1532.4799) nleep/row_max_std 52.5140 (54.2098) nleep/row_min_mean 1499.7893 (1506.6665) lr 2.2949e-04 eta 0:04:32
epoch [41/50] batch [120/181] time 0.075 (0.157) data 0.000 (0.003) loss 1.9359 (1.9696) teacher_loss 0.1380 (0.1697) loss_zs_kd 0.0497 (0.0494) loss_oracle 0.7319 (0.8182) kd_loss 1.4071 (1.3661) acc 96.8750 (94.5312) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0843 (0.0774) teacher/usage_max 0.6367 (0.5885) teacher/usage_min 0.1343 (0.1472) teacher/usage_std 0.2180 (0.1911) nleep/row_max_mean 1539.4907 (1532.8591) nleep/row_max_std 49.3586 (53.3905) nleep/row_min_mean 1511.7841 (1507.1194) lr 2.2949e-04 eta 0:04:25
epoch [41/50] batch [140/181] time 0.195 (0.150) data 0.000 (0.002) loss 1.6459 (1.9635) teacher_loss 0.0600 (0.1694) loss_zs_kd 0.0663 (0.0497) loss_oracle 0.6978 (0.8130) kd_loss 1.2039 (1.3627) acc 100.0000 (94.4420) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0476 (0.0766) teacher/usage_max 0.4494 (0.5846) teacher/usage_min 0.1565 (0.1504) teacher/usage_std 0.1270 (0.1880) nleep/row_max_mean 1542.4114 (1533.3731) nleep/row_max_std 44.0317 (53.3139) nleep/row_min_mean 1516.8450 (1507.6897) lr 2.2949e-04 eta 0:04:10
epoch [41/50] batch [160/181] time 0.078 (0.147) data 0.000 (0.002) loss 2.1020 (1.9603) teacher_loss 0.2699 (0.1717) loss_zs_kd 0.0651 (0.0498) loss_oracle 0.8055 (0.8137) kd_loss 1.3968 (1.3568) acc 90.6250 (94.2773) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0343 (0.0772) teacher/usage_max 0.5762 (0.5797) teacher/usage_min 0.2052 (0.1547) teacher/usage_std 0.1718 (0.1842) nleep/row_max_mean 1520.9963 (1533.1992) nleep/row_max_std 64.0968 (53.7700) nleep/row_min_mean 1495.8955 (1507.5112) lr 2.2949e-04 eta 0:04:03
epoch [41/50] batch [180/181] time 0.078 (0.144) data 0.000 (0.002) loss 1.8146 (1.9557) teacher_loss 0.2230 (0.1722) loss_zs_kd 0.0463 (0.0499) loss_oracle 0.7011 (0.8113) kd_loss 1.2179 (1.3528) acc 90.6250 (94.2361) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1142 (0.0777) teacher/usage_max 0.4753 (0.5761) teacher/usage_min 0.1884 (0.1555) teacher/usage_std 0.1172 (0.1820) nleep/row_max_mean 1545.7974 (1533.1252) nleep/row_max_std 48.8472 (53.7455) nleep/row_min_mean 1522.3488 (1507.5290) lr 2.2949e-04 eta 0:03:55
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,425
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,656
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain p best val acc:      97.2%, epoch: 39 *******
******* Domain p best val test acc: 99.3%, epoch: 39 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [42/50] batch [20/181] time 0.103 (0.134) data 0.001 (0.017) loss 1.8980 (1.8998) teacher_loss 0.0177 (0.1606) loss_zs_kd 0.0241 (0.0489) loss_oracle 0.6929 (0.7961) kd_loss 1.5218 (1.3167) acc 100.0000 (94.6875) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0197 (0.0728) teacher/usage_max 0.6889 (0.5335) teacher/usage_min 0.0331 (0.1609) teacher/usage_std 0.2706 (0.1573) nleep/row_max_mean 1527.5621 (1533.5470) nleep/row_max_std 53.0524 (55.1599) nleep/row_min_mean 1504.4413 (1507.5676) lr 1.9098e-04 eta 0:03:36
epoch [42/50] batch [40/181] time 0.186 (0.129) data 0.000 (0.008) loss 1.7768 (1.8894) teacher_loss 0.0721 (0.1495) loss_zs_kd 0.0396 (0.0507) loss_oracle 0.6692 (0.7909) kd_loss 1.3503 (1.3191) acc 96.8750 (95.1562) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0628 (0.0714) teacher/usage_max 0.5571 (0.5353) teacher/usage_min 0.2023 (0.1652) teacher/usage_std 0.1590 (0.1576) nleep/row_max_mean 1534.3402 (1532.5250) nleep/row_max_std 43.8899 (52.4599) nleep/row_min_mean 1510.3578 (1506.7015) lr 1.9098e-04 eta 0:03:24
epoch [42/50] batch [60/181] time 0.158 (0.123) data 0.001 (0.006) loss 2.0256 (1.9000) teacher_loss 0.3559 (0.1693) loss_zs_kd 0.0740 (0.0511) loss_oracle 0.7461 (0.7803) kd_loss 1.2597 (1.3150) acc 84.3750 (94.5833) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0756 (0.0733) teacher/usage_max 0.4785 (0.5362) teacher/usage_min 0.1599 (0.1658) teacher/usage_std 0.1316 (0.1580) nleep/row_max_mean 1537.4429 (1532.0085) nleep/row_max_std 52.7801 (51.7173) nleep/row_min_mean 1512.6964 (1506.6269) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [80/181] time 0.115 (0.124) data 0.000 (0.004) loss 1.8238 (1.8947) teacher_loss 0.1839 (0.1635) loss_zs_kd 0.0379 (0.0497) loss_oracle 0.7416 (0.7773) kd_loss 1.2500 (1.3177) acc 90.6250 (94.6094) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1125 (0.0729) teacher/usage_max 0.5062 (0.5376) teacher/usage_min 0.1447 (0.1682) teacher/usage_std 0.1480 (0.1578) nleep/row_max_mean 1540.4131 (1532.0263) nleep/row_max_std 50.3250 (52.3984) nleep/row_min_mean 1518.3215 (1506.7618) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [100/181] time 0.134 (0.124) data 0.000 (0.004) loss 1.5919 (1.8841) teacher_loss 0.1026 (0.1630) loss_zs_kd 0.0397 (0.0495) loss_oracle 0.6309 (0.7709) kd_loss 1.1540 (1.3109) acc 96.8750 (94.2812) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1526 (0.0749) teacher/usage_max 0.4493 (0.5343) teacher/usage_min 0.2008 (0.1735) teacher/usage_std 0.1021 (0.1544) nleep/row_max_mean 1519.2114 (1532.3447) nleep/row_max_std 60.8757 (53.1109) nleep/row_min_mean 1496.0862 (1507.1028) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [120/181] time 0.132 (0.127) data 0.000 (0.003) loss 1.9944 (1.8763) teacher_loss 0.1141 (0.1622) loss_zs_kd 0.0703 (0.0495) loss_oracle 0.9352 (0.7616) kd_loss 1.3775 (1.3086) acc 96.8750 (94.2708) gate/entropy 1.0192 (1.0194) gate/usage_max 0.4224 (0.4223) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0560 (0.0766) teacher/usage_max 0.5779 (0.5329) teacher/usage_min 0.1372 (0.1748) teacher/usage_std 0.1831 (0.1533) nleep/row_max_mean 1559.7095 (1532.1351) nleep/row_max_std 42.1544 (53.5116) nleep/row_min_mean 1529.6158 (1507.0382) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [140/181] time 0.169 (0.131) data 0.000 (0.003) loss 1.9009 (1.8741) teacher_loss 0.2180 (0.1666) loss_zs_kd 0.0461 (0.0496) loss_oracle 0.7392 (0.7557) kd_loss 1.2902 (1.3048) acc 90.6250 (94.2857) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1084 (0.0793) teacher/usage_max 0.5427 (0.5313) teacher/usage_min 0.2198 (0.1766) teacher/usage_std 0.1482 (0.1519) nleep/row_max_mean 1527.5112 (1531.8250) nleep/row_max_std 66.0406 (53.9358) nleep/row_min_mean 1502.6064 (1506.9276) lr 1.9098e-04 eta 0:03:15
epoch [42/50] batch [160/181] time 0.170 (0.135) data 0.000 (0.002) loss 1.8513 (1.8664) teacher_loss 0.1163 (0.1668) loss_zs_kd 0.0439 (0.0492) loss_oracle 0.7833 (0.7446) kd_loss 1.3215 (1.3027) acc 96.8750 (94.2383) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0642 (0.0794) teacher/usage_max 0.5298 (0.5290) teacher/usage_min 0.2201 (0.1790) teacher/usage_std 0.1394 (0.1502) nleep/row_max_mean 1516.2328 (1531.4538) nleep/row_max_std 63.1824 (53.9410) nleep/row_min_mean 1491.3341 (1506.7335) lr 1.9098e-04 eta 0:03:18
epoch [42/50] batch [180/181] time 0.165 (0.137) data 0.000 (0.002) loss 1.7398 (1.8604) teacher_loss 0.1117 (0.1668) loss_zs_kd 0.0327 (0.0494) loss_oracle 0.6785 (0.7365) kd_loss 1.2726 (1.3006) acc 96.8750 (94.1840) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0718 (0.0808) teacher/usage_max 0.4875 (0.5279) teacher/usage_min 0.2527 (0.1811) teacher/usage_std 0.1091 (0.1492) nleep/row_max_mean 1536.8323 (1531.0169) nleep/row_max_std 45.9715 (53.8162) nleep/row_min_mean 1511.1653 (1506.4421) lr 1.9098e-04 eta 0:03:18
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,428
* accuracy: 97.2%
* error: 2.8%
* macro_f1: 97.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,658
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [43/50] batch [20/181] time 0.077 (0.125) data 0.000 (0.015) loss 2.1394 (1.8880) teacher_loss 0.1822 (0.1799) loss_zs_kd 0.0739 (0.0490) loss_oracle 0.8487 (0.7318) kd_loss 1.4959 (1.3177) acc 93.7500 (93.5938) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4224 (0.4223) gate/usage_min 0.1573 (0.1574) gate/usage_std 0.1245 (0.1244) teacher/entropy 0.0266 (0.0781) teacher/usage_max 0.6683 (0.5397) teacher/usage_min 0.1440 (0.1806) teacher/usage_std 0.2375 (0.1560) nleep/row_max_mean 1556.0519 (1533.4657) nleep/row_max_std 37.0147 (54.6569) nleep/row_min_mean 1527.9460 (1508.4109) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [40/181] time 0.220 (0.118) data 0.000 (0.008) loss 1.8238 (1.8546) teacher_loss 0.1517 (0.1729) loss_zs_kd 0.0342 (0.0451) loss_oracle 0.7736 (0.7265) kd_loss 1.2682 (1.2960) acc 96.8750 (93.6719) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0875 (0.0848) teacher/usage_max 0.4990 (0.5244) teacher/usage_min 0.2319 (0.1893) teacher/usage_std 0.1181 (0.1444) nleep/row_max_mean 1539.5416 (1533.8658) nleep/row_max_std 59.7482 (54.3114) nleep/row_min_mean 1514.3130 (1508.9313) lr 1.5567e-04 eta 0:02:45
epoch [43/50] batch [60/181] time 0.072 (0.117) data 0.001 (0.005) loss 2.1719 (1.8473) teacher_loss 0.3385 (0.1843) loss_zs_kd 0.0710 (0.0473) loss_oracle 0.7006 (0.7140) kd_loss 1.4476 (1.2824) acc 87.5000 (93.4375) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0777 (0.0901) teacher/usage_max 0.6707 (0.5206) teacher/usage_min 0.0979 (0.1914) teacher/usage_std 0.2447 (0.1418) nleep/row_max_mean 1535.4845 (1533.6786) nleep/row_max_std 47.3301 (52.9988) nleep/row_min_mean 1512.0942 (1509.0876) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [80/181] time 0.137 (0.112) data 0.000 (0.004) loss 1.6787 (1.8348) teacher_loss 0.1197 (0.1802) loss_zs_kd 0.0512 (0.0472) loss_oracle 0.7438 (0.7142) kd_loss 1.1616 (1.2739) acc 100.0000 (93.7109) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1309 (0.0927) teacher/usage_max 0.4344 (0.5156) teacher/usage_min 0.1466 (0.1889) teacher/usage_std 0.1322 (0.1406) nleep/row_max_mean 1540.2976 (1534.2186) nleep/row_max_std 53.0770 (52.6446) nleep/row_min_mean 1515.1069 (1509.4751) lr 1.5567e-04 eta 0:02:33
epoch [43/50] batch [100/181] time 0.101 (0.112) data 0.000 (0.003) loss 1.7372 (1.8376) teacher_loss 0.1476 (0.1895) loss_zs_kd 0.0506 (0.0468) loss_oracle 0.7768 (0.7120) kd_loss 1.1758 (1.2687) acc 93.7500 (92.9375) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1290 (0.0954) teacher/usage_max 0.4471 (0.5131) teacher/usage_min 0.1848 (0.1829) teacher/usage_std 0.1099 (0.1417) nleep/row_max_mean 1529.9990 (1534.2332) nleep/row_max_std 61.3878 (53.0319) nleep/row_min_mean 1502.2358 (1509.4361) lr 1.5567e-04 eta 0:02:31
epoch [43/50] batch [120/181] time 0.162 (0.116) data 0.000 (0.003) loss 1.5959 (1.8352) teacher_loss 0.0711 (0.1945) loss_zs_kd 0.0382 (0.0464) loss_oracle 0.5928 (0.7053) kd_loss 1.2093 (1.2649) acc 96.8750 (92.7865) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0422 (0.0952) teacher/usage_max 0.5311 (0.5109) teacher/usage_min 0.0765 (0.1745) teacher/usage_std 0.1902 (0.1443) nleep/row_max_mean 1525.3550 (1533.0795) nleep/row_max_std 52.4973 (53.0541) nleep/row_min_mean 1498.3594 (1508.2112) lr 1.5567e-04 eta 0:02:34
epoch [43/50] batch [140/181] time 0.089 (0.117) data 0.000 (0.002) loss 1.5439 (1.8320) teacher_loss 0.1533 (0.1939) loss_zs_kd 0.0316 (0.0461) loss_oracle 0.6206 (0.7038) kd_loss 1.0645 (1.2632) acc 93.7500 (92.7232) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0817 (0.0942) teacher/usage_max 0.5261 (0.5104) teacher/usage_min 0.1883 (0.1688) teacher/usage_std 0.1420 (0.1465) nleep/row_max_mean 1532.7144 (1532.2382) nleep/row_max_std 54.0543 (52.6613) nleep/row_min_mean 1506.2484 (1507.4499) lr 1.5567e-04 eta 0:02:32
epoch [43/50] batch [160/181] time 0.095 (0.117) data 0.000 (0.002) loss 1.8442 (1.8372) teacher_loss 0.1501 (0.1975) loss_zs_kd 0.0547 (0.0460) loss_oracle 0.7536 (0.7054) kd_loss 1.2900 (1.2639) acc 93.7500 (92.6172) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1574) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0934 (0.0924) teacher/usage_max 0.5263 (0.5125) teacher/usage_min 0.0436 (0.1608) teacher/usage_std 0.2086 (0.1508) nleep/row_max_mean 1542.4531 (1531.9044) nleep/row_max_std 54.3727 (52.6129) nleep/row_min_mean 1513.2476 (1506.9522) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [180/181] time 0.080 (0.117) data 0.000 (0.002) loss 1.6405 (1.8413) teacher_loss 0.1395 (0.2011) loss_zs_kd 0.0497 (0.0461) loss_oracle 0.6229 (0.7053) kd_loss 1.1647 (1.2645) acc 93.7500 (92.4826) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0932 (0.0914) teacher/usage_max 0.5411 (0.5154) teacher/usage_min 0.0605 (0.1525) teacher/usage_std 0.2016 (0.1554) nleep/row_max_mean 1518.9930 (1531.6302) nleep/row_max_std 57.9243 (52.7147) nleep/row_min_mean 1489.1567 (1506.3654) lr 1.5567e-04 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,422
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,657
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [44/50] batch [20/181] time 0.154 (0.165) data 0.000 (0.014) loss 1.7802 (1.8164) teacher_loss 0.2220 (0.1922) loss_zs_kd 0.0600 (0.0462) loss_oracle 0.6510 (0.6912) kd_loss 1.2028 (1.2555) acc 90.6250 (93.2812) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0685 (0.0717) teacher/usage_max 0.5209 (0.5253) teacher/usage_min 0.0668 (0.0860) teacher/usage_std 0.1936 (0.1862) nleep/row_max_mean 1533.2756 (1524.5197) nleep/row_max_std 46.4595 (49.2985) nleep/row_min_mean 1505.0189 (1498.0471) lr 1.2369e-04 eta 0:03:25
epoch [44/50] batch [40/181] time 0.134 (0.156) data 0.000 (0.007) loss 1.8826 (1.8123) teacher_loss 0.1844 (0.1959) loss_zs_kd 0.0283 (0.0460) loss_oracle 0.7493 (0.6940) kd_loss 1.3094 (1.2464) acc 90.6250 (93.2031) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1574) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0816 (0.0781) teacher/usage_max 0.5342 (0.5252) teacher/usage_min 0.0874 (0.0840) teacher/usage_std 0.1852 (0.1874) nleep/row_max_mean 1520.7300 (1526.4236) nleep/row_max_std 46.8845 (49.3850) nleep/row_min_mean 1493.6960 (1499.4909) lr 1.2369e-04 eta 0:03:11
epoch [44/50] batch [60/181] time 0.136 (0.150) data 0.001 (0.005) loss 1.9329 (1.8194) teacher_loss 0.2618 (0.2052) loss_zs_kd 0.0391 (0.0443) loss_oracle 0.7448 (0.7051) kd_loss 1.2792 (1.2394) acc 84.3750 (92.4479) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1088 (0.0771) teacher/usage_max 0.5311 (0.5256) teacher/usage_min 0.0621 (0.0869) teacher/usage_std 0.1984 (0.1862) nleep/row_max_mean 1525.9431 (1527.1782) nleep/row_max_std 51.1750 (50.0943) nleep/row_min_mean 1499.5613 (1499.9238) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [80/181] time 0.137 (0.149) data 0.000 (0.004) loss 1.8312 (1.8174) teacher_loss 0.3144 (0.2089) loss_zs_kd 0.0446 (0.0430) loss_oracle 0.6959 (0.7074) kd_loss 1.1466 (1.2333) acc 87.5000 (92.4219) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1354 (0.0794) teacher/usage_max 0.4235 (0.5279) teacher/usage_min 0.1815 (0.0874) teacher/usage_std 0.1080 (0.1867) nleep/row_max_mean 1520.2495 (1527.3484) nleep/row_max_std 46.1388 (50.5724) nleep/row_min_mean 1493.6228 (1499.8600) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [100/181] time 0.155 (0.149) data 0.000 (0.003) loss 1.6961 (1.8245) teacher_loss 0.1729 (0.2138) loss_zs_kd 0.0243 (0.0422) loss_oracle 0.6991 (0.7128) kd_loss 1.1615 (1.2331) acc 96.8750 (92.0312) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1436 (0.0787) teacher/usage_max 0.4645 (0.5289) teacher/usage_min 0.0887 (0.0832) teacher/usage_std 0.1731 (0.1891) nleep/row_max_mean 1518.9561 (1527.7758) nleep/row_max_std 56.7322 (51.0516) nleep/row_min_mean 1494.1747 (1499.8496) lr 1.2369e-04 eta 0:02:53
epoch [44/50] batch [120/181] time 0.093 (0.139) data 0.000 (0.002) loss 1.9943 (1.8348) teacher_loss 0.4069 (0.2229) loss_zs_kd 0.0642 (0.0417) loss_oracle 0.6912 (0.7150) kd_loss 1.2096 (1.2335) acc 84.3750 (91.6146) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0204 (0.0749) teacher/usage_max 0.5987 (0.5331) teacher/usage_min 0.0313 (0.0784) teacher/usage_std 0.2331 (0.1931) nleep/row_max_mean 1526.8663 (1528.3296) nleep/row_max_std 51.8197 (50.8874) nleep/row_min_mean 1493.0503 (1499.9373) lr 1.2369e-04 eta 0:02:39
epoch [44/50] batch [140/181] time 0.113 (0.137) data 0.000 (0.002) loss 1.5803 (1.8289) teacher_loss 0.1645 (0.2250) loss_zs_kd 0.0357 (0.0425) loss_oracle 0.6835 (0.7136) kd_loss 1.0562 (1.2259) acc 93.7500 (91.7188) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0878 (0.0769) teacher/usage_max 0.6829 (0.5347) teacher/usage_min 0.0348 (0.0759) teacher/usage_std 0.2670 (0.1952) nleep/row_max_mean 1514.4719 (1528.1422) nleep/row_max_std 63.9665 (50.7794) nleep/row_min_mean 1483.9905 (1499.6360) lr 1.2369e-04 eta 0:02:34
epoch [44/50] batch [160/181] time 0.085 (0.136) data 0.000 (0.002) loss 1.9832 (1.8298) teacher_loss 0.3934 (0.2298) loss_zs_kd 0.0651 (0.0423) loss_oracle 0.7669 (0.7128) kd_loss 1.1738 (1.2225) acc 84.3750 (91.5625) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0576 (0.0765) teacher/usage_max 0.5732 (0.5377) teacher/usage_min 0.0554 (0.0724) teacher/usage_std 0.2131 (0.1980) nleep/row_max_mean 1518.5317 (1527.1465) nleep/row_max_std 49.4951 (50.8976) nleep/row_min_mean 1485.7754 (1498.5370) lr 1.2369e-04 eta 0:02:30
epoch [44/50] batch [180/181] time 0.079 (0.132) data 0.000 (0.002) loss 1.7304 (1.8268) teacher_loss 0.0977 (0.2273) loss_zs_kd 0.0366 (0.0412) loss_oracle 0.7941 (0.7131) kd_loss 1.2173 (1.2224) acc 96.8750 (91.6146) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0902 (0.0753) teacher/usage_max 0.5320 (0.5413) teacher/usage_min 0.0189 (0.0671) teacher/usage_std 0.2249 (0.2018) nleep/row_max_mean 1536.1790 (1527.1694) nleep/row_max_std 56.5627 (50.9443) nleep/row_min_mean 1500.6576 (1498.3880) lr 1.2369e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,412
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,658
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [45/50] batch [20/181] time 0.127 (0.137) data 0.001 (0.015) loss 1.5220 (1.8077) teacher_loss 0.2303 (0.2642) loss_zs_kd 0.0225 (0.0341) loss_oracle 0.5068 (0.7012) kd_loss 1.0271 (1.1759) acc 90.6250 (89.3750) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1117 (0.0717) teacher/usage_max 0.6538 (0.5790) teacher/usage_min 0.0689 (0.0379) teacher/usage_std 0.2420 (0.2299) nleep/row_max_mean 1517.9541 (1529.6754) nleep/row_max_std 52.1025 (53.6398) nleep/row_min_mean 1488.6731 (1497.2724) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [40/181] time 0.085 (0.129) data 0.000 (0.008) loss 1.5871 (1.7847) teacher_loss 0.2525 (0.2430) loss_zs_kd 0.0588 (0.0362) loss_oracle 0.6344 (0.7005) kd_loss 0.9880 (1.1733) acc 84.3750 (90.2344) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0822 (0.0665) teacher/usage_max 0.6882 (0.5851) teacher/usage_min 0.1043 (0.0438) teacher/usage_std 0.2544 (0.2297) nleep/row_max_mean 1532.5427 (1527.1103) nleep/row_max_std 59.2215 (52.9457) nleep/row_min_mean 1495.4618 (1495.1605) lr 9.5173e-05 eta 0:02:14
epoch [45/50] batch [60/181] time 0.185 (0.129) data 0.000 (0.005) loss 1.7865 (1.7898) teacher_loss 0.2443 (0.2534) loss_zs_kd 0.0489 (0.0357) loss_oracle 0.7757 (0.6998) kd_loss 1.1299 (1.1687) acc 93.7500 (90.3646) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0278 (0.0640) teacher/usage_max 0.6410 (0.5820) teacher/usage_min 0.0623 (0.0535) teacher/usage_std 0.2377 (0.2248) nleep/row_max_mean 1541.6606 (1527.9574) nleep/row_max_std 57.7346 (52.5303) nleep/row_min_mean 1503.3479 (1495.8409) lr 9.5173e-05 eta 0:02:12
epoch [45/50] batch [80/181] time 0.154 (0.126) data 0.000 (0.004) loss 1.7180 (1.7809) teacher_loss 0.1659 (0.2508) loss_zs_kd 0.0296 (0.0355) loss_oracle 0.7204 (0.7029) kd_loss 1.1772 (1.1609) acc 96.8750 (90.5078) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0591 (0.0636) teacher/usage_max 0.5801 (0.5915) teacher/usage_min 0.0437 (0.0518) teacher/usage_std 0.2211 (0.2285) nleep/row_max_mean 1530.0116 (1528.4625) nleep/row_max_std 51.5607 (52.6867) nleep/row_min_mean 1496.5204 (1496.1862) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [100/181] time 0.156 (0.133) data 0.000 (0.003) loss 1.7932 (1.7759) teacher_loss 0.2933 (0.2500) loss_zs_kd 0.0292 (0.0355) loss_oracle 0.6665 (0.7033) kd_loss 1.1521 (1.1566) acc 87.5000 (90.5312) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0563 (0.0613) teacher/usage_max 0.6385 (0.5979) teacher/usage_min 0.0133 (0.0505) teacher/usage_std 0.2554 (0.2306) nleep/row_max_mean 1522.8696 (1529.6313) nleep/row_max_std 52.2065 (52.1464) nleep/row_min_mean 1489.1776 (1496.8861) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [120/181] time 0.166 (0.137) data 0.000 (0.003) loss 1.6124 (1.7665) teacher_loss 0.2081 (0.2461) loss_zs_kd 0.0241 (0.0357) loss_oracle 0.5721 (0.7025) kd_loss 1.1062 (1.1513) acc 93.7500 (90.7292) gate/entropy 1.0196 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0546 (0.0618) teacher/usage_max 0.6683 (0.5999) teacher/usage_min 0.0321 (0.0529) teacher/usage_std 0.2608 (0.2300) nleep/row_max_mean 1512.3760 (1528.9747) nleep/row_max_std 61.2058 (52.7768) nleep/row_min_mean 1477.1995 (1496.1526) lr 9.5173e-05 eta 0:02:12
epoch [45/50] batch [140/181] time 0.144 (0.139) data 0.000 (0.002) loss 1.7518 (1.7638) teacher_loss 0.1834 (0.2480) loss_zs_kd 0.0445 (0.0360) loss_oracle 0.7417 (0.7050) kd_loss 1.1752 (1.1453) acc 90.6250 (90.6027) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0338 (0.0624) teacher/usage_max 0.6191 (0.6043) teacher/usage_min 0.0323 (0.0534) teacher/usage_std 0.2398 (0.2317) nleep/row_max_mean 1532.3345 (1528.7981) nleep/row_max_std 55.9036 (53.4370) nleep/row_min_mean 1498.5173 (1495.8372) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [160/181] time 0.190 (0.141) data 0.001 (0.002) loss 1.9198 (1.7643) teacher_loss 0.2174 (0.2491) loss_zs_kd 0.0551 (0.0362) loss_oracle 0.8669 (0.7065) kd_loss 1.2414 (1.1438) acc 90.6250 (90.5469) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0342 (0.0622) teacher/usage_max 0.5527 (0.6045) teacher/usage_min 0.0311 (0.0542) teacher/usage_std 0.2209 (0.2313) nleep/row_max_mean 1532.7350 (1528.9857) nleep/row_max_std 54.3264 (53.2458) nleep/row_min_mean 1499.8005 (1495.9154) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [180/181] time 0.146 (0.142) data 0.000 (0.002) loss 1.8019 (1.7641) teacher_loss 0.2279 (0.2510) loss_zs_kd 0.0331 (0.0368) loss_oracle 0.7384 (0.7078) kd_loss 1.1881 (1.1408) acc 90.6250 (90.3993) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0570 (0.0626) teacher/usage_max 0.5932 (0.6060) teacher/usage_min 0.0215 (0.0550) teacher/usage_std 0.2362 (0.2315) nleep/row_max_mean 1526.8601 (1529.3250) nleep/row_max_std 55.2773 (53.2545) nleep/row_min_mean 1494.7130 (1495.9921) lr 9.5173e-05 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,401
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [46/50] batch [20/181] time 0.087 (0.110) data 0.000 (0.016) loss 1.4754 (1.6945) teacher_loss 0.1646 (0.2323) loss_zs_kd 0.0257 (0.0318) loss_oracle 0.6757 (0.7099) kd_loss 0.9601 (1.0913) acc 93.7500 (91.4062) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0597 (0.0592) teacher/usage_max 0.7447 (0.6617) teacher/usage_min 0.0992 (0.0492) teacher/usage_std 0.2918 (0.2565) nleep/row_max_mean 1526.1849 (1533.5591) nleep/row_max_std 57.7910 (48.9168) nleep/row_min_mean 1489.1423 (1497.5760) lr 7.0224e-05 eta 0:01:37
epoch [46/50] batch [40/181] time 0.077 (0.116) data 0.000 (0.008) loss 1.5979 (1.6995) teacher_loss 0.2376 (0.2457) loss_zs_kd 0.0321 (0.0354) loss_oracle 0.6806 (0.7023) kd_loss 1.0039 (1.0850) acc 87.5000 (90.1562) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0829 (0.0588) teacher/usage_max 0.6674 (0.6654) teacher/usage_min 0.1081 (0.0523) teacher/usage_std 0.2410 (0.2580) nleep/row_max_mean 1520.6432 (1532.3625) nleep/row_max_std 56.9541 (48.0712) nleep/row_min_mean 1487.7505 (1496.2574) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [60/181] time 0.096 (0.110) data 0.001 (0.005) loss 1.5313 (1.7139) teacher_loss 0.1473 (0.2469) loss_zs_kd 0.0212 (0.0366) loss_oracle 0.7658 (0.7149) kd_loss 0.9905 (1.0912) acc 100.0000 (90.4167) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1013 (0.0639) teacher/usage_max 0.6773 (0.6492) teacher/usage_min 0.0934 (0.0589) teacher/usage_std 0.2495 (0.2479) nleep/row_max_mean 1544.8380 (1531.9567) nleep/row_max_std 44.9509 (47.6748) nleep/row_min_mean 1508.6855 (1496.3393) lr 7.0224e-05 eta 0:01:32
epoch [46/50] batch [80/181] time 0.196 (0.111) data 0.000 (0.004) loss 1.6893 (1.7083) teacher_loss 0.2254 (0.2496) loss_zs_kd 0.0479 (0.0371) loss_oracle 0.7278 (0.7073) kd_loss 1.0761 (1.0865) acc 90.6250 (90.3125) gate/entropy 1.0196 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1028 (0.0658) teacher/usage_max 0.6272 (0.6501) teacher/usage_min 0.0547 (0.0604) teacher/usage_std 0.2340 (0.2483) nleep/row_max_mean 1507.3083 (1530.9290) nleep/row_max_std 54.6411 (48.2804) nleep/row_min_mean 1475.9902 (1495.3930) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [100/181] time 0.160 (0.114) data 0.000 (0.003) loss 1.8378 (1.7132) teacher_loss 0.1786 (0.2470) loss_zs_kd 0.0237 (0.0363) loss_oracle 0.8084 (0.7102) kd_loss 1.2432 (1.0929) acc 90.6250 (90.3750) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0882 (0.0654) teacher/usage_max 0.4737 (0.6455) teacher/usage_min 0.0789 (0.0589) teacher/usage_std 0.1802 (0.2464) nleep/row_max_mean 1536.3694 (1531.6011) nleep/row_max_std 41.6338 (48.7165) nleep/row_min_mean 1500.2819 (1495.8936) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [120/181] time 0.131 (0.115) data 0.000 (0.003) loss 1.7032 (1.7168) teacher_loss 0.2973 (0.2505) loss_zs_kd 0.0231 (0.0366) loss_oracle 0.7315 (0.7116) kd_loss 1.0286 (1.0922) acc 84.3750 (90.0521) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0698 (0.0649) teacher/usage_max 0.7641 (0.6469) teacher/usage_min 0.0000 (0.0586) teacher/usage_std 0.3194 (0.2470) nleep/row_max_mean 1534.0801 (1531.8419) nleep/row_max_std 51.7820 (49.2725) nleep/row_min_mean 1491.8904 (1495.9220) lr 7.0224e-05 eta 0:01:30
epoch [46/50] batch [140/181] time 0.081 (0.115) data 0.000 (0.002) loss 1.8039 (1.7176) teacher_loss 0.2894 (0.2463) loss_zs_kd 0.0321 (0.0371) loss_oracle 0.7291 (0.7139) kd_loss 1.1339 (1.0957) acc 90.6250 (90.3125) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0090 (0.0637) teacher/usage_max 0.7180 (0.6435) teacher/usage_min 0.0008 (0.0594) teacher/usage_std 0.2951 (0.2448) nleep/row_max_mean 1547.0081 (1532.2091) nleep/row_max_std 54.7054 (49.9263) nleep/row_min_mean 1507.2375 (1496.2457) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [160/181] time 0.065 (0.115) data 0.000 (0.002) loss 1.6758 (1.7166) teacher_loss 0.1915 (0.2476) loss_zs_kd 0.0592 (0.0372) loss_oracle 0.6799 (0.7091) kd_loss 1.1148 (1.0958) acc 90.6250 (90.3125) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0402 (0.0650) teacher/usage_max 0.6563 (0.6419) teacher/usage_min 0.0500 (0.0595) teacher/usage_std 0.2491 (0.2440) nleep/row_max_mean 1527.3145 (1531.6559) nleep/row_max_std 48.8339 (50.0699) nleep/row_min_mean 1487.9198 (1495.7163) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [180/181] time 0.075 (0.114) data 0.000 (0.002) loss 1.6086 (1.7130) teacher_loss 0.1999 (0.2463) loss_zs_kd 0.0322 (0.0370) loss_oracle 0.7065 (0.7075) kd_loss 1.0394 (1.0944) acc 93.7500 (90.3819) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0638 (0.0639) teacher/usage_max 0.7104 (0.6442) teacher/usage_min 0.0487 (0.0595) teacher/usage_std 0.2779 (0.2451) nleep/row_max_mean 1531.9575 (1531.6430) nleep/row_max_std 53.9996 (50.0224) nleep/row_min_mean 1492.0524 (1495.5030) lr 7.0224e-05 eta 0:01:22
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [47/50] batch [20/181] time 0.165 (0.175) data 0.000 (0.015) loss 1.7710 (1.7300) teacher_loss 0.3516 (0.2943) loss_zs_kd 0.0342 (0.0381) loss_oracle 0.5802 (0.6844) kd_loss 1.1122 (1.0744) acc 84.3750 (89.6875) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.1106 (0.0706) teacher/usage_max 0.6090 (0.6427) teacher/usage_min 0.0279 (0.0702) teacher/usage_std 0.2382 (0.2408) nleep/row_max_mean 1520.1158 (1526.4365) nleep/row_max_std 45.7839 (52.3529) nleep/row_min_mean 1488.0568 (1490.1974) lr 4.8943e-05 eta 0:02:03
epoch [47/50] batch [40/181] time 0.169 (0.166) data 0.000 (0.007) loss 1.8276 (1.7279) teacher_loss 0.3446 (0.2668) loss_zs_kd 0.0531 (0.0381) loss_oracle 0.7164 (0.6990) kd_loss 1.0982 (1.0925) acc 87.5000 (90.5469) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0525 (0.0704) teacher/usage_max 0.6485 (0.6405) teacher/usage_min 0.0621 (0.0566) teacher/usage_std 0.2414 (0.2451) nleep/row_max_mean 1530.8506 (1527.9522) nleep/row_max_std 47.2886 (50.0493) nleep/row_min_mean 1497.4814 (1491.2200) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [60/181] time 0.136 (0.163) data 0.001 (0.005) loss 1.6922 (1.7112) teacher_loss 0.2626 (0.2570) loss_zs_kd 0.0262 (0.0372) loss_oracle 0.6960 (0.6926) kd_loss 1.0685 (1.0894) acc 93.7500 (90.7812) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0331 (0.0689) teacher/usage_max 0.7290 (0.6441) teacher/usage_min 0.0317 (0.0581) teacher/usage_std 0.2923 (0.2474) nleep/row_max_mean 1536.2981 (1528.0514) nleep/row_max_std 42.4495 (48.6752) nleep/row_min_mean 1496.5701 (1491.2452) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [80/181] time 0.175 (0.163) data 0.000 (0.004) loss 1.7275 (1.7242) teacher_loss 0.1200 (0.2476) loss_zs_kd 0.0425 (0.0375) loss_oracle 0.7673 (0.7085) kd_loss 1.2026 (1.1036) acc 96.8750 (91.0156) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0424 (0.0665) teacher/usage_max 0.5604 (0.6383) teacher/usage_min 0.0541 (0.0521) teacher/usage_std 0.2100 (0.2467) nleep/row_max_mean 1545.3358 (1529.9170) nleep/row_max_std 45.8584 (47.8598) nleep/row_min_mean 1506.3794 (1493.0402) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [100/181] time 0.112 (0.151) data 0.001 (0.003) loss 1.7010 (1.7239) teacher_loss 0.2933 (0.2466) loss_zs_kd 0.0442 (0.0373) loss_oracle 0.6241 (0.7099) kd_loss 1.0735 (1.1038) acc 87.5000 (90.7188) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0756 (0.0655) teacher/usage_max 0.6654 (0.6406) teacher/usage_min 0.0465 (0.0515) teacher/usage_std 0.2547 (0.2477) nleep/row_max_mean 1526.2753 (1530.1590) nleep/row_max_std 52.8657 (48.6431) nleep/row_min_mean 1492.3735 (1493.3467) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [120/181] time 0.078 (0.145) data 0.000 (0.003) loss 1.4546 (1.7249) teacher_loss 0.1935 (0.2441) loss_zs_kd 0.0322 (0.0379) loss_oracle 0.5892 (0.7113) kd_loss 0.9504 (1.1062) acc 93.7500 (90.7552) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0882 (0.0652) teacher/usage_max 0.8100 (0.6384) teacher/usage_min 0.0153 (0.0515) teacher/usage_std 0.3433 (0.2468) nleep/row_max_mean 1530.9636 (1530.5693) nleep/row_max_std 53.5072 (48.7701) nleep/row_min_mean 1495.6431 (1493.7036) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [140/181] time 0.089 (0.140) data 0.000 (0.002) loss 1.6312 (1.7183) teacher_loss 0.1489 (0.2379) loss_zs_kd 0.0167 (0.0376) loss_oracle 0.7394 (0.7104) kd_loss 1.1043 (1.1064) acc 93.7500 (91.0714) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0583 (0.0660) teacher/usage_max 0.6969 (0.6354) teacher/usage_min 0.0020 (0.0536) teacher/usage_std 0.2846 (0.2445) nleep/row_max_mean 1542.2515 (1530.4306) nleep/row_max_std 47.0420 (48.8242) nleep/row_min_mean 1504.2062 (1493.6554) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [160/181] time 0.087 (0.135) data 0.000 (0.002) loss 1.4473 (1.7240) teacher_loss 0.1653 (0.2433) loss_zs_kd 0.0239 (0.0377) loss_oracle 0.6298 (0.7108) kd_loss 0.9551 (1.1065) acc 96.8750 (90.8789) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0622 (0.0660) teacher/usage_max 0.8159 (0.6359) teacher/usage_min 0.0307 (0.0533) teacher/usage_std 0.3449 (0.2449) nleep/row_max_mean 1522.9092 (1530.0822) nleep/row_max_std 62.2377 (49.6708) nleep/row_min_mean 1486.8038 (1493.3733) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [180/181] time 0.082 (0.130) data 0.000 (0.002) loss 1.6525 (1.7166) teacher_loss 0.1448 (0.2399) loss_zs_kd 0.0229 (0.0373) loss_oracle 0.7576 (0.7074) kd_loss 1.1174 (1.1043) acc 93.7500 (91.0938) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0603 (0.0652) teacher/usage_max 0.6535 (0.6388) teacher/usage_min 0.0296 (0.0533) teacher/usage_std 0.2550 (0.2460) nleep/row_max_mean 1526.2268 (1529.6604) nleep/row_max_std 69.2938 (51.0629) nleep/row_min_mean 1487.3035 (1492.9243) lr 4.8943e-05 eta 0:01:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [48/50] batch [20/181] time 0.088 (0.135) data 0.000 (0.014) loss 1.5866 (1.7065) teacher_loss 0.0937 (0.2200) loss_zs_kd 0.0187 (0.0396) loss_oracle 0.6766 (0.7122) kd_loss 1.1452 (1.1105) acc 96.8750 (90.9375) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0790 (0.0611) teacher/usage_max 0.6063 (0.6424) teacher/usage_min 0.0297 (0.0531) teacher/usage_std 0.2364 (0.2461) nleep/row_max_mean 1525.9666 (1528.4987) nleep/row_max_std 56.7923 (56.5068) nleep/row_min_mean 1490.2402 (1492.6173) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [40/181] time 0.197 (0.128) data 0.000 (0.007) loss 1.7817 (1.7156) teacher_loss 0.2666 (0.2317) loss_zs_kd 0.0636 (0.0374) loss_oracle 0.7547 (0.7156) kd_loss 1.1060 (1.1074) acc 90.6250 (90.8594) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0888 (0.0632) teacher/usage_max 0.6166 (0.6332) teacher/usage_min 0.0492 (0.0602) teacher/usage_std 0.2316 (0.2400) nleep/row_max_mean 1533.7505 (1528.6089) nleep/row_max_std 62.6902 (55.9241) nleep/row_min_mean 1494.8993 (1492.3632) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [60/181] time 0.094 (0.124) data 0.000 (0.005) loss 1.8249 (1.7210) teacher_loss 0.2355 (0.2392) loss_zs_kd 0.0545 (0.0391) loss_oracle 0.7783 (0.7185) kd_loss 1.1730 (1.1031) acc 90.6250 (90.8854) gate/entropy 1.0193 (1.0194) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0742 (0.0630) teacher/usage_max 0.5890 (0.6408) teacher/usage_min 0.0235 (0.0562) teacher/usage_std 0.2340 (0.2448) nleep/row_max_mean 1550.8984 (1529.2128) nleep/row_max_std 47.7986 (56.0280) nleep/row_min_mean 1510.8662 (1492.3772) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [80/181] time 0.160 (0.126) data 0.000 (0.004) loss 1.6301 (1.7216) teacher_loss 0.2522 (0.2447) loss_zs_kd 0.0472 (0.0392) loss_oracle 0.7159 (0.7196) kd_loss 0.9964 (1.0975) acc 90.6250 (90.8594) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.1074 (0.0647) teacher/usage_max 0.6255 (0.6450) teacher/usage_min 0.1322 (0.0554) teacher/usage_std 0.2115 (0.2467) nleep/row_max_mean 1522.3372 (1528.5188) nleep/row_max_std 61.3492 (56.0897) nleep/row_min_mean 1488.3435 (1491.8896) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [100/181] time 0.131 (0.132) data 0.000 (0.003) loss 1.6015 (1.7214) teacher_loss 0.0603 (0.2428) loss_zs_kd 0.0207 (0.0390) loss_oracle 0.7394 (0.7155) kd_loss 1.1612 (1.1014) acc 100.0000 (91.1875) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0576 (0.0631) teacher/usage_max 0.5817 (0.6437) teacher/usage_min 0.0596 (0.0541) teacher/usage_std 0.2139 (0.2461) nleep/row_max_mean 1523.8196 (1528.0724) nleep/row_max_std 51.0203 (56.1109) nleep/row_min_mean 1487.0061 (1491.4062) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [120/181] time 0.166 (0.136) data 0.000 (0.003) loss 1.9777 (1.7173) teacher_loss 0.3088 (0.2445) loss_zs_kd 0.0213 (0.0388) loss_oracle 0.7817 (0.7113) kd_loss 1.2674 (1.0978) acc 87.5000 (90.9375) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0248 (0.0627) teacher/usage_max 0.5641 (0.6480) teacher/usage_min 0.0025 (0.0545) teacher/usage_std 0.2399 (0.2484) nleep/row_max_mean 1526.6407 (1528.3795) nleep/row_max_std 53.3014 (55.9082) nleep/row_min_mean 1490.8920 (1491.6545) lr 3.1417e-05 eta 0:00:57
epoch [48/50] batch [140/181] time 0.160 (0.140) data 0.000 (0.002) loss 1.7835 (1.7198) teacher_loss 0.3017 (0.2428) loss_zs_kd 0.0509 (0.0390) loss_oracle 0.7184 (0.7110) kd_loss 1.0972 (1.1020) acc 84.3750 (91.0714) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0583 (0.0617) teacher/usage_max 0.6717 (0.6436) teacher/usage_min 0.0338 (0.0553) teacher/usage_std 0.2619 (0.2459) nleep/row_max_mean 1521.9584 (1528.3907) nleep/row_max_std 57.0391 (55.9816) nleep/row_min_mean 1484.6295 (1491.6754) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [160/181] time 0.168 (0.142) data 0.000 (0.002) loss 1.8377 (1.7222) teacher_loss 0.4254 (0.2446) loss_zs_kd 0.0474 (0.0396) loss_oracle 0.7437 (0.7119) kd_loss 1.0168 (1.1019) acc 81.2500 (90.9961) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0949 (0.0618) teacher/usage_max 0.7452 (0.6430) teacher/usage_min 0.0056 (0.0560) teacher/usage_std 0.3077 (0.2454) nleep/row_max_mean 1547.3552 (1528.6774) nleep/row_max_std 56.2598 (56.1246) nleep/row_min_mean 1508.1982 (1491.8913) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [180/181] time 0.176 (0.144) data 0.000 (0.002) loss 1.8049 (1.7207) teacher_loss 0.3427 (0.2448) loss_zs_kd 0.0427 (0.0393) loss_oracle 0.7249 (0.7111) kd_loss 1.0784 (1.1006) acc 87.5000 (90.9549) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0310 (0.0622) teacher/usage_max 0.7246 (0.6432) teacher/usage_min 0.0281 (0.0567) teacher/usage_std 0.2908 (0.2458) nleep/row_max_mean 1538.5757 (1529.5491) nleep/row_max_std 50.8399 (56.0616) nleep/row_min_mean 1495.7690 (1492.5575) lr 3.1417e-05 eta 0:00:52
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,659
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [49/50] batch [20/181] time 0.117 (0.141) data 0.001 (0.017) loss 1.6678 (1.6983) teacher_loss 0.1990 (0.2183) loss_zs_kd 0.0423 (0.0326) loss_oracle 0.7586 (0.7117) kd_loss 1.0684 (1.1078) acc 93.7500 (92.1875) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0642 (0.0718) teacher/usage_max 0.6639 (0.6219) teacher/usage_min 0.0652 (0.0608) teacher/usage_std 0.2484 (0.2355) nleep/row_max_mean 1535.6429 (1536.3090) nleep/row_max_std 56.6219 (49.9917) nleep/row_min_mean 1499.1963 (1498.7703) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [40/181] time 0.101 (0.123) data 0.000 (0.009) loss 1.9774 (1.6999) teacher_loss 0.4792 (0.2324) loss_zs_kd 0.0393 (0.0364) loss_oracle 0.7590 (0.7089) kd_loss 1.0991 (1.0948) acc 81.2500 (91.5625) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1326 (0.0685) teacher/usage_max 0.6057 (0.6377) teacher/usage_min 0.0225 (0.0608) teacher/usage_std 0.2397 (0.2415) nleep/row_max_mean 1543.7900 (1535.9576) nleep/row_max_std 45.5853 (49.4760) nleep/row_min_mean 1506.5897 (1498.2091) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [60/181] time 0.086 (0.120) data 0.001 (0.006) loss 1.9745 (1.7168) teacher_loss 0.5263 (0.2498) loss_zs_kd 0.0403 (0.0379) loss_oracle 0.6148 (0.7069) kd_loss 1.1206 (1.0946) acc 81.2500 (90.6250) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0762 (0.0690) teacher/usage_max 0.6162 (0.6402) teacher/usage_min 0.0471 (0.0577) teacher/usage_std 0.2324 (0.2435) nleep/row_max_mean 1526.8909 (1533.8815) nleep/row_max_std 42.0819 (49.0222) nleep/row_min_mean 1492.6644 (1496.5471) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [80/181] time 0.089 (0.119) data 0.000 (0.004) loss 1.6751 (1.7093) teacher_loss 0.1350 (0.2457) loss_zs_kd 0.0392 (0.0391) loss_oracle 0.7614 (0.7064) kd_loss 1.1399 (1.0908) acc 96.8750 (90.8984) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0551 (0.0669) teacher/usage_max 0.6170 (0.6502) teacher/usage_min 0.0484 (0.0555) teacher/usage_std 0.2321 (0.2489) nleep/row_max_mean 1526.8169 (1532.8560) nleep/row_max_std 41.9837 (48.7410) nleep/row_min_mean 1488.7549 (1495.6734) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [100/181] time 0.167 (0.122) data 0.000 (0.004) loss 1.6153 (1.7206) teacher_loss 0.2858 (0.2512) loss_zs_kd 0.0623 (0.0402) loss_oracle 0.7069 (0.7134) kd_loss 0.9449 (1.0926) acc 90.6250 (90.5625) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.1355 (0.0693) teacher/usage_max 0.5943 (0.6415) teacher/usage_min 0.1870 (0.0594) teacher/usage_std 0.1850 (0.2439) nleep/row_max_mean 1526.9509 (1530.6580) nleep/row_max_std 54.2574 (48.7192) nleep/row_min_mean 1489.3245 (1493.9597) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [120/181] time 0.072 (0.122) data 0.000 (0.003) loss 1.6553 (1.7149) teacher_loss 0.1991 (0.2462) loss_zs_kd 0.0155 (0.0393) loss_oracle 0.6920 (0.7096) kd_loss 1.1024 (1.0942) acc 93.7500 (90.7031) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1243) teacher/entropy 0.0550 (0.0691) teacher/usage_max 0.6505 (0.6397) teacher/usage_min 0.0534 (0.0594) teacher/usage_std 0.2452 (0.2426) nleep/row_max_mean 1528.0227 (1529.4402) nleep/row_max_std 63.7368 (49.0031) nleep/row_min_mean 1490.3540 (1492.8685) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [140/181] time 0.105 (0.121) data 0.000 (0.003) loss 2.0282 (1.7117) teacher_loss 0.4589 (0.2432) loss_zs_kd 0.0386 (0.0392) loss_oracle 0.8549 (0.7092) kd_loss 1.1226 (1.0943) acc 75.0000 (90.9152) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1243) teacher/entropy 0.0315 (0.0670) teacher/usage_max 0.6759 (0.6430) teacher/usage_min 0.0313 (0.0580) teacher/usage_std 0.2647 (0.2450) nleep/row_max_mean 1538.2122 (1529.5666) nleep/row_max_std 41.7897 (48.7246) nleep/row_min_mean 1498.8309 (1492.8509) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [160/181] time 0.161 (0.121) data 0.000 (0.002) loss 1.9012 (1.7151) teacher_loss 0.5588 (0.2462) loss_zs_kd 0.0431 (0.0387) loss_oracle 0.5181 (0.7093) kd_loss 1.0618 (1.0949) acc 81.2500 (90.6445) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1243) teacher/entropy 0.0441 (0.0670) teacher/usage_max 0.7249 (0.6423) teacher/usage_min 0.0312 (0.0579) teacher/usage_std 0.2902 (0.2452) nleep/row_max_mean 1523.7358 (1528.6413) nleep/row_max_std 40.5145 (48.7188) nleep/row_min_mean 1489.9155 (1492.1379) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [180/181] time 0.148 (0.124) data 0.000 (0.002) loss 1.6787 (1.7104) teacher_loss 0.2737 (0.2424) loss_zs_kd 0.0401 (0.0384) loss_oracle 0.7052 (0.7101) kd_loss 1.0323 (1.0938) acc 90.6250 (90.8160) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0809 (0.0674) teacher/usage_max 0.7169 (0.6427) teacher/usage_min 0.0320 (0.0580) teacher/usage_std 0.2856 (0.2453) nleep/row_max_mean 1522.7383 (1528.3136) nleep/row_max_std 50.9355 (48.6957) nleep/row_min_mean 1484.9128 (1491.8075) lr 1.7713e-05 eta 0:00:22
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,396
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,660
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [50/50] batch [20/181] time 0.138 (0.160) data 0.001 (0.016) loss 1.7421 (1.6449) teacher_loss 0.2855 (0.2182) loss_zs_kd 0.0680 (0.0349) loss_oracle 0.7142 (0.6959) kd_loss 1.0655 (1.0614) acc 87.5000 (91.8750) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4221 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0168 (0.0511) teacher/usage_max 0.7179 (0.6925) teacher/usage_min 0.0625 (0.0569) teacher/usage_std 0.2794 (0.2696) nleep/row_max_mean 1520.9838 (1527.0032) nleep/row_max_std 65.4056 (50.7779) nleep/row_min_mean 1482.4899 (1490.0166) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [40/181] time 0.164 (0.154) data 0.000 (0.008) loss 1.9852 (1.6937) teacher_loss 0.3392 (0.2368) loss_zs_kd 0.0664 (0.0351) loss_oracle 0.7182 (0.7060) kd_loss 1.2538 (1.0863) acc 87.5000 (91.3281) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0322 (0.0540) teacher/usage_max 0.5000 (0.6687) teacher/usage_min 0.0726 (0.0524) teacher/usage_std 0.1868 (0.2606) nleep/row_max_mean 1509.2837 (1526.5111) nleep/row_max_std 46.5250 (49.6565) nleep/row_min_mean 1476.4301 (1489.3658) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [60/181] time 0.156 (0.153) data 0.000 (0.005) loss 1.6781 (1.7043) teacher_loss 0.2585 (0.2385) loss_zs_kd 0.0236 (0.0357) loss_oracle 0.7240 (0.7116) kd_loss 1.0458 (1.0921) acc 96.8750 (91.5104) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0971 (0.0582) teacher/usage_max 0.6090 (0.6591) teacher/usage_min 0.1090 (0.0518) teacher/usage_std 0.2074 (0.2553) nleep/row_max_mean 1535.7332 (1527.3845) nleep/row_max_std 53.2755 (49.7792) nleep/row_min_mean 1496.0803 (1490.4095) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/181] time 0.076 (0.139) data 0.000 (0.004) loss 1.9401 (1.7127) teacher_loss 0.2150 (0.2374) loss_zs_kd 0.0450 (0.0376) loss_oracle 0.8433 (0.7182) kd_loss 1.2809 (1.0974) acc 90.6250 (91.5234) gate/entropy 1.0194 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0582 (0.0610) teacher/usage_max 0.5124 (0.6525) teacher/usage_min 0.0063 (0.0507) teacher/usage_std 0.2316 (0.2535) nleep/row_max_mean 1523.7177 (1527.6528) nleep/row_max_std 48.5603 (49.5731) nleep/row_min_mean 1489.1074 (1490.7633) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [100/181] time 0.106 (0.130) data 0.000 (0.003) loss 1.9369 (1.7266) teacher_loss 0.3358 (0.2464) loss_zs_kd 0.0517 (0.0373) loss_oracle 0.6867 (0.7147) kd_loss 1.2319 (1.1042) acc 87.5000 (91.2500) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0411 (0.0612) teacher/usage_max 0.5828 (0.6469) teacher/usage_min 0.0034 (0.0510) teacher/usage_std 0.2433 (0.2507) nleep/row_max_mean 1537.0420 (1527.8875) nleep/row_max_std 40.4552 (49.4292) nleep/row_min_mean 1499.8652 (1491.1099) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [120/181] time 0.075 (0.126) data 0.000 (0.003) loss 1.3763 (1.7218) teacher_loss 0.0856 (0.2407) loss_zs_kd 0.0300 (0.0380) loss_oracle 0.5657 (0.7172) kd_loss 0.9929 (1.1034) acc 93.7500 (91.5365) gate/entropy 1.0195 (1.0194) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0401 (0.0623) teacher/usage_max 0.7997 (0.6444) teacher/usage_min 0.0304 (0.0527) teacher/usage_std 0.3346 (0.2488) nleep/row_max_mean 1542.2515 (1528.6844) nleep/row_max_std 56.1596 (49.3894) nleep/row_min_mean 1504.3276 (1491.8383) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [140/181] time 0.087 (0.124) data 0.000 (0.002) loss 1.6197 (1.7209) teacher_loss 0.1154 (0.2409) loss_zs_kd 0.0295 (0.0377) loss_oracle 0.7010 (0.7129) kd_loss 1.1391 (1.1047) acc 93.7500 (91.5625) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1575 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0497 (0.0635) teacher/usage_max 0.6718 (0.6418) teacher/usage_min 0.0003 (0.0526) teacher/usage_std 0.2742 (0.2477) nleep/row_max_mean 1537.3634 (1529.1323) nleep/row_max_std 52.1253 (49.4356) nleep/row_min_mean 1496.7083 (1492.2721) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [160/181] time 0.085 (0.122) data 0.000 (0.002) loss 1.7070 (1.7141) teacher_loss 0.1839 (0.2375) loss_zs_kd 0.0475 (0.0370) loss_oracle 0.7135 (0.7114) kd_loss 1.1426 (1.1024) acc 96.8750 (91.5820) gate/entropy 1.0194 (1.0195) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1574 (0.1575) gate/usage_std 0.1244 (0.1244) teacher/entropy 0.0733 (0.0633) teacher/usage_max 0.6443 (0.6423) teacher/usage_min 0.0003 (0.0543) teacher/usage_std 0.2634 (0.2474) nleep/row_max_mean 1552.0530 (1530.1247) nleep/row_max_std 39.0913 (49.0439) nleep/row_min_mean 1514.1362 (1493.0830) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [180/181] time 0.084 (0.121) data 0.000 (0.002) loss 1.7443 (1.7120) teacher_loss 0.3163 (0.2366) loss_zs_kd 0.0481 (0.0368) loss_oracle 0.7073 (0.7128) kd_loss 1.0503 (1.1006) acc 87.5000 (91.5278) gate/entropy 1.0195 (1.0195) gate/usage_max 0.4221 (0.4222) gate/usage_min 0.1576 (0.1575) gate/usage_std 0.1243 (0.1244) teacher/entropy 0.0681 (0.0649) teacher/usage_max 0.6581 (0.6396) teacher/usage_min 0.0850 (0.0570) teacher/usage_std 0.2401 (0.2452) nleep/row_max_mean 1521.3516 (1530.7445) nleep/row_max_std 59.0952 (48.6619) nleep/row_min_mean 1484.5796 (1493.7360) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,659
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain p best val acc:      97.2%, epoch: 42 *******
******* Domain p best val test acc: 99.3%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:25:05

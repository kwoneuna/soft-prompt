Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'photo']
Target     ['sketch']
# classes  7
# train_x  4,241
# val      1,821
# test     3,928
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/132] time 0.133 (0.185) data 0.000 (0.020) loss 0.7117 (0.9677) teacher_loss 0.1695 (0.2716) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.5422 (0.6961) acc 96.8750 (90.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3315 (0.3315) gate/usage_std 0.0014 (0.0013) teacher/entropy 0.5553 (0.4027) teacher/usage_max 0.5274 (0.4094) teacher/usage_min 0.1753 (0.2521) teacher/usage_std 0.1460 (0.0667) nleep/row_max_mean 1563.9468 (1569.1332) nleep/row_max_std 65.8243 (65.1822) nleep/row_min_mean 1559.1780 (1560.5080) lr 1.0000e-05 eta 0:20:19
epoch [1/50] batch [40/132] time 0.164 (0.164) data 0.000 (0.010) loss 0.6843 (0.8998) teacher_loss 0.2066 (0.2593) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.4776 (0.6405) acc 93.7500 (91.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3317 (0.3316) gate/usage_std 0.0012 (0.0013) teacher/entropy 0.6212 (0.4584) teacher/usage_max 0.3598 (0.4179) teacher/usage_min 0.2885 (0.2522) teacher/usage_std 0.0318 (0.0705) nleep/row_max_mean 1568.9504 (1575.7017) nleep/row_max_std 61.2491 (59.8937) nleep/row_min_mean 1565.4955 (1568.9617) lr 1.0000e-05 eta 0:17:58
epoch [1/50] batch [60/132] time 0.133 (0.155) data 0.000 (0.007) loss 0.9164 (0.8438) teacher_loss 0.4239 (0.2498) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0004 (0.0001) kd_loss 0.4923 (0.5940) acc 81.2500 (91.4062) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3316) gate/usage_std 0.0013 (0.0013) teacher/entropy 0.6065 (0.5050) teacher/usage_max 0.4806 (0.4168) teacher/usage_min 0.2341 (0.2499) teacher/usage_std 0.1062 (0.0713) nleep/row_max_mean 1568.0109 (1578.5404) nleep/row_max_std 55.4464 (56.3488) nleep/row_min_mean 1563.9789 (1572.7875) lr 1.0000e-05 eta 0:16:55
epoch [1/50] batch [80/132] time 0.141 (0.154) data 0.000 (0.005) loss 0.6698 (0.7891) teacher_loss 0.3838 (0.2510) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (0.0001) kd_loss 0.2859 (0.5380) acc 84.3750 (91.4844) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3316) gate/usage_std 0.0014 (0.0013) teacher/entropy 0.8128 (0.5610) teacher/usage_max 0.4022 (0.4155) teacher/usage_min 0.2574 (0.2450) teacher/usage_std 0.0593 (0.0730) nleep/row_max_mean 1583.6486 (1580.2665) nleep/row_max_std 42.5413 (52.8175) nleep/row_min_mean 1581.2833 (1575.2688) lr 1.0000e-05 eta 0:16:41
epoch [1/50] batch [100/132] time 0.160 (0.155) data 0.000 (0.004) loss 0.4347 (0.7407) teacher_loss 0.1729 (0.2573) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0007 (0.0002) kd_loss 0.2614 (0.4833) acc 90.6250 (91.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3316 (0.3316) gate/usage_std 0.0013 (0.0013) teacher/entropy 0.8378 (0.6157) teacher/usage_max 0.4279 (0.4144) teacher/usage_min 0.2021 (0.2451) teacher/usage_std 0.0958 (0.0723) nleep/row_max_mean 1580.7913 (1580.4263) nleep/row_max_std 43.7025 (51.0050) nleep/row_min_mean 1578.9708 (1576.0377) lr 1.0000e-05 eta 0:16:47
epoch [1/50] batch [120/132] time 0.086 (0.147) data 0.000 (0.004) loss 0.6242 (0.6974) teacher_loss 0.3600 (0.2563) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0013 (0.0004) kd_loss 0.2635 (0.4408) acc 87.5000 (91.4844) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3316) gate/usage_std 0.0014 (0.0013) teacher/entropy 0.8350 (0.6582) teacher/usage_max 0.4516 (0.4168) teacher/usage_min 0.2491 (0.2438) teacher/usage_std 0.0861 (0.0738) nleep/row_max_mean 1583.1953 (1580.7419) nleep/row_max_std 43.5301 (49.3623) nleep/row_min_mean 1581.3408 (1576.7989) lr 1.0000e-05 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,801
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,474
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      98.9%, epoch: 1 *******
******* Domain s best val test acc: 88.4%, epoch: 1 *******
******* Domain s best test acc:     88.4%, epoch: 1 *******
epoch [2/50] batch [20/132] time 0.156 (0.134) data 0.000 (0.015) loss 0.5386 (0.5412) teacher_loss 0.1080 (0.2376) loss_zs_kd 0.0011 (0.0028) loss_oracle 0.0758 (0.0645) kd_loss 0.3922 (0.2699) acc 100.0000 (92.5000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3345) gate/usage_min 0.3315 (0.3316) gate/usage_std 0.0014 (0.0013) teacher/entropy 0.7043 (0.8282) teacher/usage_max 0.6685 (0.5367) teacher/usage_min 0.1192 (0.1766) teacher/usage_std 0.2400 (0.1533) nleep/row_max_mean 1588.6638 (1581.2343) nleep/row_max_std 41.7203 (39.7809) nleep/row_min_mean 1586.1527 (1579.3328) lr 2.0000e-03 eta 0:14:25
epoch [2/50] batch [40/132] time 0.120 (0.125) data 0.000 (0.008) loss 1.1189 (0.6478) teacher_loss 0.3827 (0.2185) loss_zs_kd 0.0030 (0.0029) loss_oracle 0.1773 (0.1080) kd_loss 0.6460 (0.3739) acc 90.6250 (93.2031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3377 (0.3354) gate/usage_min 0.3303 (0.3313) gate/usage_std 0.0032 (0.0017) teacher/entropy 0.4428 (0.7220) teacher/usage_max 0.8390 (0.6309) teacher/usage_min 0.0591 (0.1398) teacher/usage_std 0.3580 (0.2161) nleep/row_max_mean 1579.4382 (1578.7440) nleep/row_max_std 34.2701 (39.7383) nleep/row_min_mean 1575.4785 (1576.2671) lr 2.0000e-03 eta 0:13:22
epoch [2/50] batch [60/132] time 0.178 (0.124) data 0.000 (0.005) loss 1.2224 (0.7758) teacher_loss 0.3628 (0.2134) loss_zs_kd 0.0063 (0.0030) loss_oracle 0.2694 (0.1518) kd_loss 0.7217 (0.4850) acc 84.3750 (93.3333) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3423 (0.3369) gate/usage_min 0.3282 (0.3307) gate/usage_std 0.0064 (0.0027) teacher/entropy 0.3564 (0.6067) teacher/usage_max 0.8461 (0.6992) teacher/usage_min 0.0640 (0.1165) teacher/usage_std 0.3627 (0.2626) nleep/row_max_mean 1582.7241 (1579.2888) nleep/row_max_std 31.3120 (39.6044) nleep/row_min_mean 1577.3818 (1576.0003) lr 2.0000e-03 eta 0:13:13
epoch [2/50] batch [80/132] time 0.139 (0.121) data 0.000 (0.004) loss 1.1952 (0.8598) teacher_loss 0.1607 (0.2066) loss_zs_kd 0.0025 (0.0030) loss_oracle 0.3082 (0.1906) kd_loss 0.8791 (0.5565) acc 96.8750 (93.4375) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3479 (0.3390) gate/usage_min 0.3254 (0.3297) gate/usage_std 0.0103 (0.0041) teacher/entropy 0.1813 (0.5303) teacher/usage_max 0.9330 (0.7370) teacher/usage_min 0.0238 (0.1033) teacher/usage_std 0.4241 (0.2884) nleep/row_max_mean 1574.6576 (1577.5849) nleep/row_max_std 33.6795 (39.3289) nleep/row_min_mean 1568.4883 (1573.6403) lr 2.0000e-03 eta 0:12:53
epoch [2/50] batch [100/132] time 0.077 (0.120) data 0.000 (0.003) loss 1.2405 (0.9278) teacher_loss 0.1893 (0.2033) loss_zs_kd 0.0022 (0.0030) loss_oracle 0.2677 (0.2179) kd_loss 0.9162 (0.6140) acc 93.7500 (93.5625) gate/entropy 1.0977 (1.0984) gate/usage_max 0.3537 (0.3414) gate/usage_min 0.3225 (0.3285) gate/usage_std 0.0144 (0.0058) teacher/entropy 0.1288 (0.4664) teacher/usage_max 0.9360 (0.7685) teacher/usage_min 0.0253 (0.0912) teacher/usage_std 0.4262 (0.3101) nleep/row_max_mean 1574.2449 (1575.5169) nleep/row_max_std 36.8346 (39.4969) nleep/row_min_mean 1565.4004 (1570.8744) lr 2.0000e-03 eta 0:12:45
epoch [2/50] batch [120/132] time 0.083 (0.118) data 0.000 (0.003) loss 1.1602 (0.9632) teacher_loss 0.1585 (0.2017) loss_zs_kd 0.0006 (0.0029) loss_oracle 0.2319 (0.2243) kd_loss 0.8854 (0.6479) acc 90.6250 (93.4896) gate/entropy 1.0971 (1.0982) gate/usage_max 0.3591 (0.3439) gate/usage_min 0.3197 (0.3273) gate/usage_std 0.0183 (0.0076) teacher/entropy 0.1567 (0.4271) teacher/usage_max 0.8446 (0.7803) teacher/usage_min 0.0758 (0.0874) teacher/usage_std 0.3615 (0.3181) nleep/row_max_mean 1569.6482 (1574.4834) nleep/row_max_std 34.0604 (39.1174) nleep/row_min_mean 1561.3805 (1569.3288) lr 2.0000e-03 eta 0:12:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,502
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.1%, epoch: 2 *******
******* Domain s best val test acc: 89.2%, epoch: 2 *******
******* Domain s best test acc:     89.2%, epoch: 2 *******
epoch [3/50] batch [20/132] time 0.120 (0.154) data 0.000 (0.013) loss 1.1405 (1.0903) teacher_loss 0.2850 (0.1710) loss_zs_kd 0.0035 (0.0037) loss_oracle 0.4616 (0.3823) kd_loss 0.6229 (0.7263) acc 84.3750 (94.5312) gate/entropy 1.0963 (1.0966) gate/usage_max 0.3656 (0.3638) gate/usage_min 0.3168 (0.3174) gate/usage_std 0.0228 (0.0215) teacher/entropy 0.4458 (0.3266) teacher/usage_max 0.5627 (0.6911) teacher/usage_min 0.1494 (0.1184) teacher/usage_std 0.1718 (0.2553) nleep/row_max_mean 1565.8428 (1563.9681) nleep/row_max_std 42.1000 (42.2887) nleep/row_min_mean 1558.8279 (1556.2509) lr 1.9980e-03 eta 0:16:11
epoch [3/50] batch [40/132] time 0.143 (0.143) data 0.000 (0.007) loss 1.0919 (1.0924) teacher_loss 0.2441 (0.1804) loss_zs_kd 0.0055 (0.0051) loss_oracle 0.4322 (0.3938) kd_loss 0.6290 (0.7126) acc 90.6250 (94.2188) gate/entropy 1.0958 (1.0963) gate/usage_max 0.3690 (0.3656) gate/usage_min 0.3149 (0.3167) gate/usage_std 0.0252 (0.0228) teacher/entropy 0.4517 (0.3455) teacher/usage_max 0.4631 (0.6385) teacher/usage_min 0.1703 (0.1255) teacher/usage_std 0.1218 (0.2235) nleep/row_max_mean 1562.8757 (1564.1830) nleep/row_max_std 40.6562 (42.1180) nleep/row_min_mean 1556.3956 (1556.6998) lr 1.9980e-03 eta 0:14:58
epoch [3/50] batch [60/132] time 0.117 (0.142) data 0.000 (0.004) loss 1.0848 (1.0905) teacher_loss 0.1368 (0.1768) loss_zs_kd 0.0020 (0.0050) loss_oracle 0.5117 (0.4096) kd_loss 0.6912 (0.7064) acc 90.6250 (94.1146) gate/entropy 1.0955 (1.0961) gate/usage_max 0.3708 (0.3671) gate/usage_min 0.3126 (0.3158) gate/usage_std 0.0266 (0.0239) teacher/entropy 0.3880 (0.3578) teacher/usage_max 0.4573 (0.5969) teacher/usage_min 0.1116 (0.1312) teacher/usage_std 0.1572 (0.2009) nleep/row_max_mean 1575.6995 (1564.3418) nleep/row_max_std 38.6285 (42.5538) nleep/row_min_mean 1568.8313 (1556.8664) lr 1.9980e-03 eta 0:14:51
epoch [3/50] batch [80/132] time 0.090 (0.133) data 0.000 (0.003) loss 1.3436 (1.1205) teacher_loss 0.1861 (0.1729) loss_zs_kd 0.0126 (0.0054) loss_oracle 0.5732 (0.4523) kd_loss 0.8646 (0.7187) acc 96.8750 (94.1406) gate/entropy 1.0955 (1.0959) gate/usage_max 0.3702 (0.3680) gate/usage_min 0.3099 (0.3146) gate/usage_std 0.0264 (0.0245) teacher/entropy 0.2486 (0.3555) teacher/usage_max 0.7199 (0.5947) teacher/usage_min 0.0817 (0.1302) teacher/usage_std 0.2774 (0.2001) nleep/row_max_mean 1558.0461 (1564.1749) nleep/row_max_std 42.3124 (42.6413) nleep/row_min_mean 1547.1567 (1556.3849) lr 1.9980e-03 eta 0:13:50
epoch [3/50] batch [100/132] time 0.099 (0.128) data 0.000 (0.003) loss 1.2666 (1.1460) teacher_loss 0.0842 (0.1750) loss_zs_kd 0.0043 (0.0059) loss_oracle 0.5359 (0.4613) kd_loss 0.9123 (0.7374) acc 96.8750 (94.0000) gate/entropy 1.0957 (1.0959) gate/usage_max 0.3679 (0.3682) gate/usage_min 0.3074 (0.3134) gate/usage_std 0.0254 (0.0248) teacher/entropy 0.2090 (0.3454) teacher/usage_max 0.8164 (0.6160) teacher/usage_min 0.0761 (0.1290) teacher/usage_std 0.3418 (0.2125) nleep/row_max_mean 1564.5153 (1563.7135) nleep/row_max_std 48.2422 (42.4169) nleep/row_min_mean 1553.3915 (1555.3403) lr 1.9980e-03 eta 0:13:17
epoch [3/50] batch [120/132] time 0.067 (0.127) data 0.000 (0.002) loss 1.2762 (1.1670) teacher_loss 0.1516 (0.1746) loss_zs_kd 0.0106 (0.0061) loss_oracle 0.6500 (0.4708) kd_loss 0.7943 (0.7540) acc 96.8750 (94.2448) gate/entropy 1.0960 (1.0959) gate/usage_max 0.3644 (0.3678) gate/usage_min 0.3054 (0.3123) gate/usage_std 0.0242 (0.0248) teacher/entropy 0.3220 (0.3344) teacher/usage_max 0.8045 (0.6358) teacher/usage_min 0.0394 (0.1229) teacher/usage_std 0.3365 (0.2248) nleep/row_max_mean 1554.6965 (1562.9404) nleep/row_max_std 48.4164 (42.7089) nleep/row_min_mean 1539.5823 (1553.8547) lr 1.9980e-03 eta 0:13:08
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,576
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 93.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.3%, epoch: 3 *******
******* Domain s best val test acc: 91.0%, epoch: 3 *******
******* Domain s best test acc:     91.0%, epoch: 3 *******
epoch [4/50] batch [20/132] time 0.078 (0.127) data 0.000 (0.015) loss 1.4075 (1.4932) teacher_loss 0.1136 (0.1705) loss_zs_kd 0.0018 (0.0087) loss_oracle 0.7698 (0.7502) kd_loss 0.9081 (0.9433) acc 96.8750 (95.1562) gate/entropy 1.0961 (1.0961) gate/usage_max 0.3572 (0.3594) gate/usage_min 0.3016 (0.3029) gate/usage_std 0.0234 (0.0233) teacher/entropy 0.1736 (0.1492) teacher/usage_max 0.8474 (0.8410) teacher/usage_min 0.0719 (0.0554) teacher/usage_std 0.3635 (0.3601) nleep/row_max_mean 1567.1619 (1563.8018) nleep/row_max_std 34.6592 (46.3675) nleep/row_min_mean 1553.3938 (1548.4676) lr 1.9921e-03 eta 0:13:06
epoch [4/50] batch [40/132] time 0.082 (0.119) data 0.000 (0.007) loss 1.6844 (1.5104) teacher_loss 0.4607 (0.1806) loss_zs_kd 0.0063 (0.0092) loss_oracle 0.5946 (0.7349) kd_loss 0.9233 (0.9577) acc 90.6250 (94.4531) gate/entropy 1.0958 (1.0961) gate/usage_max 0.3523 (0.3570) gate/usage_min 0.2984 (0.3014) gate/usage_std 0.0247 (0.0236) teacher/entropy 0.1432 (0.1231) teacher/usage_max 0.8268 (0.8766) teacher/usage_min 0.0770 (0.0416) teacher/usage_std 0.3490 (0.3849) nleep/row_max_mean 1556.0090 (1560.3660) nleep/row_max_std 50.1721 (47.1196) nleep/row_min_mean 1542.2222 (1544.7865) lr 1.9921e-03 eta 0:12:15
epoch [4/50] batch [60/132] time 0.090 (0.118) data 0.000 (0.005) loss 1.3912 (1.4788) teacher_loss 0.1074 (0.1683) loss_zs_kd 0.0177 (0.0086) loss_oracle 0.6153 (0.7058) kd_loss 0.9673 (0.9532) acc 100.0000 (94.7396) gate/entropy 1.0952 (1.0959) gate/usage_max 0.3570 (0.3559) gate/usage_min 0.2951 (0.2998) gate/usage_std 0.0273 (0.0244) teacher/entropy 0.0645 (0.1191) teacher/usage_max 0.9717 (0.8691) teacher/usage_min 0.0061 (0.0437) teacher/usage_std 0.4514 (0.3797) nleep/row_max_mean 1556.9469 (1559.9288) nleep/row_max_std 40.2180 (45.8301) nleep/row_min_mean 1541.5515 (1544.3517) lr 1.9921e-03 eta 0:12:07
epoch [4/50] batch [80/132] time 0.098 (0.119) data 0.000 (0.004) loss 1.4164 (1.4619) teacher_loss 0.1278 (0.1632) loss_zs_kd 0.0062 (0.0086) loss_oracle 0.6561 (0.6951) kd_loss 0.9574 (0.9469) acc 93.7500 (94.6875) gate/entropy 1.0944 (1.0956) gate/usage_max 0.3645 (0.3572) gate/usage_min 0.2921 (0.2982) gate/usage_std 0.0304 (0.0256) teacher/entropy 0.1006 (0.1182) teacher/usage_max 0.7405 (0.8615) teacher/usage_min 0.0522 (0.0439) teacher/usage_std 0.2948 (0.3746) nleep/row_max_mean 1564.5923 (1559.5766) nleep/row_max_std 32.8728 (45.6922) nleep/row_min_mean 1547.2009 (1543.9356) lr 1.9921e-03 eta 0:12:05
epoch [4/50] batch [100/132] time 0.127 (0.122) data 0.000 (0.003) loss 1.5045 (1.4560) teacher_loss 0.2642 (0.1707) loss_zs_kd 0.0177 (0.0082) loss_oracle 0.6768 (0.6886) kd_loss 0.8931 (0.9370) acc 90.6250 (94.4375) gate/entropy 1.0935 (1.0953) gate/usage_max 0.3716 (0.3594) gate/usage_min 0.2897 (0.2967) gate/usage_std 0.0337 (0.0269) teacher/entropy 0.1417 (0.1227) teacher/usage_max 0.7964 (0.8489) teacher/usage_min 0.0361 (0.0454) teacher/usage_std 0.3318 (0.3662) nleep/row_max_mean 1534.0652 (1559.5763) nleep/row_max_std 49.2914 (46.2334) nleep/row_min_mean 1519.9335 (1544.0738) lr 1.9921e-03 eta 0:12:24
epoch [4/50] batch [120/132] time 0.149 (0.127) data 0.000 (0.003) loss 1.3842 (1.4359) teacher_loss 0.2619 (0.1714) loss_zs_kd 0.0106 (0.0085) loss_oracle 0.5802 (0.6709) kd_loss 0.8269 (0.9248) acc 87.5000 (94.4271) gate/entropy 1.0924 (1.0949) gate/usage_max 0.3783 (0.3621) gate/usage_min 0.2873 (0.2953) gate/usage_std 0.0372 (0.0283) teacher/entropy 0.2166 (0.1320) teacher/usage_max 0.6864 (0.8296) teacher/usage_min 0.0987 (0.0465) teacher/usage_std 0.2541 (0.3538) nleep/row_max_mean 1551.3530 (1559.5533) nleep/row_max_std 49.8154 (46.5930) nleep/row_min_mean 1536.4675 (1544.1177) lr 1.9921e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,578
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 93.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.3%, epoch: 3 *******
******* Domain s best val test acc: 91.0%, epoch: 3 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [5/50] batch [20/132] time 0.166 (0.168) data 0.000 (0.016) loss 1.2043 (1.3048) teacher_loss 0.1289 (0.1722) loss_zs_kd 0.0125 (0.0110) loss_oracle 0.5320 (0.5467) kd_loss 0.8031 (0.8538) acc 96.8750 (94.0625) gate/entropy 1.0908 (1.0913) gate/usage_max 0.3870 (0.3846) gate/usage_min 0.2852 (0.2857) gate/usage_std 0.0418 (0.0404) teacher/entropy 0.2757 (0.2058) teacher/usage_max 0.5689 (0.6330) teacher/usage_min 0.0120 (0.0461) teacher/usage_std 0.2353 (0.2450) nleep/row_max_mean 1555.0118 (1560.8567) nleep/row_max_std 51.2094 (47.2430) nleep/row_min_mean 1539.1340 (1545.8927) lr 1.9823e-03 eta 0:16:55
epoch [5/50] batch [40/132] time 0.108 (0.139) data 0.000 (0.008) loss 1.3829 (1.2989) teacher_loss 0.2499 (0.1731) loss_zs_kd 0.0002 (0.0109) loss_oracle 0.4797 (0.5266) kd_loss 0.8931 (0.8570) acc 90.6250 (94.0625) gate/entropy 1.0902 (1.0909) gate/usage_max 0.3906 (0.3868) gate/usage_min 0.2852 (0.2854) gate/usage_std 0.0435 (0.0416) teacher/entropy 0.2418 (0.2212) teacher/usage_max 0.5803 (0.5812) teacher/usage_min 0.0648 (0.0599) teacher/usage_std 0.2110 (0.2191) nleep/row_max_mean 1555.7661 (1558.6885) nleep/row_max_std 54.4619 (47.9437) nleep/row_min_mean 1542.9117 (1544.1934) lr 1.9823e-03 eta 0:13:57
epoch [5/50] batch [60/132] time 0.069 (0.132) data 0.000 (0.005) loss 1.4217 (1.3141) teacher_loss 0.2760 (0.1803) loss_zs_kd 0.0083 (0.0104) loss_oracle 0.4872 (0.5178) kd_loss 0.8979 (0.8697) acc 90.6250 (93.9583) gate/entropy 1.0900 (1.0906) gate/usage_max 0.3923 (0.3883) gate/usage_min 0.2867 (0.2856) gate/usage_std 0.0440 (0.0423) teacher/entropy 0.2353 (0.2267) teacher/usage_max 0.5961 (0.5775) teacher/usage_min 0.0530 (0.0684) teacher/usage_std 0.2220 (0.2134) nleep/row_max_mean 1539.5891 (1558.0822) nleep/row_max_std 54.2420 (47.6279) nleep/row_min_mean 1527.2434 (1543.8065) lr 1.9823e-03 eta 0:13:16
epoch [5/50] batch [80/132] time 0.085 (0.128) data 0.000 (0.004) loss 1.6050 (1.3310) teacher_loss 0.3427 (0.1799) loss_zs_kd 0.0145 (0.0096) loss_oracle 0.4565 (0.5066) kd_loss 1.0269 (0.8930) acc 90.6250 (94.0234) gate/entropy 1.0902 (1.0905) gate/usage_max 0.3928 (0.3894) gate/usage_min 0.2892 (0.2862) gate/usage_std 0.0437 (0.0427) teacher/entropy 0.1361 (0.2199) teacher/usage_max 0.6823 (0.6035) teacher/usage_min 0.0911 (0.0699) teacher/usage_std 0.2529 (0.2249) nleep/row_max_mean 1554.2465 (1557.0127) nleep/row_max_std 50.9603 (48.0306) nleep/row_min_mean 1537.6488 (1542.7671) lr 1.9823e-03 eta 0:12:44
epoch [5/50] batch [100/132] time 0.098 (0.124) data 0.000 (0.003) loss 1.2742 (1.3539) teacher_loss 0.0376 (0.1863) loss_zs_kd 0.0014 (0.0093) loss_oracle 0.3884 (0.4910) kd_loss 1.0418 (0.9175) acc 100.0000 (93.9688) gate/entropy 1.0906 (1.0905) gate/usage_max 0.3923 (0.3900) gate/usage_min 0.2928 (0.2872) gate/usage_std 0.0427 (0.0428) teacher/entropy 0.1713 (0.2100) teacher/usage_max 0.8789 (0.6400) teacher/usage_min 0.0293 (0.0694) teacher/usage_std 0.3866 (0.2446) nleep/row_max_mean 1553.5381 (1556.9987) nleep/row_max_std 59.6298 (47.8797) nleep/row_min_mean 1539.4828 (1542.6430) lr 1.9823e-03 eta 0:12:19
epoch [5/50] batch [120/132] time 0.156 (0.121) data 0.000 (0.003) loss 1.5497 (1.3749) teacher_loss 0.2265 (0.1867) loss_zs_kd 0.0021 (0.0094) loss_oracle 0.6012 (0.4865) kd_loss 1.0215 (0.9403) acc 90.6250 (93.9323) gate/entropy 1.0914 (1.0905) gate/usage_max 0.3901 (0.3902) gate/usage_min 0.2978 (0.2885) gate/usage_std 0.0406 (0.0426) teacher/entropy 0.1598 (0.1975) teacher/usage_max 0.8756 (0.6725) teacher/usage_min 0.0144 (0.0664) teacher/usage_std 0.3854 (0.2632) nleep/row_max_mean 1556.3989 (1556.6375) nleep/row_max_std 45.3602 (47.8521) nleep/row_min_mean 1539.8750 (1542.1758) lr 1.9823e-03 eta 0:12:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,535
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.3%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 90.0%, epoch: 5 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [6/50] batch [20/132] time 0.076 (0.124) data 0.000 (0.013) loss 1.3664 (1.5517) teacher_loss 0.0295 (0.1846) loss_zs_kd 0.0088 (0.0074) loss_oracle 0.5085 (0.5142) kd_loss 1.0783 (1.1064) acc 100.0000 (93.7500) gate/entropy 1.0929 (1.0924) gate/usage_max 0.3843 (0.3863) gate/usage_min 0.3076 (0.3048) gate/usage_std 0.0360 (0.0375) teacher/entropy 0.0991 (0.0764) teacher/usage_max 0.8170 (0.9227) teacher/usage_min 0.0001 (0.0164) teacher/usage_std 0.3501 (0.4175) nleep/row_max_mean 1546.9849 (1555.6011) nleep/row_max_std 37.4369 (45.3472) nleep/row_min_mean 1526.0869 (1536.4300) lr 1.9686e-03 eta 0:12:13
epoch [6/50] batch [40/132] time 0.147 (0.119) data 0.000 (0.007) loss 1.5607 (1.5371) teacher_loss 0.2564 (0.1722) loss_zs_kd 0.0276 (0.0068) loss_oracle 0.4571 (0.5250) kd_loss 1.0618 (1.0990) acc 90.6250 (94.6875) gate/entropy 1.0937 (1.0929) gate/usage_max 0.3799 (0.3842) gate/usage_min 0.3048 (0.3055) gate/usage_std 0.0332 (0.0360) teacher/entropy 0.0953 (0.0744) teacher/usage_max 0.9149 (0.9199) teacher/usage_min 0.0001 (0.0140) teacher/usage_std 0.4127 (0.4157) nleep/row_max_mean 1543.2985 (1553.0912) nleep/row_max_std 56.0476 (46.9653) nleep/row_min_mean 1523.1797 (1533.1167) lr 1.9686e-03 eta 0:11:42
epoch [6/50] batch [60/132] time 0.153 (0.131) data 0.000 (0.005) loss 1.4488 (1.5394) teacher_loss 0.1210 (0.1755) loss_zs_kd 0.0027 (0.0068) loss_oracle 0.5444 (0.5366) kd_loss 1.0543 (1.0922) acc 96.8750 (94.3229) gate/entropy 1.0944 (1.0933) gate/usage_max 0.3754 (0.3820) gate/usage_min 0.3022 (0.3048) gate/usage_std 0.0309 (0.0347) teacher/entropy 0.0820 (0.0720) teacher/usage_max 0.9335 (0.9223) teacher/usage_min 0.0000 (0.0103) teacher/usage_std 0.4252 (0.4175) nleep/row_max_mean 1553.8141 (1552.0804) nleep/row_max_std 45.2545 (47.0399) nleep/row_min_mean 1529.0317 (1531.3052) lr 1.9686e-03 eta 0:12:48
epoch [6/50] batch [80/132] time 0.157 (0.136) data 0.000 (0.004) loss 1.5252 (1.5559) teacher_loss 0.2364 (0.1899) loss_zs_kd 0.0244 (0.0071) loss_oracle 0.5360 (0.5583) kd_loss 1.0085 (1.0833) acc 90.6250 (93.6328) gate/entropy 1.0949 (1.0936) gate/usage_max 0.3702 (0.3796) gate/usage_min 0.2999 (0.3038) gate/usage_std 0.0288 (0.0334) teacher/entropy 0.1105 (0.0716) teacher/usage_max 0.8818 (0.9181) teacher/usage_min 0.0034 (0.0081) teacher/usage_std 0.3905 (0.4148) nleep/row_max_mean 1540.5972 (1550.3704) nleep/row_max_std 47.9187 (46.7194) nleep/row_min_mean 1516.1025 (1528.4407) lr 1.9686e-03 eta 0:13:19
epoch [6/50] batch [100/132] time 0.142 (0.139) data 0.000 (0.003) loss 1.4962 (1.5498) teacher_loss 0.1240 (0.1889) loss_zs_kd 0.0021 (0.0069) loss_oracle 0.6347 (0.5636) kd_loss 1.0538 (1.0756) acc 100.0000 (93.5938) gate/entropy 1.0951 (1.0939) gate/usage_max 0.3650 (0.3772) gate/usage_min 0.2974 (0.3028) gate/usage_std 0.0278 (0.0324) teacher/entropy 0.0462 (0.0699) teacher/usage_max 0.8861 (0.9141) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.3936 (0.4124) nleep/row_max_mean 1552.9680 (1550.3564) nleep/row_max_std 40.3282 (45.9691) nleep/row_min_mean 1520.5405 (1526.8715) lr 1.9686e-03 eta 0:13:34
epoch [6/50] batch [120/132] time 0.145 (0.141) data 0.000 (0.002) loss 1.6480 (1.5371) teacher_loss 0.2646 (0.1809) loss_zs_kd 0.0063 (0.0067) loss_oracle 0.6705 (0.5704) kd_loss 1.0450 (1.0677) acc 93.7500 (93.8542) gate/entropy 1.0951 (1.0941) gate/usage_max 0.3597 (0.3747) gate/usage_min 0.2952 (0.3017) gate/usage_std 0.0276 (0.0316) teacher/entropy 0.0364 (0.0683) teacher/usage_max 0.8855 (0.9121) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3933 (0.4111) nleep/row_max_mean 1545.5780 (1550.6028) nleep/row_max_std 45.7057 (45.6303) nleep/row_min_mean 1509.9503 (1525.4274) lr 1.9686e-03 eta 0:13:43
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,544
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.4%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 90.0%, epoch: 5 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [7/50] batch [20/132] time 0.090 (0.115) data 0.000 (0.015) loss 1.6354 (1.5329) teacher_loss 0.3780 (0.2456) loss_zs_kd 0.0028 (0.0076) loss_oracle 0.5291 (0.5632) kd_loss 0.9915 (1.0019) acc 87.5000 (91.7188) gate/entropy 1.0946 (1.0949) gate/usage_max 0.3566 (0.3551) gate/usage_min 0.2918 (0.2930) gate/usage_std 0.0294 (0.0286) teacher/entropy 0.0567 (0.0571) teacher/usage_max 0.9131 (0.8990) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4115 (0.4031) nleep/row_max_mean 1552.7268 (1550.2141) nleep/row_max_std 39.8012 (46.8056) nleep/row_min_mean 1512.2970 (1511.5549) lr 1.9511e-03 eta 0:11:04
epoch [7/50] batch [40/132] time 0.061 (0.123) data 0.000 (0.007) loss 1.2632 (1.4859) teacher_loss 0.0123 (0.2124) loss_zs_kd 0.0000 (0.0067) loss_oracle 0.5227 (0.5433) kd_loss 0.9896 (0.9985) acc 100.0000 (92.9688) gate/entropy 1.0940 (1.0946) gate/usage_max 0.3639 (0.3578) gate/usage_min 0.2898 (0.2919) gate/usage_std 0.0316 (0.0295) teacher/entropy 0.0225 (0.0486) teacher/usage_max 0.9947 (0.9141) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4677 (0.4129) nleep/row_max_mean 1537.9647 (1549.4049) nleep/row_max_std 44.0275 (46.0315) nleep/row_min_mean 1499.1486 (1509.2726) lr 1.9511e-03 eta 0:11:49
epoch [7/50] batch [60/132] time 0.095 (0.112) data 0.000 (0.005) loss 1.4203 (1.4584) teacher_loss 0.1707 (0.1933) loss_zs_kd 0.0030 (0.0059) loss_oracle 0.5592 (0.5446) kd_loss 0.9684 (0.9899) acc 93.7500 (93.4896) gate/entropy 1.0930 (1.0942) gate/usage_max 0.3718 (0.3612) gate/usage_min 0.2872 (0.2908) gate/usage_std 0.0349 (0.0308) teacher/entropy 0.0385 (0.0462) teacher/usage_max 0.9311 (0.9227) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4236 (0.4186) nleep/row_max_mean 1532.1415 (1547.6680) nleep/row_max_std 46.6649 (45.6294) nleep/row_min_mean 1491.1184 (1506.6193) lr 1.9511e-03 eta 0:10:41
epoch [7/50] batch [80/132] time 0.085 (0.113) data 0.000 (0.004) loss 1.4568 (1.4433) teacher_loss 0.2137 (0.1907) loss_zs_kd 0.0013 (0.0057) loss_oracle 0.5935 (0.5400) kd_loss 0.9457 (0.9798) acc 93.7500 (93.6719) gate/entropy 1.0919 (1.0938) gate/usage_max 0.3791 (0.3648) gate/usage_min 0.2851 (0.2896) gate/usage_std 0.0384 (0.0323) teacher/entropy 0.0436 (0.0458) teacher/usage_max 0.9310 (0.9277) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4236 (0.4219) nleep/row_max_mean 1540.6528 (1548.0258) nleep/row_max_std 45.4752 (44.3131) nleep/row_min_mean 1494.4611 (1505.8983) lr 1.9511e-03 eta 0:10:44
epoch [7/50] batch [100/132] time 0.089 (0.113) data 0.000 (0.003) loss 1.2915 (1.4379) teacher_loss 0.0549 (0.1923) loss_zs_kd 0.0017 (0.0055) loss_oracle 0.6291 (0.5421) kd_loss 0.9213 (0.9718) acc 96.8750 (93.5000) gate/entropy 1.0904 (1.0933) gate/usage_max 0.3868 (0.3685) gate/usage_min 0.2823 (0.2884) gate/usage_std 0.0427 (0.0340) teacher/entropy 0.0330 (0.0454) teacher/usage_max 0.9855 (0.9256) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4612 (0.4205) nleep/row_max_mean 1551.7554 (1548.0933) nleep/row_max_std 45.9902 (44.1633) nleep/row_min_mean 1503.5575 (1505.1226) lr 1.9511e-03 eta 0:10:46
epoch [7/50] batch [120/132] time 0.189 (0.116) data 0.000 (0.003) loss 1.3995 (1.4343) teacher_loss 0.1998 (0.1934) loss_zs_kd 0.0037 (0.0058) loss_oracle 0.6284 (0.5492) kd_loss 0.8837 (0.9634) acc 90.6250 (93.4635) gate/entropy 1.0887 (1.0926) gate/usage_max 0.3945 (0.3722) gate/usage_min 0.2800 (0.2872) gate/usage_std 0.0471 (0.0358) teacher/entropy 0.0675 (0.0452) teacher/usage_max 0.9373 (0.9243) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4278 (0.4195) nleep/row_max_mean 1551.6392 (1547.7065) nleep/row_max_std 40.4692 (43.8796) nleep/row_min_mean 1505.0229 (1504.3283) lr 1.9511e-03 eta 0:11:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,550
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.6%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 90.0%, epoch: 5 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [8/50] batch [20/132] time 0.158 (0.151) data 0.000 (0.016) loss 1.3014 (1.3269) teacher_loss 0.1291 (0.1536) loss_zs_kd 0.0096 (0.0063) loss_oracle 0.5257 (0.5523) kd_loss 0.9047 (0.8940) acc 96.8750 (95.0000) gate/entropy 1.0855 (1.0864) gate/usage_max 0.4064 (0.4031) gate/usage_min 0.2762 (0.2771) gate/usage_std 0.0543 (0.0523) teacher/entropy 0.0288 (0.0471) teacher/usage_max 0.9143 (0.9118) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4123 (0.4112) nleep/row_max_mean 1531.6250 (1539.6150) nleep/row_max_std 54.5049 (44.2735) nleep/row_min_mean 1486.3879 (1492.5597) lr 1.9298e-03 eta 0:14:12
epoch [8/50] batch [40/132] time 0.120 (0.147) data 0.000 (0.008) loss 1.1771 (1.3036) teacher_loss 0.0843 (0.1632) loss_zs_kd 0.0039 (0.0064) loss_oracle 0.4581 (0.5104) kd_loss 0.8618 (0.8820) acc 96.8750 (94.1406) gate/entropy 1.0832 (1.0853) gate/usage_max 0.4140 (0.4068) gate/usage_min 0.2735 (0.2759) gate/usage_std 0.0592 (0.0547) teacher/entropy 0.0569 (0.0440) teacher/usage_max 0.9094 (0.9299) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4090 (0.4234) nleep/row_max_mean 1537.9003 (1537.5690) nleep/row_max_std 42.1703 (44.5516) nleep/row_min_mean 1493.2878 (1490.8573) lr 1.9298e-03 eta 0:13:48
epoch [8/50] batch [60/132] time 0.165 (0.147) data 0.000 (0.005) loss 1.1749 (1.2946) teacher_loss 0.0642 (0.1638) loss_zs_kd 0.0106 (0.0065) loss_oracle 0.5487 (0.5030) kd_loss 0.8310 (0.8760) acc 100.0000 (94.2188) gate/entropy 1.0807 (1.0842) gate/usage_max 0.4212 (0.4105) gate/usage_min 0.2711 (0.2746) gate/usage_std 0.0639 (0.0570) teacher/entropy 0.0633 (0.0420) teacher/usage_max 0.9316 (0.9302) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4239 (0.4236) nleep/row_max_mean 1549.5815 (1537.4050) nleep/row_max_std 32.9383 (44.6180) nleep/row_min_mean 1501.5691 (1490.8300) lr 1.9298e-03 eta 0:13:46
epoch [8/50] batch [80/132] time 0.161 (0.152) data 0.000 (0.004) loss 1.3143 (1.2971) teacher_loss 0.1889 (0.1637) loss_zs_kd 0.0026 (0.0062) loss_oracle 0.6041 (0.5166) kd_loss 0.8221 (0.8720) acc 96.8750 (94.1797) gate/entropy 1.0783 (1.0830) gate/usage_max 0.4278 (0.4140) gate/usage_min 0.2690 (0.2735) gate/usage_std 0.0683 (0.0593) teacher/entropy 0.0367 (0.0416) teacher/usage_max 0.9785 (0.9230) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4563 (0.4187) nleep/row_max_mean 1536.8278 (1537.3471) nleep/row_max_std 46.5946 (44.4117) nleep/row_min_mean 1490.1619 (1490.9932) lr 1.9298e-03 eta 0:14:10
epoch [8/50] batch [100/132] time 0.162 (0.152) data 0.000 (0.003) loss 1.2205 (1.2908) teacher_loss 0.0711 (0.1604) loss_zs_kd 0.0142 (0.0064) loss_oracle 0.5898 (0.5209) kd_loss 0.8475 (0.8668) acc 96.8750 (94.3438) gate/entropy 1.0755 (1.0818) gate/usage_max 0.4347 (0.4175) gate/usage_min 0.2667 (0.2723) gate/usage_std 0.0729 (0.0616) teacher/entropy 0.0361 (0.0406) teacher/usage_max 0.8940 (0.9205) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3988 (0.4170) nleep/row_max_mean 1533.2445 (1536.4266) nleep/row_max_std 51.9094 (44.8357) nleep/row_min_mean 1484.6583 (1490.2374) lr 1.9298e-03 eta 0:14:08
epoch [8/50] batch [120/132] time 0.078 (0.147) data 0.000 (0.003) loss 1.1955 (1.2859) teacher_loss 0.1219 (0.1646) loss_zs_kd 0.0143 (0.0062) loss_oracle 0.4809 (0.5114) kd_loss 0.8261 (0.8625) acc 96.8750 (94.2188) gate/entropy 1.0729 (1.0805) gate/usage_max 0.4409 (0.4210) gate/usage_min 0.2648 (0.2712) gate/usage_std 0.0770 (0.0638) teacher/entropy 0.0445 (0.0396) teacher/usage_max 0.8970 (0.9166) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4008 (0.4144) nleep/row_max_mean 1542.0177 (1536.7320) nleep/row_max_std 36.5378 (44.6734) nleep/row_min_mean 1496.4332 (1490.5602) lr 1.9298e-03 eta 0:13:38
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,518
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.7%
******* Domain s best val acc:      99.3%, epoch: 5 *******
******* Domain s best val test acc: 90.0%, epoch: 5 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [9/50] batch [20/132] time 0.075 (0.133) data 0.000 (0.015) loss 1.2590 (1.2193) teacher_loss 0.2240 (0.1662) loss_zs_kd 0.0096 (0.0079) loss_oracle 0.4309 (0.4781) kd_loss 0.8147 (0.8101) acc 90.6250 (93.4375) gate/entropy 1.0683 (1.0698) gate/usage_max 0.4508 (0.4476) gate/usage_min 0.2612 (0.2623) gate/usage_std 0.0838 (0.0816) teacher/entropy 0.0154 (0.0368) teacher/usage_max 0.9391 (0.9180) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4291 (0.4151) nleep/row_max_mean 1530.8975 (1537.8310) nleep/row_max_std 48.5105 (43.7258) nleep/row_min_mean 1486.7791 (1494.4193) lr 1.9048e-03 eta 0:12:13
epoch [9/50] batch [40/132] time 0.101 (0.127) data 0.000 (0.008) loss 1.2793 (1.2303) teacher_loss 0.2258 (0.1843) loss_zs_kd 0.0079 (0.0078) loss_oracle 0.5172 (0.4860) kd_loss 0.7909 (0.7992) acc 90.6250 (93.3594) gate/entropy 1.0653 (1.0683) gate/usage_max 0.4569 (0.4507) gate/usage_min 0.2590 (0.2612) gate/usage_std 0.0879 (0.0837) teacher/entropy 0.0113 (0.0364) teacher/usage_max 0.9662 (0.9279) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4477 (0.4218) nleep/row_max_mean 1545.5983 (1536.3386) nleep/row_max_std 35.1283 (44.2969) nleep/row_min_mean 1502.7286 (1493.7046) lr 1.9048e-03 eta 0:11:36
epoch [9/50] batch [60/132] time 0.198 (0.126) data 0.001 (0.005) loss 1.3059 (1.2337) teacher_loss 0.3226 (0.1964) loss_zs_kd 0.0041 (0.0076) loss_oracle 0.4621 (0.4850) kd_loss 0.7502 (0.7911) acc 84.3750 (92.8646) gate/entropy 1.0623 (1.0668) gate/usage_max 0.4627 (0.4537) gate/usage_min 0.2569 (0.2601) gate/usage_std 0.0920 (0.0858) teacher/entropy 0.0617 (0.0341) teacher/usage_max 0.9282 (0.9358) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4217 (0.4272) nleep/row_max_mean 1517.3505 (1535.8546) nleep/row_max_std 51.3096 (44.2787) nleep/row_min_mean 1477.3319 (1493.5378) lr 1.9048e-03 eta 0:11:32
epoch [9/50] batch [80/132] time 0.172 (0.124) data 0.000 (0.004) loss 1.3300 (1.2314) teacher_loss 0.2871 (0.2023) loss_zs_kd 0.0143 (0.0073) loss_oracle 0.5258 (0.4853) kd_loss 0.7728 (0.7828) acc 87.5000 (92.4609) gate/entropy 1.0587 (1.0653) gate/usage_max 0.4691 (0.4568) gate/usage_min 0.2544 (0.2590) gate/usage_std 0.0964 (0.0879) teacher/entropy 0.0031 (0.0318) teacher/usage_max 0.9682 (0.9437) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4491 (0.4326) nleep/row_max_mean 1527.1316 (1535.2264) nleep/row_max_std 44.4473 (44.2797) nleep/row_min_mean 1485.6367 (1492.7589) lr 1.9048e-03 eta 0:11:18
epoch [9/50] batch [100/132] time 0.164 (0.123) data 0.000 (0.003) loss 1.1631 (1.2182) teacher_loss 0.2243 (0.1937) loss_zs_kd 0.0051 (0.0070) loss_oracle 0.3868 (0.4910) kd_loss 0.7429 (0.7755) acc 93.7500 (92.8438) gate/entropy 1.0555 (1.0636) gate/usage_max 0.4748 (0.4598) gate/usage_min 0.2525 (0.2579) gate/usage_std 0.1004 (0.0900) teacher/entropy 0.0022 (0.0295) teacher/usage_max 0.9996 (0.9499) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4711 (0.4368) nleep/row_max_mean 1516.3757 (1535.1488) nleep/row_max_std 55.2346 (44.5981) nleep/row_min_mean 1475.1100 (1492.3251) lr 1.9048e-03 eta 0:11:08
epoch [9/50] batch [120/132] time 0.074 (0.120) data 0.000 (0.003) loss 1.2010 (1.2169) teacher_loss 0.2864 (0.2025) loss_zs_kd 0.0189 (0.0072) loss_oracle 0.3370 (0.4847) kd_loss 0.7367 (0.7684) acc 87.5000 (92.3958) gate/entropy 1.0519 (1.0619) gate/usage_max 0.4809 (0.4629) gate/usage_min 0.2502 (0.2568) gate/usage_std 0.1046 (0.0921) teacher/entropy 0.0146 (0.0267) teacher/usage_max 0.9706 (0.9561) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4508 (0.4410) nleep/row_max_mean 1530.6127 (1535.2654) nleep/row_max_std 35.3462 (44.0570) nleep/row_min_mean 1487.2808 (1492.0535) lr 1.9048e-03 eta 0:10:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,543
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.5%
******* Domain s best val acc:      99.5%, epoch: 9 *******
******* Domain s best val test acc: 90.2%, epoch: 9 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [10/50] batch [20/132] time 0.173 (0.172) data 0.000 (0.017) loss 1.2833 (1.1689) teacher_loss 0.3164 (0.2202) loss_zs_kd 0.0106 (0.0075) loss_oracle 0.5076 (0.4564) kd_loss 0.7078 (0.7167) acc 90.6250 (92.5000) gate/entropy 1.0470 (1.0478) gate/usage_max 0.4888 (0.4874) gate/usage_min 0.2474 (0.2477) gate/usage_std 0.1101 (0.1092) teacher/entropy 0.0095 (0.0179) teacher/usage_max 0.9978 (0.9761) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4699 (0.4547) nleep/row_max_mean 1528.9351 (1540.0043) nleep/row_max_std 44.6672 (41.1491) nleep/row_min_mean 1483.6865 (1493.8327) lr 1.8763e-03 eta 0:15:26
epoch [10/50] batch [40/132] time 0.147 (0.159) data 0.000 (0.008) loss 1.0301 (1.1077) teacher_loss 0.1241 (0.1662) loss_zs_kd 0.0039 (0.0068) loss_oracle 0.4051 (0.4468) kd_loss 0.7015 (0.7147) acc 93.7500 (94.2188) gate/entropy 1.0431 (1.0462) gate/usage_max 0.4947 (0.4899) gate/usage_min 0.2453 (0.2469) gate/usage_std 0.1142 (0.1109) teacher/entropy 0.0476 (0.0196) teacher/usage_max 0.9352 (0.9695) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4264 (0.4502) nleep/row_max_mean 1536.0627 (1539.7609) nleep/row_max_std 30.3070 (39.8343) nleep/row_min_mean 1490.8508 (1493.4997) lr 1.8763e-03 eta 0:14:15
epoch [10/50] batch [60/132] time 0.143 (0.159) data 0.000 (0.006) loss 1.0925 (1.0998) teacher_loss 0.1945 (0.1639) loss_zs_kd 0.0065 (0.0064) loss_oracle 0.4217 (0.4470) kd_loss 0.6840 (0.7092) acc 93.7500 (94.3750) gate/entropy 1.0399 (1.0446) gate/usage_max 0.4995 (0.4923) gate/usage_min 0.2435 (0.2460) gate/usage_std 0.1176 (0.1126) teacher/entropy 0.0225 (0.0211) teacher/usage_max 0.9830 (0.9685) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4594 (0.4495) nleep/row_max_mean 1540.7246 (1540.8591) nleep/row_max_std 38.9872 (39.0107) nleep/row_min_mean 1495.7935 (1494.2544) lr 1.8763e-03 eta 0:14:11
epoch [10/50] batch [80/132] time 0.105 (0.148) data 0.000 (0.004) loss 1.1193 (1.0849) teacher_loss 0.2506 (0.1548) loss_zs_kd 0.0020 (0.0064) loss_oracle 0.3894 (0.4460) kd_loss 0.6730 (0.7039) acc 93.7500 (94.6875) gate/entropy 1.0369 (1.0430) gate/usage_max 0.5038 (0.4947) gate/usage_min 0.2421 (0.2452) gate/usage_std 0.1206 (0.1143) teacher/entropy 0.0398 (0.0221) teacher/usage_max 0.9631 (0.9681) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4455 (0.4492) nleep/row_max_mean 1529.3081 (1539.6530) nleep/row_max_std 41.6143 (39.1074) nleep/row_min_mean 1484.3828 (1493.2659) lr 1.8763e-03 eta 0:13:10
epoch [10/50] batch [100/132] time 0.090 (0.143) data 0.000 (0.003) loss 1.1652 (1.0883) teacher_loss 0.2610 (0.1629) loss_zs_kd 0.0030 (0.0064) loss_oracle 0.4341 (0.4413) kd_loss 0.6856 (0.7015) acc 87.5000 (94.3750) gate/entropy 1.0336 (1.0415) gate/usage_max 0.5085 (0.4970) gate/usage_min 0.2403 (0.2444) gate/usage_std 0.1239 (0.1159) teacher/entropy 0.0116 (0.0218) teacher/usage_max 0.9719 (0.9659) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4517 (0.4477) nleep/row_max_mean 1536.8694 (1537.7399) nleep/row_max_std 30.7017 (38.8314) nleep/row_min_mean 1491.9785 (1491.9173) lr 1.8763e-03 eta 0:12:37
epoch [10/50] batch [120/132] time 0.080 (0.136) data 0.000 (0.003) loss 1.1849 (1.0874) teacher_loss 0.2542 (0.1654) loss_zs_kd 0.0110 (0.0065) loss_oracle 0.4549 (0.4387) kd_loss 0.6978 (0.6994) acc 87.5000 (94.1927) gate/entropy 1.0313 (1.0400) gate/usage_max 0.5117 (0.4991) gate/usage_min 0.2393 (0.2437) gate/usage_std 0.1262 (0.1174) teacher/entropy 0.0372 (0.0238) teacher/usage_max 0.9140 (0.9605) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4121 (0.4440) nleep/row_max_mean 1527.0281 (1536.3505) nleep/row_max_std 35.0851 (38.9224) nleep/row_min_mean 1487.5581 (1491.0192) lr 1.8763e-03 eta 0:12:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,518
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.8%
******* Domain s best val acc:      99.5%, epoch: 9 *******
******* Domain s best val test acc: 90.2%, epoch: 9 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [11/50] batch [20/132] time 0.087 (0.123) data 0.000 (0.018) loss 0.9841 (1.0285) teacher_loss 0.1574 (0.1494) loss_zs_kd 0.0075 (0.0069) loss_oracle 0.3411 (0.3820) kd_loss 0.6524 (0.6846) acc 93.7500 (94.6875) gate/entropy 1.0275 (1.0288) gate/usage_max 0.5168 (0.5150) gate/usage_min 0.2378 (0.2384) gate/usage_std 0.1297 (0.1285) teacher/entropy 0.0508 (0.0432) teacher/usage_max 0.9441 (0.9160) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4324 (0.4138) nleep/row_max_mean 1539.7211 (1533.0990) nleep/row_max_std 39.1342 (37.2317) nleep/row_min_mean 1492.7245 (1489.4281) lr 1.8443e-03 eta 0:10:45
epoch [11/50] batch [40/132] time 0.086 (0.116) data 0.000 (0.009) loss 1.0836 (1.0361) teacher_loss 0.1840 (0.1506) loss_zs_kd 0.0031 (0.0067) loss_oracle 0.4927 (0.3915) kd_loss 0.6516 (0.6864) acc 93.7500 (94.5312) gate/entropy 1.0258 (1.0277) gate/usage_max 0.5190 (0.5165) gate/usage_min 0.2372 (0.2379) gate/usage_std 0.1313 (0.1295) teacher/entropy 0.0850 (0.0482) teacher/usage_max 0.8964 (0.9042) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4004 (0.4062) nleep/row_max_mean 1534.4380 (1533.4501) nleep/row_max_std 39.1187 (37.1221) nleep/row_min_mean 1494.7114 (1490.2139) lr 1.8443e-03 eta 0:10:07
epoch [11/50] batch [60/132] time 0.178 (0.120) data 0.001 (0.006) loss 1.0573 (1.0464) teacher_loss 0.2109 (0.1533) loss_zs_kd 0.0067 (0.0071) loss_oracle 0.3428 (0.3932) kd_loss 0.6717 (0.6930) acc 93.7500 (94.6875) gate/entropy 1.0238 (1.0267) gate/usage_max 0.5216 (0.5178) gate/usage_min 0.2365 (0.2376) gate/usage_std 0.1331 (0.1305) teacher/entropy 0.0848 (0.0517) teacher/usage_max 0.8663 (0.8885) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3808 (0.3959) nleep/row_max_mean 1526.4954 (1532.5587) nleep/row_max_std 32.2690 (36.8036) nleep/row_min_mean 1489.5065 (1489.9067) lr 1.8443e-03 eta 0:10:26
epoch [11/50] batch [80/132] time 0.152 (0.123) data 0.000 (0.005) loss 0.9495 (1.0534) teacher_loss 0.0258 (0.1473) loss_zs_kd 0.0132 (0.0071) loss_oracle 0.4144 (0.3909) kd_loss 0.7098 (0.7071) acc 100.0000 (94.8828) gate/entropy 1.0223 (1.0257) gate/usage_max 0.5235 (0.5190) gate/usage_min 0.2360 (0.2372) gate/usage_std 0.1345 (0.1313) teacher/entropy 0.0514 (0.0523) teacher/usage_max 0.8554 (0.8674) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3739 (0.3830) nleep/row_max_mean 1529.1760 (1532.3026) nleep/row_max_std 28.6147 (36.5487) nleep/row_min_mean 1487.3655 (1489.8209) lr 1.8443e-03 eta 0:10:38
epoch [11/50] batch [100/132] time 0.158 (0.122) data 0.000 (0.004) loss 1.0683 (1.0606) teacher_loss 0.1769 (0.1506) loss_zs_kd 0.0022 (0.0075) loss_oracle 0.4077 (0.3922) kd_loss 0.6864 (0.7102) acc 90.6250 (94.7812) gate/entropy 1.0206 (1.0248) gate/usage_max 0.5257 (0.5202) gate/usage_min 0.2355 (0.2369) gate/usage_std 0.1360 (0.1322) teacher/entropy 0.0293 (0.0509) teacher/usage_max 0.9098 (0.8630) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4093 (0.3803) nleep/row_max_mean 1530.9421 (1531.3898) nleep/row_max_std 37.4863 (36.9142) nleep/row_min_mean 1490.0917 (1489.2204) lr 1.8443e-03 eta 0:10:33
epoch [11/50] batch [120/132] time 0.163 (0.128) data 0.000 (0.003) loss 1.1756 (1.0716) teacher_loss 0.2088 (0.1532) loss_zs_kd 0.0176 (0.0080) loss_oracle 0.4699 (0.4004) kd_loss 0.7230 (0.7141) acc 96.8750 (94.8177) gate/entropy 1.0191 (1.0239) gate/usage_max 0.5275 (0.5213) gate/usage_min 0.2352 (0.2366) gate/usage_std 0.1373 (0.1330) teacher/entropy 0.0441 (0.0524) teacher/usage_max 0.8414 (0.8541) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3650 (0.3748) nleep/row_max_mean 1517.0312 (1531.3593) nleep/row_max_std 44.8475 (36.9949) nleep/row_min_mean 1478.8365 (1489.3906) lr 1.8443e-03 eta 0:11:00
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,531
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.3%
******* Domain s best val acc:      99.5%, epoch: 9 *******
******* Domain s best val test acc: 90.2%, epoch: 9 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [12/50] batch [20/132] time 0.166 (0.180) data 0.000 (0.016) loss 1.1555 (1.1265) teacher_loss 0.1293 (0.1330) loss_zs_kd 0.0043 (0.0075) loss_oracle 0.4202 (0.4514) kd_loss 0.8139 (0.7641) acc 96.8750 (95.9375) gate/entropy 1.0170 (1.0179) gate/usage_max 0.5301 (0.5291) gate/usage_min 0.2348 (0.2351) gate/usage_std 0.1391 (0.1384) teacher/entropy 0.0574 (0.0518) teacher/usage_max 0.7075 (0.7780) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2903 (0.3311) nleep/row_max_mean 1545.2543 (1535.3183) nleep/row_max_std 40.4260 (37.9127) nleep/row_min_mean 1504.0234 (1493.0543) lr 1.8090e-03 eta 0:15:21
epoch [12/50] batch [40/132] time 0.092 (0.156) data 0.000 (0.008) loss 1.0825 (1.1162) teacher_loss 0.1699 (0.1421) loss_zs_kd 0.0096 (0.0090) loss_oracle 0.4043 (0.4423) kd_loss 0.7057 (0.7485) acc 93.7500 (94.9219) gate/entropy 1.0162 (1.0173) gate/usage_max 0.5311 (0.5298) gate/usage_min 0.2341 (0.2348) gate/usage_std 0.1399 (0.1389) teacher/entropy 0.0653 (0.0515) teacher/usage_max 0.8306 (0.7965) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3583 (0.3409) nleep/row_max_mean 1525.4666 (1534.2538) nleep/row_max_std 47.5343 (40.3787) nleep/row_min_mean 1485.4480 (1492.2040) lr 1.8090e-03 eta 0:13:16
epoch [12/50] batch [60/132] time 0.073 (0.142) data 0.000 (0.005) loss 1.3237 (1.1163) teacher_loss 0.3543 (0.1559) loss_zs_kd 0.0228 (0.0099) loss_oracle 0.4732 (0.4329) kd_loss 0.7215 (0.7391) acc 81.2500 (94.4792) gate/entropy 1.0141 (1.0166) gate/usage_max 0.5337 (0.5306) gate/usage_min 0.2326 (0.2344) gate/usage_std 0.1417 (0.1395) teacher/entropy 0.0083 (0.0456) teacher/usage_max 0.8766 (0.8139) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3874 (0.3511) nleep/row_max_mean 1544.7903 (1535.3197) nleep/row_max_std 47.7572 (40.8784) nleep/row_min_mean 1496.9789 (1492.8522) lr 1.8090e-03 eta 0:12:01
epoch [12/50] batch [80/132] time 0.086 (0.133) data 0.000 (0.004) loss 1.0236 (1.1060) teacher_loss 0.0843 (0.1530) loss_zs_kd 0.0108 (0.0099) loss_oracle 0.4935 (0.4318) kd_loss 0.6872 (0.7321) acc 96.8750 (94.6484) gate/entropy 1.0133 (1.0160) gate/usage_max 0.5346 (0.5314) gate/usage_min 0.2319 (0.2339) gate/usage_std 0.1424 (0.1401) teacher/entropy 0.0429 (0.0431) teacher/usage_max 0.8735 (0.8242) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3854 (0.3570) nleep/row_max_mean 1527.6826 (1535.8403) nleep/row_max_std 51.5863 (42.1798) nleep/row_min_mean 1485.5979 (1493.2776) lr 1.8090e-03 eta 0:11:13
epoch [12/50] batch [100/132] time 0.094 (0.131) data 0.000 (0.003) loss 1.0098 (1.0943) teacher_loss 0.1296 (0.1537) loss_zs_kd 0.0092 (0.0097) loss_oracle 0.4311 (0.4280) kd_loss 0.6601 (0.7217) acc 96.8750 (94.6875) gate/entropy 1.0126 (1.0153) gate/usage_max 0.5355 (0.5322) gate/usage_min 0.2312 (0.2334) gate/usage_std 0.1430 (0.1406) teacher/entropy 0.0391 (0.0431) teacher/usage_max 0.9100 (0.8357) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4094 (0.3640) nleep/row_max_mean 1526.4531 (1535.6635) nleep/row_max_std 44.8322 (42.7696) nleep/row_min_mean 1484.7860 (1493.3861) lr 1.8090e-03 eta 0:10:59
epoch [12/50] batch [120/132] time 0.081 (0.127) data 0.000 (0.003) loss 0.8814 (1.0811) teacher_loss 0.0490 (0.1512) loss_zs_kd 0.0180 (0.0100) loss_oracle 0.4084 (0.4245) kd_loss 0.6192 (0.7126) acc 100.0000 (94.8698) gate/entropy 1.0107 (1.0147) gate/usage_max 0.5377 (0.5330) gate/usage_min 0.2300 (0.2329) gate/usage_std 0.1445 (0.1412) teacher/entropy 0.0623 (0.0411) teacher/usage_max 0.9267 (0.8478) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4206 (0.3715) nleep/row_max_mean 1531.4380 (1535.1905) nleep/row_max_std 51.9820 (42.9209) nleep/row_min_mean 1493.1379 (1493.2573) lr 1.8090e-03 eta 0:10:36
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,547
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.4%
******* Domain s best val acc:      99.5%, epoch: 9 *******
******* Domain s best val test acc: 90.2%, epoch: 9 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [13/50] batch [20/132] time 0.149 (0.134) data 0.000 (0.013) loss 1.0530 (1.0159) teacher_loss 0.2432 (0.1591) loss_zs_kd 0.0118 (0.0069) loss_oracle 0.3862 (0.3999) kd_loss 0.6108 (0.6534) acc 93.7500 (95.3125) gate/entropy 1.0085 (1.0091) gate/usage_max 0.5403 (0.5396) gate/usage_min 0.2286 (0.2290) gate/usage_std 0.1464 (0.1459) teacher/entropy 0.0214 (0.0274) teacher/usage_max 0.9806 (0.9244) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4578 (0.4197) nleep/row_max_mean 1537.6902 (1535.3417) nleep/row_max_std 44.7469 (43.4966) nleep/row_min_mean 1496.5562 (1495.5345) lr 1.7705e-03 eta 0:11:10
epoch [13/50] batch [40/132] time 0.156 (0.125) data 0.000 (0.007) loss 1.0280 (1.0042) teacher_loss 0.2067 (0.1635) loss_zs_kd 0.0173 (0.0084) loss_oracle 0.3059 (0.3767) kd_loss 0.6597 (0.6482) acc 90.6250 (95.0781) gate/entropy 1.0076 (1.0085) gate/usage_max 0.5414 (0.5403) gate/usage_min 0.2280 (0.2286) gate/usage_std 0.1471 (0.1464) teacher/entropy 0.0065 (0.0292) teacher/usage_max 0.9383 (0.9270) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4285 (0.4215) nleep/row_max_mean 1527.1772 (1535.3964) nleep/row_max_std 47.3880 (43.7210) nleep/row_min_mean 1487.7490 (1495.2768) lr 1.7705e-03 eta 0:10:23
epoch [13/50] batch [60/132] time 0.126 (0.120) data 0.000 (0.005) loss 1.0711 (1.0028) teacher_loss 0.1529 (0.1665) loss_zs_kd 0.0057 (0.0086) loss_oracle 0.5080 (0.3784) kd_loss 0.6613 (0.6427) acc 96.8750 (94.8438) gate/entropy 1.0059 (1.0079) gate/usage_max 0.5434 (0.5411) gate/usage_min 0.2270 (0.2282) gate/usage_std 0.1485 (0.1469) teacher/entropy 0.0395 (0.0292) teacher/usage_max 0.8948 (0.9322) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3994 (0.4249) nleep/row_max_mean 1527.1440 (1533.7657) nleep/row_max_std 45.5578 (45.1307) nleep/row_min_mean 1489.6890 (1494.1095) lr 1.7705e-03 eta 0:09:54
epoch [13/50] batch [80/132] time 0.138 (0.127) data 0.000 (0.003) loss 1.0382 (1.0010) teacher_loss 0.1951 (0.1590) loss_zs_kd 0.0132 (0.0086) loss_oracle 0.3635 (0.3885) kd_loss 0.6548 (0.6434) acc 96.8750 (95.2344) gate/entropy 1.0048 (1.0072) gate/usage_max 0.5446 (0.5418) gate/usage_min 0.2263 (0.2278) gate/usage_std 0.1494 (0.1474) teacher/entropy 0.0059 (0.0263) teacher/usage_max 0.9386 (0.9333) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4287 (0.4256) nleep/row_max_mean 1526.9447 (1532.7634) nleep/row_max_std 35.9867 (45.7097) nleep/row_min_mean 1489.2405 (1493.4079) lr 1.7705e-03 eta 0:10:28
epoch [13/50] batch [100/132] time 0.163 (0.131) data 0.000 (0.003) loss 0.9126 (0.9997) teacher_loss 0.0952 (0.1610) loss_zs_kd 0.0091 (0.0088) loss_oracle 0.4278 (0.3911) kd_loss 0.5990 (0.6388) acc 96.8750 (95.0312) gate/entropy 1.0039 (1.0066) gate/usage_max 0.5456 (0.5425) gate/usage_min 0.2258 (0.2275) gate/usage_std 0.1501 (0.1479) teacher/entropy 0.0696 (0.0268) teacher/usage_max 0.9276 (0.9369) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4213 (0.4280) nleep/row_max_mean 1525.7346 (1532.6367) nleep/row_max_std 45.4049 (44.6837) nleep/row_min_mean 1484.2188 (1493.1345) lr 1.7705e-03 eta 0:10:45
epoch [13/50] batch [120/132] time 0.155 (0.135) data 0.000 (0.002) loss 0.8496 (0.9965) teacher_loss 0.0464 (0.1621) loss_zs_kd 0.0002 (0.0086) loss_oracle 0.3778 (0.3907) kd_loss 0.6143 (0.6348) acc 96.8750 (94.8177) gate/entropy 1.0032 (1.0061) gate/usage_max 0.5464 (0.5432) gate/usage_min 0.2254 (0.2271) gate/usage_std 0.1507 (0.1484) teacher/entropy 0.0263 (0.0261) teacher/usage_max 0.9582 (0.9411) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4421 (0.4308) nleep/row_max_mean 1526.0078 (1532.6774) nleep/row_max_std 52.2351 (44.6325) nleep/row_min_mean 1484.9692 (1493.0450) lr 1.7705e-03 eta 0:11:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,553
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.7%
******* Domain s best val acc:      99.5%, epoch: 9 *******
******* Domain s best val test acc: 90.2%, epoch: 9 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [14/50] batch [20/132] time 0.093 (0.110) data 0.000 (0.013) loss 1.0351 (1.0197) teacher_loss 0.2428 (0.2123) loss_zs_kd 0.0099 (0.0069) loss_oracle 0.3632 (0.3744) kd_loss 0.6058 (0.6168) acc 90.6250 (93.2812) gate/entropy 1.0012 (1.0014) gate/usage_max 0.5487 (0.5485) gate/usage_min 0.2242 (0.2244) gate/usage_std 0.1523 (0.1522) teacher/entropy 0.0501 (0.0236) teacher/usage_max 0.9366 (0.9547) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4273 (0.4400) nleep/row_max_mean 1528.7319 (1537.0088) nleep/row_max_std 44.6588 (42.2884) nleep/row_min_mean 1486.1714 (1495.2189) lr 1.7290e-03 eta 0:08:55
epoch [14/50] batch [40/132] time 0.073 (0.112) data 0.000 (0.007) loss 0.8091 (0.9782) teacher_loss 0.0569 (0.1688) loss_zs_kd 0.0011 (0.0065) loss_oracle 0.3307 (0.3835) kd_loss 0.5863 (0.6144) acc 96.8750 (94.3750) gate/entropy 0.9998 (1.0010) gate/usage_max 0.5502 (0.5490) gate/usage_min 0.2235 (0.2241) gate/usage_std 0.1534 (0.1525) teacher/entropy 0.0186 (0.0224) teacher/usage_max 0.9916 (0.9579) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4655 (0.4422) nleep/row_max_mean 1549.8442 (1537.2769) nleep/row_max_std 36.9417 (40.8977) nleep/row_min_mean 1506.0356 (1494.8354) lr 1.7290e-03 eta 0:09:01
epoch [14/50] batch [60/132] time 0.185 (0.115) data 0.000 (0.005) loss 0.9446 (0.9636) teacher_loss 0.1402 (0.1526) loss_zs_kd 0.0065 (0.0065) loss_oracle 0.4248 (0.3876) kd_loss 0.5888 (0.6139) acc 93.7500 (94.8958) gate/entropy 0.9991 (1.0005) gate/usage_max 0.5511 (0.5495) gate/usage_min 0.2230 (0.2238) gate/usage_std 0.1540 (0.1529) teacher/entropy 0.0218 (0.0235) teacher/usage_max 0.9833 (0.9562) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4597 (0.4411) nleep/row_max_mean 1534.9407 (1536.0225) nleep/row_max_std 38.2021 (40.5160) nleep/row_min_mean 1496.6987 (1494.0759) lr 1.7290e-03 eta 0:09:13
epoch [14/50] batch [80/132] time 0.088 (0.113) data 0.000 (0.003) loss 0.8817 (0.9648) teacher_loss 0.0898 (0.1550) loss_zs_kd 0.0034 (0.0068) loss_oracle 0.3070 (0.3842) kd_loss 0.6367 (0.6143) acc 96.8750 (94.8828) gate/entropy 0.9984 (1.0000) gate/usage_max 0.5519 (0.5500) gate/usage_min 0.2226 (0.2236) gate/usage_std 0.1545 (0.1532) teacher/entropy 0.0137 (0.0241) teacher/usage_max 0.9366 (0.9541) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4273 (0.4396) nleep/row_max_mean 1538.2537 (1536.4566) nleep/row_max_std 42.0769 (40.4078) nleep/row_min_mean 1496.6790 (1494.6027) lr 1.7290e-03 eta 0:09:01
epoch [14/50] batch [100/132] time 0.069 (0.114) data 0.000 (0.003) loss 1.0036 (0.9568) teacher_loss 0.1482 (0.1497) loss_zs_kd 0.0049 (0.0065) loss_oracle 0.4198 (0.3796) kd_loss 0.6430 (0.6141) acc 93.7500 (95.0312) gate/entropy 0.9974 (0.9996) gate/usage_max 0.5529 (0.5505) gate/usage_min 0.2221 (0.2233) gate/usage_std 0.1553 (0.1535) teacher/entropy 0.0050 (0.0241) teacher/usage_max 0.9375 (0.9535) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4279 (0.4392) nleep/row_max_mean 1530.0579 (1536.1532) nleep/row_max_std 49.6933 (40.7156) nleep/row_min_mean 1490.2958 (1494.5269) lr 1.7290e-03 eta 0:09:03
epoch [14/50] batch [120/132] time 0.184 (0.114) data 0.000 (0.002) loss 0.9232 (0.9593) teacher_loss 0.1101 (0.1522) loss_zs_kd 0.0019 (0.0065) loss_oracle 0.4095 (0.3806) kd_loss 0.6074 (0.6135) acc 93.7500 (94.8438) gate/entropy 0.9967 (0.9992) gate/usage_max 0.5537 (0.5509) gate/usage_min 0.2217 (0.2231) gate/usage_std 0.1558 (0.1539) teacher/entropy 0.0229 (0.0245) teacher/usage_max 0.9563 (0.9528) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4409 (0.4387) nleep/row_max_mean 1536.0684 (1535.8200) nleep/row_max_std 46.4367 (41.3047) nleep/row_min_mean 1495.6567 (1494.4564) lr 1.7290e-03 eta 0:09:03
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,539
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.5%
******* Domain s best val acc:      99.5%, epoch: 14 *******
******* Domain s best val test acc: 90.1%, epoch: 14 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [15/50] batch [20/132] time 0.125 (0.135) data 0.000 (0.011) loss 1.1474 (0.9579) teacher_loss 0.3003 (0.1501) loss_zs_kd 0.0167 (0.0067) loss_oracle 0.3380 (0.3826) kd_loss 0.6698 (0.6131) acc 87.5000 (95.1562) gate/entropy 0.9953 (0.9959) gate/usage_max 0.5552 (0.5545) gate/usage_min 0.2210 (0.2213) gate/usage_std 0.1569 (0.1564) teacher/entropy 0.0035 (0.0252) teacher/usage_max 0.9061 (0.9459) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4068 (0.4341) nleep/row_max_mean 1544.4630 (1535.9793) nleep/row_max_std 27.5484 (39.5633) nleep/row_min_mean 1506.2896 (1497.0830) lr 1.6845e-03 eta 0:10:38
epoch [15/50] batch [40/132] time 0.137 (0.146) data 0.000 (0.005) loss 0.9715 (0.9781) teacher_loss 0.0330 (0.1703) loss_zs_kd 0.0071 (0.0069) loss_oracle 0.5305 (0.3855) kd_loss 0.6697 (0.6115) acc 100.0000 (94.0625) gate/entropy 0.9954 (0.9956) gate/usage_max 0.5551 (0.5549) gate/usage_min 0.2210 (0.2211) gate/usage_std 0.1568 (0.1567) teacher/entropy 0.0624 (0.0274) teacher/usage_max 0.8412 (0.9445) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3649 (0.4331) nleep/row_max_mean 1520.7596 (1533.7997) nleep/row_max_std 45.2796 (41.2876) nleep/row_min_mean 1483.8281 (1495.0100) lr 1.6845e-03 eta 0:11:26
epoch [15/50] batch [60/132] time 0.151 (0.147) data 0.001 (0.004) loss 0.8536 (0.9711) teacher_loss 0.0859 (0.1590) loss_zs_kd 0.0070 (0.0066) loss_oracle 0.3899 (0.3972) kd_loss 0.5693 (0.6101) acc 96.8750 (94.7917) gate/entropy 0.9945 (0.9953) gate/usage_max 0.5561 (0.5552) gate/usage_min 0.2206 (0.2210) gate/usage_std 0.1575 (0.1569) teacher/entropy 0.0309 (0.0293) teacher/usage_max 0.9852 (0.9435) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4610 (0.4324) nleep/row_max_mean 1533.4272 (1531.8003) nleep/row_max_std 39.3037 (41.1527) nleep/row_min_mean 1496.5427 (1493.1702) lr 1.6845e-03 eta 0:11:28
epoch [15/50] batch [80/132] time 0.152 (0.149) data 0.000 (0.003) loss 0.9201 (0.9673) teacher_loss 0.0738 (0.1579) loss_zs_kd 0.0110 (0.0068) loss_oracle 0.4108 (0.3937) kd_loss 0.6354 (0.6091) acc 96.8750 (94.6484) gate/entropy 0.9937 (0.9950) gate/usage_max 0.5570 (0.5556) gate/usage_min 0.2202 (0.2208) gate/usage_std 0.1581 (0.1572) teacher/entropy 0.0084 (0.0286) teacher/usage_max 0.9357 (0.9447) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4267 (0.4332) nleep/row_max_mean 1523.0381 (1532.5222) nleep/row_max_std 42.5498 (40.7951) nleep/row_min_mean 1490.8241 (1493.9893) lr 1.6845e-03 eta 0:11:37
epoch [15/50] batch [100/132] time 0.172 (0.152) data 0.000 (0.002) loss 1.0587 (0.9644) teacher_loss 0.1921 (0.1527) loss_zs_kd 0.0043 (0.0065) loss_oracle 0.4329 (0.3947) kd_loss 0.6480 (0.6110) acc 93.7500 (94.9688) gate/entropy 0.9935 (0.9947) gate/usage_max 0.5572 (0.5559) gate/usage_min 0.2201 (0.2207) gate/usage_std 0.1583 (0.1574) teacher/entropy 0.0222 (0.0300) teacher/usage_max 0.9064 (0.9405) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4070 (0.4304) nleep/row_max_mean 1529.0864 (1532.2263) nleep/row_max_std 46.0754 (41.0878) nleep/row_min_mean 1488.7092 (1493.7544) lr 1.6845e-03 eta 0:11:47
epoch [15/50] batch [120/132] time 0.153 (0.154) data 0.000 (0.002) loss 1.0336 (0.9603) teacher_loss 0.2255 (0.1497) loss_zs_kd 0.0046 (0.0063) loss_oracle 0.4126 (0.3922) kd_loss 0.5995 (0.6113) acc 87.5000 (95.0000) gate/entropy 0.9929 (0.9944) gate/usage_max 0.5579 (0.5562) gate/usage_min 0.2197 (0.2205) gate/usage_std 0.1588 (0.1576) teacher/entropy 0.0183 (0.0327) teacher/usage_max 0.9626 (0.9368) teacher/usage_min 0.0002 (0.0000) teacher/usage_std 0.4452 (0.4279) nleep/row_max_mean 1530.0094 (1532.0875) nleep/row_max_std 41.3608 (41.3362) nleep/row_min_mean 1495.2095 (1493.7621) lr 1.6845e-03 eta 0:11:51
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,532
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.2%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [16/50] batch [20/132] time 0.077 (0.123) data 0.000 (0.012) loss 0.8620 (1.0299) teacher_loss 0.0675 (0.1989) loss_zs_kd 0.0146 (0.0053) loss_oracle 0.3888 (0.4079) kd_loss 0.5929 (0.6244) acc 100.0000 (93.1250) gate/entropy 0.9923 (0.9924) gate/usage_max 0.5584 (0.5583) gate/usage_min 0.2194 (0.2195) gate/usage_std 0.1592 (0.1591) teacher/entropy 0.0679 (0.0410) teacher/usage_max 0.9146 (0.9099) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4125 (0.4100) nleep/row_max_mean 1530.3878 (1525.9706) nleep/row_max_std 49.6042 (42.8655) nleep/row_min_mean 1494.5475 (1490.9309) lr 1.6374e-03 eta 0:09:24
epoch [16/50] batch [40/132] time 0.075 (0.122) data 0.000 (0.006) loss 1.0028 (1.0082) teacher_loss 0.0800 (0.1675) loss_zs_kd 0.0043 (0.0058) loss_oracle 0.3816 (0.4052) kd_loss 0.7299 (0.6353) acc 96.8750 (94.3750) gate/entropy 0.9920 (0.9923) gate/usage_max 0.5588 (0.5586) gate/usage_min 0.2192 (0.2194) gate/usage_std 0.1594 (0.1593) teacher/entropy 0.0741 (0.0411) teacher/usage_max 0.7582 (0.8976) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.3162 (0.4019) nleep/row_max_mean 1530.9260 (1524.6667) nleep/row_max_std 45.2404 (43.8162) nleep/row_min_mean 1497.0833 (1489.7870) lr 1.6374e-03 eta 0:09:20
epoch [16/50] batch [60/132] time 0.088 (0.120) data 0.000 (0.004) loss 1.0615 (1.0143) teacher_loss 0.1778 (0.1672) loss_zs_kd 0.0090 (0.0064) loss_oracle 0.4426 (0.4031) kd_loss 0.6579 (0.6423) acc 90.6250 (94.2708) gate/entropy 0.9915 (0.9921) gate/usage_max 0.5594 (0.5588) gate/usage_min 0.2190 (0.2193) gate/usage_std 0.1598 (0.1594) teacher/entropy 0.0262 (0.0402) teacher/usage_max 0.8878 (0.8906) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.3947 (0.3973) nleep/row_max_mean 1511.0435 (1523.9272) nleep/row_max_std 53.7940 (44.0006) nleep/row_min_mean 1478.5320 (1489.1153) lr 1.6374e-03 eta 0:09:08
epoch [16/50] batch [80/132] time 0.077 (0.118) data 0.000 (0.003) loss 1.0559 (1.0169) teacher_loss 0.1126 (0.1714) loss_zs_kd 0.0055 (0.0064) loss_oracle 0.5080 (0.4043) kd_loss 0.6865 (0.6401) acc 93.7500 (94.0234) gate/entropy 0.9914 (0.9919) gate/usage_max 0.5594 (0.5590) gate/usage_min 0.2189 (0.2192) gate/usage_std 0.1599 (0.1596) teacher/entropy 0.0649 (0.0437) teacher/usage_max 0.8154 (0.8888) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3491 (0.3961) nleep/row_max_mean 1527.9155 (1523.7796) nleep/row_max_std 27.8551 (44.4097) nleep/row_min_mean 1494.4657 (1489.2070) lr 1.6374e-03 eta 0:08:57
epoch [16/50] batch [100/132] time 0.171 (0.122) data 0.000 (0.003) loss 0.9950 (1.0180) teacher_loss 0.1547 (0.1719) loss_zs_kd 0.0132 (0.0063) loss_oracle 0.4775 (0.4086) kd_loss 0.5949 (0.6387) acc 96.8750 (94.0312) gate/entropy 0.9910 (0.9917) gate/usage_max 0.5598 (0.5592) gate/usage_min 0.2187 (0.2190) gate/usage_std 0.1602 (0.1597) teacher/entropy 0.1010 (0.0453) teacher/usage_max 0.8747 (0.8885) teacher/usage_min 0.0009 (0.0009) teacher/usage_std 0.3861 (0.3958) nleep/row_max_mean 1514.3374 (1523.8617) nleep/row_max_std 48.0283 (44.4705) nleep/row_min_mean 1482.5178 (1489.2333) lr 1.6374e-03 eta 0:09:09
epoch [16/50] batch [120/132] time 0.076 (0.119) data 0.000 (0.002) loss 0.9769 (1.0197) teacher_loss 0.1090 (0.1725) loss_zs_kd 0.0031 (0.0062) loss_oracle 0.5294 (0.4112) kd_loss 0.6017 (0.6384) acc 96.8750 (93.9062) gate/entropy 0.9905 (0.9915) gate/usage_max 0.5604 (0.5594) gate/usage_min 0.2184 (0.2190) gate/usage_std 0.1606 (0.1598) teacher/entropy 0.1027 (0.0486) teacher/usage_max 0.8654 (0.8848) teacher/usage_min 0.0162 (0.0012) teacher/usage_std 0.3785 (0.3934) nleep/row_max_mean 1523.3201 (1523.3627) nleep/row_max_std 38.6979 (44.3930) nleep/row_min_mean 1491.5842 (1489.0152) lr 1.6374e-03 eta 0:08:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,549
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.7%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [17/50] batch [20/132] time 0.161 (0.166) data 0.000 (0.015) loss 1.0337 (1.0650) teacher_loss 0.0384 (0.1487) loss_zs_kd 0.0005 (0.0040) loss_oracle 0.4826 (0.4696) kd_loss 0.7538 (0.6795) acc 100.0000 (95.1562) gate/entropy 0.9904 (0.9904) gate/usage_max 0.5606 (0.5605) gate/usage_min 0.2182 (0.2183) gate/usage_std 0.1607 (0.1606) teacher/entropy 0.0221 (0.0801) teacher/usage_max 0.7876 (0.8052) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.3327 (0.3442) nleep/row_max_mean 1535.7338 (1527.5307) nleep/row_max_std 39.0342 (43.7202) nleep/row_min_mean 1497.6096 (1493.3422) lr 1.5878e-03 eta 0:12:19
epoch [17/50] batch [40/132] time 0.191 (0.153) data 0.000 (0.007) loss 1.0923 (1.1044) teacher_loss 0.1671 (0.1655) loss_zs_kd 0.0086 (0.0062) loss_oracle 0.5335 (0.4876) kd_loss 0.6541 (0.6920) acc 93.7500 (94.4531) gate/entropy 0.9902 (0.9903) gate/usage_max 0.5607 (0.5606) gate/usage_min 0.2181 (0.2182) gate/usage_std 0.1608 (0.1607) teacher/entropy 0.1367 (0.0783) teacher/usage_max 0.7710 (0.7951) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3233 (0.3399) nleep/row_max_mean 1526.9620 (1530.0401) nleep/row_max_std 43.8226 (43.8237) nleep/row_min_mean 1490.7565 (1495.2957) lr 1.5878e-03 eta 0:11:20
epoch [17/50] batch [60/132] time 0.171 (0.153) data 0.000 (0.005) loss 1.0818 (1.1114) teacher_loss 0.0781 (0.1652) loss_zs_kd 0.0175 (0.0065) loss_oracle 0.4769 (0.4752) kd_loss 0.7565 (0.7053) acc 96.8750 (94.3750) gate/entropy 0.9901 (0.9903) gate/usage_max 0.5608 (0.5606) gate/usage_min 0.2179 (0.2181) gate/usage_std 0.1609 (0.1607) teacher/entropy 0.0582 (0.0758) teacher/usage_max 0.7447 (0.7828) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.3090 (0.3323) nleep/row_max_mean 1526.2164 (1529.6104) nleep/row_max_std 51.1027 (44.7262) nleep/row_min_mean 1492.3750 (1494.8754) lr 1.5878e-03 eta 0:11:16
epoch [17/50] batch [80/132] time 0.101 (0.146) data 0.000 (0.004) loss 0.9268 (1.1023) teacher_loss 0.0261 (0.1546) loss_zs_kd 0.0051 (0.0072) loss_oracle 0.4146 (0.4679) kd_loss 0.6908 (0.7101) acc 100.0000 (94.7656) gate/entropy 0.9899 (0.9902) gate/usage_max 0.5610 (0.5607) gate/usage_min 0.2178 (0.2181) gate/usage_std 0.1610 (0.1608) teacher/entropy 0.0748 (0.0715) teacher/usage_max 0.7978 (0.7818) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3386 (0.3318) nleep/row_max_mean 1522.8556 (1529.7027) nleep/row_max_std 47.3427 (45.2980) nleep/row_min_mean 1489.3833 (1495.0450) lr 1.5878e-03 eta 0:10:41
epoch [17/50] batch [100/132] time 0.169 (0.140) data 0.000 (0.003) loss 1.1273 (1.1030) teacher_loss 0.0615 (0.1537) loss_zs_kd 0.0146 (0.0079) loss_oracle 0.5757 (0.4688) kd_loss 0.7707 (0.7110) acc 100.0000 (94.8125) gate/entropy 0.9898 (0.9901) gate/usage_max 0.5612 (0.5608) gate/usage_min 0.2177 (0.2180) gate/usage_std 0.1611 (0.1609) teacher/entropy 0.0359 (0.0689) teacher/usage_max 0.7539 (0.7834) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.3139 (0.3324) nleep/row_max_mean 1528.8868 (1529.5024) nleep/row_max_std 48.7370 (44.8598) nleep/row_min_mean 1493.2412 (1495.0303) lr 1.5878e-03 eta 0:10:16
epoch [17/50] batch [120/132] time 0.074 (0.134) data 0.000 (0.003) loss 0.9775 (1.1030) teacher_loss 0.0750 (0.1473) loss_zs_kd 0.0080 (0.0081) loss_oracle 0.3748 (0.4683) kd_loss 0.7111 (0.7175) acc 96.8750 (94.9740) gate/entropy 0.9897 (0.9901) gate/usage_max 0.5612 (0.5609) gate/usage_min 0.2176 (0.2179) gate/usage_std 0.1612 (0.1609) teacher/entropy 0.0643 (0.0644) teacher/usage_max 0.7875 (0.7810) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.3326 (0.3312) nleep/row_max_mean 1526.1296 (1529.8204) nleep/row_max_std 46.3637 (44.9740) nleep/row_min_mean 1491.9949 (1495.3532) lr 1.5878e-03 eta 0:09:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,568
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 92.9%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     91.1%, epoch: 4 *******
epoch [18/50] batch [20/132] time 0.061 (0.125) data 0.000 (0.014) loss 1.1744 (1.1870) teacher_loss 0.1293 (0.1224) loss_zs_kd 0.0094 (0.0120) loss_oracle 0.5975 (0.5604) kd_loss 0.7416 (0.7784) acc 93.7500 (95.3125) gate/entropy 0.9896 (0.9895) gate/usage_max 0.5614 (0.5615) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1613 (0.1613) teacher/entropy 0.0114 (0.0482) teacher/usage_max 0.8111 (0.7321) teacher/usage_min 0.0002 (0.0013) teacher/usage_std 0.3465 (0.3073) nleep/row_max_mean 1518.0525 (1529.9558) nleep/row_max_std 61.0075 (45.3662) nleep/row_min_mean 1483.7078 (1495.1698) lr 1.5358e-03 eta 0:09:02
epoch [18/50] batch [40/132] time 0.068 (0.120) data 0.000 (0.007) loss 1.0522 (1.1927) teacher_loss 0.1544 (0.1187) loss_zs_kd 0.0048 (0.0115) loss_oracle 0.4954 (0.5586) kd_loss 0.6478 (0.7889) acc 93.7500 (95.6250) gate/entropy 0.9893 (0.9895) gate/usage_max 0.5617 (0.5615) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1615 (0.1613) teacher/entropy 0.0223 (0.0446) teacher/usage_max 0.9003 (0.7245) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4030 (0.3033) nleep/row_max_mean 1525.0945 (1530.8599) nleep/row_max_std 51.5219 (47.0275) nleep/row_min_mean 1492.3230 (1495.9893) lr 1.5358e-03 eta 0:08:39
epoch [18/50] batch [60/132] time 0.072 (0.120) data 0.000 (0.005) loss 1.0256 (1.1819) teacher_loss 0.0051 (0.1170) loss_zs_kd 0.0007 (0.0103) loss_oracle 0.4320 (0.5393) kd_loss 0.8042 (0.7900) acc 100.0000 (95.8333) gate/entropy 0.9893 (0.9895) gate/usage_max 0.5617 (0.5615) gate/usage_min 0.2172 (0.2173) gate/usage_std 0.1615 (0.1613) teacher/entropy 0.0047 (0.0409) teacher/usage_max 0.7505 (0.7272) teacher/usage_min 0.0001 (0.0022) teacher/usage_std 0.3120 (0.3039) nleep/row_max_mean 1530.9088 (1529.1614) nleep/row_max_std 63.8486 (47.6550) nleep/row_min_mean 1496.7698 (1494.7085) lr 1.5358e-03 eta 0:08:34
epoch [18/50] batch [80/132] time 0.080 (0.118) data 0.000 (0.004) loss 1.1886 (1.1954) teacher_loss 0.1796 (0.1277) loss_zs_kd 0.0057 (0.0110) loss_oracle 0.5436 (0.5458) kd_loss 0.7343 (0.7893) acc 93.7500 (95.6250) gate/entropy 0.9895 (0.9895) gate/usage_max 0.5615 (0.5615) gate/usage_min 0.2172 (0.2173) gate/usage_std 0.1614 (0.1614) teacher/entropy 0.0511 (0.0383) teacher/usage_max 0.7755 (0.7308) teacher/usage_min 0.0045 (0.0026) teacher/usage_std 0.3248 (0.3048) nleep/row_max_mean 1527.4260 (1527.3381) nleep/row_max_std 46.6781 (47.9231) nleep/row_min_mean 1491.5221 (1493.3931) lr 1.5358e-03 eta 0:08:24
epoch [18/50] batch [100/132] time 0.081 (0.118) data 0.000 (0.003) loss 1.0614 (1.1980) teacher_loss 0.0465 (0.1232) loss_zs_kd 0.0082 (0.0109) loss_oracle 0.5751 (0.5556) kd_loss 0.7233 (0.7916) acc 100.0000 (95.8750) gate/entropy 0.9895 (0.9894) gate/usage_max 0.5614 (0.5616) gate/usage_min 0.2172 (0.2173) gate/usage_std 0.1613 (0.1614) teacher/entropy 0.0459 (0.0365) teacher/usage_max 0.7934 (0.7301) teacher/usage_min 0.0002 (0.0028) teacher/usage_std 0.3360 (0.3044) nleep/row_max_mean 1512.7485 (1527.0665) nleep/row_max_std 55.1655 (46.8738) nleep/row_min_mean 1482.4058 (1493.5534) lr 1.5358e-03 eta 0:08:20
epoch [18/50] batch [120/132] time 0.154 (0.121) data 0.000 (0.003) loss 1.2777 (1.1965) teacher_loss 0.0550 (0.1214) loss_zs_kd 0.0166 (0.0114) loss_oracle 0.5488 (0.5556) kd_loss 0.9400 (0.7916) acc 96.8750 (95.8073) gate/entropy 0.9894 (0.9894) gate/usage_max 0.5616 (0.5616) gate/usage_min 0.2172 (0.2172) gate/usage_std 0.1614 (0.1614) teacher/entropy 0.0121 (0.0362) teacher/usage_max 0.5969 (0.7304) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2486 (0.3047) nleep/row_max_mean 1510.5571 (1526.2435) nleep/row_max_std 38.2019 (46.2067) nleep/row_min_mean 1480.2947 (1493.1453) lr 1.5358e-03 eta 0:08:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,632
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 94.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [19/50] batch [20/132] time 0.132 (0.162) data 0.000 (0.016) loss 1.4585 (1.3259) teacher_loss 0.2065 (0.1327) loss_zs_kd 0.0239 (0.0151) loss_oracle 0.8983 (0.7558) kd_loss 0.7909 (0.8077) acc 93.7500 (95.0000) gate/entropy 0.9892 (0.9892) gate/usage_max 0.5618 (0.5618) gate/usage_min 0.2170 (0.2170) gate/usage_std 0.1616 (0.1616) teacher/entropy 0.0792 (0.0456) teacher/usage_max 0.6852 (0.7030) teacher/usage_min 0.0408 (0.0124) teacher/usage_std 0.2664 (0.2869) nleep/row_max_mean 1524.8589 (1524.4251) nleep/row_max_std 45.0950 (44.7279) nleep/row_min_mean 1499.6086 (1496.2905) lr 1.4818e-03 eta 0:11:22
epoch [19/50] batch [40/132] time 0.147 (0.152) data 0.000 (0.008) loss 1.3889 (1.3278) teacher_loss 0.0033 (0.1141) loss_zs_kd 0.0000 (0.0137) loss_oracle 0.9926 (0.8034) kd_loss 0.8893 (0.8051) acc 100.0000 (95.8594) gate/entropy 0.9891 (0.9892) gate/usage_max 0.5619 (0.5618) gate/usage_min 0.2170 (0.2170) gate/usage_std 0.1616 (0.1616) teacher/entropy 0.0895 (0.0512) teacher/usage_max 0.5721 (0.7004) teacher/usage_min 0.2029 (0.0392) teacher/usage_std 0.1691 (0.2781) nleep/row_max_mean 1519.8228 (1527.2446) nleep/row_max_std 47.9370 (42.6674) nleep/row_min_mean 1501.0796 (1501.5457) lr 1.4818e-03 eta 0:10:36
epoch [19/50] batch [60/132] time 0.110 (0.135) data 0.000 (0.006) loss 1.6927 (1.3928) teacher_loss 0.1815 (0.1229) loss_zs_kd 0.0189 (0.0138) loss_oracle 0.8440 (0.8401) kd_loss 1.0798 (0.8430) acc 93.7500 (95.5208) gate/entropy 0.9895 (0.9892) gate/usage_max 0.5615 (0.5618) gate/usage_min 0.2172 (0.2170) gate/usage_std 0.1614 (0.1616) teacher/entropy 0.1528 (0.0823) teacher/usage_max 0.5126 (0.6352) teacher/usage_min 0.1811 (0.0881) teacher/usage_std 0.1367 (0.2305) nleep/row_max_mean 1507.9846 (1525.4174) nleep/row_max_std 49.3126 (42.6348) nleep/row_min_mean 1488.1506 (1501.5611) lr 1.4818e-03 eta 0:09:24
epoch [19/50] batch [80/132] time 0.101 (0.128) data 0.000 (0.004) loss 1.8291 (1.4716) teacher_loss 0.0489 (0.1269) loss_zs_kd 0.0097 (0.0128) loss_oracle 1.0437 (0.8701) kd_loss 1.2534 (0.9032) acc 100.0000 (95.5469) gate/entropy 0.9895 (0.9893) gate/usage_max 0.5615 (0.5617) gate/usage_min 0.2173 (0.2171) gate/usage_std 0.1614 (0.1615) teacher/entropy 0.0908 (0.0997) teacher/usage_max 0.7054 (0.6238) teacher/usage_min 0.1047 (0.0989) teacher/usage_std 0.2654 (0.2223) nleep/row_max_mean 1539.4669 (1526.1884) nleep/row_max_std 34.7561 (41.8620) nleep/row_min_mean 1513.2699 (1502.7686) lr 1.4818e-03 eta 0:08:48
epoch [19/50] batch [100/132] time 0.151 (0.127) data 0.000 (0.003) loss 2.1523 (1.5647) teacher_loss 0.2893 (0.1387) loss_zs_kd 0.0259 (0.0130) loss_oracle 0.9107 (0.8761) kd_loss 1.3947 (0.9815) acc 90.6250 (95.2500) gate/entropy 0.9897 (0.9893) gate/usage_max 0.5613 (0.5617) gate/usage_min 0.2176 (0.2172) gate/usage_std 0.1612 (0.1615) teacher/entropy 0.0562 (0.1008) teacher/usage_max 0.8856 (0.6567) teacher/usage_min 0.0370 (0.0923) teacher/usage_std 0.3909 (0.2429) nleep/row_max_mean 1534.3447 (1527.5794) nleep/row_max_std 39.2529 (41.9047) nleep/row_min_mean 1509.7434 (1503.9621) lr 1.4818e-03 eta 0:08:44
epoch [19/50] batch [120/132] time 0.075 (0.125) data 0.000 (0.003) loss 2.1777 (1.6571) teacher_loss 0.3414 (0.1518) loss_zs_kd 0.0307 (0.0134) loss_oracle 0.9069 (0.8871) kd_loss 1.3676 (1.0550) acc 87.5000 (94.9219) gate/entropy 0.9905 (0.9894) gate/usage_max 0.5605 (0.5616) gate/usage_min 0.2183 (0.2173) gate/usage_std 0.1606 (0.1614) teacher/entropy 0.0356 (0.0932) teacher/usage_max 0.8417 (0.6997) teacher/usage_min 0.0326 (0.0811) teacher/usage_std 0.3615 (0.2710) nleep/row_max_mean 1527.5275 (1528.1859) nleep/row_max_std 42.5970 (41.9050) nleep/row_min_mean 1499.1685 (1503.8890) lr 1.4818e-03 eta 0:08:33
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,626
* accuracy: 92.3%
* error: 7.7%
* macro_f1: 93.8%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [20/50] batch [20/132] time 0.177 (0.134) data 0.000 (0.014) loss 1.9481 (2.0955) teacher_loss 0.0373 (0.1802) loss_zs_kd 0.0033 (0.0102) loss_oracle 0.8469 (0.8542) kd_loss 1.4856 (1.4830) acc 100.0000 (93.7500) gate/entropy 0.9913 (0.9906) gate/usage_max 0.5596 (0.5603) gate/usage_min 0.2192 (0.2187) gate/usage_std 0.1600 (0.1605) teacher/entropy 0.0244 (0.0252) teacher/usage_max 0.9907 (0.9678) teacher/usage_min 0.0012 (0.0069) teacher/usage_std 0.4648 (0.4488) nleep/row_max_mean 1528.0168 (1535.9025) nleep/row_max_std 38.6977 (35.7554) nleep/row_min_mean 1497.7496 (1505.3711) lr 1.4258e-03 eta 0:09:06
epoch [20/50] batch [40/132] time 0.171 (0.128) data 0.000 (0.007) loss 2.0189 (2.0785) teacher_loss 0.1616 (0.1789) loss_zs_kd 0.0029 (0.0095) loss_oracle 0.7112 (0.8041) kd_loss 1.5003 (1.4927) acc 93.7500 (94.4531) gate/entropy 0.9910 (0.9909) gate/usage_max 0.5599 (0.5600) gate/usage_min 0.2195 (0.2191) gate/usage_std 0.1602 (0.1603) teacher/entropy 0.0162 (0.0189) teacher/usage_max 0.9754 (0.9763) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.4541 (0.4547) nleep/row_max_mean 1552.9056 (1536.7274) nleep/row_max_std 31.6935 (36.8234) nleep/row_min_mean 1518.3193 (1504.4612) lr 1.4258e-03 eta 0:08:37
epoch [20/50] batch [60/132] time 0.102 (0.119) data 0.000 (0.005) loss 2.1243 (2.0917) teacher_loss 0.1685 (0.1688) loss_zs_kd 0.0045 (0.0097) loss_oracle 0.8913 (0.8372) kd_loss 1.5079 (1.4994) acc 93.7500 (94.7396) gate/entropy 0.9920 (0.9912) gate/usage_max 0.5588 (0.5597) gate/usage_min 0.2204 (0.2194) gate/usage_std 0.1594 (0.1601) teacher/entropy 0.0045 (0.0129) teacher/usage_max 0.9991 (0.9841) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4708 (0.4602) nleep/row_max_mean 1550.2085 (1539.3986) nleep/row_max_std 32.5852 (36.7049) nleep/row_min_mean 1513.7694 (1505.1648) lr 1.4258e-03 eta 0:07:59
epoch [20/50] batch [80/132] time 0.135 (0.124) data 0.000 (0.004) loss 2.2589 (2.1044) teacher_loss 0.3692 (0.1653) loss_zs_kd 0.0038 (0.0100) loss_oracle 0.7668 (0.8684) kd_loss 1.5043 (1.4999) acc 90.6250 (94.7656) gate/entropy 0.9932 (0.9915) gate/usage_max 0.5576 (0.5594) gate/usage_min 0.2209 (0.2197) gate/usage_std 0.1585 (0.1598) teacher/entropy 0.0027 (0.0115) teacher/usage_max 0.9995 (0.9860) teacher/usage_min 0.0001 (0.0018) teacher/usage_std 0.4711 (0.4616) nleep/row_max_mean 1534.0183 (1540.9114) nleep/row_max_std 49.7953 (37.6715) nleep/row_min_mean 1498.9282 (1505.7991) lr 1.4258e-03 eta 0:08:17
epoch [20/50] batch [100/132] time 0.116 (0.126) data 0.000 (0.003) loss 2.2458 (2.1168) teacher_loss 0.2334 (0.1703) loss_zs_kd 0.0042 (0.0099) loss_oracle 1.0112 (0.8827) kd_loss 1.5047 (1.5002) acc 87.5000 (94.4062) gate/entropy 0.9933 (0.9918) gate/usage_max 0.5574 (0.5590) gate/usage_min 0.2205 (0.2199) gate/usage_std 0.1585 (0.1596) teacher/entropy 0.0000 (0.0101) teacher/usage_max 1.0000 (0.9882) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4714 (0.4631) nleep/row_max_mean 1557.7413 (1542.3180) nleep/row_max_std 40.5838 (38.4249) nleep/row_min_mean 1520.9260 (1506.7652) lr 1.4258e-03 eta 0:08:24
epoch [20/50] batch [120/132] time 0.150 (0.129) data 0.000 (0.003) loss 2.0127 (2.1159) teacher_loss 0.1020 (0.1733) loss_zs_kd 0.0083 (0.0096) loss_oracle 0.8517 (0.8775) kd_loss 1.4807 (1.4990) acc 96.8750 (94.2188) gate/entropy 0.9942 (0.9922) gate/usage_max 0.5564 (0.5586) gate/usage_min 0.2204 (0.2200) gate/usage_std 0.1578 (0.1593) teacher/entropy 0.0194 (0.0099) teacher/usage_max 0.9785 (0.9879) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4563 (0.4629) nleep/row_max_mean 1571.6013 (1543.8231) nleep/row_max_std 32.9817 (39.3185) nleep/row_min_mean 1530.8790 (1507.8146) lr 1.4258e-03 eta 0:08:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,613
* accuracy: 92.0%
* error: 8.0%
* macro_f1: 93.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [21/50] batch [20/132] time 0.104 (0.133) data 0.001 (0.018) loss 2.1033 (2.1312) teacher_loss 0.1435 (0.1906) loss_zs_kd 0.0060 (0.0095) loss_oracle 0.9332 (0.8872) kd_loss 1.4902 (1.4922) acc 90.6250 (93.2812) gate/entropy 0.9961 (0.9955) gate/usage_max 0.5543 (0.5550) gate/usage_min 0.2204 (0.2203) gate/usage_std 0.1563 (0.1568) teacher/entropy 0.0000 (0.0011) teacher/usage_max 1.0000 (0.9983) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4702) nleep/row_max_mean 1560.2017 (1557.3332) nleep/row_max_std 36.5972 (41.9353) nleep/row_min_mean 1518.4177 (1517.0172) lr 1.3681e-03 eta 0:08:42
epoch [21/50] batch [40/132] time 0.098 (0.121) data 0.001 (0.009) loss 1.9043 (2.1156) teacher_loss 0.0931 (0.1754) loss_zs_kd 0.0008 (0.0088) loss_oracle 0.6549 (0.8947) kd_loss 1.4834 (1.4886) acc 96.8750 (94.2188) gate/entropy 0.9967 (0.9960) gate/usage_max 0.5536 (0.5544) gate/usage_min 0.2198 (0.2202) gate/usage_std 0.1558 (0.1563) teacher/entropy 0.0015 (0.0016) teacher/usage_max 0.9997 (0.9973) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4712 (0.4695) nleep/row_max_mean 1567.9524 (1555.4484) nleep/row_max_std 40.3313 (42.9775) nleep/row_min_mean 1530.7677 (1515.6785) lr 1.3681e-03 eta 0:07:53
epoch [21/50] batch [60/132] time 0.076 (0.117) data 0.001 (0.006) loss 2.0829 (2.1087) teacher_loss 0.1716 (0.1731) loss_zs_kd 0.0154 (0.0087) loss_oracle 0.9011 (0.8951) kd_loss 1.4531 (1.4837) acc 96.8750 (94.3750) gate/entropy 0.9984 (0.9966) gate/usage_max 0.5517 (0.5537) gate/usage_min 0.2198 (0.2202) gate/usage_std 0.1545 (0.1559) teacher/entropy 0.0234 (0.0027) teacher/usage_max 0.9896 (0.9964) teacher/usage_min 0.0002 (0.0001) teacher/usage_std 0.4641 (0.4689) nleep/row_max_mean 1532.0177 (1553.2582) nleep/row_max_std 56.1792 (44.5596) nleep/row_min_mean 1496.2788 (1513.9086) lr 1.3681e-03 eta 0:07:38
epoch [21/50] batch [80/132] time 0.080 (0.116) data 0.000 (0.005) loss 2.4122 (2.0965) teacher_loss 0.5537 (0.1737) loss_zs_kd 0.0060 (0.0086) loss_oracle 0.8099 (0.8786) kd_loss 1.4506 (1.4791) acc 87.5000 (94.2969) gate/entropy 1.0002 (0.9973) gate/usage_max 0.5497 (0.5529) gate/usage_min 0.2197 (0.2201) gate/usage_std 0.1531 (0.1553) teacher/entropy 0.0168 (0.0036) teacher/usage_max 0.9931 (0.9950) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4665 (0.4679) nleep/row_max_mean 1526.4429 (1551.6188) nleep/row_max_std 54.8889 (45.5574) nleep/row_min_mean 1491.4316 (1512.9129) lr 1.3681e-03 eta 0:07:29
epoch [21/50] batch [100/132] time 0.167 (0.113) data 0.000 (0.004) loss 2.2376 (2.1005) teacher_loss 0.2407 (0.1790) loss_zs_kd 0.0069 (0.0088) loss_oracle 1.0692 (0.8845) kd_loss 1.4588 (1.4748) acc 87.5000 (94.0625) gate/entropy 1.0018 (0.9980) gate/usage_max 0.5479 (0.5521) gate/usage_min 0.2193 (0.2199) gate/usage_std 0.1518 (0.1548) teacher/entropy 0.0005 (0.0040) teacher/usage_max 0.9687 (0.9943) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4495 (0.4674) nleep/row_max_mean 1559.0873 (1551.2977) nleep/row_max_std 37.7495 (45.6733) nleep/row_min_mean 1518.8086 (1513.1108) lr 1.3681e-03 eta 0:07:17
epoch [21/50] batch [120/132] time 0.074 (0.109) data 0.000 (0.003) loss 2.0463 (2.0947) teacher_loss 0.1837 (0.1806) loss_zs_kd 0.0011 (0.0086) loss_oracle 0.8631 (0.8805) kd_loss 1.4306 (1.4696) acc 93.7500 (94.0365) gate/entropy 1.0040 (0.9988) gate/usage_max 0.5452 (0.5512) gate/usage_min 0.2190 (0.2198) gate/usage_std 0.1500 (0.1541) teacher/entropy 0.0163 (0.0047) teacher/usage_max 0.9753 (0.9932) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4541 (0.4666) nleep/row_max_mean 1538.0564 (1551.2856) nleep/row_max_std 47.8093 (45.6319) nleep/row_min_mean 1503.0454 (1513.4790) lr 1.3681e-03 eta 0:06:58
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,586
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 93.2%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [22/50] batch [20/132] time 0.078 (0.119) data 0.001 (0.019) loss 2.2828 (2.0181) teacher_loss 0.3640 (0.1537) loss_zs_kd 0.0052 (0.0101) loss_oracle 1.0130 (0.8667) kd_loss 1.4097 (1.4260) acc 90.6250 (94.6875) gate/entropy 1.0074 (1.0061) gate/usage_max 0.5409 (0.5425) gate/usage_min 0.2180 (0.2182) gate/usage_std 0.1471 (0.1482) teacher/entropy 0.0135 (0.0051) teacher/usage_max 0.9956 (0.9899) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4683 (0.4644) nleep/row_max_mean 1553.8494 (1551.1067) nleep/row_max_std 37.6514 (46.6562) nleep/row_min_mean 1516.4160 (1515.3945) lr 1.3090e-03 eta 0:07:32
epoch [22/50] batch [40/132] time 0.187 (0.127) data 0.000 (0.010) loss 2.0270 (2.0349) teacher_loss 0.2426 (0.1635) loss_zs_kd 0.0121 (0.0082) loss_oracle 0.7804 (0.9007) kd_loss 1.3881 (1.4170) acc 93.7500 (94.6875) gate/entropy 1.0097 (1.0073) gate/usage_max 0.5379 (0.5410) gate/usage_min 0.2172 (0.2179) gate/usage_std 0.1451 (0.1472) teacher/entropy 0.0211 (0.0060) teacher/usage_max 0.9810 (0.9890) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4581 (0.4637) nleep/row_max_mean 1550.8684 (1550.6375) nleep/row_max_std 46.4971 (45.0330) nleep/row_min_mean 1516.0455 (1514.9502) lr 1.3090e-03 eta 0:08:01
epoch [22/50] batch [60/132] time 0.138 (0.138) data 0.000 (0.007) loss 1.7828 (2.0260) teacher_loss 0.0201 (0.1644) loss_zs_kd 0.0118 (0.0088) loss_oracle 0.7836 (0.8960) kd_loss 1.3650 (1.4092) acc 100.0000 (94.5833) gate/entropy 1.0128 (1.0087) gate/usage_max 0.5338 (0.5392) gate/usage_min 0.2163 (0.2175) gate/usage_std 0.1424 (0.1460) teacher/entropy 0.0240 (0.0054) teacher/usage_max 0.9852 (0.9888) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4610 (0.4635) nleep/row_max_mean 1537.6826 (1549.3422) nleep/row_max_std 47.7022 (44.5305) nleep/row_min_mean 1504.3885 (1513.7233) lr 1.3090e-03 eta 0:08:41
epoch [22/50] batch [80/132] time 0.139 (0.145) data 0.000 (0.005) loss 1.9201 (2.0083) teacher_loss 0.1268 (0.1636) loss_zs_kd 0.0109 (0.0082) loss_oracle 0.8959 (0.8831) kd_loss 1.3398 (1.3991) acc 93.7500 (94.3359) gate/entropy 1.0156 (1.0101) gate/usage_max 0.5298 (0.5374) gate/usage_min 0.2150 (0.2171) gate/usage_std 0.1399 (0.1448) teacher/entropy 0.0230 (0.0063) teacher/usage_max 0.9575 (0.9875) teacher/usage_min 0.0115 (0.0002) teacher/usage_std 0.4414 (0.4627) nleep/row_max_mean 1530.3893 (1548.7930) nleep/row_max_std 58.0616 (44.0414) nleep/row_min_mean 1496.7661 (1513.3341) lr 1.3090e-03 eta 0:09:01
epoch [22/50] batch [100/132] time 0.162 (0.145) data 0.000 (0.004) loss 1.7574 (1.9831) teacher_loss 0.0263 (0.1577) loss_zs_kd 0.0166 (0.0082) loss_oracle 0.7814 (0.8650) kd_loss 1.3321 (1.3887) acc 100.0000 (94.5625) gate/entropy 1.0189 (1.0115) gate/usage_max 0.5248 (0.5353) gate/usage_min 0.2136 (0.2165) gate/usage_std 0.1368 (0.1435) teacher/entropy 0.0088 (0.0060) teacher/usage_max 0.9979 (0.9888) teacher/usage_min 0.0005 (0.0002) teacher/usage_std 0.4699 (0.4635) nleep/row_max_mean 1539.5665 (1548.2083) nleep/row_max_std 44.2756 (43.7586) nleep/row_min_mean 1506.7852 (1512.9088) lr 1.3090e-03 eta 0:08:59
epoch [22/50] batch [120/132] time 0.142 (0.145) data 0.000 (0.003) loss 1.9351 (1.9626) teacher_loss 0.2630 (0.1579) loss_zs_kd 0.0078 (0.0081) loss_oracle 0.7102 (0.8458) kd_loss 1.3131 (1.3777) acc 90.6250 (94.5573) gate/entropy 1.0223 (1.0131) gate/usage_max 0.5192 (0.5331) gate/usage_min 0.2119 (0.2159) gate/usage_std 0.1334 (0.1421) teacher/entropy 0.0002 (0.0059) teacher/usage_max 1.0000 (0.9899) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4714 (0.4644) nleep/row_max_mean 1544.1353 (1547.5432) nleep/row_max_std 46.1677 (43.2224) nleep/row_min_mean 1509.9917 (1512.5026) lr 1.3090e-03 eta 0:08:58
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,568
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 92.7%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [23/50] batch [20/132] time 0.104 (0.128) data 0.000 (0.014) loss 2.0545 (1.8643) teacher_loss 0.4109 (0.2046) loss_zs_kd 0.0104 (0.0093) loss_oracle 0.7858 (0.7654) kd_loss 1.2455 (1.2724) acc 84.3750 (91.7188) gate/entropy 1.0275 (1.0262) gate/usage_max 0.5093 (0.5121) gate/usage_min 0.2084 (0.2096) gate/usage_std 0.1280 (0.1295) teacher/entropy 0.0286 (0.0096) teacher/usage_max 0.9689 (0.9903) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4496 (0.4646) nleep/row_max_mean 1548.1814 (1540.8265) nleep/row_max_std 47.2433 (44.2547) nleep/row_min_mean 1516.6600 (1508.6739) lr 1.2487e-03 eta 0:07:50
epoch [23/50] batch [40/132] time 0.149 (0.116) data 0.000 (0.007) loss 1.6850 (1.8364) teacher_loss 0.1075 (0.1952) loss_zs_kd 0.0026 (0.0091) loss_oracle 0.7399 (0.7609) kd_loss 1.2063 (1.2562) acc 96.8750 (92.2656) gate/entropy 1.0309 (1.0278) gate/usage_max 0.5021 (0.5087) gate/usage_min 0.2061 (0.2085) gate/usage_std 0.1243 (0.1277) teacher/entropy 0.0301 (0.0091) teacher/usage_max 0.9869 (0.9909) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4621 (0.4650) nleep/row_max_mean 1538.6160 (1539.5634) nleep/row_max_std 41.6595 (44.3714) nleep/row_min_mean 1508.7151 (1507.5848) lr 1.2487e-03 eta 0:07:03
epoch [23/50] batch [60/132] time 0.093 (0.118) data 0.000 (0.005) loss 1.5983 (1.7981) teacher_loss 0.0708 (0.1759) loss_zs_kd 0.0000 (0.0082) loss_oracle 0.7058 (0.7582) kd_loss 1.1746 (1.2390) acc 96.8750 (93.1250) gate/entropy 1.0336 (1.0293) gate/usage_max 0.4948 (0.5053) gate/usage_min 0.2033 (0.2072) gate/usage_std 0.1211 (0.1260) teacher/entropy 0.0279 (0.0106) teacher/usage_max 0.9875 (0.9895) teacher/usage_min 0.0004 (0.0001) teacher/usage_std 0.4626 (0.4640) nleep/row_max_mean 1541.9492 (1539.3419) nleep/row_max_std 43.8386 (45.2518) nleep/row_min_mean 1511.5339 (1507.7365) lr 1.2487e-03 eta 0:07:08
epoch [23/50] batch [80/132] time 0.190 (0.123) data 0.000 (0.004) loss 1.6436 (1.7834) teacher_loss 0.0865 (0.1799) loss_zs_kd 0.0026 (0.0082) loss_oracle 0.7836 (0.7531) kd_loss 1.1640 (1.2229) acc 96.8750 (93.3203) gate/entropy 1.0359 (1.0307) gate/usage_max 0.4873 (0.5017) gate/usage_min 0.2005 (0.2059) gate/usage_std 0.1180 (0.1244) teacher/entropy 0.0126 (0.0115) teacher/usage_max 0.9719 (0.9865) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4517 (0.4619) nleep/row_max_mean 1538.7827 (1539.0851) nleep/row_max_std 46.0739 (45.3714) nleep/row_min_mean 1508.7694 (1507.6847) lr 1.2487e-03 eta 0:07:23
epoch [23/50] batch [100/132] time 0.093 (0.122) data 0.000 (0.003) loss 1.4527 (1.7600) teacher_loss 0.0135 (0.1749) loss_zs_kd 0.0014 (0.0078) loss_oracle 0.6412 (0.7478) kd_loss 1.1178 (1.2073) acc 100.0000 (93.5625) gate/entropy 1.0375 (1.0319) gate/usage_max 0.4799 (0.4980) gate/usage_min 0.1972 (0.2045) gate/usage_std 0.1156 (0.1228) teacher/entropy 0.0359 (0.0112) teacher/usage_max 0.9528 (0.9856) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4384 (0.4613) nleep/row_max_mean 1544.4694 (1539.8723) nleep/row_max_std 49.5994 (44.3711) nleep/row_min_mean 1516.4241 (1508.5642) lr 1.2487e-03 eta 0:07:18
epoch [23/50] batch [120/132] time 0.060 (0.120) data 0.000 (0.003) loss 1.4696 (1.7397) teacher_loss 0.0893 (0.1759) loss_zs_kd 0.0046 (0.0084) loss_oracle 0.5979 (0.7372) kd_loss 1.0791 (1.1910) acc 100.0000 (93.5938) gate/entropy 1.0388 (1.0330) gate/usage_max 0.4726 (0.4943) gate/usage_min 0.1944 (0.2031) gate/usage_std 0.1136 (0.1214) teacher/entropy 0.0511 (0.0127) teacher/usage_max 0.9417 (0.9823) teacher/usage_min 0.0014 (0.0005) teacher/usage_std 0.4308 (0.4590) nleep/row_max_mean 1530.5876 (1539.2859) nleep/row_max_std 51.9403 (44.0683) nleep/row_min_mean 1504.3713 (1508.2444) lr 1.2487e-03 eta 0:07:09
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,539
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.2%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [24/50] batch [20/132] time 0.157 (0.168) data 0.000 (0.015) loss 1.4947 (1.5670) teacher_loss 0.1270 (0.1690) loss_zs_kd 0.0167 (0.0071) loss_oracle 0.6003 (0.6643) kd_loss 1.0592 (1.0624) acc 96.8750 (94.5312) gate/entropy 1.0393 (1.0394) gate/usage_max 0.4622 (0.4651) gate/usage_min 0.1895 (0.1912) gate/usage_std 0.1118 (0.1121) teacher/entropy 0.0263 (0.0238) teacher/usage_max 0.9496 (0.9692) teacher/usage_min 0.0002 (0.0001) teacher/usage_std 0.4362 (0.4500) nleep/row_max_mean 1548.8450 (1539.2749) nleep/row_max_std 32.9730 (41.9787) nleep/row_min_mean 1517.6373 (1509.6828) lr 1.1874e-03 eta 0:09:55
epoch [24/50] batch [40/132] time 0.168 (0.157) data 0.000 (0.007) loss 1.3986 (1.5587) teacher_loss 0.0808 (0.1679) loss_zs_kd 0.0037 (0.0080) loss_oracle 0.6022 (0.6717) kd_loss 1.0149 (1.0509) acc 93.7500 (94.1406) gate/entropy 1.0394 (1.0394) gate/usage_max 0.4561 (0.4621) gate/usage_min 0.1871 (0.1898) gate/usage_std 0.1111 (0.1117) teacher/entropy 0.0346 (0.0207) teacher/usage_max 0.9696 (0.9732) teacher/usage_min 0.0011 (0.0001) teacher/usage_std 0.4500 (0.4527) nleep/row_max_mean 1536.3092 (1539.7003) nleep/row_max_std 45.8314 (41.5761) nleep/row_min_mean 1508.3088 (1509.5026) lr 1.1874e-03 eta 0:09:11
epoch [24/50] batch [60/132] time 0.132 (0.154) data 0.000 (0.005) loss 1.6927 (1.5433) teacher_loss 0.3673 (0.1690) loss_zs_kd 0.0050 (0.0084) loss_oracle 0.6039 (0.6604) kd_loss 1.0209 (1.0399) acc 90.6250 (94.3750) gate/entropy 1.0391 (1.0394) gate/usage_max 0.4508 (0.4592) gate/usage_min 0.1848 (0.1886) gate/usage_std 0.1108 (0.1114) teacher/entropy 0.0113 (0.0212) teacher/usage_max 0.9662 (0.9717) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4477 (0.4517) nleep/row_max_mean 1547.1619 (1538.8158) nleep/row_max_std 38.7664 (42.9663) nleep/row_min_mean 1515.3453 (1508.5895) lr 1.1874e-03 eta 0:09:00
epoch [24/50] batch [80/132] time 0.134 (0.154) data 0.000 (0.004) loss 1.4205 (1.5340) teacher_loss 0.1029 (0.1743) loss_zs_kd 0.0042 (0.0087) loss_oracle 0.6497 (0.6508) kd_loss 0.9907 (1.0300) acc 96.8750 (94.1797) gate/entropy 1.0387 (1.0393) gate/usage_max 0.4460 (0.4564) gate/usage_min 0.1830 (0.1874) gate/usage_std 0.1107 (0.1112) teacher/entropy 0.0009 (0.0193) teacher/usage_max 0.9999 (0.9730) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4713 (0.4526) nleep/row_max_mean 1522.6782 (1536.9521) nleep/row_max_std 52.2941 (45.0736) nleep/row_min_mean 1491.8242 (1506.6767) lr 1.1874e-03 eta 0:08:56
epoch [24/50] batch [100/132] time 0.146 (0.152) data 0.001 (0.003) loss 1.4954 (1.5078) teacher_loss 0.2146 (0.1655) loss_zs_kd 0.0151 (0.0086) loss_oracle 0.5846 (0.6360) kd_loss 0.9809 (1.0201) acc 90.6250 (94.4062) gate/entropy 1.0379 (1.0391) gate/usage_max 0.4417 (0.4539) gate/usage_min 0.1808 (0.1863) gate/usage_std 0.1110 (0.1111) teacher/entropy 0.0168 (0.0195) teacher/usage_max 0.9684 (0.9733) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4492 (0.4528) nleep/row_max_mean 1526.0183 (1536.4286) nleep/row_max_std 50.2294 (45.3495) nleep/row_min_mean 1494.3955 (1506.0112) lr 1.1874e-03 eta 0:08:47
epoch [24/50] batch [120/132] time 0.087 (0.142) data 0.000 (0.003) loss 1.3534 (1.4847) teacher_loss 0.1037 (0.1612) loss_zs_kd 0.0127 (0.0081) loss_oracle 0.5633 (0.6168) kd_loss 0.9618 (1.0112) acc 96.8750 (94.6354) gate/entropy 1.0372 (1.0388) gate/usage_max 0.4379 (0.4515) gate/usage_min 0.1791 (0.1852) gate/usage_std 0.1113 (0.1111) teacher/entropy 0.0310 (0.0188) teacher/usage_max 0.9561 (0.9743) teacher/usage_min 0.0002 (0.0003) teacher/usage_std 0.4407 (0.4535) nleep/row_max_mean 1529.5101 (1536.1463) nleep/row_max_std 42.2966 (45.2985) nleep/row_min_mean 1500.5813 (1505.7015) lr 1.1874e-03 eta 0:08:09
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,546
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.3%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [25/50] batch [20/132] time 0.092 (0.109) data 0.000 (0.013) loss 1.3206 (1.3916) teacher_loss 0.0846 (0.1498) loss_zs_kd 0.0175 (0.0077) loss_oracle 0.5764 (0.5832) kd_loss 0.9391 (0.9464) acc 100.0000 (95.4688) gate/entropy 1.0362 (1.0364) gate/usage_max 0.4331 (0.4344) gate/usage_min 0.1771 (0.1775) gate/usage_std 0.1119 (0.1118) teacher/entropy 0.0652 (0.0205) teacher/usage_max 0.9205 (0.9740) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4164 (0.4533) nleep/row_max_mean 1527.5616 (1540.5099) nleep/row_max_std 40.8952 (40.6819) nleep/row_min_mean 1499.9534 (1510.0258) lr 1.1253e-03 eta 0:06:13
epoch [25/50] batch [40/132] time 0.087 (0.113) data 0.000 (0.007) loss 1.4410 (1.3978) teacher_loss 0.1793 (0.1579) loss_zs_kd 0.0108 (0.0070) loss_oracle 0.6476 (0.5883) kd_loss 0.9326 (0.9423) acc 90.6250 (94.6875) gate/entropy 1.0353 (1.0361) gate/usage_max 0.4304 (0.4330) gate/usage_min 0.1756 (0.1769) gate/usage_std 0.1125 (0.1120) teacher/entropy 0.0419 (0.0223) teacher/usage_max 0.9468 (0.9688) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4343 (0.4497) nleep/row_max_mean 1533.9978 (1538.0315) nleep/row_max_std 41.8579 (42.7289) nleep/row_min_mean 1504.4980 (1507.7868) lr 1.1253e-03 eta 0:06:23
epoch [25/50] batch [60/132] time 0.086 (0.115) data 0.000 (0.004) loss 1.4854 (1.3938) teacher_loss 0.2522 (0.1541) loss_zs_kd 0.0158 (0.0074) loss_oracle 0.5797 (0.5904) kd_loss 0.9354 (0.9407) acc 87.5000 (94.8438) gate/entropy 1.0344 (1.0358) gate/usage_max 0.4280 (0.4317) gate/usage_min 0.1743 (0.1764) gate/usage_std 0.1131 (0.1122) teacher/entropy 0.0187 (0.0202) teacher/usage_max 0.9613 (0.9679) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4443 (0.4490) nleep/row_max_mean 1544.8365 (1538.6951) nleep/row_max_std 46.8746 (42.3868) nleep/row_min_mean 1514.5293 (1508.3714) lr 1.1253e-03 eta 0:06:26
epoch [25/50] batch [80/132] time 0.100 (0.116) data 0.000 (0.003) loss 1.2557 (1.3882) teacher_loss 0.0948 (0.1541) loss_zs_kd 0.0050 (0.0070) loss_oracle 0.5128 (0.5917) kd_loss 0.9019 (0.9347) acc 96.8750 (94.8438) gate/entropy 1.0342 (1.0355) gate/usage_max 0.4260 (0.4306) gate/usage_min 0.1739 (0.1759) gate/usage_std 0.1133 (0.1124) teacher/entropy 0.0178 (0.0205) teacher/usage_max 0.9616 (0.9698) teacher/usage_min 0.0071 (0.0010) teacher/usage_std 0.4444 (0.4504) nleep/row_max_mean 1545.5336 (1538.4921) nleep/row_max_std 37.7124 (42.0001) nleep/row_min_mean 1518.7423 (1508.2847) lr 1.1253e-03 eta 0:06:30
epoch [25/50] batch [100/132] time 0.170 (0.118) data 0.000 (0.003) loss 1.2598 (1.3834) teacher_loss 0.1037 (0.1534) loss_zs_kd 0.0175 (0.0072) loss_oracle 0.5681 (0.5911) kd_loss 0.8634 (0.9309) acc 96.8750 (94.7500) gate/entropy 1.0336 (1.0352) gate/usage_max 0.4241 (0.4295) gate/usage_min 0.1731 (0.1754) gate/usage_std 0.1137 (0.1126) teacher/entropy 0.0442 (0.0218) teacher/usage_max 0.9134 (0.9672) teacher/usage_min 0.0031 (0.0015) teacher/usage_std 0.4114 (0.4485) nleep/row_max_mean 1550.5601 (1538.9398) nleep/row_max_std 32.9434 (41.7602) nleep/row_min_mean 1519.9290 (1508.8237) lr 1.1253e-03 eta 0:06:34
epoch [25/50] batch [120/132] time 0.073 (0.120) data 0.000 (0.002) loss 1.3797 (1.3805) teacher_loss 0.2136 (0.1557) loss_zs_kd 0.0036 (0.0074) loss_oracle 0.5207 (0.5865) kd_loss 0.9039 (0.9278) acc 93.7500 (94.7135) gate/entropy 1.0334 (1.0349) gate/usage_max 0.4225 (0.4284) gate/usage_min 0.1727 (0.1750) gate/usage_std 0.1138 (0.1128) teacher/entropy 0.0457 (0.0222) teacher/usage_max 0.9464 (0.9655) teacher/usage_min 0.0001 (0.0023) teacher/usage_std 0.4341 (0.4473) nleep/row_max_mean 1537.4150 (1538.5820) nleep/row_max_std 39.1045 (41.9587) nleep/row_min_mean 1512.2231 (1508.8217) lr 1.1253e-03 eta 0:06:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,545
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.3%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [26/50] batch [20/132] time 0.167 (0.178) data 0.000 (0.016) loss 1.3439 (1.3158) teacher_loss 0.1154 (0.1278) loss_zs_kd 0.0038 (0.0053) loss_oracle 0.6184 (0.5744) kd_loss 0.9174 (0.8981) acc 93.7500 (96.0938) gate/entropy 1.0326 (1.0328) gate/usage_max 0.4201 (0.4207) gate/usage_min 0.1717 (0.1720) gate/usage_std 0.1144 (0.1142) teacher/entropy 0.0051 (0.0334) teacher/usage_max 0.9695 (0.9546) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.4500 (0.4396) nleep/row_max_mean 1539.2296 (1535.0125) nleep/row_max_std 33.3420 (38.8405) nleep/row_min_mean 1509.1169 (1507.7564) lr 1.0628e-03 eta 0:09:45
epoch [26/50] batch [40/132] time 0.163 (0.167) data 0.000 (0.008) loss 1.4492 (1.3625) teacher_loss 0.2962 (0.1737) loss_zs_kd 0.0104 (0.0059) loss_oracle 0.5193 (0.5742) kd_loss 0.8881 (0.8988) acc 93.7500 (94.7656) gate/entropy 1.0326 (1.0327) gate/usage_max 0.4188 (0.4200) gate/usage_min 0.1717 (0.1718) gate/usage_std 0.1144 (0.1143) teacher/entropy 0.0284 (0.0302) teacher/usage_max 0.9420 (0.9556) teacher/usage_min 0.0281 (0.0055) teacher/usage_std 0.4304 (0.4404) nleep/row_max_mean 1522.9199 (1533.4206) nleep/row_max_std 51.0288 (39.7978) nleep/row_min_mean 1494.5469 (1506.2663) lr 1.0628e-03 eta 0:09:04
epoch [26/50] batch [60/132] time 0.151 (0.161) data 0.000 (0.005) loss 1.4132 (1.3661) teacher_loss 0.2505 (0.1828) loss_zs_kd 0.0013 (0.0066) loss_oracle 0.5508 (0.5710) kd_loss 0.8866 (0.8945) acc 93.7500 (94.0625) gate/entropy 1.0320 (1.0325) gate/usage_max 0.4175 (0.4194) gate/usage_min 0.1709 (0.1716) gate/usage_std 0.1149 (0.1145) teacher/entropy 0.0346 (0.0291) teacher/usage_max 0.9622 (0.9594) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4449 (0.4429) nleep/row_max_mean 1545.2852 (1533.3076) nleep/row_max_std 48.5590 (40.5107) nleep/row_min_mean 1517.7183 (1505.7897) lr 1.0628e-03 eta 0:08:42
epoch [26/50] batch [80/132] time 0.088 (0.151) data 0.000 (0.004) loss 1.2516 (1.3642) teacher_loss 0.0820 (0.1812) loss_zs_kd 0.0297 (0.0082) loss_oracle 0.5640 (0.5732) kd_loss 0.8727 (0.8923) acc 96.8750 (94.0234) gate/entropy 1.0316 (1.0324) gate/usage_max 0.4163 (0.4187) gate/usage_min 0.1705 (0.1714) gate/usage_std 0.1151 (0.1146) teacher/entropy 0.0189 (0.0277) teacher/usage_max 0.9912 (0.9608) teacher/usage_min 0.0000 (0.0050) teacher/usage_std 0.4652 (0.4439) nleep/row_max_mean 1545.3142 (1531.5316) nleep/row_max_std 31.5174 (41.3393) nleep/row_min_mean 1513.9905 (1503.8993) lr 1.0628e-03 eta 0:08:06
epoch [26/50] batch [100/132] time 0.074 (0.141) data 0.000 (0.003) loss 1.2930 (1.3644) teacher_loss 0.1092 (0.1830) loss_zs_kd 0.0019 (0.0080) loss_oracle 0.6303 (0.5746) kd_loss 0.8676 (0.8901) acc 93.7500 (93.9375) gate/entropy 1.0316 (1.0322) gate/usage_max 0.4151 (0.4181) gate/usage_min 0.1705 (0.1712) gate/usage_std 0.1151 (0.1147) teacher/entropy 0.0181 (0.0273) teacher/usage_max 0.9943 (0.9617) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4674 (0.4446) nleep/row_max_mean 1535.4148 (1530.8751) nleep/row_max_std 38.0467 (41.1730) nleep/row_min_mean 1504.7651 (1503.0662) lr 1.0628e-03 eta 0:07:30
epoch [26/50] batch [120/132] time 0.078 (0.134) data 0.000 (0.003) loss 1.2710 (1.3631) teacher_loss 0.0651 (0.1803) loss_zs_kd 0.0119 (0.0081) loss_oracle 0.6284 (0.5831) kd_loss 0.8857 (0.8873) acc 100.0000 (94.0885) gate/entropy 1.0312 (1.0321) gate/usage_max 0.4161 (0.4176) gate/usage_min 0.1700 (0.1711) gate/usage_std 0.1155 (0.1148) teacher/entropy 0.0217 (0.0263) teacher/usage_max 0.9653 (0.9650) teacher/usage_min 0.0005 (0.0041) teacher/usage_std 0.4471 (0.4469) nleep/row_max_mean 1539.5424 (1530.1499) nleep/row_max_std 41.5462 (41.2661) nleep/row_min_mean 1509.4261 (1502.1154) lr 1.0628e-03 eta 0:07:06
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,546
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [27/50] batch [20/132] time 0.136 (0.108) data 0.000 (0.016) loss 1.5037 (1.3758) teacher_loss 0.2925 (0.1832) loss_zs_kd 0.0001 (0.0077) loss_oracle 0.6312 (0.6309) kd_loss 0.8956 (0.8732) acc 96.8750 (93.2812) gate/entropy 1.0311 (1.0312) gate/usage_max 0.4180 (0.4174) gate/usage_min 0.1700 (0.1700) gate/usage_std 0.1156 (0.1155) teacher/entropy 0.0038 (0.0168) teacher/usage_max 0.9690 (0.9773) teacher/usage_min 0.0003 (0.0022) teacher/usage_std 0.4497 (0.4555) nleep/row_max_mean 1525.9246 (1530.3090) nleep/row_max_std 43.1934 (43.6780) nleep/row_min_mean 1496.1382 (1500.0919) lr 1.0000e-03 eta 0:05:40
epoch [27/50] batch [40/132] time 0.137 (0.095) data 0.000 (0.008) loss 1.2455 (1.3649) teacher_loss 0.0729 (0.1726) loss_zs_kd 0.0018 (0.0080) loss_oracle 0.6270 (0.6326) kd_loss 0.8582 (0.8720) acc 96.8750 (93.7500) gate/entropy 1.0310 (1.0311) gate/usage_max 0.4192 (0.4180) gate/usage_min 0.1699 (0.1700) gate/usage_std 0.1156 (0.1155) teacher/entropy 0.0166 (0.0164) teacher/usage_max 0.9940 (0.9782) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4672 (0.4561) nleep/row_max_mean 1540.4109 (1532.1522) nleep/row_max_std 46.6762 (44.2299) nleep/row_min_mean 1506.4749 (1501.2331) lr 1.0000e-03 eta 0:04:57
epoch [27/50] batch [60/132] time 0.161 (0.093) data 0.000 (0.005) loss 1.1832 (1.3606) teacher_loss 0.0222 (0.1698) loss_zs_kd 0.0008 (0.0074) loss_oracle 0.6084 (0.6356) kd_loss 0.8564 (0.8693) acc 100.0000 (94.0104) gate/entropy 1.0311 (1.0311) gate/usage_max 0.4203 (0.4186) gate/usage_min 0.1700 (0.1699) gate/usage_std 0.1156 (0.1156) teacher/entropy 0.0202 (0.0144) teacher/usage_max 0.9893 (0.9829) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4638 (0.4594) nleep/row_max_mean 1537.0581 (1532.0345) nleep/row_max_std 39.9199 (45.5657) nleep/row_min_mean 1503.2688 (1500.4461) lr 1.0000e-03 eta 0:04:49
epoch [27/50] batch [80/132] time 0.075 (0.098) data 0.000 (0.004) loss 1.2573 (1.3506) teacher_loss 0.0958 (0.1656) loss_zs_kd 0.0174 (0.0075) loss_oracle 0.5803 (0.6295) kd_loss 0.8626 (0.8665) acc 96.8750 (94.1797) gate/entropy 1.0307 (1.0310) gate/usage_max 0.4218 (0.4192) gate/usage_min 0.1695 (0.1699) gate/usage_std 0.1159 (0.1156) teacher/entropy 0.0008 (0.0137) teacher/usage_max 0.9999 (0.9852) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4713 (0.4610) nleep/row_max_mean 1536.3987 (1532.4243) nleep/row_max_std 61.1623 (45.8554) nleep/row_min_mean 1504.4255 (1500.5474) lr 1.0000e-03 eta 0:05:03
epoch [27/50] batch [100/132] time 0.166 (0.102) data 0.000 (0.003) loss 1.3397 (1.3524) teacher_loss 0.1695 (0.1720) loss_zs_kd 0.0035 (0.0073) loss_oracle 0.6169 (0.6218) kd_loss 0.8600 (0.8658) acc 90.6250 (94.0000) gate/entropy 1.0305 (1.0310) gate/usage_max 0.4230 (0.4198) gate/usage_min 0.1694 (0.1698) gate/usage_std 0.1161 (0.1157) teacher/entropy 0.0004 (0.0131) teacher/usage_max 1.0000 (0.9855) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4714 (0.4612) nleep/row_max_mean 1540.9517 (1533.0097) nleep/row_max_std 37.0916 (45.9295) nleep/row_min_mean 1506.1245 (1500.6921) lr 1.0000e-03 eta 0:05:14
epoch [27/50] batch [120/132] time 0.083 (0.105) data 0.000 (0.003) loss 1.2302 (1.3459) teacher_loss 0.1163 (0.1711) loss_zs_kd 0.0020 (0.0072) loss_oracle 0.5224 (0.6140) kd_loss 0.8516 (0.8642) acc 96.8750 (94.0885) gate/entropy 1.0310 (1.0309) gate/usage_max 0.4238 (0.4204) gate/usage_min 0.1700 (0.1698) gate/usage_std 0.1157 (0.1157) teacher/entropy 0.0088 (0.0127) teacher/usage_max 0.9980 (0.9863) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4700 (0.4618) nleep/row_max_mean 1534.4351 (1533.5712) nleep/row_max_std 47.5058 (46.4258) nleep/row_min_mean 1499.4795 (1500.9081) lr 1.0000e-03 eta 0:05:19
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,556
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [28/50] batch [20/132] time 0.160 (0.184) data 0.000 (0.019) loss 1.2437 (1.3167) teacher_loss 0.1066 (0.1632) loss_zs_kd 0.0120 (0.0069) loss_oracle 0.5632 (0.6032) kd_loss 0.8496 (0.8485) acc 96.8750 (94.6875) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4258 (0.4252) gate/usage_min 0.1697 (0.1697) gate/usage_std 0.1160 (0.1160) teacher/entropy 0.0052 (0.0115) teacher/usage_max 0.9989 (0.9902) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4706 (0.4645) nleep/row_max_mean 1531.3936 (1535.1832) nleep/row_max_std 46.9001 (45.1749) nleep/row_min_mean 1497.0969 (1500.6724) lr 9.3721e-04 eta 0:09:16
epoch [28/50] batch [40/132] time 0.150 (0.170) data 0.000 (0.010) loss 1.3681 (1.3233) teacher_loss 0.2251 (0.1684) loss_zs_kd 0.0114 (0.0066) loss_oracle 0.5743 (0.6011) kd_loss 0.8501 (0.8510) acc 90.6250 (94.5312) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4269 (0.4258) gate/usage_min 0.1698 (0.1698) gate/usage_std 0.1160 (0.1160) teacher/entropy 0.0013 (0.0078) teacher/usage_max 0.9998 (0.9909) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4713 (0.4650) nleep/row_max_mean 1544.2766 (1537.2887) nleep/row_max_std 33.9817 (41.9869) nleep/row_min_mean 1511.1218 (1502.9293) lr 9.3721e-04 eta 0:08:28
epoch [28/50] batch [60/132] time 0.143 (0.164) data 0.000 (0.006) loss 1.1734 (1.3267) teacher_loss 0.0113 (0.1696) loss_zs_kd 0.0054 (0.0067) loss_oracle 0.6366 (0.6082) kd_loss 0.8411 (0.8497) acc 100.0000 (94.4792) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4281 (0.4264) gate/usage_min 0.1698 (0.1698) gate/usage_std 0.1161 (0.1160) teacher/entropy 0.0218 (0.0075) teacher/usage_max 0.9843 (0.9923) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4603 (0.4660) nleep/row_max_mean 1542.1870 (1538.2356) nleep/row_max_std 37.0972 (40.5062) nleep/row_min_mean 1507.3252 (1503.5036) lr 9.3721e-04 eta 0:08:09
epoch [28/50] batch [80/132] time 0.089 (0.152) data 0.000 (0.005) loss 1.6382 (1.3266) teacher_loss 0.5056 (0.1708) loss_zs_kd 0.0114 (0.0064) loss_oracle 0.5842 (0.6092) kd_loss 0.8349 (0.8479) acc 84.3750 (94.2578) gate/entropy 1.0304 (1.0307) gate/usage_max 0.4294 (0.4269) gate/usage_min 0.1697 (0.1698) gate/usage_std 0.1163 (0.1160) teacher/entropy 0.0197 (0.0081) teacher/usage_max 0.9899 (0.9919) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4643 (0.4657) nleep/row_max_mean 1542.5742 (1538.5078) nleep/row_max_std 39.0790 (40.2695) nleep/row_min_mean 1510.7482 (1503.6897) lr 9.3721e-04 eta 0:07:29
epoch [28/50] batch [100/132] time 0.098 (0.142) data 0.000 (0.004) loss 1.2459 (1.3145) teacher_loss 0.1193 (0.1611) loss_zs_kd 0.0102 (0.0066) loss_oracle 0.5580 (0.6066) kd_loss 0.8425 (0.8468) acc 96.8750 (94.6562) gate/entropy 1.0309 (1.0307) gate/usage_max 0.4304 (0.4275) gate/usage_min 0.1704 (0.1699) gate/usage_std 0.1159 (0.1160) teacher/entropy 0.0006 (0.0076) teacher/usage_max 0.9999 (0.9923) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4660) nleep/row_max_mean 1533.7617 (1538.6529) nleep/row_max_std 41.4054 (40.1686) nleep/row_min_mean 1499.1846 (1503.6605) lr 9.3721e-04 eta 0:06:57
epoch [28/50] batch [120/132] time 0.073 (0.139) data 0.000 (0.003) loss 1.2260 (1.3119) teacher_loss 0.1084 (0.1615) loss_zs_kd 0.0022 (0.0065) loss_oracle 0.5526 (0.6038) kd_loss 0.8403 (0.8453) acc 96.8750 (94.6354) gate/entropy 1.0312 (1.0307) gate/usage_max 0.4316 (0.4281) gate/usage_min 0.1707 (0.1700) gate/usage_std 0.1158 (0.1160) teacher/entropy 0.0000 (0.0073) teacher/usage_max 1.0000 (0.9929) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4714 (0.4664) nleep/row_max_mean 1524.9584 (1537.6071) nleep/row_max_std 53.0578 (40.9979) nleep/row_min_mean 1488.7020 (1502.5413) lr 9.3721e-04 eta 0:06:44
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,559
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [29/50] batch [20/132] time 0.122 (0.133) data 0.000 (0.016) loss 1.2471 (1.2883) teacher_loss 0.1287 (0.1545) loss_zs_kd 0.0030 (0.0063) loss_oracle 0.5659 (0.5874) kd_loss 0.8339 (0.8369) acc 93.7500 (94.0625) gate/entropy 1.0310 (1.0311) gate/usage_max 0.4339 (0.4332) gate/usage_min 0.1707 (0.1708) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0013 (0.0037) teacher/usage_max 0.9998 (0.9924) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4713 (0.4661) nleep/row_max_mean 1527.3168 (1532.8016) nleep/row_max_std 44.4065 (42.8563) nleep/row_min_mean 1494.0873 (1497.4130) lr 8.7467e-04 eta 0:06:22
epoch [29/50] batch [40/132] time 0.070 (0.124) data 0.000 (0.008) loss 1.2246 (1.3330) teacher_loss 0.0765 (0.1876) loss_zs_kd 0.0082 (0.0060) loss_oracle 0.6279 (0.6143) kd_loss 0.8300 (0.8352) acc 96.8750 (93.3594) gate/entropy 1.0311 (1.0311) gate/usage_max 0.4352 (0.4338) gate/usage_min 0.1710 (0.1709) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0023 (0.0027) teacher/usage_max 0.9996 (0.9952) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4711 (0.4680) nleep/row_max_mean 1528.6785 (1533.5130) nleep/row_max_std 53.9707 (43.6448) nleep/row_min_mean 1493.5797 (1497.6056) lr 8.7467e-04 eta 0:05:54
epoch [29/50] batch [60/132] time 0.086 (0.122) data 0.000 (0.005) loss 1.3851 (1.3174) teacher_loss 0.2868 (0.1712) loss_zs_kd 0.0032 (0.0058) loss_oracle 0.5377 (0.6196) kd_loss 0.8279 (0.8335) acc 90.6250 (94.1667) gate/entropy 1.0310 (1.0311) gate/usage_max 0.4367 (0.4345) gate/usage_min 0.1712 (0.1710) gate/usage_std 0.1161 (0.1159) teacher/entropy 0.0006 (0.0020) teacher/usage_max 0.9999 (0.9963) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4713 (0.4688) nleep/row_max_mean 1555.3094 (1536.2124) nleep/row_max_std 41.2481 (43.6324) nleep/row_min_mean 1517.3271 (1499.7768) lr 8.7467e-04 eta 0:05:47
epoch [29/50] batch [80/132] time 0.086 (0.122) data 0.000 (0.004) loss 1.1433 (1.3108) teacher_loss 0.0256 (0.1661) loss_zs_kd 0.0004 (0.0063) loss_oracle 0.5985 (0.6206) kd_loss 0.8182 (0.8312) acc 100.0000 (94.4141) gate/entropy 1.0312 (1.0312) gate/usage_max 0.4382 (0.4352) gate/usage_min 0.1716 (0.1712) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0070 (0.0022) teacher/usage_max 0.9985 (0.9965) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4703 (0.4690) nleep/row_max_mean 1550.4312 (1537.0390) nleep/row_max_std 43.2779 (44.5673) nleep/row_min_mean 1510.5035 (1500.0971) lr 8.7467e-04 eta 0:05:43
epoch [29/50] batch [100/132] time 0.147 (0.123) data 0.000 (0.003) loss 1.3254 (1.3075) teacher_loss 0.2157 (0.1660) loss_zs_kd 0.0089 (0.0062) loss_oracle 0.5675 (0.6180) kd_loss 0.8215 (0.8294) acc 93.7500 (94.4062) gate/entropy 1.0315 (1.0312) gate/usage_max 0.4398 (0.4360) gate/usage_min 0.1722 (0.1713) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0000 (0.0021) teacher/usage_max 1.0000 (0.9971) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4694) nleep/row_max_mean 1529.5818 (1537.2853) nleep/row_max_std 46.3419 (44.3470) nleep/row_min_mean 1491.4805 (1500.2211) lr 8.7467e-04 eta 0:05:45
epoch [29/50] batch [120/132] time 0.130 (0.128) data 0.000 (0.003) loss 1.3435 (1.3040) teacher_loss 0.2184 (0.1643) loss_zs_kd 0.0044 (0.0064) loss_oracle 0.6104 (0.6186) kd_loss 0.8177 (0.8273) acc 90.6250 (94.5312) gate/entropy 1.0317 (1.0313) gate/usage_max 0.4414 (0.4368) gate/usage_min 0.1726 (0.1715) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0000 (0.0026) teacher/usage_max 1.0000 (0.9970) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4693) nleep/row_max_mean 1536.3611 (1537.2935) nleep/row_max_std 42.8871 (43.6898) nleep/row_min_mean 1497.0999 (1500.2276) lr 8.7467e-04 eta 0:05:56
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,549
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.5%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [30/50] batch [20/132] time 0.168 (0.168) data 0.000 (0.016) loss 1.1920 (1.2494) teacher_loss 0.0809 (0.1350) loss_zs_kd 0.0016 (0.0071) loss_oracle 0.5986 (0.5996) kd_loss 0.8110 (0.8111) acc 96.8750 (96.0938) gate/entropy 1.0319 (1.0319) gate/usage_max 0.4443 (0.4434) gate/usage_min 0.1734 (0.1733) gate/usage_std 0.1159 (0.1158) teacher/entropy 0.0001 (0.0034) teacher/usage_max 1.0000 (0.9976) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4697) nleep/row_max_mean 1534.7031 (1537.7836) nleep/row_max_std 38.1015 (39.0832) nleep/row_min_mean 1498.8113 (1501.5391) lr 8.1262e-04 eta 0:07:42
epoch [30/50] batch [40/132] time 0.105 (0.141) data 0.000 (0.008) loss 1.1527 (1.2657) teacher_loss 0.0167 (0.1575) loss_zs_kd 0.0057 (0.0069) loss_oracle 0.6725 (0.5917) kd_loss 0.7969 (0.8090) acc 100.0000 (95.3125) gate/entropy 1.0319 (1.0320) gate/usage_max 0.4463 (0.4443) gate/usage_min 0.1738 (0.1735) gate/usage_std 0.1160 (0.1158) teacher/entropy 0.0368 (0.0046) teacher/usage_max 0.9716 (0.9950) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4515 (0.4679) nleep/row_max_mean 1548.7881 (1537.7480) nleep/row_max_std 34.6002 (39.5056) nleep/row_min_mean 1515.2434 (1502.1332) lr 8.1262e-04 eta 0:06:26
epoch [30/50] batch [60/132] time 0.181 (0.132) data 0.000 (0.006) loss 1.3249 (1.2664) teacher_loss 0.2472 (0.1651) loss_zs_kd 0.0172 (0.0079) loss_oracle 0.5239 (0.5815) kd_loss 0.8071 (0.8066) acc 90.6250 (94.7396) gate/entropy 1.0321 (1.0320) gate/usage_max 0.4482 (0.4452) gate/usage_min 0.1745 (0.1738) gate/usage_std 0.1160 (0.1158) teacher/entropy 0.0008 (0.0062) teacher/usage_max 0.9689 (0.9927) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4496 (0.4662) nleep/row_max_mean 1544.7487 (1537.4391) nleep/row_max_std 42.7017 (39.1356) nleep/row_min_mean 1509.8054 (1502.4051) lr 8.1262e-04 eta 0:05:57
epoch [30/50] batch [80/132] time 0.192 (0.131) data 0.000 (0.004) loss 1.2019 (1.2581) teacher_loss 0.1525 (0.1646) loss_zs_kd 0.0083 (0.0079) loss_oracle 0.5125 (0.5722) kd_loss 0.7890 (0.8035) acc 93.7500 (94.5703) gate/entropy 1.0325 (1.0321) gate/usage_max 0.4500 (0.4462) gate/usage_min 0.1754 (0.1741) gate/usage_std 0.1158 (0.1158) teacher/entropy 0.0142 (0.0066) teacher/usage_max 0.9740 (0.9930) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4531 (0.4665) nleep/row_max_mean 1535.7100 (1536.7156) nleep/row_max_std 42.4182 (39.3936) nleep/row_min_mean 1500.5962 (1501.9109) lr 8.1262e-04 eta 0:05:51
epoch [30/50] batch [100/132] time 0.091 (0.127) data 0.000 (0.003) loss 1.5282 (1.2542) teacher_loss 0.4149 (0.1616) loss_zs_kd 0.0039 (0.0079) loss_oracle 0.6478 (0.5750) kd_loss 0.7874 (0.8012) acc 90.6250 (94.7812) gate/entropy 1.0325 (1.0322) gate/usage_max 0.4523 (0.4472) gate/usage_min 0.1760 (0.1744) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0079 (0.0072) teacher/usage_max 0.9979 (0.9925) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4699 (0.4661) nleep/row_max_mean 1526.0605 (1535.4504) nleep/row_max_std 37.7515 (39.5589) nleep/row_min_mean 1493.4561 (1501.0736) lr 8.1262e-04 eta 0:05:40
epoch [30/50] batch [120/132] time 0.068 (0.124) data 0.000 (0.003) loss 1.2752 (1.2525) teacher_loss 0.2418 (0.1641) loss_zs_kd 0.0036 (0.0077) loss_oracle 0.4881 (0.5709) kd_loss 0.7877 (0.7990) acc 90.6250 (94.5573) gate/entropy 1.0324 (1.0322) gate/usage_max 0.4549 (0.4483) gate/usage_min 0.1766 (0.1747) gate/usage_std 0.1163 (0.1159) teacher/entropy 0.0001 (0.0068) teacher/usage_max 1.0000 (0.9927) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4714 (0.4663) nleep/row_max_mean 1539.5579 (1535.0495) nleep/row_max_std 41.6979 (39.3450) nleep/row_min_mean 1504.6558 (1500.7522) lr 8.1262e-04 eta 0:05:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,553
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [31/50] batch [20/132] time 0.067 (0.129) data 0.000 (0.018) loss 1.2526 (1.2440) teacher_loss 0.2043 (0.1837) loss_zs_kd 0.0063 (0.0077) loss_oracle 0.5310 (0.5520) kd_loss 0.7797 (0.7805) acc 93.7500 (93.9062) gate/entropy 1.0326 (1.0325) gate/usage_max 0.4586 (0.4575) gate/usage_min 0.1781 (0.1776) gate/usage_std 0.1165 (0.1164) teacher/entropy 0.0000 (0.0037) teacher/usage_max 1.0000 (0.9962) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4688) nleep/row_max_mean 1537.3494 (1531.9836) nleep/row_max_std 37.1949 (37.2303) nleep/row_min_mean 1501.7135 (1497.7192) lr 7.5131e-04 eta 0:05:37
epoch [31/50] batch [40/132] time 0.077 (0.119) data 0.000 (0.009) loss 1.1639 (1.2358) teacher_loss 0.1311 (0.1775) loss_zs_kd 0.0099 (0.0073) loss_oracle 0.5432 (0.5564) kd_loss 0.7562 (0.7765) acc 96.8750 (93.9844) gate/entropy 1.0326 (1.0325) gate/usage_max 0.4611 (0.4587) gate/usage_min 0.1789 (0.1780) gate/usage_std 0.1167 (0.1166) teacher/entropy 0.0214 (0.0049) teacher/usage_max 0.9865 (0.9945) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4619 (0.4675) nleep/row_max_mean 1539.1898 (1532.9661) nleep/row_max_std 33.3451 (37.2587) nleep/row_min_mean 1502.7332 (1498.5999) lr 7.5131e-04 eta 0:05:09
epoch [31/50] batch [60/132] time 0.148 (0.121) data 0.000 (0.006) loss 1.3956 (1.2245) teacher_loss 0.3575 (0.1732) loss_zs_kd 0.0048 (0.0073) loss_oracle 0.5189 (0.5485) kd_loss 0.7762 (0.7734) acc 87.5000 (94.0625) gate/entropy 1.0325 (1.0325) gate/usage_max 0.4638 (0.4600) gate/usage_min 0.1797 (0.1784) gate/usage_std 0.1171 (0.1167) teacher/entropy 0.0002 (0.0056) teacher/usage_max 0.9688 (0.9923) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4495 (0.4660) nleep/row_max_mean 1529.5186 (1533.0414) nleep/row_max_std 42.3780 (36.8494) nleep/row_min_mean 1496.2034 (1498.9001) lr 7.5131e-04 eta 0:05:11
epoch [31/50] batch [80/132] time 0.159 (0.129) data 0.000 (0.005) loss 1.0798 (1.2070) teacher_loss 0.0936 (0.1639) loss_zs_kd 0.0006 (0.0065) loss_oracle 0.4473 (0.5385) kd_loss 0.7622 (0.7706) acc 93.7500 (94.1406) gate/entropy 1.0324 (1.0325) gate/usage_max 0.4666 (0.4613) gate/usage_min 0.1807 (0.1789) gate/usage_std 0.1175 (0.1169) teacher/entropy 0.0001 (0.0054) teacher/usage_max 1.0000 (0.9922) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4660) nleep/row_max_mean 1536.8965 (1532.2756) nleep/row_max_std 33.4640 (36.7350) nleep/row_min_mean 1502.3729 (1498.4106) lr 7.5131e-04 eta 0:05:30
epoch [31/50] batch [100/132] time 0.142 (0.134) data 0.000 (0.004) loss 1.1109 (1.1977) teacher_loss 0.0414 (0.1593) loss_zs_kd 0.0012 (0.0065) loss_oracle 0.6159 (0.5343) kd_loss 0.7610 (0.7681) acc 100.0000 (94.4062) gate/entropy 1.0322 (1.0324) gate/usage_max 0.4696 (0.4627) gate/usage_min 0.1817 (0.1793) gate/usage_std 0.1181 (0.1171) teacher/entropy 0.0433 (0.0062) teacher/usage_max 0.9482 (0.9909) teacher/usage_min 0.0014 (0.0004) teacher/usage_std 0.4352 (0.4650) nleep/row_max_mean 1524.9048 (1531.9349) nleep/row_max_std 45.5864 (36.8333) nleep/row_min_mean 1495.3782 (1498.4193) lr 7.5131e-04 eta 0:05:39
epoch [31/50] batch [120/132] time 0.154 (0.138) data 0.000 (0.003) loss 1.2242 (1.1896) teacher_loss 0.2313 (0.1604) loss_zs_kd 0.0039 (0.0062) loss_oracle 0.4826 (0.5245) kd_loss 0.7496 (0.7639) acc 93.7500 (94.3229) gate/entropy 1.0319 (1.0324) gate/usage_max 0.4726 (0.4641) gate/usage_min 0.1826 (0.1798) gate/usage_std 0.1186 (0.1173) teacher/entropy 0.0000 (0.0077) teacher/usage_max 1.0000 (0.9903) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4646) nleep/row_max_mean 1529.4594 (1531.1804) nleep/row_max_std 38.8975 (36.9595) nleep/row_min_mean 1497.3381 (1497.9726) lr 7.5131e-04 eta 0:05:48
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,564
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 92.8%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [32/50] batch [20/132] time 0.081 (0.117) data 0.000 (0.014) loss 1.0983 (1.1488) teacher_loss 0.0955 (0.1532) loss_zs_kd 0.0072 (0.0055) loss_oracle 0.5205 (0.5069) kd_loss 0.7390 (0.7395) acc 96.8750 (94.8438) gate/entropy 1.0313 (1.0315) gate/usage_max 0.4774 (0.4761) gate/usage_min 0.1843 (0.1838) gate/usage_std 0.1197 (0.1194) teacher/entropy 0.0005 (0.0084) teacher/usage_max 0.9999 (0.9890) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4714 (0.4637) nleep/row_max_mean 1530.5457 (1531.4422) nleep/row_max_std 40.9231 (39.6957) nleep/row_min_mean 1498.4116 (1499.3727) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [40/132] time 0.074 (0.113) data 0.000 (0.007) loss 1.1367 (1.1460) teacher_loss 0.1557 (0.1610) loss_zs_kd 0.0065 (0.0063) loss_oracle 0.4704 (0.4901) kd_loss 0.7425 (0.7368) acc 96.8750 (94.6875) gate/entropy 1.0309 (1.0312) gate/usage_max 0.4803 (0.4776) gate/usage_min 0.1854 (0.1843) gate/usage_std 0.1204 (0.1198) teacher/entropy 0.0020 (0.0083) teacher/usage_max 0.9690 (0.9876) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4497 (0.4627) nleep/row_max_mean 1522.4634 (1531.4631) nleep/row_max_std 36.1444 (39.5737) nleep/row_min_mean 1489.8375 (1499.1527) lr 6.9098e-04 eta 0:04:39
epoch [32/50] batch [60/132] time 0.083 (0.115) data 0.000 (0.005) loss 1.0056 (1.1353) teacher_loss 0.0609 (0.1573) loss_zs_kd 0.0001 (0.0067) loss_oracle 0.4735 (0.4810) kd_loss 0.7079 (0.7342) acc 100.0000 (94.7396) gate/entropy 1.0301 (1.0310) gate/usage_max 0.4838 (0.4791) gate/usage_min 0.1862 (0.1848) gate/usage_std 0.1215 (0.1202) teacher/entropy 0.0224 (0.0097) teacher/usage_max 0.9893 (0.9844) teacher/usage_min 0.0004 (0.0008) teacher/usage_std 0.4639 (0.4605) nleep/row_max_mean 1538.1094 (1531.0987) nleep/row_max_std 40.7528 (39.5799) nleep/row_min_mean 1507.6624 (1499.1825) lr 6.9098e-04 eta 0:04:42
epoch [32/50] batch [80/132] time 0.105 (0.112) data 0.000 (0.004) loss 1.1693 (1.1277) teacher_loss 0.2004 (0.1539) loss_zs_kd 0.0152 (0.0068) loss_oracle 0.4640 (0.4798) kd_loss 0.7293 (0.7305) acc 93.7500 (94.6484) gate/entropy 1.0295 (1.0307) gate/usage_max 0.4869 (0.4806) gate/usage_min 0.1873 (0.1853) gate/usage_std 0.1224 (0.1206) teacher/entropy 0.0033 (0.0106) teacher/usage_max 0.9682 (0.9841) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4491 (0.4603) nleep/row_max_mean 1538.9084 (1530.1224) nleep/row_max_std 41.7828 (39.7532) nleep/row_min_mean 1508.2430 (1498.6727) lr 6.9098e-04 eta 0:04:32
epoch [32/50] batch [100/132] time 0.142 (0.111) data 0.000 (0.003) loss 1.1534 (1.1302) teacher_loss 0.1291 (0.1596) loss_zs_kd 0.0220 (0.0073) loss_oracle 0.4908 (0.4781) kd_loss 0.7680 (0.7278) acc 93.7500 (94.3438) gate/entropy 1.0288 (1.0304) gate/usage_max 0.4901 (0.4822) gate/usage_min 0.1884 (0.1858) gate/usage_std 0.1235 (0.1211) teacher/entropy 0.0012 (0.0119) teacher/usage_max 0.9061 (0.9813) teacher/usage_min 0.0313 (0.0018) teacher/usage_std 0.4052 (0.4583) nleep/row_max_mean 1520.1655 (1529.1981) nleep/row_max_std 43.5574 (39.5175) nleep/row_min_mean 1493.6600 (1498.2871) lr 6.9098e-04 eta 0:04:27
epoch [32/50] batch [120/132] time 0.160 (0.111) data 0.000 (0.003) loss 0.9702 (1.1340) teacher_loss 0.0188 (0.1666) loss_zs_kd 0.0011 (0.0073) loss_oracle 0.4847 (0.4779) kd_loss 0.7085 (0.7248) acc 100.0000 (94.0885) gate/entropy 1.0284 (1.0301) gate/usage_max 0.4924 (0.4837) gate/usage_min 0.1896 (0.1863) gate/usage_std 0.1241 (0.1215) teacher/entropy 0.0124 (0.0126) teacher/usage_max 0.9706 (0.9804) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4508 (0.4576) nleep/row_max_mean 1518.4786 (1528.1333) nleep/row_max_std 41.6929 (39.1620) nleep/row_min_mean 1487.4396 (1497.6347) lr 6.9098e-04 eta 0:04:24
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,553
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [33/50] batch [20/132] time 0.159 (0.123) data 0.000 (0.012) loss 1.0446 (1.1123) teacher_loss 0.1276 (0.1791) loss_zs_kd 0.0011 (0.0066) loss_oracle 0.4745 (0.4742) kd_loss 0.6792 (0.6928) acc 96.8750 (93.5938) gate/entropy 1.0263 (1.0270) gate/usage_max 0.4987 (0.4967) gate/usage_min 0.1910 (0.1906) gate/usage_std 0.1267 (0.1258) teacher/entropy 0.0269 (0.0221) teacher/usage_max 0.9793 (0.9772) teacher/usage_min 0.0014 (0.0036) teacher/usage_std 0.4568 (0.4554) nleep/row_max_mean 1527.5596 (1523.6950) nleep/row_max_std 38.0678 (39.5360) nleep/row_min_mean 1501.3328 (1495.4485) lr 6.3188e-04 eta 0:04:49
epoch [33/50] batch [40/132] time 0.156 (0.136) data 0.000 (0.006) loss 1.0212 (1.0962) teacher_loss 0.1033 (0.1619) loss_zs_kd 0.0009 (0.0064) loss_oracle 0.4534 (0.4717) kd_loss 0.6907 (0.6952) acc 93.7500 (93.9844) gate/entropy 1.0256 (1.0266) gate/usage_max 0.5012 (0.4981) gate/usage_min 0.1921 (0.1911) gate/usage_std 0.1276 (0.1263) teacher/entropy 0.0000 (0.0181) teacher/usage_max 1.0000 (0.9758) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.4714 (0.4544) nleep/row_max_mean 1525.8982 (1523.6033) nleep/row_max_std 31.3765 (38.1670) nleep/row_min_mean 1496.7211 (1494.9992) lr 6.3188e-04 eta 0:05:18
epoch [33/50] batch [60/132] time 0.154 (0.143) data 0.000 (0.004) loss 1.0822 (1.0854) teacher_loss 0.1424 (0.1545) loss_zs_kd 0.0132 (0.0067) loss_oracle 0.4947 (0.4706) kd_loss 0.6858 (0.6923) acc 93.7500 (94.3750) gate/entropy 1.0249 (1.0262) gate/usage_max 0.5035 (0.4995) gate/usage_min 0.1931 (0.1916) gate/usage_std 0.1285 (0.1269) teacher/entropy 0.0005 (0.0196) teacher/usage_max 0.9999 (0.9738) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.4714 (0.4530) nleep/row_max_mean 1530.2759 (1524.1233) nleep/row_max_std 39.2947 (37.7116) nleep/row_min_mean 1495.9504 (1495.3503) lr 6.3188e-04 eta 0:05:32
epoch [33/50] batch [80/132] time 0.148 (0.145) data 0.000 (0.003) loss 1.0479 (1.0697) teacher_loss 0.1704 (0.1444) loss_zs_kd 0.0092 (0.0067) loss_oracle 0.3921 (0.4648) kd_loss 0.6768 (0.6895) acc 90.6250 (94.8828) gate/entropy 1.0239 (1.0257) gate/usage_max 0.5063 (0.5010) gate/usage_min 0.1940 (0.1921) gate/usage_std 0.1297 (0.1275) teacher/entropy 0.0042 (0.0198) teacher/usage_max 0.9992 (0.9732) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.4709 (0.4526) nleep/row_max_mean 1531.2834 (1525.0387) nleep/row_max_std 25.7672 (37.2382) nleep/row_min_mean 1502.6117 (1496.2262) lr 6.3188e-04 eta 0:05:33
epoch [33/50] batch [100/132] time 0.187 (0.146) data 0.000 (0.003) loss 1.0543 (1.0702) teacher_loss 0.1440 (0.1507) loss_zs_kd 0.0071 (0.0070) loss_oracle 0.4713 (0.4574) kd_loss 0.6711 (0.6874) acc 96.8750 (94.7500) gate/entropy 1.0227 (1.0252) gate/usage_max 0.5092 (0.5024) gate/usage_min 0.1949 (0.1926) gate/usage_std 0.1310 (0.1281) teacher/entropy 0.0043 (0.0192) teacher/usage_max 0.9990 (0.9737) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.4707 (0.4529) nleep/row_max_mean 1527.3180 (1525.1471) nleep/row_max_std 42.1027 (37.6577) nleep/row_min_mean 1497.1815 (1496.4668) lr 6.3188e-04 eta 0:05:32
epoch [33/50] batch [120/132] time 0.163 (0.148) data 0.000 (0.002) loss 1.0811 (1.0711) teacher_loss 0.1693 (0.1553) loss_zs_kd 0.0039 (0.0070) loss_oracle 0.4603 (0.4533) kd_loss 0.6797 (0.6856) acc 93.7500 (94.6615) gate/entropy 1.0215 (1.0246) gate/usage_max 0.5120 (0.5038) gate/usage_min 0.1958 (0.1931) gate/usage_std 0.1323 (0.1287) teacher/entropy 0.0080 (0.0187) teacher/usage_max 0.9681 (0.9732) teacher/usage_min 0.0012 (0.0043) teacher/usage_std 0.4490 (0.4526) nleep/row_max_mean 1525.0051 (1524.6379) nleep/row_max_std 36.3722 (38.1981) nleep/row_min_mean 1497.2355 (1496.1539) lr 6.3188e-04 eta 0:05:33
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,529
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.2%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [34/50] batch [20/132] time 0.079 (0.098) data 0.000 (0.012) loss 1.0633 (1.0486) teacher_loss 0.1715 (0.1430) loss_zs_kd 0.0050 (0.0062) loss_oracle 0.4860 (0.4591) kd_loss 0.6463 (0.6730) acc 96.8750 (95.3125) gate/entropy 1.0196 (1.0202) gate/usage_max 0.5162 (0.5150) gate/usage_min 0.1971 (0.1968) gate/usage_std 0.1344 (0.1338) teacher/entropy 0.0259 (0.0176) teacher/usage_max 0.9886 (0.9663) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.4634 (0.4477) nleep/row_max_mean 1536.6428 (1521.6489) nleep/row_max_std 38.2613 (40.7017) nleep/row_min_mean 1508.7668 (1494.2452) lr 5.7422e-04 eta 0:03:36
epoch [34/50] batch [40/132] time 0.109 (0.108) data 0.000 (0.006) loss 1.1044 (1.0406) teacher_loss 0.2305 (0.1421) loss_zs_kd 0.0059 (0.0066) loss_oracle 0.4400 (0.4577) kd_loss 0.6510 (0.6664) acc 90.6250 (95.2344) gate/entropy 1.0185 (1.0196) gate/usage_max 0.5185 (0.5162) gate/usage_min 0.1979 (0.1971) gate/usage_std 0.1355 (0.1344) teacher/entropy 0.0077 (0.0202) teacher/usage_max 0.9981 (0.9676) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.4700 (0.4487) nleep/row_max_mean 1518.9927 (1523.9012) nleep/row_max_std 41.2986 (39.7127) nleep/row_min_mean 1491.2324 (1495.3965) lr 5.7422e-04 eta 0:03:58
epoch [34/50] batch [60/132] time 0.125 (0.115) data 0.000 (0.004) loss 1.0752 (1.0304) teacher_loss 0.2244 (0.1355) loss_zs_kd 0.0013 (0.0064) loss_oracle 0.4103 (0.4549) kd_loss 0.6449 (0.6642) acc 93.7500 (95.4688) gate/entropy 1.0172 (1.0191) gate/usage_max 0.5211 (0.5174) gate/usage_min 0.1986 (0.1975) gate/usage_std 0.1369 (0.1350) teacher/entropy 0.0094 (0.0184) teacher/usage_max 0.9974 (0.9691) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4695 (0.4497) nleep/row_max_mean 1516.5696 (1524.8576) nleep/row_max_std 47.7515 (39.9809) nleep/row_min_mean 1488.9867 (1495.8309) lr 5.7422e-04 eta 0:04:12
epoch [34/50] batch [80/132] time 0.075 (0.115) data 0.001 (0.003) loss 0.8857 (1.0359) teacher_loss 0.0162 (0.1451) loss_zs_kd 0.0154 (0.0066) loss_oracle 0.4287 (0.4538) kd_loss 0.6475 (0.6606) acc 100.0000 (95.1562) gate/entropy 1.0162 (1.0185) gate/usage_max 0.5230 (0.5185) gate/usage_min 0.1993 (0.1979) gate/usage_std 0.1379 (0.1355) teacher/entropy 0.0008 (0.0178) teacher/usage_max 0.9999 (0.9719) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.4713 (0.4517) nleep/row_max_mean 1547.5930 (1525.2408) nleep/row_max_std 27.4767 (39.6878) nleep/row_min_mean 1513.8911 (1495.8594) lr 5.7422e-04 eta 0:04:09
epoch [34/50] batch [100/132] time 0.067 (0.115) data 0.000 (0.003) loss 1.2079 (1.0370) teacher_loss 0.3242 (0.1508) loss_zs_kd 0.0099 (0.0068) loss_oracle 0.4705 (0.4515) kd_loss 0.6435 (0.6570) acc 90.6250 (94.9062) gate/entropy 1.0155 (1.0179) gate/usage_max 0.5245 (0.5196) gate/usage_min 0.2000 (0.1983) gate/usage_std 0.1387 (0.1361) teacher/entropy 0.0019 (0.0162) teacher/usage_max 0.9997 (0.9755) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4712 (0.4542) nleep/row_max_mean 1515.3159 (1525.7941) nleep/row_max_std 36.3068 (39.9619) nleep/row_min_mean 1482.3909 (1496.0068) lr 5.7422e-04 eta 0:04:07
epoch [34/50] batch [120/132] time 0.072 (0.114) data 0.000 (0.002) loss 1.0514 (1.0402) teacher_loss 0.2061 (0.1549) loss_zs_kd 0.0156 (0.0071) loss_oracle 0.4256 (0.4531) kd_loss 0.6246 (0.6552) acc 90.6250 (94.7396) gate/entropy 1.0139 (1.0174) gate/usage_max 0.5273 (0.5207) gate/usage_min 0.2007 (0.1986) gate/usage_std 0.1402 (0.1367) teacher/entropy 0.0201 (0.0158) teacher/usage_max 0.9950 (0.9759) teacher/usage_min 0.0001 (0.0043) teacher/usage_std 0.4679 (0.4544) nleep/row_max_mean 1525.0750 (1526.6104) nleep/row_max_std 35.4330 (39.5317) nleep/row_min_mean 1496.0880 (1496.4929) lr 5.7422e-04 eta 0:04:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,546
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.5%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [35/50] batch [20/132] time 0.158 (0.166) data 0.000 (0.015) loss 1.2349 (1.0303) teacher_loss 0.3927 (0.1648) loss_zs_kd 0.0099 (0.0052) loss_oracle 0.4296 (0.4576) kd_loss 0.6225 (0.6342) acc 87.5000 (94.8438) gate/entropy 1.0128 (1.0127) gate/usage_max 0.5293 (0.5293) gate/usage_min 0.2016 (0.2014) gate/usage_std 0.1413 (0.1413) teacher/entropy 0.0397 (0.0209) teacher/usage_max 0.9620 (0.9758) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4448 (0.4544) nleep/row_max_mean 1525.6503 (1531.5997) nleep/row_max_std 36.9278 (37.6605) nleep/row_min_mean 1490.3511 (1500.1760) lr 5.1825e-04 eta 0:05:47
epoch [35/50] batch [40/132] time 0.141 (0.157) data 0.000 (0.008) loss 0.9347 (1.0099) teacher_loss 0.0907 (0.1517) loss_zs_kd 0.0177 (0.0064) loss_oracle 0.4114 (0.4387) kd_loss 0.6295 (0.6356) acc 96.8750 (95.2344) gate/entropy 1.0112 (1.0122) gate/usage_max 0.5319 (0.5302) gate/usage_min 0.2021 (0.2016) gate/usage_std 0.1428 (0.1418) teacher/entropy 0.0020 (0.0180) teacher/usage_max 0.9997 (0.9763) teacher/usage_min 0.0001 (0.0029) teacher/usage_std 0.4712 (0.4548) nleep/row_max_mean 1526.8950 (1530.9273) nleep/row_max_std 43.3707 (38.1111) nleep/row_min_mean 1498.1431 (1499.6811) lr 5.1825e-04 eta 0:05:25
epoch [35/50] batch [60/132] time 0.142 (0.154) data 0.000 (0.005) loss 1.0333 (1.0136) teacher_loss 0.1184 (0.1579) loss_zs_kd 0.0018 (0.0063) loss_oracle 0.5182 (0.4379) kd_loss 0.6550 (0.6336) acc 96.8750 (94.9479) gate/entropy 1.0104 (1.0118) gate/usage_max 0.5333 (0.5309) gate/usage_min 0.2026 (0.2019) gate/usage_std 0.1436 (0.1423) teacher/entropy 0.0051 (0.0177) teacher/usage_max 0.9677 (0.9780) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.4487 (0.4560) nleep/row_max_mean 1527.0588 (1529.0126) nleep/row_max_std 42.3603 (38.8107) nleep/row_min_mean 1492.2908 (1497.6865) lr 5.1825e-04 eta 0:05:16
epoch [35/50] batch [80/132] time 0.162 (0.153) data 0.000 (0.004) loss 0.9785 (1.0062) teacher_loss 0.1437 (0.1541) loss_zs_kd 0.0024 (0.0063) loss_oracle 0.4475 (0.4331) kd_loss 0.6099 (0.6325) acc 93.7500 (94.8828) gate/entropy 1.0092 (1.0113) gate/usage_max 0.5352 (0.5317) gate/usage_min 0.2031 (0.2021) gate/usage_std 0.1447 (0.1427) teacher/entropy 0.0193 (0.0178) teacher/usage_max 0.9943 (0.9769) teacher/usage_min 0.0001 (0.0026) teacher/usage_std 0.4674 (0.4552) nleep/row_max_mean 1514.8040 (1528.4327) nleep/row_max_std 45.6688 (39.0933) nleep/row_min_mean 1483.9011 (1497.1383) lr 5.1825e-04 eta 0:05:11
epoch [35/50] batch [100/132] time 0.091 (0.142) data 0.000 (0.003) loss 0.9695 (1.0019) teacher_loss 0.1385 (0.1501) loss_zs_kd 0.0029 (0.0063) loss_oracle 0.4261 (0.4342) kd_loss 0.6166 (0.6315) acc 96.8750 (95.0000) gate/entropy 1.0082 (1.0108) gate/usage_max 0.5366 (0.5325) gate/usage_min 0.2035 (0.2024) gate/usage_std 0.1456 (0.1431) teacher/entropy 0.0074 (0.0171) teacher/usage_max 0.9983 (0.9773) teacher/usage_min 0.0003 (0.0024) teacher/usage_std 0.4702 (0.4554) nleep/row_max_mean 1528.4216 (1527.2173) nleep/row_max_std 36.3194 (39.4940) nleep/row_min_mean 1498.3743 (1496.0780) lr 5.1825e-04 eta 0:04:45
epoch [35/50] batch [120/132] time 0.183 (0.138) data 0.000 (0.003) loss 0.9979 (1.0014) teacher_loss 0.1025 (0.1488) loss_zs_kd 0.0190 (0.0065) loss_oracle 0.5111 (0.4362) kd_loss 0.6304 (0.6312) acc 93.7500 (94.7917) gate/entropy 1.0077 (1.0104) gate/usage_max 0.5374 (0.5332) gate/usage_min 0.2040 (0.2026) gate/usage_std 0.1460 (0.1436) teacher/entropy 0.0173 (0.0180) teacher/usage_max 0.9643 (0.9750) teacher/usage_min 0.0020 (0.0030) teacher/usage_std 0.4463 (0.4539) nleep/row_max_mean 1530.4080 (1527.1037) nleep/row_max_std 46.5435 (40.1547) nleep/row_min_mean 1498.3999 (1496.0505) lr 5.1825e-04 eta 0:04:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,552
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [36/50] batch [20/132] time 0.103 (0.141) data 0.000 (0.016) loss 0.9241 (0.9972) teacher_loss 0.0948 (0.1563) loss_zs_kd 0.0123 (0.0090) loss_oracle 0.4133 (0.4329) kd_loss 0.6165 (0.6200) acc 93.7500 (94.0625) gate/entropy 1.0063 (1.0066) gate/usage_max 0.5396 (0.5390) gate/usage_min 0.2046 (0.2044) gate/usage_std 0.1473 (0.1470) teacher/entropy 0.0005 (0.0183) teacher/usage_max 0.9999 (0.9766) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.4714 (0.4550) nleep/row_max_mean 1538.4783 (1530.0511) nleep/row_max_std 39.1477 (43.3375) nleep/row_min_mean 1503.7565 (1498.8773) lr 4.6417e-04 eta 0:04:36
epoch [36/50] batch [40/132] time 0.101 (0.127) data 0.000 (0.008) loss 0.9459 (0.9804) teacher_loss 0.0739 (0.1398) loss_zs_kd 0.0121 (0.0089) loss_oracle 0.4621 (0.4236) kd_loss 0.6349 (0.6243) acc 96.8750 (95.1562) gate/entropy 1.0056 (1.0063) gate/usage_max 0.5406 (0.5396) gate/usage_min 0.2049 (0.2046) gate/usage_std 0.1479 (0.1473) teacher/entropy 0.0044 (0.0170) teacher/usage_max 0.9678 (0.9718) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4488 (0.4516) nleep/row_max_mean 1530.2885 (1529.1105) nleep/row_max_std 34.0793 (42.5082) nleep/row_min_mean 1495.2092 (1498.1636) lr 4.6417e-04 eta 0:04:05
epoch [36/50] batch [60/132] time 0.075 (0.123) data 0.000 (0.005) loss 0.9415 (0.9775) teacher_loss 0.1310 (0.1408) loss_zs_kd 0.0048 (0.0078) loss_oracle 0.4335 (0.4221) kd_loss 0.5914 (0.6217) acc 93.7500 (95.1562) gate/entropy 1.0046 (1.0059) gate/usage_max 0.5420 (0.5402) gate/usage_min 0.2052 (0.2047) gate/usage_std 0.1488 (0.1477) teacher/entropy 0.0437 (0.0186) teacher/usage_max 0.9745 (0.9714) teacher/usage_min 0.0111 (0.0049) teacher/usage_std 0.4534 (0.4513) nleep/row_max_mean 1533.9196 (1528.6066) nleep/row_max_std 47.4817 (40.7385) nleep/row_min_mean 1502.9474 (1497.8602) lr 4.6417e-04 eta 0:03:55
epoch [36/50] batch [80/132] time 0.089 (0.121) data 0.000 (0.004) loss 0.8349 (0.9687) teacher_loss 0.0183 (0.1368) loss_zs_kd 0.0050 (0.0077) loss_oracle 0.4408 (0.4177) kd_loss 0.5937 (0.6192) acc 100.0000 (95.2734) gate/entropy 1.0040 (1.0055) gate/usage_max 0.5429 (0.5407) gate/usage_min 0.2055 (0.2049) gate/usage_std 0.1494 (0.1480) teacher/entropy 0.0233 (0.0176) teacher/usage_max 0.9934 (0.9745) teacher/usage_min 0.0015 (0.0039) teacher/usage_std 0.4667 (0.4535) nleep/row_max_mean 1510.4978 (1527.0358) nleep/row_max_std 56.5600 (41.5474) nleep/row_min_mean 1485.1938 (1496.5893) lr 4.6417e-04 eta 0:03:50
epoch [36/50] batch [100/132] time 0.165 (0.125) data 0.000 (0.003) loss 1.1624 (0.9707) teacher_loss 0.3053 (0.1401) loss_zs_kd 0.0050 (0.0075) loss_oracle 0.4345 (0.4163) kd_loss 0.6374 (0.6188) acc 87.5000 (95.0312) gate/entropy 1.0033 (1.0052) gate/usage_max 0.5438 (0.5412) gate/usage_min 0.2058 (0.2051) gate/usage_std 0.1500 (0.1483) teacher/entropy 0.0375 (0.0190) teacher/usage_max 0.9188 (0.9725) teacher/usage_min 0.0118 (0.0040) teacher/usage_std 0.4147 (0.4521) nleep/row_max_mean 1519.6320 (1526.3769) nleep/row_max_std 44.2898 (41.5403) nleep/row_min_mean 1490.1826 (1496.3087) lr 4.6417e-04 eta 0:03:54
epoch [36/50] batch [120/132] time 0.187 (0.135) data 0.000 (0.003) loss 0.9875 (0.9695) teacher_loss 0.1112 (0.1411) loss_zs_kd 0.0087 (0.0078) loss_oracle 0.4457 (0.4129) kd_loss 0.6491 (0.6180) acc 96.8750 (95.0260) gate/entropy 1.0030 (1.0048) gate/usage_max 0.5443 (0.5417) gate/usage_min 0.2060 (0.2052) gate/usage_std 0.1502 (0.1486) teacher/entropy 0.0268 (0.0201) teacher/usage_max 0.9243 (0.9712) teacher/usage_min 0.0306 (0.0050) teacher/usage_std 0.4179 (0.4512) nleep/row_max_mean 1518.8438 (1526.3224) nleep/row_max_std 46.4234 (41.6490) nleep/row_min_mean 1488.1156 (1496.4435) lr 4.6417e-04 eta 0:04:10
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,542
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [37/50] batch [20/132] time 0.076 (0.171) data 0.000 (0.020) loss 1.2159 (0.9895) teacher_loss 0.4094 (0.1766) loss_zs_kd 0.0213 (0.0088) loss_oracle 0.3683 (0.3985) kd_loss 0.6116 (0.6093) acc 87.5000 (94.3750) gate/entropy 1.0018 (1.0022) gate/usage_max 0.5459 (0.5453) gate/usage_min 0.2064 (0.2063) gate/usage_std 0.1512 (0.1509) teacher/entropy 0.0423 (0.0334) teacher/usage_max 0.9398 (0.9608) teacher/usage_min 0.0029 (0.0044) teacher/usage_std 0.4294 (0.4440) nleep/row_max_mean 1519.6796 (1525.7637) nleep/row_max_std 38.5166 (41.0352) nleep/row_min_mean 1493.6445 (1497.5999) lr 4.1221e-04 eta 0:05:13
epoch [37/50] batch [40/132] time 0.085 (0.138) data 0.000 (0.010) loss 0.9120 (0.9896) teacher_loss 0.1311 (0.1706) loss_zs_kd 0.0060 (0.0085) loss_oracle 0.3638 (0.4037) kd_loss 0.5960 (0.6129) acc 96.8750 (94.1406) gate/entropy 1.0014 (1.0019) gate/usage_max 0.5464 (0.5457) gate/usage_min 0.2066 (0.2064) gate/usage_std 0.1516 (0.1511) teacher/entropy 0.0350 (0.0323) teacher/usage_max 0.9727 (0.9562) teacher/usage_min 0.0000 (0.0081) teacher/usage_std 0.4522 (0.4407) nleep/row_max_mean 1522.8206 (1526.3253) nleep/row_max_std 48.4016 (39.5294) nleep/row_min_mean 1498.8652 (1498.1480) lr 4.1221e-04 eta 0:04:09
epoch [37/50] batch [60/132] time 0.076 (0.131) data 0.000 (0.007) loss 0.8725 (0.9783) teacher_loss 0.0552 (0.1585) loss_zs_kd 0.0060 (0.0085) loss_oracle 0.4381 (0.4059) kd_loss 0.5953 (0.6126) acc 96.8750 (94.5312) gate/entropy 1.0008 (1.0016) gate/usage_max 0.5473 (0.5461) gate/usage_min 0.2068 (0.2065) gate/usage_std 0.1521 (0.1514) teacher/entropy 0.0097 (0.0327) teacher/usage_max 0.9977 (0.9554) teacher/usage_min 0.0000 (0.0089) teacher/usage_std 0.4698 (0.4401) nleep/row_max_mean 1534.8547 (1527.9481) nleep/row_max_std 37.8721 (38.9762) nleep/row_min_mean 1503.6393 (1499.6923) lr 4.1221e-04 eta 0:03:54
epoch [37/50] batch [80/132] time 0.100 (0.130) data 0.000 (0.005) loss 0.8876 (0.9758) teacher_loss 0.0452 (0.1550) loss_zs_kd 0.0142 (0.0091) loss_oracle 0.4200 (0.4069) kd_loss 0.6253 (0.6128) acc 100.0000 (94.7656) gate/entropy 1.0000 (1.0014) gate/usage_max 0.5482 (0.5465) gate/usage_min 0.2071 (0.2066) gate/usage_std 0.1527 (0.1516) teacher/entropy 0.0335 (0.0332) teacher/usage_max 0.9299 (0.9536) teacher/usage_min 0.0073 (0.0099) teacher/usage_std 0.4225 (0.4388) nleep/row_max_mean 1534.5291 (1528.2957) nleep/row_max_std 42.2860 (39.4319) nleep/row_min_mean 1508.6499 (1500.0062) lr 4.1221e-04 eta 0:03:49
epoch [37/50] batch [100/132] time 0.103 (0.126) data 0.000 (0.004) loss 1.0656 (0.9797) teacher_loss 0.2718 (0.1559) loss_zs_kd 0.0037 (0.0087) loss_oracle 0.4375 (0.4096) kd_loss 0.5732 (0.6146) acc 90.6250 (94.5938) gate/entropy 0.9994 (1.0011) gate/usage_max 0.5491 (0.5468) gate/usage_min 0.2073 (0.2067) gate/usage_std 0.1533 (0.1518) teacher/entropy 0.0395 (0.0312) teacher/usage_max 0.9857 (0.9532) teacher/usage_min 0.0040 (0.0102) teacher/usage_std 0.4613 (0.4385) nleep/row_max_mean 1529.0164 (1528.2653) nleep/row_max_std 39.8735 (39.8111) nleep/row_min_mean 1503.2806 (1499.9995) lr 4.1221e-04 eta 0:03:39
epoch [37/50] batch [120/132] time 0.171 (0.125) data 0.000 (0.004) loss 0.8339 (0.9791) teacher_loss 0.0399 (0.1543) loss_zs_kd 0.0052 (0.0086) loss_oracle 0.4063 (0.4110) kd_loss 0.5882 (0.6150) acc 100.0000 (94.4531) gate/entropy 0.9991 (1.0008) gate/usage_max 0.5495 (0.5472) gate/usage_min 0.2074 (0.2068) gate/usage_std 0.1535 (0.1521) teacher/entropy 0.0135 (0.0303) teacher/usage_max 0.9967 (0.9531) teacher/usage_min 0.0010 (0.0111) teacher/usage_std 0.4691 (0.4384) nleep/row_max_mean 1532.4517 (1528.9354) nleep/row_max_std 37.4047 (39.8041) nleep/row_min_mean 1505.7273 (1500.6275) lr 4.1221e-04 eta 0:03:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,517
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [38/50] batch [20/132] time 0.137 (0.122) data 0.000 (0.017) loss 1.2135 (0.9710) teacher_loss 0.3250 (0.1478) loss_zs_kd 0.0052 (0.0080) loss_oracle 0.4506 (0.4159) kd_loss 0.6606 (0.6112) acc 84.3750 (93.7500) gate/entropy 0.9990 (0.9989) gate/usage_max 0.5496 (0.5498) gate/usage_min 0.2077 (0.2076) gate/usage_std 0.1536 (0.1537) teacher/entropy 0.0439 (0.0361) teacher/usage_max 0.8792 (0.9460) teacher/usage_min 0.0467 (0.0111) teacher/usage_std 0.3862 (0.4335) nleep/row_max_mean 1511.8165 (1527.4609) nleep/row_max_std 44.5762 (42.6449) nleep/row_min_mean 1486.8719 (1500.0782) lr 3.6258e-04 eta 0:03:27
epoch [38/50] batch [40/132] time 0.161 (0.139) data 0.000 (0.009) loss 0.9669 (0.9984) teacher_loss 0.1841 (0.1698) loss_zs_kd 0.0029 (0.0077) loss_oracle 0.4440 (0.4161) kd_loss 0.5593 (0.6167) acc 93.7500 (93.6719) gate/entropy 0.9990 (0.9987) gate/usage_max 0.5496 (0.5500) gate/usage_min 0.2078 (0.2077) gate/usage_std 0.1536 (0.1539) teacher/entropy 0.0969 (0.0417) teacher/usage_max 0.9405 (0.9343) teacher/usage_min 0.0010 (0.0131) teacher/usage_std 0.4300 (0.4255) nleep/row_max_mean 1518.9402 (1527.5279) nleep/row_max_std 47.6128 (42.5671) nleep/row_min_mean 1490.6611 (1500.5007) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [60/132] time 0.149 (0.143) data 0.000 (0.006) loss 1.0258 (0.9891) teacher_loss 0.1531 (0.1599) loss_zs_kd 0.0111 (0.0075) loss_oracle 0.4276 (0.4152) kd_loss 0.6533 (0.6178) acc 93.7500 (94.2708) gate/entropy 0.9971 (0.9985) gate/usage_max 0.5520 (0.5503) gate/usage_min 0.2080 (0.2077) gate/usage_std 0.1552 (0.1540) teacher/entropy 0.0778 (0.0443) teacher/usage_max 0.8566 (0.9303) teacher/usage_min 0.0210 (0.0124) teacher/usage_std 0.3723 (0.4229) nleep/row_max_mean 1534.2858 (1527.6115) nleep/row_max_std 33.7065 (41.5418) nleep/row_min_mean 1510.6844 (1500.6620) lr 3.6258e-04 eta 0:03:57
epoch [38/50] batch [80/132] time 0.161 (0.144) data 0.000 (0.004) loss 0.9480 (0.9884) teacher_loss 0.0944 (0.1585) loss_zs_kd 0.0067 (0.0074) loss_oracle 0.4492 (0.4148) kd_loss 0.6257 (0.6189) acc 96.8750 (94.4141) gate/entropy 0.9970 (0.9983) gate/usage_max 0.5522 (0.5506) gate/usage_min 0.2081 (0.2078) gate/usage_std 0.1553 (0.1542) teacher/entropy 0.0754 (0.0476) teacher/usage_max 0.8903 (0.9254) teacher/usage_min 0.0005 (0.0143) teacher/usage_std 0.3963 (0.4194) nleep/row_max_mean 1523.5262 (1526.2411) nleep/row_max_std 47.6063 (40.9107) nleep/row_min_mean 1500.1542 (1499.6269) lr 3.6258e-04 eta 0:03:55
epoch [38/50] batch [100/132] time 0.143 (0.145) data 0.000 (0.004) loss 0.9876 (0.9879) teacher_loss 0.0867 (0.1551) loss_zs_kd 0.0013 (0.0076) loss_oracle 0.4373 (0.4145) kd_loss 0.6816 (0.6217) acc 96.8750 (94.5000) gate/entropy 0.9971 (0.9981) gate/usage_max 0.5521 (0.5508) gate/usage_min 0.2082 (0.2079) gate/usage_std 0.1552 (0.1544) teacher/entropy 0.0382 (0.0510) teacher/usage_max 0.8665 (0.9183) teacher/usage_min 0.0309 (0.0162) teacher/usage_std 0.3781 (0.4145) nleep/row_max_mean 1522.5337 (1525.4578) nleep/row_max_std 41.0296 (40.3798) nleep/row_min_mean 1496.4949 (1499.2834) lr 3.6258e-04 eta 0:03:54
epoch [38/50] batch [120/132] time 0.138 (0.146) data 0.000 (0.003) loss 1.0392 (0.9863) teacher_loss 0.1661 (0.1526) loss_zs_kd 0.0095 (0.0078) loss_oracle 0.4224 (0.4138) kd_loss 0.6571 (0.6228) acc 93.7500 (94.6615) gate/entropy 0.9970 (0.9979) gate/usage_max 0.5522 (0.5510) gate/usage_min 0.2083 (0.2080) gate/usage_std 0.1553 (0.1545) teacher/entropy 0.0433 (0.0508) teacher/usage_max 0.8861 (0.9171) teacher/usage_min 0.0315 (0.0158) teacher/usage_std 0.3914 (0.4137) nleep/row_max_mean 1516.7488 (1525.4400) nleep/row_max_std 35.5511 (40.0476) nleep/row_min_mean 1493.4652 (1499.3862) lr 3.6258e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,539
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [39/50] batch [20/132] time 0.093 (0.130) data 0.000 (0.016) loss 0.8739 (0.9342) teacher_loss 0.1033 (0.1268) loss_zs_kd 0.0103 (0.0060) loss_oracle 0.3502 (0.3931) kd_loss 0.5904 (0.6078) acc 96.8750 (95.3125) gate/entropy 0.9962 (0.9965) gate/usage_max 0.5532 (0.5528) gate/usage_min 0.2085 (0.2085) gate/usage_std 0.1559 (0.1557) teacher/entropy 0.0755 (0.0552) teacher/usage_max 0.9202 (0.9249) teacher/usage_min 0.0328 (0.0177) teacher/usage_std 0.4150 (0.4187) nleep/row_max_mean 1531.8206 (1523.1643) nleep/row_max_std 33.1229 (40.0732) nleep/row_min_mean 1505.3516 (1497.7515) lr 3.1545e-04 eta 0:03:23
epoch [39/50] batch [40/132] time 0.199 (0.111) data 0.000 (0.008) loss 1.1000 (0.9676) teacher_loss 0.2155 (0.1444) loss_zs_kd 0.0203 (0.0070) loss_oracle 0.3683 (0.3959) kd_loss 0.6901 (0.6217) acc 87.5000 (94.4531) gate/entropy 0.9962 (0.9963) gate/usage_max 0.5532 (0.5531) gate/usage_min 0.2086 (0.2085) gate/usage_std 0.1559 (0.1559) teacher/entropy 0.0502 (0.0578) teacher/usage_max 0.8409 (0.9069) teacher/usage_min 0.0557 (0.0248) teacher/usage_std 0.3594 (0.4062) nleep/row_max_mean 1506.5105 (1519.8307) nleep/row_max_std 42.3842 (41.9438) nleep/row_min_mean 1485.2688 (1495.1303) lr 3.1545e-04 eta 0:02:52
epoch [39/50] batch [60/132] time 0.080 (0.111) data 0.000 (0.005) loss 1.0172 (0.9843) teacher_loss 0.1472 (0.1541) loss_zs_kd 0.0030 (0.0081) loss_oracle 0.4531 (0.4034) kd_loss 0.6420 (0.6245) acc 93.7500 (94.1667) gate/entropy 0.9957 (0.9961) gate/usage_max 0.5538 (0.5532) gate/usage_min 0.2087 (0.2086) gate/usage_std 0.1563 (0.1560) teacher/entropy 0.0125 (0.0575) teacher/usage_max 0.9347 (0.9042) teacher/usage_min 0.0026 (0.0232) teacher/usage_std 0.4259 (0.4045) nleep/row_max_mean 1530.0725 (1519.4002) nleep/row_max_std 37.3183 (41.1800) nleep/row_min_mean 1504.1246 (1494.7619) lr 3.1545e-04 eta 0:02:48
epoch [39/50] batch [80/132] time 0.168 (0.112) data 0.000 (0.004) loss 0.8046 (0.9885) teacher_loss 0.0217 (0.1539) loss_zs_kd 0.0117 (0.0078) loss_oracle 0.3902 (0.4084) kd_loss 0.5820 (0.6265) acc 100.0000 (94.4141) gate/entropy 0.9957 (0.9960) gate/usage_max 0.5538 (0.5534) gate/usage_min 0.2088 (0.2086) gate/usage_std 0.1563 (0.1561) teacher/entropy 0.0126 (0.0558) teacher/usage_max 0.9964 (0.9035) teacher/usage_min 0.0000 (0.0233) teacher/usage_std 0.4689 (0.4040) nleep/row_max_mean 1516.4873 (1519.1620) nleep/row_max_std 47.0394 (41.6989) nleep/row_min_mean 1489.2148 (1494.4294) lr 3.1545e-04 eta 0:02:49
epoch [39/50] batch [100/132] time 0.179 (0.114) data 0.000 (0.003) loss 1.1365 (0.9899) teacher_loss 0.2845 (0.1542) loss_zs_kd 0.0055 (0.0074) loss_oracle 0.4458 (0.4095) kd_loss 0.6264 (0.6273) acc 96.8750 (94.5625) gate/entropy 0.9951 (0.9959) gate/usage_max 0.5545 (0.5536) gate/usage_min 0.2089 (0.2087) gate/usage_std 0.1568 (0.1562) teacher/entropy 0.0803 (0.0550) teacher/usage_max 0.8721 (0.9033) teacher/usage_min 0.0636 (0.0229) teacher/usage_std 0.3809 (0.4040) nleep/row_max_mean 1529.4747 (1519.5123) nleep/row_max_std 35.1508 (42.1716) nleep/row_min_mean 1500.1758 (1494.6159) lr 3.1545e-04 eta 0:02:49
epoch [39/50] batch [120/132] time 0.071 (0.114) data 0.000 (0.003) loss 0.9464 (0.9818) teacher_loss 0.1122 (0.1487) loss_zs_kd 0.0015 (0.0076) loss_oracle 0.3589 (0.4093) kd_loss 0.6540 (0.6247) acc 96.8750 (94.8177) gate/entropy 0.9946 (0.9957) gate/usage_max 0.5551 (0.5537) gate/usage_min 0.2090 (0.2087) gate/usage_std 0.1572 (0.1563) teacher/entropy 0.0596 (0.0545) teacher/usage_max 0.8663 (0.9061) teacher/usage_min 0.0498 (0.0232) teacher/usage_std 0.3771 (0.4059) nleep/row_max_mean 1526.0549 (1520.4391) nleep/row_max_std 42.2459 (42.0908) nleep/row_min_mean 1502.1860 (1495.3249) lr 3.1545e-04 eta 0:02:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,529
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [40/50] batch [20/132] time 0.135 (0.160) data 0.000 (0.017) loss 0.9575 (0.9820) teacher_loss 0.1058 (0.1494) loss_zs_kd 0.0110 (0.0087) loss_oracle 0.4316 (0.4187) kd_loss 0.6304 (0.6190) acc 100.0000 (95.0000) gate/entropy 0.9949 (0.9946) gate/usage_max 0.5547 (0.5551) gate/usage_min 0.2091 (0.2091) gate/usage_std 0.1569 (0.1572) teacher/entropy 0.0336 (0.0500) teacher/usage_max 0.9194 (0.9144) teacher/usage_min 0.0312 (0.0241) teacher/usage_std 0.4145 (0.4115) nleep/row_max_mean 1515.4432 (1521.1055) nleep/row_max_std 46.9249 (44.0981) nleep/row_min_mean 1485.1776 (1494.7886) lr 2.7103e-04 eta 0:03:49
epoch [40/50] batch [40/132] time 0.155 (0.153) data 0.000 (0.009) loss 0.9535 (0.9763) teacher_loss 0.0849 (0.1393) loss_zs_kd 0.0168 (0.0084) loss_oracle 0.4278 (0.4250) kd_loss 0.6463 (0.6203) acc 96.8750 (95.0781) gate/entropy 0.9947 (0.9945) gate/usage_max 0.5550 (0.5552) gate/usage_min 0.2092 (0.2091) gate/usage_std 0.1571 (0.1573) teacher/entropy 0.0419 (0.0476) teacher/usage_max 0.8860 (0.9152) teacher/usage_min 0.0098 (0.0239) teacher/usage_std 0.3927 (0.4119) nleep/row_max_mean 1508.7006 (1521.3973) nleep/row_max_std 46.0048 (44.5163) nleep/row_min_mean 1481.8073 (1494.7562) lr 2.7103e-04 eta 0:03:36
epoch [40/50] batch [60/132] time 0.125 (0.151) data 0.000 (0.006) loss 1.0256 (0.9677) teacher_loss 0.1819 (0.1356) loss_zs_kd 0.0032 (0.0090) loss_oracle 0.4419 (0.4231) kd_loss 0.6212 (0.6160) acc 90.6250 (95.2083) gate/entropy 0.9942 (0.9944) gate/usage_max 0.5556 (0.5553) gate/usage_min 0.2093 (0.2092) gate/usage_std 0.1575 (0.1574) teacher/entropy 0.0295 (0.0480) teacher/usage_max 0.9314 (0.9192) teacher/usage_min 0.0321 (0.0209) teacher/usage_std 0.4229 (0.4148) nleep/row_max_mean 1516.7076 (1522.5813) nleep/row_max_std 41.4594 (44.3310) nleep/row_min_mean 1486.6545 (1495.3781) lr 2.7103e-04 eta 0:03:29
epoch [40/50] batch [80/132] time 0.127 (0.149) data 0.000 (0.004) loss 0.8963 (0.9716) teacher_loss 0.0902 (0.1393) loss_zs_kd 0.0087 (0.0090) loss_oracle 0.4451 (0.4237) kd_loss 0.5792 (0.6159) acc 96.8750 (95.0000) gate/entropy 0.9939 (0.9943) gate/usage_max 0.5560 (0.5555) gate/usage_min 0.2093 (0.2092) gate/usage_std 0.1578 (0.1574) teacher/entropy 0.1004 (0.0463) teacher/usage_max 0.9042 (0.9208) teacher/usage_min 0.0088 (0.0193) teacher/usage_std 0.4049 (0.4160) nleep/row_max_mean 1529.2235 (1523.6586) nleep/row_max_std 40.1258 (43.9648) nleep/row_min_mean 1502.4480 (1496.2131) lr 2.7103e-04 eta 0:03:24
epoch [40/50] batch [100/132] time 0.133 (0.147) data 0.000 (0.004) loss 0.9361 (0.9713) teacher_loss 0.1560 (0.1407) loss_zs_kd 0.0079 (0.0085) loss_oracle 0.3692 (0.4222) kd_loss 0.5915 (0.6152) acc 90.6250 (94.8750) gate/entropy 0.9937 (0.9942) gate/usage_max 0.5562 (0.5556) gate/usage_min 0.2094 (0.2092) gate/usage_std 0.1579 (0.1575) teacher/entropy 0.0377 (0.0447) teacher/usage_max 0.9563 (0.9230) teacher/usage_min 0.0000 (0.0181) teacher/usage_std 0.4409 (0.4176) nleep/row_max_mean 1511.4714 (1524.1748) nleep/row_max_std 47.7223 (43.1294) nleep/row_min_mean 1485.3286 (1496.5958) lr 2.7103e-04 eta 0:03:19
epoch [40/50] batch [120/132] time 0.078 (0.139) data 0.000 (0.003) loss 0.9442 (0.9672) teacher_loss 0.0390 (0.1379) loss_zs_kd 0.0097 (0.0081) loss_oracle 0.4302 (0.4209) kd_loss 0.6853 (0.6148) acc 100.0000 (95.1302) gate/entropy 0.9937 (0.9941) gate/usage_max 0.5562 (0.5557) gate/usage_min 0.2095 (0.2093) gate/usage_std 0.1579 (0.1576) teacher/entropy 0.0207 (0.0445) teacher/usage_max 0.8780 (0.9234) teacher/usage_min 0.0009 (0.0186) teacher/usage_std 0.3883 (0.4178) nleep/row_max_mean 1513.1107 (1523.9128) nleep/row_max_std 35.5131 (42.5755) nleep/row_min_mean 1486.8071 (1496.4130) lr 2.7103e-04 eta 0:03:05
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,509
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.8%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [41/50] batch [20/132] time 0.082 (0.125) data 0.000 (0.016) loss 0.9742 (1.0318) teacher_loss 0.1683 (0.1844) loss_zs_kd 0.0153 (0.0094) loss_oracle 0.4043 (0.4252) kd_loss 0.5961 (0.6300) acc 90.6250 (93.2812) gate/entropy 0.9930 (0.9933) gate/usage_max 0.5570 (0.5567) gate/usage_min 0.2095 (0.2095) gate/usage_std 0.1585 (0.1583) teacher/entropy 0.0455 (0.0417) teacher/usage_max 0.9387 (0.9088) teacher/usage_min 0.0300 (0.0191) teacher/usage_std 0.4281 (0.4080) nleep/row_max_mean 1533.9547 (1525.1770) nleep/row_max_std 33.1722 (39.5169) nleep/row_min_mean 1505.7432 (1497.7862) lr 2.2949e-04 eta 0:02:43
epoch [41/50] batch [40/132] time 0.107 (0.122) data 0.000 (0.008) loss 1.1106 (0.9973) teacher_loss 0.3477 (0.1682) loss_zs_kd 0.0117 (0.0081) loss_oracle 0.3977 (0.4175) kd_loss 0.5582 (0.6163) acc 81.2500 (93.9062) gate/entropy 0.9927 (0.9932) gate/usage_max 0.5574 (0.5568) gate/usage_min 0.2096 (0.2096) gate/usage_std 0.1587 (0.1583) teacher/entropy 0.0529 (0.0429) teacher/usage_max 0.9700 (0.9217) teacher/usage_min 0.0043 (0.0162) teacher/usage_std 0.4503 (0.4168) nleep/row_max_mean 1519.4955 (1526.5162) nleep/row_max_std 36.8641 (39.4767) nleep/row_min_mean 1494.0833 (1498.9936) lr 2.2949e-04 eta 0:02:35
epoch [41/50] batch [60/132] time 0.116 (0.123) data 0.000 (0.005) loss 1.1241 (0.9836) teacher_loss 0.3155 (0.1629) loss_zs_kd 0.0056 (0.0082) loss_oracle 0.4055 (0.4115) kd_loss 0.6030 (0.6108) acc 90.6250 (94.1146) gate/entropy 0.9934 (0.9931) gate/usage_max 0.5566 (0.5569) gate/usage_min 0.2096 (0.2096) gate/usage_std 0.1581 (0.1584) teacher/entropy 0.0223 (0.0442) teacher/usage_max 0.9598 (0.9257) teacher/usage_min 0.0001 (0.0169) teacher/usage_std 0.4433 (0.4195) nleep/row_max_mean 1499.9243 (1526.2718) nleep/row_max_std 36.6876 (38.9308) nleep/row_min_mean 1474.5457 (1498.8343) lr 2.2949e-04 eta 0:02:35
epoch [41/50] batch [80/132] time 0.195 (0.124) data 0.000 (0.004) loss 0.9088 (0.9794) teacher_loss 0.0506 (0.1560) loss_zs_kd 0.0020 (0.0082) loss_oracle 0.4145 (0.4160) kd_loss 0.6500 (0.6114) acc 100.0000 (94.6094) gate/entropy 0.9930 (0.9930) gate/usage_max 0.5571 (0.5570) gate/usage_min 0.2097 (0.2096) gate/usage_std 0.1585 (0.1585) teacher/entropy 0.0328 (0.0436) teacher/usage_max 0.8935 (0.9256) teacher/usage_min 0.0444 (0.0177) teacher/usage_std 0.3961 (0.4193) nleep/row_max_mean 1522.7537 (1526.3635) nleep/row_max_std 33.8387 (38.6584) nleep/row_min_mean 1493.9209 (1498.9652) lr 2.2949e-04 eta 0:02:33
epoch [41/50] batch [100/132] time 0.078 (0.123) data 0.000 (0.003) loss 0.9736 (0.9809) teacher_loss 0.1542 (0.1587) loss_zs_kd 0.0060 (0.0082) loss_oracle 0.4291 (0.4150) kd_loss 0.6018 (0.6106) acc 96.8750 (94.5625) gate/entropy 0.9927 (0.9929) gate/usage_max 0.5574 (0.5571) gate/usage_min 0.2098 (0.2096) gate/usage_std 0.1587 (0.1585) teacher/entropy 0.0081 (0.0429) teacher/usage_max 0.9709 (0.9269) teacher/usage_min 0.0000 (0.0180) teacher/usage_std 0.4510 (0.4202) nleep/row_max_mean 1530.0090 (1526.6656) nleep/row_max_std 38.6049 (38.2205) nleep/row_min_mean 1499.5922 (1499.1360) lr 2.2949e-04 eta 0:02:29
epoch [41/50] batch [120/132] time 0.092 (0.119) data 0.000 (0.003) loss 0.9014 (0.9758) teacher_loss 0.0603 (0.1526) loss_zs_kd 0.0162 (0.0083) loss_oracle 0.4376 (0.4153) kd_loss 0.6142 (0.6114) acc 96.8750 (94.8177) gate/entropy 0.9925 (0.9929) gate/usage_max 0.5577 (0.5572) gate/usage_min 0.2098 (0.2097) gate/usage_std 0.1589 (0.1586) teacher/entropy 0.0681 (0.0427) teacher/usage_max 0.8989 (0.9262) teacher/usage_min 0.0068 (0.0177) teacher/usage_std 0.4015 (0.4198) nleep/row_max_mean 1531.9912 (1526.6098) nleep/row_max_std 39.7045 (38.5431) nleep/row_min_mean 1506.3882 (1499.2034) lr 2.2949e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,510
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.8%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [42/50] batch [20/132] time 0.165 (0.175) data 0.000 (0.015) loss 0.9319 (0.9857) teacher_loss 0.0746 (0.1674) loss_zs_kd 0.0175 (0.0074) loss_oracle 0.4380 (0.4172) kd_loss 0.6296 (0.6060) acc 96.8750 (95.0000) gate/entropy 0.9920 (0.9921) gate/usage_max 0.5583 (0.5581) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1593 (0.1592) teacher/entropy 0.0634 (0.0540) teacher/usage_max 0.8856 (0.9183) teacher/usage_min 0.0199 (0.0167) teacher/usage_std 0.3917 (0.4143) nleep/row_max_mean 1528.1709 (1529.4597) nleep/row_max_std 43.9212 (41.2623) nleep/row_min_mean 1503.8270 (1502.2454) lr 1.9098e-04 eta 0:03:24
epoch [42/50] batch [40/132] time 0.153 (0.169) data 0.000 (0.008) loss 0.8088 (0.9698) teacher_loss 0.0615 (0.1515) loss_zs_kd 0.0057 (0.0074) loss_oracle 0.3333 (0.4140) kd_loss 0.5778 (0.6076) acc 96.8750 (95.3125) gate/entropy 0.9921 (0.9921) gate/usage_max 0.5581 (0.5581) gate/usage_min 0.2099 (0.2099) gate/usage_std 0.1592 (0.1592) teacher/entropy 0.0505 (0.0480) teacher/usage_max 0.9489 (0.9230) teacher/usage_min 0.0030 (0.0161) teacher/usage_std 0.4357 (0.4176) nleep/row_max_mean 1529.5898 (1529.1293) nleep/row_max_std 52.0338 (40.6806) nleep/row_min_mean 1500.5159 (1501.7810) lr 1.9098e-04 eta 0:03:14
epoch [42/50] batch [60/132] time 0.079 (0.163) data 0.000 (0.005) loss 1.0146 (0.9776) teacher_loss 0.1524 (0.1515) loss_zs_kd 0.0049 (0.0087) loss_oracle 0.4122 (0.4110) kd_loss 0.6536 (0.6163) acc 93.7500 (94.9479) gate/entropy 0.9918 (0.9921) gate/usage_max 0.5584 (0.5581) gate/usage_min 0.2099 (0.2099) gate/usage_std 0.1594 (0.1592) teacher/entropy 0.0382 (0.0490) teacher/usage_max 0.8851 (0.9124) teacher/usage_min 0.0327 (0.0213) teacher/usage_std 0.3907 (0.4101) nleep/row_max_mean 1535.2144 (1527.0264) nleep/row_max_std 39.6772 (41.6004) nleep/row_min_mean 1505.1860 (1500.0479) lr 1.9098e-04 eta 0:03:03
epoch [42/50] batch [80/132] time 0.080 (0.149) data 0.000 (0.004) loss 0.8966 (0.9667) teacher_loss 0.1169 (0.1417) loss_zs_kd 0.0117 (0.0087) loss_oracle 0.3946 (0.4113) kd_loss 0.5765 (0.6150) acc 93.7500 (95.1562) gate/entropy 0.9917 (0.9921) gate/usage_max 0.5586 (0.5582) gate/usage_min 0.2100 (0.2099) gate/usage_std 0.1595 (0.1592) teacher/entropy 0.0529 (0.0515) teacher/usage_max 0.9517 (0.9111) teacher/usage_min 0.0029 (0.0227) teacher/usage_std 0.4376 (0.4091) nleep/row_max_mean 1515.2943 (1526.6297) nleep/row_max_std 40.0862 (41.4536) nleep/row_min_mean 1489.3098 (1499.9006) lr 1.9098e-04 eta 0:02:45
epoch [42/50] batch [100/132] time 0.135 (0.144) data 0.000 (0.003) loss 0.9280 (0.9676) teacher_loss 0.1186 (0.1432) loss_zs_kd 0.0052 (0.0088) loss_oracle 0.4069 (0.4097) kd_loss 0.6034 (0.6151) acc 96.8750 (95.0938) gate/entropy 0.9914 (0.9920) gate/usage_max 0.5590 (0.5583) gate/usage_min 0.2100 (0.2099) gate/usage_std 0.1598 (0.1593) teacher/entropy 0.0530 (0.0537) teacher/usage_max 0.9170 (0.9085) teacher/usage_min 0.0218 (0.0237) teacher/usage_std 0.4130 (0.4074) nleep/row_max_mean 1525.8818 (1526.2180) nleep/row_max_std 36.9293 (40.8247) nleep/row_min_mean 1500.5146 (1499.7229) lr 1.9098e-04 eta 0:02:36
epoch [42/50] batch [120/132] time 0.073 (0.139) data 0.000 (0.003) loss 0.9781 (0.9687) teacher_loss 0.1128 (0.1420) loss_zs_kd 0.0124 (0.0090) loss_oracle 0.3926 (0.4098) kd_loss 0.6629 (0.6174) acc 96.8750 (95.2083) gate/entropy 0.9913 (0.9920) gate/usage_max 0.5591 (0.5583) gate/usage_min 0.2100 (0.2099) gate/usage_std 0.1599 (0.1593) teacher/entropy 0.0526 (0.0553) teacher/usage_max 0.8584 (0.9044) teacher/usage_min 0.0503 (0.0248) teacher/usage_std 0.3717 (0.4045) nleep/row_max_mean 1528.4150 (1525.0125) nleep/row_max_std 44.9949 (41.0274) nleep/row_min_mean 1502.6300 (1498.6971) lr 1.9098e-04 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,519
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [43/50] batch [20/132] time 0.133 (0.143) data 0.000 (0.016) loss 1.0058 (1.0042) teacher_loss 0.1127 (0.1751) loss_zs_kd 0.0048 (0.0111) loss_oracle 0.4143 (0.4061) kd_loss 0.6835 (0.6205) acc 96.8750 (93.5938) gate/entropy 0.9919 (0.9915) gate/usage_max 0.5584 (0.5588) gate/usage_min 0.2101 (0.2101) gate/usage_std 0.1594 (0.1597) teacher/entropy 0.0607 (0.0592) teacher/usage_max 0.8223 (0.8956) teacher/usage_min 0.0403 (0.0320) teacher/usage_std 0.3480 (0.3982) nleep/row_max_mean 1524.3531 (1523.6573) nleep/row_max_std 40.7230 (40.2454) nleep/row_min_mean 1500.5811 (1498.1970) lr 1.5567e-04 eta 0:02:28
epoch [43/50] batch [40/132] time 0.193 (0.134) data 0.000 (0.008) loss 0.9235 (0.9817) teacher_loss 0.0966 (0.1523) loss_zs_kd 0.0303 (0.0093) loss_oracle 0.4320 (0.4022) kd_loss 0.5958 (0.6237) acc 96.8750 (94.8438) gate/entropy 0.9913 (0.9915) gate/usage_max 0.5591 (0.5588) gate/usage_min 0.2101 (0.2101) gate/usage_std 0.1599 (0.1597) teacher/entropy 0.0215 (0.0617) teacher/usage_max 0.9630 (0.8896) teacher/usage_min 0.0042 (0.0345) teacher/usage_std 0.4454 (0.3940) nleep/row_max_mean 1513.6106 (1523.2829) nleep/row_max_std 37.8111 (40.1746) nleep/row_min_mean 1486.7219 (1498.2357) lr 1.5567e-04 eta 0:02:15
epoch [43/50] batch [60/132] time 0.096 (0.127) data 0.001 (0.005) loss 1.1087 (0.9836) teacher_loss 0.3355 (0.1537) loss_zs_kd 0.0104 (0.0094) loss_oracle 0.4081 (0.4044) kd_loss 0.5639 (0.6230) acc 90.6250 (94.6875) gate/entropy 0.9913 (0.9914) gate/usage_max 0.5590 (0.5589) gate/usage_min 0.2101 (0.2101) gate/usage_std 0.1598 (0.1597) teacher/entropy 0.0600 (0.0631) teacher/usage_max 0.9550 (0.8888) teacher/usage_min 0.0177 (0.0362) teacher/usage_std 0.4396 (0.3933) nleep/row_max_mean 1519.2909 (1523.5280) nleep/row_max_std 35.6515 (38.7387) nleep/row_min_mean 1491.0555 (1498.3612) lr 1.5567e-04 eta 0:02:06
epoch [43/50] batch [80/132] time 0.168 (0.132) data 0.000 (0.004) loss 0.9345 (0.9823) teacher_loss 0.0575 (0.1490) loss_zs_kd 0.0010 (0.0096) loss_oracle 0.4124 (0.4037) kd_loss 0.6703 (0.6266) acc 96.8750 (94.7266) gate/entropy 0.9911 (0.9914) gate/usage_max 0.5593 (0.5590) gate/usage_min 0.2102 (0.2101) gate/usage_std 0.1600 (0.1598) teacher/entropy 0.0364 (0.0603) teacher/usage_max 0.8687 (0.8880) teacher/usage_min 0.0342 (0.0357) teacher/usage_std 0.3794 (0.3928) nleep/row_max_mean 1535.7664 (1523.9047) nleep/row_max_std 32.4729 (38.0629) nleep/row_min_mean 1510.8024 (1498.7034) lr 1.5567e-04 eta 0:02:08
epoch [43/50] batch [100/132] time 0.149 (0.137) data 0.000 (0.003) loss 0.9101 (0.9831) teacher_loss 0.1188 (0.1477) loss_zs_kd 0.0069 (0.0098) loss_oracle 0.3610 (0.4028) kd_loss 0.6074 (0.6290) acc 100.0000 (94.9062) gate/entropy 0.9913 (0.9913) gate/usage_max 0.5591 (0.5590) gate/usage_min 0.2102 (0.2101) gate/usage_std 0.1599 (0.1598) teacher/entropy 0.0931 (0.0623) teacher/usage_max 0.8725 (0.8833) teacher/usage_min 0.0633 (0.0367) teacher/usage_std 0.3813 (0.3895) nleep/row_max_mean 1524.3821 (1523.8185) nleep/row_max_std 25.8204 (38.2491) nleep/row_min_mean 1503.1619 (1498.7976) lr 1.5567e-04 eta 0:02:10
epoch [43/50] batch [120/132] time 0.145 (0.140) data 0.000 (0.003) loss 0.9255 (0.9843) teacher_loss 0.0545 (0.1456) loss_zs_kd 0.0081 (0.0097) loss_oracle 0.4100 (0.4058) kd_loss 0.6620 (0.6309) acc 96.8750 (94.7917) gate/entropy 0.9908 (0.9913) gate/usage_max 0.5597 (0.5590) gate/usage_min 0.2102 (0.2101) gate/usage_std 0.1603 (0.1598) teacher/entropy 0.0748 (0.0620) teacher/usage_max 0.8308 (0.8815) teacher/usage_min 0.0691 (0.0379) teacher/usage_std 0.3520 (0.3882) nleep/row_max_mean 1523.4100 (1523.9976) nleep/row_max_std 45.3210 (38.2256) nleep/row_min_mean 1502.6707 (1498.8703) lr 1.5567e-04 eta 0:02:10
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,528
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [44/50] batch [20/132] time 0.083 (0.110) data 0.000 (0.014) loss 0.9931 (0.9582) teacher_loss 0.1455 (0.1212) loss_zs_kd 0.0117 (0.0103) loss_oracle 0.3750 (0.4127) kd_loss 0.6542 (0.6255) acc 96.8750 (95.1562) gate/entropy 0.9908 (0.9910) gate/usage_max 0.5596 (0.5594) gate/usage_min 0.2102 (0.2102) gate/usage_std 0.1602 (0.1600) teacher/entropy 0.1219 (0.0631) teacher/usage_max 0.7878 (0.8845) teacher/usage_min 0.0703 (0.0338) teacher/usage_std 0.3226 (0.3905) nleep/row_max_mean 1527.5698 (1522.7489) nleep/row_max_std 34.0500 (40.2469) nleep/row_min_mean 1503.9408 (1497.1995) lr 1.2369e-04 eta 0:01:39
epoch [44/50] batch [40/132] time 0.093 (0.114) data 0.000 (0.007) loss 0.8497 (0.9656) teacher_loss 0.0213 (0.1280) loss_zs_kd 0.0071 (0.0091) loss_oracle 0.4004 (0.4087) kd_loss 0.6247 (0.6288) acc 100.0000 (95.3125) gate/entropy 0.9909 (0.9910) gate/usage_max 0.5595 (0.5594) gate/usage_min 0.2103 (0.2102) gate/usage_std 0.1602 (0.1601) teacher/entropy 0.0573 (0.0629) teacher/usage_max 0.8941 (0.8813) teacher/usage_min 0.0290 (0.0363) teacher/usage_std 0.3970 (0.3882) nleep/row_max_mean 1527.3070 (1524.7259) nleep/row_max_std 42.8825 (39.8193) nleep/row_min_mean 1500.4211 (1499.2728) lr 1.2369e-04 eta 0:01:40
epoch [44/50] batch [60/132] time 0.083 (0.121) data 0.000 (0.005) loss 0.9900 (0.9810) teacher_loss 0.1222 (0.1416) loss_zs_kd 0.0135 (0.0098) loss_oracle 0.4283 (0.4054) kd_loss 0.6468 (0.6319) acc 96.8750 (94.9479) gate/entropy 0.9909 (0.9909) gate/usage_max 0.5595 (0.5595) gate/usage_min 0.2103 (0.2102) gate/usage_std 0.1602 (0.1601) teacher/entropy 0.0551 (0.0626) teacher/usage_max 0.8735 (0.8785) teacher/usage_min 0.0305 (0.0397) teacher/usage_std 0.3829 (0.3861) nleep/row_max_mean 1525.9126 (1526.5146) nleep/row_max_std 50.6907 (40.5831) nleep/row_min_mean 1499.8685 (1501.0658) lr 1.2369e-04 eta 0:01:44
epoch [44/50] batch [80/132] time 0.100 (0.116) data 0.000 (0.004) loss 1.0272 (0.9801) teacher_loss 0.0829 (0.1409) loss_zs_kd 0.0097 (0.0095) loss_oracle 0.4829 (0.4066) kd_loss 0.6981 (0.6311) acc 96.8750 (95.1562) gate/entropy 0.9905 (0.9909) gate/usage_max 0.5600 (0.5595) gate/usage_min 0.2103 (0.2102) gate/usage_std 0.1605 (0.1602) teacher/entropy 0.0338 (0.0604) teacher/usage_max 0.8395 (0.8817) teacher/usage_min 0.0632 (0.0377) teacher/usage_std 0.3582 (0.3884) nleep/row_max_mean 1542.7637 (1527.1035) nleep/row_max_std 45.0983 (41.2312) nleep/row_min_mean 1516.5356 (1501.6749) lr 1.2369e-04 eta 0:01:37
epoch [44/50] batch [100/132] time 0.181 (0.118) data 0.000 (0.003) loss 0.8610 (0.9751) teacher_loss 0.0966 (0.1370) loss_zs_kd 0.0108 (0.0097) loss_oracle 0.4050 (0.4068) kd_loss 0.5565 (0.6298) acc 96.8750 (95.2812) gate/entropy 0.9905 (0.9908) gate/usage_max 0.5600 (0.5596) gate/usage_min 0.2103 (0.2103) gate/usage_std 0.1604 (0.1602) teacher/entropy 0.0607 (0.0575) teacher/usage_max 0.9602 (0.8862) teacher/usage_min 0.0189 (0.0366) teacher/usage_std 0.4432 (0.3915) nleep/row_max_mean 1541.0227 (1527.6723) nleep/row_max_std 39.2291 (42.1368) nleep/row_min_mean 1512.7605 (1502.1017) lr 1.2369e-04 eta 0:01:37
epoch [44/50] batch [120/132] time 0.163 (0.119) data 0.000 (0.003) loss 1.0352 (0.9752) teacher_loss 0.2674 (0.1366) loss_zs_kd 0.0103 (0.0098) loss_oracle 0.3719 (0.4040) kd_loss 0.5768 (0.6317) acc 90.6250 (95.3385) gate/entropy 0.9906 (0.9908) gate/usage_max 0.5599 (0.5596) gate/usage_min 0.2103 (0.2103) gate/usage_std 0.1604 (0.1602) teacher/entropy 0.0530 (0.0581) teacher/usage_max 0.9461 (0.8835) teacher/usage_min 0.0219 (0.0381) teacher/usage_std 0.4333 (0.3896) nleep/row_max_mean 1518.0210 (1527.6999) nleep/row_max_std 49.7785 (43.0318) nleep/row_min_mean 1493.3823 (1502.2359) lr 1.2369e-04 eta 0:01:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,527
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [45/50] batch [20/132] time 0.136 (0.160) data 0.000 (0.017) loss 0.9456 (0.9812) teacher_loss 0.1803 (0.1352) loss_zs_kd 0.0173 (0.0100) loss_oracle 0.3734 (0.4109) kd_loss 0.5699 (0.6356) acc 93.7500 (96.0938) gate/entropy 0.9904 (0.9906) gate/usage_max 0.5601 (0.5599) gate/usage_min 0.2103 (0.2103) gate/usage_std 0.1605 (0.1604) teacher/entropy 0.1535 (0.0564) teacher/usage_max 0.8475 (0.8798) teacher/usage_min 0.0600 (0.0397) teacher/usage_std 0.3638 (0.3869) nleep/row_max_mean 1525.6567 (1528.2122) nleep/row_max_std 46.1243 (43.0009) nleep/row_min_mean 1503.0991 (1502.2009) lr 9.5173e-05 eta 0:02:03
epoch [45/50] batch [40/132] time 0.145 (0.147) data 0.000 (0.009) loss 0.9514 (0.9697) teacher_loss 0.1109 (0.1189) loss_zs_kd 0.0188 (0.0099) loss_oracle 0.4379 (0.4117) kd_loss 0.6121 (0.6399) acc 96.8750 (96.3281) gate/entropy 0.9905 (0.9906) gate/usage_max 0.5600 (0.5599) gate/usage_min 0.2104 (0.2103) gate/usage_std 0.1605 (0.1604) teacher/entropy 0.0650 (0.0590) teacher/usage_max 0.8976 (0.8730) teacher/usage_min 0.0357 (0.0433) teacher/usage_std 0.3992 (0.3822) nleep/row_max_mean 1518.7812 (1528.0900) nleep/row_max_std 45.4262 (42.9306) nleep/row_min_mean 1494.2954 (1502.4033) lr 9.5173e-05 eta 0:01:50
epoch [45/50] batch [60/132] time 0.119 (0.144) data 0.000 (0.006) loss 0.9081 (0.9716) teacher_loss 0.0016 (0.1275) loss_zs_kd 0.0000 (0.0102) loss_oracle 0.4221 (0.4080) kd_loss 0.6955 (0.6350) acc 100.0000 (96.1458) gate/entropy 0.9906 (0.9905) gate/usage_max 0.5598 (0.5599) gate/usage_min 0.2104 (0.2103) gate/usage_std 0.1604 (0.1604) teacher/entropy 0.0018 (0.0560) teacher/usage_max 0.8752 (0.8816) teacher/usage_min 0.0623 (0.0406) teacher/usage_std 0.3832 (0.3882) nleep/row_max_mean 1548.0220 (1529.1283) nleep/row_max_std 37.2991 (42.9855) nleep/row_min_mean 1518.7854 (1503.3128) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [80/132] time 0.154 (0.144) data 0.000 (0.004) loss 0.7945 (0.9752) teacher_loss 0.0131 (0.1342) loss_zs_kd 0.0012 (0.0104) loss_oracle 0.3574 (0.4046) kd_loss 0.6021 (0.6334) acc 100.0000 (95.6250) gate/entropy 0.9905 (0.9905) gate/usage_max 0.5600 (0.5600) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1605 (0.1604) teacher/entropy 0.0381 (0.0542) teacher/usage_max 0.9334 (0.8849) teacher/usage_min 0.0063 (0.0368) teacher/usage_std 0.4249 (0.3906) nleep/row_max_mean 1534.2224 (1528.7356) nleep/row_max_std 45.5192 (43.3795) nleep/row_min_mean 1510.1011 (1502.9569) lr 9.5173e-05 eta 0:01:42
epoch [45/50] batch [100/132] time 0.151 (0.144) data 0.000 (0.004) loss 0.8184 (0.9745) teacher_loss 0.0413 (0.1351) loss_zs_kd 0.0030 (0.0108) loss_oracle 0.4221 (0.4054) kd_loss 0.5646 (0.6313) acc 100.0000 (95.4375) gate/entropy 0.9906 (0.9905) gate/usage_max 0.5599 (0.5600) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1604 (0.1605) teacher/entropy 0.0757 (0.0551) teacher/usage_max 0.9360 (0.8862) teacher/usage_min 0.0280 (0.0351) teacher/usage_std 0.4262 (0.3916) nleep/row_max_mean 1506.9677 (1527.7986) nleep/row_max_std 54.0285 (43.7281) nleep/row_min_mean 1482.4526 (1502.1969) lr 9.5173e-05 eta 0:01:39
epoch [45/50] batch [120/132] time 0.157 (0.146) data 0.000 (0.003) loss 0.8785 (0.9788) teacher_loss 0.1101 (0.1392) loss_zs_kd 0.0104 (0.0108) loss_oracle 0.3743 (0.4053) kd_loss 0.5760 (0.6315) acc 96.8750 (95.3385) gate/entropy 0.9903 (0.9905) gate/usage_max 0.5603 (0.5600) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1606 (0.1605) teacher/entropy 0.0319 (0.0552) teacher/usage_max 0.9708 (0.8856) teacher/usage_min 0.0000 (0.0355) teacher/usage_std 0.4509 (0.3912) nleep/row_max_mean 1525.3762 (1527.4150) nleep/row_max_std 51.0033 (43.9242) nleep/row_min_mean 1498.9446 (1501.8525) lr 9.5173e-05 eta 0:01:38
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,528
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [46/50] batch [20/132] time 0.090 (0.121) data 0.000 (0.016) loss 0.9560 (0.9672) teacher_loss 0.0836 (0.1254) loss_zs_kd 0.0054 (0.0091) loss_oracle 0.4286 (0.4069) kd_loss 0.6554 (0.6338) acc 93.7500 (96.0938) gate/entropy 0.9901 (0.9903) gate/usage_max 0.5604 (0.5602) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1608 (0.1606) teacher/entropy 0.0610 (0.0422) teacher/usage_max 0.8540 (0.8970) teacher/usage_min 0.0662 (0.0344) teacher/usage_std 0.3682 (0.3990) nleep/row_max_mean 1532.7366 (1529.0971) nleep/row_max_std 40.9772 (43.9637) nleep/row_min_mean 1507.8558 (1503.7092) lr 7.0224e-05 eta 0:01:17
epoch [46/50] batch [40/132] time 0.235 (0.126) data 0.000 (0.008) loss 1.1325 (0.9722) teacher_loss 0.2487 (0.1307) loss_zs_kd 0.0184 (0.0087) loss_oracle 0.3858 (0.4080) kd_loss 0.6817 (0.6332) acc 93.7500 (95.9375) gate/entropy 0.9899 (0.9903) gate/usage_max 0.5607 (0.5603) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1610 (0.1606) teacher/entropy 0.0464 (0.0498) teacher/usage_max 0.8367 (0.8893) teacher/usage_min 0.0374 (0.0346) teacher/usage_std 0.3578 (0.3937) nleep/row_max_mean 1525.5664 (1530.1681) nleep/row_max_std 37.1380 (43.0263) nleep/row_min_mean 1503.6858 (1504.4777) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [60/132] time 0.098 (0.123) data 0.000 (0.006) loss 0.8534 (0.9758) teacher_loss 0.0473 (0.1354) loss_zs_kd 0.0032 (0.0090) loss_oracle 0.4018 (0.4089) kd_loss 0.6036 (0.6315) acc 100.0000 (95.7292) gate/entropy 0.9902 (0.9903) gate/usage_max 0.5603 (0.5603) gate/usage_min 0.2105 (0.2104) gate/usage_std 0.1607 (0.1606) teacher/entropy 0.0574 (0.0490) teacher/usage_max 0.9117 (0.8921) teacher/usage_min 0.0318 (0.0325) teacher/usage_std 0.4091 (0.3957) nleep/row_max_mean 1508.4814 (1527.6215) nleep/row_max_std 51.2418 (42.3570) nleep/row_min_mean 1484.6509 (1502.0479) lr 7.0224e-05 eta 0:01:14
epoch [46/50] batch [80/132] time 0.085 (0.120) data 0.000 (0.004) loss 1.0134 (0.9727) teacher_loss 0.1893 (0.1356) loss_zs_kd 0.0020 (0.0088) loss_oracle 0.3897 (0.4101) kd_loss 0.6282 (0.6276) acc 96.8750 (95.7812) gate/entropy 0.9904 (0.9902) gate/usage_max 0.5601 (0.5603) gate/usage_min 0.2104 (0.2104) gate/usage_std 0.1605 (0.1607) teacher/entropy 0.0488 (0.0527) teacher/usage_max 0.8941 (0.8920) teacher/usage_min 0.0334 (0.0316) teacher/usage_std 0.3969 (0.3957) nleep/row_max_mean 1526.2402 (1527.5995) nleep/row_max_std 42.4559 (41.7062) nleep/row_min_mean 1499.1404 (1502.1621) lr 7.0224e-05 eta 0:01:09
epoch [46/50] batch [100/132] time 0.085 (0.120) data 0.000 (0.003) loss 0.9890 (0.9632) teacher_loss 0.0962 (0.1289) loss_zs_kd 0.0062 (0.0085) loss_oracle 0.4268 (0.4075) kd_loss 0.6763 (0.6262) acc 93.7500 (95.9062) gate/entropy 0.9900 (0.9902) gate/usage_max 0.5606 (0.5603) gate/usage_min 0.2105 (0.2104) gate/usage_std 0.1609 (0.1607) teacher/entropy 0.0401 (0.0539) teacher/usage_max 0.8489 (0.8922) teacher/usage_min 0.0348 (0.0309) teacher/usage_std 0.3661 (0.3959) nleep/row_max_mean 1530.2854 (1527.6611) nleep/row_max_std 39.5514 (41.3265) nleep/row_min_mean 1505.5294 (1502.3643) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [120/132] time 0.081 (0.118) data 0.000 (0.003) loss 1.0170 (0.9664) teacher_loss 0.2112 (0.1317) loss_zs_kd 0.0000 (0.0090) loss_oracle 0.3212 (0.4073) kd_loss 0.6452 (0.6266) acc 93.7500 (95.7292) gate/entropy 0.9899 (0.9902) gate/usage_max 0.5606 (0.5604) gate/usage_min 0.2105 (0.2104) gate/usage_std 0.1609 (0.1607) teacher/entropy 0.0620 (0.0544) teacher/usage_max 0.8581 (0.8911) teacher/usage_min 0.0080 (0.0309) teacher/usage_std 0.3746 (0.3951) nleep/row_max_mean 1533.2266 (1527.4024) nleep/row_max_std 43.0823 (41.3304) nleep/row_min_mean 1509.7942 (1502.1214) lr 7.0224e-05 eta 0:01:03
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,526
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [47/50] batch [20/132] time 0.158 (0.156) data 0.000 (0.015) loss 0.9234 (1.0032) teacher_loss 0.0529 (0.1452) loss_zs_kd 0.0074 (0.0100) loss_oracle 0.4353 (0.4275) kd_loss 0.6491 (0.6393) acc 100.0000 (95.6250) gate/entropy 0.9897 (0.9900) gate/usage_max 0.5609 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1611 (0.1608) teacher/entropy 0.0233 (0.0505) teacher/usage_max 0.8984 (0.8820) teacher/usage_min 0.0377 (0.0382) teacher/usage_std 0.3997 (0.3886) nleep/row_max_mean 1532.5554 (1530.5710) nleep/row_max_std 32.4030 (40.4040) nleep/row_min_mean 1507.8121 (1504.7548) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [40/132] time 0.165 (0.152) data 0.000 (0.007) loss 0.9127 (1.0093) teacher_loss 0.0429 (0.1516) loss_zs_kd 0.0063 (0.0106) loss_oracle 0.4809 (0.4217) kd_loss 0.6262 (0.6416) acc 100.0000 (94.7656) gate/entropy 0.9905 (0.9900) gate/usage_max 0.5600 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1605 (0.1608) teacher/entropy 0.0329 (0.0547) teacher/usage_max 0.9189 (0.8751) teacher/usage_min 0.0003 (0.0421) teacher/usage_std 0.4154 (0.3837) nleep/row_max_mean 1529.4866 (1530.0912) nleep/row_max_std 52.3152 (40.6949) nleep/row_min_mean 1498.1355 (1503.9064) lr 4.8943e-05 eta 0:01:13
epoch [47/50] batch [60/132] time 0.152 (0.149) data 0.000 (0.005) loss 0.8545 (0.9950) teacher_loss 0.0317 (0.1479) loss_zs_kd 0.0066 (0.0107) loss_oracle 0.3855 (0.4163) kd_loss 0.6268 (0.6337) acc 100.0000 (94.7396) gate/entropy 0.9900 (0.9900) gate/usage_max 0.5605 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1608 (0.1608) teacher/entropy 0.0464 (0.0541) teacher/usage_max 0.8957 (0.8841) teacher/usage_min 0.0016 (0.0358) teacher/usage_std 0.3998 (0.3902) nleep/row_max_mean 1526.6793 (1529.6012) nleep/row_max_std 33.5369 (40.9738) nleep/row_min_mean 1498.5294 (1503.2379) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [80/132] time 0.131 (0.149) data 0.000 (0.004) loss 1.2363 (0.9908) teacher_loss 0.3804 (0.1457) loss_zs_kd 0.0082 (0.0103) loss_oracle 0.3847 (0.4169) kd_loss 0.6594 (0.6316) acc 90.6250 (95.0391) gate/entropy 0.9900 (0.9900) gate/usage_max 0.5606 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1609 (0.1608) teacher/entropy 0.0583 (0.0550) teacher/usage_max 0.8456 (0.8853) teacher/usage_min 0.0051 (0.0360) teacher/usage_std 0.3670 (0.3910) nleep/row_max_mean 1521.0452 (1529.4021) nleep/row_max_std 44.8582 (40.9627) nleep/row_min_mean 1497.6212 (1503.1669) lr 4.8943e-05 eta 0:01:06
epoch [47/50] batch [100/132] time 0.133 (0.148) data 0.000 (0.003) loss 1.0246 (0.9828) teacher_loss 0.2309 (0.1453) loss_zs_kd 0.0295 (0.0103) loss_oracle 0.3960 (0.4159) kd_loss 0.5810 (0.6244) acc 93.7500 (95.0625) gate/entropy 0.9898 (0.9900) gate/usage_max 0.5608 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1610 (0.1608) teacher/entropy 0.1304 (0.0562) teacher/usage_max 0.8578 (0.8916) teacher/usage_min 0.0600 (0.0335) teacher/usage_std 0.3710 (0.3953) nleep/row_max_mean 1520.5396 (1528.4313) nleep/row_max_std 49.6771 (41.1482) nleep/row_min_mean 1496.5104 (1502.1999) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [120/132] time 0.072 (0.140) data 0.000 (0.003) loss 1.1237 (0.9744) teacher_loss 0.2031 (0.1408) loss_zs_kd 0.0022 (0.0104) loss_oracle 0.4698 (0.4120) kd_loss 0.6845 (0.6224) acc 96.8750 (95.0521) gate/entropy 0.9899 (0.9900) gate/usage_max 0.5607 (0.5605) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1609 (0.1608) teacher/entropy 0.0281 (0.0580) teacher/usage_max 0.8609 (0.8919) teacher/usage_min 0.0313 (0.0329) teacher/usage_std 0.3743 (0.3956) nleep/row_max_mean 1519.8962 (1527.2453) nleep/row_max_std 47.2851 (41.2446) nleep/row_min_mean 1493.8838 (1501.0872) lr 4.8943e-05 eta 0:00:56
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,522
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [48/50] batch [20/132] time 0.087 (0.136) data 0.000 (0.016) loss 0.8437 (0.9711) teacher_loss 0.0225 (0.1278) loss_zs_kd 0.0123 (0.0112) loss_oracle 0.4089 (0.4180) kd_loss 0.6105 (0.6286) acc 100.0000 (95.0000) gate/entropy 0.9899 (0.9899) gate/usage_max 0.5607 (0.5606) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1610 (0.1609) teacher/entropy 0.0409 (0.0632) teacher/usage_max 0.9203 (0.8792) teacher/usage_min 0.0163 (0.0427) teacher/usage_std 0.4155 (0.3865) nleep/row_max_mean 1526.2262 (1520.4620) nleep/row_max_std 44.8099 (43.1586) nleep/row_min_mean 1501.1841 (1494.9442) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [40/132] time 0.164 (0.131) data 0.000 (0.008) loss 1.0761 (0.9454) teacher_loss 0.2254 (0.1128) loss_zs_kd 0.0225 (0.0104) loss_oracle 0.4083 (0.4102) kd_loss 0.6354 (0.6223) acc 93.7500 (95.9375) gate/entropy 0.9899 (0.9899) gate/usage_max 0.5606 (0.5606) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1609 (0.1609) teacher/entropy 0.0494 (0.0619) teacher/usage_max 0.8850 (0.8869) teacher/usage_min 0.0313 (0.0373) teacher/usage_std 0.3907 (0.3920) nleep/row_max_mean 1515.9586 (1520.1522) nleep/row_max_std 38.6039 (40.7656) nleep/row_min_mean 1491.0017 (1494.9184) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [60/132] time 0.126 (0.129) data 0.000 (0.005) loss 0.9164 (0.9415) teacher_loss 0.0807 (0.1157) loss_zs_kd 0.0037 (0.0095) loss_oracle 0.4224 (0.4094) kd_loss 0.6227 (0.6164) acc 100.0000 (95.7812) gate/entropy 0.9898 (0.9899) gate/usage_max 0.5608 (0.5606) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1610 (0.1609) teacher/entropy 0.0132 (0.0574) teacher/usage_max 0.9386 (0.8984) teacher/usage_min 0.0301 (0.0317) teacher/usage_std 0.4280 (0.4001) nleep/row_max_mean 1522.4677 (1520.1850) nleep/row_max_std 43.5837 (39.1389) nleep/row_min_mean 1496.2418 (1494.8830) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [80/132] time 0.078 (0.126) data 0.000 (0.004) loss 0.8996 (0.9539) teacher_loss 0.0452 (0.1283) loss_zs_kd 0.0037 (0.0093) loss_oracle 0.4334 (0.4087) kd_loss 0.6359 (0.6166) acc 100.0000 (95.5078) gate/entropy 0.9899 (0.9899) gate/usage_max 0.5606 (0.5606) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1609 (0.1609) teacher/entropy 0.0589 (0.0570) teacher/usage_max 0.8766 (0.8985) teacher/usage_min 0.0575 (0.0319) teacher/usage_std 0.3842 (0.4001) nleep/row_max_mean 1516.9084 (1520.3922) nleep/row_max_std 39.2636 (38.7392) nleep/row_min_mean 1492.3906 (1495.0820) lr 3.1417e-05 eta 0:00:39
epoch [48/50] batch [100/132] time 0.130 (0.126) data 0.000 (0.003) loss 0.9035 (0.9591) teacher_loss 0.1295 (0.1322) loss_zs_kd 0.0075 (0.0090) loss_oracle 0.3759 (0.4083) kd_loss 0.5823 (0.6183) acc 93.7500 (95.3125) gate/entropy 0.9896 (0.9899) gate/usage_max 0.5610 (0.5607) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1611 (0.1609) teacher/entropy 0.0533 (0.0565) teacher/usage_max 0.9398 (0.8972) teacher/usage_min 0.0224 (0.0322) teacher/usage_std 0.4289 (0.3992) nleep/row_max_mean 1519.1946 (1520.2734) nleep/row_max_std 53.6184 (38.8171) nleep/row_min_mean 1493.4219 (1494.9965) lr 3.1417e-05 eta 0:00:37
epoch [48/50] batch [120/132] time 0.128 (0.123) data 0.000 (0.003) loss 0.7615 (0.9635) teacher_loss 0.0338 (0.1360) loss_zs_kd 0.0100 (0.0093) loss_oracle 0.4032 (0.4084) kd_loss 0.5212 (0.6186) acc 100.0000 (95.1302) gate/entropy 0.9897 (0.9899) gate/usage_max 0.5609 (0.5607) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1611 (0.1609) teacher/entropy 0.0961 (0.0563) teacher/usage_max 0.9596 (0.8971) teacher/usage_min 0.0073 (0.0315) teacher/usage_std 0.4429 (0.3992) nleep/row_max_mean 1522.8872 (1520.0951) nleep/row_max_std 40.6859 (39.1031) nleep/row_min_mean 1496.4025 (1494.8558) lr 3.1417e-05 eta 0:00:33
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [49/50] batch [20/132] time 0.158 (0.158) data 0.000 (0.015) loss 1.1739 (0.9996) teacher_loss 0.2764 (0.1631) loss_zs_kd 0.0069 (0.0080) loss_oracle 0.4629 (0.4139) kd_loss 0.6626 (0.6256) acc 90.6250 (94.5312) gate/entropy 0.9897 (0.9897) gate/usage_max 0.5609 (0.5609) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1611 (0.1611) teacher/entropy 0.0027 (0.0491) teacher/usage_max 0.9061 (0.8975) teacher/usage_min 0.0314 (0.0303) teacher/usage_std 0.4052 (0.3996) nleep/row_max_mean 1522.6212 (1525.8863) nleep/row_max_std 51.7041 (38.8930) nleep/row_min_mean 1492.4875 (1500.2040) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [40/132] time 0.125 (0.152) data 0.000 (0.008) loss 1.0527 (1.0007) teacher_loss 0.2156 (0.1563) loss_zs_kd 0.0067 (0.0096) loss_oracle 0.3935 (0.4134) kd_loss 0.6370 (0.6329) acc 90.6250 (94.9219) gate/entropy 0.9898 (0.9898) gate/usage_max 0.5608 (0.5608) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1610 (0.1610) teacher/entropy 0.0903 (0.0559) teacher/usage_max 0.8448 (0.8823) teacher/usage_min 0.0375 (0.0361) teacher/usage_std 0.3631 (0.3889) nleep/row_max_mean 1514.8589 (1522.8390) nleep/row_max_std 42.0401 (41.6348) nleep/row_min_mean 1490.9613 (1497.0876) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [60/132] time 0.168 (0.150) data 0.000 (0.005) loss 1.0422 (0.9967) teacher_loss 0.2242 (0.1588) loss_zs_kd 0.0007 (0.0090) loss_oracle 0.4250 (0.4088) kd_loss 0.6051 (0.6290) acc 90.6250 (94.6354) gate/entropy 0.9896 (0.9898) gate/usage_max 0.5610 (0.5608) gate/usage_min 0.2106 (0.2105) gate/usage_std 0.1612 (0.1610) teacher/entropy 0.0456 (0.0549) teacher/usage_max 0.9213 (0.8878) teacher/usage_min 0.0177 (0.0325) teacher/usage_std 0.4162 (0.3928) nleep/row_max_mean 1514.4482 (1520.6673) nleep/row_max_std 46.9217 (41.4760) nleep/row_min_mean 1487.2419 (1495.2976) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [80/132] time 0.155 (0.138) data 0.000 (0.004) loss 0.9605 (0.9852) teacher_loss 0.1037 (0.1504) loss_zs_kd 0.0027 (0.0089) loss_oracle 0.4216 (0.4099) kd_loss 0.6446 (0.6254) acc 93.7500 (94.8438) gate/entropy 0.9899 (0.9898) gate/usage_max 0.5606 (0.5608) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1609 (0.1610) teacher/entropy 0.0419 (0.0542) teacher/usage_max 0.8836 (0.8923) teacher/usage_min 0.0302 (0.0302) teacher/usage_std 0.3898 (0.3960) nleep/row_max_mean 1523.6349 (1519.8592) nleep/row_max_std 33.6149 (41.1493) nleep/row_min_mean 1494.6082 (1494.3813) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [100/132] time 0.075 (0.132) data 0.000 (0.003) loss 0.9365 (0.9904) teacher_loss 0.1113 (0.1549) loss_zs_kd 0.0039 (0.0093) loss_oracle 0.4232 (0.4098) kd_loss 0.6117 (0.6260) acc 93.7500 (94.7188) gate/entropy 0.9901 (0.9898) gate/usage_max 0.5605 (0.5608) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1608 (0.1610) teacher/entropy 0.0500 (0.0541) teacher/usage_max 0.9131 (0.8916) teacher/usage_min 0.0313 (0.0320) teacher/usage_std 0.4101 (0.3954) nleep/row_max_mean 1514.9761 (1520.2037) nleep/row_max_std 44.2271 (40.8476) nleep/row_min_mean 1488.9523 (1494.7019) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [120/132] time 0.136 (0.127) data 0.000 (0.003) loss 0.8963 (0.9852) teacher_loss 0.0316 (0.1504) loss_zs_kd 0.0034 (0.0092) loss_oracle 0.4637 (0.4100) kd_loss 0.6311 (0.6252) acc 100.0000 (94.8438) gate/entropy 0.9898 (0.9898) gate/usage_max 0.5608 (0.5608) gate/usage_min 0.2106 (0.2105) gate/usage_std 0.1610 (0.1610) teacher/entropy 0.0291 (0.0548) teacher/usage_max 0.9124 (0.8917) teacher/usage_min 0.0308 (0.0317) teacher/usage_std 0.4096 (0.3955) nleep/row_max_mean 1529.1616 (1521.1904) nleep/row_max_std 49.4169 (40.9389) nleep/row_min_mean 1500.8047 (1495.6636) lr 1.7713e-05 eta 0:00:18
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,525
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
epoch [50/50] batch [20/132] time 0.184 (0.140) data 0.000 (0.014) loss 1.4761 (0.9752) teacher_loss 0.5200 (0.1369) loss_zs_kd 0.0181 (0.0117) loss_oracle 0.4667 (0.4033) kd_loss 0.7136 (0.6308) acc 84.3750 (95.1562) gate/entropy 0.9896 (0.9897) gate/usage_max 0.5610 (0.5609) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1611 (0.1611) teacher/entropy 0.0363 (0.0594) teacher/usage_max 0.8144 (0.8794) teacher/usage_min 0.0593 (0.0330) teacher/usage_std 0.3412 (0.3870) nleep/row_max_mean 1519.7349 (1523.2321) nleep/row_max_std 54.7816 (44.2394) nleep/row_min_mean 1495.3390 (1498.0939) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [40/132] time 0.147 (0.123) data 0.000 (0.007) loss 0.8852 (0.9436) teacher_loss 0.0692 (0.1088) loss_zs_kd 0.0046 (0.0094) loss_oracle 0.4301 (0.4083) kd_loss 0.5986 (0.6261) acc 96.8750 (96.4844) gate/entropy 0.9895 (0.9897) gate/usage_max 0.5612 (0.5609) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1613 (0.1611) teacher/entropy 0.0462 (0.0545) teacher/usage_max 0.9306 (0.8903) teacher/usage_min 0.0131 (0.0327) teacher/usage_std 0.4227 (0.3945) nleep/row_max_mean 1520.0635 (1525.2528) nleep/row_max_std 47.8687 (43.9461) nleep/row_min_mean 1496.3451 (1499.6098) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/132] time 0.191 (0.116) data 0.000 (0.005) loss 0.8656 (0.9521) teacher_loss 0.0131 (0.1226) loss_zs_kd 0.0104 (0.0087) loss_oracle 0.4053 (0.4042) kd_loss 0.6446 (0.6230) acc 100.0000 (95.7812) gate/entropy 0.9897 (0.9897) gate/usage_max 0.5609 (0.5608) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1611 (0.1610) teacher/entropy 0.0799 (0.0548) teacher/usage_max 0.8435 (0.8933) teacher/usage_min 0.0636 (0.0297) teacher/usage_std 0.3609 (0.3967) nleep/row_max_mean 1531.6641 (1525.6576) nleep/row_max_std 45.8070 (44.5725) nleep/row_min_mean 1506.1521 (1500.1598) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [80/132] time 0.083 (0.120) data 0.000 (0.004) loss 0.9515 (0.9610) teacher_loss 0.0615 (0.1259) loss_zs_kd 0.0133 (0.0094) loss_oracle 0.4499 (0.4085) kd_loss 0.6584 (0.6261) acc 100.0000 (95.5859) gate/entropy 0.9896 (0.9898) gate/usage_max 0.5610 (0.5608) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1611 (0.1610) teacher/entropy 0.0416 (0.0552) teacher/usage_max 0.8681 (0.8897) teacher/usage_min 0.0415 (0.0325) teacher/usage_std 0.3787 (0.3941) nleep/row_max_mean 1528.7410 (1525.6661) nleep/row_max_std 37.9449 (44.3915) nleep/row_min_mean 1502.3514 (1499.9333) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [100/132] time 0.151 (0.118) data 0.000 (0.003) loss 0.9838 (0.9694) teacher_loss 0.0754 (0.1309) loss_zs_kd 0.0113 (0.0093) loss_oracle 0.4457 (0.4100) kd_loss 0.6799 (0.6289) acc 96.8750 (95.5000) gate/entropy 0.9895 (0.9898) gate/usage_max 0.5611 (0.5608) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1612 (0.1610) teacher/entropy 0.0195 (0.0541) teacher/usage_max 0.8735 (0.8882) teacher/usage_min 0.0313 (0.0347) teacher/usage_std 0.3829 (0.3930) nleep/row_max_mean 1527.2432 (1525.6692) nleep/row_max_std 37.7675 (43.7346) nleep/row_min_mean 1500.2134 (1499.9700) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [120/132] time 0.148 (0.123) data 0.000 (0.003) loss 0.8458 (0.9679) teacher_loss 0.0486 (0.1274) loss_zs_kd 0.0031 (0.0094) loss_oracle 0.3922 (0.4101) kd_loss 0.5995 (0.6308) acc 100.0000 (95.6250) gate/entropy 0.9896 (0.9898) gate/usage_max 0.5610 (0.5608) gate/usage_min 0.2106 (0.2106) gate/usage_std 0.1612 (0.1610) teacher/entropy 0.0454 (0.0528) teacher/usage_max 0.9314 (0.8876) teacher/usage_min 0.0050 (0.0352) teacher/usage_std 0.4236 (0.3926) nleep/row_max_mean 1519.9292 (1525.6872) nleep/row_max_std 46.7959 (42.8839) nleep/row_min_mean 1496.7242 (1499.9514) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,523
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 15 *******
******* Domain s best val test acc: 89.9%, epoch: 15 *******
******* Domain s best test acc:     92.5%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:20:45

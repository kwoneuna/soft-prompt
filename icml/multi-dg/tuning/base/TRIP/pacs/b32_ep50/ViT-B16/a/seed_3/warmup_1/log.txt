Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------
Dataset    SPG_PACS
Source     ['cartoon', 'photo', 'sketch']
Target     ['art_painting']
# classes  7
# train_x  5,557
# val      2,385
# test     2,048
---------  ------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/173] time 0.164 (0.219) data 0.001 (0.027) loss 0.9694 (1.2070) teacher_loss 0.4490 (0.4210) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0003 (0.0000) kd_loss 0.5203 (0.7860) acc 84.3750 (84.8438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3298 (0.3297) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.5762 (0.3126) teacher/usage_max 0.4237 (0.4082) teacher/usage_min 0.2383 (0.2595) teacher/usage_std 0.0758 (0.0627) nleep/row_max_mean 1644.9684 (1595.8356) nleep/row_max_std 64.4863 (95.1486) nleep/row_min_mean 1637.8750 (1583.9341) lr 1.0000e-05 eta 0:31:27
epoch [1/50] batch [40/173] time 0.158 (0.188) data 0.000 (0.013) loss 0.8427 (1.1284) teacher_loss 0.4048 (0.4399) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0005 (0.0002) kd_loss 0.4377 (0.6884) acc 90.6250 (84.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3297 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.6598 (0.4098) teacher/usage_max 0.3847 (0.4088) teacher/usage_min 0.2491 (0.2544) teacher/usage_std 0.0600 (0.0655) nleep/row_max_mean 1601.1570 (1605.7755) nleep/row_max_std 69.5414 (83.6643) nleep/row_min_mean 1597.5688 (1597.1897) lr 1.0000e-05 eta 0:26:54
epoch [1/50] batch [60/173] time 0.161 (0.173) data 0.001 (0.009) loss 0.8093 (1.0732) teacher_loss 0.4564 (0.4646) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0026 (0.0006) kd_loss 0.3516 (0.6083) acc 81.2500 (83.5417) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3296 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7448 (0.4897) teacher/usage_max 0.4441 (0.4118) teacher/usage_min 0.2369 (0.2510) teacher/usage_std 0.0852 (0.0681) nleep/row_max_mean 1633.9785 (1609.9700) nleep/row_max_std 40.4555 (75.9157) nleep/row_min_mean 1631.4690 (1603.0323) lr 1.0000e-05 eta 0:24:44
epoch [1/50] batch [80/173] time 0.157 (0.166) data 0.000 (0.007) loss 0.6533 (1.0069) teacher_loss 0.3377 (0.4584) loss_zs_kd 0.0000 (0.0001) loss_oracle 0.0035 (0.0013) kd_loss 0.3138 (0.5478) acc 87.5000 (83.8672) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3298 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7824 (0.5500) teacher/usage_max 0.4226 (0.4166) teacher/usage_min 0.1917 (0.2438) teacher/usage_std 0.1013 (0.0733) nleep/row_max_mean 1607.5641 (1611.3645) nleep/row_max_std 55.0188 (70.9187) nleep/row_min_mean 1604.5825 (1605.4447) lr 1.0000e-05 eta 0:23:42
epoch [1/50] batch [100/173] time 0.110 (0.161) data 0.000 (0.005) loss 0.5353 (0.9501) teacher_loss 0.2323 (0.4460) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0092 (0.0023) kd_loss 0.2981 (0.5029) acc 93.7500 (84.1250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3298 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7983 (0.5946) teacher/usage_max 0.4133 (0.4201) teacher/usage_min 0.2085 (0.2339) teacher/usage_std 0.0894 (0.0792) nleep/row_max_mean 1618.1265 (1611.9429) nleep/row_max_std 64.2466 (68.3513) nleep/row_min_mean 1615.8986 (1606.7199) lr 1.0000e-05 eta 0:22:56
epoch [1/50] batch [120/173] time 0.153 (0.159) data 0.000 (0.005) loss 0.9588 (0.9244) teacher_loss 0.6218 (0.4474) loss_zs_kd 0.0012 (0.0002) loss_oracle 0.0139 (0.0039) kd_loss 0.3295 (0.4750) acc 71.8750 (83.8802) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3297 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7663 (0.6223) teacher/usage_max 0.4785 (0.4238) teacher/usage_min 0.2431 (0.2268) teacher/usage_std 0.1037 (0.0839) nleep/row_max_mean 1624.9819 (1611.7815) nleep/row_max_std 56.0854 (66.5113) nleep/row_min_mean 1622.5182 (1607.0230) lr 1.0000e-05 eta 0:22:37
epoch [1/50] batch [140/173] time 0.140 (0.157) data 0.000 (0.004) loss 1.0907 (0.9018) teacher_loss 0.6306 (0.4418) loss_zs_kd 0.0014 (0.0002) loss_oracle 0.0264 (0.0058) kd_loss 0.4463 (0.4570) acc 81.2500 (84.2857) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3297 (0.3297) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.6478 (0.6400) teacher/usage_max 0.5372 (0.4332) teacher/usage_min 0.1580 (0.2172) teacher/usage_std 0.1561 (0.0917) nleep/row_max_mean 1609.3855 (1611.6000) nleep/row_max_std 49.6623 (64.7915) nleep/row_min_mean 1606.4396 (1607.1617) lr 1.0000e-05 eta 0:22:17
epoch [1/50] batch [160/173] time 0.067 (0.151) data 0.000 (0.003) loss 0.7140 (0.8954) teacher_loss 0.3219 (0.4402) loss_zs_kd 0.0005 (0.0003) loss_oracle 0.0305 (0.0082) kd_loss 0.3766 (0.4510) acc 87.5000 (84.3164) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3296 (0.3297) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.7176 (0.6456) teacher/usage_max 0.5357 (0.4477) teacher/usage_min 0.1607 (0.2092) teacher/usage_std 0.1545 (0.1009) nleep/row_max_mean 1602.4539 (1611.8501) nleep/row_max_std 62.7821 (63.5402) nleep/row_min_mean 1599.9854 (1607.6213) lr 1.0000e-05 eta 0:21:21
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,264
* accuracy: 94.9%
* error: 5.1%
* macro_f1: 95.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      94.9%, epoch: 1 *******
******* Domain a best val test acc: 97.7%, epoch: 1 *******
******* Domain a best test acc:     97.7%, epoch: 1 *******
epoch [2/50] batch [20/173] time 0.104 (0.132) data 0.000 (0.016) loss 0.9483 (0.9281) teacher_loss 0.3542 (0.3206) loss_zs_kd 0.0028 (0.0045) loss_oracle 0.1971 (0.1739) kd_loss 0.4941 (0.5183) acc 93.7500 (89.0625) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3398 (0.3386) gate/usage_min 0.3279 (0.3288) gate/usage_std 0.0049 (0.0040) teacher/entropy 0.5967 (0.5727) teacher/usage_max 0.5956 (0.6403) teacher/usage_min 0.1708 (0.1347) teacher/usage_std 0.1872 (0.2211) nleep/row_max_mean 1620.5791 (1611.5339) nleep/row_max_std 45.3177 (52.7643) nleep/row_min_mean 1616.7681 (1607.6384) lr 2.0000e-03 eta 0:18:38
epoch [2/50] batch [40/173] time 0.180 (0.120) data 0.000 (0.008) loss 1.1588 (1.0301) teacher_loss 0.4203 (0.3509) loss_zs_kd 0.0139 (0.0081) loss_oracle 0.3592 (0.2454) kd_loss 0.5519 (0.5525) acc 87.5000 (87.6562) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3424 (0.3399) gate/usage_min 0.3259 (0.3278) gate/usage_std 0.0069 (0.0050) teacher/entropy 0.5357 (0.5374) teacher/usage_max 0.5753 (0.6189) teacher/usage_min 0.1384 (0.1404) teacher/usage_std 0.1814 (0.2075) nleep/row_max_mean 1601.9087 (1610.4183) nleep/row_max_std 51.2990 (52.6391) nleep/row_min_mean 1596.8013 (1605.8173) lr 2.0000e-03 eta 0:16:49
epoch [2/50] batch [60/173] time 0.092 (0.116) data 0.000 (0.006) loss 1.0036 (1.0653) teacher_loss 0.2241 (0.3318) loss_zs_kd 0.0156 (0.0091) loss_oracle 0.3282 (0.2856) kd_loss 0.6076 (0.5861) acc 93.7500 (88.5417) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3446 (0.3412) gate/usage_min 0.3231 (0.3267) gate/usage_std 0.0088 (0.0060) teacher/entropy 0.4772 (0.5025) teacher/usage_max 0.5325 (0.5970) teacher/usage_min 0.0822 (0.1283) teacher/usage_std 0.1875 (0.2014) nleep/row_max_mean 1604.3589 (1609.2432) nleep/row_max_std 53.0898 (52.9245) nleep/row_min_mean 1597.4133 (1603.8861) lr 2.0000e-03 eta 0:16:16
epoch [2/50] batch [80/173] time 0.090 (0.116) data 0.000 (0.004) loss 1.1366 (1.0901) teacher_loss 0.2930 (0.3182) loss_zs_kd 0.0174 (0.0099) loss_oracle 0.3125 (0.3034) kd_loss 0.6787 (0.6153) acc 87.5000 (88.9453) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3464 (0.3423) gate/usage_min 0.3200 (0.3254) gate/usage_std 0.0108 (0.0069) teacher/entropy 0.4107 (0.4725) teacher/usage_max 0.4217 (0.5751) teacher/usage_min 0.1744 (0.1238) teacher/usage_std 0.1126 (0.1934) nleep/row_max_mean 1612.8000 (1609.7501) nleep/row_max_std 44.0449 (52.6937) nleep/row_min_mean 1606.1759 (1603.8586) lr 2.0000e-03 eta 0:16:16
epoch [2/50] batch [100/173] time 0.090 (0.117) data 0.000 (0.003) loss 1.3070 (1.1241) teacher_loss 0.2836 (0.3035) loss_zs_kd 0.0301 (0.0123) loss_oracle 0.4821 (0.3390) kd_loss 0.7673 (0.6449) acc 84.3750 (89.4062) gate/entropy 1.0979 (1.0983) gate/usage_max 0.3473 (0.3432) gate/usage_min 0.3174 (0.3240) gate/usage_std 0.0123 (0.0079) teacher/entropy 0.3223 (0.4429) teacher/usage_max 0.4683 (0.5565) teacher/usage_min 0.1694 (0.1276) teacher/usage_std 0.1237 (0.1841) nleep/row_max_mean 1606.5530 (1608.6634) nleep/row_max_std 47.8783 (52.5356) nleep/row_min_mean 1597.7024 (1602.2537) lr 2.0000e-03 eta 0:16:18
epoch [2/50] batch [120/173] time 0.161 (0.122) data 0.000 (0.003) loss 1.3177 (1.1568) teacher_loss 0.1650 (0.2903) loss_zs_kd 0.0224 (0.0145) loss_oracle 0.5885 (0.3704) kd_loss 0.8473 (0.6741) acc 93.7500 (89.7656) gate/entropy 1.0978 (1.0982) gate/usage_max 0.3475 (0.3439) gate/usage_min 0.3149 (0.3227) gate/usage_std 0.0136 (0.0087) teacher/entropy 0.2330 (0.4136) teacher/usage_max 0.4563 (0.5433) teacher/usage_min 0.1087 (0.1346) teacher/usage_std 0.1591 (0.1754) nleep/row_max_mean 1591.5946 (1607.8531) nleep/row_max_std 50.0143 (52.5034) nleep/row_min_mean 1580.2633 (1600.7522) lr 2.0000e-03 eta 0:17:03
epoch [2/50] batch [140/173] time 0.127 (0.126) data 0.000 (0.003) loss 1.4449 (1.1855) teacher_loss 0.2224 (0.2793) loss_zs_kd 0.0183 (0.0160) loss_oracle 0.6948 (0.4059) kd_loss 0.8659 (0.6953) acc 90.6250 (90.2455) gate/entropy 1.0976 (1.0981) gate/usage_max 0.3475 (0.3444) gate/usage_min 0.3130 (0.3214) gate/usage_std 0.0148 (0.0095) teacher/entropy 0.2201 (0.3930) teacher/usage_max 0.5544 (0.5289) teacher/usage_min 0.1553 (0.1468) teacher/usage_std 0.1657 (0.1638) nleep/row_max_mean 1590.4769 (1605.3763) nleep/row_max_std 47.2516 (51.9620) nleep/row_min_mean 1579.4486 (1597.7141) lr 2.0000e-03 eta 0:17:34
epoch [2/50] batch [160/173] time 0.138 (0.129) data 0.000 (0.002) loss 1.4984 (1.2186) teacher_loss 0.4213 (0.2787) loss_zs_kd 0.0296 (0.0178) loss_oracle 0.4910 (0.4265) kd_loss 0.8168 (0.7177) acc 87.5000 (90.2734) gate/entropy 1.0974 (1.0981) gate/usage_max 0.3475 (0.3448) gate/usage_min 0.3109 (0.3202) gate/usage_std 0.0160 (0.0103) teacher/entropy 0.2752 (0.3709) teacher/usage_max 0.3937 (0.5189) teacher/usage_min 0.2591 (0.1555) teacher/usage_std 0.0558 (0.1558) nleep/row_max_mean 1606.1434 (1603.6829) nleep/row_max_std 33.5792 (51.0094) nleep/row_min_mean 1593.3845 (1595.4310) lr 2.0000e-03 eta 0:17:52
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      95.8%, epoch: 2 *******
******* Domain a best val test acc: 97.6%, epoch: 2 *******
******* Domain a best test acc:     97.7%, epoch: 1 *******
epoch [3/50] batch [20/173] time 0.159 (0.167) data 0.000 (0.016) loss 1.5957 (1.4281) teacher_loss 0.4067 (0.2080) loss_zs_kd 0.0547 (0.0366) loss_oracle 0.5121 (0.5282) kd_loss 0.9055 (0.9378) acc 78.1250 (91.5625) gate/entropy 1.0975 (1.0975) gate/usage_max 0.3472 (0.3473) gate/usage_min 0.3116 (0.3112) gate/usage_std 0.0155 (0.0158) teacher/entropy 0.2123 (0.1752) teacher/usage_max 0.5117 (0.4689) teacher/usage_min 0.2244 (0.2268) teacher/usage_std 0.1271 (0.1027) nleep/row_max_mean 1578.0886 (1592.4173) nleep/row_max_std 57.3412 (48.2563) nleep/row_min_mean 1563.8582 (1576.7707) lr 1.9980e-03 eta 0:23:04
epoch [3/50] batch [40/173] time 0.125 (0.158) data 0.000 (0.008) loss 1.6285 (1.4799) teacher_loss 0.3698 (0.2287) loss_zs_kd 0.0410 (0.0392) loss_oracle 0.5289 (0.5553) kd_loss 0.9737 (0.9539) acc 84.3750 (91.0938) gate/entropy 1.0976 (1.0975) gate/usage_max 0.3474 (0.3473) gate/usage_min 0.3129 (0.3117) gate/usage_std 0.0148 (0.0155) teacher/entropy 0.1505 (0.1620) teacher/usage_max 0.5992 (0.5037) teacher/usage_min 0.1969 (0.2115) teacher/usage_std 0.1880 (0.1264) nleep/row_max_mean 1585.4086 (1589.8353) nleep/row_max_std 40.2243 (47.0720) nleep/row_min_mean 1571.9454 (1573.6547) lr 1.9980e-03 eta 0:21:49
epoch [3/50] batch [60/173] time 0.099 (0.143) data 0.000 (0.005) loss 1.7021 (1.4859) teacher_loss 0.4531 (0.2369) loss_zs_kd 0.0292 (0.0361) loss_oracle 0.4376 (0.5339) kd_loss 1.0155 (0.9640) acc 84.3750 (90.9375) gate/entropy 1.0978 (1.0976) gate/usage_max 0.3469 (0.3472) gate/usage_min 0.3150 (0.3124) gate/usage_std 0.0135 (0.0151) teacher/entropy 0.1147 (0.1531) teacher/usage_max 0.7322 (0.5295) teacher/usage_min 0.0326 (0.1914) teacher/usage_std 0.2939 (0.1461) nleep/row_max_mean 1577.0339 (1586.5820) nleep/row_max_std 57.0486 (47.9448) nleep/row_min_mean 1559.2490 (1569.9024) lr 1.9980e-03 eta 0:19:40
epoch [3/50] batch [80/173] time 0.074 (0.138) data 0.000 (0.004) loss 1.5435 (1.5006) teacher_loss 0.3491 (0.2575) loss_zs_kd 0.0390 (0.0337) loss_oracle 0.3303 (0.5016) kd_loss 1.0098 (0.9755) acc 87.5000 (90.4688) gate/entropy 1.0980 (1.0977) gate/usage_max 0.3462 (0.3471) gate/usage_min 0.3177 (0.3134) gate/usage_std 0.0118 (0.0144) teacher/entropy 0.1097 (0.1420) teacher/usage_max 0.6855 (0.5515) teacher/usage_min 0.0004 (0.1694) teacher/usage_std 0.2800 (0.1636) nleep/row_max_mean 1598.4409 (1586.0447) nleep/row_max_std 44.8940 (48.0908) nleep/row_min_mean 1578.1259 (1568.8502) lr 1.9980e-03 eta 0:18:53
epoch [3/50] batch [100/173] time 0.092 (0.134) data 0.000 (0.003) loss 1.4797 (1.5067) teacher_loss 0.2600 (0.2590) loss_zs_kd 0.0152 (0.0319) loss_oracle 0.4285 (0.4950) kd_loss 0.9978 (0.9843) acc 93.7500 (90.4062) gate/entropy 1.0982 (1.0977) gate/usage_max 0.3455 (0.3468) gate/usage_min 0.3210 (0.3146) gate/usage_std 0.0100 (0.0137) teacher/entropy 0.1178 (0.1330) teacher/usage_max 0.6609 (0.5718) teacher/usage_min 0.1292 (0.1539) teacher/usage_std 0.2340 (0.1786) nleep/row_max_mean 1571.1530 (1585.2204) nleep/row_max_std 46.7778 (48.5739) nleep/row_min_mean 1551.4727 (1567.2454) lr 1.9980e-03 eta 0:18:15
epoch [3/50] batch [120/173] time 0.114 (0.132) data 0.000 (0.003) loss 1.6174 (1.5052) teacher_loss 0.4032 (0.2602) loss_zs_kd 0.0290 (0.0312) loss_oracle 0.4194 (0.4879) kd_loss 0.9900 (0.9854) acc 87.5000 (90.5729) gate/entropy 1.0983 (1.0978) gate/usage_max 0.3446 (0.3465) gate/usage_min 0.3250 (0.3160) gate/usage_std 0.0083 (0.0129) teacher/entropy 0.1170 (0.1308) teacher/usage_max 0.6542 (0.5862) teacher/usage_min 0.0903 (0.1443) teacher/usage_std 0.2367 (0.1889) nleep/row_max_mean 1580.7629 (1584.4043) nleep/row_max_std 44.0747 (47.7216) nleep/row_min_mean 1555.4087 (1565.6716) lr 1.9980e-03 eta 0:17:58
epoch [3/50] batch [140/173] time 0.097 (0.127) data 0.000 (0.002) loss 1.7997 (1.5078) teacher_loss 0.4841 (0.2655) loss_zs_kd 0.0351 (0.0300) loss_oracle 0.5327 (0.4822) kd_loss 1.0316 (0.9862) acc 81.2500 (90.4018) gate/entropy 1.0984 (1.0979) gate/usage_max 0.3429 (0.3461) gate/usage_min 0.3274 (0.3176) gate/usage_std 0.0068 (0.0122) teacher/entropy 0.0740 (0.1288) teacher/usage_max 0.8038 (0.6078) teacher/usage_min 0.0868 (0.1361) teacher/usage_std 0.3328 (0.2032) nleep/row_max_mean 1575.1959 (1583.2851) nleep/row_max_std 43.7752 (48.1491) nleep/row_min_mean 1549.6536 (1563.7931) lr 1.9980e-03 eta 0:17:20
epoch [3/50] batch [160/173] time 0.121 (0.126) data 0.000 (0.002) loss 1.6842 (1.5242) teacher_loss 0.3165 (0.2706) loss_zs_kd 0.0090 (0.0284) loss_oracle 0.7057 (0.5008) kd_loss 1.0103 (0.9889) acc 84.3750 (90.4297) gate/entropy 1.0984 (1.0980) gate/usage_max 0.3395 (0.3455) gate/usage_min 0.3242 (0.3186) gate/usage_std 0.0066 (0.0115) teacher/entropy 0.0806 (0.1240) teacher/usage_max 0.9105 (0.6388) teacher/usage_min 0.0407 (0.1245) teacher/usage_std 0.4081 (0.2241) nleep/row_max_mean 1567.6470 (1581.3844) nleep/row_max_std 47.7111 (49.1095) nleep/row_min_mean 1540.3326 (1561.0621) lr 1.9980e-03 eta 0:17:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,278
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.7%
******* Domain a best val acc:      95.8%, epoch: 2 *******
******* Domain a best val test acc: 97.6%, epoch: 2 *******
******* Domain a best test acc:     97.7%, epoch: 1 *******
epoch [4/50] batch [20/173] time 0.126 (0.150) data 0.000 (0.017) loss 1.6737 (1.6659) teacher_loss 0.3748 (0.3276) loss_zs_kd 0.0062 (0.0127) loss_oracle 0.5280 (0.5976) kd_loss 1.0317 (1.0332) acc 84.3750 (87.5000) gate/entropy 1.0979 (1.0981) gate/usage_max 0.3491 (0.3454) gate/usage_min 0.3193 (0.3206) gate/usage_std 0.0122 (0.0102) teacher/entropy 0.0246 (0.0324) teacher/usage_max 0.9563 (0.9622) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4409 (0.4450) nleep/row_max_mean 1581.3049 (1575.2235) nleep/row_max_std 44.3119 (52.4683) nleep/row_min_mean 1545.6024 (1541.6718) lr 1.9921e-03 eta 0:20:17
epoch [4/50] batch [40/173] time 0.160 (0.149) data 0.000 (0.009) loss 1.9603 (1.7150) teacher_loss 0.5947 (0.3788) loss_zs_kd 0.0046 (0.0112) loss_oracle 0.6763 (0.5939) kd_loss 1.0252 (1.0336) acc 78.1250 (86.3281) gate/entropy 1.0974 (1.0979) gate/usage_max 0.3563 (0.3491) gate/usage_min 0.3171 (0.3194) gate/usage_std 0.0167 (0.0123) teacher/entropy 0.0071 (0.0204) teacher/usage_max 0.9982 (0.9787) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4702 (0.4565) nleep/row_max_mean 1575.5172 (1575.2508) nleep/row_max_std 51.1315 (53.0209) nleep/row_min_mean 1536.8982 (1540.1797) lr 1.9921e-03 eta 0:20:07
epoch [4/50] batch [60/173] time 0.132 (0.146) data 0.001 (0.006) loss 1.7368 (1.7154) teacher_loss 0.3957 (0.3796) loss_zs_kd 0.0048 (0.0102) loss_oracle 0.6840 (0.6048) kd_loss 0.9966 (1.0282) acc 84.3750 (86.0417) gate/entropy 1.0966 (1.0976) gate/usage_max 0.3635 (0.3527) gate/usage_min 0.3151 (0.3183) gate/usage_std 0.0215 (0.0146) teacher/entropy 0.0164 (0.0152) teacher/usage_max 0.9936 (0.9846) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4669 (0.4606) nleep/row_max_mean 1579.4292 (1576.3796) nleep/row_max_std 45.8899 (51.1093) nleep/row_min_mean 1537.4526 (1539.6708) lr 1.9921e-03 eta 0:19:37
epoch [4/50] batch [80/173] time 0.155 (0.145) data 0.000 (0.004) loss 1.5210 (1.7065) teacher_loss 0.1878 (0.3712) loss_zs_kd 0.0026 (0.0096) loss_oracle 0.6855 (0.6189) kd_loss 0.9892 (1.0211) acc 93.7500 (86.4844) gate/entropy 1.0953 (1.0972) gate/usage_max 0.3719 (0.3565) gate/usage_min 0.3116 (0.3170) gate/usage_std 0.0273 (0.0171) teacher/entropy 0.0000 (0.0115) teacher/usage_max 1.0000 (0.9884) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4714 (0.4633) nleep/row_max_mean 1581.6991 (1577.0636) nleep/row_max_std 52.7068 (51.2100) nleep/row_min_mean 1533.6489 (1538.2502) lr 1.9921e-03 eta 0:19:23
epoch [4/50] batch [100/173] time 0.150 (0.144) data 0.000 (0.004) loss 1.6071 (1.7020) teacher_loss 0.3200 (0.3749) loss_zs_kd 0.0060 (0.0089) loss_oracle 0.6324 (0.6205) kd_loss 0.9679 (1.0124) acc 87.5000 (86.3125) gate/entropy 1.0938 (1.0967) gate/usage_max 0.3799 (0.3604) gate/usage_min 0.3086 (0.3156) gate/usage_std 0.0329 (0.0197) teacher/entropy 0.0000 (0.0092) teacher/usage_max 1.0000 (0.9907) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4649) nleep/row_max_mean 1587.0178 (1577.8789) nleep/row_max_std 60.5835 (51.6332) nleep/row_min_mean 1539.3203 (1537.2165) lr 1.9921e-03 eta 0:19:17
epoch [4/50] batch [120/173] time 0.135 (0.144) data 0.000 (0.003) loss 1.4613 (1.6900) teacher_loss 0.1870 (0.3715) loss_zs_kd 0.0107 (0.0083) loss_oracle 0.6384 (0.6218) kd_loss 0.9498 (1.0034) acc 96.8750 (86.4844) gate/entropy 1.0923 (1.0961) gate/usage_max 0.3868 (0.3643) gate/usage_min 0.3065 (0.3143) gate/usage_std 0.0378 (0.0224) teacher/entropy 0.0000 (0.0077) teacher/usage_max 1.0000 (0.9923) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4714 (0.4660) nleep/row_max_mean 1586.4647 (1578.5212) nleep/row_max_std 52.6012 (51.4640) nleep/row_min_mean 1536.3450 (1536.5307) lr 1.9921e-03 eta 0:19:14
epoch [4/50] batch [140/173] time 0.159 (0.144) data 0.000 (0.003) loss 1.5171 (1.6825) teacher_loss 0.2956 (0.3754) loss_zs_kd 0.0072 (0.0081) loss_oracle 0.5738 (0.6175) kd_loss 0.9310 (0.9943) acc 84.3750 (86.2946) gate/entropy 1.0905 (1.0954) gate/usage_max 0.3942 (0.3681) gate/usage_min 0.3019 (0.3128) gate/usage_std 0.0430 (0.0250) teacher/entropy 0.0000 (0.0066) teacher/usage_max 1.0000 (0.9934) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4714 (0.4668) nleep/row_max_mean 1573.4866 (1578.6573) nleep/row_max_std 58.2749 (51.5896) nleep/row_min_mean 1524.6667 (1535.7195) lr 1.9921e-03 eta 0:19:11
epoch [4/50] batch [160/173] time 0.161 (0.144) data 0.000 (0.002) loss 2.1585 (1.6694) teacher_loss 0.9461 (0.3721) loss_zs_kd 0.0090 (0.0079) loss_oracle 0.5903 (0.6161) kd_loss 0.9127 (0.9852) acc 71.8750 (86.4062) gate/entropy 1.0885 (1.0946) gate/usage_max 0.4014 (0.3718) gate/usage_min 0.2971 (0.3112) gate/usage_std 0.0482 (0.0275) teacher/entropy 0.0000 (0.0058) teacher/usage_max 1.0000 (0.9942) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4714 (0.4674) nleep/row_max_mean 1577.4807 (1577.6429) nleep/row_max_std 44.3848 (52.0079) nleep/row_min_mean 1531.9249 (1533.9786) lr 1.9921e-03 eta 0:19:09
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,282
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.8%, epoch: 2 *******
******* Domain a best val test acc: 97.6%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [5/50] batch [20/173] time 0.105 (0.134) data 0.000 (0.020) loss 1.3745 (1.5330) teacher_loss 0.1293 (0.3318) loss_zs_kd 0.0015 (0.0050) loss_oracle 0.7219 (0.6141) kd_loss 0.8836 (0.8916) acc 96.8750 (88.4375) gate/entropy 1.0847 (1.0858) gate/usage_max 0.4133 (0.4099) gate/usage_min 0.2896 (0.2918) gate/usage_std 0.0566 (0.0542) teacher/entropy 0.0000 (0.0002) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1559.4788 (1572.6184) nleep/row_max_std 58.4089 (52.7806) nleep/row_min_mean 1509.5251 (1522.3289) lr 1.9823e-03 eta 0:17:42
epoch [5/50] batch [40/173] time 0.075 (0.125) data 0.000 (0.010) loss 1.5412 (1.5127) teacher_loss 0.3724 (0.3253) loss_zs_kd 0.0070 (0.0051) loss_oracle 0.6012 (0.6049) kd_loss 0.8647 (0.8824) acc 84.3750 (87.5781) gate/entropy 1.0818 (1.0845) gate/usage_max 0.4212 (0.4138) gate/usage_min 0.2851 (0.2895) gate/usage_std 0.0622 (0.0570) teacher/entropy 0.0000 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1567.0851 (1574.4870) nleep/row_max_std 45.0652 (53.1476) nleep/row_min_mean 1517.6929 (1523.4456) lr 1.9823e-03 eta 0:16:32
epoch [5/50] batch [60/173] time 0.114 (0.116) data 0.001 (0.007) loss 1.3085 (1.5099) teacher_loss 0.2000 (0.3357) loss_zs_kd 0.0052 (0.0053) loss_oracle 0.5181 (0.5968) kd_loss 0.8469 (0.8731) acc 93.7500 (87.3958) gate/entropy 1.0788 (1.0830) gate/usage_max 0.4287 (0.4176) gate/usage_min 0.2808 (0.2873) gate/usage_std 0.0676 (0.0597) teacher/entropy 0.0000 (0.0002) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1575.6859 (1575.2272) nleep/row_max_std 62.3416 (53.9558) nleep/row_min_mean 1521.6729 (1523.6519) lr 1.9823e-03 eta 0:15:16
epoch [5/50] batch [80/173] time 0.175 (0.119) data 0.000 (0.005) loss 1.3967 (1.4997) teacher_loss 0.2979 (0.3376) loss_zs_kd 0.0045 (0.0061) loss_oracle 0.5361 (0.5899) kd_loss 0.8284 (0.8642) acc 87.5000 (87.3438) gate/entropy 1.0754 (1.0815) gate/usage_max 0.4367 (0.4215) gate/usage_min 0.2763 (0.2851) gate/usage_std 0.0732 (0.0624) teacher/entropy 0.0000 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1592.4873 (1575.2298) nleep/row_max_std 50.5733 (53.6193) nleep/row_min_mean 1534.0758 (1523.0937) lr 1.9823e-03 eta 0:15:40
epoch [5/50] batch [100/173] time 0.079 (0.119) data 0.000 (0.004) loss 1.5156 (1.4849) teacher_loss 0.4288 (0.3338) loss_zs_kd 0.0120 (0.0059) loss_oracle 0.5382 (0.5856) kd_loss 0.8117 (0.8553) acc 84.3750 (87.5312) gate/entropy 1.0721 (1.0800) gate/usage_max 0.4441 (0.4252) gate/usage_min 0.2721 (0.2829) gate/usage_std 0.0785 (0.0651) teacher/entropy 0.0000 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1573.3765 (1575.5129) nleep/row_max_std 55.3478 (53.8443) nleep/row_min_mean 1519.3596 (1522.8810) lr 1.9823e-03 eta 0:15:36
epoch [5/50] batch [120/173] time 0.108 (0.119) data 0.000 (0.004) loss 1.3862 (1.4777) teacher_loss 0.2960 (0.3337) loss_zs_kd 0.0034 (0.0058) loss_oracle 0.5821 (0.5886) kd_loss 0.7975 (0.8469) acc 93.7500 (87.6302) gate/entropy 1.0690 (1.0784) gate/usage_max 0.4505 (0.4289) gate/usage_min 0.2684 (0.2808) gate/usage_std 0.0830 (0.0677) teacher/entropy 0.0000 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1562.0682 (1574.3883) nleep/row_max_std 61.2965 (54.1973) nleep/row_min_mean 1511.7490 (1521.8472) lr 1.9823e-03 eta 0:15:31
epoch [5/50] batch [140/173] time 0.161 (0.124) data 0.000 (0.003) loss 1.5877 (1.4732) teacher_loss 0.5209 (0.3343) loss_zs_kd 0.0156 (0.0061) loss_oracle 0.5541 (0.5943) kd_loss 0.7819 (0.8387) acc 81.2500 (87.6562) gate/entropy 1.0654 (1.0768) gate/usage_max 0.4575 (0.4325) gate/usage_min 0.2644 (0.2787) gate/usage_std 0.0880 (0.0702) teacher/entropy 0.0001 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1564.9768 (1573.2155) nleep/row_max_std 55.4744 (54.8085) nleep/row_min_mean 1514.8219 (1520.8743) lr 1.9823e-03 eta 0:16:06
epoch [5/50] batch [160/173] time 0.140 (0.128) data 0.000 (0.003) loss 1.2529 (1.4623) teacher_loss 0.1960 (0.3319) loss_zs_kd 0.0062 (0.0062) loss_oracle 0.5729 (0.5933) kd_loss 0.7673 (0.8306) acc 93.7500 (87.5781) gate/entropy 1.0617 (1.0752) gate/usage_max 0.4643 (0.4361) gate/usage_min 0.2606 (0.2767) gate/usage_std 0.0928 (0.0728) teacher/entropy 0.0000 (0.0001) teacher/usage_max 1.0000 (1.0000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4714) nleep/row_max_mean 1568.3315 (1572.5221) nleep/row_max_std 57.5551 (55.3861) nleep/row_min_mean 1519.9370 (1520.3660) lr 1.9823e-03 eta 0:16:39
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 97.8%, epoch: 5 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [6/50] batch [20/173] time 0.137 (0.160) data 0.000 (0.013) loss 1.2060 (1.3784) teacher_loss 0.1430 (0.3390) loss_zs_kd 0.0018 (0.0060) loss_oracle 0.6322 (0.5746) kd_loss 0.7460 (0.7491) acc 96.8750 (88.5938) gate/entropy 1.0560 (1.0575) gate/usage_max 0.4742 (0.4716) gate/usage_min 0.2553 (0.2567) gate/usage_std 0.0998 (0.0980) teacher/entropy 0.0001 (0.0045) teacher/usage_max 1.0000 (0.9962) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4687) nleep/row_max_mean 1567.7299 (1563.3936) nleep/row_max_std 56.4159 (54.5744) nleep/row_min_mean 1518.3103 (1515.6186) lr 1.9686e-03 eta 0:20:46
epoch [6/50] batch [40/173] time 0.168 (0.161) data 0.000 (0.007) loss 1.4870 (1.3798) teacher_loss 0.4616 (0.3399) loss_zs_kd 0.0062 (0.0060) loss_oracle 0.5814 (0.5882) kd_loss 0.7316 (0.7428) acc 75.0000 (87.4219) gate/entropy 1.0520 (1.0558) gate/usage_max 0.4808 (0.4746) gate/usage_min 0.2518 (0.2551) gate/usage_std 0.1045 (0.1001) teacher/entropy 0.0007 (0.0055) teacher/usage_max 0.9999 (0.9945) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4713 (0.4675) nleep/row_max_mean 1561.4916 (1562.6473) nleep/row_max_std 62.0625 (55.8407) nleep/row_min_mean 1511.4590 (1515.0619) lr 1.9686e-03 eta 0:20:48
epoch [6/50] batch [60/173] time 0.079 (0.163) data 0.001 (0.005) loss 1.3177 (1.3600) teacher_loss 0.3079 (0.3321) loss_zs_kd 0.0053 (0.0057) loss_oracle 0.5739 (0.5782) kd_loss 0.7202 (0.7360) acc 93.7500 (87.7083) gate/entropy 1.0486 (1.0540) gate/usage_max 0.4862 (0.4775) gate/usage_min 0.2489 (0.2535) gate/usage_std 0.1083 (0.1022) teacher/entropy 0.0010 (0.0068) teacher/usage_max 0.9999 (0.9938) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4713 (0.4671) nleep/row_max_mean 1575.8511 (1563.7953) nleep/row_max_std 59.3564 (57.0361) nleep/row_min_mean 1524.0359 (1516.2250) lr 1.9686e-03 eta 0:20:55
epoch [6/50] batch [80/173] time 0.164 (0.152) data 0.000 (0.004) loss 1.2061 (1.3421) teacher_loss 0.2025 (0.3171) loss_zs_kd 0.0082 (0.0057) loss_oracle 0.6351 (0.5853) kd_loss 0.6820 (0.7296) acc 90.6250 (88.0859) gate/entropy 1.0456 (1.0523) gate/usage_max 0.4909 (0.4803) gate/usage_min 0.2464 (0.2521) gate/usage_std 0.1116 (0.1041) teacher/entropy 0.0433 (0.0085) teacher/usage_max 0.9774 (0.9923) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4555 (0.4660) nleep/row_max_mean 1553.2734 (1561.6062) nleep/row_max_std 63.3772 (57.5721) nleep/row_min_mean 1512.8423 (1515.0751) lr 1.9686e-03 eta 0:19:28
epoch [6/50] batch [100/173] time 0.106 (0.144) data 0.000 (0.003) loss 1.2775 (1.3335) teacher_loss 0.3218 (0.3156) loss_zs_kd 0.0177 (0.0059) loss_oracle 0.5119 (0.5805) kd_loss 0.6909 (0.7246) acc 96.8750 (88.0625) gate/entropy 1.0424 (1.0506) gate/usage_max 0.4957 (0.4829) gate/usage_min 0.2438 (0.2506) gate/usage_std 0.1150 (0.1060) teacher/entropy 0.0225 (0.0106) teacher/usage_max 0.9813 (0.9881) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4582 (0.4631) nleep/row_max_mean 1550.5461 (1560.7619) nleep/row_max_std 71.1935 (58.0754) nleep/row_min_mean 1506.9541 (1515.0763) lr 1.9686e-03 eta 0:18:30
epoch [6/50] batch [120/173] time 0.082 (0.140) data 0.000 (0.002) loss 1.3269 (1.3280) teacher_loss 0.3442 (0.3129) loss_zs_kd 0.0070 (0.0060) loss_oracle 0.5308 (0.5814) kd_loss 0.7138 (0.7214) acc 81.2500 (88.1510) gate/entropy 1.0397 (1.0489) gate/usage_max 0.4996 (0.4855) gate/usage_min 0.2417 (0.2493) gate/usage_std 0.1178 (0.1078) teacher/entropy 0.0285 (0.0117) teacher/usage_max 0.9265 (0.9833) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4205 (0.4598) nleep/row_max_mean 1533.1849 (1560.5107) nleep/row_max_std 66.9591 (58.2707) nleep/row_min_mean 1495.4617 (1515.3327) lr 1.9686e-03 eta 0:17:54
epoch [6/50] batch [140/173] time 0.082 (0.138) data 0.000 (0.002) loss 1.7250 (1.3331) teacher_loss 0.7540 (0.3216) loss_zs_kd 0.0127 (0.0061) loss_oracle 0.5438 (0.5829) kd_loss 0.6928 (0.7170) acc 68.7500 (87.7902) gate/entropy 1.0363 (1.0473) gate/usage_max 0.5045 (0.4879) gate/usage_min 0.2392 (0.2480) gate/usage_std 0.1212 (0.1095) teacher/entropy 0.0159 (0.0139) teacher/usage_max 0.9629 (0.9792) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4454 (0.4569) nleep/row_max_mean 1540.6936 (1559.7912) nleep/row_max_std 55.4480 (58.0100) nleep/row_min_mean 1501.0601 (1515.1326) lr 1.9686e-03 eta 0:17:33
epoch [6/50] batch [160/173] time 0.121 (0.134) data 0.000 (0.002) loss 1.3219 (1.3282) teacher_loss 0.3437 (0.3220) loss_zs_kd 0.0038 (0.0063) loss_oracle 0.5647 (0.5818) kd_loss 0.6939 (0.7122) acc 90.6250 (87.7734) gate/entropy 1.0327 (1.0457) gate/usage_max 0.5095 (0.4903) gate/usage_min 0.2369 (0.2467) gate/usage_std 0.1248 (0.1112) teacher/entropy 0.0018 (0.0147) teacher/usage_max 0.9689 (0.9782) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4496 (0.4562) nleep/row_max_mean 1576.1710 (1559.8666) nleep/row_max_std 57.7838 (57.6823) nleep/row_min_mean 1530.3672 (1515.4465) lr 1.9686e-03 eta 0:17:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 97.8%, epoch: 5 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [7/50] batch [20/173] time 0.150 (0.168) data 0.000 (0.014) loss 1.2565 (1.2343) teacher_loss 0.3057 (0.2858) loss_zs_kd 0.0114 (0.0073) loss_oracle 0.5256 (0.5530) kd_loss 0.6824 (0.6684) acc 87.5000 (89.0625) gate/entropy 1.0281 (1.0295) gate/usage_max 0.5157 (0.5138) gate/usage_min 0.2342 (0.2349) gate/usage_std 0.1291 (0.1278) teacher/entropy 0.0019 (0.0168) teacher/usage_max 0.9685 (0.9723) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4493 (0.4520) nleep/row_max_mean 1567.6932 (1565.4993) nleep/row_max_std 66.0902 (54.9194) nleep/row_min_mean 1522.7528 (1522.5246) lr 1.9511e-03 eta 0:21:18
epoch [7/50] batch [40/173] time 0.138 (0.157) data 0.000 (0.007) loss 1.3764 (1.2606) teacher_loss 0.4767 (0.3075) loss_zs_kd 0.0043 (0.0068) loss_oracle 0.4762 (0.5572) kd_loss 0.6594 (0.6711) acc 84.3750 (88.3594) gate/entropy 1.0257 (1.0281) gate/usage_max 0.5188 (0.5157) gate/usage_min 0.2328 (0.2341) gate/usage_std 0.1313 (0.1291) teacher/entropy 0.0159 (0.0168) teacher/usage_max 0.9737 (0.9638) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4529 (0.4462) nleep/row_max_mean 1542.9532 (1562.9796) nleep/row_max_std 60.3635 (55.6275) nleep/row_min_mean 1504.5364 (1519.7292) lr 1.9511e-03 eta 0:19:50
epoch [7/50] batch [60/173] time 0.150 (0.154) data 0.000 (0.005) loss 1.1004 (1.2681) teacher_loss 0.0927 (0.3207) loss_zs_kd 0.0034 (0.0077) loss_oracle 0.5809 (0.5515) kd_loss 0.7156 (0.6678) acc 93.7500 (87.7604) gate/entropy 1.0226 (1.0267) gate/usage_max 0.5228 (0.5175) gate/usage_min 0.2311 (0.2333) gate/usage_std 0.1341 (0.1304) teacher/entropy 0.0024 (0.0183) teacher/usage_max 0.9064 (0.9619) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4070 (0.4449) nleep/row_max_mean 1572.6121 (1563.0113) nleep/row_max_std 44.5779 (55.5543) nleep/row_min_mean 1529.0229 (1519.7443) lr 1.9511e-03 eta 0:19:25
epoch [7/50] batch [80/173] time 0.152 (0.156) data 0.000 (0.004) loss 1.3884 (1.2625) teacher_loss 0.4381 (0.3191) loss_zs_kd 0.0123 (0.0073) loss_oracle 0.5805 (0.5521) kd_loss 0.6540 (0.6637) acc 81.2500 (87.6562) gate/entropy 1.0202 (1.0254) gate/usage_max 0.5259 (0.5192) gate/usage_min 0.2297 (0.2326) gate/usage_std 0.1363 (0.1316) teacher/entropy 0.0112 (0.0197) teacher/usage_max 0.9693 (0.9616) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4498 (0.4447) nleep/row_max_mean 1556.3762 (1560.3493) nleep/row_max_std 58.4280 (56.6006) nleep/row_min_mean 1513.8086 (1517.4549) lr 1.9511e-03 eta 0:19:31
epoch [7/50] batch [100/173] time 0.162 (0.154) data 0.001 (0.003) loss 1.2389 (1.2686) teacher_loss 0.3687 (0.3266) loss_zs_kd 0.0057 (0.0075) loss_oracle 0.4758 (0.5579) kd_loss 0.6295 (0.6593) acc 84.3750 (87.4375) gate/entropy 1.0177 (1.0241) gate/usage_max 0.5291 (0.5208) gate/usage_min 0.2284 (0.2319) gate/usage_std 0.1385 (0.1327) teacher/entropy 0.0088 (0.0204) teacher/usage_max 0.9980 (0.9626) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4700 (0.4454) nleep/row_max_mean 1561.3630 (1560.2379) nleep/row_max_std 57.1074 (56.4176) nleep/row_min_mean 1516.3535 (1517.1728) lr 1.9511e-03 eta 0:19:15
epoch [7/50] batch [120/173] time 0.155 (0.154) data 0.000 (0.002) loss 1.1897 (1.2555) teacher_loss 0.2671 (0.3174) loss_zs_kd 0.0079 (0.0075) loss_oracle 0.5732 (0.5564) kd_loss 0.6321 (0.6561) acc 90.6250 (87.7604) gate/entropy 1.0158 (1.0229) gate/usage_max 0.5313 (0.5224) gate/usage_min 0.2275 (0.2313) gate/usage_std 0.1401 (0.1338) teacher/entropy 0.0003 (0.0192) teacher/usage_max 1.0000 (0.9647) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4469) nleep/row_max_mean 1563.0677 (1559.5547) nleep/row_max_std 61.7972 (56.9946) nleep/row_min_mean 1514.9642 (1516.3473) lr 1.9511e-03 eta 0:19:10
epoch [7/50] batch [140/173] time 0.149 (0.153) data 0.000 (0.002) loss 1.4658 (1.2564) teacher_loss 0.5734 (0.3238) loss_zs_kd 0.0068 (0.0076) loss_oracle 0.5566 (0.5525) kd_loss 0.6108 (0.6525) acc 78.1250 (87.7679) gate/entropy 1.0137 (1.0217) gate/usage_max 0.5339 (0.5239) gate/usage_min 0.2265 (0.2306) gate/usage_std 0.1419 (0.1349) teacher/entropy 0.0326 (0.0183) teacher/usage_max 0.9799 (0.9673) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4572 (0.4486) nleep/row_max_mean 1556.6509 (1559.5854) nleep/row_max_std 63.0034 (56.9332) nleep/row_min_mean 1511.3517 (1516.1217) lr 1.9511e-03 eta 0:19:01
epoch [7/50] batch [160/173] time 0.072 (0.152) data 0.000 (0.002) loss 1.3506 (1.2568) teacher_loss 0.4358 (0.3303) loss_zs_kd 0.0084 (0.0077) loss_oracle 0.5287 (0.5467) kd_loss 0.6463 (0.6493) acc 87.5000 (87.4414) gate/entropy 1.0116 (1.0205) gate/usage_max 0.5365 (0.5254) gate/usage_min 0.2255 (0.2300) gate/usage_std 0.1438 (0.1359) teacher/entropy 0.0016 (0.0171) teacher/usage_max 0.9685 (0.9695) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4493 (0.4502) nleep/row_max_mean 1545.4932 (1559.8317) nleep/row_max_std 55.8277 (56.6789) nleep/row_min_mean 1502.1177 (1516.0057) lr 1.9511e-03 eta 0:18:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.0%, epoch: 5 *******
******* Domain a best val test acc: 97.8%, epoch: 5 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [8/50] batch [20/173] time 0.090 (0.142) data 0.000 (0.017) loss 1.2420 (1.2381) teacher_loss 0.3064 (0.3382) loss_zs_kd 0.0096 (0.0058) loss_oracle 0.6036 (0.5562) kd_loss 0.6291 (0.6190) acc 90.6250 (87.6562) gate/entropy 1.0087 (1.0092) gate/usage_max 0.5400 (0.5393) gate/usage_min 0.2242 (0.2245) gate/usage_std 0.1462 (0.1457) teacher/entropy 0.0233 (0.0108) teacher/usage_max 0.9552 (0.9848) teacher/usage_min 0.0001 (0.0000) teacher/usage_std 0.4401 (0.4608) nleep/row_max_mean 1557.7424 (1562.9131) nleep/row_max_std 55.5215 (55.2106) nleep/row_min_mean 1515.3018 (1516.6179) lr 1.9298e-03 eta 0:17:31
epoch [8/50] batch [40/173] time 0.195 (0.125) data 0.000 (0.008) loss 1.1446 (1.2272) teacher_loss 0.2051 (0.3275) loss_zs_kd 0.0040 (0.0054) loss_oracle 0.5242 (0.5498) kd_loss 0.6754 (0.6221) acc 90.6250 (86.8750) gate/entropy 1.0069 (1.0084) gate/usage_max 0.5421 (0.5403) gate/usage_min 0.2233 (0.2241) gate/usage_std 0.1477 (0.1464) teacher/entropy 0.0140 (0.0138) teacher/usage_max 0.9090 (0.9752) teacher/usage_min 0.0314 (0.0009) teacher/usage_std 0.4072 (0.4541) nleep/row_max_mean 1557.7365 (1561.9296) nleep/row_max_std 52.9144 (55.2843) nleep/row_min_mean 1517.7283 (1516.8979) lr 1.9298e-03 eta 0:15:23
epoch [8/50] batch [60/173] time 0.192 (0.125) data 0.000 (0.006) loss 1.0994 (1.2329) teacher_loss 0.2075 (0.3312) loss_zs_kd 0.0061 (0.0063) loss_oracle 0.5655 (0.5464) kd_loss 0.6061 (0.6254) acc 90.6250 (86.4062) gate/entropy 1.0063 (1.0076) gate/usage_max 0.5427 (0.5412) gate/usage_min 0.2231 (0.2237) gate/usage_std 0.1481 (0.1470) teacher/entropy 0.0525 (0.0160) teacher/usage_max 0.9425 (0.9668) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4314 (0.4483) nleep/row_max_mean 1537.9314 (1561.7921) nleep/row_max_std 70.9774 (55.7929) nleep/row_min_mean 1498.5404 (1517.1457) lr 1.9298e-03 eta 0:15:24
epoch [8/50] batch [80/173] time 0.073 (0.124) data 0.000 (0.004) loss 1.0847 (1.2297) teacher_loss 0.1970 (0.3321) loss_zs_kd 0.0091 (0.0066) loss_oracle 0.5407 (0.5404) kd_loss 0.6128 (0.6241) acc 93.7500 (86.7578) gate/entropy 1.0041 (1.0069) gate/usage_max 0.5453 (0.5420) gate/usage_min 0.2220 (0.2234) gate/usage_std 0.1499 (0.1476) teacher/entropy 0.0556 (0.0186) teacher/usage_max 0.9265 (0.9636) teacher/usage_min 0.0076 (0.0007) teacher/usage_std 0.4201 (0.4461) nleep/row_max_mean 1557.0989 (1560.7422) nleep/row_max_std 51.1531 (56.8828) nleep/row_min_mean 1517.2830 (1516.7395) lr 1.9298e-03 eta 0:15:16
epoch [8/50] batch [100/173] time 0.159 (0.124) data 0.000 (0.004) loss 1.2879 (1.2292) teacher_loss 0.3173 (0.3283) loss_zs_kd 0.0106 (0.0072) loss_oracle 0.5848 (0.5425) kd_loss 0.6729 (0.6260) acc 87.5000 (87.0312) gate/entropy 1.0032 (1.0063) gate/usage_max 0.5463 (0.5427) gate/usage_min 0.2216 (0.2231) gate/usage_std 0.1507 (0.1481) teacher/entropy 0.0116 (0.0207) teacher/usage_max 0.9049 (0.9572) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4060 (0.4418) nleep/row_max_mean 1553.9148 (1559.1367) nleep/row_max_std 55.8426 (57.9727) nleep/row_min_mean 1512.9535 (1515.7456) lr 1.9298e-03 eta 0:15:10
epoch [8/50] batch [120/173] time 0.145 (0.128) data 0.000 (0.003) loss 1.4591 (1.2257) teacher_loss 0.4846 (0.3224) loss_zs_kd 0.0074 (0.0073) loss_oracle 0.6125 (0.5461) kd_loss 0.6646 (0.6266) acc 81.2500 (87.4219) gate/entropy 1.0020 (1.0057) gate/usage_max 0.5477 (0.5434) gate/usage_min 0.2210 (0.2228) gate/usage_std 0.1516 (0.1486) teacher/entropy 0.0475 (0.0245) teacher/usage_max 0.8705 (0.9506) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.3835 (0.4373) nleep/row_max_mean 1538.9385 (1557.1767) nleep/row_max_std 64.5871 (59.0618) nleep/row_min_mean 1499.5906 (1514.4479) lr 1.9298e-03 eta 0:15:37
epoch [8/50] batch [140/173] time 0.132 (0.131) data 0.000 (0.003) loss 1.0402 (1.2161) teacher_loss 0.1170 (0.3125) loss_zs_kd 0.0084 (0.0074) loss_oracle 0.5428 (0.5437) kd_loss 0.6476 (0.6280) acc 96.8750 (88.0804) gate/entropy 1.0012 (1.0051) gate/usage_max 0.5486 (0.5441) gate/usage_min 0.2205 (0.2225) gate/usage_std 0.1523 (0.1491) teacher/entropy 0.0578 (0.0247) teacher/usage_max 0.8769 (0.9474) teacher/usage_min 0.0001 (0.0007) teacher/usage_std 0.3876 (0.4352) nleep/row_max_mean 1549.8030 (1555.6639) nleep/row_max_std 59.1652 (59.0364) nleep/row_min_mean 1513.0168 (1513.4905) lr 1.9298e-03 eta 0:15:58
epoch [8/50] batch [160/173] time 0.148 (0.134) data 0.000 (0.002) loss 1.0846 (1.2135) teacher_loss 0.1279 (0.3114) loss_zs_kd 0.0098 (0.0078) loss_oracle 0.5850 (0.5413) kd_loss 0.6593 (0.6276) acc 96.8750 (88.0469) gate/entropy 1.0002 (1.0045) gate/usage_max 0.5497 (0.5448) gate/usage_min 0.2201 (0.2222) gate/usage_std 0.1530 (0.1496) teacher/entropy 0.0528 (0.0258) teacher/usage_max 0.8671 (0.9454) teacher/usage_min 0.0001 (0.0007) teacher/usage_std 0.3813 (0.4338) nleep/row_max_mean 1549.0720 (1555.3082) nleep/row_max_std 57.5887 (59.1174) nleep/row_min_mean 1512.5465 (1513.5646) lr 1.9298e-03 eta 0:16:12
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,301
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.5%, epoch: 8 *******
******* Domain a best val test acc: 98.0%, epoch: 8 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [9/50] batch [20/173] time 0.181 (0.174) data 0.000 (0.016) loss 1.2246 (1.2591) teacher_loss 0.2515 (0.3028) loss_zs_kd 0.0051 (0.0134) loss_oracle 0.5969 (0.5690) kd_loss 0.6721 (0.6651) acc 90.6250 (87.6562) gate/entropy 0.9987 (0.9989) gate/usage_max 0.5514 (0.5511) gate/usage_min 0.2194 (0.2196) gate/usage_std 0.1542 (0.1541) teacher/entropy 0.0484 (0.0410) teacher/usage_max 0.8552 (0.8730) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.3737 (0.3859) nleep/row_max_mean 1548.7336 (1551.2820) nleep/row_max_std 60.0438 (61.5999) nleep/row_min_mean 1508.1968 (1512.7065) lr 1.9048e-03 eta 0:20:57
epoch [9/50] batch [40/173] time 0.165 (0.165) data 0.000 (0.008) loss 1.1312 (1.2544) teacher_loss 0.2560 (0.2994) loss_zs_kd 0.0113 (0.0126) loss_oracle 0.4590 (0.5530) kd_loss 0.6400 (0.6721) acc 90.6250 (88.5938) gate/entropy 0.9976 (0.9986) gate/usage_max 0.5526 (0.5515) gate/usage_min 0.2189 (0.2194) gate/usage_std 0.1551 (0.1544) teacher/entropy 0.0071 (0.0375) teacher/usage_max 0.9383 (0.8681) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4285 (0.3828) nleep/row_max_mean 1568.0078 (1555.1968) nleep/row_max_std 54.7188 (61.0109) nleep/row_min_mean 1525.3098 (1515.8054) lr 1.9048e-03 eta 0:19:51
epoch [9/50] batch [60/173] time 0.073 (0.137) data 0.001 (0.005) loss 1.2999 (1.2731) teacher_loss 0.2151 (0.2995) loss_zs_kd 0.0000 (0.0124) loss_oracle 0.6018 (0.5564) kd_loss 0.7839 (0.6892) acc 96.8750 (88.8542) gate/entropy 0.9978 (0.9983) gate/usage_max 0.5524 (0.5518) gate/usage_min 0.2188 (0.2192) gate/usage_std 0.1549 (0.1546) teacher/entropy 0.0661 (0.0414) teacher/usage_max 0.7067 (0.8437) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2899 (0.3685) nleep/row_max_mean 1547.3042 (1554.9158) nleep/row_max_std 66.7137 (61.6856) nleep/row_min_mean 1510.4901 (1515.3999) lr 1.9048e-03 eta 0:16:28
epoch [9/50] batch [80/173] time 0.076 (0.132) data 0.000 (0.004) loss 1.2853 (1.2817) teacher_loss 0.1353 (0.2943) loss_zs_kd 0.0059 (0.0120) loss_oracle 0.6761 (0.5636) kd_loss 0.8089 (0.6996) acc 93.7500 (89.1016) gate/entropy 0.9974 (0.9980) gate/usage_max 0.5528 (0.5521) gate/usage_min 0.2185 (0.2190) gate/usage_std 0.1552 (0.1547) teacher/entropy 0.0344 (0.0445) teacher/usage_max 0.7124 (0.8279) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2926 (0.3591) nleep/row_max_mean 1547.9326 (1554.6665) nleep/row_max_std 71.5995 (62.4672) nleep/row_min_mean 1511.5364 (1514.8476) lr 1.9048e-03 eta 0:15:47
epoch [9/50] batch [100/173] time 0.091 (0.130) data 0.000 (0.003) loss 1.3336 (1.3015) teacher_loss 0.2315 (0.3046) loss_zs_kd 0.0247 (0.0124) loss_oracle 0.5723 (0.5616) kd_loss 0.8036 (0.7099) acc 87.5000 (88.6562) gate/entropy 0.9969 (0.9978) gate/usage_max 0.5534 (0.5524) gate/usage_min 0.2180 (0.2188) gate/usage_std 0.1556 (0.1549) teacher/entropy 0.0461 (0.0481) teacher/usage_max 0.7055 (0.8118) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.2893 (0.3501) nleep/row_max_mean 1546.9369 (1554.4942) nleep/row_max_std 64.8893 (62.9462) nleep/row_min_mean 1507.7782 (1514.7037) lr 1.9048e-03 eta 0:15:28
epoch [9/50] batch [120/173] time 0.076 (0.128) data 0.000 (0.003) loss 1.2426 (1.3037) teacher_loss 0.2437 (0.2976) loss_zs_kd 0.0126 (0.0120) loss_oracle 0.5052 (0.5632) kd_loss 0.7401 (0.7186) acc 90.6250 (88.9062) gate/entropy 0.9963 (0.9976) gate/usage_max 0.5540 (0.5525) gate/usage_min 0.2175 (0.2187) gate/usage_std 0.1561 (0.1551) teacher/entropy 0.0635 (0.0512) teacher/usage_max 0.7596 (0.7981) teacher/usage_min 0.0283 (0.0014) teacher/usage_std 0.3106 (0.3427) nleep/row_max_mean 1553.1246 (1553.3272) nleep/row_max_std 58.0202 (62.8379) nleep/row_min_mean 1516.5566 (1513.7623) lr 1.9048e-03 eta 0:15:11
epoch [9/50] batch [140/173] time 0.088 (0.124) data 0.000 (0.002) loss 1.4936 (1.3033) teacher_loss 0.2482 (0.2928) loss_zs_kd 0.0099 (0.0120) loss_oracle 0.6641 (0.5607) kd_loss 0.9084 (0.7241) acc 87.5000 (88.9732) gate/entropy 0.9973 (0.9975) gate/usage_max 0.5529 (0.5527) gate/usage_min 0.2178 (0.2185) gate/usage_std 0.1553 (0.1552) teacher/entropy 0.0590 (0.0520) teacher/usage_max 0.5720 (0.7905) teacher/usage_min 0.0004 (0.0016) teacher/usage_std 0.2427 (0.3390) nleep/row_max_mean 1522.5837 (1552.1322) nleep/row_max_std 63.9686 (63.3949) nleep/row_min_mean 1490.8142 (1512.7060) lr 1.9048e-03 eta 0:14:43
epoch [9/50] batch [160/173] time 0.102 (0.123) data 0.000 (0.002) loss 1.3016 (1.3018) teacher_loss 0.2980 (0.2936) loss_zs_kd 0.0101 (0.0125) loss_oracle 0.5392 (0.5554) kd_loss 0.7290 (0.7243) acc 90.6250 (88.9844) gate/entropy 0.9968 (0.9974) gate/usage_max 0.5534 (0.5529) gate/usage_min 0.2174 (0.2184) gate/usage_std 0.1557 (0.1553) teacher/entropy 0.0409 (0.0525) teacher/usage_max 0.7953 (0.7896) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.3372 (0.3381) nleep/row_max_mean 1536.8176 (1550.7902) nleep/row_max_std 59.6930 (63.0734) nleep/row_min_mean 1498.6320 (1511.7659) lr 1.9048e-03 eta 0:14:33
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,297
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      96.5%, epoch: 8 *******
******* Domain a best val test acc: 98.0%, epoch: 8 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [10/50] batch [20/173] time 0.171 (0.166) data 0.000 (0.014) loss 1.3207 (1.3011) teacher_loss 0.1825 (0.2928) loss_zs_kd 0.0202 (0.0161) loss_oracle 0.6722 (0.5621) kd_loss 0.7920 (0.7192) acc 93.7500 (88.2812) gate/entropy 0.9952 (0.9955) gate/usage_max 0.5552 (0.5548) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1570 (0.1567) teacher/entropy 0.0428 (0.0637) teacher/usage_max 0.7205 (0.7799) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.2966 (0.3292) nleep/row_max_mean 1537.3672 (1545.6984) nleep/row_max_std 64.8779 (65.2403) nleep/row_min_mean 1500.2712 (1508.0278) lr 1.8763e-03 eta 0:19:30
epoch [10/50] batch [40/173] time 0.164 (0.162) data 0.000 (0.007) loss 1.1989 (1.2568) teacher_loss 0.1914 (0.2671) loss_zs_kd 0.0000 (0.0144) loss_oracle 0.5558 (0.5485) kd_loss 0.7296 (0.7082) acc 90.6250 (89.2969) gate/entropy 0.9948 (0.9953) gate/usage_max 0.5557 (0.5551) gate/usage_min 0.2165 (0.2168) gate/usage_std 0.1573 (0.1569) teacher/entropy 0.0382 (0.0585) teacher/usage_max 0.7969 (0.7982) teacher/usage_min 0.0001 (0.0048) teacher/usage_std 0.3381 (0.3399) nleep/row_max_mean 1559.0793 (1547.4930) nleep/row_max_std 48.6786 (63.8664) nleep/row_min_mean 1518.5364 (1509.7010) lr 1.8763e-03 eta 0:19:05
epoch [10/50] batch [60/173] time 0.160 (0.162) data 0.001 (0.005) loss 1.4228 (1.2860) teacher_loss 0.3634 (0.2790) loss_zs_kd 0.0225 (0.0150) loss_oracle 0.6524 (0.5753) kd_loss 0.7220 (0.7118) acc 84.3750 (88.8542) gate/entropy 0.9951 (0.9951) gate/usage_max 0.5553 (0.5553) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1570 (0.1570) teacher/entropy 0.0322 (0.0555) teacher/usage_max 0.8111 (0.7973) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3465 (0.3397) nleep/row_max_mean 1536.9812 (1547.3204) nleep/row_max_std 59.0554 (62.0524) nleep/row_min_mean 1499.5146 (1509.8140) lr 1.8763e-03 eta 0:18:56
epoch [10/50] batch [80/173] time 0.142 (0.160) data 0.000 (0.004) loss 1.7010 (1.3230) teacher_loss 0.5746 (0.2828) loss_zs_kd 0.0115 (0.0149) loss_oracle 0.7028 (0.6109) kd_loss 0.7693 (0.7273) acc 78.1250 (88.8672) gate/entropy 0.9950 (0.9950) gate/usage_max 0.5554 (0.5554) gate/usage_min 0.2162 (0.2166) gate/usage_std 0.1571 (0.1571) teacher/entropy 0.0700 (0.0524) teacher/usage_max 0.7147 (0.7832) teacher/usage_min 0.0010 (0.0052) teacher/usage_std 0.2934 (0.3321) nleep/row_max_mean 1539.2289 (1547.4038) nleep/row_max_std 65.9726 (60.7854) nleep/row_min_mean 1506.3682 (1509.9626) lr 1.8763e-03 eta 0:18:44
epoch [10/50] batch [100/173] time 0.166 (0.161) data 0.000 (0.003) loss 1.4284 (1.3348) teacher_loss 0.2977 (0.2848) loss_zs_kd 0.0092 (0.0153) loss_oracle 0.5449 (0.6082) kd_loss 0.8536 (0.7382) acc 87.5000 (88.9062) gate/entropy 0.9939 (0.9949) gate/usage_max 0.5566 (0.5555) gate/usage_min 0.2156 (0.2164) gate/usage_std 0.1580 (0.1572) teacher/entropy 0.0384 (0.0507) teacher/usage_max 0.6567 (0.7727) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.2682 (0.3267) nleep/row_max_mean 1557.0687 (1547.7720) nleep/row_max_std 56.2832 (60.0151) nleep/row_min_mean 1521.3396 (1510.4478) lr 1.8763e-03 eta 0:18:48
epoch [10/50] batch [120/173] time 0.168 (0.161) data 0.000 (0.003) loss 1.4015 (1.3304) teacher_loss 0.4498 (0.2786) loss_zs_kd 0.0194 (0.0155) loss_oracle 0.5311 (0.5985) kd_loss 0.6764 (0.7448) acc 81.2500 (89.3229) gate/entropy 0.9940 (0.9948) gate/usage_max 0.5564 (0.5556) gate/usage_min 0.2155 (0.2163) gate/usage_std 0.1578 (0.1572) teacher/entropy 0.0357 (0.0511) teacher/usage_max 0.8569 (0.7646) teacher/usage_min 0.0001 (0.0057) teacher/usage_std 0.3748 (0.3223) nleep/row_max_mean 1563.1729 (1547.6894) nleep/row_max_std 68.9360 (60.5640) nleep/row_min_mean 1524.9452 (1510.5581) lr 1.8763e-03 eta 0:18:40
epoch [10/50] batch [140/173] time 0.168 (0.161) data 0.000 (0.002) loss 1.4663 (1.3386) teacher_loss 0.2141 (0.2849) loss_zs_kd 0.0154 (0.0156) loss_oracle 0.6536 (0.5948) kd_loss 0.9178 (0.7484) acc 93.7500 (88.9732) gate/entropy 0.9944 (0.9948) gate/usage_max 0.5560 (0.5556) gate/usage_min 0.2154 (0.2162) gate/usage_std 0.1576 (0.1573) teacher/entropy 0.0281 (0.0539) teacher/usage_max 0.5954 (0.7573) teacher/usage_min 0.0001 (0.0062) teacher/usage_std 0.2482 (0.3182) nleep/row_max_mean 1545.8230 (1547.2380) nleep/row_max_std 59.8097 (61.5193) nleep/row_min_mean 1515.0142 (1510.4126) lr 1.8763e-03 eta 0:18:37
epoch [10/50] batch [160/173] time 0.091 (0.154) data 0.000 (0.002) loss 1.3018 (1.3242) teacher_loss 0.2289 (0.2742) loss_zs_kd 0.0208 (0.0149) loss_oracle 0.6294 (0.5897) kd_loss 0.7479 (0.7477) acc 93.7500 (89.3750) gate/entropy 0.9950 (0.9948) gate/usage_max 0.5554 (0.5557) gate/usage_min 0.2155 (0.2161) gate/usage_std 0.1571 (0.1573) teacher/entropy 0.0373 (0.0558) teacher/usage_max 0.7754 (0.7559) teacher/usage_min 0.0159 (0.0073) teacher/usage_std 0.3224 (0.3170) nleep/row_max_mean 1553.9084 (1547.9527) nleep/row_max_std 68.5622 (61.9110) nleep/row_min_mean 1513.8726 (1511.0977) lr 1.8763e-03 eta 0:17:46
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,299
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.5%, epoch: 8 *******
******* Domain a best val test acc: 98.0%, epoch: 8 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [11/50] batch [20/173] time 0.106 (0.116) data 0.000 (0.016) loss 1.0575 (1.2783) teacher_loss 0.1535 (0.2839) loss_zs_kd 0.0030 (0.0148) loss_oracle 0.4705 (0.5630) kd_loss 0.6673 (0.7056) acc 93.7500 (89.0625) gate/entropy 0.9940 (0.9943) gate/usage_max 0.5564 (0.5561) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1578 (0.1576) teacher/entropy 0.0562 (0.0610) teacher/usage_max 0.8466 (0.7975) teacher/usage_min 0.0298 (0.0244) teacher/usage_std 0.3650 (0.3362) nleep/row_max_mean 1564.5901 (1552.7510) nleep/row_max_std 60.3567 (62.6032) nleep/row_min_mean 1527.5703 (1514.8084) lr 1.8443e-03 eta 0:13:18
epoch [11/50] batch [40/173] time 0.089 (0.117) data 0.000 (0.008) loss 1.2395 (1.2969) teacher_loss 0.2618 (0.2878) loss_zs_kd 0.0084 (0.0140) loss_oracle 0.5469 (0.5623) kd_loss 0.7001 (0.7210) acc 90.6250 (88.7500) gate/entropy 0.9942 (0.9942) gate/usage_max 0.5562 (0.5562) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1577 (0.1577) teacher/entropy 0.0216 (0.0557) teacher/usage_max 0.8458 (0.7859) teacher/usage_min 0.0003 (0.0231) teacher/usage_std 0.3677 (0.3294) nleep/row_max_mean 1558.5344 (1552.2735) nleep/row_max_std 68.5188 (63.1412) nleep/row_min_mean 1518.2534 (1514.2573) lr 1.8443e-03 eta 0:13:26
epoch [11/50] batch [60/173] time 0.094 (0.116) data 0.001 (0.006) loss 1.2869 (1.2953) teacher_loss 0.3520 (0.2885) loss_zs_kd 0.0194 (0.0147) loss_oracle 0.4708 (0.5563) kd_loss 0.6898 (0.7213) acc 84.3750 (88.8021) gate/entropy 0.9934 (0.9941) gate/usage_max 0.5571 (0.5564) gate/usage_min 0.2146 (0.2149) gate/usage_std 0.1583 (0.1578) teacher/entropy 0.0766 (0.0562) teacher/usage_max 0.7975 (0.7849) teacher/usage_min 0.0303 (0.0218) teacher/usage_std 0.3333 (0.3290) nleep/row_max_mean 1558.2739 (1551.9626) nleep/row_max_std 65.4430 (63.3220) nleep/row_min_mean 1517.7410 (1513.6945) lr 1.8443e-03 eta 0:13:18
epoch [11/50] batch [80/173] time 0.066 (0.120) data 0.000 (0.004) loss 1.2594 (1.2913) teacher_loss 0.1386 (0.2872) loss_zs_kd 0.0071 (0.0149) loss_oracle 0.6691 (0.5459) kd_loss 0.7828 (0.7237) acc 93.7500 (88.9062) gate/entropy 0.9935 (0.9940) gate/usage_max 0.5569 (0.5565) gate/usage_min 0.2146 (0.2149) gate/usage_std 0.1582 (0.1579) teacher/entropy 0.0580 (0.0561) teacher/usage_max 0.7127 (0.7824) teacher/usage_min 0.0029 (0.0250) teacher/usage_std 0.2918 (0.3268) nleep/row_max_mean 1551.6658 (1551.2825) nleep/row_max_std 60.5965 (63.3057) nleep/row_min_mean 1516.2220 (1513.3004) lr 1.8443e-03 eta 0:13:39
epoch [11/50] batch [100/173] time 0.161 (0.119) data 0.000 (0.003) loss 1.0889 (1.2863) teacher_loss 0.2271 (0.2865) loss_zs_kd 0.0220 (0.0145) loss_oracle 0.5433 (0.5455) kd_loss 0.5792 (0.7198) acc 87.5000 (88.7812) gate/entropy 0.9933 (0.9939) gate/usage_max 0.5572 (0.5566) gate/usage_min 0.2145 (0.2148) gate/usage_std 0.1584 (0.1580) teacher/entropy 0.0381 (0.0560) teacher/usage_max 0.9637 (0.7867) teacher/usage_min 0.0123 (0.0247) teacher/usage_std 0.4458 (0.3294) nleep/row_max_mean 1556.9062 (1551.4643) nleep/row_max_std 82.4381 (63.2482) nleep/row_min_mean 1514.8739 (1513.7408) lr 1.8443e-03 eta 0:13:30
epoch [11/50] batch [120/173] time 0.148 (0.123) data 0.000 (0.003) loss 1.4065 (1.2903) teacher_loss 0.3703 (0.2904) loss_zs_kd 0.0229 (0.0156) loss_oracle 0.6287 (0.5485) kd_loss 0.7104 (0.7178) acc 84.3750 (88.8542) gate/entropy 0.9923 (0.9937) gate/usage_max 0.5583 (0.5567) gate/usage_min 0.2142 (0.2147) gate/usage_std 0.1592 (0.1581) teacher/entropy 0.0290 (0.0579) teacher/usage_max 0.8268 (0.7869) teacher/usage_min 0.0315 (0.0270) teacher/usage_std 0.3518 (0.3290) nleep/row_max_mean 1571.0890 (1550.6902) nleep/row_max_std 56.3687 (63.6738) nleep/row_min_mean 1530.3027 (1513.2194) lr 1.8443e-03 eta 0:13:55
epoch [11/50] batch [140/173] time 0.129 (0.125) data 0.000 (0.003) loss 1.2956 (1.2902) teacher_loss 0.3377 (0.2914) loss_zs_kd 0.0133 (0.0160) loss_oracle 0.5262 (0.5475) kd_loss 0.6882 (0.7171) acc 90.6250 (88.8170) gate/entropy 0.9924 (0.9936) gate/usage_max 0.5582 (0.5568) gate/usage_min 0.2142 (0.2147) gate/usage_std 0.1591 (0.1581) teacher/entropy 0.0318 (0.0585) teacher/usage_max 0.8486 (0.7870) teacher/usage_min 0.0312 (0.0281) teacher/usage_std 0.3661 (0.3290) nleep/row_max_mean 1559.1046 (1549.5895) nleep/row_max_std 58.4370 (63.4749) nleep/row_min_mean 1520.4463 (1512.3680) lr 1.8443e-03 eta 0:14:09
epoch [11/50] batch [160/173] time 0.127 (0.128) data 0.000 (0.002) loss 1.2492 (1.2863) teacher_loss 0.2264 (0.2878) loss_zs_kd 0.0142 (0.0160) loss_oracle 0.5474 (0.5468) kd_loss 0.7420 (0.7171) acc 96.8750 (88.9453) gate/entropy 0.9926 (0.9935) gate/usage_max 0.5579 (0.5570) gate/usage_min 0.2142 (0.2146) gate/usage_std 0.1589 (0.1582) teacher/entropy 0.0430 (0.0588) teacher/usage_max 0.7781 (0.7866) teacher/usage_min 0.0605 (0.0290) teacher/usage_std 0.3172 (0.3287) nleep/row_max_mean 1567.3862 (1549.1713) nleep/row_max_std 63.3281 (63.9438) nleep/row_min_mean 1524.6150 (1512.0002) lr 1.8443e-03 eta 0:14:25
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,308
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [12/50] batch [20/173] time 0.150 (0.152) data 0.000 (0.013) loss 1.3671 (1.2983) teacher_loss 0.3193 (0.2918) loss_zs_kd 0.0211 (0.0199) loss_oracle 0.5550 (0.5272) kd_loss 0.7598 (0.7329) acc 90.6250 (88.5938) gate/entropy 0.9928 (0.9922) gate/usage_max 0.5577 (0.5584) gate/usage_min 0.2143 (0.2141) gate/usage_std 0.1588 (0.1592) teacher/entropy 0.0745 (0.0429) teacher/usage_max 0.7232 (0.7869) teacher/usage_min 0.0869 (0.0511) teacher/usage_std 0.2789 (0.3245) nleep/row_max_mean 1540.8282 (1552.3377) nleep/row_max_std 73.7350 (62.3556) nleep/row_min_mean 1503.2151 (1515.2194) lr 1.8090e-03 eta 0:17:05
epoch [12/50] batch [40/173] time 0.119 (0.144) data 0.000 (0.006) loss 1.3435 (1.2877) teacher_loss 0.2714 (0.2778) loss_zs_kd 0.0161 (0.0177) loss_oracle 0.5431 (0.5335) kd_loss 0.7924 (0.7343) acc 93.7500 (89.2969) gate/entropy 0.9919 (0.9921) gate/usage_max 0.5587 (0.5585) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1594 (0.1593) teacher/entropy 0.0174 (0.0498) teacher/usage_max 0.7502 (0.7781) teacher/usage_min 0.0669 (0.0564) teacher/usage_std 0.2985 (0.3183) nleep/row_max_mean 1535.4146 (1552.0712) nleep/row_max_std 68.5501 (63.3507) nleep/row_min_mean 1505.4211 (1515.9879) lr 1.8090e-03 eta 0:16:07
epoch [12/50] batch [60/173] time 0.091 (0.135) data 0.001 (0.004) loss 1.3636 (1.2779) teacher_loss 0.4102 (0.2617) loss_zs_kd 0.0121 (0.0170) loss_oracle 0.4550 (0.5438) kd_loss 0.7198 (0.7358) acc 84.3750 (90.0000) gate/entropy 0.9918 (0.9920) gate/usage_max 0.5588 (0.5586) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1595 (0.1594) teacher/entropy 0.0244 (0.0511) teacher/usage_max 0.8201 (0.7746) teacher/usage_min 0.0318 (0.0511) teacher/usage_std 0.3474 (0.3176) nleep/row_max_mean 1553.0000 (1550.8727) nleep/row_max_std 64.9966 (63.9420) nleep/row_min_mean 1516.5010 (1515.5197) lr 1.8090e-03 eta 0:15:02
epoch [12/50] batch [80/173] time 0.083 (0.127) data 0.000 (0.003) loss 1.2437 (1.2736) teacher_loss 0.2435 (0.2618) loss_zs_kd 0.0142 (0.0181) loss_oracle 0.5312 (0.5368) kd_loss 0.7275 (0.7344) acc 90.6250 (90.1953) gate/entropy 0.9914 (0.9919) gate/usage_max 0.5593 (0.5587) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1598 (0.1595) teacher/entropy 0.0880 (0.0537) teacher/usage_max 0.7424 (0.7730) teacher/usage_min 0.0816 (0.0500) teacher/usage_std 0.2918 (0.3169) nleep/row_max_mean 1546.8530 (1551.1183) nleep/row_max_std 69.6988 (64.3788) nleep/row_min_mean 1514.9954 (1515.9602) lr 1.8090e-03 eta 0:14:07
epoch [12/50] batch [100/173] time 0.148 (0.125) data 0.000 (0.003) loss 1.3790 (1.2760) teacher_loss 0.2908 (0.2606) loss_zs_kd 0.0418 (0.0186) loss_oracle 0.5774 (0.5370) kd_loss 0.7786 (0.7375) acc 93.7500 (90.3438) gate/entropy 0.9913 (0.9918) gate/usage_max 0.5594 (0.5588) gate/usage_min 0.2138 (0.2140) gate/usage_std 0.1599 (0.1595) teacher/entropy 0.0810 (0.0572) teacher/usage_max 0.6951 (0.7657) teacher/usage_min 0.0620 (0.0528) teacher/usage_std 0.2662 (0.3121) nleep/row_max_mean 1540.1243 (1550.5450) nleep/row_max_std 60.6503 (64.6236) nleep/row_min_mean 1509.7432 (1515.7372) lr 1.8090e-03 eta 0:13:53
epoch [12/50] batch [120/173] time 0.079 (0.121) data 0.000 (0.002) loss 1.3590 (1.2797) teacher_loss 0.2419 (0.2535) loss_zs_kd 0.0270 (0.0188) loss_oracle 0.5296 (0.5409) kd_loss 0.8388 (0.7463) acc 90.6250 (90.4427) gate/entropy 0.9913 (0.9918) gate/usage_max 0.5594 (0.5589) gate/usage_min 0.2137 (0.2140) gate/usage_std 0.1599 (0.1596) teacher/entropy 0.0213 (0.0601) teacher/usage_max 0.6913 (0.7527) teacher/usage_min 0.0262 (0.0543) teacher/usage_std 0.2739 (0.3043) nleep/row_max_mean 1551.0054 (1550.3396) nleep/row_max_std 60.9104 (64.3609) nleep/row_min_mean 1514.2380 (1515.8255) lr 1.8090e-03 eta 0:13:18
epoch [12/50] batch [140/173] time 0.085 (0.119) data 0.000 (0.002) loss 1.2130 (1.2812) teacher_loss 0.2133 (0.2578) loss_zs_kd 0.0196 (0.0192) loss_oracle 0.5186 (0.5382) kd_loss 0.7306 (0.7447) acc 93.7500 (90.2679) gate/entropy 0.9914 (0.9917) gate/usage_max 0.5593 (0.5590) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1599 (0.1596) teacher/entropy 0.0882 (0.0633) teacher/usage_max 0.7417 (0.7510) teacher/usage_min 0.0813 (0.0569) teacher/usage_std 0.2914 (0.3030) nleep/row_max_mean 1539.0027 (1550.8292) nleep/row_max_std 69.0579 (64.0967) nleep/row_min_mean 1511.4277 (1516.4461) lr 1.8090e-03 eta 0:13:08
epoch [12/50] batch [160/173] time 0.076 (0.117) data 0.000 (0.002) loss 1.1003 (1.2843) teacher_loss 0.0149 (0.2579) loss_zs_kd 0.0116 (0.0201) loss_oracle 0.5565 (0.5386) kd_loss 0.8013 (0.7471) acc 100.0000 (90.2930) gate/entropy 0.9913 (0.9916) gate/usage_max 0.5594 (0.5590) gate/usage_min 0.2137 (0.2139) gate/usage_std 0.1599 (0.1597) teacher/entropy 0.0785 (0.0658) teacher/usage_max 0.6711 (0.7458) teacher/usage_min 0.0692 (0.0612) teacher/usage_std 0.2512 (0.2991) nleep/row_max_mean 1548.7893 (1550.3262) nleep/row_max_std 66.1210 (63.6918) nleep/row_min_mean 1515.7800 (1516.2837) lr 1.8090e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [13/50] batch [20/173] time 0.163 (0.159) data 0.000 (0.014) loss 1.4138 (1.3376) teacher_loss 0.3424 (0.2959) loss_zs_kd 0.0204 (0.0214) loss_oracle 0.5874 (0.5491) kd_loss 0.7675 (0.7564) acc 81.2500 (88.9062) gate/entropy 0.9909 (0.9908) gate/usage_max 0.5598 (0.5600) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1602 (0.1603) teacher/entropy 0.0760 (0.0581) teacher/usage_max 0.7087 (0.7426) teacher/usage_min 0.0446 (0.0500) teacher/usage_std 0.2779 (0.2987) nleep/row_max_mean 1560.6898 (1552.8667) nleep/row_max_std 63.2031 (61.3219) nleep/row_min_mean 1523.5632 (1517.7961) lr 1.7705e-03 eta 0:17:21
epoch [13/50] batch [40/173] time 0.166 (0.156) data 0.000 (0.007) loss 1.1419 (1.3225) teacher_loss 0.1133 (0.2742) loss_zs_kd 0.0101 (0.0208) loss_oracle 0.5311 (0.5494) kd_loss 0.7580 (0.7632) acc 96.8750 (89.7656) gate/entropy 0.9910 (0.9907) gate/usage_max 0.5596 (0.5600) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1601 (0.1604) teacher/entropy 0.0283 (0.0521) teacher/usage_max 0.7751 (0.7415) teacher/usage_min 0.0608 (0.0472) teacher/usage_std 0.3152 (0.2988) nleep/row_max_mean 1550.4873 (1552.9257) nleep/row_max_std 87.8058 (64.2276) nleep/row_min_mean 1512.6162 (1516.6306) lr 1.7705e-03 eta 0:17:00
epoch [13/50] batch [60/173] time 0.166 (0.152) data 0.001 (0.005) loss 1.2659 (1.3161) teacher_loss 0.3560 (0.2668) loss_zs_kd 0.0073 (0.0198) loss_oracle 0.4604 (0.5483) kd_loss 0.6761 (0.7653) acc 90.6250 (90.2083) gate/entropy 0.9904 (0.9907) gate/usage_max 0.5604 (0.5601) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1606 (0.1604) teacher/entropy 0.0905 (0.0507) teacher/usage_max 0.7928 (0.7416) teacher/usage_min 0.0007 (0.0456) teacher/usage_std 0.3356 (0.3001) nleep/row_max_mean 1542.4521 (1552.4134) nleep/row_max_std 72.9273 (64.8292) nleep/row_min_mean 1509.5498 (1515.8596) lr 1.7705e-03 eta 0:16:31
epoch [13/50] batch [80/173] time 0.145 (0.150) data 0.000 (0.004) loss 1.2844 (1.3091) teacher_loss 0.1258 (0.2595) loss_zs_kd 0.0572 (0.0210) loss_oracle 0.5241 (0.5437) kd_loss 0.8680 (0.7673) acc 96.8750 (90.5859) gate/entropy 0.9903 (0.9906) gate/usage_max 0.5605 (0.5601) gate/usage_min 0.2134 (0.2136) gate/usage_std 0.1607 (0.1604) teacher/entropy 0.0270 (0.0523) teacher/usage_max 0.6539 (0.7375) teacher/usage_min 0.0602 (0.0464) teacher/usage_std 0.2447 (0.2972) nleep/row_max_mean 1538.9697 (1551.5288) nleep/row_max_std 59.8023 (64.5551) nleep/row_min_mean 1508.5061 (1515.1809) lr 1.7705e-03 eta 0:16:12
epoch [13/50] batch [100/173] time 0.153 (0.148) data 0.000 (0.003) loss 1.2941 (1.3148) teacher_loss 0.2013 (0.2550) loss_zs_kd 0.0085 (0.0210) loss_oracle 0.6042 (0.5521) kd_loss 0.7865 (0.7732) acc 93.7500 (90.6875) gate/entropy 0.9906 (0.9905) gate/usage_max 0.5602 (0.5602) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1605 (0.1605) teacher/entropy 0.0759 (0.0532) teacher/usage_max 0.6906 (0.7299) teacher/usage_min 0.0705 (0.0483) teacher/usage_std 0.2618 (0.2926) nleep/row_max_mean 1532.1711 (1550.8359) nleep/row_max_std 70.8686 (64.4675) nleep/row_min_mean 1498.6487 (1514.7267) lr 1.7705e-03 eta 0:16:00
epoch [13/50] batch [120/173] time 0.164 (0.148) data 0.000 (0.002) loss 1.4611 (1.3175) teacher_loss 0.4359 (0.2534) loss_zs_kd 0.0617 (0.0224) loss_oracle 0.5408 (0.5571) kd_loss 0.7239 (0.7743) acc 78.1250 (90.8073) gate/entropy 0.9898 (0.9905) gate/usage_max 0.5610 (0.5603) gate/usage_min 0.2132 (0.2135) gate/usage_std 0.1611 (0.1606) teacher/entropy 0.0340 (0.0554) teacher/usage_max 0.8032 (0.7262) teacher/usage_min 0.0347 (0.0499) teacher/usage_std 0.3363 (0.2899) nleep/row_max_mean 1571.3228 (1551.0637) nleep/row_max_std 44.5162 (64.3536) nleep/row_min_mean 1530.3721 (1514.8379) lr 1.7705e-03 eta 0:15:57
epoch [13/50] batch [140/173] time 0.140 (0.148) data 0.000 (0.002) loss 1.3789 (1.3233) teacher_loss 0.2916 (0.2559) loss_zs_kd 0.0350 (0.0231) loss_oracle 0.5212 (0.5584) kd_loss 0.8093 (0.7767) acc 87.5000 (90.5357) gate/entropy 0.9905 (0.9904) gate/usage_max 0.5602 (0.5603) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1605 (0.1606) teacher/entropy 0.0444 (0.0554) teacher/usage_max 0.6985 (0.7234) teacher/usage_min 0.0313 (0.0485) teacher/usage_std 0.2760 (0.2887) nleep/row_max_mean 1538.8408 (1550.8227) nleep/row_max_std 57.3786 (64.6431) nleep/row_min_mean 1506.0052 (1514.4734) lr 1.7705e-03 eta 0:15:50
epoch [13/50] batch [160/173] time 0.148 (0.148) data 0.000 (0.002) loss 1.3193 (1.3222) teacher_loss 0.1286 (0.2511) loss_zs_kd 0.0165 (0.0229) loss_oracle 0.6440 (0.5588) kd_loss 0.8603 (0.7802) acc 96.8750 (90.7617) gate/entropy 0.9901 (0.9904) gate/usage_max 0.5606 (0.5603) gate/usage_min 0.2132 (0.2134) gate/usage_std 0.1608 (0.1606) teacher/entropy 0.0866 (0.0572) teacher/usage_max 0.5936 (0.7174) teacher/usage_min 0.0196 (0.0476) teacher/usage_std 0.2374 (0.2858) nleep/row_max_mean 1558.4169 (1551.1910) nleep/row_max_std 52.8114 (64.4933) nleep/row_min_mean 1523.2041 (1514.9094) lr 1.7705e-03 eta 0:15:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,308
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [14/50] batch [20/173] time 0.096 (0.121) data 0.001 (0.016) loss 1.3046 (1.3175) teacher_loss 0.0375 (0.2121) loss_zs_kd 0.0156 (0.0257) loss_oracle 0.6661 (0.5630) kd_loss 0.9263 (0.8111) acc 100.0000 (91.7188) gate/entropy 0.9904 (0.9900) gate/usage_max 0.5604 (0.5608) gate/usage_min 0.2133 (0.2132) gate/usage_std 0.1606 (0.1609) teacher/entropy 0.0479 (0.0575) teacher/usage_max 0.5665 (0.6836) teacher/usage_min 0.0891 (0.0667) teacher/usage_std 0.1951 (0.2606) nleep/row_max_mean 1543.4089 (1549.3178) nleep/row_max_std 63.5541 (58.9658) nleep/row_min_mean 1507.5498 (1513.2620) lr 1.7290e-03 eta 0:12:52
epoch [14/50] batch [40/173] time 0.077 (0.118) data 0.000 (0.008) loss 1.3457 (1.3436) teacher_loss 0.0593 (0.2248) loss_zs_kd 0.0068 (0.0281) loss_oracle 0.6231 (0.5617) kd_loss 0.9714 (0.8240) acc 96.8750 (90.8594) gate/entropy 0.9903 (0.9899) gate/usage_max 0.5604 (0.5609) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1606 (0.1610) teacher/entropy 0.0441 (0.0569) teacher/usage_max 0.5295 (0.6725) teacher/usage_min 0.1804 (0.0864) teacher/usage_std 0.1458 (0.2508) nleep/row_max_mean 1536.5488 (1549.5833) nleep/row_max_std 56.3938 (57.4935) nleep/row_min_mean 1506.3514 (1514.1786) lr 1.7290e-03 eta 0:12:27
epoch [14/50] batch [60/173] time 0.109 (0.116) data 0.001 (0.005) loss 1.2448 (1.3493) teacher_loss 0.2322 (0.2246) loss_zs_kd 0.0084 (0.0283) loss_oracle 0.4802 (0.5593) kd_loss 0.7683 (0.8309) acc 90.6250 (91.1979) gate/entropy 0.9896 (0.9899) gate/usage_max 0.5612 (0.5609) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1612 (0.1610) teacher/entropy 0.0394 (0.0602) teacher/usage_max 0.7550 (0.6625) teacher/usage_min 0.1162 (0.1003) teacher/usage_std 0.2982 (0.2433) nleep/row_max_mean 1553.6311 (1547.2596) nleep/row_max_std 46.8069 (57.3103) nleep/row_min_mean 1517.8032 (1512.1949) lr 1.7290e-03 eta 0:12:17
epoch [14/50] batch [80/173] time 0.089 (0.118) data 0.000 (0.004) loss 1.6039 (1.3607) teacher_loss 0.3287 (0.2263) loss_zs_kd 0.0285 (0.0279) loss_oracle 0.6417 (0.5618) kd_loss 0.9401 (0.8396) acc 87.5000 (91.2109) gate/entropy 0.9899 (0.9899) gate/usage_max 0.5609 (0.5609) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1610 (0.1610) teacher/entropy 0.0743 (0.0572) teacher/usage_max 0.5327 (0.6569) teacher/usage_min 0.2203 (0.1129) teacher/usage_std 0.1414 (0.2372) nleep/row_max_mean 1538.5071 (1548.2893) nleep/row_max_std 67.7772 (57.3060) nleep/row_min_mean 1506.3108 (1512.7722) lr 1.7290e-03 eta 0:12:25
epoch [14/50] batch [100/173] time 0.071 (0.118) data 0.000 (0.003) loss 1.3216 (1.3764) teacher_loss 0.1405 (0.2253) loss_zs_kd 0.0258 (0.0294) loss_oracle 0.5442 (0.5761) kd_loss 0.8961 (0.8483) acc 93.7500 (91.1875) gate/entropy 0.9898 (0.9899) gate/usage_max 0.5610 (0.5609) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1611 (0.1610) teacher/entropy 0.1241 (0.0615) teacher/usage_max 0.5312 (0.6436) teacher/usage_min 0.1954 (0.1215) teacher/usage_std 0.1435 (0.2275) nleep/row_max_mean 1549.4617 (1547.9447) nleep/row_max_std 53.0771 (57.6746) nleep/row_min_mean 1520.7289 (1512.4498) lr 1.7290e-03 eta 0:12:25
epoch [14/50] batch [120/173] time 0.133 (0.119) data 0.000 (0.003) loss 1.4822 (1.3953) teacher_loss 0.2446 (0.2264) loss_zs_kd 0.0240 (0.0303) loss_oracle 0.5435 (0.5831) kd_loss 0.9539 (0.8621) acc 87.5000 (91.1979) gate/entropy 0.9891 (0.9898) gate/usage_max 0.5617 (0.5609) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1616 (0.1610) teacher/entropy 0.0483 (0.0608) teacher/usage_max 0.5578 (0.6302) teacher/usage_min 0.0590 (0.1306) teacher/usage_std 0.2066 (0.2179) nleep/row_max_mean 1581.7151 (1548.9595) nleep/row_max_std 32.0139 (57.5345) nleep/row_min_mean 1545.3989 (1513.4635) lr 1.7290e-03 eta 0:12:25
epoch [14/50] batch [140/173] time 0.150 (0.123) data 0.000 (0.002) loss 1.5830 (1.4033) teacher_loss 0.3824 (0.2281) loss_zs_kd 0.0365 (0.0303) loss_oracle 0.5541 (0.5867) kd_loss 0.9053 (0.8667) acc 87.5000 (91.0714) gate/entropy 0.9894 (0.9898) gate/usage_max 0.5614 (0.5609) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1613 (0.1610) teacher/entropy 0.0195 (0.0604) teacher/usage_max 0.6271 (0.6261) teacher/usage_min 0.1573 (0.1333) teacher/usage_std 0.2091 (0.2150) nleep/row_max_mean 1564.9719 (1549.6719) nleep/row_max_std 59.6292 (58.0317) nleep/row_min_mean 1526.0325 (1513.9267) lr 1.7290e-03 eta 0:12:51
epoch [14/50] batch [160/173] time 0.135 (0.127) data 0.000 (0.002) loss 1.3953 (1.4235) teacher_loss 0.1519 (0.2276) loss_zs_kd 0.0332 (0.0304) loss_oracle 0.6355 (0.5955) kd_loss 0.9090 (0.8829) acc 100.0000 (91.2109) gate/entropy 0.9899 (0.9898) gate/usage_max 0.5608 (0.5609) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1610 (0.1610) teacher/entropy 0.0181 (0.0569) teacher/usage_max 0.6258 (0.6142) teacher/usage_min 0.1840 (0.1343) teacher/usage_std 0.2068 (0.2088) nleep/row_max_mean 1563.0969 (1550.3975) nleep/row_max_std 63.8198 (57.6688) nleep/row_min_mean 1525.3164 (1514.5502) lr 1.7290e-03 eta 0:13:11
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [15/50] batch [20/173] time 0.165 (0.179) data 0.000 (0.014) loss 1.6412 (1.5662) teacher_loss 0.3003 (0.2114) loss_zs_kd 0.0418 (0.0299) loss_oracle 0.7981 (0.7790) kd_loss 0.9210 (0.9503) acc 90.6250 (91.8750) gate/entropy 0.9904 (0.9903) gate/usage_max 0.5603 (0.5604) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1606 (0.1607) teacher/entropy 0.0798 (0.0642) teacher/usage_max 0.5422 (0.5339) teacher/usage_min 0.1496 (0.1889) teacher/usage_std 0.1613 (0.1486) nleep/row_max_mean 1548.4912 (1552.5423) nleep/row_max_std 63.8869 (60.5633) nleep/row_min_mean 1511.9509 (1515.5825) lr 1.6845e-03 eta 0:18:29
epoch [15/50] batch [40/173] time 0.156 (0.168) data 0.000 (0.007) loss 1.6411 (1.5555) teacher_loss 0.1808 (0.2073) loss_zs_kd 0.0432 (0.0307) loss_oracle 0.9493 (0.7677) kd_loss 0.9640 (0.9490) acc 93.7500 (91.8750) gate/entropy 0.9906 (0.9904) gate/usage_max 0.5600 (0.5603) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1604 (0.1606) teacher/entropy 0.1049 (0.0657) teacher/usage_max 0.4695 (0.5325) teacher/usage_min 0.1769 (0.1876) teacher/usage_std 0.1203 (0.1489) nleep/row_max_mean 1557.4871 (1552.6389) nleep/row_max_std 58.7888 (60.5040) nleep/row_min_mean 1520.7816 (1516.1422) lr 1.6845e-03 eta 0:17:21
epoch [15/50] batch [60/173] time 0.071 (0.164) data 0.000 (0.005) loss 1.3000 (1.5416) teacher_loss 0.0653 (0.2155) loss_zs_kd 0.0217 (0.0345) loss_oracle 0.6662 (0.7355) kd_loss 0.8908 (0.9411) acc 96.8750 (91.3021) gate/entropy 0.9909 (0.9905) gate/usage_max 0.5598 (0.5601) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1602 (0.1605) teacher/entropy 0.0624 (0.0688) teacher/usage_max 0.5947 (0.5371) teacher/usage_min 0.1408 (0.1823) teacher/usage_std 0.1916 (0.1528) nleep/row_max_mean 1563.2559 (1552.8421) nleep/row_max_std 67.0298 (61.5050) nleep/row_min_mean 1523.4155 (1516.2830) lr 1.6845e-03 eta 0:16:51
epoch [15/50] batch [80/173] time 0.087 (0.152) data 0.000 (0.004) loss 1.4729 (1.5222) teacher_loss 0.1052 (0.2083) loss_zs_kd 0.0227 (0.0338) loss_oracle 0.7215 (0.7206) kd_loss 0.9956 (0.9367) acc 96.8750 (91.8359) gate/entropy 0.9915 (0.9907) gate/usage_max 0.5591 (0.5600) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1597 (0.1604) teacher/entropy 0.0744 (0.0676) teacher/usage_max 0.4660 (0.5428) teacher/usage_min 0.1725 (0.1773) teacher/usage_std 0.1215 (0.1579) nleep/row_max_mean 1547.6188 (1553.6471) nleep/row_max_std 65.0334 (62.1313) nleep/row_min_mean 1513.7104 (1516.6310) lr 1.6845e-03 eta 0:15:32
epoch [15/50] batch [100/173] time 0.208 (0.144) data 0.000 (0.003) loss 1.2548 (1.5144) teacher_loss 0.1165 (0.2041) loss_zs_kd 0.0440 (0.0349) loss_oracle 0.5943 (0.7029) kd_loss 0.8191 (0.9414) acc 96.8750 (91.7500) gate/entropy 0.9912 (0.9908) gate/usage_max 0.5594 (0.5598) gate/usage_min 0.2125 (0.2128) gate/usage_std 0.1600 (0.1603) teacher/entropy 0.0600 (0.0686) teacher/usage_max 0.6719 (0.5362) teacher/usage_min 0.0999 (0.1771) teacher/usage_std 0.2451 (0.1550) nleep/row_max_mean 1562.6753 (1552.2047) nleep/row_max_std 73.4211 (62.7426) nleep/row_min_mean 1521.3934 (1515.5508) lr 1.6845e-03 eta 0:14:45
epoch [15/50] batch [120/173] time 0.179 (0.140) data 0.000 (0.002) loss 1.4244 (1.5056) teacher_loss 0.1721 (0.2015) loss_zs_kd 0.0358 (0.0361) loss_oracle 0.6617 (0.6885) kd_loss 0.9035 (0.9418) acc 90.6250 (91.8490) gate/entropy 0.9914 (0.9910) gate/usage_max 0.5592 (0.5597) gate/usage_min 0.2124 (0.2127) gate/usage_std 0.1598 (0.1602) teacher/entropy 0.1052 (0.0691) teacher/usage_max 0.5405 (0.5350) teacher/usage_min 0.2269 (0.1778) teacher/usage_std 0.1465 (0.1542) nleep/row_max_mean 1566.0350 (1551.9969) nleep/row_max_std 52.3054 (62.4647) nleep/row_min_mean 1527.2607 (1515.3063) lr 1.6845e-03 eta 0:14:16
epoch [15/50] batch [140/173] time 0.059 (0.134) data 0.000 (0.002) loss 1.3688 (1.5087) teacher_loss 0.2293 (0.2046) loss_zs_kd 0.0497 (0.0368) loss_oracle 0.5500 (0.6815) kd_loss 0.8396 (0.9449) acc 87.5000 (91.5402) gate/entropy 0.9913 (0.9911) gate/usage_max 0.5593 (0.5595) gate/usage_min 0.2122 (0.2127) gate/usage_std 0.1599 (0.1601) teacher/entropy 0.0876 (0.0679) teacher/usage_max 0.6251 (0.5333) teacher/usage_min 0.1701 (0.1789) teacher/usage_std 0.2068 (0.1530) nleep/row_max_mean 1581.4106 (1552.4619) nleep/row_max_std 59.4130 (61.9272) nleep/row_min_mean 1541.0455 (1515.7508) lr 1.6845e-03 eta 0:13:35
epoch [15/50] batch [160/173] time 0.088 (0.129) data 0.000 (0.002) loss 1.4807 (1.5136) teacher_loss 0.2847 (0.2060) loss_zs_kd 0.0437 (0.0368) loss_oracle 0.5722 (0.6865) kd_loss 0.8880 (0.9459) acc 87.5000 (91.5820) gate/entropy 0.9921 (0.9912) gate/usage_max 0.5583 (0.5594) gate/usage_min 0.2122 (0.2126) gate/usage_std 0.1593 (0.1600) teacher/entropy 0.0467 (0.0664) teacher/usage_max 0.6249 (0.5335) teacher/usage_min 0.1238 (0.1749) teacher/usage_std 0.2126 (0.1544) nleep/row_max_mean 1566.7688 (1552.1110) nleep/row_max_std 50.5061 (61.8759) nleep/row_min_mean 1527.6714 (1515.5175) lr 1.6845e-03 eta 0:13:05
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [16/50] batch [20/173] time 0.161 (0.162) data 0.000 (0.011) loss 1.4115 (1.5071) teacher_loss 0.2235 (0.1782) loss_zs_kd 0.0210 (0.0366) loss_oracle 0.5634 (0.6351) kd_loss 0.8958 (0.9931) acc 90.6250 (92.3438) gate/entropy 0.9933 (0.9929) gate/usage_max 0.5570 (0.5575) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1583 (0.1587) teacher/entropy 0.0233 (0.0591) teacher/usage_max 0.6251 (0.5027) teacher/usage_min 0.0691 (0.1831) teacher/usage_std 0.2278 (0.1349) nleep/row_max_mean 1548.5129 (1551.6827) nleep/row_max_std 61.4572 (57.5856) nleep/row_min_mean 1510.0994 (1516.8046) lr 1.6374e-03 eta 0:16:16
epoch [16/50] batch [40/173] time 0.164 (0.158) data 0.000 (0.006) loss 1.7081 (1.5158) teacher_loss 0.3895 (0.1829) loss_zs_kd 0.0565 (0.0337) loss_oracle 0.6139 (0.6260) kd_loss 0.9834 (1.0030) acc 84.3750 (91.8750) gate/entropy 0.9937 (0.9931) gate/usage_max 0.5565 (0.5572) gate/usage_min 0.2120 (0.2120) gate/usage_std 0.1580 (0.1585) teacher/entropy 0.0678 (0.0526) teacher/usage_max 0.4946 (0.4949) teacher/usage_min 0.2508 (0.1969) teacher/usage_std 0.1140 (0.1274) nleep/row_max_mean 1532.9877 (1550.6517) nleep/row_max_std 55.8783 (57.6121) nleep/row_min_mean 1498.8175 (1515.3161) lr 1.6374e-03 eta 0:15:47
epoch [16/50] batch [60/173] time 0.138 (0.157) data 0.001 (0.004) loss 1.6242 (1.5184) teacher_loss 0.1242 (0.1824) loss_zs_kd 0.0221 (0.0329) loss_oracle 0.7392 (0.6245) kd_loss 1.1194 (1.0073) acc 93.7500 (92.2917) gate/entropy 0.9935 (0.9932) gate/usage_max 0.5567 (0.5571) gate/usage_min 0.2118 (0.2120) gate/usage_std 0.1582 (0.1584) teacher/entropy 0.0341 (0.0489) teacher/usage_max 0.3852 (0.4919) teacher/usage_min 0.2398 (0.2016) teacher/usage_std 0.0663 (0.1246) nleep/row_max_mean 1554.0162 (1551.9441) nleep/row_max_std 51.2916 (57.4321) nleep/row_min_mean 1514.2855 (1516.4992) lr 1.6374e-03 eta 0:15:39
epoch [16/50] batch [80/173] time 0.148 (0.155) data 0.000 (0.003) loss 1.5969 (1.5380) teacher_loss 0.1990 (0.1930) loss_zs_kd 0.0332 (0.0331) loss_oracle 0.6551 (0.6282) kd_loss 1.0538 (1.0143) acc 93.7500 (91.9531) gate/entropy 0.9937 (0.9933) gate/usage_max 0.5565 (0.5570) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1580 (0.1583) teacher/entropy 0.0240 (0.0451) teacher/usage_max 0.4593 (0.4877) teacher/usage_min 0.2193 (0.2058) teacher/usage_std 0.0983 (0.1211) nleep/row_max_mean 1552.8815 (1551.3798) nleep/row_max_std 55.8570 (57.8772) nleep/row_min_mean 1519.7189 (1516.0634) lr 1.6374e-03 eta 0:15:27
epoch [16/50] batch [100/173] time 0.152 (0.154) data 0.000 (0.002) loss 1.6901 (1.5372) teacher_loss 0.1232 (0.1944) loss_zs_kd 0.0142 (0.0331) loss_oracle 0.7371 (0.6253) kd_loss 1.1913 (1.0136) acc 93.7500 (92.0000) gate/entropy 0.9939 (0.9934) gate/usage_max 0.5563 (0.5568) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1578 (0.1582) teacher/entropy 0.0315 (0.0425) teacher/usage_max 0.4070 (0.4921) teacher/usage_min 0.2805 (0.2051) teacher/usage_std 0.0537 (0.1235) nleep/row_max_mean 1546.9106 (1551.3683) nleep/row_max_std 58.4323 (58.1345) nleep/row_min_mean 1508.8479 (1516.1013) lr 1.6374e-03 eta 0:15:15
epoch [16/50] batch [120/173] time 0.144 (0.152) data 0.000 (0.002) loss 1.6081 (1.5281) teacher_loss 0.2142 (0.1913) loss_zs_kd 0.0216 (0.0324) loss_oracle 0.6883 (0.6190) kd_loss 1.0390 (1.0111) acc 90.6250 (92.2917) gate/entropy 0.9942 (0.9935) gate/usage_max 0.5560 (0.5567) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1576 (0.1582) teacher/entropy 0.0011 (0.0428) teacher/usage_max 0.5000 (0.4950) teacher/usage_min 0.2186 (0.2043) teacher/usage_std 0.1206 (0.1252) nleep/row_max_mean 1548.5127 (1551.5090) nleep/row_max_std 61.8651 (58.6228) nleep/row_min_mean 1513.5565 (1516.3183) lr 1.6374e-03 eta 0:15:03
epoch [16/50] batch [140/173] time 0.162 (0.151) data 0.000 (0.002) loss 1.6424 (1.5320) teacher_loss 0.1944 (0.1968) loss_zs_kd 0.0352 (0.0320) loss_oracle 0.7347 (0.6197) kd_loss 1.0630 (1.0093) acc 90.6250 (91.8750) gate/entropy 0.9948 (0.9936) gate/usage_max 0.5552 (0.5566) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1571 (0.1581) teacher/entropy 0.0793 (0.0415) teacher/usage_max 0.4333 (0.4987) teacher/usage_min 0.1880 (0.2023) teacher/usage_std 0.1051 (0.1279) nleep/row_max_mean 1528.8379 (1551.7363) nleep/row_max_std 63.4407 (58.5755) nleep/row_min_mean 1499.6311 (1516.6479) lr 1.6374e-03 eta 0:14:55
epoch [16/50] batch [160/173] time 0.167 (0.152) data 0.000 (0.002) loss 1.6453 (1.5404) teacher_loss 0.2511 (0.1993) loss_zs_kd 0.0485 (0.0334) loss_oracle 0.6788 (0.6186) kd_loss 1.0305 (1.0152) acc 87.5000 (91.7578) gate/entropy 0.9941 (0.9937) gate/usage_max 0.5560 (0.5566) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1577 (0.1580) teacher/entropy 0.0046 (0.0398) teacher/usage_max 0.4994 (0.4954) teacher/usage_min 0.1563 (0.2015) teacher/usage_std 0.1403 (0.1265) nleep/row_max_mean 1546.9900 (1551.5141) nleep/row_max_std 63.3071 (58.1265) nleep/row_min_mean 1512.7139 (1516.5158) lr 1.6374e-03 eta 0:14:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [17/50] batch [20/173] time 0.080 (0.132) data 0.000 (0.017) loss 1.6772 (1.5064) teacher_loss 0.3099 (0.1977) loss_zs_kd 0.0496 (0.0329) loss_oracle 0.7107 (0.5989) kd_loss 0.9872 (0.9928) acc 81.2500 (91.8750) gate/entropy 0.9942 (0.9943) gate/usage_max 0.5559 (0.5558) gate/usage_min 0.2118 (0.2118) gate/usage_std 0.1576 (0.1576) teacher/entropy 0.0397 (0.0328) teacher/usage_max 0.5208 (0.5236) teacher/usage_min 0.2229 (0.1931) teacher/usage_std 0.1333 (0.1426) nleep/row_max_mean 1551.9971 (1556.0251) nleep/row_max_std 62.0026 (56.3711) nleep/row_min_mean 1515.7695 (1520.3010) lr 1.5878e-03 eta 0:12:52
epoch [17/50] batch [40/173] time 0.185 (0.115) data 0.000 (0.008) loss 1.3309 (1.5187) teacher_loss 0.1435 (0.2003) loss_zs_kd 0.0185 (0.0320) loss_oracle 0.4899 (0.5996) kd_loss 0.9332 (1.0026) acc 93.7500 (91.7969) gate/entropy 0.9948 (0.9944) gate/usage_max 0.5552 (0.5557) gate/usage_min 0.2119 (0.2118) gate/usage_std 0.1571 (0.1575) teacher/entropy 0.0421 (0.0336) teacher/usage_max 0.5636 (0.5161) teacher/usage_min 0.1035 (0.1957) teacher/usage_std 0.1878 (0.1379) nleep/row_max_mean 1552.4956 (1554.8298) nleep/row_max_std 53.6757 (57.4662) nleep/row_min_mean 1518.8062 (1519.4438) lr 1.5878e-03 eta 0:11:12
epoch [17/50] batch [60/173] time 0.086 (0.110) data 0.000 (0.006) loss 1.4843 (1.5089) teacher_loss 0.0739 (0.1803) loss_zs_kd 0.0344 (0.0307) loss_oracle 0.6549 (0.6059) kd_loss 1.0657 (1.0104) acc 96.8750 (92.8646) gate/entropy 0.9945 (0.9944) gate/usage_max 0.5556 (0.5557) gate/usage_min 0.2118 (0.2118) gate/usage_std 0.1574 (0.1574) teacher/entropy 0.0366 (0.0328) teacher/usage_max 0.4366 (0.5099) teacher/usage_min 0.2762 (0.1990) teacher/usage_std 0.0732 (0.1337) nleep/row_max_mean 1553.5280 (1553.7575) nleep/row_max_std 54.7309 (58.3228) nleep/row_min_mean 1517.6306 (1518.6636) lr 1.5878e-03 eta 0:10:41
epoch [17/50] batch [80/173] time 0.206 (0.113) data 0.000 (0.004) loss 1.5246 (1.5226) teacher_loss 0.2304 (0.1862) loss_zs_kd 0.0307 (0.0313) loss_oracle 0.5672 (0.6173) kd_loss 0.9953 (1.0121) acc 93.7500 (92.5781) gate/entropy 0.9946 (0.9945) gate/usage_max 0.5555 (0.5556) gate/usage_min 0.2117 (0.2118) gate/usage_std 0.1573 (0.1574) teacher/entropy 0.0277 (0.0329) teacher/usage_max 0.5207 (0.5063) teacher/usage_min 0.2182 (0.2027) teacher/usage_std 0.1336 (0.1312) nleep/row_max_mean 1561.4097 (1555.3131) nleep/row_max_std 57.8080 (58.1657) nleep/row_min_mean 1524.2834 (1519.8241) lr 1.5878e-03 eta 0:10:58
epoch [17/50] batch [100/173] time 0.121 (0.113) data 0.000 (0.003) loss 1.5580 (1.5254) teacher_loss 0.0963 (0.1881) loss_zs_kd 0.0410 (0.0323) loss_oracle 0.6401 (0.6179) kd_loss 1.1212 (1.0122) acc 96.8750 (92.5312) gate/entropy 0.9953 (0.9945) gate/usage_max 0.5546 (0.5555) gate/usage_min 0.2118 (0.2118) gate/usage_std 0.1567 (0.1574) teacher/entropy 0.0137 (0.0353) teacher/usage_max 0.4054 (0.5037) teacher/usage_min 0.2526 (0.2001) teacher/usage_std 0.0627 (0.1308) nleep/row_max_mean 1549.4839 (1555.8376) nleep/row_max_std 44.9830 (57.1634) nleep/row_min_mean 1515.8323 (1520.5788) lr 1.5878e-03 eta 0:10:53
epoch [17/50] batch [120/173] time 0.187 (0.121) data 0.000 (0.003) loss 1.5923 (1.5381) teacher_loss 0.2022 (0.1896) loss_zs_kd 0.0397 (0.0326) loss_oracle 0.6455 (0.6206) kd_loss 1.0475 (1.0219) acc 93.7500 (92.3958) gate/entropy 0.9956 (0.9946) gate/usage_max 0.5543 (0.5554) gate/usage_min 0.2117 (0.2118) gate/usage_std 0.1565 (0.1573) teacher/entropy 0.0564 (0.0366) teacher/usage_max 0.4282 (0.4931) teacher/usage_min 0.2251 (0.2051) teacher/usage_std 0.0834 (0.1239) nleep/row_max_mean 1540.4995 (1555.4541) nleep/row_max_std 48.7665 (56.0842) nleep/row_min_mean 1508.9928 (1520.3320) lr 1.5878e-03 eta 0:11:34
epoch [17/50] batch [140/173] time 0.162 (0.127) data 0.000 (0.003) loss 1.6212 (1.5374) teacher_loss 0.2826 (0.1896) loss_zs_kd 0.0355 (0.0332) loss_oracle 0.6271 (0.6194) kd_loss 1.0073 (1.0215) acc 90.6250 (92.4330) gate/entropy 0.9952 (0.9947) gate/usage_max 0.5547 (0.5553) gate/usage_min 0.2115 (0.2117) gate/usage_std 0.1568 (0.1572) teacher/entropy 0.1499 (0.0387) teacher/usage_max 0.3817 (0.4907) teacher/usage_min 0.2478 (0.2047) teacher/usage_std 0.0606 (0.1232) nleep/row_max_mean 1547.1475 (1555.1234) nleep/row_max_std 52.3280 (55.0293) nleep/row_min_mean 1512.6765 (1520.1109) lr 1.5878e-03 eta 0:12:08
epoch [17/50] batch [160/173] time 0.129 (0.130) data 0.000 (0.002) loss 1.2871 (1.5335) teacher_loss 0.1463 (0.1902) loss_zs_kd 0.0232 (0.0319) loss_oracle 0.4037 (0.6149) kd_loss 0.9273 (1.0199) acc 96.8750 (92.5000) gate/entropy 0.9953 (0.9949) gate/usage_max 0.5546 (0.5552) gate/usage_min 0.2114 (0.2117) gate/usage_std 0.1568 (0.1571) teacher/entropy 0.0416 (0.0407) teacher/usage_max 0.5943 (0.4899) teacher/usage_min 0.1212 (0.2057) teacher/usage_std 0.1962 (0.1226) nleep/row_max_mean 1560.5256 (1554.5188) nleep/row_max_std 33.5029 (54.8281) nleep/row_min_mean 1531.8530 (1519.7254) lr 1.5878e-03 eta 0:12:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,281
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [18/50] batch [20/173] time 0.134 (0.171) data 0.000 (0.015) loss 1.4370 (1.5603) teacher_loss 0.2066 (0.2069) loss_zs_kd 0.0266 (0.0427) loss_oracle 0.5486 (0.6059) kd_loss 0.9428 (1.0291) acc 90.6250 (91.5625) gate/entropy 0.9966 (0.9962) gate/usage_max 0.5531 (0.5535) gate/usage_min 0.2114 (0.2114) gate/usage_std 0.1557 (0.1560) teacher/entropy 0.1045 (0.0641) teacher/usage_max 0.4854 (0.4489) teacher/usage_min 0.1578 (0.2076) teacher/usage_std 0.1348 (0.1041) nleep/row_max_mean 1554.7083 (1550.7588) nleep/row_max_std 45.1057 (52.9400) nleep/row_min_mean 1523.3308 (1518.0760) lr 1.5358e-03 eta 0:16:11
epoch [18/50] batch [40/173] time 0.085 (0.161) data 0.000 (0.008) loss 1.4607 (1.5596) teacher_loss 0.0942 (0.1759) loss_zs_kd 0.0301 (0.0383) loss_oracle 0.6042 (0.6298) kd_loss 1.0493 (1.0497) acc 96.8750 (93.2812) gate/entropy 0.9972 (0.9965) gate/usage_max 0.5524 (0.5532) gate/usage_min 0.2112 (0.2113) gate/usage_std 0.1552 (0.1558) teacher/entropy 0.0235 (0.0632) teacher/usage_max 0.4671 (0.4439) teacher/usage_min 0.2468 (0.2128) teacher/usage_std 0.0959 (0.0985) nleep/row_max_mean 1562.9812 (1551.5174) nleep/row_max_std 49.3360 (55.1434) nleep/row_min_mean 1529.4294 (1518.3530) lr 1.5358e-03 eta 0:15:13
epoch [18/50] batch [60/173] time 0.073 (0.143) data 0.000 (0.005) loss 1.7094 (1.5713) teacher_loss 0.1837 (0.1757) loss_zs_kd 0.0481 (0.0386) loss_oracle 0.7624 (0.6457) kd_loss 1.1205 (1.0534) acc 93.7500 (93.2812) gate/entropy 0.9975 (0.9969) gate/usage_max 0.5520 (0.5528) gate/usage_min 0.2109 (0.2112) gate/usage_std 0.1550 (0.1555) teacher/entropy 0.0358 (0.0569) teacher/usage_max 0.4536 (0.4512) teacher/usage_min 0.1883 (0.2023) teacher/usage_std 0.1097 (0.1055) nleep/row_max_mean 1547.9824 (1552.3347) nleep/row_max_std 67.7368 (56.9703) nleep/row_min_mean 1511.1598 (1518.4072) lr 1.5358e-03 eta 0:13:27
epoch [18/50] batch [80/173] time 0.097 (0.135) data 0.000 (0.004) loss 1.5109 (1.5921) teacher_loss 0.0639 (0.1696) loss_zs_kd 0.0273 (0.0393) loss_oracle 0.7093 (0.6728) kd_loss 1.0787 (1.0665) acc 100.0000 (93.7109) gate/entropy 0.9991 (0.9972) gate/usage_max 0.5501 (0.5523) gate/usage_min 0.2107 (0.2111) gate/usage_std 0.1537 (0.1552) teacher/entropy 0.0042 (0.0512) teacher/usage_max 0.4383 (0.4625) teacher/usage_min 0.1556 (0.1919) teacher/usage_std 0.1263 (0.1152) nleep/row_max_mean 1548.5061 (1552.5202) nleep/row_max_std 66.4830 (57.4452) nleep/row_min_mean 1509.6764 (1518.1677) lr 1.5358e-03 eta 0:12:37
epoch [18/50] batch [100/173] time 0.183 (0.132) data 0.000 (0.003) loss 1.6952 (1.6082) teacher_loss 0.1061 (0.1648) loss_zs_kd 0.0439 (0.0392) loss_oracle 0.6720 (0.6831) kd_loss 1.2311 (1.0822) acc 96.8750 (93.8438) gate/entropy 0.9999 (0.9976) gate/usage_max 0.5490 (0.5518) gate/usage_min 0.2103 (0.2110) gate/usage_std 0.1530 (0.1549) teacher/entropy 0.0146 (0.0454) teacher/usage_max 0.5674 (0.4682) teacher/usage_min 0.1877 (0.1891) teacher/usage_std 0.1671 (0.1186) nleep/row_max_mean 1552.3142 (1552.3654) nleep/row_max_std 53.6860 (57.3192) nleep/row_min_mean 1516.8185 (1517.6304) lr 1.5358e-03 eta 0:12:23
epoch [18/50] batch [120/173] time 0.158 (0.131) data 0.000 (0.003) loss 1.4977 (1.6110) teacher_loss 0.1020 (0.1596) loss_zs_kd 0.0306 (0.0408) loss_oracle 0.5915 (0.6837) kd_loss 1.0846 (1.0891) acc 93.7500 (93.9062) gate/entropy 1.0009 (0.9981) gate/usage_max 0.5477 (0.5512) gate/usage_min 0.2099 (0.2108) gate/usage_std 0.1521 (0.1545) teacher/entropy 0.0177 (0.0417) teacher/usage_max 0.4326 (0.4705) teacher/usage_min 0.1565 (0.1861) teacher/usage_std 0.1254 (0.1208) nleep/row_max_mean 1554.7400 (1552.0071) nleep/row_max_std 55.7349 (56.3564) nleep/row_min_mean 1517.5151 (1517.0577) lr 1.5358e-03 eta 0:12:14
epoch [18/50] batch [140/173] time 0.092 (0.125) data 0.000 (0.002) loss 1.8042 (1.6225) teacher_loss 0.1704 (0.1569) loss_zs_kd 0.0556 (0.0421) loss_oracle 0.8785 (0.6981) kd_loss 1.1668 (1.0954) acc 93.7500 (94.0848) gate/entropy 1.0019 (0.9986) gate/usage_max 0.5465 (0.5507) gate/usage_min 0.2095 (0.2107) gate/usage_std 0.1514 (0.1541) teacher/entropy 0.0144 (0.0383) teacher/usage_max 0.4947 (0.4719) teacher/usage_min 0.1875 (0.1858) teacher/usage_std 0.1259 (0.1214) nleep/row_max_mean 1537.7101 (1551.5503) nleep/row_max_std 66.7246 (56.2185) nleep/row_min_mean 1502.4175 (1516.3368) lr 1.5358e-03 eta 0:11:37
epoch [18/50] batch [160/173] time 0.182 (0.126) data 0.000 (0.002) loss 1.5978 (1.6298) teacher_loss 0.0609 (0.1539) loss_zs_kd 0.0358 (0.0429) loss_oracle 0.8326 (0.7121) kd_loss 1.1027 (1.0985) acc 100.0000 (94.1992) gate/entropy 1.0032 (0.9990) gate/usage_max 0.5447 (0.5500) gate/usage_min 0.2089 (0.2105) gate/usage_std 0.1502 (0.1537) teacher/entropy 0.0195 (0.0355) teacher/usage_max 0.4924 (0.4751) teacher/usage_min 0.1320 (0.1807) teacher/usage_std 0.1501 (0.1251) nleep/row_max_mean 1552.3575 (1551.4212) nleep/row_max_std 60.7677 (56.0515) nleep/row_min_mean 1514.3994 (1516.0008) lr 1.5358e-03 eta 0:11:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.8%, epoch: 11 *******
******* Domain a best val test acc: 97.9%, epoch: 11 *******
******* Domain a best test acc:     98.1%, epoch: 6 *******
epoch [19/50] batch [20/173] time 0.160 (0.169) data 0.000 (0.017) loss 1.6797 (1.6844) teacher_loss 0.1099 (0.1154) loss_zs_kd 0.0448 (0.0489) loss_oracle 0.7670 (0.7966) kd_loss 1.1639 (1.1462) acc 93.7500 (95.1562) gate/entropy 1.0056 (1.0050) gate/usage_max 0.5413 (0.5422) gate/usage_min 0.2079 (0.2082) gate/usage_std 0.1481 (0.1487) teacher/entropy 0.0144 (0.0108) teacher/usage_max 0.6528 (0.5275) teacher/usage_min 0.0666 (0.1474) teacher/usage_std 0.2422 (0.1618) nleep/row_max_mean 1551.0126 (1549.4834) nleep/row_max_std 59.3028 (53.0366) nleep/row_min_mean 1515.2930 (1513.8744) lr 1.4818e-03 eta 0:15:34
epoch [19/50] batch [40/173] time 0.161 (0.157) data 0.000 (0.008) loss 1.6593 (1.6837) teacher_loss 0.0828 (0.1261) loss_zs_kd 0.0550 (0.0481) loss_oracle 0.7685 (0.7905) kd_loss 1.1647 (1.1383) acc 96.8750 (95.0781) gate/entropy 1.0070 (1.0058) gate/usage_max 0.5393 (0.5411) gate/usage_min 0.2071 (0.2079) gate/usage_std 0.1469 (0.1480) teacher/entropy 0.0018 (0.0113) teacher/usage_max 0.5315 (0.5155) teacher/usage_min 0.1560 (0.1517) teacher/usage_std 0.1540 (0.1552) nleep/row_max_mean 1551.9906 (1550.6970) nleep/row_max_std 56.6598 (53.7205) nleep/row_min_mean 1514.5054 (1514.4697) lr 1.4818e-03 eta 0:14:23
epoch [19/50] batch [60/173] time 0.145 (0.153) data 0.000 (0.006) loss 1.5659 (1.6854) teacher_loss 0.0914 (0.1326) loss_zs_kd 0.0451 (0.0487) loss_oracle 0.7371 (0.7953) kd_loss 1.0834 (1.1308) acc 93.7500 (94.7396) gate/entropy 1.0090 (1.0065) gate/usage_max 0.5364 (0.5401) gate/usage_min 0.2064 (0.2075) gate/usage_std 0.1451 (0.1473) teacher/entropy 0.0074 (0.0110) teacher/usage_max 0.4373 (0.5095) teacher/usage_min 0.1553 (0.1543) teacher/usage_std 0.1265 (0.1508) nleep/row_max_mean 1552.8782 (1551.2889) nleep/row_max_std 52.4281 (52.9332) nleep/row_min_mean 1513.8408 (1514.6051) lr 1.4818e-03 eta 0:13:59
epoch [19/50] batch [80/173] time 0.145 (0.154) data 0.000 (0.004) loss 1.5466 (1.6920) teacher_loss 0.0876 (0.1400) loss_zs_kd 0.0449 (0.0482) loss_oracle 0.7585 (0.7955) kd_loss 1.0573 (1.1301) acc 96.8750 (94.7656) gate/entropy 1.0106 (1.0073) gate/usage_max 0.5340 (0.5389) gate/usage_min 0.2054 (0.2071) gate/usage_std 0.1436 (0.1466) teacher/entropy 0.0015 (0.0138) teacher/usage_max 0.4375 (0.5116) teacher/usage_min 0.1252 (0.1538) teacher/usage_std 0.1472 (0.1513) nleep/row_max_mean 1559.9569 (1550.7142) nleep/row_max_std 52.5603 (53.4343) nleep/row_min_mean 1519.1282 (1514.2796) lr 1.4818e-03 eta 0:14:02
epoch [19/50] batch [100/173] time 0.136 (0.154) data 0.000 (0.003) loss 1.9241 (1.6960) teacher_loss 0.3362 (0.1405) loss_zs_kd 0.0967 (0.0484) loss_oracle 0.7904 (0.7941) kd_loss 1.1443 (1.1342) acc 84.3750 (94.7188) gate/entropy 1.0121 (1.0082) gate/usage_max 0.5315 (0.5376) gate/usage_min 0.2046 (0.2067) gate/usage_std 0.1422 (0.1458) teacher/entropy 0.0250 (0.0144) teacher/usage_max 0.5775 (0.5109) teacher/usage_min 0.1413 (0.1582) teacher/usage_std 0.1819 (0.1495) nleep/row_max_mean 1542.1721 (1549.1601) nleep/row_max_std 61.4671 (53.1513) nleep/row_min_mean 1506.0284 (1513.2137) lr 1.4818e-03 eta 0:13:58
epoch [19/50] batch [120/173] time 0.146 (0.153) data 0.000 (0.003) loss 1.7012 (1.6874) teacher_loss 0.0214 (0.1410) loss_zs_kd 0.0225 (0.0484) loss_oracle 0.8188 (0.7888) kd_loss 1.2591 (1.1279) acc 100.0000 (94.6875) gate/entropy 1.0142 (1.0090) gate/usage_max 0.5282 (0.5363) gate/usage_min 0.2037 (0.2063) gate/usage_std 0.1402 (0.1451) teacher/entropy 0.0067 (0.0158) teacher/usage_max 0.5318 (0.5112) teacher/usage_min 0.1875 (0.1552) teacher/usage_std 0.1454 (0.1510) nleep/row_max_mean 1546.7332 (1549.0087) nleep/row_max_std 45.1027 (52.4894) nleep/row_min_mean 1514.4534 (1513.1145) lr 1.4818e-03 eta 0:13:50
epoch [19/50] batch [140/173] time 0.066 (0.153) data 0.000 (0.003) loss 1.4743 (1.6824) teacher_loss 0.0546 (0.1425) loss_zs_kd 0.0265 (0.0478) loss_oracle 0.6523 (0.7829) kd_loss 1.0803 (1.1246) acc 100.0000 (94.6205) gate/entropy 1.0165 (1.0099) gate/usage_max 0.5243 (0.5349) gate/usage_min 0.2027 (0.2058) gate/usage_std 0.1380 (0.1443) teacher/entropy 0.0014 (0.0175) teacher/usage_max 0.6248 (0.5126) teacher/usage_min 0.0314 (0.1549) teacher/usage_std 0.2424 (0.1517) nleep/row_max_mean 1544.5344 (1548.6688) nleep/row_max_std 58.8106 (51.8512) nleep/row_min_mean 1508.1051 (1512.9811) lr 1.4818e-03 eta 0:13:43
epoch [19/50] batch [160/173] time 0.080 (0.145) data 0.000 (0.002) loss 1.4347 (1.6744) teacher_loss 0.0928 (0.1426) loss_zs_kd 0.0496 (0.0473) loss_oracle 0.7004 (0.7812) kd_loss 0.9669 (1.1175) acc 96.8750 (94.5898) gate/entropy 1.0181 (1.0108) gate/usage_max 0.5211 (0.5334) gate/usage_min 0.2013 (0.2053) gate/usage_std 0.1364 (0.1434) teacher/entropy 0.0170 (0.0205) teacher/usage_max 0.5321 (0.5131) teacher/usage_min 0.1200 (0.1548) teacher/usage_std 0.1686 (0.1524) nleep/row_max_mean 1550.6741 (1549.0941) nleep/row_max_std 41.1613 (51.4978) nleep/row_min_mean 1516.2896 (1513.4951) lr 1.4818e-03 eta 0:12:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,316
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,012
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [20/50] batch [20/173] time 0.069 (0.119) data 0.000 (0.014) loss 1.5795 (1.6376) teacher_loss 0.1531 (0.1848) loss_zs_kd 0.0360 (0.0430) loss_oracle 0.7194 (0.6936) kd_loss 1.0488 (1.0845) acc 93.7500 (93.1250) gate/entropy 1.0210 (1.0199) gate/usage_max 0.5151 (0.5174) gate/usage_min 0.1992 (0.1998) gate/usage_std 0.1333 (0.1345) teacher/entropy 0.0141 (0.0476) teacher/usage_max 0.5321 (0.5716) teacher/usage_min 0.0917 (0.1350) teacher/usage_std 0.1824 (0.1850) nleep/row_max_mean 1548.3474 (1547.3834) nleep/row_max_std 55.5712 (53.9638) nleep/row_min_mean 1509.8125 (1513.4812) lr 1.4258e-03 eta 0:10:36
epoch [20/50] batch [40/173] time 0.177 (0.110) data 0.000 (0.007) loss 1.7080 (1.6226) teacher_loss 0.2028 (0.1834) loss_zs_kd 0.0356 (0.0418) loss_oracle 0.7179 (0.7093) kd_loss 1.1284 (1.0637) acc 90.6250 (93.2812) gate/entropy 1.0227 (1.0208) gate/usage_max 0.5111 (0.5154) gate/usage_min 0.1976 (0.1990) gate/usage_std 0.1314 (0.1335) teacher/entropy 0.0205 (0.0403) teacher/usage_max 0.6855 (0.5682) teacher/usage_min 0.0978 (0.1140) teacher/usage_std 0.2537 (0.1923) nleep/row_max_mean 1542.4924 (1550.6840) nleep/row_max_std 49.6002 (53.1775) nleep/row_min_mean 1509.8868 (1516.6288) lr 1.4258e-03 eta 0:09:47
epoch [20/50] batch [60/173] time 0.114 (0.117) data 0.000 (0.005) loss 1.5901 (1.6142) teacher_loss 0.2016 (0.1874) loss_zs_kd 0.0402 (0.0408) loss_oracle 0.6489 (0.7098) kd_loss 1.0438 (1.0515) acc 90.6250 (92.9167) gate/entropy 1.0245 (1.0217) gate/usage_max 0.5065 (0.5132) gate/usage_min 0.1957 (0.1982) gate/usage_std 0.1294 (0.1325) teacher/entropy 0.0607 (0.0360) teacher/usage_max 0.4016 (0.5609) teacher/usage_min 0.2229 (0.1076) teacher/usage_std 0.0788 (0.1916) nleep/row_max_mean 1543.0225 (1549.1276) nleep/row_max_std 59.3683 (54.8698) nleep/row_min_mean 1510.2720 (1514.9877) lr 1.4258e-03 eta 0:10:20
epoch [20/50] batch [80/173] time 0.154 (0.115) data 0.000 (0.004) loss 1.5497 (1.6124) teacher_loss 0.1025 (0.1888) loss_zs_kd 0.0216 (0.0407) loss_oracle 0.7442 (0.7098) kd_loss 1.0643 (1.0483) acc 93.7500 (92.8906) gate/entropy 1.0261 (1.0226) gate/usage_max 0.5019 (0.5110) gate/usage_min 0.1939 (0.1973) gate/usage_std 0.1274 (0.1315) teacher/entropy 0.0333 (0.0346) teacher/usage_max 0.6215 (0.5717) teacher/usage_min 0.1021 (0.1020) teacher/usage_std 0.2158 (0.1987) nleep/row_max_mean 1547.7141 (1548.1860) nleep/row_max_std 53.2598 (54.8523) nleep/row_min_mean 1514.0323 (1514.0245) lr 1.4258e-03 eta 0:10:07
epoch [20/50] batch [100/173] time 0.174 (0.123) data 0.000 (0.003) loss 1.5458 (1.6016) teacher_loss 0.2395 (0.1926) loss_zs_kd 0.0222 (0.0400) loss_oracle 0.6149 (0.6982) kd_loss 0.9878 (1.0398) acc 90.6250 (92.7500) gate/entropy 1.0274 (1.0234) gate/usage_max 0.4973 (0.5087) gate/usage_min 0.1920 (0.1964) gate/usage_std 0.1257 (0.1305) teacher/entropy 0.0056 (0.0340) teacher/usage_max 0.6238 (0.5763) teacher/usage_min 0.0012 (0.0933) teacher/usage_std 0.2559 (0.2045) nleep/row_max_mean 1546.8979 (1547.4654) nleep/row_max_std 56.9437 (54.8135) nleep/row_min_mean 1512.2637 (1513.4753) lr 1.4258e-03 eta 0:10:45
epoch [20/50] batch [120/173] time 0.165 (0.131) data 0.000 (0.002) loss 1.6821 (1.5927) teacher_loss 0.2089 (0.1928) loss_zs_kd 0.0652 (0.0394) loss_oracle 0.7824 (0.6942) kd_loss 1.0493 (1.0331) acc 87.5000 (92.5000) gate/entropy 1.0286 (1.0242) gate/usage_max 0.4928 (0.5064) gate/usage_min 0.1902 (0.1955) gate/usage_std 0.1241 (0.1295) teacher/entropy 0.0369 (0.0342) teacher/usage_max 0.5933 (0.5783) teacher/usage_min 0.1232 (0.0890) teacher/usage_std 0.1951 (0.2070) nleep/row_max_mean 1546.3442 (1547.5384) nleep/row_max_std 62.2503 (54.7666) nleep/row_min_mean 1514.1581 (1513.4957) lr 1.4258e-03 eta 0:11:27
epoch [20/50] batch [140/173] time 0.164 (0.136) data 0.000 (0.002) loss 1.6743 (1.5903) teacher_loss 0.2393 (0.1942) loss_zs_kd 0.0178 (0.0387) loss_oracle 0.7317 (0.6968) kd_loss 1.0603 (1.0283) acc 93.7500 (92.4554) gate/entropy 1.0295 (1.0249) gate/usage_max 0.4882 (0.5041) gate/usage_min 0.1882 (0.1946) gate/usage_std 0.1226 (0.1286) teacher/entropy 0.0095 (0.0334) teacher/usage_max 0.5025 (0.5815) teacher/usage_min 0.1537 (0.0860) teacher/usage_std 0.1426 (0.2094) nleep/row_max_mean 1557.9189 (1547.3880) nleep/row_max_std 58.3798 (54.8673) nleep/row_min_mean 1523.8267 (1513.3694) lr 1.4258e-03 eta 0:11:51
epoch [20/50] batch [160/173] time 0.161 (0.138) data 0.000 (0.002) loss 1.4827 (1.5781) teacher_loss 0.2032 (0.1930) loss_zs_kd 0.0250 (0.0375) loss_oracle 0.5761 (0.6899) kd_loss 0.9790 (1.0214) acc 90.6250 (92.5000) gate/entropy 1.0306 (1.0256) gate/usage_max 0.4832 (0.5018) gate/usage_min 0.1866 (0.1937) gate/usage_std 0.1211 (0.1278) teacher/entropy 0.0157 (0.0328) teacher/usage_max 0.6233 (0.5838) teacher/usage_min 0.0315 (0.0808) teacher/usage_std 0.2417 (0.2124) nleep/row_max_mean 1539.0439 (1547.1917) nleep/row_max_std 61.7815 (54.9572) nleep/row_min_mean 1505.0181 (1513.3332) lr 1.4258e-03 eta 0:11:58
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,312
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [21/50] batch [20/173] time 0.081 (0.138) data 0.000 (0.015) loss 1.6177 (1.5081) teacher_loss 0.2144 (0.2000) loss_zs_kd 0.0620 (0.0321) loss_oracle 0.7149 (0.6599) kd_loss 1.0149 (0.9621) acc 87.5000 (91.7188) gate/entropy 1.0313 (1.0311) gate/usage_max 0.4763 (0.4781) gate/usage_min 0.1837 (0.1843) gate/usage_std 0.1196 (0.1200) teacher/entropy 0.0219 (0.0266) teacher/usage_max 0.6815 (0.5864) teacher/usage_min 0.0682 (0.0497) teacher/usage_std 0.2572 (0.2262) nleep/row_max_mean 1535.8250 (1547.7845) nleep/row_max_std 50.6755 (54.7462) nleep/row_min_mean 1507.0408 (1514.7404) lr 1.3681e-03 eta 0:11:52
epoch [21/50] batch [40/173] time 0.076 (0.121) data 0.000 (0.008) loss 1.7974 (1.5205) teacher_loss 0.4986 (0.2065) loss_zs_kd 0.0259 (0.0320) loss_oracle 0.6691 (0.6784) kd_loss 0.9513 (0.9588) acc 87.5000 (91.5625) gate/entropy 1.0316 (1.0312) gate/usage_max 0.4724 (0.4762) gate/usage_min 0.1821 (0.1835) gate/usage_std 0.1188 (0.1196) teacher/entropy 0.0194 (0.0274) teacher/usage_max 0.6334 (0.6060) teacher/usage_min 0.0230 (0.0435) teacher/usage_std 0.2493 (0.2365) nleep/row_max_mean 1522.5980 (1543.9805) nleep/row_max_std 55.3270 (56.3235) nleep/row_min_mean 1490.9789 (1511.0657) lr 1.3681e-03 eta 0:10:23
epoch [21/50] batch [60/173] time 0.081 (0.119) data 0.001 (0.005) loss 1.4576 (1.5015) teacher_loss 0.2417 (0.1935) loss_zs_kd 0.0301 (0.0300) loss_oracle 0.6267 (0.6773) kd_loss 0.8874 (0.9543) acc 87.5000 (92.4479) gate/entropy 1.0317 (1.0314) gate/usage_max 0.4684 (0.4742) gate/usage_min 0.1805 (0.1827) gate/usage_std 0.1182 (0.1192) teacher/entropy 0.0412 (0.0274) teacher/usage_max 0.5000 (0.6096) teacher/usage_min 0.0370 (0.0407) teacher/usage_std 0.2101 (0.2392) nleep/row_max_mean 1546.8774 (1542.8652) nleep/row_max_std 61.2314 (56.9651) nleep/row_min_mean 1510.1855 (1509.7710) lr 1.3681e-03 eta 0:10:12
epoch [21/50] batch [80/173] time 0.072 (0.121) data 0.000 (0.004) loss 1.4503 (1.4954) teacher_loss 0.1945 (0.1928) loss_zs_kd 0.0401 (0.0305) loss_oracle 0.5840 (0.6706) kd_loss 0.9438 (0.9522) acc 90.6250 (92.5391) gate/entropy 1.0319 (1.0314) gate/usage_max 0.4651 (0.4723) gate/usage_min 0.1793 (0.1819) gate/usage_std 0.1177 (0.1189) teacher/entropy 0.0241 (0.0255) teacher/usage_max 0.6604 (0.6130) teacher/usage_min 0.0249 (0.0385) teacher/usage_std 0.2598 (0.2403) nleep/row_max_mean 1521.5006 (1542.2693) nleep/row_max_std 62.0309 (57.0016) nleep/row_min_mean 1489.2446 (1508.8393) lr 1.3681e-03 eta 0:10:18
epoch [21/50] batch [100/173] time 0.088 (0.121) data 0.000 (0.003) loss 1.5748 (1.4968) teacher_loss 0.2490 (0.1937) loss_zs_kd 0.0418 (0.0311) loss_oracle 0.7479 (0.6745) kd_loss 0.9310 (0.9504) acc 90.6250 (92.5938) gate/entropy 1.0315 (1.0315) gate/usage_max 0.4617 (0.4705) gate/usage_min 0.1775 (0.1812) gate/usage_std 0.1176 (0.1187) teacher/entropy 0.0010 (0.0237) teacher/usage_max 0.5312 (0.6133) teacher/usage_min 0.0624 (0.0381) teacher/usage_std 0.1982 (0.2410) nleep/row_max_mean 1551.0215 (1542.6782) nleep/row_max_std 58.8163 (56.8407) nleep/row_min_mean 1513.7740 (1508.9818) lr 1.3681e-03 eta 0:10:14
epoch [21/50] batch [120/173] time 0.174 (0.118) data 0.000 (0.003) loss 1.4899 (1.4927) teacher_loss 0.1994 (0.1916) loss_zs_kd 0.0130 (0.0310) loss_oracle 0.7006 (0.6743) kd_loss 0.9337 (0.9484) acc 93.7500 (92.5521) gate/entropy 1.0316 (1.0315) gate/usage_max 0.4588 (0.4688) gate/usage_min 0.1767 (0.1805) gate/usage_std 0.1173 (0.1185) teacher/entropy 0.0056 (0.0238) teacher/usage_max 0.6862 (0.6182) teacher/usage_min 0.0013 (0.0375) teacher/usage_std 0.2800 (0.2429) nleep/row_max_mean 1527.9681 (1542.3142) nleep/row_max_std 48.9310 (56.0056) nleep/row_min_mean 1493.6844 (1508.6817) lr 1.3681e-03 eta 0:09:56
epoch [21/50] batch [140/173] time 0.169 (0.119) data 0.000 (0.002) loss 1.4862 (1.4899) teacher_loss 0.1815 (0.1914) loss_zs_kd 0.0508 (0.0315) loss_oracle 0.7163 (0.6771) kd_loss 0.9212 (0.9442) acc 93.7500 (92.3661) gate/entropy 1.0310 (1.0314) gate/usage_max 0.4558 (0.4671) gate/usage_min 0.1750 (0.1798) gate/usage_std 0.1174 (0.1184) teacher/entropy 0.0046 (0.0231) teacher/usage_max 0.6552 (0.6142) teacher/usage_min 0.0011 (0.0365) teacher/usage_std 0.2671 (0.2421) nleep/row_max_mean 1540.9762 (1542.9085) nleep/row_max_std 57.2297 (55.0667) nleep/row_min_mean 1506.5791 (1508.8846) lr 1.3681e-03 eta 0:09:59
epoch [21/50] batch [160/173] time 0.159 (0.118) data 0.000 (0.002) loss 1.3240 (1.4906) teacher_loss 0.0526 (0.1915) loss_zs_kd 0.0171 (0.0318) loss_oracle 0.7444 (0.6808) kd_loss 0.8907 (0.9428) acc 96.8750 (92.2852) gate/entropy 1.0308 (1.0313) gate/usage_max 0.4532 (0.4655) gate/usage_min 0.1741 (0.1791) gate/usage_std 0.1173 (0.1182) teacher/entropy 0.0245 (0.0224) teacher/usage_max 0.5312 (0.6202) teacher/usage_min 0.0402 (0.0355) teacher/usage_std 0.2115 (0.2450) nleep/row_max_mean 1546.1252 (1542.4718) nleep/row_max_std 53.1044 (54.9262) nleep/row_min_mean 1507.1223 (1508.4697) lr 1.3681e-03 eta 0:09:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,307
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [22/50] batch [20/173] time 0.137 (0.162) data 0.000 (0.013) loss 1.5588 (1.4913) teacher_loss 0.3190 (0.2042) loss_zs_kd 0.0236 (0.0315) loss_oracle 0.6078 (0.6953) kd_loss 0.9241 (0.9236) acc 87.5000 (92.0312) gate/entropy 1.0301 (1.0303) gate/usage_max 0.4492 (0.4503) gate/usage_min 0.1722 (0.1727) gate/usage_std 0.1176 (0.1175) teacher/entropy 0.0004 (0.0234) teacher/usage_max 0.7187 (0.6487) teacher/usage_min 0.0001 (0.0349) teacher/usage_std 0.2957 (0.2565) nleep/row_max_mean 1544.4768 (1539.1819) nleep/row_max_std 59.2835 (52.6706) nleep/row_min_mean 1507.9963 (1505.0711) lr 1.3090e-03 eta 0:13:29
epoch [22/50] batch [40/173] time 0.155 (0.159) data 0.000 (0.007) loss 1.3638 (1.4694) teacher_loss 0.1124 (0.1957) loss_zs_kd 0.0159 (0.0312) loss_oracle 0.6182 (0.6749) kd_loss 0.9343 (0.9207) acc 96.8750 (92.0312) gate/entropy 1.0298 (1.0302) gate/usage_max 0.4474 (0.4493) gate/usage_min 0.1714 (0.1723) gate/usage_std 0.1176 (0.1175) teacher/entropy 0.0099 (0.0188) teacher/usage_max 0.6849 (0.6495) teacher/usage_min 0.0315 (0.0300) teacher/usage_std 0.2691 (0.2580) nleep/row_max_mean 1548.1617 (1539.2108) nleep/row_max_std 66.4671 (55.8918) nleep/row_min_mean 1514.2805 (1504.4725) lr 1.3090e-03 eta 0:13:09
epoch [22/50] batch [60/173] time 0.152 (0.155) data 0.000 (0.004) loss 1.4976 (1.4690) teacher_loss 0.2070 (0.1962) loss_zs_kd 0.0237 (0.0305) loss_oracle 0.7010 (0.6703) kd_loss 0.9282 (0.9223) acc 90.6250 (91.6146) gate/entropy 1.0297 (1.0300) gate/usage_max 0.4459 (0.4484) gate/usage_min 0.1710 (0.1719) gate/usage_std 0.1176 (0.1176) teacher/entropy 0.0258 (0.0181) teacher/usage_max 0.6012 (0.6409) teacher/usage_min 0.0571 (0.0339) teacher/usage_std 0.2222 (0.2533) nleep/row_max_mean 1524.0173 (1540.5693) nleep/row_max_std 65.3241 (55.6975) nleep/row_min_mean 1491.1074 (1505.3988) lr 1.3090e-03 eta 0:12:47
epoch [22/50] batch [80/173] time 0.159 (0.153) data 0.000 (0.003) loss 1.4332 (1.4646) teacher_loss 0.2384 (0.1978) loss_zs_kd 0.0266 (0.0307) loss_oracle 0.5805 (0.6660) kd_loss 0.8912 (0.9184) acc 93.7500 (91.7188) gate/entropy 1.0292 (1.0298) gate/usage_max 0.4443 (0.4475) gate/usage_min 0.1702 (0.1715) gate/usage_std 0.1179 (0.1176) teacher/entropy 0.0011 (0.0186) teacher/usage_max 0.5627 (0.6313) teacher/usage_min 0.0000 (0.0329) teacher/usage_std 0.2412 (0.2500) nleep/row_max_mean 1543.5129 (1541.1060) nleep/row_max_std 71.8779 (56.0104) nleep/row_min_mean 1505.4880 (1505.8831) lr 1.3090e-03 eta 0:12:36
epoch [22/50] batch [100/173] time 0.147 (0.152) data 0.000 (0.003) loss 1.3267 (1.4533) teacher_loss 0.0773 (0.1937) loss_zs_kd 0.0248 (0.0301) loss_oracle 0.6241 (0.6551) kd_loss 0.9250 (0.9170) acc 96.8750 (91.7812) gate/entropy 1.0289 (1.0297) gate/usage_max 0.4430 (0.4467) gate/usage_min 0.1696 (0.1712) gate/usage_std 0.1180 (0.1177) teacher/entropy 0.0255 (0.0192) teacher/usage_max 0.6330 (0.6336) teacher/usage_min 0.0529 (0.0327) teacher/usage_std 0.2372 (0.2505) nleep/row_max_mean 1550.0896 (1540.7486) nleep/row_max_std 55.7091 (56.0733) nleep/row_min_mean 1516.4956 (1505.6983) lr 1.3090e-03 eta 0:12:29
epoch [22/50] batch [120/173] time 0.157 (0.152) data 0.000 (0.002) loss 1.4153 (1.4505) teacher_loss 0.1903 (0.1904) loss_zs_kd 0.0308 (0.0305) loss_oracle 0.6184 (0.6560) kd_loss 0.9004 (0.9169) acc 93.7500 (91.9010) gate/entropy 1.0284 (1.0295) gate/usage_max 0.4415 (0.4460) gate/usage_min 0.1687 (0.1709) gate/usage_std 0.1183 (0.1177) teacher/entropy 0.0042 (0.0187) teacher/usage_max 0.6866 (0.6279) teacher/usage_min 0.0009 (0.0340) teacher/usage_std 0.2803 (0.2479) nleep/row_max_mean 1551.6594 (1541.2769) nleep/row_max_std 65.3457 (56.6561) nleep/row_min_mean 1515.3938 (1506.0951) lr 1.3090e-03 eta 0:12:22
epoch [22/50] batch [140/173] time 0.108 (0.148) data 0.000 (0.002) loss 1.3799 (1.4453) teacher_loss 0.1165 (0.1869) loss_zs_kd 0.0216 (0.0308) loss_oracle 0.6551 (0.6564) kd_loss 0.9251 (0.9148) acc 93.7500 (92.0089) gate/entropy 1.0283 (1.0294) gate/usage_max 0.4404 (0.4453) gate/usage_min 0.1684 (0.1705) gate/usage_std 0.1183 (0.1178) teacher/entropy 0.0225 (0.0193) teacher/usage_max 0.6330 (0.6271) teacher/usage_min 0.0545 (0.0336) teacher/usage_std 0.2367 (0.2479) nleep/row_max_mean 1525.9172 (1541.5929) nleep/row_max_std 71.9504 (56.8463) nleep/row_min_mean 1492.8115 (1506.3333) lr 1.3090e-03 eta 0:12:03
epoch [22/50] batch [160/173] time 0.077 (0.144) data 0.000 (0.002) loss 1.3610 (1.4407) teacher_loss 0.1162 (0.1839) loss_zs_kd 0.0311 (0.0308) loss_oracle 0.6278 (0.6556) kd_loss 0.9154 (0.9136) acc 93.7500 (92.1484) gate/entropy 1.0280 (1.0292) gate/usage_max 0.4393 (0.4446) gate/usage_min 0.1680 (0.1702) gate/usage_std 0.1185 (0.1179) teacher/entropy 0.0286 (0.0193) teacher/usage_max 0.7063 (0.6290) teacher/usage_min 0.0436 (0.0334) teacher/usage_std 0.2769 (0.2491) nleep/row_max_mean 1530.7004 (1541.5038) nleep/row_max_std 68.3862 (57.5393) nleep/row_min_mean 1499.6907 (1506.2896) lr 1.3090e-03 eta 0:11:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,299
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,012
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.2%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [23/50] batch [20/173] time 0.096 (0.103) data 0.000 (0.014) loss 1.2977 (1.4052) teacher_loss 0.0470 (0.1563) loss_zs_kd 0.0262 (0.0268) loss_oracle 0.6857 (0.6479) kd_loss 0.8948 (0.9116) acc 100.0000 (93.7500) gate/entropy 1.0277 (1.0278) gate/usage_max 0.4379 (0.4383) gate/usage_min 0.1674 (0.1675) gate/usage_std 0.1186 (0.1186) teacher/entropy 0.0178 (0.0162) teacher/usage_max 0.6014 (0.6161) teacher/usage_min 0.0236 (0.0382) teacher/usage_std 0.2377 (0.2406) nleep/row_max_mean 1543.1394 (1536.6603) nleep/row_max_std 66.6980 (59.1530) nleep/row_min_mean 1503.3301 (1502.6667) lr 1.2487e-03 eta 0:08:14
epoch [23/50] batch [40/173] time 0.160 (0.111) data 0.000 (0.007) loss 1.3421 (1.4169) teacher_loss 0.1073 (0.1633) loss_zs_kd 0.0236 (0.0289) loss_oracle 0.6758 (0.6590) kd_loss 0.8852 (0.9097) acc 93.7500 (93.9062) gate/entropy 1.0273 (1.0276) gate/usage_max 0.4369 (0.4378) gate/usage_min 0.1667 (0.1673) gate/usage_std 0.1190 (0.1187) teacher/entropy 0.0311 (0.0170) teacher/usage_max 0.5259 (0.6086) teacher/usage_min 0.0367 (0.0387) teacher/usage_std 0.2128 (0.2387) nleep/row_max_mean 1545.7687 (1538.8644) nleep/row_max_std 62.7939 (59.3994) nleep/row_min_mean 1507.9950 (1504.1162) lr 1.2487e-03 eta 0:08:51
epoch [23/50] batch [60/173] time 0.099 (0.110) data 0.000 (0.005) loss 1.3182 (1.4131) teacher_loss 0.1160 (0.1658) loss_zs_kd 0.0375 (0.0313) loss_oracle 0.6257 (0.6552) kd_loss 0.8706 (0.9041) acc 96.8750 (93.7500) gate/entropy 1.0269 (1.0275) gate/usage_max 0.4359 (0.4374) gate/usage_min 0.1662 (0.1671) gate/usage_std 0.1192 (0.1188) teacher/entropy 0.0217 (0.0170) teacher/usage_max 0.5160 (0.6151) teacher/usage_min 0.0152 (0.0332) teacher/usage_std 0.2258 (0.2438) nleep/row_max_mean 1554.9365 (1539.7912) nleep/row_max_std 64.1037 (58.8726) nleep/row_min_mean 1513.5046 (1504.8056) lr 1.2487e-03 eta 0:08:44
epoch [23/50] batch [80/173] time 0.094 (0.112) data 0.000 (0.004) loss 1.5491 (1.4169) teacher_loss 0.3156 (0.1697) loss_zs_kd 0.0248 (0.0324) loss_oracle 0.6165 (0.6571) kd_loss 0.9128 (0.9025) acc 90.6250 (93.5156) gate/entropy 1.0268 (1.0274) gate/usage_max 0.4353 (0.4370) gate/usage_min 0.1660 (0.1669) gate/usage_std 0.1192 (0.1189) teacher/entropy 0.0086 (0.0162) teacher/usage_max 0.6540 (0.6252) teacher/usage_min 0.0333 (0.0303) teacher/usage_std 0.2538 (0.2499) nleep/row_max_mean 1529.4331 (1539.7537) nleep/row_max_std 62.0444 (58.9862) nleep/row_min_mean 1496.6119 (1504.5515) lr 1.2487e-03 eta 0:08:55
epoch [23/50] batch [100/173] time 0.129 (0.116) data 0.000 (0.003) loss 1.3432 (1.4124) teacher_loss 0.1909 (0.1729) loss_zs_kd 0.0231 (0.0313) loss_oracle 0.5577 (0.6453) kd_loss 0.8620 (0.9012) acc 93.7500 (93.5000) gate/entropy 1.0265 (1.0272) gate/usage_max 0.4345 (0.4366) gate/usage_min 0.1656 (0.1667) gate/usage_std 0.1194 (0.1190) teacher/entropy 0.0366 (0.0168) teacher/usage_max 0.6443 (0.6258) teacher/usage_min 0.0116 (0.0304) teacher/usage_std 0.2584 (0.2498) nleep/row_max_mean 1548.0349 (1539.3462) nleep/row_max_std 46.7600 (59.0726) nleep/row_min_mean 1513.6123 (1504.4005) lr 1.2487e-03 eta 0:09:10
epoch [23/50] batch [120/173] time 0.166 (0.123) data 0.000 (0.002) loss 1.4248 (1.4134) teacher_loss 0.1882 (0.1766) loss_zs_kd 0.0187 (0.0308) loss_oracle 0.6829 (0.6410) kd_loss 0.8858 (0.9009) acc 93.7500 (93.1771) gate/entropy 1.0269 (1.0271) gate/usage_max 0.4343 (0.4362) gate/usage_min 0.1660 (0.1665) gate/usage_std 0.1191 (0.1190) teacher/entropy 0.0338 (0.0177) teacher/usage_max 0.7254 (0.6250) teacher/usage_min 0.0248 (0.0317) teacher/usage_std 0.2920 (0.2488) nleep/row_max_mean 1514.7650 (1538.8505) nleep/row_max_std 68.2575 (59.5636) nleep/row_min_mean 1482.5703 (1503.8800) lr 1.2487e-03 eta 0:09:40
epoch [23/50] batch [140/173] time 0.166 (0.128) data 0.000 (0.002) loss 1.3443 (1.4098) teacher_loss 0.1372 (0.1732) loss_zs_kd 0.0305 (0.0304) loss_oracle 0.6051 (0.6410) kd_loss 0.8893 (0.9009) acc 93.7500 (93.2143) gate/entropy 1.0265 (1.0270) gate/usage_max 0.4336 (0.4358) gate/usage_min 0.1655 (0.1664) gate/usage_std 0.1194 (0.1191) teacher/entropy 0.0346 (0.0186) teacher/usage_max 0.5814 (0.6228) teacher/usage_min 0.0434 (0.0332) teacher/usage_std 0.2216 (0.2476) nleep/row_max_mean 1522.4624 (1538.2316) nleep/row_max_std 59.0007 (59.2724) nleep/row_min_mean 1488.7344 (1503.3741) lr 1.2487e-03 eta 0:10:02
epoch [23/50] batch [160/173] time 0.152 (0.131) data 0.000 (0.002) loss 1.3453 (1.4137) teacher_loss 0.0502 (0.1766) loss_zs_kd 0.0197 (0.0306) loss_oracle 0.6737 (0.6434) kd_loss 0.9484 (0.9001) acc 96.8750 (93.1445) gate/entropy 1.0259 (1.0269) gate/usage_max 0.4327 (0.4355) gate/usage_min 0.1648 (0.1662) gate/usage_std 0.1198 (0.1192) teacher/entropy 0.0210 (0.0198) teacher/usage_max 0.5615 (0.6224) teacher/usage_min 0.0943 (0.0341) teacher/usage_std 0.1909 (0.2467) nleep/row_max_mean 1552.8591 (1537.7185) nleep/row_max_std 56.8394 (59.4597) nleep/row_min_mean 1520.4575 (1502.9924) lr 1.2487e-03 eta 0:10:11
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [24/50] batch [20/173] time 0.129 (0.169) data 0.000 (0.016) loss 1.3935 (1.4074) teacher_loss 0.1022 (0.1734) loss_zs_kd 0.0288 (0.0312) loss_oracle 0.6564 (0.6299) kd_loss 0.9486 (0.9035) acc 96.8750 (92.0312) gate/entropy 1.0259 (1.0258) gate/usage_max 0.4321 (0.4322) gate/usage_min 0.1647 (0.1647) gate/usage_std 0.1198 (0.1199) teacher/entropy 0.0183 (0.0230) teacher/usage_max 0.4972 (0.6001) teacher/usage_min 0.0966 (0.0471) teacher/usage_std 0.1715 (0.2303) nleep/row_max_mean 1546.5229 (1542.7154) nleep/row_max_std 54.3274 (55.6611) nleep/row_min_mean 1510.4045 (1509.0828) lr 1.1874e-03 eta 0:13:08
epoch [24/50] batch [40/173] time 0.078 (0.156) data 0.000 (0.008) loss 1.4437 (1.4056) teacher_loss 0.1923 (0.1722) loss_zs_kd 0.0352 (0.0335) loss_oracle 0.6527 (0.6396) kd_loss 0.9074 (0.8968) acc 90.6250 (92.6562) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4316 (0.4319) gate/usage_min 0.1645 (0.1645) gate/usage_std 0.1199 (0.1199) teacher/entropy 0.0296 (0.0212) teacher/usage_max 0.4702 (0.5959) teacher/usage_min 0.0673 (0.0393) teacher/usage_std 0.1881 (0.2332) nleep/row_max_mean 1536.3778 (1545.2820) nleep/row_max_std 63.5081 (57.3149) nleep/row_min_mean 1499.1254 (1510.4607) lr 1.1874e-03 eta 0:12:03
epoch [24/50] batch [60/173] time 0.145 (0.137) data 0.001 (0.006) loss 1.4461 (1.4136) teacher_loss 0.1930 (0.1745) loss_zs_kd 0.0166 (0.0332) loss_oracle 0.7132 (0.6447) kd_loss 0.8882 (0.9002) acc 93.7500 (92.9688) gate/entropy 1.0255 (1.0257) gate/usage_max 0.4312 (0.4317) gate/usage_min 0.1643 (0.1644) gate/usage_std 0.1200 (0.1200) teacher/entropy 0.0679 (0.0225) teacher/usage_max 0.6097 (0.5983) teacher/usage_min 0.0778 (0.0440) teacher/usage_std 0.2177 (0.2321) nleep/row_max_mean 1546.8149 (1544.4282) nleep/row_max_std 75.3650 (58.2194) nleep/row_min_mean 1510.4365 (1509.7287) lr 1.1874e-03 eta 0:10:32
epoch [24/50] batch [80/173] time 0.134 (0.131) data 0.000 (0.004) loss 1.3456 (1.4174) teacher_loss 0.1107 (0.1754) loss_zs_kd 0.0363 (0.0324) loss_oracle 0.5562 (0.6486) kd_loss 0.9387 (0.9015) acc 96.8750 (93.0469) gate/entropy 1.0252 (1.0256) gate/usage_max 0.4306 (0.4315) gate/usage_min 0.1638 (0.1643) gate/usage_std 0.1203 (0.1200) teacher/entropy 0.0096 (0.0238) teacher/usage_max 0.7494 (0.6067) teacher/usage_min 0.0629 (0.0457) teacher/usage_std 0.2986 (0.2356) nleep/row_max_mean 1547.3938 (1543.9904) nleep/row_max_std 59.8216 (58.7113) nleep/row_min_mean 1519.7428 (1509.7742) lr 1.1874e-03 eta 0:10:00
epoch [24/50] batch [100/173] time 0.191 (0.128) data 0.000 (0.003) loss 1.4047 (1.4245) teacher_loss 0.1435 (0.1798) loss_zs_kd 0.0390 (0.0314) loss_oracle 0.5887 (0.6487) kd_loss 0.9473 (0.9046) acc 96.8750 (92.9062) gate/entropy 1.0252 (1.0255) gate/usage_max 0.4303 (0.4313) gate/usage_min 0.1638 (0.1643) gate/usage_std 0.1203 (0.1201) teacher/entropy 0.0238 (0.0255) teacher/usage_max 0.5231 (0.6034) teacher/usage_min 0.1010 (0.0514) teacher/usage_std 0.1749 (0.2317) nleep/row_max_mean 1546.4723 (1544.3632) nleep/row_max_std 52.4196 (58.0191) nleep/row_min_mean 1515.3499 (1510.5098) lr 1.1874e-03 eta 0:09:43
epoch [24/50] batch [120/173] time 0.185 (0.128) data 0.000 (0.003) loss 1.5044 (1.4359) teacher_loss 0.0925 (0.1872) loss_zs_kd 0.0390 (0.0309) loss_oracle 0.7578 (0.6518) kd_loss 1.0135 (0.9074) acc 96.8750 (92.5000) gate/entropy 1.0251 (1.0254) gate/usage_max 0.4300 (0.4311) gate/usage_min 0.1637 (0.1642) gate/usage_std 0.1204 (0.1201) teacher/entropy 0.0422 (0.0268) teacher/usage_max 0.4311 (0.5955) teacher/usage_min 0.1939 (0.0564) teacher/usage_std 0.1012 (0.2265) nleep/row_max_mean 1544.3300 (1543.4594) nleep/row_max_std 53.2794 (58.8761) nleep/row_min_mean 1509.1248 (1509.8407) lr 1.1874e-03 eta 0:09:42
epoch [24/50] batch [140/173] time 0.076 (0.122) data 0.000 (0.003) loss 1.5988 (1.4376) teacher_loss 0.3311 (0.1868) loss_zs_kd 0.0473 (0.0319) loss_oracle 0.7288 (0.6552) kd_loss 0.8796 (0.9072) acc 87.5000 (92.6786) gate/entropy 1.0250 (1.0254) gate/usage_max 0.4298 (0.4310) gate/usage_min 0.1636 (0.1641) gate/usage_std 0.1204 (0.1201) teacher/entropy 0.0346 (0.0286) teacher/usage_max 0.5532 (0.5928) teacher/usage_min 0.0405 (0.0586) teacher/usage_std 0.2156 (0.2246) nleep/row_max_mean 1533.4951 (1542.5025) nleep/row_max_std 67.1094 (58.8375) nleep/row_min_mean 1499.5984 (1509.1102) lr 1.1874e-03 eta 0:09:11
epoch [24/50] batch [160/173] time 0.079 (0.119) data 0.000 (0.002) loss 1.2926 (1.4406) teacher_loss 0.1211 (0.1874) loss_zs_kd 0.0309 (0.0319) loss_oracle 0.5913 (0.6557) kd_loss 0.8604 (0.9095) acc 100.0000 (92.6367) gate/entropy 1.0252 (1.0253) gate/usage_max 0.4297 (0.4308) gate/usage_min 0.1638 (0.1640) gate/usage_std 0.1203 (0.1202) teacher/entropy 0.0398 (0.0294) teacher/usage_max 0.6358 (0.5896) teacher/usage_min 0.0205 (0.0622) teacher/usage_std 0.2513 (0.2215) nleep/row_max_mean 1520.1327 (1542.4721) nleep/row_max_std 58.4719 (58.4983) nleep/row_min_mean 1487.0286 (1509.2522) lr 1.1874e-03 eta 0:08:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,010
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [25/50] batch [20/173] time 0.147 (0.174) data 0.000 (0.016) loss 1.4663 (1.4687) teacher_loss 0.1090 (0.1821) loss_zs_kd 0.0217 (0.0364) loss_oracle 0.7675 (0.6895) kd_loss 0.9627 (0.9236) acc 96.8750 (92.3438) gate/entropy 1.0250 (1.0248) gate/usage_max 0.4293 (0.4292) gate/usage_min 0.1636 (0.1633) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0267 (0.0377) teacher/usage_max 0.6366 (0.5398) teacher/usage_min 0.1134 (0.0910) teacher/usage_std 0.2216 (0.1895) nleep/row_max_mean 1524.5599 (1540.0205) nleep/row_max_std 51.6345 (60.2307) nleep/row_min_mean 1496.2402 (1507.7835) lr 1.1253e-03 eta 0:12:57
epoch [25/50] batch [40/173] time 0.163 (0.163) data 0.000 (0.008) loss 1.4838 (1.4614) teacher_loss 0.2054 (0.1784) loss_zs_kd 0.0340 (0.0350) loss_oracle 0.7173 (0.6844) kd_loss 0.9027 (0.9234) acc 87.5000 (92.0312) gate/entropy 1.0247 (1.0248) gate/usage_max 0.4290 (0.4291) gate/usage_min 0.1633 (0.1633) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0704 (0.0435) teacher/usage_max 0.5217 (0.5522) teacher/usage_min 0.1034 (0.0961) teacher/usage_std 0.1733 (0.1922) nleep/row_max_mean 1550.7135 (1539.3113) nleep/row_max_std 64.6275 (57.9047) nleep/row_min_mean 1514.4080 (1507.8202) lr 1.1253e-03 eta 0:12:08
epoch [25/50] batch [60/173] time 0.145 (0.159) data 0.000 (0.005) loss 1.3794 (1.4603) teacher_loss 0.1033 (0.1726) loss_zs_kd 0.0388 (0.0333) loss_oracle 0.7136 (0.6851) kd_loss 0.8999 (0.9285) acc 100.0000 (92.7083) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4287 (0.4290) gate/usage_min 0.1631 (0.1632) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0934 (0.0473) teacher/usage_max 0.5776 (0.5449) teacher/usage_min 0.1221 (0.1060) teacher/usage_std 0.1874 (0.1846) nleep/row_max_mean 1532.9523 (1539.3167) nleep/row_max_std 46.3486 (55.4433) nleep/row_min_mean 1507.7112 (1508.2575) lr 1.1253e-03 eta 0:11:45
epoch [25/50] batch [80/173] time 0.156 (0.156) data 0.000 (0.004) loss 1.5229 (1.4707) teacher_loss 0.2705 (0.1734) loss_zs_kd 0.0271 (0.0334) loss_oracle 0.7165 (0.6857) kd_loss 0.8806 (0.9378) acc 87.5000 (92.7344) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4286 (0.4289) gate/usage_min 0.1630 (0.1632) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0495 (0.0468) teacher/usage_max 0.5686 (0.5391) teacher/usage_min 0.0564 (0.1153) teacher/usage_std 0.2112 (0.1784) nleep/row_max_mean 1548.2542 (1538.9207) nleep/row_max_std 58.9896 (54.3599) nleep/row_min_mean 1516.6556 (1508.0461) lr 1.1253e-03 eta 0:11:29
epoch [25/50] batch [100/173] time 0.154 (0.155) data 0.000 (0.003) loss 1.5198 (1.4831) teacher_loss 0.1627 (0.1796) loss_zs_kd 0.0211 (0.0342) loss_oracle 0.7035 (0.6814) kd_loss 0.9947 (0.9457) acc 90.6250 (92.6562) gate/entropy 1.0246 (1.0246) gate/usage_max 0.4284 (0.4288) gate/usage_min 0.1630 (0.1631) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0420 (0.0472) teacher/usage_max 0.4155 (0.5318) teacher/usage_min 0.1753 (0.1244) teacher/usage_std 0.1117 (0.1717) nleep/row_max_mean 1539.6091 (1539.1746) nleep/row_max_std 63.9475 (54.1856) nleep/row_min_mean 1506.7332 (1508.3993) lr 1.1253e-03 eta 0:11:19
epoch [25/50] batch [120/173] time 0.129 (0.153) data 0.000 (0.003) loss 1.4975 (1.4856) teacher_loss 0.2312 (0.1801) loss_zs_kd 0.0323 (0.0349) loss_oracle 0.6287 (0.6787) kd_loss 0.9359 (0.9487) acc 93.7500 (92.6042) gate/entropy 1.0244 (1.0246) gate/usage_max 0.4282 (0.4287) gate/usage_min 0.1629 (0.1631) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0817 (0.0498) teacher/usage_max 0.5380 (0.5336) teacher/usage_min 0.1494 (0.1285) teacher/usage_std 0.1593 (0.1707) nleep/row_max_mean 1532.0288 (1538.6145) nleep/row_max_std 53.4176 (55.1238) nleep/row_min_mean 1502.1787 (1507.8684) lr 1.1253e-03 eta 0:11:08
epoch [25/50] batch [140/173] time 0.138 (0.151) data 0.000 (0.002) loss 1.3938 (1.4853) teacher_loss 0.1146 (0.1804) loss_zs_kd 0.0223 (0.0345) loss_oracle 0.6033 (0.6741) kd_loss 0.9663 (0.9505) acc 93.7500 (92.7679) gate/entropy 1.0243 (1.0246) gate/usage_max 0.4280 (0.4286) gate/usage_min 0.1627 (0.1631) gate/usage_std 0.1209 (0.1207) teacher/entropy 0.0351 (0.0492) teacher/usage_max 0.4569 (0.5295) teacher/usage_min 0.1367 (0.1302) teacher/usage_std 0.1406 (0.1682) nleep/row_max_mean 1544.4984 (1538.4098) nleep/row_max_std 63.1611 (55.8391) nleep/row_min_mean 1511.5559 (1507.5622) lr 1.1253e-03 eta 0:10:57
epoch [25/50] batch [160/173] time 0.071 (0.149) data 0.000 (0.002) loss 1.5186 (1.4893) teacher_loss 0.1796 (0.1843) loss_zs_kd 0.0345 (0.0347) loss_oracle 0.6765 (0.6722) kd_loss 0.9834 (0.9516) acc 87.5000 (92.5391) gate/entropy 1.0245 (1.0246) gate/usage_max 0.4279 (0.4285) gate/usage_min 0.1629 (0.1630) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0555 (0.0503) teacher/usage_max 0.5477 (0.5307) teacher/usage_min 0.1709 (0.1323) teacher/usage_std 0.1581 (0.1683) nleep/row_max_mean 1531.3981 (1537.6445) nleep/row_max_std 71.2296 (56.4107) nleep/row_min_mean 1497.8196 (1506.9333) lr 1.1253e-03 eta 0:10:46
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,010
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [26/50] batch [20/173] time 0.149 (0.136) data 0.000 (0.015) loss 1.5037 (1.4600) teacher_loss 0.1151 (0.1484) loss_zs_kd 0.0127 (0.0337) loss_oracle 0.7191 (0.6606) kd_loss 1.0227 (0.9644) acc 96.8750 (94.8438) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4276 (0.4276) gate/usage_min 0.1628 (0.1627) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0566 (0.0555) teacher/usage_max 0.4372 (0.5072) teacher/usage_min 0.2191 (0.1497) teacher/usage_std 0.0893 (0.1500) nleep/row_max_mean 1541.2163 (1536.8657) nleep/row_max_std 67.7766 (60.9946) nleep/row_min_mean 1508.8762 (1505.3427) lr 1.0628e-03 eta 0:09:44
epoch [26/50] batch [40/173] time 0.092 (0.115) data 0.000 (0.008) loss 1.4592 (1.4706) teacher_loss 0.2084 (0.1472) loss_zs_kd 0.0260 (0.0341) loss_oracle 0.6414 (0.6553) kd_loss 0.9171 (0.9787) acc 90.6250 (94.5312) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4274 (0.4275) gate/usage_min 0.1627 (0.1626) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0918 (0.0592) teacher/usage_max 0.5410 (0.4917) teacher/usage_min 0.1403 (0.1703) teacher/usage_std 0.1639 (0.1356) nleep/row_max_mean 1528.6365 (1534.7390) nleep/row_max_std 72.4413 (61.2822) nleep/row_min_mean 1498.5026 (1503.7923) lr 1.0628e-03 eta 0:08:14
epoch [26/50] batch [60/173] time 0.083 (0.117) data 0.000 (0.005) loss 1.7275 (1.4764) teacher_loss 0.3991 (0.1582) loss_zs_kd 0.0507 (0.0346) loss_oracle 0.6476 (0.6498) kd_loss 0.9792 (0.9760) acc 84.3750 (94.0104) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4272 (0.4274) gate/usage_min 0.1624 (0.1626) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0658 (0.0597) teacher/usage_max 0.5323 (0.4949) teacher/usage_min 0.1788 (0.1683) teacher/usage_std 0.1477 (0.1383) nleep/row_max_mean 1521.5276 (1534.4029) nleep/row_max_std 58.1673 (61.4754) nleep/row_min_mean 1494.2292 (1503.8057) lr 1.0628e-03 eta 0:08:18
epoch [26/50] batch [80/173] time 0.080 (0.116) data 0.000 (0.004) loss 1.3734 (1.4788) teacher_loss 0.1074 (0.1535) loss_zs_kd 0.0207 (0.0333) loss_oracle 0.6773 (0.6533) kd_loss 0.9170 (0.9820) acc 96.8750 (94.0625) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4271 (0.4274) gate/usage_min 0.1625 (0.1626) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0634 (0.0604) teacher/usage_max 0.5453 (0.4981) teacher/usage_min 0.1112 (0.1728) teacher/usage_std 0.1774 (0.1378) nleep/row_max_mean 1543.5837 (1534.0230) nleep/row_max_std 61.8825 (60.8220) nleep/row_min_mean 1513.1515 (1503.6489) lr 1.0628e-03 eta 0:08:12
epoch [26/50] batch [100/173] time 0.085 (0.115) data 0.000 (0.003) loss 1.5731 (1.4945) teacher_loss 0.1621 (0.1546) loss_zs_kd 0.0424 (0.0343) loss_oracle 0.7519 (0.6578) kd_loss 1.0138 (0.9939) acc 96.8750 (93.8125) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4270 (0.4273) gate/usage_min 0.1624 (0.1626) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0320 (0.0594) teacher/usage_max 0.4408 (0.4934) teacher/usage_min 0.1842 (0.1795) teacher/usage_std 0.1088 (0.1332) nleep/row_max_mean 1542.9176 (1534.0820) nleep/row_max_std 54.2293 (58.8986) nleep/row_min_mean 1510.9089 (1503.9166) lr 1.0628e-03 eta 0:08:06
epoch [26/50] batch [120/173] time 0.156 (0.119) data 0.000 (0.003) loss 1.5958 (1.4986) teacher_loss 0.2446 (0.1518) loss_zs_kd 0.0439 (0.0340) loss_oracle 0.7353 (0.6637) kd_loss 0.9615 (0.9979) acc 87.5000 (94.0104) gate/entropy 1.0238 (1.0242) gate/usage_max 0.4267 (0.4272) gate/usage_min 0.1621 (0.1625) gate/usage_std 0.1212 (0.1210) teacher/entropy 0.0939 (0.0595) teacher/usage_max 0.5248 (0.4885) teacher/usage_min 0.1906 (0.1845) teacher/usage_std 0.1407 (0.1294) nleep/row_max_mean 1544.9536 (1534.4054) nleep/row_max_std 50.6298 (58.2846) nleep/row_min_mean 1519.3662 (1504.3457) lr 1.0628e-03 eta 0:08:19
epoch [26/50] batch [140/173] time 0.173 (0.123) data 0.000 (0.002) loss 1.5687 (1.5047) teacher_loss 0.2335 (0.1549) loss_zs_kd 0.0278 (0.0341) loss_oracle 0.5976 (0.6617) kd_loss 1.0225 (1.0019) acc 87.5000 (93.7500) gate/entropy 1.0239 (1.0241) gate/usage_max 0.4267 (0.4271) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0780 (0.0575) teacher/usage_max 0.3831 (0.4848) teacher/usage_min 0.2424 (0.1876) teacher/usage_std 0.0644 (0.1266) nleep/row_max_mean 1541.5828 (1535.0941) nleep/row_max_std 50.7819 (57.9999) nleep/row_min_mean 1513.3953 (1504.8011) lr 1.0628e-03 eta 0:08:36
epoch [26/50] batch [160/173] time 0.150 (0.127) data 0.000 (0.002) loss 1.4811 (1.5097) teacher_loss 0.1452 (0.1568) loss_zs_kd 0.0328 (0.0343) loss_oracle 0.6463 (0.6638) kd_loss 0.9963 (1.0039) acc 93.7500 (93.6133) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4267 (0.4271) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0672 (0.0562) teacher/usage_max 0.5746 (0.4841) teacher/usage_min 0.1967 (0.1884) teacher/usage_std 0.1711 (0.1260) nleep/row_max_mean 1536.6737 (1535.6739) nleep/row_max_std 59.6239 (57.3395) nleep/row_min_mean 1507.1344 (1505.2147) lr 1.0628e-03 eta 0:08:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,010
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [27/50] batch [20/173] time 0.155 (0.172) data 0.000 (0.016) loss 1.6759 (1.5441) teacher_loss 0.2277 (0.1767) loss_zs_kd 0.0486 (0.0347) loss_oracle 0.6793 (0.6680) kd_loss 1.0842 (1.0161) acc 90.6250 (92.8125) gate/entropy 1.0240 (1.0240) gate/usage_max 0.4265 (0.4265) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0541 (0.0486) teacher/usage_max 0.5371 (0.4790) teacher/usage_min 0.1875 (0.1899) teacher/usage_std 0.1485 (0.1240) nleep/row_max_mean 1530.5636 (1541.9268) nleep/row_max_std 57.8361 (53.2014) nleep/row_min_mean 1502.4938 (1509.5508) lr 1.0000e-03 eta 0:11:50
epoch [27/50] batch [40/173] time 0.151 (0.162) data 0.000 (0.008) loss 1.4598 (1.5351) teacher_loss 0.1388 (0.1621) loss_zs_kd 0.0327 (0.0380) loss_oracle 0.6355 (0.6678) kd_loss 0.9869 (1.0201) acc 90.6250 (93.2812) gate/entropy 1.0241 (1.0240) gate/usage_max 0.4264 (0.4265) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0272 (0.0449) teacher/usage_max 0.5407 (0.4765) teacher/usage_min 0.1468 (0.1928) teacher/usage_std 0.1615 (0.1211) nleep/row_max_mean 1536.1299 (1541.4738) nleep/row_max_std 50.8395 (51.2156) nleep/row_min_mean 1503.3679 (1509.3638) lr 1.0000e-03 eta 0:11:06
epoch [27/50] batch [60/173] time 0.104 (0.150) data 0.000 (0.005) loss 1.3957 (1.5287) teacher_loss 0.1410 (0.1646) loss_zs_kd 0.0284 (0.0389) loss_oracle 0.5592 (0.6620) kd_loss 0.9609 (1.0137) acc 96.8750 (93.2812) gate/entropy 1.0241 (1.0239) gate/usage_max 0.4263 (0.4264) gate/usage_min 0.1625 (0.1623) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0752 (0.0442) teacher/usage_max 0.5123 (0.4833) teacher/usage_min 0.1711 (0.1845) teacher/usage_std 0.1398 (0.1268) nleep/row_max_mean 1545.8060 (1543.4179) nleep/row_max_std 43.6591 (50.9505) nleep/row_min_mean 1511.3163 (1511.0835) lr 1.0000e-03 eta 0:10:15
epoch [27/50] batch [80/173] time 0.077 (0.139) data 0.000 (0.004) loss 1.6017 (1.5343) teacher_loss 0.1982 (0.1655) loss_zs_kd 0.0420 (0.0379) loss_oracle 0.6529 (0.6602) kd_loss 1.0561 (1.0197) acc 90.6250 (93.2031) gate/entropy 1.0237 (1.0239) gate/usage_max 0.4261 (0.4264) gate/usage_min 0.1620 (0.1623) gate/usage_std 0.1213 (0.1211) teacher/entropy 0.0217 (0.0404) teacher/usage_max 0.5366 (0.4853) teacher/usage_min 0.2134 (0.1866) teacher/usage_std 0.1445 (0.1272) nleep/row_max_mean 1554.3744 (1544.4363) nleep/row_max_std 46.2469 (50.3495) nleep/row_min_mean 1525.9580 (1512.1760) lr 1.0000e-03 eta 0:09:25
epoch [27/50] batch [100/173] time 0.115 (0.134) data 0.000 (0.003) loss 1.5016 (1.5435) teacher_loss 0.1468 (0.1668) loss_zs_kd 0.0223 (0.0381) loss_oracle 0.6065 (0.6590) kd_loss 1.0404 (1.0281) acc 93.7500 (93.0000) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4260 (0.4263) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0548 (0.0395) teacher/usage_max 0.4181 (0.4804) teacher/usage_min 0.2351 (0.1915) teacher/usage_std 0.0753 (0.1233) nleep/row_max_mean 1555.4073 (1545.3828) nleep/row_max_std 64.1103 (50.4977) nleep/row_min_mean 1521.7098 (1513.2382) lr 1.0000e-03 eta 0:09:03
epoch [27/50] batch [120/173] time 0.118 (0.131) data 0.000 (0.003) loss 1.6254 (1.5491) teacher_loss 0.1369 (0.1658) loss_zs_kd 0.0413 (0.0376) loss_oracle 0.7046 (0.6551) kd_loss 1.1155 (1.0369) acc 90.6250 (93.1510) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4260 (0.4263) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0222 (0.0400) teacher/usage_max 0.4320 (0.4729) teacher/usage_min 0.2832 (0.2001) teacher/usage_std 0.0697 (0.1165) nleep/row_max_mean 1548.6261 (1545.9074) nleep/row_max_std 50.1857 (50.6063) nleep/row_min_mean 1510.3567 (1513.7363) lr 1.0000e-03 eta 0:08:46
epoch [27/50] batch [140/173] time 0.085 (0.128) data 0.000 (0.002) loss 1.5919 (1.5499) teacher_loss 0.1535 (0.1601) loss_zs_kd 0.0515 (0.0372) loss_oracle 0.6681 (0.6558) kd_loss 1.0786 (1.0433) acc 93.7500 (93.5268) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4259 (0.4262) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0041 (0.0407) teacher/usage_max 0.5307 (0.4693) teacher/usage_min 0.2194 (0.2060) teacher/usage_std 0.1401 (0.1125) nleep/row_max_mean 1541.0854 (1546.5715) nleep/row_max_std 62.3901 (50.7160) nleep/row_min_mean 1510.2805 (1514.3260) lr 1.0000e-03 eta 0:08:34
epoch [27/50] batch [160/173] time 0.077 (0.124) data 0.000 (0.002) loss 1.6027 (1.5541) teacher_loss 0.1703 (0.1616) loss_zs_kd 0.0463 (0.0373) loss_oracle 0.6979 (0.6562) kd_loss 1.0603 (1.0458) acc 90.6250 (93.5547) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4258 (0.4262) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1212 (0.1212) teacher/entropy 0.0273 (0.0403) teacher/usage_max 0.3977 (0.4658) teacher/usage_min 0.2281 (0.2069) teacher/usage_std 0.0750 (0.1106) nleep/row_max_mean 1556.7382 (1547.3081) nleep/row_max_std 49.9881 (51.4296) nleep/row_min_mean 1522.1309 (1515.0931) lr 1.0000e-03 eta 0:08:15
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,312
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [28/50] batch [20/173] time 0.130 (0.143) data 0.000 (0.014) loss 1.7417 (1.5840) teacher_loss 0.1170 (0.1422) loss_zs_kd 0.0344 (0.0389) loss_oracle 0.8443 (0.7094) kd_loss 1.1853 (1.0677) acc 93.7500 (94.6875) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4257 (0.4258) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1212 (0.1212) teacher/entropy 0.0235 (0.0314) teacher/usage_max 0.3572 (0.4588) teacher/usage_min 0.2987 (0.2292) teacher/usage_std 0.0251 (0.0992) nleep/row_max_mean 1557.7529 (1547.6539) nleep/row_max_std 49.3659 (55.4059) nleep/row_min_mean 1522.7595 (1515.3170) lr 9.3721e-04 eta 0:09:24
epoch [28/50] batch [40/173] time 0.147 (0.144) data 0.000 (0.007) loss 1.7049 (1.6106) teacher_loss 0.1068 (0.1448) loss_zs_kd 0.0316 (0.0361) loss_oracle 0.7073 (0.7085) kd_loss 1.2287 (1.0935) acc 93.7500 (94.7656) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4257 (0.4257) gate/usage_min 0.1621 (0.1621) gate/usage_std 0.1212 (0.1212) teacher/entropy 0.0013 (0.0362) teacher/usage_max 0.4062 (0.4491) teacher/usage_min 0.2187 (0.2275) teacher/usage_std 0.0820 (0.0951) nleep/row_max_mean 1541.8038 (1546.7314) nleep/row_max_std 68.4324 (57.4273) nleep/row_min_mean 1509.1639 (1514.9555) lr 9.3721e-04 eta 0:09:25
epoch [28/50] batch [60/173] time 0.142 (0.145) data 0.000 (0.005) loss 1.6948 (1.6120) teacher_loss 0.2393 (0.1485) loss_zs_kd 0.0292 (0.0363) loss_oracle 0.6465 (0.7021) kd_loss 1.1177 (1.0942) acc 90.6250 (94.7396) gate/entropy 1.0237 (1.0238) gate/usage_max 0.4256 (0.4257) gate/usage_min 0.1620 (0.1621) gate/usage_std 0.1213 (0.1212) teacher/entropy 0.0466 (0.0396) teacher/usage_max 0.4517 (0.4425) teacher/usage_min 0.2359 (0.2273) teacher/usage_std 0.0893 (0.0921) nleep/row_max_mean 1559.2157 (1548.4254) nleep/row_max_std 50.3552 (57.5770) nleep/row_min_mean 1526.7832 (1516.1238) lr 9.3721e-04 eta 0:09:26
epoch [28/50] batch [80/173] time 0.158 (0.144) data 0.000 (0.004) loss 1.6540 (1.6346) teacher_loss 0.2227 (0.1554) loss_zs_kd 0.0496 (0.0366) loss_oracle 0.6814 (0.7114) kd_loss 1.0658 (1.1052) acc 87.5000 (94.4922) gate/entropy 1.0241 (1.0239) gate/usage_max 0.4256 (0.4257) gate/usage_min 0.1624 (0.1622) gate/usage_std 0.1210 (0.1212) teacher/entropy 0.0585 (0.0418) teacher/usage_max 0.3796 (0.4374) teacher/usage_min 0.2682 (0.2306) teacher/usage_std 0.0474 (0.0881) nleep/row_max_mean 1538.2603 (1547.9062) nleep/row_max_std 66.5214 (57.9580) nleep/row_min_mean 1500.0261 (1515.4112) lr 9.3721e-04 eta 0:09:23
epoch [28/50] batch [100/173] time 0.131 (0.145) data 0.000 (0.003) loss 1.7659 (1.6325) teacher_loss 0.1752 (0.1503) loss_zs_kd 0.0443 (0.0368) loss_oracle 0.8276 (0.7098) kd_loss 1.1547 (1.1089) acc 96.8750 (94.8125) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4255 (0.4257) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0715 (0.0448) teacher/usage_max 0.4397 (0.4358) teacher/usage_min 0.1804 (0.2329) teacher/usage_std 0.1109 (0.0868) nleep/row_max_mean 1561.6924 (1547.5166) nleep/row_max_std 54.9153 (58.5570) nleep/row_min_mean 1521.3597 (1514.7558) lr 9.3721e-04 eta 0:09:22
epoch [28/50] batch [120/173] time 0.153 (0.146) data 0.000 (0.002) loss 1.6927 (1.6426) teacher_loss 0.1811 (0.1547) loss_zs_kd 0.0529 (0.0373) loss_oracle 0.6473 (0.7062) kd_loss 1.1616 (1.1162) acc 90.6250 (94.4792) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4255 (0.4256) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0060 (0.0451) teacher/usage_max 0.3758 (0.4347) teacher/usage_min 0.3118 (0.2356) teacher/usage_std 0.0300 (0.0852) nleep/row_max_mean 1547.9832 (1547.7164) nleep/row_max_std 52.2621 (58.5016) nleep/row_min_mean 1509.8705 (1514.7787) lr 9.3721e-04 eta 0:09:23
epoch [28/50] batch [140/173] time 0.156 (0.146) data 0.000 (0.002) loss 1.6647 (1.6503) teacher_loss 0.1208 (0.1505) loss_zs_kd 0.0341 (0.0382) loss_oracle 0.7898 (0.7147) kd_loss 1.1320 (1.1233) acc 96.8750 (94.6652) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1623 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0273 (0.0447) teacher/usage_max 0.4404 (0.4328) teacher/usage_min 0.2520 (0.2373) teacher/usage_std 0.0790 (0.0835) nleep/row_max_mean 1554.9827 (1548.0906) nleep/row_max_std 59.4939 (58.4319) nleep/row_min_mean 1518.1760 (1514.8103) lr 9.3721e-04 eta 0:09:20
epoch [28/50] batch [160/173] time 0.131 (0.146) data 0.000 (0.002) loss 1.6510 (1.6589) teacher_loss 0.0634 (0.1539) loss_zs_kd 0.0370 (0.0388) loss_oracle 0.6875 (0.7163) kd_loss 1.2254 (1.1275) acc 100.0000 (94.4336) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4255 (0.4256) gate/usage_min 0.1623 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0866 (0.0456) teacher/usage_max 0.4659 (0.4307) teacher/usage_min 0.2359 (0.2401) teacher/usage_std 0.0971 (0.0814) nleep/row_max_mean 1547.5529 (1547.8694) nleep/row_max_std 57.2410 (57.9421) nleep/row_min_mean 1513.1353 (1514.5116) lr 9.3721e-04 eta 0:09:16
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,309
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [29/50] batch [20/173] time 0.183 (0.137) data 0.000 (0.017) loss 1.7442 (1.7123) teacher_loss 0.2390 (0.1912) loss_zs_kd 0.0547 (0.0383) loss_oracle 0.7256 (0.6804) kd_loss 1.1150 (1.1618) acc 84.3750 (92.0312) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0450 (0.0488) teacher/usage_max 0.4418 (0.4438) teacher/usage_min 0.2556 (0.2322) teacher/usage_std 0.0791 (0.0900) nleep/row_max_mean 1536.1145 (1542.0908) nleep/row_max_std 56.2898 (54.8650) nleep/row_min_mean 1504.3296 (1509.3995) lr 8.7467e-04 eta 0:08:39
epoch [29/50] batch [40/173] time 0.076 (0.125) data 0.000 (0.008) loss 1.6131 (1.6668) teacher_loss 0.0689 (0.1701) loss_zs_kd 0.0348 (0.0383) loss_oracle 0.6578 (0.6569) kd_loss 1.1979 (1.1491) acc 100.0000 (93.0469) gate/entropy 1.0245 (1.0242) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0420 (0.0489) teacher/usage_max 0.3898 (0.4286) teacher/usage_min 0.2813 (0.2388) teacher/usage_std 0.0444 (0.0813) nleep/row_max_mean 1544.6982 (1543.9998) nleep/row_max_std 62.8948 (54.2964) nleep/row_min_mean 1509.6384 (1510.5492) lr 8.7467e-04 eta 0:07:52
epoch [29/50] batch [60/173] time 0.099 (0.119) data 0.001 (0.006) loss 1.6300 (1.6404) teacher_loss 0.2270 (0.1664) loss_zs_kd 0.0465 (0.0397) loss_oracle 0.6514 (0.6476) kd_loss 1.0541 (1.1303) acc 87.5000 (93.2292) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4255 (0.4256) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0280 (0.0478) teacher/usage_max 0.4400 (0.4299) teacher/usage_min 0.2247 (0.2432) teacher/usage_std 0.0879 (0.0800) nleep/row_max_mean 1541.8599 (1543.7147) nleep/row_max_std 62.4724 (54.5926) nleep/row_min_mean 1507.8206 (1510.0182) lr 8.7467e-04 eta 0:07:26
epoch [29/50] batch [80/173] time 0.093 (0.116) data 0.000 (0.004) loss 1.6207 (1.6344) teacher_loss 0.1609 (0.1725) loss_zs_kd 0.0346 (0.0422) loss_oracle 0.5918 (0.6415) kd_loss 1.1467 (1.1201) acc 93.7500 (93.2031) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4254 (0.4255) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0314 (0.0462) teacher/usage_max 0.4035 (0.4332) teacher/usage_min 0.2689 (0.2412) teacher/usage_std 0.0551 (0.0829) nleep/row_max_mean 1553.1757 (1544.2838) nleep/row_max_std 39.5155 (53.9816) nleep/row_min_mean 1518.1112 (1510.6441) lr 8.7467e-04 eta 0:07:13
epoch [29/50] batch [100/173] time 0.195 (0.120) data 0.000 (0.004) loss 1.4945 (1.6267) teacher_loss 0.0386 (0.1650) loss_zs_kd 0.0333 (0.0421) loss_oracle 0.6519 (0.6398) kd_loss 1.1132 (1.1207) acc 100.0000 (93.3438) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4254 (0.4255) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0307 (0.0449) teacher/usage_max 0.3745 (0.4277) teacher/usage_min 0.2873 (0.2454) teacher/usage_std 0.0358 (0.0786) nleep/row_max_mean 1540.3696 (1544.7034) nleep/row_max_std 57.7009 (53.7110) nleep/row_min_mean 1504.0790 (1510.8305) lr 8.7467e-04 eta 0:07:22
epoch [29/50] batch [120/173] time 0.088 (0.120) data 0.000 (0.003) loss 1.5036 (1.6145) teacher_loss 0.0907 (0.1616) loss_zs_kd 0.0361 (0.0419) loss_oracle 0.5636 (0.6363) kd_loss 1.1130 (1.1138) acc 96.8750 (93.4115) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4253 (0.4255) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0484 (0.0434) teacher/usage_max 0.3501 (0.4308) teacher/usage_min 0.3060 (0.2437) teacher/usage_std 0.0195 (0.0806) nleep/row_max_mean 1560.9302 (1545.0153) nleep/row_max_std 43.5813 (53.4709) nleep/row_min_mean 1526.8890 (1511.0794) lr 8.7467e-04 eta 0:07:22
epoch [29/50] batch [140/173] time 0.163 (0.123) data 0.000 (0.003) loss 1.5570 (1.6085) teacher_loss 0.0695 (0.1568) loss_zs_kd 0.0479 (0.0411) loss_oracle 0.6155 (0.6348) kd_loss 1.1558 (1.1137) acc 96.8750 (93.6384) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4252 (0.4254) gate/usage_min 0.1622 (0.1625) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0081 (0.0416) teacher/usage_max 0.4062 (0.4318) teacher/usage_min 0.2829 (0.2459) teacher/usage_std 0.0528 (0.0803) nleep/row_max_mean 1559.1091 (1545.7607) nleep/row_max_std 47.2241 (53.5168) nleep/row_min_mean 1524.2141 (1511.7011) lr 8.7467e-04 eta 0:07:31
epoch [29/50] batch [160/173] time 0.145 (0.127) data 0.000 (0.002) loss 1.6681 (1.6081) teacher_loss 0.2628 (0.1582) loss_zs_kd 0.0450 (0.0416) loss_oracle 0.6214 (0.6344) kd_loss 1.0721 (1.1119) acc 90.6250 (93.6719) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4251 (0.4254) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0067 (0.0402) teacher/usage_max 0.4373 (0.4310) teacher/usage_min 0.2190 (0.2457) teacher/usage_std 0.0894 (0.0800) nleep/row_max_mean 1554.1677 (1545.7741) nleep/row_max_std 62.3084 (53.6485) nleep/row_min_mean 1516.1121 (1511.6679) lr 8.7467e-04 eta 0:07:43
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,305
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [30/50] batch [20/173] time 0.159 (0.161) data 0.000 (0.015) loss 1.5611 (1.5863) teacher_loss 0.1093 (0.1564) loss_zs_kd 0.0268 (0.0374) loss_oracle 0.5834 (0.6395) kd_loss 1.1467 (1.0914) acc 96.8750 (93.9062) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0183 (0.0373) teacher/usage_max 0.3785 (0.4349) teacher/usage_min 0.3089 (0.2495) teacher/usage_std 0.0319 (0.0790) nleep/row_max_mean 1552.5668 (1545.6093) nleep/row_max_std 45.7377 (52.4001) nleep/row_min_mean 1523.5959 (1511.7776) lr 8.1262e-04 eta 0:09:42
epoch [30/50] batch [40/173] time 0.151 (0.151) data 0.000 (0.008) loss 1.4866 (1.5763) teacher_loss 0.1756 (0.1413) loss_zs_kd 0.0385 (0.0371) loss_oracle 0.6135 (0.6350) kd_loss 0.9850 (1.0988) acc 87.5000 (94.6875) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4250 (0.4251) gate/usage_min 0.1622 (0.1625) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0299 (0.0296) teacher/usage_max 0.4698 (0.4305) teacher/usage_min 0.1528 (0.2455) teacher/usage_std 0.1331 (0.0796) nleep/row_max_mean 1565.1245 (1547.1734) nleep/row_max_std 53.8697 (52.9496) nleep/row_min_mean 1523.7712 (1512.9968) lr 8.1262e-04 eta 0:09:04
epoch [30/50] batch [60/173] time 0.141 (0.149) data 0.001 (0.005) loss 1.5630 (1.5697) teacher_loss 0.2473 (0.1404) loss_zs_kd 0.0529 (0.0396) loss_oracle 0.6088 (0.6384) kd_loss 0.9849 (1.0903) acc 90.6250 (94.8958) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1626 (0.1625) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0387 (0.0301) teacher/usage_max 0.4516 (0.4329) teacher/usage_min 0.1601 (0.2407) teacher/usage_std 0.1252 (0.0824) nleep/row_max_mean 1543.9725 (1547.1761) nleep/row_max_std 61.2882 (53.5182) nleep/row_min_mean 1506.2368 (1512.7996) lr 8.1262e-04 eta 0:08:54
epoch [30/50] batch [80/173] time 0.094 (0.144) data 0.000 (0.004) loss 1.3947 (1.5597) teacher_loss 0.0766 (0.1370) loss_zs_kd 0.0358 (0.0409) loss_oracle 0.6802 (0.6386) kd_loss 0.9601 (1.0830) acc 100.0000 (95.0391) gate/entropy 1.0246 (1.0242) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1629 (0.1625) gate/usage_std 0.1206 (0.1209) teacher/entropy 0.0675 (0.0292) teacher/usage_max 0.4237 (0.4429) teacher/usage_min 0.1651 (0.2332) teacher/usage_std 0.1191 (0.0903) nleep/row_max_mean 1541.2091 (1547.0533) nleep/row_max_std 61.3467 (53.9469) nleep/row_min_mean 1498.9702 (1512.3784) lr 8.1262e-04 eta 0:08:32
epoch [30/50] batch [100/173] time 0.071 (0.137) data 0.000 (0.003) loss 1.7135 (1.5614) teacher_loss 0.2538 (0.1384) loss_zs_kd 0.0798 (0.0422) loss_oracle 0.6619 (0.6388) kd_loss 1.0888 (1.0824) acc 87.5000 (94.7812) gate/entropy 1.0239 (1.0242) gate/usage_max 0.4249 (0.4250) gate/usage_min 0.1622 (0.1625) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0272 (0.0292) teacher/usage_max 0.3765 (0.4446) teacher/usage_min 0.2590 (0.2336) teacher/usage_std 0.0528 (0.0907) nleep/row_max_mean 1554.8287 (1546.6255) nleep/row_max_std 55.4431 (54.1079) nleep/row_min_mean 1516.9229 (1511.8555) lr 8.1262e-04 eta 0:08:05
epoch [30/50] batch [120/173] time 0.104 (0.134) data 0.000 (0.003) loss 1.6203 (1.5564) teacher_loss 0.1454 (0.1403) loss_zs_kd 0.0417 (0.0423) loss_oracle 0.6785 (0.6385) kd_loss 1.1148 (1.0756) acc 93.7500 (94.6875) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4249 (0.4250) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0205 (0.0285) teacher/usage_max 0.4746 (0.4503) teacher/usage_min 0.2500 (0.2266) teacher/usage_std 0.1004 (0.0960) nleep/row_max_mean 1543.3391 (1546.1753) nleep/row_max_std 44.1292 (54.2163) nleep/row_min_mean 1507.6643 (1511.3792) lr 8.1262e-04 eta 0:07:52
epoch [30/50] batch [140/173] time 0.067 (0.131) data 0.000 (0.002) loss 1.5793 (1.5529) teacher_loss 0.1254 (0.1399) loss_zs_kd 0.0310 (0.0418) loss_oracle 0.7321 (0.6360) kd_loss 1.0723 (1.0742) acc 93.7500 (94.5312) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4248 (0.4250) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0080 (0.0279) teacher/usage_max 0.5310 (0.4483) teacher/usage_min 0.2173 (0.2264) teacher/usage_std 0.1405 (0.0952) nleep/row_max_mean 1546.3198 (1545.2067) nleep/row_max_std 62.5287 (54.3929) nleep/row_min_mean 1511.0399 (1510.5132) lr 8.1262e-04 eta 0:07:39
epoch [30/50] batch [160/173] time 0.081 (0.128) data 0.000 (0.002) loss 1.5411 (1.5569) teacher_loss 0.1891 (0.1417) loss_zs_kd 0.0324 (0.0415) loss_oracle 0.6773 (0.6380) kd_loss 0.9972 (1.0755) acc 93.7500 (94.3359) gate/entropy 1.0246 (1.0242) gate/usage_max 0.4249 (0.4250) gate/usage_min 0.1630 (0.1625) gate/usage_std 0.1206 (0.1209) teacher/entropy 0.0249 (0.0267) teacher/usage_max 0.4822 (0.4495) teacher/usage_min 0.1569 (0.2242) teacher/usage_std 0.1342 (0.0967) nleep/row_max_mean 1526.6309 (1544.4529) nleep/row_max_std 70.4285 (54.3558) nleep/row_min_mean 1489.8359 (1509.7990) lr 8.1262e-04 eta 0:07:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,314
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [31/50] batch [20/173] time 0.104 (0.129) data 0.000 (0.014) loss 1.5409 (1.5162) teacher_loss 0.1289 (0.1328) loss_zs_kd 0.0243 (0.0381) loss_oracle 0.5851 (0.6071) kd_loss 1.1073 (1.0607) acc 93.7500 (94.2188) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0267 (0.0340) teacher/usage_max 0.4372 (0.4567) teacher/usage_min 0.2797 (0.2175) teacher/usage_std 0.0735 (0.1033) nleep/row_max_mean 1531.4047 (1538.9732) nleep/row_max_std 60.0592 (50.7224) nleep/row_min_mean 1496.2496 (1505.2764) lr 7.5131e-04 eta 0:07:23
epoch [31/50] batch [40/173] time 0.142 (0.132) data 0.000 (0.007) loss 1.5305 (1.5210) teacher_loss 0.1023 (0.1330) loss_zs_kd 0.0304 (0.0373) loss_oracle 0.6000 (0.6158) kd_loss 1.1129 (1.0615) acc 96.8750 (94.4531) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1626 (0.1625) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0464 (0.0315) teacher/usage_max 0.3725 (0.4609) teacher/usage_min 0.3041 (0.2152) teacher/usage_std 0.0288 (0.1058) nleep/row_max_mean 1536.8169 (1538.5814) nleep/row_max_std 57.9288 (50.9963) nleep/row_min_mean 1503.9226 (1505.0303) lr 7.5131e-04 eta 0:07:30
epoch [31/50] batch [60/173] time 0.172 (0.138) data 0.000 (0.005) loss 1.3814 (1.5123) teacher_loss 0.0362 (0.1290) loss_zs_kd 0.0253 (0.0370) loss_oracle 0.5688 (0.6182) kd_loss 1.0482 (1.0557) acc 100.0000 (94.6354) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4246 (0.4247) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0740 (0.0303) teacher/usage_max 0.5159 (0.4651) teacher/usage_min 0.2232 (0.2117) teacher/usage_std 0.1300 (0.1087) nleep/row_max_mean 1519.4690 (1539.1363) nleep/row_max_std 54.8729 (51.1008) nleep/row_min_mean 1489.0430 (1505.7373) lr 7.5131e-04 eta 0:07:50
epoch [31/50] batch [80/173] time 0.150 (0.141) data 0.000 (0.004) loss 1.6975 (1.5272) teacher_loss 0.2466 (0.1406) loss_zs_kd 0.0224 (0.0393) loss_oracle 0.6662 (0.6212) kd_loss 1.1067 (1.0563) acc 90.6250 (94.1016) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0030 (0.0296) teacher/usage_max 0.4693 (0.4645) teacher/usage_min 0.2494 (0.2144) teacher/usage_std 0.0970 (0.1071) nleep/row_max_mean 1533.2806 (1540.1986) nleep/row_max_std 62.4654 (52.0749) nleep/row_min_mean 1499.4463 (1506.7481) lr 7.5131e-04 eta 0:07:58
epoch [31/50] batch [100/173] time 0.149 (0.145) data 0.000 (0.003) loss 1.6445 (1.5348) teacher_loss 0.1936 (0.1451) loss_zs_kd 0.0402 (0.0391) loss_oracle 0.6674 (0.6265) kd_loss 1.0970 (1.0570) acc 90.6250 (93.8750) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0314 (0.0288) teacher/usage_max 0.4172 (0.4627) teacher/usage_min 0.2738 (0.2154) teacher/usage_std 0.0610 (0.1060) nleep/row_max_mean 1544.3799 (1540.6410) nleep/row_max_std 55.3999 (52.8871) nleep/row_min_mean 1507.3861 (1506.9832) lr 7.5131e-04 eta 0:08:06
epoch [31/50] batch [120/173] time 0.164 (0.147) data 0.000 (0.002) loss 1.4538 (1.5346) teacher_loss 0.1289 (0.1477) loss_zs_kd 0.0462 (0.0394) loss_oracle 0.6233 (0.6240) kd_loss 0.9901 (1.0551) acc 96.8750 (93.8021) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4244 (0.4246) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0207 (0.0284) teacher/usage_max 0.5312 (0.4646) teacher/usage_min 0.1450 (0.2120) teacher/usage_std 0.1578 (0.1080) nleep/row_max_mean 1541.4277 (1540.9177) nleep/row_max_std 52.1799 (52.8585) nleep/row_min_mean 1507.3109 (1507.2207) lr 7.5131e-04 eta 0:08:11
epoch [31/50] batch [140/173] time 0.152 (0.150) data 0.000 (0.002) loss 1.4128 (1.5240) teacher_loss 0.0792 (0.1431) loss_zs_kd 0.0450 (0.0387) loss_oracle 0.6447 (0.6237) kd_loss 0.9888 (1.0497) acc 93.7500 (94.1295) gate/entropy 1.0245 (1.0242) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0035 (0.0282) teacher/usage_max 0.5307 (0.4653) teacher/usage_min 0.1256 (0.2071) teacher/usage_std 0.1656 (0.1106) nleep/row_max_mean 1529.0217 (1541.2862) nleep/row_max_std 65.2255 (53.1305) nleep/row_min_mean 1495.3903 (1507.5334) lr 7.5131e-04 eta 0:08:16
epoch [31/50] batch [160/173] time 0.159 (0.150) data 0.000 (0.002) loss 1.3974 (1.5223) teacher_loss 0.0770 (0.1426) loss_zs_kd 0.0491 (0.0390) loss_oracle 0.5859 (0.6220) kd_loss 1.0029 (1.0492) acc 100.0000 (94.1406) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4243 (0.4245) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0370 (0.0279) teacher/usage_max 0.5151 (0.4653) teacher/usage_min 0.1816 (0.2060) teacher/usage_std 0.1378 (0.1109) nleep/row_max_mean 1550.3636 (1540.8550) nleep/row_max_std 43.5591 (53.2799) nleep/row_min_mean 1511.1682 (1507.1038) lr 7.5131e-04 eta 0:08:15
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,312
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [32/50] batch [20/173] time 0.158 (0.129) data 0.000 (0.016) loss 1.4653 (1.4682) teacher_loss 0.1227 (0.1286) loss_zs_kd 0.0381 (0.0358) loss_oracle 0.6653 (0.6177) kd_loss 0.9910 (1.0129) acc 93.7500 (95.1562) gate/entropy 1.0240 (1.0241) gate/usage_max 0.4242 (0.4242) gate/usage_min 0.1622 (0.1624) gate/usage_std 0.1211 (0.1209) teacher/entropy 0.0674 (0.0372) teacher/usage_max 0.4926 (0.4795) teacher/usage_min 0.1949 (0.1879) teacher/usage_std 0.1224 (0.1235) nleep/row_max_mean 1546.3826 (1538.7824) nleep/row_max_std 51.4025 (53.3675) nleep/row_min_mean 1512.8127 (1505.3270) lr 6.9098e-04 eta 0:07:00
epoch [32/50] batch [40/173] time 0.174 (0.123) data 0.000 (0.008) loss 1.7051 (1.4744) teacher_loss 0.2879 (0.1328) loss_zs_kd 0.0705 (0.0393) loss_oracle 0.6183 (0.6243) kd_loss 1.0728 (1.0098) acc 90.6250 (94.7656) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4241 (0.4242) gate/usage_min 0.1624 (0.1624) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0058 (0.0277) teacher/usage_max 0.5010 (0.4861) teacher/usage_min 0.2177 (0.1728) teacher/usage_std 0.1214 (0.1326) nleep/row_max_mean 1531.1990 (1540.6376) nleep/row_max_std 54.1297 (53.9851) nleep/row_min_mean 1500.9570 (1506.1678) lr 6.9098e-04 eta 0:06:39
epoch [32/50] batch [60/173] time 0.095 (0.115) data 0.000 (0.005) loss 1.5876 (1.4928) teacher_loss 0.1438 (0.1459) loss_zs_kd 0.0314 (0.0424) loss_oracle 0.6592 (0.6274) kd_loss 1.0984 (1.0119) acc 93.7500 (94.3229) gate/entropy 1.0240 (1.0241) gate/usage_max 0.4240 (0.4242) gate/usage_min 0.1622 (0.1624) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0378 (0.0278) teacher/usage_max 0.4373 (0.4871) teacher/usage_min 0.2781 (0.1741) teacher/usage_std 0.0735 (0.1329) nleep/row_max_mean 1535.7990 (1542.1689) nleep/row_max_std 57.6005 (53.3633) nleep/row_min_mean 1502.0938 (1507.5139) lr 6.9098e-04 eta 0:06:10
epoch [32/50] batch [80/173] time 0.164 (0.114) data 0.000 (0.004) loss 1.3337 (1.4931) teacher_loss 0.0591 (0.1490) loss_zs_kd 0.0368 (0.0411) loss_oracle 0.6065 (0.6236) kd_loss 0.9529 (1.0118) acc 100.0000 (94.1797) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4240 (0.4241) gate/usage_min 0.1624 (0.1624) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0095 (0.0257) teacher/usage_max 0.4687 (0.4880) teacher/usage_min 0.0965 (0.1724) teacher/usage_std 0.1680 (0.1339) nleep/row_max_mean 1543.0334 (1542.7124) nleep/row_max_std 57.3386 (53.8905) nleep/row_min_mean 1504.7456 (1507.9306) lr 6.9098e-04 eta 0:06:07
epoch [32/50] batch [100/173] time 0.190 (0.117) data 0.000 (0.003) loss 1.3637 (1.4888) teacher_loss 0.1087 (0.1473) loss_zs_kd 0.0231 (0.0404) loss_oracle 0.5455 (0.6209) kd_loss 0.9707 (1.0109) acc 96.8750 (94.2500) gate/entropy 1.0242 (1.0241) gate/usage_max 0.4239 (0.4241) gate/usage_min 0.1625 (0.1623) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0142 (0.0266) teacher/usage_max 0.4688 (0.4937) teacher/usage_min 0.1206 (0.1717) teacher/usage_std 0.1523 (0.1369) nleep/row_max_mean 1547.3843 (1543.3619) nleep/row_max_std 59.2490 (54.4566) nleep/row_min_mean 1508.4036 (1508.4305) lr 6.9098e-04 eta 0:06:12
epoch [32/50] batch [120/173] time 0.180 (0.117) data 0.000 (0.003) loss 1.4739 (1.4866) teacher_loss 0.0818 (0.1470) loss_zs_kd 0.0398 (0.0401) loss_oracle 0.5360 (0.6201) kd_loss 1.1042 (1.0095) acc 96.8750 (94.3490) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4238 (0.4240) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0044 (0.0275) teacher/usage_max 0.4384 (0.4964) teacher/usage_min 0.2499 (0.1715) teacher/usage_std 0.0784 (0.1384) nleep/row_max_mean 1551.7607 (1543.7832) nleep/row_max_std 44.1282 (54.3932) nleep/row_min_mean 1517.7710 (1508.7823) lr 6.9098e-04 eta 0:06:11
epoch [32/50] batch [140/173] time 0.140 (0.116) data 0.000 (0.002) loss 1.4266 (1.4856) teacher_loss 0.1106 (0.1474) loss_zs_kd 0.0379 (0.0397) loss_oracle 0.5901 (0.6214) kd_loss 1.0020 (1.0076) acc 93.7500 (94.2634) gate/entropy 1.0242 (1.0241) gate/usage_max 0.4238 (0.4240) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0189 (0.0271) teacher/usage_max 0.5077 (0.4996) teacher/usage_min 0.1563 (0.1694) teacher/usage_std 0.1435 (0.1404) nleep/row_max_mean 1523.5245 (1543.9596) nleep/row_max_std 63.3500 (54.6778) nleep/row_min_mean 1489.9177 (1508.8716) lr 6.9098e-04 eta 0:06:04
epoch [32/50] batch [160/173] time 0.130 (0.120) data 0.000 (0.002) loss 1.6381 (1.4864) teacher_loss 0.2559 (0.1505) loss_zs_kd 0.0709 (0.0399) loss_oracle 0.5914 (0.6186) kd_loss 1.0511 (1.0067) acc 87.5000 (94.1602) gate/entropy 1.0240 (1.0241) gate/usage_max 0.4237 (0.4240) gate/usage_min 0.1622 (0.1623) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0574 (0.0279) teacher/usage_max 0.4112 (0.4979) teacher/usage_min 0.2501 (0.1697) teacher/usage_std 0.0659 (0.1396) nleep/row_max_mean 1533.4507 (1543.8023) nleep/row_max_std 54.0660 (54.9300) nleep/row_min_mean 1501.7737 (1508.6679) lr 6.9098e-04 eta 0:06:15
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,309
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [33/50] batch [20/173] time 0.149 (0.171) data 0.000 (0.014) loss 1.5347 (1.5131) teacher_loss 0.1102 (0.1539) loss_zs_kd 0.0399 (0.0424) loss_oracle 0.5685 (0.6209) kd_loss 1.1203 (1.0275) acc 96.8750 (93.5938) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4236 (0.4236) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0223 (0.0308) teacher/usage_max 0.4029 (0.5093) teacher/usage_min 0.2846 (0.1820) teacher/usage_std 0.0505 (0.1386) nleep/row_max_mean 1539.0293 (1543.2471) nleep/row_max_std 62.6562 (58.8701) nleep/row_min_mean 1504.6135 (1509.9098) lr 6.3188e-04 eta 0:08:48
epoch [33/50] batch [40/173] time 0.153 (0.156) data 0.000 (0.007) loss 1.3530 (1.4810) teacher_loss 0.1537 (0.1482) loss_zs_kd 0.0290 (0.0408) loss_oracle 0.6297 (0.6196) kd_loss 0.8699 (1.0026) acc 90.6250 (93.5938) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4235 (0.4236) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0316 (0.0296) teacher/usage_max 0.5152 (0.5082) teacher/usage_min 0.0318 (0.1620) teacher/usage_std 0.2147 (0.1462) nleep/row_max_mean 1548.5903 (1544.9167) nleep/row_max_std 61.8447 (59.0356) nleep/row_min_mean 1511.7410 (1510.4685) lr 6.3188e-04 eta 0:07:59
epoch [33/50] batch [60/173] time 0.136 (0.151) data 0.000 (0.005) loss 1.4159 (1.4748) teacher_loss 0.0632 (0.1427) loss_zs_kd 0.0265 (0.0398) loss_oracle 0.6022 (0.6234) kd_loss 1.0384 (1.0006) acc 100.0000 (94.1146) gate/entropy 1.0242 (1.0239) gate/usage_max 0.4235 (0.4236) gate/usage_min 0.1625 (0.1622) gate/usage_std 0.1209 (0.1211) teacher/entropy 0.0251 (0.0321) teacher/usage_max 0.4865 (0.5028) teacher/usage_min 0.2010 (0.1643) teacher/usage_std 0.1175 (0.1442) nleep/row_max_mean 1527.3387 (1543.9013) nleep/row_max_std 58.4633 (58.0692) nleep/row_min_mean 1493.6833 (1509.3935) lr 6.3188e-04 eta 0:07:39
epoch [33/50] batch [80/173] time 0.162 (0.150) data 0.000 (0.004) loss 1.3303 (1.4762) teacher_loss 0.0570 (0.1478) loss_zs_kd 0.0341 (0.0394) loss_oracle 0.5984 (0.6219) kd_loss 0.9570 (0.9977) acc 100.0000 (93.9844) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4234 (0.4235) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0056 (0.0333) teacher/usage_max 0.5615 (0.5030) teacher/usage_min 0.0946 (0.1614) teacher/usage_std 0.1908 (0.1452) nleep/row_max_mean 1548.7675 (1544.0703) nleep/row_max_std 59.4724 (57.7672) nleep/row_min_mean 1512.5374 (1509.5537) lr 6.3188e-04 eta 0:07:33
epoch [33/50] batch [100/173] time 0.095 (0.142) data 0.000 (0.003) loss 1.4024 (1.4750) teacher_loss 0.0974 (0.1479) loss_zs_kd 0.0531 (0.0389) loss_oracle 0.6483 (0.6229) kd_loss 0.9543 (0.9962) acc 96.8750 (94.0000) gate/entropy 1.0236 (1.0239) gate/usage_max 0.4233 (0.4235) gate/usage_min 0.1618 (0.1621) gate/usage_std 0.1213 (0.1211) teacher/entropy 0.0583 (0.0335) teacher/usage_max 0.5068 (0.5015) teacher/usage_min 0.1518 (0.1607) teacher/usage_std 0.1451 (0.1449) nleep/row_max_mean 1558.7137 (1544.4540) nleep/row_max_std 60.7232 (57.7224) nleep/row_min_mean 1517.7780 (1509.8989) lr 6.3188e-04 eta 0:07:08
epoch [33/50] batch [120/173] time 0.171 (0.138) data 0.000 (0.002) loss 1.5582 (1.4839) teacher_loss 0.2761 (0.1538) loss_zs_kd 0.0337 (0.0395) loss_oracle 0.6129 (0.6254) kd_loss 0.9588 (0.9977) acc 87.5000 (93.9323) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4233 (0.4235) gate/usage_min 0.1621 (0.1621) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0005 (0.0325) teacher/usage_max 0.4688 (0.4961) teacher/usage_min 0.0937 (0.1621) teacher/usage_std 0.1699 (0.1424) nleep/row_max_mean 1541.5223 (1544.4511) nleep/row_max_std 73.9822 (58.3099) nleep/row_min_mean 1503.9094 (1509.5543) lr 6.3188e-04 eta 0:06:52
epoch [33/50] batch [140/173] time 0.083 (0.133) data 0.000 (0.002) loss 1.4518 (1.4840) teacher_loss 0.0468 (0.1524) loss_zs_kd 0.0256 (0.0393) loss_oracle 0.6451 (0.6286) kd_loss 1.0697 (0.9977) acc 100.0000 (94.0402) gate/entropy 1.0237 (1.0239) gate/usage_max 0.4233 (0.4235) gate/usage_min 0.1620 (0.1621) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0107 (0.0328) teacher/usage_max 0.4063 (0.4976) teacher/usage_min 0.2217 (0.1629) teacher/usage_std 0.0802 (0.1427) nleep/row_max_mean 1543.8605 (1543.8219) nleep/row_max_std 55.6071 (58.4152) nleep/row_min_mean 1507.6885 (1509.0317) lr 6.3188e-04 eta 0:06:35
epoch [33/50] batch [160/173] time 0.162 (0.131) data 0.000 (0.002) loss 1.5387 (1.4837) teacher_loss 0.1751 (0.1512) loss_zs_kd 0.0268 (0.0385) loss_oracle 0.6761 (0.6264) kd_loss 1.0121 (1.0000) acc 90.6250 (94.1602) gate/entropy 1.0241 (1.0239) gate/usage_max 0.4233 (0.4234) gate/usage_min 0.1624 (0.1621) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0318 (0.0324) teacher/usage_max 0.4182 (0.4939) teacher/usage_min 0.1818 (0.1656) teacher/usage_std 0.1074 (0.1401) nleep/row_max_mean 1532.6339 (1542.9456) nleep/row_max_std 62.0071 (58.4123) nleep/row_min_mean 1498.4160 (1508.4371) lr 6.3188e-04 eta 0:06:25
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,307
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,010
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [34/50] batch [20/173] time 0.083 (0.136) data 0.000 (0.016) loss 1.4811 (1.4922) teacher_loss 0.1747 (0.1482) loss_zs_kd 0.0507 (0.0390) loss_oracle 0.6270 (0.6305) kd_loss 0.9675 (1.0093) acc 93.7500 (94.3750) gate/entropy 1.0236 (1.0238) gate/usage_max 0.4231 (0.4232) gate/usage_min 0.1618 (0.1620) gate/usage_std 0.1213 (0.1212) teacher/entropy 0.0593 (0.0351) teacher/usage_max 0.4604 (0.4899) teacher/usage_min 0.1640 (0.1804) teacher/usage_std 0.1246 (0.1311) nleep/row_max_mean 1549.0182 (1541.3690) nleep/row_max_std 57.7760 (55.1132) nleep/row_min_mean 1515.2507 (1509.4889) lr 5.7422e-04 eta 0:06:37
epoch [34/50] batch [40/173] time 0.079 (0.124) data 0.000 (0.008) loss 1.4352 (1.4909) teacher_loss 0.1476 (0.1448) loss_zs_kd 0.0458 (0.0401) loss_oracle 0.6174 (0.6463) kd_loss 0.9559 (1.0029) acc 93.7500 (94.2969) gate/entropy 1.0236 (1.0238) gate/usage_max 0.4231 (0.4231) gate/usage_min 0.1618 (0.1620) gate/usage_std 0.1213 (0.1212) teacher/entropy 0.0040 (0.0316) teacher/usage_max 0.5002 (0.5007) teacher/usage_min 0.0935 (0.1661) teacher/usage_std 0.1739 (0.1418) nleep/row_max_mean 1556.1409 (1539.3490) nleep/row_max_std 63.3390 (58.7742) nleep/row_min_mean 1519.1644 (1506.9297) lr 5.7422e-04 eta 0:06:01
epoch [34/50] batch [60/173] time 0.152 (0.130) data 0.000 (0.006) loss 1.4862 (1.5024) teacher_loss 0.1320 (0.1486) loss_zs_kd 0.0207 (0.0409) loss_oracle 0.6305 (0.6480) kd_loss 1.0286 (1.0094) acc 93.7500 (93.9062) gate/entropy 1.0240 (1.0238) gate/usage_max 0.4231 (0.4231) gate/usage_min 0.1622 (0.1620) gate/usage_std 0.1211 (0.1212) teacher/entropy 0.0195 (0.0341) teacher/usage_max 0.4070 (0.4926) teacher/usage_min 0.1869 (0.1764) teacher/usage_std 0.1035 (0.1346) nleep/row_max_mean 1534.0553 (1537.7812) nleep/row_max_std 60.5842 (58.5025) nleep/row_min_mean 1505.1433 (1506.0357) lr 5.7422e-04 eta 0:06:14
epoch [34/50] batch [80/173] time 0.170 (0.135) data 0.000 (0.004) loss 1.4648 (1.5082) teacher_loss 0.0320 (0.1465) loss_zs_kd 0.0181 (0.0404) loss_oracle 0.6815 (0.6511) kd_loss 1.0830 (1.0159) acc 100.0000 (93.8672) gate/entropy 1.0237 (1.0238) gate/usage_max 0.4230 (0.4231) gate/usage_min 0.1619 (0.1620) gate/usage_std 0.1213 (0.1212) teacher/entropy 0.0444 (0.0356) teacher/usage_max 0.4376 (0.4850) teacher/usage_min 0.2716 (0.1849) teacher/usage_std 0.0741 (0.1281) nleep/row_max_mean 1553.6799 (1537.9182) nleep/row_max_std 59.1836 (57.7556) nleep/row_min_mean 1519.7197 (1506.3659) lr 5.7422e-04 eta 0:06:27
epoch [34/50] batch [100/173] time 0.145 (0.139) data 0.000 (0.003) loss 1.6109 (1.5129) teacher_loss 0.3432 (0.1461) loss_zs_kd 0.0514 (0.0397) loss_oracle 0.6560 (0.6572) kd_loss 0.9141 (1.0183) acc 84.3750 (93.9375) gate/entropy 1.0237 (1.0238) gate/usage_max 0.4230 (0.4231) gate/usage_min 0.1619 (0.1620) gate/usage_std 0.1213 (0.1212) teacher/entropy 0.0197 (0.0365) teacher/usage_max 0.5268 (0.4803) teacher/usage_min 0.0655 (0.1854) teacher/usage_std 0.1955 (0.1256) nleep/row_max_mean 1544.4780 (1538.8433) nleep/row_max_std 68.9046 (58.0270) nleep/row_min_mean 1509.0659 (1506.9450) lr 5.7422e-04 eta 0:06:33
epoch [34/50] batch [120/173] time 0.150 (0.139) data 0.000 (0.003) loss 1.7048 (1.5212) teacher_loss 0.1879 (0.1482) loss_zs_kd 0.0493 (0.0401) loss_oracle 0.7417 (0.6554) kd_loss 1.1214 (1.0252) acc 93.7500 (94.0885) gate/entropy 1.0238 (1.0238) gate/usage_max 0.4230 (0.4231) gate/usage_min 0.1620 (0.1620) gate/usage_std 0.1212 (0.1212) teacher/entropy 0.0258 (0.0369) teacher/usage_max 0.4293 (0.4767) teacher/usage_min 0.2812 (0.1931) teacher/usage_std 0.0680 (0.1207) nleep/row_max_mean 1540.7489 (1539.1815) nleep/row_max_std 63.7276 (57.9900) nleep/row_min_mean 1504.7388 (1507.3222) lr 5.7422e-04 eta 0:06:32
epoch [34/50] batch [140/173] time 0.161 (0.140) data 0.001 (0.003) loss 1.3988 (1.5268) teacher_loss 0.0059 (0.1496) loss_zs_kd 0.0059 (0.0395) loss_oracle 0.7313 (0.6552) kd_loss 1.0243 (1.0299) acc 100.0000 (94.1071) gate/entropy 1.0241 (1.0238) gate/usage_max 0.4230 (0.4230) gate/usage_min 0.1623 (0.1620) gate/usage_std 0.1210 (0.1212) teacher/entropy 0.0384 (0.0369) teacher/usage_max 0.5675 (0.4736) teacher/usage_min 0.1978 (0.1978) teacher/usage_std 0.1663 (0.1175) nleep/row_max_mean 1527.5566 (1539.8472) nleep/row_max_std 65.4872 (57.7794) nleep/row_min_mean 1497.6274 (1507.8075) lr 5.7422e-04 eta 0:06:32
epoch [34/50] batch [160/173] time 0.125 (0.141) data 0.000 (0.002) loss 1.7467 (1.5323) teacher_loss 0.2867 (0.1505) loss_zs_kd 0.0563 (0.0397) loss_oracle 0.7103 (0.6561) kd_loss 1.0767 (1.0339) acc 87.5000 (94.1406) gate/entropy 1.0240 (1.0238) gate/usage_max 0.4229 (0.4230) gate/usage_min 0.1623 (0.1620) gate/usage_std 0.1210 (0.1212) teacher/entropy 0.0473 (0.0381) teacher/usage_max 0.4210 (0.4698) teacher/usage_min 0.2659 (0.2012) teacher/usage_std 0.0649 (0.1146) nleep/row_max_mean 1527.8779 (1539.8965) nleep/row_max_std 67.0582 (57.6007) nleep/row_min_mean 1496.8862 (1507.8108) lr 5.7422e-04 eta 0:06:31
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,310
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [35/50] batch [20/173] time 0.147 (0.133) data 0.000 (0.017) loss 1.4701 (1.6528) teacher_loss 0.0905 (0.1826) loss_zs_kd 0.0269 (0.0365) loss_oracle 0.5973 (0.6334) kd_loss 1.0675 (1.1352) acc 93.7500 (91.7188) gate/entropy 1.0239 (1.0238) gate/usage_max 0.4229 (0.4229) gate/usage_min 0.1622 (0.1620) gate/usage_std 0.1211 (0.1212) teacher/entropy 0.0683 (0.0479) teacher/usage_max 0.4478 (0.3993) teacher/usage_min 0.2753 (0.2575) teacher/usage_std 0.0810 (0.0609) nleep/row_max_mean 1528.9620 (1546.9759) nleep/row_max_std 70.5767 (55.4265) nleep/row_min_mean 1499.9438 (1513.6892) lr 5.1825e-04 eta 0:06:05
epoch [35/50] batch [40/173] time 0.083 (0.124) data 0.000 (0.009) loss 1.7546 (1.6365) teacher_loss 0.2733 (0.1639) loss_zs_kd 0.0463 (0.0383) loss_oracle 0.7241 (0.6478) kd_loss 1.0960 (1.1295) acc 87.5000 (92.8906) gate/entropy 1.0237 (1.0238) gate/usage_max 0.4229 (0.4229) gate/usage_min 0.1619 (0.1620) gate/usage_std 0.1212 (0.1212) teacher/entropy 0.0911 (0.0428) teacher/usage_max 0.3524 (0.4162) teacher/usage_min 0.3141 (0.2491) teacher/usage_std 0.0156 (0.0712) nleep/row_max_mean 1558.4124 (1543.4161) nleep/row_max_std 54.2900 (55.4514) nleep/row_min_mean 1522.3158 (1509.9344) lr 5.1825e-04 eta 0:05:39
epoch [35/50] batch [60/173] time 0.090 (0.123) data 0.001 (0.006) loss 1.6383 (1.6287) teacher_loss 0.1254 (0.1550) loss_zs_kd 0.0426 (0.0388) loss_oracle 0.7137 (0.6525) kd_loss 1.1347 (1.1281) acc 93.7500 (93.3854) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4228 (0.4229) gate/usage_min 0.1620 (0.1621) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0011 (0.0377) teacher/usage_max 0.4374 (0.4220) teacher/usage_min 0.2813 (0.2469) teacher/usage_std 0.0736 (0.0749) nleep/row_max_mean 1548.1145 (1540.5943) nleep/row_max_std 54.6267 (56.3066) nleep/row_min_mean 1508.5654 (1507.3665) lr 5.1825e-04 eta 0:05:32
epoch [35/50] batch [80/173] time 0.090 (0.121) data 0.000 (0.005) loss 1.3988 (1.6296) teacher_loss 0.0277 (0.1466) loss_zs_kd 0.0303 (0.0392) loss_oracle 0.5961 (0.6624) kd_loss 1.0579 (1.1322) acc 100.0000 (93.9062) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4228 (0.4229) gate/usage_min 0.1622 (0.1621) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0280 (0.0377) teacher/usage_max 0.3984 (0.4213) teacher/usage_min 0.2266 (0.2472) teacher/usage_std 0.0761 (0.0749) nleep/row_max_mean 1535.7114 (1540.2513) nleep/row_max_std 56.0164 (55.2555) nleep/row_min_mean 1499.1433 (1506.9571) lr 5.1825e-04 eta 0:05:26
epoch [35/50] batch [100/173] time 0.084 (0.117) data 0.000 (0.004) loss 1.7983 (1.6423) teacher_loss 0.1537 (0.1440) loss_zs_kd 0.0410 (0.0412) loss_oracle 0.7554 (0.6741) kd_loss 1.2464 (1.1407) acc 93.7500 (94.1250) gate/entropy 1.0239 (1.0239) gate/usage_max 0.4228 (0.4229) gate/usage_min 0.1621 (0.1621) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0306 (0.0378) teacher/usage_max 0.4251 (0.4180) teacher/usage_min 0.2188 (0.2481) teacher/usage_std 0.0858 (0.0731) nleep/row_max_mean 1541.8932 (1540.7472) nleep/row_max_std 54.6735 (54.4262) nleep/row_min_mean 1507.3546 (1507.3438) lr 5.1825e-04 eta 0:05:13
epoch [35/50] batch [120/173] time 0.071 (0.116) data 0.000 (0.003) loss 1.4821 (1.6493) teacher_loss 0.0907 (0.1424) loss_zs_kd 0.0402 (0.0420) loss_oracle 0.6714 (0.6784) kd_loss 1.0356 (1.1467) acc 93.7500 (94.2708) gate/entropy 1.0243 (1.0239) gate/usage_max 0.4228 (0.4229) gate/usage_min 0.1626 (0.1621) gate/usage_std 0.1208 (0.1211) teacher/entropy 0.0194 (0.0372) teacher/usage_max 0.4053 (0.4182) teacher/usage_min 0.1933 (0.2493) teacher/usage_std 0.0990 (0.0728) nleep/row_max_mean 1527.9420 (1541.2120) nleep/row_max_std 63.8325 (53.6186) nleep/row_min_mean 1490.5942 (1507.4954) lr 5.1825e-04 eta 0:05:06
epoch [35/50] batch [140/173] time 0.087 (0.115) data 0.000 (0.003) loss 1.6865 (1.6520) teacher_loss 0.0944 (0.1398) loss_zs_kd 0.0413 (0.0440) loss_oracle 0.6626 (0.6775) kd_loss 1.2402 (1.1515) acc 96.8750 (94.4420) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4228 (0.4228) gate/usage_min 0.1623 (0.1621) gate/usage_std 0.1210 (0.1211) teacher/entropy 0.0269 (0.0365) teacher/usage_max 0.4158 (0.4165) teacher/usage_min 0.2409 (0.2513) teacher/usage_std 0.0717 (0.0711) nleep/row_max_mean 1536.3979 (1542.2919) nleep/row_max_std 49.3800 (53.1605) nleep/row_min_mean 1506.4072 (1508.3506) lr 5.1825e-04 eta 0:05:03
epoch [35/50] batch [160/173] time 0.091 (0.115) data 0.000 (0.002) loss 1.5185 (1.6462) teacher_loss 0.0859 (0.1400) loss_zs_kd 0.0336 (0.0435) loss_oracle 0.6470 (0.6713) kd_loss 1.0924 (1.1488) acc 96.8750 (94.5117) gate/entropy 1.0243 (1.0239) gate/usage_max 0.4228 (0.4228) gate/usage_min 0.1625 (0.1621) gate/usage_std 0.1208 (0.1211) teacher/entropy 0.0278 (0.0359) teacher/usage_max 0.4052 (0.4181) teacher/usage_min 0.2615 (0.2494) teacher/usage_std 0.0587 (0.0726) nleep/row_max_mean 1531.8877 (1542.6706) nleep/row_max_std 52.6231 (53.3449) nleep/row_min_mean 1500.9417 (1508.6697) lr 5.1825e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,305
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [36/50] batch [20/173] time 0.134 (0.153) data 0.000 (0.015) loss 1.4834 (1.5666) teacher_loss 0.1533 (0.1118) loss_zs_kd 0.0332 (0.0425) loss_oracle 0.5426 (0.6007) kd_loss 1.0422 (1.1332) acc 96.8750 (95.7812) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4227 (0.4227) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0392 (0.0235) teacher/usage_max 0.4258 (0.4297) teacher/usage_min 0.2208 (0.2368) teacher/usage_std 0.0849 (0.0823) nleep/row_max_mean 1557.0754 (1544.6618) nleep/row_max_std 53.5618 (50.8338) nleep/row_min_mean 1525.8604 (1510.9938) lr 4.6417e-04 eta 0:06:34
epoch [36/50] batch [40/173] time 0.152 (0.148) data 0.000 (0.007) loss 1.6066 (1.5716) teacher_loss 0.0479 (0.1001) loss_zs_kd 0.0618 (0.0415) loss_oracle 0.7214 (0.6170) kd_loss 1.1671 (1.1423) acc 100.0000 (96.0938) gate/entropy 1.0241 (1.0240) gate/usage_max 0.4226 (0.4227) gate/usage_min 0.1623 (0.1622) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0342 (0.0192) teacher/usage_max 0.5379 (0.4427) teacher/usage_min 0.1178 (0.2297) teacher/usage_std 0.1717 (0.0905) nleep/row_max_mean 1539.7814 (1544.7204) nleep/row_max_std 48.0381 (50.1065) nleep/row_min_mean 1506.8201 (1510.8000) lr 4.6417e-04 eta 0:06:18
epoch [36/50] batch [60/173] time 0.128 (0.146) data 0.001 (0.005) loss 1.4261 (1.5756) teacher_loss 0.0390 (0.1065) loss_zs_kd 0.0404 (0.0434) loss_oracle 0.6920 (0.6193) kd_loss 1.0208 (1.1377) acc 100.0000 (95.8854) gate/entropy 1.0237 (1.0240) gate/usage_max 0.4226 (0.4227) gate/usage_min 0.1619 (0.1622) gate/usage_std 0.1212 (0.1210) teacher/entropy 0.0519 (0.0217) teacher/usage_max 0.4200 (0.4470) teacher/usage_min 0.2138 (0.2261) teacher/usage_std 0.0873 (0.0942) nleep/row_max_mean 1567.2061 (1544.7241) nleep/row_max_std 44.1207 (49.9790) nleep/row_min_mean 1530.0754 (1510.6510) lr 4.6417e-04 eta 0:06:10
epoch [36/50] batch [80/173] time 0.129 (0.146) data 0.000 (0.004) loss 1.5832 (1.5974) teacher_loss 0.1113 (0.1108) loss_zs_kd 0.0701 (0.0447) loss_oracle 0.6752 (0.6327) kd_loss 1.0992 (1.1479) acc 96.8750 (95.6250) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4226 (0.4227) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0474 (0.0218) teacher/usage_max 0.4953 (0.4406) teacher/usage_min 0.2171 (0.2313) teacher/usage_std 0.1181 (0.0892) nleep/row_max_mean 1538.5387 (1544.0169) nleep/row_max_std 55.0481 (49.6705) nleep/row_min_mean 1507.7534 (1510.1836) lr 4.6417e-04 eta 0:06:06
epoch [36/50] batch [100/173] time 0.162 (0.146) data 0.000 (0.003) loss 1.6527 (1.5971) teacher_loss 0.1971 (0.1148) loss_zs_kd 0.0422 (0.0465) loss_oracle 0.5548 (0.6367) kd_loss 1.1571 (1.1408) acc 93.7500 (95.5938) gate/entropy 1.0240 (1.0240) gate/usage_max 0.4226 (0.4226) gate/usage_min 0.1622 (0.1622) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0214 (0.0213) teacher/usage_max 0.4063 (0.4367) teacher/usage_min 0.2710 (0.2334) teacher/usage_std 0.0557 (0.0868) nleep/row_max_mean 1547.3755 (1543.4513) nleep/row_max_std 55.1008 (50.5578) nleep/row_min_mean 1515.0205 (1509.6720) lr 4.6417e-04 eta 0:06:04
epoch [36/50] batch [120/173] time 0.130 (0.146) data 0.000 (0.003) loss 1.5664 (1.5987) teacher_loss 0.1858 (0.1137) loss_zs_kd 0.0795 (0.0461) loss_oracle 0.5835 (0.6408) kd_loss 1.0492 (1.1415) acc 90.6250 (95.6510) gate/entropy 1.0236 (1.0240) gate/usage_max 0.4225 (0.4226) gate/usage_min 0.1618 (0.1622) gate/usage_std 0.1213 (0.1210) teacher/entropy 0.0003 (0.0216) teacher/usage_max 0.4688 (0.4362) teacher/usage_min 0.1875 (0.2341) teacher/usage_std 0.1151 (0.0862) nleep/row_max_mean 1572.7960 (1543.3239) nleep/row_max_std 51.9942 (51.1435) nleep/row_min_mean 1529.6035 (1509.6583) lr 4.6417e-04 eta 0:06:02
epoch [36/50] batch [140/173] time 0.143 (0.139) data 0.000 (0.002) loss 1.4669 (1.6008) teacher_loss 0.0557 (0.1144) loss_zs_kd 0.0368 (0.0456) loss_oracle 0.7054 (0.6458) kd_loss 1.0401 (1.1407) acc 100.0000 (95.6473) gate/entropy 1.0242 (1.0240) gate/usage_max 0.4225 (0.4226) gate/usage_min 0.1624 (0.1622) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0215 (0.0221) teacher/usage_max 0.5311 (0.4329) teacher/usage_min 0.1979 (0.2377) teacher/usage_std 0.1430 (0.0833) nleep/row_max_mean 1538.3988 (1543.0012) nleep/row_max_std 61.1030 (51.6103) nleep/row_min_mean 1508.5797 (1509.2915) lr 4.6417e-04 eta 0:05:40
epoch [36/50] batch [160/173] time 0.071 (0.136) data 0.000 (0.002) loss 1.6266 (1.6029) teacher_loss 0.0321 (0.1137) loss_zs_kd 0.0499 (0.0456) loss_oracle 0.7653 (0.6509) kd_loss 1.1870 (1.1409) acc 100.0000 (95.6445) gate/entropy 1.0242 (1.0240) gate/usage_max 0.4225 (0.4226) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0196 (0.0223) teacher/usage_max 0.3975 (0.4315) teacher/usage_min 0.2500 (0.2393) teacher/usage_std 0.0617 (0.0820) nleep/row_max_mean 1543.1211 (1542.8828) nleep/row_max_std 53.0132 (51.6862) nleep/row_min_mean 1504.1653 (1509.1425) lr 4.6417e-04 eta 0:05:30
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,305
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [37/50] batch [20/173] time 0.199 (0.125) data 0.000 (0.015) loss 1.6546 (1.6152) teacher_loss 0.1151 (0.0972) loss_zs_kd 0.0522 (0.0475) loss_oracle 0.7171 (0.6713) kd_loss 1.1549 (1.1586) acc 93.7500 (97.1875) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4224 (0.4224) gate/usage_min 0.1623 (0.1623) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0494 (0.0258) teacher/usage_max 0.4101 (0.4425) teacher/usage_min 0.2395 (0.2307) teacher/usage_std 0.0707 (0.0916) nleep/row_max_mean 1543.0879 (1545.4243) nleep/row_max_std 47.9033 (53.8354) nleep/row_min_mean 1507.8870 (1511.7638) lr 4.1221e-04 eta 0:04:59
epoch [37/50] batch [40/173] time 0.089 (0.115) data 0.000 (0.007) loss 1.5716 (1.6305) teacher_loss 0.0364 (0.1129) loss_zs_kd 0.0127 (0.0443) loss_oracle 0.7122 (0.6841) kd_loss 1.1727 (1.1534) acc 100.0000 (96.4844) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4224 (0.4224) gate/usage_min 0.1623 (0.1623) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0394 (0.0263) teacher/usage_max 0.3770 (0.4216) teacher/usage_min 0.2639 (0.2428) teacher/usage_std 0.0496 (0.0772) nleep/row_max_mean 1546.6884 (1546.7596) nleep/row_max_std 54.4527 (53.6265) nleep/row_min_mean 1512.8585 (1513.0244) lr 4.1221e-04 eta 0:04:34
epoch [37/50] batch [60/173] time 0.075 (0.114) data 0.000 (0.005) loss 1.6704 (1.6339) teacher_loss 0.1806 (0.1171) loss_zs_kd 0.0482 (0.0437) loss_oracle 0.6949 (0.6900) kd_loss 1.1182 (1.1500) acc 93.7500 (95.9375) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4223 (0.4224) gate/usage_min 0.1624 (0.1623) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0583 (0.0259) teacher/usage_max 0.3389 (0.4234) teacher/usage_min 0.3227 (0.2436) teacher/usage_std 0.0075 (0.0773) nleep/row_max_mean 1539.9841 (1545.8998) nleep/row_max_std 57.4124 (53.9340) nleep/row_min_mean 1508.1112 (1512.2353) lr 4.1221e-04 eta 0:04:28
epoch [37/50] batch [80/173] time 0.143 (0.115) data 0.000 (0.004) loss 1.7195 (1.6413) teacher_loss 0.2188 (0.1169) loss_zs_kd 0.0801 (0.0446) loss_oracle 0.6103 (0.6929) kd_loss 1.1554 (1.1556) acc 93.7500 (95.8984) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4223 (0.4224) gate/usage_min 0.1623 (0.1623) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0113 (0.0262) teacher/usage_max 0.3739 (0.4273) teacher/usage_min 0.3124 (0.2439) teacher/usage_std 0.0287 (0.0792) nleep/row_max_mean 1546.4551 (1545.5916) nleep/row_max_std 47.8325 (53.8351) nleep/row_min_mean 1514.3030 (1512.0461) lr 4.1221e-04 eta 0:04:29
epoch [37/50] batch [100/173] time 0.155 (0.124) data 0.000 (0.003) loss 1.6780 (1.6470) teacher_loss 0.1530 (0.1133) loss_zs_kd 0.0608 (0.0456) loss_oracle 0.7736 (0.6982) kd_loss 1.1079 (1.1618) acc 93.7500 (95.8750) gate/entropy 1.0239 (1.0241) gate/usage_max 0.4223 (0.4224) gate/usage_min 0.1621 (0.1623) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0006 (0.0260) teacher/usage_max 0.4062 (0.4313) teacher/usage_min 0.2500 (0.2401) teacher/usage_std 0.0642 (0.0828) nleep/row_max_mean 1567.8298 (1546.3652) nleep/row_max_std 54.7882 (53.1964) nleep/row_min_mean 1527.5157 (1512.7037) lr 4.1221e-04 eta 0:04:48
epoch [37/50] batch [120/173] time 0.161 (0.129) data 0.000 (0.003) loss 1.7873 (1.6493) teacher_loss 0.1347 (0.1100) loss_zs_kd 0.0396 (0.0455) loss_oracle 0.8582 (0.7014) kd_loss 1.2037 (1.1659) acc 93.7500 (95.9896) gate/entropy 1.0245 (1.0241) gate/usage_max 0.4223 (0.4224) gate/usage_min 0.1627 (0.1623) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0445 (0.0255) teacher/usage_max 0.3976 (0.4291) teacher/usage_min 0.2627 (0.2411) teacher/usage_std 0.0553 (0.0810) nleep/row_max_mean 1542.8262 (1546.6215) nleep/row_max_std 60.8321 (53.6325) nleep/row_min_mean 1505.0635 (1512.9229) lr 4.1221e-04 eta 0:04:57
epoch [37/50] batch [140/173] time 0.161 (0.134) data 0.000 (0.002) loss 1.6966 (1.6550) teacher_loss 0.0659 (0.1115) loss_zs_kd 0.0156 (0.0449) loss_oracle 0.7896 (0.7077) kd_loss 1.2281 (1.1672) acc 96.8750 (96.0045) gate/entropy 1.0243 (1.0241) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1625 (0.1623) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0004 (0.0272) teacher/usage_max 0.4375 (0.4278) teacher/usage_min 0.1875 (0.2398) teacher/usage_std 0.1062 (0.0810) nleep/row_max_mean 1544.1630 (1546.6410) nleep/row_max_std 54.9847 (53.7960) nleep/row_min_mean 1511.2966 (1513.0974) lr 4.1221e-04 eta 0:05:04
epoch [37/50] batch [160/173] time 0.161 (0.137) data 0.000 (0.002) loss 1.5519 (1.6462) teacher_loss 0.1532 (0.1103) loss_zs_kd 0.0511 (0.0443) loss_oracle 0.6798 (0.7026) kd_loss 1.0332 (1.1624) acc 96.8750 (96.0547) gate/entropy 1.0242 (1.0241) gate/usage_max 0.4222 (0.4223) gate/usage_min 0.1625 (0.1624) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0584 (0.0279) teacher/usage_max 0.6302 (0.4347) teacher/usage_min 0.1404 (0.2371) teacher/usage_std 0.2131 (0.0850) nleep/row_max_mean 1549.2385 (1546.2100) nleep/row_max_std 50.5461 (53.8700) nleep/row_min_mean 1517.2568 (1512.7603) lr 4.1221e-04 eta 0:05:10
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,302
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [38/50] batch [20/173] time 0.082 (0.148) data 0.000 (0.017) loss 1.7236 (1.6475) teacher_loss 0.1598 (0.1090) loss_zs_kd 0.0786 (0.0515) loss_oracle 0.6882 (0.6769) kd_loss 1.1804 (1.1744) acc 90.6250 (96.0938) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1623 (0.1624) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0352 (0.0325) teacher/usage_max 0.3644 (0.4399) teacher/usage_min 0.2891 (0.2211) teacher/usage_std 0.0321 (0.0926) nleep/row_max_mean 1549.4791 (1545.9618) nleep/row_max_std 46.8629 (49.3171) nleep/row_min_mean 1511.9216 (1513.4316) lr 3.6258e-04 eta 0:05:30
epoch [38/50] batch [40/173] time 0.074 (0.126) data 0.000 (0.008) loss 2.0315 (1.6554) teacher_loss 0.4152 (0.1327) loss_zs_kd 0.0731 (0.0498) loss_oracle 0.7199 (0.6763) kd_loss 1.2197 (1.1596) acc 81.2500 (94.8438) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4221 (0.4221) gate/usage_min 0.1626 (0.1624) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0060 (0.0302) teacher/usage_max 0.3750 (0.4446) teacher/usage_min 0.3125 (0.2234) teacher/usage_std 0.0295 (0.0938) nleep/row_max_mean 1543.6791 (1546.9202) nleep/row_max_std 52.7273 (48.4443) nleep/row_min_mean 1507.5938 (1514.0560) lr 3.6258e-04 eta 0:04:38
epoch [38/50] batch [60/173] time 0.149 (0.120) data 0.000 (0.006) loss 1.7118 (1.6395) teacher_loss 0.2270 (0.1300) loss_zs_kd 0.0561 (0.0478) loss_oracle 0.6990 (0.6720) kd_loss 1.1072 (1.1497) acc 90.6250 (94.7917) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1624 (0.1624) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0326 (0.0319) teacher/usage_max 0.5327 (0.4507) teacher/usage_min 0.1853 (0.2176) teacher/usage_std 0.1464 (0.0991) nleep/row_max_mean 1542.5742 (1546.7394) nleep/row_max_std 41.3185 (48.5918) nleep/row_min_mean 1512.9062 (1514.0447) lr 3.6258e-04 eta 0:04:23
epoch [38/50] batch [80/173] time 0.166 (0.117) data 0.000 (0.004) loss 1.6057 (1.6309) teacher_loss 0.0783 (0.1339) loss_zs_kd 0.0572 (0.0467) loss_oracle 0.6378 (0.6615) kd_loss 1.1800 (1.1429) acc 100.0000 (94.6875) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4220 (0.4221) gate/usage_min 0.1626 (0.1624) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0199 (0.0322) teacher/usage_max 0.4748 (0.4569) teacher/usage_min 0.1811 (0.2166) teacher/usage_std 0.1201 (0.1020) nleep/row_max_mean 1539.3430 (1546.5283) nleep/row_max_std 43.0984 (48.0974) nleep/row_min_mean 1509.2596 (1513.9315) lr 3.6258e-04 eta 0:04:14
epoch [38/50] batch [100/173] time 0.154 (0.117) data 0.000 (0.004) loss 1.4308 (1.6227) teacher_loss 0.1366 (0.1365) loss_zs_kd 0.0539 (0.0475) loss_oracle 0.5032 (0.6553) kd_loss 1.0156 (1.1349) acc 93.7500 (94.5625) gate/entropy 1.0240 (1.0242) gate/usage_max 0.4219 (0.4221) gate/usage_min 0.1622 (0.1624) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0503 (0.0335) teacher/usage_max 0.4211 (0.4647) teacher/usage_min 0.2054 (0.2121) teacher/usage_std 0.0925 (0.1074) nleep/row_max_mean 1559.9774 (1546.6213) nleep/row_max_std 48.5412 (48.0563) nleep/row_min_mean 1525.1632 (1514.0297) lr 3.6258e-04 eta 0:04:10
epoch [38/50] batch [120/173] time 0.129 (0.113) data 0.000 (0.003) loss 1.3727 (1.6150) teacher_loss 0.0975 (0.1341) loss_zs_kd 0.0525 (0.0473) loss_oracle 0.5683 (0.6551) kd_loss 0.9648 (1.1297) acc 96.8750 (94.7396) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4219 (0.4220) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0272 (0.0329) teacher/usage_max 0.6286 (0.4739) teacher/usage_min 0.1254 (0.2085) teacher/usage_std 0.2145 (0.1133) nleep/row_max_mean 1546.0004 (1546.8483) nleep/row_max_std 48.9532 (48.4586) nleep/row_min_mean 1512.9565 (1513.9670) lr 3.6258e-04 eta 0:04:00
epoch [38/50] batch [140/173] time 0.088 (0.114) data 0.000 (0.003) loss 1.6010 (1.6165) teacher_loss 0.0915 (0.1366) loss_zs_kd 0.0274 (0.0472) loss_oracle 0.6844 (0.6574) kd_loss 1.1536 (1.1277) acc 93.7500 (94.7098) gate/entropy 1.0241 (1.0242) gate/usage_max 0.4218 (0.4220) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.0570 (0.0320) teacher/usage_max 0.5121 (0.4847) teacher/usage_min 0.1311 (0.2031) teacher/usage_std 0.1564 (0.1203) nleep/row_max_mean 1546.1663 (1546.2791) nleep/row_max_std 46.0618 (48.3070) nleep/row_min_mean 1514.6038 (1513.4314) lr 3.6258e-04 eta 0:03:59
epoch [38/50] batch [160/173] time 0.072 (0.114) data 0.000 (0.002) loss 1.6464 (1.6169) teacher_loss 0.2136 (0.1364) loss_zs_kd 0.0468 (0.0470) loss_oracle 0.7001 (0.6581) kd_loss 1.0593 (1.1279) acc 93.7500 (94.7656) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4218 (0.4220) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0622 (0.0309) teacher/usage_max 0.6577 (0.4900) teacher/usage_min 0.0822 (0.1994) teacher/usage_std 0.2406 (0.1241) nleep/row_max_mean 1537.7141 (1545.6814) nleep/row_max_std 58.1753 (48.6572) nleep/row_min_mean 1507.3068 (1512.8219) lr 3.6258e-04 eta 0:03:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [39/50] batch [20/173] time 0.136 (0.172) data 0.000 (0.016) loss 1.4659 (1.5797) teacher_loss 0.0709 (0.1493) loss_zs_kd 0.0601 (0.0509) loss_oracle 0.6356 (0.6394) kd_loss 1.0472 (1.0853) acc 96.8750 (94.6875) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4216 (0.4217) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0354 (0.0193) teacher/usage_max 0.5506 (0.5644) teacher/usage_min 0.2214 (0.1642) teacher/usage_std 0.1536 (0.1728) nleep/row_max_mean 1537.8970 (1538.7613) nleep/row_max_std 53.9186 (53.9350) nleep/row_min_mean 1508.0336 (1505.6221) lr 3.1545e-04 eta 0:05:54
epoch [39/50] batch [40/173] time 0.151 (0.162) data 0.000 (0.008) loss 1.5711 (1.6078) teacher_loss 0.0526 (0.1479) loss_zs_kd 0.0533 (0.0514) loss_oracle 0.7780 (0.6487) kd_loss 1.1028 (1.1098) acc 100.0000 (94.8438) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0057 (0.0205) teacher/usage_max 0.5011 (0.5427) teacher/usage_min 0.2489 (0.1680) teacher/usage_std 0.1186 (0.1607) nleep/row_max_mean 1549.3418 (1538.3776) nleep/row_max_std 59.5457 (54.3493) nleep/row_min_mean 1510.9541 (1505.4365) lr 3.1545e-04 eta 0:05:29
epoch [39/50] batch [60/173] time 0.137 (0.159) data 0.001 (0.006) loss 1.6284 (1.6035) teacher_loss 0.1864 (0.1399) loss_zs_kd 0.0717 (0.0512) loss_oracle 0.6596 (0.6524) kd_loss 1.0763 (1.1118) acc 96.8750 (95.1042) gate/entropy 1.0239 (1.0242) gate/usage_max 0.4216 (0.4216) gate/usage_min 0.1621 (0.1625) gate/usage_std 0.1211 (0.1208) teacher/entropy 0.0017 (0.0196) teacher/usage_max 0.4378 (0.5380) teacher/usage_min 0.2185 (0.1702) teacher/usage_std 0.0898 (0.1579) nleep/row_max_mean 1564.3246 (1539.4120) nleep/row_max_std 44.0549 (54.1227) nleep/row_min_mean 1526.1512 (1506.6378) lr 3.1545e-04 eta 0:05:21
epoch [39/50] batch [80/173] time 0.160 (0.157) data 0.000 (0.004) loss 1.6804 (1.6014) teacher_loss 0.1175 (0.1413) loss_zs_kd 0.0589 (0.0500) loss_oracle 0.7515 (0.6536) kd_loss 1.1577 (1.1083) acc 93.7500 (95.0781) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4215 (0.4216) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0089 (0.0208) teacher/usage_max 0.5023 (0.5405) teacher/usage_min 0.1875 (0.1707) teacher/usage_std 0.1295 (0.1591) nleep/row_max_mean 1542.3712 (1539.1137) nleep/row_max_std 50.4849 (53.7866) nleep/row_min_mean 1505.6063 (1506.4499) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [100/173] time 0.160 (0.156) data 0.000 (0.003) loss 1.4797 (1.6038) teacher_loss 0.0346 (0.1379) loss_zs_kd 0.0451 (0.0503) loss_oracle 0.6568 (0.6553) kd_loss 1.0940 (1.1132) acc 100.0000 (95.0938) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4214 (0.4216) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0187 (0.0208) teacher/usage_max 0.5592 (0.5373) teacher/usage_min 0.1875 (0.1711) teacher/usage_std 0.1619 (0.1574) nleep/row_max_mean 1529.6647 (1538.5775) nleep/row_max_std 65.0076 (53.8045) nleep/row_min_mean 1496.9006 (1505.9809) lr 3.1545e-04 eta 0:05:07
epoch [39/50] batch [120/173] time 0.162 (0.155) data 0.000 (0.003) loss 1.5009 (1.5959) teacher_loss 0.0660 (0.1337) loss_zs_kd 0.0486 (0.0497) loss_oracle 0.6365 (0.6589) kd_loss 1.0923 (1.1079) acc 100.0000 (95.1823) gate/entropy 1.0242 (1.0242) gate/usage_max 0.4214 (0.4215) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0218 (0.0205) teacher/usage_max 0.4318 (0.5459) teacher/usage_min 0.2556 (0.1693) teacher/usage_std 0.0734 (0.1626) nleep/row_max_mean 1538.4255 (1537.8568) nleep/row_max_std 56.6703 (54.3914) nleep/row_min_mean 1504.3672 (1505.3705) lr 3.1545e-04 eta 0:05:03
epoch [39/50] batch [140/173] time 0.141 (0.152) data 0.001 (0.003) loss 1.5776 (1.6004) teacher_loss 0.0935 (0.1313) loss_zs_kd 0.0614 (0.0491) loss_oracle 0.7494 (0.6671) kd_loss 1.0787 (1.1110) acc 96.8750 (95.3348) gate/entropy 1.0241 (1.0243) gate/usage_max 0.4213 (0.4215) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0014 (0.0206) teacher/usage_max 0.5937 (0.5445) teacher/usage_min 0.1875 (0.1693) teacher/usage_std 0.1846 (0.1620) nleep/row_max_mean 1552.0417 (1537.4661) nleep/row_max_std 60.5078 (54.5551) nleep/row_min_mean 1516.8464 (1505.0392) lr 3.1545e-04 eta 0:04:53
epoch [39/50] batch [160/173] time 0.065 (0.147) data 0.000 (0.002) loss 1.3754 (1.6019) teacher_loss 0.0305 (0.1289) loss_zs_kd 0.0362 (0.0485) loss_oracle 0.6354 (0.6700) kd_loss 1.0091 (1.1137) acc 100.0000 (95.4297) gate/entropy 1.0245 (1.0243) gate/usage_max 0.4212 (0.4215) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0344 (0.0200) teacher/usage_max 0.6710 (0.5470) teacher/usage_min 0.1495 (0.1679) teacher/usage_std 0.2391 (0.1636) nleep/row_max_mean 1537.0437 (1537.1394) nleep/row_max_std 62.0532 (54.9659) nleep/row_min_mean 1504.1755 (1504.7249) lr 3.1545e-04 eta 0:04:41
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [40/50] batch [20/173] time 0.088 (0.112) data 0.000 (0.015) loss 1.5620 (1.5725) teacher_loss 0.1152 (0.0907) loss_zs_kd 0.0232 (0.0468) loss_oracle 0.6807 (0.6718) kd_loss 1.0948 (1.1224) acc 96.8750 (96.5625) gate/entropy 1.0245 (1.0243) gate/usage_max 0.4212 (0.4212) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0256 (0.0209) teacher/usage_max 0.5834 (0.5421) teacher/usage_min 0.1562 (0.1680) teacher/usage_std 0.1819 (0.1610) nleep/row_max_mean 1528.8794 (1537.4255) nleep/row_max_std 61.4633 (56.1671) nleep/row_min_mean 1498.9629 (1504.7098) lr 2.7103e-04 eta 0:03:31
epoch [40/50] batch [40/173] time 0.214 (0.112) data 0.000 (0.008) loss 1.5564 (1.5749) teacher_loss 0.0816 (0.1024) loss_zs_kd 0.0426 (0.0460) loss_oracle 0.6907 (0.6715) kd_loss 1.1081 (1.1138) acc 96.8750 (96.7969) gate/entropy 1.0241 (1.0243) gate/usage_max 0.4211 (0.4211) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1210 (0.1208) teacher/entropy 0.0001 (0.0178) teacher/usage_max 0.4687 (0.5440) teacher/usage_min 0.2500 (0.1705) teacher/usage_std 0.0966 (0.1619) nleep/row_max_mean 1556.8677 (1536.6686) nleep/row_max_std 47.1889 (56.5276) nleep/row_min_mean 1518.9891 (1503.5407) lr 2.7103e-04 eta 0:03:29
epoch [40/50] batch [60/173] time 0.163 (0.119) data 0.001 (0.005) loss 1.7070 (1.5801) teacher_loss 0.2260 (0.1079) loss_zs_kd 0.0334 (0.0460) loss_oracle 0.7054 (0.6749) kd_loss 1.1116 (1.1118) acc 93.7500 (96.1979) gate/entropy 1.0241 (1.0243) gate/usage_max 0.4211 (0.4211) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0203 (0.0177) teacher/usage_max 0.5328 (0.5482) teacher/usage_min 0.1929 (0.1660) teacher/usage_std 0.1449 (0.1649) nleep/row_max_mean 1549.8308 (1535.3846) nleep/row_max_std 45.3863 (56.8578) nleep/row_min_mean 1515.9646 (1502.4916) lr 2.7103e-04 eta 0:03:38
epoch [40/50] batch [80/173] time 0.091 (0.118) data 0.000 (0.004) loss 1.4248 (1.5775) teacher_loss 0.0168 (0.1045) loss_zs_kd 0.0403 (0.0455) loss_oracle 0.6205 (0.6762) kd_loss 1.0776 (1.1121) acc 100.0000 (96.2891) gate/entropy 1.0242 (1.0243) gate/usage_max 0.4210 (0.4211) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0008 (0.0179) teacher/usage_max 0.4686 (0.5450) teacher/usage_min 0.2189 (0.1679) teacher/usage_std 0.1030 (0.1628) nleep/row_max_mean 1545.2588 (1536.7066) nleep/row_max_std 53.1661 (56.7211) nleep/row_min_mean 1510.1628 (1503.6435) lr 2.7103e-04 eta 0:03:35
epoch [40/50] batch [100/173] time 0.116 (0.120) data 0.001 (0.003) loss 1.4728 (1.5773) teacher_loss 0.0140 (0.1010) loss_zs_kd 0.0237 (0.0463) loss_oracle 0.6657 (0.6756) kd_loss 1.1142 (1.1154) acc 100.0000 (96.5312) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4209 (0.4211) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0334 (0.0170) teacher/usage_max 0.5392 (0.5462) teacher/usage_min 0.1707 (0.1639) teacher/usage_std 0.1535 (0.1642) nleep/row_max_mean 1539.0195 (1536.1633) nleep/row_max_std 64.6989 (56.6982) nleep/row_min_mean 1508.8159 (1503.3564) lr 2.7103e-04 eta 0:03:36
epoch [40/50] batch [120/173] time 0.122 (0.121) data 0.000 (0.003) loss 1.4703 (1.5762) teacher_loss 0.0259 (0.1037) loss_zs_kd 0.0243 (0.0464) loss_oracle 0.7115 (0.6744) kd_loss 1.0766 (1.1121) acc 100.0000 (96.4323) gate/entropy 1.0242 (1.0243) gate/usage_max 0.4209 (0.4210) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0023 (0.0172) teacher/usage_max 0.5317 (0.5526) teacher/usage_min 0.2183 (0.1624) teacher/usage_std 0.1408 (0.1682) nleep/row_max_mean 1530.6482 (1536.2082) nleep/row_max_std 69.5613 (56.0453) nleep/row_min_mean 1496.7371 (1503.5690) lr 2.7103e-04 eta 0:03:35
epoch [40/50] batch [140/173] time 0.122 (0.122) data 0.000 (0.002) loss 1.4974 (1.5758) teacher_loss 0.1485 (0.1053) loss_zs_kd 0.0444 (0.0460) loss_oracle 0.7105 (0.6734) kd_loss 0.9714 (1.1108) acc 93.7500 (96.3616) gate/entropy 1.0245 (1.0243) gate/usage_max 0.4208 (0.4210) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0307 (0.0177) teacher/usage_max 0.6126 (0.5538) teacher/usage_min 0.1363 (0.1634) teacher/usage_std 0.2029 (0.1685) nleep/row_max_mean 1521.1967 (1536.2356) nleep/row_max_std 51.4295 (55.7209) nleep/row_min_mean 1487.8286 (1503.7043) lr 2.7103e-04 eta 0:03:35
epoch [40/50] batch [160/173] time 0.127 (0.124) data 0.000 (0.002) loss 1.4871 (1.5737) teacher_loss 0.0237 (0.1053) loss_zs_kd 0.0349 (0.0462) loss_oracle 0.7349 (0.6715) kd_loss 1.0785 (1.1096) acc 100.0000 (96.3281) gate/entropy 1.0242 (1.0243) gate/usage_max 0.4208 (0.4210) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0204 (0.0190) teacher/usage_max 0.6047 (0.5530) teacher/usage_min 0.1563 (0.1632) teacher/usage_std 0.1948 (0.1682) nleep/row_max_mean 1549.0627 (1536.0831) nleep/row_max_std 43.3701 (55.9073) nleep/row_min_mean 1514.9780 (1503.7793) lr 2.7103e-04 eta 0:03:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,303
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [41/50] batch [20/173] time 0.133 (0.161) data 0.000 (0.016) loss 1.6962 (1.6301) teacher_loss 0.1234 (0.1226) loss_zs_kd 0.0423 (0.0516) loss_oracle 0.6862 (0.6815) kd_loss 1.2085 (1.1409) acc 96.8750 (95.4688) gate/entropy 1.0243 (1.0242) gate/usage_max 0.4207 (0.4207) gate/usage_min 0.1625 (0.1624) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0513 (0.0298) teacher/usage_max 0.4330 (0.4785) teacher/usage_min 0.1566 (0.1913) teacher/usage_std 0.1253 (0.1212) nleep/row_max_mean 1538.2257 (1539.2760) nleep/row_max_std 62.6444 (59.0450) nleep/row_min_mean 1510.3489 (1507.8327) lr 2.2949e-04 eta 0:04:35
epoch [41/50] batch [40/173] time 0.131 (0.151) data 0.000 (0.008) loss 1.7038 (1.6162) teacher_loss 0.1788 (0.1378) loss_zs_kd 0.0468 (0.0509) loss_oracle 0.6464 (0.6787) kd_loss 1.1784 (1.1137) acc 87.5000 (95.1562) gate/entropy 1.0245 (1.0242) gate/usage_max 0.4206 (0.4207) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0176 (0.0285) teacher/usage_max 0.5325 (0.5171) teacher/usage_min 0.1253 (0.1824) teacher/usage_std 0.1663 (0.1438) nleep/row_max_mean 1522.0144 (1538.8696) nleep/row_max_std 56.4007 (58.0537) nleep/row_min_mean 1493.1250 (1507.3776) lr 2.2949e-04 eta 0:04:14
epoch [41/50] batch [60/173] time 0.077 (0.144) data 0.001 (0.005) loss 2.0136 (1.6224) teacher_loss 0.3606 (0.1448) loss_zs_kd 0.0375 (0.0487) loss_oracle 0.7674 (0.6827) kd_loss 1.2506 (1.1120) acc 90.6250 (95.0521) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4206 (0.4207) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0271 (0.0309) teacher/usage_max 0.4307 (0.5298) teacher/usage_min 0.1876 (0.1750) teacher/usage_std 0.1050 (0.1520) nleep/row_max_mean 1549.1450 (1538.1674) nleep/row_max_std 49.2448 (57.3527) nleep/row_min_mean 1516.7087 (1507.0406) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [80/173] time 0.075 (0.135) data 0.000 (0.004) loss 1.6497 (1.6156) teacher_loss 0.1580 (0.1351) loss_zs_kd 0.0383 (0.0486) loss_oracle 0.5759 (0.6832) kd_loss 1.1846 (1.1146) acc 93.7500 (95.2734) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4206 (0.4207) gate/usage_min 0.1626 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0317 (0.0323) teacher/usage_max 0.4489 (0.5238) teacher/usage_min 0.1877 (0.1775) teacher/usage_std 0.1088 (0.1486) nleep/row_max_mean 1527.2952 (1538.0169) nleep/row_max_std 56.6968 (56.7631) nleep/row_min_mean 1498.1976 (1506.9122) lr 2.2949e-04 eta 0:03:42
epoch [41/50] batch [100/173] time 0.082 (0.131) data 0.000 (0.003) loss 1.5911 (1.6078) teacher_loss 0.0344 (0.1290) loss_zs_kd 0.0319 (0.0475) loss_oracle 0.7769 (0.6803) kd_loss 1.1523 (1.1149) acc 100.0000 (95.6562) gate/entropy 1.0245 (1.0243) gate/usage_max 0.4205 (0.4207) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0129 (0.0350) teacher/usage_max 0.5011 (0.5203) teacher/usage_min 0.1875 (0.1781) teacher/usage_std 0.1290 (0.1465) nleep/row_max_mean 1525.6373 (1537.0918) nleep/row_max_std 60.2413 (56.4820) nleep/row_min_mean 1493.8420 (1506.2242) lr 2.2949e-04 eta 0:03:32
epoch [41/50] batch [120/173] time 0.149 (0.128) data 0.000 (0.003) loss 1.6156 (1.6033) teacher_loss 0.0462 (0.1283) loss_zs_kd 0.0373 (0.0469) loss_oracle 0.7214 (0.6804) kd_loss 1.1900 (1.1113) acc 96.8750 (95.5990) gate/entropy 1.0242 (1.0243) gate/usage_max 0.4205 (0.4206) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0378 (0.0384) teacher/usage_max 0.4363 (0.5249) teacher/usage_min 0.1875 (0.1735) teacher/usage_std 0.1060 (0.1504) nleep/row_max_mean 1544.6923 (1536.0487) nleep/row_max_std 50.2055 (56.4973) nleep/row_min_mean 1512.7267 (1505.4212) lr 2.2949e-04 eta 0:03:25
epoch [41/50] batch [140/173] time 0.081 (0.127) data 0.000 (0.002) loss 1.6047 (1.6093) teacher_loss 0.0794 (0.1292) loss_zs_kd 0.0517 (0.0475) loss_oracle 0.7133 (0.6801) kd_loss 1.1428 (1.1163) acc 100.0000 (95.6027) gate/entropy 1.0241 (1.0243) gate/usage_max 0.4205 (0.4206) gate/usage_min 0.1623 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0737 (0.0419) teacher/usage_max 0.3662 (0.5210) teacher/usage_min 0.2851 (0.1730) teacher/usage_std 0.0348 (0.1490) nleep/row_max_mean 1548.4753 (1536.0868) nleep/row_max_std 56.7607 (56.3717) nleep/row_min_mean 1516.0056 (1505.5315) lr 2.2949e-04 eta 0:03:21
epoch [41/50] batch [160/173] time 0.151 (0.123) data 0.000 (0.002) loss 1.5114 (1.6165) teacher_loss 0.0771 (0.1303) loss_zs_kd 0.0292 (0.0484) loss_oracle 0.6701 (0.6830) kd_loss 1.0847 (1.1205) acc 96.8750 (95.5273) gate/entropy 1.0246 (1.0243) gate/usage_max 0.4204 (0.4206) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0506 (0.0430) teacher/usage_max 0.5034 (0.5163) teacher/usage_min 0.2186 (0.1753) teacher/usage_std 0.1227 (0.1457) nleep/row_max_mean 1509.8375 (1535.6728) nleep/row_max_std 59.3931 (56.3615) nleep/row_min_mean 1480.6560 (1505.0598) lr 2.2949e-04 eta 0:03:13
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [42/50] batch [20/173] time 0.152 (0.157) data 0.000 (0.015) loss 1.7334 (1.7205) teacher_loss 0.1185 (0.1685) loss_zs_kd 0.0516 (0.0498) loss_oracle 0.7358 (0.6788) kd_loss 1.2212 (1.1877) acc 96.8750 (93.9062) gate/entropy 1.0244 (1.0242) gate/usage_max 0.4204 (0.4204) gate/usage_min 0.1626 (0.1624) gate/usage_std 0.1207 (0.1209) teacher/entropy 0.0264 (0.0328) teacher/usage_max 0.4780 (0.4725) teacher/usage_min 0.1250 (0.1780) teacher/usage_std 0.1510 (0.1254) nleep/row_max_mean 1531.3710 (1538.9771) nleep/row_max_std 59.4786 (53.5802) nleep/row_min_mean 1501.0815 (1508.2111) lr 1.9098e-04 eta 0:04:01
epoch [42/50] batch [40/173] time 0.155 (0.152) data 0.000 (0.007) loss 1.7865 (1.7040) teacher_loss 0.1256 (0.1476) loss_zs_kd 0.0694 (0.0486) loss_oracle 0.6784 (0.6774) kd_loss 1.2871 (1.1934) acc 96.8750 (94.7656) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4203 (0.4204) gate/usage_min 0.1625 (0.1625) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0320 (0.0370) teacher/usage_max 0.4738 (0.4719) teacher/usage_min 0.1250 (0.1730) teacher/usage_std 0.1503 (0.1279) nleep/row_max_mean 1536.1011 (1538.6777) nleep/row_max_std 51.1137 (54.6000) nleep/row_min_mean 1505.4177 (1508.2833) lr 1.9098e-04 eta 0:03:50
epoch [42/50] batch [60/173] time 0.148 (0.146) data 0.001 (0.005) loss 1.6570 (1.7131) teacher_loss 0.1204 (0.1441) loss_zs_kd 0.0496 (0.0488) loss_oracle 0.6473 (0.6784) kd_loss 1.1882 (1.2053) acc 96.8750 (94.6875) gate/entropy 1.0242 (1.0243) gate/usage_max 0.4203 (0.4204) gate/usage_min 0.1624 (0.1625) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0226 (0.0362) teacher/usage_max 0.4536 (0.4690) teacher/usage_min 0.1875 (0.1777) teacher/usage_std 0.1101 (0.1248) nleep/row_max_mean 1538.9821 (1538.8687) nleep/row_max_std 67.3756 (55.4668) nleep/row_min_mean 1509.1499 (1508.2360) lr 1.9098e-04 eta 0:03:39
epoch [42/50] batch [80/173] time 0.146 (0.145) data 0.000 (0.004) loss 1.9419 (1.7181) teacher_loss 0.2105 (0.1400) loss_zs_kd 0.0837 (0.0494) loss_oracle 0.6741 (0.6785) kd_loss 1.3525 (1.2142) acc 87.5000 (94.8828) gate/entropy 1.0244 (1.0243) gate/usage_max 0.4203 (0.4204) gate/usage_min 0.1626 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0411 (0.0348) teacher/usage_max 0.5534 (0.4649) teacher/usage_min 0.1584 (0.1807) teacher/usage_std 0.1644 (0.1217) nleep/row_max_mean 1527.6418 (1539.4520) nleep/row_max_std 49.9474 (54.6952) nleep/row_min_mean 1496.5951 (1508.4779) lr 1.9098e-04 eta 0:03:33
epoch [42/50] batch [100/173] time 0.136 (0.142) data 0.000 (0.003) loss 1.6964 (1.7148) teacher_loss 0.0303 (0.1303) loss_zs_kd 0.0115 (0.0488) loss_oracle 0.7019 (0.6802) kd_loss 1.3094 (1.2200) acc 96.8750 (95.2188) gate/entropy 1.0246 (1.0243) gate/usage_max 0.4202 (0.4203) gate/usage_min 0.1628 (0.1625) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0048 (0.0330) teacher/usage_max 0.4696 (0.4657) teacher/usage_min 0.1250 (0.1802) teacher/usage_std 0.1496 (0.1221) nleep/row_max_mean 1534.4307 (1539.3401) nleep/row_max_std 50.8437 (54.5956) nleep/row_min_mean 1503.9829 (1508.1994) lr 1.9098e-04 eta 0:03:27
epoch [42/50] batch [120/173] time 0.122 (0.141) data 0.000 (0.003) loss 1.7824 (1.7179) teacher_loss 0.1663 (0.1257) loss_zs_kd 0.0492 (0.0479) loss_oracle 0.7361 (0.6779) kd_loss 1.2234 (1.2293) acc 96.8750 (95.4948) gate/entropy 1.0244 (1.0243) gate/usage_max 0.4202 (0.4203) gate/usage_min 0.1626 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0694 (0.0321) teacher/usage_max 0.4471 (0.4690) teacher/usage_min 0.1875 (0.1754) teacher/usage_std 0.1084 (0.1255) nleep/row_max_mean 1529.9031 (1538.0980) nleep/row_max_std 58.4161 (55.5134) nleep/row_min_mean 1495.6711 (1506.9609) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [140/173] time 0.128 (0.140) data 0.000 (0.002) loss 1.7386 (1.7215) teacher_loss 0.0210 (0.1236) loss_zs_kd 0.0341 (0.0478) loss_oracle 0.7870 (0.6766) kd_loss 1.3071 (1.2357) acc 100.0000 (95.5580) gate/entropy 1.0245 (1.0243) gate/usage_max 0.4202 (0.4203) gate/usage_min 0.1627 (0.1625) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0082 (0.0317) teacher/usage_max 0.4988 (0.4704) teacher/usage_min 0.0315 (0.1757) teacher/usage_std 0.2137 (0.1261) nleep/row_max_mean 1530.2740 (1538.3560) nleep/row_max_std 58.9948 (55.4512) nleep/row_min_mean 1500.1973 (1506.9347) lr 1.9098e-04 eta 0:03:18
epoch [42/50] batch [160/173] time 0.115 (0.139) data 0.000 (0.002) loss 1.7641 (1.7215) teacher_loss 0.1262 (0.1202) loss_zs_kd 0.0552 (0.0478) loss_oracle 0.7444 (0.6769) kd_loss 1.2381 (1.2390) acc 96.8750 (95.7031) gate/entropy 1.0243 (1.0243) gate/usage_max 0.4202 (0.4203) gate/usage_min 0.1625 (0.1626) gate/usage_std 0.1208 (0.1208) teacher/entropy 0.0221 (0.0303) teacher/usage_max 0.4327 (0.4722) teacher/usage_min 0.1563 (0.1746) teacher/usage_std 0.1255 (0.1273) nleep/row_max_mean 1546.3315 (1538.6322) nleep/row_max_std 45.5483 (55.1419) nleep/row_min_mean 1510.3167 (1507.0355) lr 1.9098e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,301
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [43/50] batch [20/173] time 0.087 (0.134) data 0.000 (0.018) loss 1.6686 (1.7324) teacher_loss 0.0172 (0.1127) loss_zs_kd 0.0472 (0.0447) loss_oracle 0.6723 (0.6678) kd_loss 1.2917 (1.2635) acc 100.0000 (95.7812) gate/entropy 1.0246 (1.0244) gate/usage_max 0.4202 (0.4202) gate/usage_min 0.1628 (0.1626) gate/usage_std 0.1206 (0.1207) teacher/entropy 0.0238 (0.0237) teacher/usage_max 0.4718 (0.4677) teacher/usage_min 0.2469 (0.1574) teacher/usage_std 0.0989 (0.1337) nleep/row_max_mean 1532.8450 (1536.1516) nleep/row_max_std 54.3642 (51.0977) nleep/row_min_mean 1497.2612 (1504.5514) lr 1.5567e-04 eta 0:03:03
epoch [43/50] batch [40/173] time 0.201 (0.130) data 0.000 (0.009) loss 1.6793 (1.7070) teacher_loss 0.0501 (0.1015) loss_zs_kd 0.0500 (0.0425) loss_oracle 0.7306 (0.6686) kd_loss 1.2388 (1.2500) acc 96.8750 (96.5625) gate/entropy 1.0244 (1.0244) gate/usage_max 0.4202 (0.4202) gate/usage_min 0.1626 (0.1626) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0195 (0.0220) teacher/usage_max 0.4090 (0.4711) teacher/usage_min 0.1875 (0.1549) teacher/usage_std 0.1031 (0.1355) nleep/row_max_mean 1539.9807 (1536.1168) nleep/row_max_std 44.9134 (50.5847) nleep/row_min_mean 1506.3440 (1504.3289) lr 1.5567e-04 eta 0:02:54
epoch [43/50] batch [60/173] time 0.088 (0.123) data 0.000 (0.006) loss 1.7777 (1.7082) teacher_loss 0.1253 (0.1062) loss_zs_kd 0.0797 (0.0447) loss_oracle 0.6788 (0.6751) kd_loss 1.2731 (1.2420) acc 100.0000 (95.9896) gate/entropy 1.0245 (1.0244) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1627 (0.1626) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0224 (0.0214) teacher/usage_max 0.4499 (0.4702) teacher/usage_min 0.1875 (0.1641) teacher/usage_std 0.1091 (0.1309) nleep/row_max_mean 1538.4241 (1538.0621) nleep/row_max_std 41.2798 (50.1243) nleep/row_min_mean 1504.5585 (1505.7594) lr 1.5567e-04 eta 0:02:43
epoch [43/50] batch [80/173] time 0.077 (0.124) data 0.000 (0.005) loss 1.6862 (1.7191) teacher_loss 0.0321 (0.1049) loss_zs_kd 0.0418 (0.0453) loss_oracle 0.6490 (0.6745) kd_loss 1.3087 (1.2543) acc 100.0000 (95.8984) gate/entropy 1.0245 (1.0244) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1627 (0.1627) gate/usage_std 0.1206 (0.1207) teacher/entropy 0.0060 (0.0227) teacher/usage_max 0.4701 (0.4730) teacher/usage_min 0.1875 (0.1661) teacher/usage_std 0.1156 (0.1308) nleep/row_max_mean 1531.8918 (1537.7695) nleep/row_max_std 47.4105 (50.5233) nleep/row_min_mean 1496.2601 (1505.5757) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [100/173] time 0.083 (0.122) data 0.000 (0.004) loss 1.7494 (1.7240) teacher_loss 0.1284 (0.1057) loss_zs_kd 0.0490 (0.0467) loss_oracle 0.6514 (0.6711) kd_loss 1.2708 (1.2594) acc 90.6250 (95.8438) gate/entropy 1.0248 (1.0244) gate/usage_max 0.4200 (0.4201) gate/usage_min 0.1630 (0.1627) gate/usage_std 0.1204 (0.1207) teacher/entropy 0.0136 (0.0230) teacher/usage_max 0.4386 (0.4765) teacher/usage_min 0.2196 (0.1664) teacher/usage_std 0.0896 (0.1319) nleep/row_max_mean 1523.1587 (1537.8391) nleep/row_max_std 57.3598 (50.8776) nleep/row_min_mean 1494.0737 (1505.6641) lr 1.5567e-04 eta 0:02:36
epoch [43/50] batch [120/173] time 0.087 (0.122) data 0.000 (0.003) loss 1.8617 (1.7239) teacher_loss 0.1295 (0.1065) loss_zs_kd 0.0440 (0.0469) loss_oracle 0.6475 (0.6696) kd_loss 1.3864 (1.2591) acc 93.7500 (95.8594) gate/entropy 1.0243 (1.0244) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1625 (0.1627) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0263 (0.0228) teacher/usage_max 0.5740 (0.4752) teacher/usage_min 0.1563 (0.1694) teacher/usage_std 0.1764 (0.1304) nleep/row_max_mean 1547.5315 (1538.4092) nleep/row_max_std 50.1602 (51.2900) nleep/row_min_mean 1516.7354 (1506.1832) lr 1.5567e-04 eta 0:02:33
epoch [43/50] batch [140/173] time 0.161 (0.124) data 0.000 (0.003) loss 1.7521 (1.7244) teacher_loss 0.1061 (0.1055) loss_zs_kd 0.0291 (0.0465) loss_oracle 0.6636 (0.6728) kd_loss 1.2997 (1.2592) acc 93.7500 (95.8929) gate/entropy 1.0246 (1.0245) gate/usage_max 0.4200 (0.4201) gate/usage_min 0.1629 (0.1627) gate/usage_std 0.1205 (0.1207) teacher/entropy 0.0182 (0.0217) teacher/usage_max 0.4727 (0.4757) teacher/usage_min 0.1250 (0.1675) teacher/usage_std 0.1501 (0.1314) nleep/row_max_mean 1535.3956 (1538.3219) nleep/row_max_std 53.3154 (51.3255) nleep/row_min_mean 1504.6870 (1506.1407) lr 1.5567e-04 eta 0:02:34
epoch [43/50] batch [160/173] time 0.151 (0.128) data 0.000 (0.002) loss 1.9333 (1.7280) teacher_loss 0.2819 (0.1105) loss_zs_kd 0.0471 (0.0472) loss_oracle 0.7157 (0.6737) kd_loss 1.2700 (1.2570) acc 87.5000 (95.7617) gate/entropy 1.0246 (1.0245) gate/usage_max 0.4200 (0.4201) gate/usage_min 0.1628 (0.1627) gate/usage_std 0.1206 (0.1207) teacher/entropy 0.0264 (0.0216) teacher/usage_max 0.4505 (0.4755) teacher/usage_min 0.1563 (0.1698) teacher/usage_std 0.1273 (0.1303) nleep/row_max_mean 1532.4230 (1538.7682) nleep/row_max_std 43.6809 (50.8777) nleep/row_min_mean 1501.7706 (1506.5043) lr 1.5567e-04 eta 0:02:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,301
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [44/50] batch [20/173] time 0.176 (0.183) data 0.000 (0.013) loss 1.5703 (1.7453) teacher_loss 0.0258 (0.1222) loss_zs_kd 0.0250 (0.0557) loss_oracle 0.6874 (0.6742) kd_loss 1.1883 (1.2581) acc 100.0000 (95.3125) gate/entropy 1.0248 (1.0245) gate/usage_max 0.4199 (0.4200) gate/usage_min 0.1630 (0.1628) gate/usage_std 0.1204 (0.1206) teacher/entropy 0.0061 (0.0204) teacher/usage_max 0.4389 (0.4611) teacher/usage_min 0.2188 (0.1638) teacher/usage_std 0.0901 (0.1276) nleep/row_max_mean 1535.9594 (1535.8413) nleep/row_max_std 53.4420 (50.7386) nleep/row_min_mean 1503.8739 (1503.4608) lr 1.2369e-04 eta 0:03:37
epoch [44/50] batch [40/173] time 0.159 (0.180) data 0.000 (0.007) loss 1.7798 (1.7351) teacher_loss 0.1002 (0.1157) loss_zs_kd 0.0471 (0.0510) loss_oracle 0.7021 (0.6689) kd_loss 1.3051 (1.2595) acc 96.8750 (95.3906) gate/entropy 1.0246 (1.0245) gate/usage_max 0.4200 (0.4200) gate/usage_min 0.1628 (0.1627) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0264 (0.0232) teacher/usage_max 0.4875 (0.4740) teacher/usage_min 0.1563 (0.1691) teacher/usage_std 0.1362 (0.1305) nleep/row_max_mean 1534.4613 (1538.7025) nleep/row_max_std 59.0836 (50.2280) nleep/row_min_mean 1502.1697 (1506.3577) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [60/173] time 0.158 (0.173) data 0.000 (0.005) loss 1.7405 (1.7250) teacher_loss 0.1398 (0.1114) loss_zs_kd 0.0489 (0.0489) loss_oracle 0.7192 (0.6701) kd_loss 1.2167 (1.2541) acc 93.7500 (95.5729) gate/entropy 1.0247 (1.0245) gate/usage_max 0.4199 (0.4200) gate/usage_min 0.1630 (0.1627) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0326 (0.0244) teacher/usage_max 0.4434 (0.4788) teacher/usage_min 0.1563 (0.1654) teacher/usage_std 0.1264 (0.1340) nleep/row_max_mean 1518.6721 (1538.0504) nleep/row_max_std 51.9649 (49.9211) nleep/row_min_mean 1487.9503 (1506.1727) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [80/173] time 0.085 (0.159) data 0.000 (0.003) loss 1.7948 (1.7331) teacher_loss 0.0856 (0.1142) loss_zs_kd 0.0588 (0.0493) loss_oracle 0.6396 (0.6712) kd_loss 1.3600 (1.2586) acc 96.8750 (95.3906) gate/entropy 1.0245 (1.0245) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1628 (0.1627) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0131 (0.0238) teacher/usage_max 0.5325 (0.4808) teacher/usage_min 0.1562 (0.1671) teacher/usage_std 0.1544 (0.1335) nleep/row_max_mean 1544.5105 (1538.7790) nleep/row_max_std 42.1989 (50.1467) nleep/row_min_mean 1508.7750 (1506.8060) lr 1.2369e-04 eta 0:02:59
epoch [44/50] batch [100/173] time 0.083 (0.151) data 0.000 (0.003) loss 1.7016 (1.7280) teacher_loss 0.1094 (0.1155) loss_zs_kd 0.0839 (0.0490) loss_oracle 0.6565 (0.6690) kd_loss 1.2220 (1.2535) acc 93.7500 (95.5938) gate/entropy 1.0245 (1.0245) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1627 (0.1627) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0030 (0.0230) teacher/usage_max 0.4057 (0.4769) teacher/usage_min 0.2188 (0.1702) teacher/usage_std 0.0820 (0.1304) nleep/row_max_mean 1548.6659 (1539.7060) nleep/row_max_std 56.3922 (50.3495) nleep/row_min_mean 1514.1537 (1507.7012) lr 1.2369e-04 eta 0:02:47
epoch [44/50] batch [120/173] time 0.093 (0.144) data 0.000 (0.002) loss 1.8831 (1.7300) teacher_loss 0.1047 (0.1160) loss_zs_kd 0.0287 (0.0489) loss_oracle 0.7425 (0.6706) kd_loss 1.3927 (1.2542) acc 93.7500 (95.5469) gate/entropy 1.0246 (1.0245) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1628 (0.1628) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0094 (0.0231) teacher/usage_max 0.5625 (0.4757) teacher/usage_min 0.2188 (0.1730) teacher/usage_std 0.1620 (0.1286) nleep/row_max_mean 1544.7474 (1539.8680) nleep/row_max_std 54.0266 (50.5966) nleep/row_min_mean 1509.1068 (1507.7614) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [140/173] time 0.084 (0.141) data 0.000 (0.002) loss 1.7189 (1.7334) teacher_loss 0.0952 (0.1137) loss_zs_kd 0.0542 (0.0486) loss_oracle 0.6921 (0.6737) kd_loss 1.2505 (1.2585) acc 96.8750 (95.5580) gate/entropy 1.0245 (1.0245) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1627 (0.1628) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0035 (0.0229) teacher/usage_max 0.4067 (0.4763) teacher/usage_min 0.1875 (0.1730) teacher/usage_std 0.1031 (0.1293) nleep/row_max_mean 1547.1157 (1540.1440) nleep/row_max_std 51.3958 (50.8214) nleep/row_min_mean 1515.2159 (1508.0019) lr 1.2369e-04 eta 0:02:30
epoch [44/50] batch [160/173] time 0.087 (0.138) data 0.000 (0.002) loss 1.6358 (1.7327) teacher_loss 0.0471 (0.1144) loss_zs_kd 0.0480 (0.0490) loss_oracle 0.6935 (0.6756) kd_loss 1.2179 (1.2559) acc 96.8750 (95.5664) gate/entropy 1.0246 (1.0245) gate/usage_max 0.4199 (0.4199) gate/usage_min 0.1629 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0273 (0.0237) teacher/usage_max 0.3964 (0.4733) teacher/usage_min 0.2190 (0.1747) teacher/usage_std 0.0810 (0.1272) nleep/row_max_mean 1533.7373 (1540.4948) nleep/row_max_std 62.7788 (51.1519) nleep/row_min_mean 1500.8296 (1508.2838) lr 1.2369e-04 eta 0:02:25
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,299
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [45/50] batch [20/173] time 0.157 (0.160) data 0.000 (0.019) loss 1.6601 (1.7214) teacher_loss 0.0743 (0.1067) loss_zs_kd 0.0545 (0.0448) loss_oracle 0.6504 (0.6794) kd_loss 1.2333 (1.2525) acc 96.8750 (96.4062) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1629 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0270 (0.0244) teacher/usage_max 0.4663 (0.4702) teacher/usage_min 0.1229 (0.1460) teacher/usage_std 0.1505 (0.1383) nleep/row_max_mean 1531.9917 (1533.9982) nleep/row_max_std 50.8394 (53.6687) nleep/row_min_mean 1500.7783 (1502.6776) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [40/173] time 0.166 (0.159) data 0.000 (0.009) loss 1.5971 (1.7307) teacher_loss 0.0493 (0.1085) loss_zs_kd 0.0407 (0.0472) loss_oracle 0.6100 (0.6757) kd_loss 1.2225 (1.2608) acc 100.0000 (96.2500) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1629 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0246 (0.0258) teacher/usage_max 0.5024 (0.4809) teacher/usage_min 0.1003 (0.1546) teacher/usage_std 0.1703 (0.1393) nleep/row_max_mean 1521.3113 (1536.4767) nleep/row_max_std 62.3033 (52.1945) nleep/row_min_mean 1492.3129 (1504.8071) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [60/173] time 0.155 (0.155) data 0.001 (0.006) loss 1.5719 (1.7179) teacher_loss 0.0827 (0.1006) loss_zs_kd 0.0299 (0.0486) loss_oracle 0.5720 (0.6712) kd_loss 1.1882 (1.2575) acc 96.8750 (96.5625) gate/entropy 1.0250 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1633 (0.1628) gate/usage_std 0.1203 (0.1206) teacher/entropy 0.0514 (0.0262) teacher/usage_max 0.4365 (0.4867) teacher/usage_min 0.1734 (0.1621) teacher/usage_std 0.1147 (0.1379) nleep/row_max_mean 1525.2644 (1538.6981) nleep/row_max_std 62.8657 (51.2463) nleep/row_min_mean 1497.0818 (1506.7701) lr 9.5173e-05 eta 0:02:32
epoch [45/50] batch [80/173] time 0.153 (0.151) data 0.000 (0.005) loss 1.5627 (1.7007) teacher_loss 0.0919 (0.0975) loss_zs_kd 0.0460 (0.0484) loss_oracle 0.6453 (0.6737) kd_loss 1.1252 (1.2421) acc 96.8750 (96.6406) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1629 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0646 (0.0274) teacher/usage_max 0.4112 (0.4781) teacher/usage_min 0.2500 (0.1707) teacher/usage_std 0.0659 (0.1307) nleep/row_max_mean 1549.1095 (1540.1580) nleep/row_max_std 52.0605 (51.6633) nleep/row_min_mean 1513.4482 (1507.8786) lr 9.5173e-05 eta 0:02:24
epoch [45/50] batch [100/173] time 0.118 (0.151) data 0.000 (0.004) loss 1.7160 (1.6983) teacher_loss 0.0669 (0.0989) loss_zs_kd 0.0506 (0.0483) loss_oracle 0.6781 (0.6695) kd_loss 1.2847 (1.2405) acc 100.0000 (96.6250) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4197 (0.4198) gate/usage_min 0.1630 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0197 (0.0277) teacher/usage_max 0.4593 (0.4717) teacher/usage_min 0.1563 (0.1745) teacher/usage_std 0.1289 (0.1268) nleep/row_max_mean 1521.2638 (1540.0643) nleep/row_max_std 56.3483 (51.5234) nleep/row_min_mean 1490.1060 (1507.9000) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [120/173] time 0.129 (0.148) data 0.000 (0.003) loss 1.9129 (1.7082) teacher_loss 0.1219 (0.1053) loss_zs_kd 0.0457 (0.0491) loss_oracle 0.7108 (0.6700) kd_loss 1.4127 (1.2433) acc 96.8750 (96.5365) gate/entropy 1.0245 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1627 (0.1628) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0479 (0.0298) teacher/usage_max 0.6235 (0.4744) teacher/usage_min 0.0938 (0.1727) teacher/usage_std 0.2192 (0.1290) nleep/row_max_mean 1529.8180 (1538.7169) nleep/row_max_std 49.4614 (51.7775) nleep/row_min_mean 1499.5370 (1506.7612) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [140/173] time 0.126 (0.147) data 0.000 (0.003) loss 1.6541 (1.7042) teacher_loss 0.0635 (0.1031) loss_zs_kd 0.0561 (0.0490) loss_oracle 0.6369 (0.6692) kd_loss 1.2442 (1.2420) acc 100.0000 (96.5848) gate/entropy 1.0242 (1.0246) gate/usage_max 0.4198 (0.4198) gate/usage_min 0.1624 (0.1628) gate/usage_std 0.1209 (0.1206) teacher/entropy 0.0092 (0.0293) teacher/usage_max 0.4396 (0.4733) teacher/usage_min 0.1561 (0.1724) teacher/usage_std 0.1261 (0.1287) nleep/row_max_mean 1553.5559 (1538.9215) nleep/row_max_std 41.1893 (51.8946) nleep/row_min_mean 1520.8948 (1507.0237) lr 9.5173e-05 eta 0:02:12
epoch [45/50] batch [160/173] time 0.155 (0.146) data 0.000 (0.002) loss 1.7590 (1.7053) teacher_loss 0.1957 (0.1053) loss_zs_kd 0.0594 (0.0496) loss_oracle 0.6671 (0.6671) kd_loss 1.2001 (1.2417) acc 93.7500 (96.5430) gate/entropy 1.0246 (1.0246) gate/usage_max 0.4197 (0.4198) gate/usage_min 0.1629 (0.1628) gate/usage_std 0.1205 (0.1206) teacher/entropy 0.0341 (0.0293) teacher/usage_max 0.5005 (0.4738) teacher/usage_min 0.1146 (0.1731) teacher/usage_std 0.1617 (0.1284) nleep/row_max_mean 1533.4241 (1538.7892) nleep/row_max_std 62.2834 (52.2413) nleep/row_min_mean 1503.0615 (1506.9040) lr 9.5173e-05 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,305
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [46/50] batch [20/173] time 0.169 (0.123) data 0.000 (0.016) loss 1.6814 (1.6987) teacher_loss 0.0712 (0.1169) loss_zs_kd 0.0400 (0.0467) loss_oracle 0.6659 (0.6495) kd_loss 1.2573 (1.2336) acc 100.0000 (95.9375) gate/entropy 1.0245 (1.0246) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1207 (0.1205) teacher/entropy 0.0228 (0.0322) teacher/usage_max 0.4409 (0.4625) teacher/usage_min 0.1267 (0.1801) teacher/usage_std 0.1461 (0.1204) nleep/row_max_mean 1529.4110 (1531.3406) nleep/row_max_std 56.6072 (56.5664) nleep/row_min_mean 1502.2212 (1500.7271) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [40/173] time 0.110 (0.123) data 0.000 (0.008) loss 1.6593 (1.6941) teacher_loss 0.1229 (0.1121) loss_zs_kd 0.0456 (0.0467) loss_oracle 0.6298 (0.6464) kd_loss 1.1987 (1.2355) acc 96.8750 (95.9375) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0186 (0.0311) teacher/usage_max 0.4141 (0.4727) teacher/usage_min 0.2188 (0.1852) teacher/usage_std 0.0833 (0.1218) nleep/row_max_mean 1541.1672 (1532.4507) nleep/row_max_std 61.4699 (56.3813) nleep/row_min_mean 1509.0789 (1501.4378) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [60/173] time 0.111 (0.113) data 0.000 (0.006) loss 1.5689 (1.6964) teacher_loss 0.1409 (0.1143) loss_zs_kd 0.0415 (0.0459) loss_oracle 0.7286 (0.6567) kd_loss 1.0430 (1.2309) acc 93.7500 (95.9896) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0450 (0.0309) teacher/usage_max 0.6458 (0.4789) teacher/usage_min 0.1250 (0.1799) teacher/usage_std 0.2250 (0.1272) nleep/row_max_mean 1540.8082 (1533.1084) nleep/row_max_std 59.9263 (55.9442) nleep/row_min_mean 1508.7280 (1502.0004) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [80/173] time 0.161 (0.116) data 0.000 (0.004) loss 1.7599 (1.6942) teacher_loss 0.0795 (0.1123) loss_zs_kd 0.0496 (0.0463) loss_oracle 0.6431 (0.6579) kd_loss 1.3340 (1.2298) acc 100.0000 (96.0156) gate/entropy 1.0245 (1.0246) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1207 (0.1205) teacher/entropy 0.0618 (0.0316) teacher/usage_max 0.5549 (0.4789) teacher/usage_min 0.0975 (0.1757) teacher/usage_std 0.1870 (0.1288) nleep/row_max_mean 1538.4615 (1534.2388) nleep/row_max_std 51.7486 (55.6576) nleep/row_min_mean 1508.3462 (1503.0533) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [100/173] time 0.158 (0.113) data 0.000 (0.003) loss 1.7857 (1.6922) teacher_loss 0.2375 (0.1141) loss_zs_kd 0.0526 (0.0480) loss_oracle 0.7459 (0.6583) kd_loss 1.1490 (1.2249) acc 90.6250 (95.8750) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4196 (0.4197) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0146 (0.0311) teacher/usage_max 0.5346 (0.4721) teacher/usage_min 0.1562 (0.1793) teacher/usage_std 0.1554 (0.1248) nleep/row_max_mean 1533.0206 (1535.2271) nleep/row_max_std 64.0457 (55.9355) nleep/row_min_mean 1498.9192 (1503.8211) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [120/173] time 0.090 (0.110) data 0.000 (0.003) loss 1.7416 (1.6933) teacher_loss 0.0487 (0.1143) loss_zs_kd 0.0322 (0.0483) loss_oracle 0.6755 (0.6574) kd_loss 1.3391 (1.2262) acc 100.0000 (95.9375) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4196 (0.4197) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0039 (0.0313) teacher/usage_max 0.4994 (0.4745) teacher/usage_min 0.0627 (0.1731) teacher/usage_std 0.1930 (0.1285) nleep/row_max_mean 1528.0498 (1535.1164) nleep/row_max_std 63.6991 (56.2801) nleep/row_min_mean 1499.1259 (1503.8192) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [140/173] time 0.175 (0.116) data 0.000 (0.003) loss 1.6944 (1.6969) teacher_loss 0.0750 (0.1173) loss_zs_kd 0.0373 (0.0479) loss_oracle 0.6733 (0.6569) kd_loss 1.2641 (1.2271) acc 96.8750 (95.8482) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0269 (0.0314) teacher/usage_max 0.4439 (0.4707) teacher/usage_min 0.1251 (0.1742) teacher/usage_std 0.1474 (0.1265) nleep/row_max_mean 1524.1871 (1534.7862) nleep/row_max_std 65.1700 (56.9383) nleep/row_min_mean 1495.5732 (1503.4754) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [160/173] time 0.155 (0.120) data 0.000 (0.002) loss 1.9773 (1.6995) teacher_loss 0.2754 (0.1181) loss_zs_kd 0.0659 (0.0480) loss_oracle 0.7469 (0.6572) kd_loss 1.2956 (1.2288) acc 87.5000 (95.7812) gate/entropy 1.0249 (1.0247) gate/usage_max 0.4196 (0.4197) gate/usage_min 0.1631 (0.1629) gate/usage_std 0.1203 (0.1205) teacher/entropy 0.0233 (0.0310) teacher/usage_max 0.4744 (0.4711) teacher/usage_min 0.0625 (0.1755) teacher/usage_std 0.1916 (0.1264) nleep/row_max_mean 1516.8036 (1535.2223) nleep/row_max_std 59.7042 (56.7954) nleep/row_min_mean 1486.5671 (1503.8141) lr 7.0224e-05 eta 0:01:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,304
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [47/50] batch [20/173] time 0.150 (0.170) data 0.000 (0.017) loss 1.6423 (1.7256) teacher_loss 0.0657 (0.1292) loss_zs_kd 0.0413 (0.0487) loss_oracle 0.6342 (0.6683) kd_loss 1.2389 (1.2379) acc 100.0000 (95.7812) gate/entropy 1.0243 (1.0247) gate/usage_max 0.4197 (0.4196) gate/usage_min 0.1625 (0.1629) gate/usage_std 0.1208 (0.1205) teacher/entropy 0.0395 (0.0357) teacher/usage_max 0.4310 (0.4985) teacher/usage_min 0.2705 (0.1500) teacher/usage_std 0.0700 (0.1497) nleep/row_max_mean 1555.8143 (1533.6926) nleep/row_max_std 53.2077 (54.2945) nleep/row_min_mean 1521.3333 (1502.8755) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [40/173] time 0.149 (0.157) data 0.000 (0.008) loss 1.6765 (1.7134) teacher_loss 0.1660 (0.1274) loss_zs_kd 0.0468 (0.0497) loss_oracle 0.5803 (0.6464) kd_loss 1.1969 (1.2379) acc 96.8750 (95.9375) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4196 (0.4196) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0317 (0.0357) teacher/usage_max 0.4337 (0.4896) teacher/usage_min 0.1875 (0.1629) teacher/usage_std 0.1055 (0.1400) nleep/row_max_mean 1537.3303 (1535.0481) nleep/row_max_std 55.5123 (54.2376) nleep/row_min_mean 1506.5857 (1504.0550) lr 4.8943e-05 eta 0:01:42
epoch [47/50] batch [60/173] time 0.148 (0.155) data 0.001 (0.006) loss 1.7105 (1.6959) teacher_loss 0.0992 (0.1178) loss_zs_kd 0.0490 (0.0480) loss_oracle 0.6707 (0.6510) kd_loss 1.2515 (1.2286) acc 93.7500 (96.0938) gate/entropy 1.0249 (1.0247) gate/usage_max 0.4195 (0.4196) gate/usage_min 0.1632 (0.1629) gate/usage_std 0.1203 (0.1205) teacher/entropy 0.0033 (0.0357) teacher/usage_max 0.5311 (0.4917) teacher/usage_min 0.0625 (0.1639) teacher/usage_std 0.1982 (0.1401) nleep/row_max_mean 1533.7925 (1536.7422) nleep/row_max_std 46.3492 (53.8994) nleep/row_min_mean 1504.3472 (1505.5811) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [80/173] time 0.085 (0.147) data 0.000 (0.004) loss 1.5984 (1.6906) teacher_loss 0.1012 (0.1211) loss_zs_kd 0.0465 (0.0481) loss_oracle 0.6317 (0.6508) kd_loss 1.1581 (1.2200) acc 96.8750 (95.8594) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4196 (0.4196) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0248 (0.0357) teacher/usage_max 0.5450 (0.4859) teacher/usage_min 0.1250 (0.1689) teacher/usage_std 0.1715 (0.1354) nleep/row_max_mean 1539.0044 (1538.0194) nleep/row_max_std 57.9534 (54.1104) nleep/row_min_mean 1505.5444 (1506.6632) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [100/173] time 0.082 (0.139) data 0.000 (0.003) loss 1.5457 (1.6878) teacher_loss 0.1430 (0.1201) loss_zs_kd 0.0639 (0.0484) loss_oracle 0.6221 (0.6535) kd_loss 1.0597 (1.2167) acc 93.7500 (95.7500) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4196 (0.4196) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0280 (0.0339) teacher/usage_max 0.5515 (0.4821) teacher/usage_min 0.2188 (0.1697) teacher/usage_std 0.1544 (0.1337) nleep/row_max_mean 1553.0563 (1538.1319) nleep/row_max_std 54.8803 (54.6383) nleep/row_min_mean 1519.0864 (1506.6764) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [120/173] time 0.097 (0.134) data 0.000 (0.003) loss 1.5815 (1.6859) teacher_loss 0.0645 (0.1171) loss_zs_kd 0.0346 (0.0486) loss_oracle 0.6514 (0.6553) kd_loss 1.1740 (1.2168) acc 96.8750 (95.8594) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4195 (0.4196) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0314 (0.0322) teacher/usage_max 0.3641 (0.4743) teacher/usage_min 0.2813 (0.1744) teacher/usage_std 0.0370 (0.1283) nleep/row_max_mean 1548.4288 (1538.3387) nleep/row_max_std 55.5793 (54.2896) nleep/row_min_mean 1513.8241 (1506.6120) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [140/173] time 0.093 (0.132) data 0.000 (0.003) loss 1.6591 (1.6878) teacher_loss 0.0584 (0.1198) loss_zs_kd 0.0308 (0.0499) loss_oracle 0.6466 (0.6563) kd_loss 1.2619 (1.2149) acc 96.8750 (95.7589) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4196 (0.4196) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1207 (0.1205) teacher/entropy 0.0174 (0.0319) teacher/usage_max 0.4332 (0.4741) teacher/usage_min 0.1569 (0.1747) teacher/usage_std 0.1251 (0.1278) nleep/row_max_mean 1545.3231 (1538.3917) nleep/row_max_std 55.3860 (54.1265) nleep/row_min_mean 1513.4004 (1506.6040) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [160/173] time 0.082 (0.129) data 0.000 (0.002) loss 1.6468 (1.6914) teacher_loss 0.1239 (0.1196) loss_zs_kd 0.0567 (0.0497) loss_oracle 0.6306 (0.6571) kd_loss 1.1792 (1.2184) acc 93.7500 (95.7617) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4196 (0.4196) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0397 (0.0322) teacher/usage_max 0.5385 (0.4753) teacher/usage_min 0.0938 (0.1752) teacher/usage_std 0.1832 (0.1280) nleep/row_max_mean 1540.6304 (1538.4077) nleep/row_max_std 56.0155 (53.8346) nleep/row_min_mean 1510.0304 (1506.6791) lr 4.8943e-05 eta 0:01:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,304
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [48/50] batch [20/173] time 0.080 (0.134) data 0.000 (0.017) loss 1.7059 (1.7301) teacher_loss 0.1008 (0.1489) loss_zs_kd 0.0421 (0.0488) loss_oracle 0.6428 (0.6532) kd_loss 1.2626 (1.2302) acc 100.0000 (95.1562) gate/entropy 1.0250 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1633 (0.1630) gate/usage_std 0.1203 (0.1205) teacher/entropy 0.0428 (0.0313) teacher/usage_max 0.4596 (0.4764) teacher/usage_min 0.0956 (0.1648) teacher/usage_std 0.1682 (0.1341) nleep/row_max_mean 1518.7773 (1531.7539) nleep/row_max_std 56.7911 (54.7888) nleep/row_min_mean 1493.6393 (1501.3050) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [40/173] time 0.159 (0.132) data 0.000 (0.009) loss 1.6038 (1.6967) teacher_loss 0.0516 (0.1267) loss_zs_kd 0.0415 (0.0504) loss_oracle 0.6470 (0.6636) kd_loss 1.2080 (1.2130) acc 100.0000 (95.7812) gate/entropy 1.0249 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1632 (0.1630) gate/usage_std 0.1203 (0.1205) teacher/entropy 0.0191 (0.0308) teacher/usage_max 0.3783 (0.4674) teacher/usage_min 0.2800 (0.1762) teacher/usage_std 0.0406 (0.1251) nleep/row_max_mean 1524.5996 (1533.2569) nleep/row_max_std 56.6983 (53.1540) nleep/row_min_mean 1492.4543 (1502.2695) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [60/173] time 0.170 (0.141) data 0.001 (0.006) loss 1.6163 (1.6927) teacher_loss 0.1521 (0.1216) loss_zs_kd 0.0924 (0.0496) loss_oracle 0.5682 (0.6596) kd_loss 1.1339 (1.2166) acc 96.8750 (95.9896) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4196 (0.4195) gate/usage_min 0.1628 (0.1630) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0024 (0.0301) teacher/usage_max 0.4062 (0.4664) teacher/usage_min 0.2809 (0.1763) teacher/usage_std 0.0532 (0.1249) nleep/row_max_mean 1537.6593 (1534.1684) nleep/row_max_std 55.5296 (52.2125) nleep/row_min_mean 1503.8469 (1503.1615) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [80/173] time 0.164 (0.145) data 0.000 (0.004) loss 1.8616 (1.6919) teacher_loss 0.2238 (0.1289) loss_zs_kd 0.0712 (0.0504) loss_oracle 0.6549 (0.6607) kd_loss 1.2747 (1.2074) acc 90.6250 (95.7031) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0545 (0.0324) teacher/usage_max 0.4855 (0.4719) teacher/usage_min 0.1875 (0.1729) teacher/usage_std 0.1217 (0.1285) nleep/row_max_mean 1546.6370 (1534.7623) nleep/row_max_std 40.2480 (51.7925) nleep/row_min_mean 1515.6333 (1503.7902) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [100/173] time 0.150 (0.147) data 0.000 (0.004) loss 1.5571 (1.6906) teacher_loss 0.0397 (0.1263) loss_zs_kd 0.0517 (0.0507) loss_oracle 0.6789 (0.6582) kd_loss 1.1520 (1.2099) acc 100.0000 (95.8125) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0337 (0.0319) teacher/usage_max 0.4470 (0.4673) teacher/usage_min 0.2196 (0.1782) teacher/usage_std 0.0928 (0.1240) nleep/row_max_mean 1541.7786 (1535.4143) nleep/row_max_std 51.3207 (52.0952) nleep/row_min_mean 1510.1343 (1504.3917) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [120/173] time 0.146 (0.147) data 0.000 (0.003) loss 1.7390 (1.6945) teacher_loss 0.1230 (0.1288) loss_zs_kd 0.0309 (0.0502) loss_oracle 0.6287 (0.6591) kd_loss 1.2862 (1.2111) acc 96.8750 (95.7552) gate/entropy 1.0248 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1630 (0.1629) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0390 (0.0300) teacher/usage_max 0.4814 (0.4712) teacher/usage_min 0.2120 (0.1781) teacher/usage_std 0.1116 (0.1251) nleep/row_max_mean 1535.3486 (1535.8899) nleep/row_max_std 52.0268 (51.8096) nleep/row_min_mean 1506.0708 (1504.8128) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [140/173] time 0.155 (0.147) data 0.000 (0.003) loss 1.7362 (1.6976) teacher_loss 0.1273 (0.1289) loss_zs_kd 0.0557 (0.0492) loss_oracle 0.6659 (0.6599) kd_loss 1.2482 (1.2142) acc 93.7500 (95.6920) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0273 (0.0301) teacher/usage_max 0.4286 (0.4759) teacher/usage_min 0.2189 (0.1743) teacher/usage_std 0.0867 (0.1284) nleep/row_max_mean 1544.5529 (1535.9106) nleep/row_max_std 53.2757 (51.5242) nleep/row_min_mean 1512.3601 (1504.8663) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [160/173] time 0.137 (0.148) data 0.000 (0.002) loss 1.7574 (1.6943) teacher_loss 0.1558 (0.1289) loss_zs_kd 0.0699 (0.0491) loss_oracle 0.6522 (0.6605) kd_loss 1.2406 (1.2105) acc 93.7500 (95.7227) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0333 (0.0302) teacher/usage_max 0.4262 (0.4748) teacher/usage_min 0.1875 (0.1765) teacher/usage_std 0.1044 (0.1269) nleep/row_max_mean 1553.4740 (1536.4744) nleep/row_max_std 43.4523 (51.4900) nleep/row_min_mean 1518.9954 (1505.2723) lr 3.1417e-05 eta 0:00:52
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,306
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [49/50] batch [20/173] time 0.200 (0.128) data 0.000 (0.015) loss 1.6735 (1.6474) teacher_loss 0.1285 (0.1085) loss_zs_kd 0.0299 (0.0484) loss_oracle 0.6346 (0.6625) kd_loss 1.2127 (1.1835) acc 96.8750 (95.6250) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0100 (0.0262) teacher/usage_max 0.4402 (0.4732) teacher/usage_min 0.1876 (0.1695) teacher/usage_std 0.1067 (0.1284) nleep/row_max_mean 1545.5145 (1540.9132) nleep/row_max_std 42.5879 (49.2001) nleep/row_min_mean 1512.6420 (1508.7258) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [40/173] time 0.173 (0.125) data 0.000 (0.008) loss 1.6067 (1.6609) teacher_loss 0.1168 (0.1060) loss_zs_kd 0.0514 (0.0482) loss_oracle 0.6435 (0.6613) kd_loss 1.1424 (1.2002) acc 93.7500 (96.1719) gate/entropy 1.0248 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1630 (0.1629) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0421 (0.0284) teacher/usage_max 0.5753 (0.4672) teacher/usage_min 0.0938 (0.1759) teacher/usage_std 0.1966 (0.1236) nleep/row_max_mean 1534.2288 (1538.0381) nleep/row_max_std 54.8243 (50.7987) nleep/row_min_mean 1504.5522 (1506.2735) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [60/173] time 0.066 (0.122) data 0.001 (0.005) loss 1.6135 (1.6765) teacher_loss 0.0877 (0.1048) loss_zs_kd 0.0728 (0.0481) loss_oracle 0.6911 (0.6654) kd_loss 1.1439 (1.2150) acc 93.7500 (96.1458) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0174 (0.0295) teacher/usage_max 0.4101 (0.4818) teacher/usage_min 0.2820 (0.1666) teacher/usage_std 0.0553 (0.1333) nleep/row_max_mean 1547.0979 (1537.1894) nleep/row_max_std 58.2897 (50.8746) nleep/row_min_mean 1511.7123 (1505.7076) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [80/173] time 0.060 (0.114) data 0.000 (0.004) loss 1.8298 (1.6888) teacher_loss 0.1964 (0.1144) loss_zs_kd 0.0747 (0.0488) loss_oracle 0.6589 (0.6641) kd_loss 1.2666 (1.2178) acc 93.7500 (95.9375) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0361 (0.0302) teacher/usage_max 0.4567 (0.4769) teacher/usage_min 0.1563 (0.1699) teacher/usage_std 0.1284 (0.1302) nleep/row_max_mean 1532.1987 (1537.0389) nleep/row_max_std 42.7343 (50.5847) nleep/row_min_mean 1501.0205 (1505.4622) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [100/173] time 0.079 (0.114) data 0.000 (0.003) loss 1.6426 (1.6848) teacher_loss 0.0934 (0.1143) loss_zs_kd 0.0751 (0.0489) loss_oracle 0.6510 (0.6607) kd_loss 1.1861 (1.2157) acc 100.0000 (96.0312) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0252 (0.0306) teacher/usage_max 0.5452 (0.4761) teacher/usage_min 0.0938 (0.1730) teacher/usage_std 0.1853 (0.1290) nleep/row_max_mean 1546.1183 (1536.5292) nleep/row_max_std 39.2770 (50.9417) nleep/row_min_mean 1514.2377 (1505.0740) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [120/173] time 0.159 (0.114) data 0.000 (0.003) loss 1.7775 (1.6882) teacher_loss 0.1514 (0.1173) loss_zs_kd 0.0578 (0.0493) loss_oracle 0.7037 (0.6622) kd_loss 1.2454 (1.2152) acc 96.8750 (96.0677) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0120 (0.0313) teacher/usage_max 0.4097 (0.4730) teacher/usage_min 0.1875 (0.1737) teacher/usage_std 0.1032 (0.1277) nleep/row_max_mean 1536.2185 (1536.3933) nleep/row_max_std 49.9631 (51.3545) nleep/row_min_mean 1503.5322 (1504.9754) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [140/173] time 0.079 (0.113) data 0.000 (0.002) loss 1.8750 (1.6944) teacher_loss 0.1555 (0.1212) loss_zs_kd 0.0856 (0.0494) loss_oracle 0.6912 (0.6611) kd_loss 1.3311 (1.2178) acc 96.8750 (95.9152) gate/entropy 1.0248 (1.0247) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1631 (0.1629) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0162 (0.0311) teacher/usage_max 0.5066 (0.4730) teacher/usage_min 0.1250 (0.1733) teacher/usage_std 0.1577 (0.1277) nleep/row_max_mean 1528.7140 (1535.9658) nleep/row_max_std 49.6906 (51.5776) nleep/row_min_mean 1496.5073 (1504.6504) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [160/173] time 0.163 (0.115) data 0.000 (0.002) loss 1.7026 (1.6904) teacher_loss 0.0873 (0.1205) loss_zs_kd 0.0703 (0.0489) loss_oracle 0.6177 (0.6608) kd_loss 1.2713 (1.2150) acc 96.8750 (95.9180) gate/entropy 1.0247 (1.0247) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1629 (0.1629) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0102 (0.0312) teacher/usage_max 0.4353 (0.4738) teacher/usage_min 0.1875 (0.1730) teacher/usage_std 0.1058 (0.1282) nleep/row_max_mean 1537.1086 (1535.7772) nleep/row_max_std 49.0861 (51.5340) nleep/row_min_mean 1506.7240 (1504.5189) lr 1.7713e-05 eta 0:00:21
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,306
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
epoch [50/50] batch [20/173] time 0.167 (0.172) data 0.000 (0.016) loss 1.7997 (1.6853) teacher_loss 0.0715 (0.1314) loss_zs_kd 0.0267 (0.0515) loss_oracle 0.5522 (0.6498) kd_loss 1.4388 (1.2033) acc 100.0000 (95.7812) gate/entropy 1.0249 (1.0248) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1631 (0.1630) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0355 (0.0320) teacher/usage_max 0.6413 (0.4818) teacher/usage_min 0.1253 (0.1701) teacher/usage_std 0.2222 (0.1334) nleep/row_max_mean 1515.8220 (1529.6350) nleep/row_max_std 41.2318 (50.8455) nleep/row_min_mean 1488.4172 (1499.2787) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [40/173] time 0.150 (0.167) data 0.000 (0.008) loss 1.7483 (1.6937) teacher_loss 0.0957 (0.1234) loss_zs_kd 0.0537 (0.0505) loss_oracle 0.6373 (0.6598) kd_loss 1.3072 (1.2151) acc 93.7500 (95.6250) gate/entropy 1.0249 (1.0248) gate/usage_max 0.4194 (0.4194) gate/usage_min 0.1631 (0.1630) gate/usage_std 0.1204 (0.1204) teacher/entropy 0.0282 (0.0309) teacher/usage_max 0.4937 (0.4808) teacher/usage_min 0.2188 (0.1672) teacher/usage_std 0.1168 (0.1345) nleep/row_max_mean 1523.8625 (1529.5825) nleep/row_max_std 44.3138 (49.6708) nleep/row_min_mean 1494.8607 (1499.2965) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [60/173] time 0.151 (0.163) data 0.001 (0.005) loss 1.6514 (1.6790) teacher_loss 0.0796 (0.1159) loss_zs_kd 0.0334 (0.0489) loss_oracle 0.6856 (0.6567) kd_loss 1.2123 (1.2103) acc 96.8750 (96.0938) gate/entropy 1.0247 (1.0248) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1629 (0.1630) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0176 (0.0332) teacher/usage_max 0.4994 (0.4789) teacher/usage_min 0.1196 (0.1712) teacher/usage_std 0.1587 (0.1320) nleep/row_max_mean 1532.1975 (1529.6141) nleep/row_max_std 49.1552 (49.8868) nleep/row_min_mean 1504.9048 (1499.2725) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/173] time 0.160 (0.162) data 0.000 (0.004) loss 1.9146 (1.6864) teacher_loss 0.2469 (0.1225) loss_zs_kd 0.0366 (0.0492) loss_oracle 0.6303 (0.6560) kd_loss 1.3342 (1.2114) acc 87.5000 (95.9766) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1630) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0101 (0.0333) teacher/usage_max 0.5016 (0.4761) teacher/usage_min 0.0625 (0.1707) teacher/usage_std 0.1934 (0.1311) nleep/row_max_mean 1532.0754 (1530.0145) nleep/row_max_std 43.2612 (50.3071) nleep/row_min_mean 1502.3473 (1499.5929) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [100/173] time 0.079 (0.155) data 0.000 (0.003) loss 1.6013 (1.6838) teacher_loss 0.0919 (0.1182) loss_zs_kd 0.0636 (0.0498) loss_oracle 0.7046 (0.6584) kd_loss 1.1254 (1.2115) acc 96.8750 (96.1562) gate/entropy 1.0248 (1.0247) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1630 (0.1630) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0230 (0.0340) teacher/usage_max 0.5184 (0.4740) teacher/usage_min 0.1875 (0.1750) teacher/usage_std 0.1379 (0.1282) nleep/row_max_mean 1527.3882 (1530.2557) nleep/row_max_std 57.2593 (50.7366) nleep/row_min_mean 1491.2922 (1499.6844) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [120/173] time 0.185 (0.146) data 0.000 (0.003) loss 1.5804 (1.6847) teacher_loss 0.0366 (0.1161) loss_zs_kd 0.0318 (0.0490) loss_oracle 0.5763 (0.6615) kd_loss 1.2397 (1.2133) acc 100.0000 (96.1719) gate/entropy 1.0249 (1.0247) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1631 (0.1630) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0550 (0.0323) teacher/usage_max 0.4485 (0.4755) teacher/usage_min 0.1984 (0.1745) teacher/usage_std 0.1030 (0.1290) nleep/row_max_mean 1511.8474 (1529.6405) nleep/row_max_std 54.4251 (51.5001) nleep/row_min_mean 1485.4583 (1499.0698) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [140/173] time 0.183 (0.141) data 0.000 (0.002) loss 1.7659 (1.6837) teacher_loss 0.2062 (0.1178) loss_zs_kd 0.0661 (0.0498) loss_oracle 0.6689 (0.6600) kd_loss 1.1922 (1.2110) acc 96.8750 (96.1607) gate/entropy 1.0246 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1630) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0235 (0.0332) teacher/usage_max 0.4072 (0.4736) teacher/usage_min 0.2265 (0.1756) teacher/usage_std 0.0773 (0.1276) nleep/row_max_mean 1535.9948 (1530.1212) nleep/row_max_std 58.6606 (51.7071) nleep/row_min_mean 1504.3430 (1499.4482) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [160/173] time 0.078 (0.138) data 0.000 (0.002) loss 1.7686 (1.6835) teacher_loss 0.2527 (0.1192) loss_zs_kd 0.0504 (0.0500) loss_oracle 0.6289 (0.6598) kd_loss 1.1762 (1.2093) acc 93.7500 (96.1719) gate/entropy 1.0245 (1.0247) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1628 (0.1630) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0629 (0.0339) teacher/usage_max 0.4226 (0.4728) teacher/usage_min 0.1875 (0.1753) teacher/usage_std 0.1040 (0.1274) nleep/row_max_mean 1541.3425 (1529.9105) nleep/row_max_std 48.2570 (51.9809) nleep/row_min_mean 1508.6782 (1499.2564) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,307
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      97.1%, epoch: 19 *******
******* Domain a best val test acc: 98.2%, epoch: 19 *******
******* Domain a best test acc:     98.2%, epoch: 19 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:33

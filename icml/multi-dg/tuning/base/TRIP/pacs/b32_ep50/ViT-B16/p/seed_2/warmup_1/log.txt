Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'sketch']
Target     ['photo']
# classes  7
# train_x  5,823
# val      2,497
# test     1,670
---------  -------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/181] time 0.097 (0.135) data 0.000 (0.017) loss 1.0152 (1.1388) teacher_loss 0.5551 (0.5796) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0001 (-0.0000) kd_loss 0.4601 (0.5592) acc 78.1250 (79.6875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.6416 (0.5420) teacher/usage_max 0.4585 (0.4567) teacher/usage_min 0.2128 (0.2271) teacher/usage_std 0.1004 (0.0975) nleep/row_max_mean 1544.1130 (1561.3926) nleep/row_max_std 156.6948 (140.3885) nleep/row_min_mean 1540.7014 (1556.4811) lr 1.0000e-05 eta 0:20:18
epoch [1/50] batch [40/181] time 0.182 (0.125) data 0.000 (0.009) loss 0.9020 (1.0168) teacher_loss 0.4926 (0.5235) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0014 (0.0003) kd_loss 0.4087 (0.4932) acc 81.2500 (81.6406) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.6924 (0.6081) teacher/usage_max 0.4816 (0.4577) teacher/usage_min 0.2577 (0.2296) teacher/usage_std 0.1049 (0.0975) nleep/row_max_mean 1581.9214 (1559.8115) nleep/row_max_std 97.6116 (135.3374) nleep/row_min_mean 1579.0348 (1555.8224) lr 1.0000e-05 eta 0:18:44
epoch [1/50] batch [60/181] time 0.076 (0.125) data 0.001 (0.006) loss 0.9686 (0.9749) teacher_loss 0.6955 (0.5105) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0031 (0.0008) kd_loss 0.2714 (0.4640) acc 71.8750 (81.9792) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8278 (0.6371) teacher/usage_max 0.3482 (0.4508) teacher/usage_min 0.3197 (0.2356) teacher/usage_std 0.0117 (0.0922) nleep/row_max_mean 1522.9371 (1562.1908) nleep/row_max_std 142.3491 (131.0475) nleep/row_min_mean 1521.0477 (1558.6104) lr 1.0000e-05 eta 0:18:39
epoch [1/50] batch [80/181] time 0.106 (0.123) data 0.000 (0.005) loss 0.7873 (0.9413) teacher_loss 0.4347 (0.5071) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0049 (0.0016) kd_loss 0.3498 (0.4333) acc 90.6250 (82.4219) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7503 (0.6675) teacher/usage_max 0.4002 (0.4369) teacher/usage_min 0.2842 (0.2475) teacher/usage_std 0.0490 (0.0811) nleep/row_max_mean 1563.1230 (1565.9653) nleep/row_max_std 131.0801 (124.1912) nleep/row_min_mean 1560.7310 (1562.6948) lr 1.0000e-05 eta 0:18:25
epoch [1/50] batch [100/181] time 0.162 (0.126) data 0.000 (0.004) loss 0.8381 (0.9186) teacher_loss 0.4254 (0.5082) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0100 (0.0030) kd_loss 0.4073 (0.4088) acc 84.3750 (82.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.6895 (0.6916) teacher/usage_max 0.4195 (0.4247) teacher/usage_min 0.1924 (0.2562) teacher/usage_std 0.1005 (0.0722) nleep/row_max_mean 1606.7517 (1568.6300) nleep/row_max_std 74.7055 (118.8144) nleep/row_min_mean 1604.1462 (1565.5939) lr 1.0000e-05 eta 0:18:45
epoch [1/50] batch [120/181] time 0.148 (0.129) data 0.000 (0.003) loss 0.9401 (0.8998) teacher_loss 0.6299 (0.5070) loss_zs_kd 0.0013 (0.0004) loss_oracle 0.0113 (0.0050) kd_loss 0.3039 (0.3901) acc 78.1250 (82.0573) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.7916 (0.7099) teacher/usage_max 0.4329 (0.4204) teacher/usage_min 0.1752 (0.2556) teacher/usage_std 0.1131 (0.0707) nleep/row_max_mean 1594.8871 (1570.8181) nleep/row_max_std 84.9615 (114.4784) nleep/row_min_mean 1592.5756 (1567.9406) lr 1.0000e-05 eta 0:19:16
epoch [1/50] batch [140/181] time 0.145 (0.131) data 0.000 (0.003) loss 0.8209 (0.8771) teacher_loss 0.5083 (0.5005) loss_zs_kd 0.0012 (0.0006) loss_oracle 0.0135 (0.0069) kd_loss 0.3052 (0.3729) acc 84.3750 (82.5670) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7906 (0.7266) teacher/usage_max 0.4324 (0.4207) teacher/usage_min 0.1890 (0.2500) teacher/usage_std 0.1044 (0.0731) nleep/row_max_mean 1584.2178 (1571.7536) nleep/row_max_std 106.8432 (111.8106) nleep/row_min_mean 1581.7241 (1568.9774) lr 1.0000e-05 eta 0:19:23
epoch [1/50] batch [160/181] time 0.139 (0.131) data 0.000 (0.002) loss 0.5563 (0.8529) teacher_loss 0.3123 (0.4917) loss_zs_kd 0.0017 (0.0007) loss_oracle 0.0215 (0.0087) kd_loss 0.2324 (0.3564) acc 90.6250 (82.8906) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.8648 (0.7427) teacher/usage_max 0.3845 (0.4197) teacher/usage_min 0.2443 (0.2444) teacher/usage_std 0.0632 (0.0755) nleep/row_max_mean 1617.5658 (1573.1161) nleep/row_max_std 66.3489 (108.2710) nleep/row_min_mean 1615.2463 (1570.3958) lr 1.0000e-05 eta 0:19:27
epoch [1/50] batch [180/181] time 0.126 (0.131) data 0.000 (0.002) loss 0.6016 (0.8404) teacher_loss 0.3502 (0.4900) loss_zs_kd 0.0007 (0.0009) loss_oracle 0.0211 (0.0109) kd_loss 0.2405 (0.3446) acc 90.6250 (82.8993) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.8545 (0.7541) teacher/usage_max 0.4672 (0.4242) teacher/usage_min 0.1772 (0.2360) teacher/usage_std 0.1195 (0.0808) nleep/row_max_mean 1569.1818 (1573.3174) nleep/row_max_std 92.2394 (105.7357) nleep/row_min_mean 1566.5475 (1570.5926) lr 1.0000e-05 eta 0:19:25
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,367
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      94.8%, epoch: 1 *******
******* Domain p best val test acc: 99.9%, epoch: 1 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [2/50] batch [20/181] time 0.119 (0.154) data 0.000 (0.013) loss 1.1860 (0.8712) teacher_loss 0.6889 (0.4304) loss_zs_kd 0.0100 (0.0080) loss_oracle 0.2612 (0.2522) kd_loss 0.3615 (0.3108) acc 75.0000 (85.7812) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3393 (0.3388) gate/usage_min 0.3282 (0.3290) gate/usage_std 0.0046 (0.0041) teacher/entropy 0.7295 (0.7821) teacher/usage_max 0.5464 (0.5162) teacher/usage_min 0.0756 (0.1212) teacher/usage_std 0.1948 (0.1635) nleep/row_max_mean 1571.4774 (1581.2196) nleep/row_max_std 81.3896 (82.7960) nleep/row_min_mean 1566.1327 (1577.0860) lr 2.0000e-03 eta 0:22:44
epoch [2/50] batch [40/181] time 0.074 (0.127) data 0.000 (0.007) loss 1.3156 (1.1111) teacher_loss 0.3837 (0.5039) loss_zs_kd 0.0111 (0.0093) loss_oracle 0.3457 (0.2961) kd_loss 0.7535 (0.4545) acc 81.2500 (83.4375) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3398 (0.3393) gate/usage_min 0.3253 (0.3278) gate/usage_std 0.0060 (0.0047) teacher/entropy 0.3390 (0.6385) teacher/usage_max 0.8206 (0.6049) teacher/usage_min 0.0237 (0.0756) teacher/usage_std 0.3487 (0.2227) nleep/row_max_mean 1586.7961 (1583.4972) nleep/row_max_std 82.2261 (80.1337) nleep/row_min_mean 1576.7559 (1577.1901) lr 2.0000e-03 eta 0:18:42
epoch [2/50] batch [60/181] time 0.089 (0.118) data 0.000 (0.004) loss 1.5095 (1.1979) teacher_loss 0.5365 (0.4853) loss_zs_kd 0.0087 (0.0079) loss_oracle 0.3036 (0.2934) kd_loss 0.8169 (0.5619) acc 75.0000 (83.6458) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3395 (0.3392) gate/usage_min 0.3223 (0.3265) gate/usage_std 0.0078 (0.0054) teacher/entropy 0.2645 (0.5289) teacher/usage_max 0.8455 (0.6753) teacher/usage_min 0.0098 (0.0560) teacher/usage_std 0.3663 (0.2644) nleep/row_max_mean 1580.2773 (1583.1876) nleep/row_max_std 85.0143 (79.8611) nleep/row_min_mean 1571.4827 (1575.6280) lr 2.0000e-03 eta 0:17:23
epoch [2/50] batch [80/181] time 0.138 (0.117) data 0.000 (0.003) loss 1.4852 (1.2809) teacher_loss 0.3790 (0.4762) loss_zs_kd 0.0043 (0.0073) loss_oracle 0.4005 (0.3136) kd_loss 0.9037 (0.6442) acc 93.7500 (83.8672) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3454 (0.3401) gate/usage_min 0.3189 (0.3250) gate/usage_std 0.0109 (0.0064) teacher/entropy 0.1625 (0.4425) teacher/usage_max 0.9029 (0.7267) teacher/usage_min 0.0065 (0.0467) teacher/usage_std 0.4042 (0.2955) nleep/row_max_mean 1609.4138 (1584.2670) nleep/row_max_std 56.3622 (78.5188) nleep/row_min_mean 1596.5033 (1575.5143) lr 2.0000e-03 eta 0:17:04
epoch [2/50] batch [100/181] time 0.084 (0.117) data 0.000 (0.003) loss 1.4902 (1.3408) teacher_loss 0.3976 (0.4744) loss_zs_kd 0.0057 (0.0074) loss_oracle 0.3263 (0.3311) kd_loss 0.9265 (0.6972) acc 87.5000 (83.6875) gate/entropy 1.0976 (1.0983) gate/usage_max 0.3516 (0.3418) gate/usage_min 0.3157 (0.3235) gate/usage_std 0.0146 (0.0077) teacher/entropy 0.1243 (0.3844) teacher/usage_max 0.9270 (0.7564) teacher/usage_min 0.0297 (0.0437) teacher/usage_std 0.4198 (0.3133) nleep/row_max_mean 1580.6425 (1585.3074) nleep/row_max_std 83.0229 (77.0879) nleep/row_min_mean 1566.6033 (1575.5655) lr 2.0000e-03 eta 0:17:03
epoch [2/50] batch [120/181] time 0.075 (0.117) data 0.000 (0.002) loss 1.6152 (1.3723) teacher_loss 0.5468 (0.4706) loss_zs_kd 0.0075 (0.0072) loss_oracle 0.4233 (0.3381) kd_loss 0.8530 (0.7290) acc 81.2500 (83.8021) gate/entropy 1.0971 (1.0981) gate/usage_max 0.3578 (0.3439) gate/usage_min 0.3128 (0.3219) gate/usage_std 0.0186 (0.0092) teacher/entropy 0.1996 (0.3470) teacher/usage_max 0.8077 (0.7763) teacher/usage_min 0.0169 (0.0425) teacher/usage_std 0.3416 (0.3252) nleep/row_max_mean 1581.5083 (1584.9312) nleep/row_max_std 70.0808 (75.9650) nleep/row_min_mean 1567.9626 (1574.5693) lr 2.0000e-03 eta 0:17:01
epoch [2/50] batch [140/181] time 0.170 (0.118) data 0.000 (0.002) loss 1.3534 (1.3764) teacher_loss 0.3541 (0.4553) loss_zs_kd 0.0092 (0.0072) loss_oracle 0.3404 (0.3420) kd_loss 0.8245 (0.7464) acc 87.5000 (84.3080) gate/entropy 1.0964 (1.0979) gate/usage_max 0.3639 (0.3464) gate/usage_min 0.3105 (0.3204) gate/usage_std 0.0225 (0.0108) teacher/entropy 0.2116 (0.3253) teacher/usage_max 0.8276 (0.7792) teacher/usage_min 0.0439 (0.0441) teacher/usage_std 0.3512 (0.3260) nleep/row_max_mean 1594.6251 (1585.2262) nleep/row_max_std 71.4408 (74.9760) nleep/row_min_mean 1583.0688 (1574.5343) lr 2.0000e-03 eta 0:17:08
epoch [2/50] batch [160/181] time 0.162 (0.119) data 0.000 (0.002) loss 1.4561 (1.3830) teacher_loss 0.4372 (0.4514) loss_zs_kd 0.0055 (0.0075) loss_oracle 0.3624 (0.3429) kd_loss 0.8349 (0.7563) acc 84.3750 (84.4727) gate/entropy 1.0957 (1.0977) gate/usage_max 0.3690 (0.3489) gate/usage_min 0.3089 (0.3191) gate/usage_std 0.0258 (0.0125) teacher/entropy 0.2175 (0.3126) teacher/usage_max 0.6670 (0.7705) teacher/usage_min 0.0823 (0.0465) teacher/usage_std 0.2458 (0.3198) nleep/row_max_mean 1594.3130 (1584.7360) nleep/row_max_std 65.2002 (73.5815) nleep/row_min_mean 1582.0061 (1573.9408) lr 2.0000e-03 eta 0:17:13
epoch [2/50] batch [180/181] time 0.073 (0.117) data 0.000 (0.002) loss 1.4519 (1.3867) teacher_loss 0.3341 (0.4418) loss_zs_kd 0.0096 (0.0074) loss_oracle 0.3742 (0.3468) kd_loss 0.9258 (0.7679) acc 87.5000 (84.7743) gate/entropy 1.0950 (1.0974) gate/usage_max 0.3734 (0.3514) gate/usage_min 0.3078 (0.3179) gate/usage_std 0.0287 (0.0141) teacher/entropy 0.1064 (0.2993) teacher/usage_max 0.7485 (0.7572) teacher/usage_min 0.0438 (0.0491) teacher/usage_std 0.3011 (0.3111) nleep/row_max_mean 1593.9012 (1584.2171) nleep/row_max_std 50.6770 (72.1648) nleep/row_min_mean 1581.4413 (1573.3269) lr 2.0000e-03 eta 0:16:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [3/50] batch [20/181] time 0.155 (0.157) data 0.000 (0.015) loss 1.2474 (1.3815) teacher_loss 0.2109 (0.3517) loss_zs_kd 0.0082 (0.0086) loss_oracle 0.4013 (0.3660) kd_loss 0.8318 (0.8426) acc 93.7500 (87.3438) gate/entropy 1.0942 (1.0946) gate/usage_max 0.3776 (0.3757) gate/usage_min 0.3067 (0.3072) gate/usage_std 0.0315 (0.0303) teacher/entropy 0.2150 (0.2071) teacher/usage_max 0.6351 (0.6345) teacher/usage_min 0.1040 (0.0847) teacher/usage_std 0.2228 (0.2299) nleep/row_max_mean 1589.3368 (1577.4648) nleep/row_max_std 52.2306 (58.1253) nleep/row_min_mean 1576.7249 (1566.2440) lr 1.9980e-03 eta 0:22:43
epoch [3/50] batch [40/181] time 0.137 (0.154) data 0.000 (0.008) loss 1.5633 (1.4016) teacher_loss 0.4183 (0.3435) loss_zs_kd 0.0079 (0.0102) loss_oracle 0.5201 (0.4103) kd_loss 0.8811 (0.8478) acc 81.2500 (87.8906) gate/entropy 1.0935 (1.0942) gate/usage_max 0.3814 (0.3777) gate/usage_min 0.3063 (0.3068) gate/usage_std 0.0341 (0.0316) teacher/entropy 0.1625 (0.2065) teacher/usage_max 0.6263 (0.6022) teacher/usage_min 0.1002 (0.0856) teacher/usage_std 0.2189 (0.2170) nleep/row_max_mean 1581.5735 (1576.7552) nleep/row_max_std 52.2578 (57.9121) nleep/row_min_mean 1569.0480 (1565.5899) lr 1.9980e-03 eta 0:22:13
epoch [3/50] batch [60/181] time 0.150 (0.152) data 0.000 (0.005) loss 1.4284 (1.4326) teacher_loss 0.3540 (0.3464) loss_zs_kd 0.0076 (0.0107) loss_oracle 0.5271 (0.4523) kd_loss 0.8071 (0.8547) acc 87.5000 (87.7083) gate/entropy 1.0928 (1.0938) gate/usage_max 0.3848 (0.3795) gate/usage_min 0.3058 (0.3066) gate/usage_std 0.0364 (0.0328) teacher/entropy 0.2616 (0.2015) teacher/usage_max 0.4975 (0.5830) teacher/usage_min 0.1017 (0.0891) teacher/usage_std 0.1685 (0.2075) nleep/row_max_mean 1565.3856 (1575.7109) nleep/row_max_std 66.7273 (57.8686) nleep/row_min_mean 1554.5190 (1564.4158) lr 1.9980e-03 eta 0:21:52
epoch [3/50] batch [80/181] time 0.167 (0.154) data 0.000 (0.004) loss 1.5286 (1.4527) teacher_loss 0.3142 (0.3458) loss_zs_kd 0.0162 (0.0104) loss_oracle 0.6093 (0.4800) kd_loss 0.9018 (0.8616) acc 84.3750 (87.6953) gate/entropy 1.0919 (1.0935) gate/usage_max 0.3886 (0.3814) gate/usage_min 0.3049 (0.3063) gate/usage_std 0.0391 (0.0341) teacher/entropy 0.1553 (0.1918) teacher/usage_max 0.5322 (0.5859) teacher/usage_min 0.1769 (0.0838) teacher/usage_std 0.1481 (0.2101) nleep/row_max_mean 1577.0151 (1575.9885) nleep/row_max_std 45.9179 (57.8231) nleep/row_min_mean 1563.7229 (1564.3802) lr 1.9980e-03 eta 0:22:02
epoch [3/50] batch [100/181] time 0.172 (0.155) data 0.000 (0.003) loss 1.9208 (1.4702) teacher_loss 0.6472 (0.3393) loss_zs_kd 0.0134 (0.0106) loss_oracle 0.6880 (0.5094) kd_loss 0.9229 (0.8709) acc 75.0000 (87.7188) gate/entropy 1.0909 (1.0930) gate/usage_max 0.3927 (0.3833) gate/usage_min 0.3036 (0.3058) gate/usage_std 0.0420 (0.0354) teacher/entropy 0.0951 (0.1802) teacher/usage_max 0.6735 (0.5887) teacher/usage_min 0.0192 (0.0780) teacher/usage_std 0.2677 (0.2139) nleep/row_max_mean 1574.4891 (1576.8711) nleep/row_max_std 54.8095 (57.6478) nleep/row_min_mean 1559.9703 (1564.8398) lr 1.9980e-03 eta 0:22:10
epoch [3/50] batch [120/181] time 0.159 (0.155) data 0.000 (0.003) loss 1.5265 (1.4974) teacher_loss 0.1902 (0.3420) loss_zs_kd 0.0048 (0.0115) loss_oracle 0.7767 (0.5489) kd_loss 0.9455 (0.8751) acc 93.7500 (87.5000) gate/entropy 1.0897 (1.0926) gate/usage_max 0.3973 (0.3852) gate/usage_min 0.3002 (0.3052) gate/usage_std 0.0452 (0.0368) teacher/entropy 0.0900 (0.1712) teacher/usage_max 0.5860 (0.5982) teacher/usage_min 0.0652 (0.0729) teacher/usage_std 0.2129 (0.2205) nleep/row_max_mean 1563.6023 (1577.0188) nleep/row_max_std 68.5387 (57.6263) nleep/row_min_mean 1547.6284 (1564.4449) lr 1.9980e-03 eta 0:22:07
epoch [3/50] batch [140/181] time 0.150 (0.152) data 0.000 (0.002) loss 1.7608 (1.5162) teacher_loss 0.4680 (0.3409) loss_zs_kd 0.0215 (0.0128) loss_oracle 0.7095 (0.5791) kd_loss 0.9273 (0.8793) acc 81.2500 (87.5223) gate/entropy 1.0880 (1.0920) gate/usage_max 0.4031 (0.3874) gate/usage_min 0.2963 (0.3042) gate/usage_std 0.0494 (0.0383) teacher/entropy 0.0561 (0.1601) teacher/usage_max 0.7458 (0.6139) teacher/usage_min 0.0525 (0.0676) teacher/usage_std 0.2980 (0.2293) nleep/row_max_mean 1581.8459 (1577.1979) nleep/row_max_std 56.2868 (58.0283) nleep/row_min_mean 1560.9194 (1563.8386) lr 1.9980e-03 eta 0:21:36
epoch [3/50] batch [160/181] time 0.078 (0.147) data 0.000 (0.002) loss 1.4885 (1.5339) teacher_loss 0.2119 (0.3479) loss_zs_kd 0.0162 (0.0132) loss_oracle 0.6784 (0.5931) kd_loss 0.9293 (0.8829) acc 90.6250 (87.1289) gate/entropy 1.0861 (1.0914) gate/usage_max 0.4092 (0.3898) gate/usage_min 0.2923 (0.3029) gate/usage_std 0.0537 (0.0400) teacher/entropy 0.0605 (0.1497) teacher/usage_max 0.6932 (0.6274) teacher/usage_min 0.0122 (0.0634) teacher/usage_std 0.2794 (0.2369) nleep/row_max_mean 1577.9971 (1577.4648) nleep/row_max_std 62.6303 (58.1305) nleep/row_min_mean 1558.9954 (1563.3589) lr 1.9980e-03 eta 0:20:57
epoch [3/50] batch [180/181] time 0.141 (0.143) data 0.000 (0.002) loss 1.5139 (1.5394) teacher_loss 0.2630 (0.3460) loss_zs_kd 0.0195 (0.0136) loss_oracle 0.6330 (0.6041) kd_loss 0.9246 (0.8846) acc 90.6250 (87.1528) gate/entropy 1.0841 (1.0907) gate/usage_max 0.4150 (0.3922) gate/usage_min 0.2886 (0.3015) gate/usage_std 0.0578 (0.0417) teacher/entropy 0.0581 (0.1430) teacher/usage_max 0.6938 (0.6345) teacher/usage_min 0.0159 (0.0618) teacher/usage_std 0.2784 (0.2407) nleep/row_max_mean 1575.5376 (1577.2198) nleep/row_max_std 51.7463 (58.3150) nleep/row_min_mean 1555.4301 (1562.4255) lr 1.9980e-03 eta 0:20:13
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,379
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [4/50] batch [20/181] time 0.067 (0.118) data 0.000 (0.015) loss 1.4259 (1.4961) teacher_loss 0.2565 (0.3214) loss_zs_kd 0.0110 (0.0168) loss_oracle 0.5149 (0.5486) kd_loss 0.9065 (0.8921) acc 84.3750 (87.3438) gate/entropy 1.0822 (1.0830) gate/usage_max 0.4202 (0.4179) gate/usage_min 0.2856 (0.2868) gate/usage_std 0.0615 (0.0599) teacher/entropy 0.0884 (0.0777) teacher/usage_max 0.6422 (0.7224) teacher/usage_min 0.0464 (0.0584) teacher/usage_std 0.2437 (0.2845) nleep/row_max_mean 1572.3945 (1577.7875) nleep/row_max_std 60.9949 (56.0352) nleep/row_min_mean 1551.4775 (1556.9996) lr 1.9921e-03 eta 0:16:41
epoch [4/50] batch [40/181] time 0.154 (0.118) data 0.000 (0.008) loss 1.6713 (1.5190) teacher_loss 0.4325 (0.3459) loss_zs_kd 0.0151 (0.0186) loss_oracle 0.6637 (0.5619) kd_loss 0.8993 (0.8828) acc 81.2500 (86.5625) gate/entropy 1.0804 (1.0821) gate/usage_max 0.4250 (0.4202) gate/usage_min 0.2832 (0.2856) gate/usage_std 0.0649 (0.0616) teacher/entropy 0.0442 (0.0846) teacher/usage_max 0.7672 (0.7225) teacher/usage_min 0.0457 (0.0769) teacher/usage_std 0.3122 (0.2819) nleep/row_max_mean 1592.3887 (1577.3761) nleep/row_max_std 48.5959 (56.3341) nleep/row_min_mean 1569.3264 (1556.5673) lr 1.9921e-03 eta 0:16:39
epoch [4/50] batch [60/181] time 0.084 (0.113) data 0.001 (0.005) loss 1.4644 (1.5096) teacher_loss 0.2847 (0.3353) loss_zs_kd 0.0072 (0.0181) loss_oracle 0.5435 (0.5703) kd_loss 0.9044 (0.8800) acc 87.5000 (87.3438) gate/entropy 1.0785 (1.0812) gate/usage_max 0.4297 (0.4227) gate/usage_min 0.2812 (0.2844) gate/usage_std 0.0682 (0.0633) teacher/entropy 0.0548 (0.0844) teacher/usage_max 0.7195 (0.7234) teacher/usage_min 0.1168 (0.0856) teacher/usage_std 0.2737 (0.2811) nleep/row_max_mean 1584.5239 (1577.6678) nleep/row_max_std 60.8967 (56.4823) nleep/row_min_mean 1559.8123 (1556.3122) lr 1.9921e-03 eta 0:15:54
epoch [4/50] batch [80/181] time 0.142 (0.110) data 0.000 (0.004) loss 1.5137 (1.5101) teacher_loss 0.2913 (0.3335) loss_zs_kd 0.0353 (0.0188) loss_oracle 0.5722 (0.5754) kd_loss 0.9186 (0.8796) acc 90.6250 (87.2266) gate/entropy 1.0767 (1.0803) gate/usage_max 0.4339 (0.4250) gate/usage_min 0.2799 (0.2834) gate/usage_std 0.0712 (0.0649) teacher/entropy 0.0208 (0.0828) teacher/usage_max 0.7509 (0.7222) teacher/usage_min 0.0927 (0.0898) teacher/usage_std 0.2964 (0.2797) nleep/row_max_mean 1568.6670 (1577.2509) nleep/row_max_std 61.2557 (56.6384) nleep/row_min_mean 1545.1323 (1555.4722) lr 1.9921e-03 eta 0:15:23
epoch [4/50] batch [100/181] time 0.151 (0.117) data 0.000 (0.003) loss 1.6859 (1.5035) teacher_loss 0.5227 (0.3290) loss_zs_kd 0.0202 (0.0194) loss_oracle 0.6022 (0.5802) kd_loss 0.8520 (0.8747) acc 78.1250 (87.6875) gate/entropy 1.0748 (1.0794) gate/usage_max 0.4383 (0.4273) gate/usage_min 0.2783 (0.2825) gate/usage_std 0.0743 (0.0665) teacher/entropy 0.0624 (0.0830) teacher/usage_max 0.8004 (0.7271) teacher/usage_min 0.0492 (0.0904) teacher/usage_std 0.3328 (0.2827) nleep/row_max_mean 1556.6663 (1575.5265) nleep/row_max_std 68.8149 (57.5426) nleep/row_min_mean 1531.8748 (1553.4548) lr 1.9921e-03 eta 0:16:27
epoch [4/50] batch [120/181] time 0.164 (0.124) data 0.000 (0.003) loss 1.4294 (1.5115) teacher_loss 0.3136 (0.3405) loss_zs_kd 0.0256 (0.0196) loss_oracle 0.5419 (0.5807) kd_loss 0.8320 (0.8709) acc 90.6250 (87.3438) gate/entropy 1.0729 (1.0784) gate/usage_max 0.4425 (0.4296) gate/usage_min 0.2772 (0.2817) gate/usage_std 0.0772 (0.0681) teacher/entropy 0.1292 (0.0846) teacher/usage_max 0.6831 (0.7265) teacher/usage_min 0.1240 (0.0902) teacher/usage_std 0.2489 (0.2824) nleep/row_max_mean 1548.0781 (1574.2837) nleep/row_max_std 56.4002 (58.0221) nleep/row_min_mean 1525.8320 (1551.8985) lr 1.9921e-03 eta 0:17:24
epoch [4/50] batch [140/181] time 0.139 (0.128) data 0.000 (0.002) loss 1.5517 (1.5173) teacher_loss 0.3847 (0.3460) loss_zs_kd 0.0214 (0.0203) loss_oracle 0.5546 (0.5842) kd_loss 0.8790 (0.8691) acc 84.3750 (87.0312) gate/entropy 1.0710 (1.0775) gate/usage_max 0.4467 (0.4317) gate/usage_min 0.2764 (0.2810) gate/usage_std 0.0801 (0.0696) teacher/entropy 0.0187 (0.0844) teacher/usage_max 0.8069 (0.7256) teacher/usage_min 0.0627 (0.0902) teacher/usage_std 0.3360 (0.2819) nleep/row_max_mean 1583.4916 (1573.1885) nleep/row_max_std 57.0326 (58.1385) nleep/row_min_mean 1554.6202 (1550.4189) lr 1.9921e-03 eta 0:17:50
epoch [4/50] batch [160/181] time 0.143 (0.131) data 0.000 (0.002) loss 1.4139 (1.5239) teacher_loss 0.1928 (0.3498) loss_zs_kd 0.0088 (0.0210) loss_oracle 0.6047 (0.5883) kd_loss 0.9143 (0.8694) acc 90.6250 (86.7578) gate/entropy 1.0695 (1.0766) gate/usage_max 0.4496 (0.4338) gate/usage_min 0.2740 (0.2803) gate/usage_std 0.0822 (0.0711) teacher/entropy 0.0617 (0.0851) teacher/usage_max 0.6339 (0.7186) teacher/usage_min 0.0595 (0.0886) teacher/usage_std 0.2353 (0.2781) nleep/row_max_mean 1570.0415 (1572.1297) nleep/row_max_std 62.1438 (57.9895) nleep/row_min_mean 1543.0707 (1549.1097) lr 1.9921e-03 eta 0:18:10
epoch [4/50] batch [180/181] time 0.163 (0.134) data 0.000 (0.002) loss 1.4228 (1.5206) teacher_loss 0.2182 (0.3484) loss_zs_kd 0.0181 (0.0205) loss_oracle 0.6112 (0.5884) kd_loss 0.8899 (0.8678) acc 90.6250 (86.8576) gate/entropy 1.0678 (1.0757) gate/usage_max 0.4531 (0.4357) gate/usage_min 0.2709 (0.2794) gate/usage_std 0.0847 (0.0724) teacher/entropy 0.0834 (0.0854) teacher/usage_max 0.6331 (0.7165) teacher/usage_min 0.0469 (0.0860) teacher/usage_std 0.2395 (0.2775) nleep/row_max_mean 1586.7324 (1572.1313) nleep/row_max_std 55.0057 (57.9830) nleep/row_min_mean 1558.2595 (1548.5371) lr 1.9921e-03 eta 0:18:38
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.7%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [5/50] batch [20/181] time 0.083 (0.109) data 0.000 (0.014) loss 1.6632 (1.5379) teacher_loss 0.4931 (0.3603) loss_zs_kd 0.0378 (0.0185) loss_oracle 0.6447 (0.6126) kd_loss 0.8288 (0.8620) acc 78.1250 (85.4688) gate/entropy 1.0661 (1.0669) gate/usage_max 0.4564 (0.4548) gate/usage_min 0.2677 (0.2692) gate/usage_std 0.0871 (0.0859) teacher/entropy 0.1048 (0.0812) teacher/usage_max 0.7007 (0.6889) teacher/usage_min 0.0103 (0.0489) teacher/usage_std 0.2836 (0.2694) nleep/row_max_mean 1570.7756 (1565.2972) nleep/row_max_std 63.3158 (60.6831) nleep/row_min_mean 1542.1991 (1536.6167) lr 1.9823e-03 eta 0:15:04
epoch [5/50] batch [40/181] time 0.060 (0.101) data 0.000 (0.007) loss 1.4236 (1.5247) teacher_loss 0.3506 (0.3670) loss_zs_kd 0.0241 (0.0184) loss_oracle 0.5748 (0.6096) kd_loss 0.7735 (0.8437) acc 90.6250 (86.3281) gate/entropy 1.0644 (1.0661) gate/usage_max 0.4595 (0.4563) gate/usage_min 0.2646 (0.2676) gate/usage_std 0.0893 (0.0870) teacher/entropy 0.0659 (0.0824) teacher/usage_max 0.8789 (0.7188) teacher/usage_min 0.0049 (0.0451) teacher/usage_std 0.3884 (0.2868) nleep/row_max_mean 1577.3071 (1567.8963) nleep/row_max_std 61.8596 (62.5868) nleep/row_min_mean 1545.9348 (1538.6096) lr 1.9823e-03 eta 0:14:00
epoch [5/50] batch [60/181] time 0.086 (0.101) data 0.000 (0.005) loss 1.4684 (1.5171) teacher_loss 0.2744 (0.3577) loss_zs_kd 0.0305 (0.0184) loss_oracle 0.6623 (0.6076) kd_loss 0.8477 (0.8464) acc 90.6250 (86.6146) gate/entropy 1.0623 (1.0652) gate/usage_max 0.4633 (0.4579) gate/usage_min 0.2612 (0.2661) gate/usage_std 0.0921 (0.0882) teacher/entropy 0.0535 (0.0835) teacher/usage_max 0.7463 (0.7069) teacher/usage_min 0.0122 (0.0436) teacher/usage_std 0.3067 (0.2811) nleep/row_max_mean 1581.3845 (1568.3849) nleep/row_max_std 60.4459 (62.9144) nleep/row_min_mean 1545.2922 (1538.8402) lr 1.9823e-03 eta 0:13:58
epoch [5/50] batch [80/181] time 0.068 (0.103) data 0.000 (0.004) loss 1.4417 (1.5411) teacher_loss 0.3002 (0.3499) loss_zs_kd 0.0258 (0.0178) loss_oracle 0.6163 (0.6420) kd_loss 0.8205 (0.8612) acc 87.5000 (86.5234) gate/entropy 1.0617 (1.0645) gate/usage_max 0.4641 (0.4593) gate/usage_min 0.2587 (0.2646) gate/usage_std 0.0928 (0.0892) teacher/entropy 0.0911 (0.0772) teacher/usage_max 0.7264 (0.6863) teacher/usage_min 0.0512 (0.0409) teacher/usage_std 0.2866 (0.2726) nleep/row_max_mean 1571.3481 (1567.2700) nleep/row_max_std 63.0576 (62.9824) nleep/row_min_mean 1540.9624 (1537.9450) lr 1.9823e-03 eta 0:14:07
epoch [5/50] batch [100/181] time 0.077 (0.104) data 0.000 (0.003) loss 1.7346 (1.5437) teacher_loss 0.4756 (0.3439) loss_zs_kd 0.0159 (0.0169) loss_oracle 0.6028 (0.6423) kd_loss 0.9496 (0.8701) acc 81.2500 (86.5625) gate/entropy 1.0611 (1.0639) gate/usage_max 0.4649 (0.4603) gate/usage_min 0.2558 (0.2632) gate/usage_std 0.0935 (0.0899) teacher/entropy 0.0234 (0.0767) teacher/usage_max 0.5936 (0.6684) teacher/usage_min 0.0178 (0.0381) teacher/usage_std 0.2383 (0.2658) nleep/row_max_mean 1563.7302 (1566.4166) nleep/row_max_std 53.5667 (62.0359) nleep/row_min_mean 1532.9851 (1537.1949) lr 1.9823e-03 eta 0:14:12
epoch [5/50] batch [120/181] time 0.091 (0.101) data 0.000 (0.003) loss 1.4358 (1.5447) teacher_loss 0.2935 (0.3502) loss_zs_kd 0.0133 (0.0172) loss_oracle 0.5782 (0.6337) kd_loss 0.8466 (0.8691) acc 90.6250 (86.6146) gate/entropy 1.0596 (1.0633) gate/usage_max 0.4672 (0.4612) gate/usage_min 0.2529 (0.2617) gate/usage_std 0.0953 (0.0906) teacher/entropy 0.0898 (0.0753) teacher/usage_max 0.6602 (0.6689) teacher/usage_min 0.0270 (0.0352) teacher/usage_std 0.2589 (0.2663) nleep/row_max_mean 1580.5244 (1565.5626) nleep/row_max_std 58.0696 (61.7759) nleep/row_min_mean 1548.8110 (1536.3191) lr 1.9823e-03 eta 0:13:49
epoch [5/50] batch [140/181] time 0.068 (0.100) data 0.000 (0.002) loss 1.4830 (1.5381) teacher_loss 0.4476 (0.3513) loss_zs_kd 0.0211 (0.0172) loss_oracle 0.6128 (0.6269) kd_loss 0.7184 (0.8647) acc 84.3750 (86.5625) gate/entropy 1.0582 (1.0627) gate/usage_max 0.4695 (0.4621) gate/usage_min 0.2505 (0.2603) gate/usage_std 0.0971 (0.0914) teacher/entropy 0.1511 (0.0743) teacher/usage_max 0.7898 (0.6754) teacher/usage_min 0.0582 (0.0329) teacher/usage_std 0.3250 (0.2700) nleep/row_max_mean 1547.5864 (1564.1039) nleep/row_max_std 67.4033 (62.3504) nleep/row_min_mean 1518.7411 (1534.8634) lr 1.9823e-03 eta 0:13:41
epoch [5/50] batch [160/181] time 0.067 (0.101) data 0.000 (0.002) loss 1.3544 (1.5243) teacher_loss 0.2094 (0.3479) loss_zs_kd 0.0083 (0.0165) loss_oracle 0.6216 (0.6237) kd_loss 0.8301 (0.8563) acc 90.6250 (86.6602) gate/entropy 1.0561 (1.0620) gate/usage_max 0.4729 (0.4632) gate/usage_min 0.2481 (0.2589) gate/usage_std 0.0995 (0.0922) teacher/entropy 0.0393 (0.0768) teacher/usage_max 0.7849 (0.6841) teacher/usage_min 0.0659 (0.0355) teacher/usage_std 0.3211 (0.2736) nleep/row_max_mean 1573.5283 (1562.8425) nleep/row_max_std 55.7919 (62.8188) nleep/row_min_mean 1541.1429 (1533.6986) lr 1.9823e-03 eta 0:13:45
epoch [5/50] batch [180/181] time 0.161 (0.102) data 0.000 (0.002) loss 1.5177 (1.5122) teacher_loss 0.4653 (0.3494) loss_zs_kd 0.0176 (0.0159) loss_oracle 0.5643 (0.6195) kd_loss 0.7615 (0.8451) acc 78.1250 (86.6146) gate/entropy 1.0540 (1.0613) gate/usage_max 0.4764 (0.4645) gate/usage_min 0.2458 (0.2576) gate/usage_std 0.1020 (0.0932) teacher/entropy 0.0940 (0.0771) teacher/usage_max 0.8088 (0.7019) teacher/usage_min 0.0928 (0.0376) teacher/usage_std 0.3362 (0.2834) nleep/row_max_mean 1555.0896 (1562.5937) nleep/row_max_std 60.3940 (62.9033) nleep/row_min_mean 1527.6870 (1533.3337) lr 1.9823e-03 eta 0:13:50
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 5 *******
******* Domain p best val test acc: 99.9%, epoch: 5 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [6/50] batch [20/181] time 0.152 (0.181) data 0.000 (0.018) loss 1.2776 (1.3974) teacher_loss 0.2305 (0.3611) loss_zs_kd 0.0136 (0.0153) loss_oracle 0.5173 (0.5572) kd_loss 0.7816 (0.7501) acc 93.7500 (87.5000) gate/entropy 1.0515 (1.0526) gate/usage_max 0.4804 (0.4787) gate/usage_min 0.2438 (0.2447) gate/usage_std 0.1048 (0.1036) teacher/entropy 0.0265 (0.0534) teacher/usage_max 0.8721 (0.8867) teacher/usage_min 0.0357 (0.0332) teacher/usage_std 0.3817 (0.3920) nleep/row_max_mean 1558.3654 (1562.3628) nleep/row_max_std 62.2236 (63.4957) nleep/row_min_mean 1528.8052 (1531.4890) lr 1.9686e-03 eta 0:24:26
epoch [6/50] batch [40/181] time 0.155 (0.164) data 0.000 (0.009) loss 1.2139 (1.3707) teacher_loss 0.2790 (0.3542) loss_zs_kd 0.0108 (0.0147) loss_oracle 0.4870 (0.5333) kd_loss 0.6860 (0.7426) acc 93.7500 (86.7188) gate/entropy 1.0485 (1.0513) gate/usage_max 0.4853 (0.4808) gate/usage_min 0.2417 (0.2437) gate/usage_std 0.1082 (0.1051) teacher/entropy 0.0506 (0.0516) teacher/usage_max 0.9790 (0.8964) teacher/usage_min 0.0083 (0.0293) teacher/usage_std 0.4566 (0.3988) nleep/row_max_mean 1555.4427 (1560.5627) nleep/row_max_std 78.9876 (66.3861) nleep/row_min_mean 1523.4093 (1529.7510) lr 1.9686e-03 eta 0:22:09
epoch [6/50] batch [60/181] time 0.151 (0.162) data 0.000 (0.006) loss 1.3516 (1.3560) teacher_loss 0.3500 (0.3453) loss_zs_kd 0.0135 (0.0148) loss_oracle 0.4948 (0.5287) kd_loss 0.7475 (0.7389) acc 87.5000 (87.2396) gate/entropy 1.0457 (1.0498) gate/usage_max 0.4897 (0.4832) gate/usage_min 0.2398 (0.2427) gate/usage_std 0.1113 (0.1067) teacher/entropy 0.0210 (0.0470) teacher/usage_max 0.9086 (0.9036) teacher/usage_min 0.0008 (0.0271) teacher/usage_std 0.4084 (0.4038) nleep/row_max_mean 1557.7767 (1560.8037) nleep/row_max_std 73.8788 (67.5694) nleep/row_min_mean 1528.8942 (1529.6093) lr 1.9686e-03 eta 0:21:47
epoch [6/50] batch [80/181] time 0.138 (0.160) data 0.000 (0.005) loss 1.5970 (1.3661) teacher_loss 0.5850 (0.3522) loss_zs_kd 0.0288 (0.0149) loss_oracle 0.4972 (0.5337) kd_loss 0.7490 (0.7396) acc 78.1250 (86.7969) gate/entropy 1.0430 (1.0484) gate/usage_max 0.4938 (0.4854) gate/usage_min 0.2380 (0.2417) gate/usage_std 0.1141 (0.1083) teacher/entropy 0.0548 (0.0468) teacher/usage_max 0.8481 (0.8971) teacher/usage_min 0.0505 (0.0285) teacher/usage_std 0.3646 (0.3994) nleep/row_max_mean 1555.4637 (1560.7558) nleep/row_max_std 77.4210 (67.2551) nleep/row_min_mean 1527.0385 (1529.7935) lr 1.9686e-03 eta 0:21:30
epoch [6/50] batch [100/181] time 0.156 (0.159) data 0.000 (0.004) loss 1.4322 (1.3680) teacher_loss 0.3169 (0.3488) loss_zs_kd 0.0180 (0.0151) loss_oracle 0.6821 (0.5396) kd_loss 0.7653 (0.7418) acc 87.5000 (86.6250) gate/entropy 1.0408 (1.0471) gate/usage_max 0.4970 (0.4874) gate/usage_min 0.2364 (0.2408) gate/usage_std 0.1164 (0.1097) teacher/entropy 0.0434 (0.0483) teacher/usage_max 0.8297 (0.8859) teacher/usage_min 0.0319 (0.0293) teacher/usage_std 0.3536 (0.3919) nleep/row_max_mean 1556.5371 (1560.1943) nleep/row_max_std 69.1206 (67.6217) nleep/row_min_mean 1526.8058 (1529.4454) lr 1.9686e-03 eta 0:21:15
epoch [6/50] batch [120/181] time 0.149 (0.157) data 0.000 (0.003) loss 1.6393 (1.3705) teacher_loss 0.5138 (0.3463) loss_zs_kd 0.0114 (0.0151) loss_oracle 0.6593 (0.5472) kd_loss 0.7901 (0.7431) acc 84.3750 (86.6146) gate/entropy 1.0386 (1.0459) gate/usage_max 0.5002 (0.4893) gate/usage_min 0.2347 (0.2399) gate/usage_std 0.1186 (0.1110) teacher/entropy 0.0706 (0.0490) teacher/usage_max 0.7400 (0.8774) teacher/usage_min 0.0391 (0.0288) teacher/usage_std 0.2970 (0.3864) nleep/row_max_mean 1551.3743 (1559.6348) nleep/row_max_std 63.4794 (67.5360) nleep/row_min_mean 1523.6033 (1529.0888) lr 1.9686e-03 eta 0:20:57
epoch [6/50] batch [140/181] time 0.092 (0.152) data 0.000 (0.003) loss 1.5532 (1.3845) teacher_loss 0.5036 (0.3491) loss_zs_kd 0.0247 (0.0154) loss_oracle 0.6197 (0.5581) kd_loss 0.7274 (0.7486) acc 78.1250 (86.7188) gate/entropy 1.0370 (1.0447) gate/usage_max 0.5025 (0.4911) gate/usage_min 0.2332 (0.2390) gate/usage_std 0.1203 (0.1122) teacher/entropy 0.1087 (0.0511) teacher/usage_max 0.7731 (0.8610) teacher/usage_min 0.0230 (0.0295) teacher/usage_std 0.3196 (0.3762) nleep/row_max_mean 1547.3107 (1558.6574) nleep/row_max_std 68.2041 (67.1981) nleep/row_min_mean 1517.3198 (1528.4104) lr 1.9686e-03 eta 0:20:19
epoch [6/50] batch [160/181] time 0.079 (0.146) data 0.000 (0.002) loss 1.3801 (1.3915) teacher_loss 0.2681 (0.3460) loss_zs_kd 0.0081 (0.0159) loss_oracle 0.5757 (0.5640) kd_loss 0.8201 (0.7556) acc 87.5000 (86.8750) gate/entropy 1.0355 (1.0436) gate/usage_max 0.5044 (0.4926) gate/usage_min 0.2315 (0.2382) gate/usage_std 0.1217 (0.1133) teacher/entropy 0.0538 (0.0525) teacher/usage_max 0.7146 (0.8436) teacher/usage_min 0.0465 (0.0287) teacher/usage_std 0.2808 (0.3661) nleep/row_max_mean 1567.4562 (1558.3027) nleep/row_max_std 63.6017 (66.8750) nleep/row_min_mean 1535.2285 (1528.0985) lr 1.9686e-03 eta 0:19:26
epoch [6/50] batch [180/181] time 0.070 (0.142) data 0.000 (0.002) loss 1.4373 (1.3944) teacher_loss 0.3822 (0.3464) loss_zs_kd 0.0224 (0.0160) loss_oracle 0.5709 (0.5661) kd_loss 0.7584 (0.7570) acc 87.5000 (86.8403) gate/entropy 1.0345 (1.0427) gate/usage_max 0.5058 (0.4940) gate/usage_min 0.2303 (0.2374) gate/usage_std 0.1227 (0.1143) teacher/entropy 0.1016 (0.0557) teacher/usage_max 0.7319 (0.8327) teacher/usage_min 0.0411 (0.0280) teacher/usage_std 0.2919 (0.3595) nleep/row_max_mean 1551.5947 (1557.8101) nleep/row_max_std 72.2575 (67.2585) nleep/row_min_mean 1525.7310 (1527.6506) lr 1.9686e-03 eta 0:18:53
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,394
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 5 *******
******* Domain p best val test acc: 99.9%, epoch: 5 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [7/50] batch [20/181] time 0.130 (0.135) data 0.001 (0.016) loss 1.2694 (1.4653) teacher_loss 0.1648 (0.3835) loss_zs_kd 0.0072 (0.0183) loss_oracle 0.5788 (0.5946) kd_loss 0.8116 (0.7753) acc 96.8750 (86.0938) gate/entropy 1.0326 (1.0336) gate/usage_max 0.5083 (0.5070) gate/usage_min 0.2287 (0.2294) gate/usage_std 0.1245 (0.1236) teacher/entropy 0.0365 (0.0769) teacher/usage_max 0.7449 (0.7440) teacher/usage_min 0.0320 (0.0487) teacher/usage_std 0.3013 (0.3000) nleep/row_max_mean 1556.3597 (1552.5204) nleep/row_max_std 63.8159 (65.1105) nleep/row_min_mean 1527.8927 (1523.6286) lr 1.9511e-03 eta 0:17:51
epoch [7/50] batch [40/181] time 0.160 (0.133) data 0.000 (0.008) loss 1.4100 (1.4308) teacher_loss 0.4175 (0.3654) loss_zs_kd 0.0079 (0.0162) loss_oracle 0.5522 (0.5759) kd_loss 0.7125 (0.7693) acc 81.2500 (86.4062) gate/entropy 1.0305 (1.0328) gate/usage_max 0.5112 (0.5081) gate/usage_min 0.2275 (0.2289) gate/usage_std 0.1265 (0.1244) teacher/entropy 0.1024 (0.0705) teacher/usage_max 0.7949 (0.7627) teacher/usage_min 0.0559 (0.0553) teacher/usage_std 0.3286 (0.3104) nleep/row_max_mean 1571.3425 (1550.9387) nleep/row_max_std 60.9332 (65.2909) nleep/row_min_mean 1538.9701 (1522.4430) lr 1.9511e-03 eta 0:17:36
epoch [7/50] batch [60/181] time 0.078 (0.129) data 0.000 (0.006) loss 1.4439 (1.4249) teacher_loss 0.3980 (0.3692) loss_zs_kd 0.0134 (0.0172) loss_oracle 0.5079 (0.5681) kd_loss 0.7852 (0.7632) acc 84.3750 (86.1979) gate/entropy 1.0298 (1.0319) gate/usage_max 0.5123 (0.5093) gate/usage_min 0.2273 (0.2284) gate/usage_std 0.1273 (0.1252) teacher/entropy 0.0631 (0.0696) teacher/usage_max 0.7502 (0.7711) teacher/usage_min 0.0830 (0.0525) teacher/usage_std 0.2967 (0.3159) nleep/row_max_mean 1530.9221 (1551.2192) nleep/row_max_std 70.4501 (65.3290) nleep/row_min_mean 1504.1550 (1522.5258) lr 1.9511e-03 eta 0:16:56
epoch [7/50] batch [80/181] time 0.097 (0.123) data 0.000 (0.004) loss 1.2474 (1.4103) teacher_loss 0.1133 (0.3617) loss_zs_kd 0.0129 (0.0164) loss_oracle 0.5590 (0.5648) kd_loss 0.8481 (0.7581) acc 100.0000 (86.5234) gate/entropy 1.0273 (1.0310) gate/usage_max 0.5157 (0.5106) gate/usage_min 0.2261 (0.2279) gate/usage_std 0.1296 (0.1261) teacher/entropy 0.0619 (0.0667) teacher/usage_max 0.6728 (0.7815) teacher/usage_min 0.1513 (0.0540) teacher/usage_std 0.2402 (0.3222) nleep/row_max_mean 1541.6510 (1551.3635) nleep/row_max_std 70.0962 (64.0102) nleep/row_min_mean 1514.9067 (1522.6766) lr 1.9511e-03 eta 0:16:12
epoch [7/50] batch [100/181] time 0.164 (0.130) data 0.000 (0.003) loss 1.6496 (1.4151) teacher_loss 0.5486 (0.3678) loss_zs_kd 0.0125 (0.0166) loss_oracle 0.5118 (0.5615) kd_loss 0.8388 (0.7583) acc 78.1250 (86.1875) gate/entropy 1.0258 (1.0300) gate/usage_max 0.5178 (0.5119) gate/usage_min 0.2256 (0.2275) gate/usage_std 0.1310 (0.1270) teacher/entropy 0.1079 (0.0643) teacher/usage_max 0.6249 (0.7837) teacher/usage_min 0.1723 (0.0567) teacher/usage_std 0.2065 (0.3231) nleep/row_max_mean 1530.8608 (1549.6305) nleep/row_max_std 64.5884 (63.6156) nleep/row_min_mean 1505.8950 (1520.9917) lr 1.9511e-03 eta 0:17:04
epoch [7/50] batch [120/181] time 0.158 (0.133) data 0.000 (0.003) loss 1.3391 (1.4005) teacher_loss 0.2807 (0.3604) loss_zs_kd 0.0076 (0.0166) loss_oracle 0.5083 (0.5566) kd_loss 0.8005 (0.7534) acc 90.6250 (86.5365) gate/entropy 1.0238 (1.0291) gate/usage_max 0.5204 (0.5132) gate/usage_min 0.2251 (0.2271) gate/usage_std 0.1328 (0.1279) teacher/entropy 0.0395 (0.0636) teacher/usage_max 0.7615 (0.7903) teacher/usage_min 0.0928 (0.0580) teacher/usage_std 0.3035 (0.3272) nleep/row_max_mean 1525.4199 (1548.8569) nleep/row_max_std 67.6725 (63.8766) nleep/row_min_mean 1497.5613 (1520.2050) lr 1.9511e-03 eta 0:17:22
epoch [7/50] batch [140/181] time 0.134 (0.136) data 0.000 (0.002) loss 1.2896 (1.3903) teacher_loss 0.3414 (0.3583) loss_zs_kd 0.0098 (0.0164) loss_oracle 0.4766 (0.5479) kd_loss 0.7050 (0.7499) acc 84.3750 (86.4509) gate/entropy 1.0211 (1.0281) gate/usage_max 0.5240 (0.5145) gate/usage_min 0.2241 (0.2267) gate/usage_std 0.1353 (0.1288) teacher/entropy 0.0164 (0.0613) teacher/usage_max 0.9062 (0.7968) teacher/usage_min 0.0322 (0.0578) teacher/usage_std 0.4053 (0.3313) nleep/row_max_mean 1556.6729 (1548.5953) nleep/row_max_std 58.4479 (63.1759) nleep/row_min_mean 1523.5853 (1519.8640) lr 1.9511e-03 eta 0:17:42
epoch [7/50] batch [160/181] time 0.139 (0.138) data 0.000 (0.002) loss 1.1613 (1.3798) teacher_loss 0.2489 (0.3517) loss_zs_kd 0.0125 (0.0164) loss_oracle 0.4739 (0.5445) kd_loss 0.6692 (0.7476) acc 84.3750 (86.7773) gate/entropy 1.0191 (1.0271) gate/usage_max 0.5266 (0.5158) gate/usage_min 0.2235 (0.2264) gate/usage_std 0.1371 (0.1297) teacher/entropy 0.0390 (0.0600) teacher/usage_max 0.9149 (0.8007) teacher/usage_min 0.0378 (0.0580) teacher/usage_std 0.4113 (0.3337) nleep/row_max_mean 1555.9474 (1548.2850) nleep/row_max_std 59.9094 (62.8173) nleep/row_min_mean 1524.3049 (1519.3807) lr 1.9511e-03 eta 0:17:57
epoch [7/50] batch [180/181] time 0.135 (0.139) data 0.000 (0.002) loss 1.6992 (1.3744) teacher_loss 0.6786 (0.3508) loss_zs_kd 0.0303 (0.0163) loss_oracle 0.5533 (0.5410) kd_loss 0.7288 (0.7450) acc 81.2500 (86.8576) gate/entropy 1.0177 (1.0262) gate/usage_max 0.5284 (0.5171) gate/usage_min 0.2232 (0.2261) gate/usage_std 0.1383 (0.1305) teacher/entropy 0.0091 (0.0583) teacher/usage_max 0.8756 (0.8052) teacher/usage_min 0.0610 (0.0576) teacher/usage_std 0.3834 (0.3367) nleep/row_max_mean 1548.1165 (1547.7251) nleep/row_max_std 62.0075 (62.5028) nleep/row_min_mean 1514.5894 (1518.7176) lr 1.9511e-03 eta 0:18:05
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,406
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [8/50] batch [20/181] time 0.091 (0.135) data 0.000 (0.010) loss 1.2354 (1.2958) teacher_loss 0.1609 (0.3077) loss_zs_kd 0.0249 (0.0162) loss_oracle 0.5946 (0.5092) kd_loss 0.7648 (0.7253) acc 93.7500 (88.9062) gate/entropy 1.0166 (1.0170) gate/usage_max 0.5298 (0.5293) gate/usage_min 0.2231 (0.2230) gate/usage_std 0.1393 (0.1390) teacher/entropy 0.0707 (0.0523) teacher/usage_max 0.7591 (0.8277) teacher/usage_min 0.0658 (0.0473) teacher/usage_std 0.3043 (0.3519) nleep/row_max_mean 1531.0062 (1546.0475) nleep/row_max_std 56.6115 (54.6196) nleep/row_min_mean 1505.7344 (1517.4606) lr 1.9298e-03 eta 0:17:31
epoch [8/50] batch [40/181] time 0.077 (0.129) data 0.000 (0.005) loss 1.4356 (1.3478) teacher_loss 0.3503 (0.3500) loss_zs_kd 0.0141 (0.0178) loss_oracle 0.5893 (0.5078) kd_loss 0.7837 (0.7350) acc 84.3750 (87.5000) gate/entropy 1.0143 (1.0162) gate/usage_max 0.5327 (0.5304) gate/usage_min 0.2222 (0.2228) gate/usage_std 0.1413 (0.1397) teacher/entropy 0.0255 (0.0471) teacher/usage_max 0.7806 (0.8200) teacher/usage_min 0.0999 (0.0563) teacher/usage_std 0.3163 (0.3460) nleep/row_max_mean 1561.8040 (1546.5509) nleep/row_max_std 61.2769 (54.6529) nleep/row_min_mean 1531.8938 (1517.6796) lr 1.9298e-03 eta 0:16:39
epoch [8/50] batch [60/181] time 0.177 (0.124) data 0.001 (0.003) loss 1.2871 (1.3324) teacher_loss 0.3196 (0.3350) loss_zs_kd 0.0047 (0.0169) loss_oracle 0.4983 (0.5132) kd_loss 0.7160 (0.7324) acc 84.3750 (88.1250) gate/entropy 1.0134 (1.0155) gate/usage_max 0.5338 (0.5312) gate/usage_min 0.2221 (0.2227) gate/usage_std 0.1421 (0.1403) teacher/entropy 0.0306 (0.0476) teacher/usage_max 0.8640 (0.8215) teacher/usage_min 0.0006 (0.0569) teacher/usage_std 0.3792 (0.3468) nleep/row_max_mean 1551.4845 (1544.6974) nleep/row_max_std 55.5361 (55.0161) nleep/row_min_mean 1520.4683 (1516.0168) lr 1.9298e-03 eta 0:15:58
epoch [8/50] batch [80/181] time 0.090 (0.122) data 0.000 (0.003) loss 1.4994 (1.3279) teacher_loss 0.5506 (0.3391) loss_zs_kd 0.0175 (0.0157) loss_oracle 0.5052 (0.5102) kd_loss 0.6874 (0.7259) acc 81.2500 (87.6172) gate/entropy 1.0113 (1.0147) gate/usage_max 0.5364 (0.5322) gate/usage_min 0.2214 (0.2224) gate/usage_std 0.1439 (0.1409) teacher/entropy 0.0672 (0.0462) teacher/usage_max 0.8416 (0.8293) teacher/usage_min 0.0790 (0.0559) teacher/usage_std 0.3594 (0.3522) nleep/row_max_mean 1567.1147 (1546.5777) nleep/row_max_std 49.8945 (54.9863) nleep/row_min_mean 1534.1176 (1517.6952) lr 1.9298e-03 eta 0:15:42
epoch [8/50] batch [100/181] time 0.093 (0.119) data 0.000 (0.002) loss 1.2462 (1.3272) teacher_loss 0.3201 (0.3424) loss_zs_kd 0.0138 (0.0150) loss_oracle 0.5031 (0.5121) kd_loss 0.6676 (0.7212) acc 84.3750 (87.3438) gate/entropy 1.0107 (1.0140) gate/usage_max 0.5372 (0.5331) gate/usage_min 0.2214 (0.2222) gate/usage_std 0.1444 (0.1416) teacher/entropy 0.0647 (0.0487) teacher/usage_max 0.8709 (0.8304) teacher/usage_min 0.0367 (0.0557) teacher/usage_std 0.3808 (0.3529) nleep/row_max_mean 1548.7217 (1547.2890) nleep/row_max_std 56.2513 (55.6966) nleep/row_min_mean 1520.2513 (1518.4613) lr 1.9298e-03 eta 0:15:17
epoch [8/50] batch [120/181] time 0.091 (0.116) data 0.000 (0.002) loss 1.4964 (1.3347) teacher_loss 0.5497 (0.3480) loss_zs_kd 0.0224 (0.0146) loss_oracle 0.4532 (0.5161) kd_loss 0.7089 (0.7214) acc 84.3750 (87.0052) gate/entropy 1.0097 (1.0133) gate/usage_max 0.5384 (0.5339) gate/usage_min 0.2211 (0.2220) gate/usage_std 0.1453 (0.1421) teacher/entropy 0.0498 (0.0503) teacher/usage_max 0.8383 (0.8272) teacher/usage_min 0.0360 (0.0566) teacher/usage_std 0.3590 (0.3506) nleep/row_max_mean 1528.6277 (1547.1784) nleep/row_max_std 64.2587 (56.2858) nleep/row_min_mean 1503.0195 (1518.5173) lr 1.9298e-03 eta 0:14:50
epoch [8/50] batch [140/181] time 0.150 (0.118) data 0.000 (0.002) loss 1.4448 (1.3340) teacher_loss 0.4520 (0.3498) loss_zs_kd 0.0097 (0.0147) loss_oracle 0.4996 (0.5139) kd_loss 0.7381 (0.7199) acc 81.2500 (86.9866) gate/entropy 1.0082 (1.0127) gate/usage_max 0.5403 (0.5347) gate/usage_min 0.2207 (0.2219) gate/usage_std 0.1465 (0.1427) teacher/entropy 0.0398 (0.0501) teacher/usage_max 0.8132 (0.8282) teacher/usage_min 0.0505 (0.0549) teacher/usage_std 0.3411 (0.3514) nleep/row_max_mean 1540.6488 (1546.9563) nleep/row_max_std 53.4015 (55.9750) nleep/row_min_mean 1514.0005 (1518.4236) lr 1.9298e-03 eta 0:15:01
epoch [8/50] batch [160/181] time 0.099 (0.119) data 0.000 (0.001) loss 1.2559 (1.3374) teacher_loss 0.4216 (0.3535) loss_zs_kd 0.0109 (0.0149) loss_oracle 0.4804 (0.5170) kd_loss 0.5887 (0.7180) acc 84.3750 (86.7578) gate/entropy 1.0063 (1.0120) gate/usage_max 0.5425 (0.5355) gate/usage_min 0.2201 (0.2217) gate/usage_std 0.1481 (0.1432) teacher/entropy 0.0348 (0.0496) teacher/usage_max 0.9865 (0.8298) teacher/usage_min 0.0034 (0.0546) teacher/usage_std 0.4618 (0.3525) nleep/row_max_mean 1559.6689 (1547.1253) nleep/row_max_std 63.5954 (55.9862) nleep/row_min_mean 1524.7209 (1518.4438) lr 1.9298e-03 eta 0:15:04
epoch [8/50] batch [180/181] time 0.074 (0.118) data 0.000 (0.001) loss 1.3257 (1.3418) teacher_loss 0.3478 (0.3576) loss_zs_kd 0.0097 (0.0150) loss_oracle 0.5389 (0.5164) kd_loss 0.7036 (0.7185) acc 84.3750 (86.6146) gate/entropy 1.0053 (1.0114) gate/usage_max 0.5437 (0.5363) gate/usage_min 0.2199 (0.2215) gate/usage_std 0.1489 (0.1438) teacher/entropy 0.0324 (0.0510) teacher/usage_max 0.8516 (0.8267) teacher/usage_min 0.0547 (0.0548) teacher/usage_std 0.3668 (0.3504) nleep/row_max_mean 1566.0261 (1546.8749) nleep/row_max_std 56.4249 (56.2417) nleep/row_min_mean 1530.0486 (1518.0769) lr 1.9298e-03 eta 0:14:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [9/50] batch [20/181] time 0.153 (0.174) data 0.000 (0.014) loss 1.1192 (1.3185) teacher_loss 0.2354 (0.3576) loss_zs_kd 0.0101 (0.0118) loss_oracle 0.4846 (0.5015) kd_loss 0.6364 (0.7043) acc 93.7500 (86.4062) gate/entropy 1.0045 (1.0051) gate/usage_max 0.5447 (0.5440) gate/usage_min 0.2199 (0.2200) gate/usage_std 0.1496 (0.1491) teacher/entropy 0.0444 (0.0416) teacher/usage_max 0.9167 (0.8443) teacher/usage_min 0.0316 (0.0397) teacher/usage_std 0.4126 (0.3636) nleep/row_max_mean 1548.2883 (1551.5157) nleep/row_max_std 58.0959 (57.3627) nleep/row_min_mean 1518.6042 (1520.3291) lr 1.9048e-03 eta 0:22:02
epoch [9/50] batch [40/181] time 0.167 (0.167) data 0.000 (0.007) loss 1.1524 (1.3107) teacher_loss 0.1926 (0.3514) loss_zs_kd 0.0065 (0.0120) loss_oracle 0.5054 (0.5023) kd_loss 0.7038 (0.7021) acc 93.7500 (86.4844) gate/entropy 1.0036 (1.0045) gate/usage_max 0.5457 (0.5446) gate/usage_min 0.2197 (0.2199) gate/usage_std 0.1503 (0.1495) teacher/entropy 0.0694 (0.0484) teacher/usage_max 0.8105 (0.8381) teacher/usage_min 0.0611 (0.0426) teacher/usage_std 0.3385 (0.3591) nleep/row_max_mean 1550.5465 (1552.4857) nleep/row_max_std 55.9793 (55.3053) nleep/row_min_mean 1520.4642 (1521.3027) lr 1.9048e-03 eta 0:21:04
epoch [9/50] batch [60/181] time 0.173 (0.165) data 0.000 (0.005) loss 1.2110 (1.2972) teacher_loss 0.2624 (0.3457) loss_zs_kd 0.0162 (0.0138) loss_oracle 0.4791 (0.4925) kd_loss 0.7010 (0.6984) acc 90.6250 (86.6667) gate/entropy 1.0024 (1.0040) gate/usage_max 0.5470 (0.5452) gate/usage_min 0.2194 (0.2198) gate/usage_std 0.1512 (0.1499) teacher/entropy 0.0550 (0.0528) teacher/usage_max 0.8280 (0.8365) teacher/usage_min 0.0622 (0.0431) teacher/usage_std 0.3503 (0.3581) nleep/row_max_mean 1558.2120 (1552.3221) nleep/row_max_std 41.7715 (54.1609) nleep/row_min_mean 1527.5490 (1521.3948) lr 1.9048e-03 eta 0:20:46
epoch [9/50] batch [80/181] time 0.144 (0.165) data 0.000 (0.004) loss 1.2067 (1.2881) teacher_loss 0.2952 (0.3411) loss_zs_kd 0.0113 (0.0137) loss_oracle 0.4316 (0.4846) kd_loss 0.6900 (0.6979) acc 84.3750 (87.0312) gate/entropy 1.0017 (1.0035) gate/usage_max 0.5479 (0.5458) gate/usage_min 0.2193 (0.2197) gate/usage_std 0.1518 (0.1503) teacher/entropy 0.0842 (0.0507) teacher/usage_max 0.8079 (0.8387) teacher/usage_min 0.0389 (0.0408) teacher/usage_std 0.3388 (0.3598) nleep/row_max_mean 1553.1552 (1553.1900) nleep/row_max_std 44.4007 (54.0295) nleep/row_min_mean 1525.5665 (1522.5284) lr 1.9048e-03 eta 0:20:39
epoch [9/50] batch [100/181] time 0.157 (0.164) data 0.000 (0.003) loss 1.2208 (1.2929) teacher_loss 0.3296 (0.3452) loss_zs_kd 0.0361 (0.0147) loss_oracle 0.4348 (0.4831) kd_loss 0.6557 (0.6988) acc 90.6250 (86.8125) gate/entropy 1.0002 (1.0031) gate/usage_max 0.5497 (0.5463) gate/usage_min 0.2188 (0.2196) gate/usage_std 0.1530 (0.1507) teacher/entropy 0.0519 (0.0509) teacher/usage_max 0.8775 (0.8367) teacher/usage_min 0.0605 (0.0405) teacher/usage_std 0.3848 (0.3585) nleep/row_max_mean 1568.9048 (1553.3867) nleep/row_max_std 52.7087 (54.5069) nleep/row_min_mean 1539.6182 (1522.7886) lr 1.9048e-03 eta 0:20:28
epoch [9/50] batch [120/181] time 0.095 (0.159) data 0.000 (0.002) loss 1.2301 (1.2842) teacher_loss 0.3582 (0.3371) loss_zs_kd 0.0193 (0.0144) loss_oracle 0.4435 (0.4789) kd_loss 0.6405 (0.7004) acc 87.5000 (87.3438) gate/entropy 0.9997 (1.0026) gate/usage_max 0.5502 (0.5469) gate/usage_min 0.2188 (0.2195) gate/usage_std 0.1535 (0.1511) teacher/entropy 0.0176 (0.0511) teacher/usage_max 0.9333 (0.8342) teacher/usage_min 0.0000 (0.0376) teacher/usage_std 0.4251 (0.3573) nleep/row_max_mean 1564.6592 (1553.6172) nleep/row_max_std 57.5097 (54.9231) nleep/row_min_mean 1531.4319 (1523.2636) lr 1.9048e-03 eta 0:19:49
epoch [9/50] batch [140/181] time 0.123 (0.154) data 0.000 (0.002) loss 1.3871 (1.2934) teacher_loss 0.4400 (0.3399) loss_zs_kd 0.0032 (0.0145) loss_oracle 0.4798 (0.4773) kd_loss 0.7056 (0.7076) acc 87.5000 (87.3214) gate/entropy 0.9990 (1.0021) gate/usage_max 0.5510 (0.5474) gate/usage_min 0.2188 (0.2194) gate/usage_std 0.1540 (0.1515) teacher/entropy 0.0452 (0.0504) teacher/usage_max 0.8290 (0.8265) teacher/usage_min 0.0495 (0.0364) teacher/usage_std 0.3517 (0.3526) nleep/row_max_mean 1568.8176 (1554.2070) nleep/row_max_std 53.2447 (55.3144) nleep/row_min_mean 1538.5469 (1523.9891) lr 1.9048e-03 eta 0:19:10
epoch [9/50] batch [160/181] time 0.184 (0.149) data 0.000 (0.002) loss 1.6727 (1.2963) teacher_loss 0.5804 (0.3398) loss_zs_kd 0.0045 (0.0142) loss_oracle 0.5409 (0.4747) kd_loss 0.8197 (0.7121) acc 75.0000 (87.1094) gate/entropy 0.9981 (1.0017) gate/usage_max 0.5520 (0.5479) gate/usage_min 0.2186 (0.2193) gate/usage_std 0.1547 (0.1518) teacher/entropy 0.0777 (0.0511) teacher/usage_max 0.6695 (0.8201) teacher/usage_min 0.0361 (0.0375) teacher/usage_std 0.2601 (0.3484) nleep/row_max_mean 1555.9331 (1554.6974) nleep/row_max_std 56.8026 (55.7994) nleep/row_min_mean 1528.8696 (1524.6367) lr 1.9048e-03 eta 0:18:32
epoch [9/50] batch [180/181] time 0.173 (0.145) data 0.000 (0.002) loss 1.3607 (1.3021) teacher_loss 0.3025 (0.3416) loss_zs_kd 0.0222 (0.0146) loss_oracle 0.5070 (0.4751) kd_loss 0.7936 (0.7156) acc 87.5000 (86.9618) gate/entropy 0.9979 (1.0013) gate/usage_max 0.5523 (0.5484) gate/usage_min 0.2186 (0.2192) gate/usage_std 0.1549 (0.1521) teacher/entropy 0.0498 (0.0522) teacher/usage_max 0.7277 (0.8146) teacher/usage_min 0.0320 (0.0373) teacher/usage_std 0.2915 (0.3450) nleep/row_max_mean 1538.7356 (1554.6695) nleep/row_max_std 66.9965 (55.8891) nleep/row_min_mean 1512.6957 (1524.8522) lr 1.9048e-03 eta 0:17:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,402
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [10/50] batch [20/181] time 0.176 (0.132) data 0.000 (0.015) loss 1.5508 (1.3014) teacher_loss 0.5055 (0.3080) loss_zs_kd 0.0210 (0.0148) loss_oracle 0.4441 (0.4811) kd_loss 0.8128 (0.7455) acc 81.2500 (88.4375) gate/entropy 0.9971 (0.9974) gate/usage_max 0.5531 (0.5528) gate/usage_min 0.2184 (0.2185) gate/usage_std 0.1555 (0.1553) teacher/entropy 0.0087 (0.0536) teacher/usage_max 0.7513 (0.7744) teacher/usage_min 0.0002 (0.0377) teacher/usage_std 0.3125 (0.3197) nleep/row_max_mean 1559.2357 (1552.3220) nleep/row_max_std 57.1544 (58.2397) nleep/row_min_mean 1529.7620 (1526.2223) lr 1.8763e-03 eta 0:16:18
epoch [10/50] batch [40/181] time 0.078 (0.131) data 0.000 (0.007) loss 1.3309 (1.3140) teacher_loss 0.1974 (0.3141) loss_zs_kd 0.0212 (0.0135) loss_oracle 0.6131 (0.4919) kd_loss 0.8164 (0.7472) acc 96.8750 (88.0469) gate/entropy 0.9966 (0.9972) gate/usage_max 0.5537 (0.5531) gate/usage_min 0.2183 (0.2185) gate/usage_std 0.1559 (0.1554) teacher/entropy 0.0278 (0.0571) teacher/usage_max 0.7221 (0.7683) teacher/usage_min 0.0932 (0.0428) teacher/usage_std 0.2774 (0.3153) nleep/row_max_mean 1567.4679 (1551.7767) nleep/row_max_std 34.2091 (55.7569) nleep/row_min_mean 1541.3682 (1525.8794) lr 1.8763e-03 eta 0:16:09
epoch [10/50] batch [60/181] time 0.169 (0.126) data 0.000 (0.005) loss 1.2051 (1.3312) teacher_loss 0.1128 (0.3260) loss_zs_kd 0.0070 (0.0135) loss_oracle 0.5934 (0.5031) kd_loss 0.7922 (0.7469) acc 96.8750 (87.2917) gate/entropy 0.9966 (0.9970) gate/usage_max 0.5537 (0.5533) gate/usage_min 0.2184 (0.2184) gate/usage_std 0.1559 (0.1556) teacher/entropy 0.1206 (0.0621) teacher/usage_max 0.6483 (0.7628) teacher/usage_min 0.1088 (0.0459) teacher/usage_std 0.2294 (0.3116) nleep/row_max_mean 1541.1166 (1552.7863) nleep/row_max_std 73.2823 (57.2193) nleep/row_min_mean 1518.6841 (1526.8147) lr 1.8763e-03 eta 0:15:30
epoch [10/50] batch [80/181] time 0.166 (0.136) data 0.000 (0.004) loss 1.3310 (1.3297) teacher_loss 0.4066 (0.3265) loss_zs_kd 0.0320 (0.0140) loss_oracle 0.4589 (0.5065) kd_loss 0.6789 (0.7429) acc 87.5000 (87.6953) gate/entropy 0.9961 (0.9968) gate/usage_max 0.5543 (0.5535) gate/usage_min 0.2182 (0.2184) gate/usage_std 0.1563 (0.1557) teacher/entropy 0.0893 (0.0661) teacher/usage_max 0.8043 (0.7624) teacher/usage_min 0.0701 (0.0503) teacher/usage_std 0.3338 (0.3106) nleep/row_max_mean 1538.5011 (1551.0725) nleep/row_max_std 58.9934 (57.9307) nleep/row_min_mean 1513.6177 (1525.4557) lr 1.8763e-03 eta 0:16:36
epoch [10/50] batch [100/181] time 0.189 (0.144) data 0.000 (0.003) loss 1.3883 (1.3313) teacher_loss 0.3372 (0.3288) loss_zs_kd 0.0210 (0.0140) loss_oracle 0.6262 (0.5092) kd_loss 0.7275 (0.7409) acc 84.3750 (87.7188) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5538 (0.5537) gate/usage_min 0.2184 (0.2183) gate/usage_std 0.1560 (0.1559) teacher/entropy 0.1449 (0.0682) teacher/usage_max 0.6952 (0.7619) teacher/usage_min 0.0263 (0.0530) teacher/usage_std 0.2758 (0.3102) nleep/row_max_mean 1511.5287 (1549.1214) nleep/row_max_std 72.4253 (58.6305) nleep/row_min_mean 1489.9293 (1523.5377) lr 1.8763e-03 eta 0:17:36
epoch [10/50] batch [120/181] time 0.176 (0.150) data 0.000 (0.003) loss 1.4001 (1.3371) teacher_loss 0.3481 (0.3289) loss_zs_kd 0.0168 (0.0139) loss_oracle 0.4644 (0.5131) kd_loss 0.8114 (0.7447) acc 84.3750 (87.6562) gate/entropy 0.9955 (0.9964) gate/usage_max 0.5549 (0.5539) gate/usage_min 0.2180 (0.2183) gate/usage_std 0.1567 (0.1560) teacher/entropy 0.0693 (0.0679) teacher/usage_max 0.6833 (0.7578) teacher/usage_min 0.0607 (0.0572) teacher/usage_std 0.2600 (0.3069) nleep/row_max_mean 1540.2590 (1547.3802) nleep/row_max_std 60.5368 (58.2066) nleep/row_min_mean 1514.6416 (1522.0682) lr 1.8763e-03 eta 0:18:18
epoch [10/50] batch [140/181] time 0.114 (0.154) data 0.000 (0.002) loss 1.3801 (1.3267) teacher_loss 0.3796 (0.3245) loss_zs_kd 0.0307 (0.0141) loss_oracle 0.4467 (0.5088) kd_loss 0.7618 (0.7407) acc 84.3750 (87.8125) gate/entropy 0.9952 (0.9962) gate/usage_max 0.5552 (0.5541) gate/usage_min 0.2179 (0.2182) gate/usage_std 0.1569 (0.1562) teacher/entropy 0.0582 (0.0690) teacher/usage_max 0.7497 (0.7605) teacher/usage_min 0.0314 (0.0588) teacher/usage_std 0.3042 (0.3082) nleep/row_max_mean 1537.1403 (1546.2226) nleep/row_max_std 56.5269 (58.0370) nleep/row_min_mean 1513.8392 (1521.1097) lr 1.8763e-03 eta 0:18:39
epoch [10/50] batch [160/181] time 0.156 (0.153) data 0.000 (0.002) loss 1.2128 (1.3345) teacher_loss 0.1661 (0.3299) loss_zs_kd 0.0181 (0.0140) loss_oracle 0.5447 (0.5088) kd_loss 0.7654 (0.7432) acc 96.8750 (87.6172) gate/entropy 0.9945 (0.9961) gate/usage_max 0.5560 (0.5543) gate/usage_min 0.2177 (0.2182) gate/usage_std 0.1575 (0.1563) teacher/entropy 0.0749 (0.0679) teacher/usage_max 0.7269 (0.7588) teacher/usage_min 0.0545 (0.0584) teacher/usage_std 0.2862 (0.3072) nleep/row_max_mean 1532.4678 (1545.5561) nleep/row_max_std 55.3187 (58.0816) nleep/row_min_mean 1511.3235 (1520.4783) lr 1.8763e-03 eta 0:18:28
epoch [10/50] batch [180/181] time 0.155 (0.153) data 0.000 (0.002) loss 1.2764 (1.3282) teacher_loss 0.3968 (0.3287) loss_zs_kd 0.0185 (0.0139) loss_oracle 0.4946 (0.5070) kd_loss 0.6231 (0.7390) acc 87.5000 (87.6389) gate/entropy 0.9941 (0.9959) gate/usage_max 0.5565 (0.5545) gate/usage_min 0.2176 (0.2181) gate/usage_std 0.1578 (0.1565) teacher/entropy 0.0283 (0.0683) teacher/usage_max 0.9286 (0.7628) teacher/usage_min 0.0320 (0.0575) teacher/usage_std 0.4209 (0.3100) nleep/row_max_mean 1533.2891 (1545.4451) nleep/row_max_std 47.4294 (57.9374) nleep/row_min_mean 1510.0723 (1520.2419) lr 1.8763e-03 eta 0:18:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [11/50] batch [20/181] time 0.081 (0.120) data 0.000 (0.013) loss 1.4066 (1.3300) teacher_loss 0.4465 (0.3678) loss_zs_kd 0.0123 (0.0127) loss_oracle 0.4748 (0.5007) kd_loss 0.7165 (0.7055) acc 84.3750 (86.0938) gate/entropy 0.9939 (0.9939) gate/usage_max 0.5567 (0.5567) gate/usage_min 0.2176 (0.2176) gate/usage_std 0.1580 (0.1580) teacher/entropy 0.0235 (0.0664) teacher/usage_max 0.8334 (0.7985) teacher/usage_min 0.0313 (0.0537) teacher/usage_std 0.3561 (0.3322) nleep/row_max_mean 1550.2695 (1548.6516) nleep/row_max_std 53.1476 (56.8906) nleep/row_min_mean 1519.8671 (1521.0349) lr 1.8443e-03 eta 0:14:28
epoch [11/50] batch [40/181] time 0.141 (0.120) data 0.000 (0.007) loss 1.3326 (1.3492) teacher_loss 0.3487 (0.3536) loss_zs_kd 0.0171 (0.0134) loss_oracle 0.4406 (0.5072) kd_loss 0.7551 (0.7353) acc 81.2500 (86.5625) gate/entropy 0.9932 (0.9937) gate/usage_max 0.5574 (0.5569) gate/usage_min 0.2174 (0.2175) gate/usage_std 0.1585 (0.1582) teacher/entropy 0.0241 (0.0642) teacher/usage_max 0.7893 (0.7686) teacher/usage_min 0.0560 (0.0559) teacher/usage_std 0.3249 (0.3146) nleep/row_max_mean 1560.4001 (1547.0539) nleep/row_max_std 54.9882 (56.1091) nleep/row_min_mean 1529.5342 (1520.1335) lr 1.8443e-03 eta 0:14:22
epoch [11/50] batch [60/181] time 0.091 (0.117) data 0.000 (0.005) loss 1.0730 (1.3239) teacher_loss 0.1311 (0.3303) loss_zs_kd 0.0082 (0.0129) loss_oracle 0.3997 (0.5001) kd_loss 0.7380 (0.7372) acc 93.7500 (87.3958) gate/entropy 0.9935 (0.9935) gate/usage_max 0.5572 (0.5571) gate/usage_min 0.2176 (0.2175) gate/usage_std 0.1583 (0.1582) teacher/entropy 0.0917 (0.0651) teacher/usage_max 0.7371 (0.7657) teacher/usage_min 0.0313 (0.0525) teacher/usage_std 0.2970 (0.3128) nleep/row_max_mean 1530.0120 (1545.8591) nleep/row_max_std 65.4897 (57.6186) nleep/row_min_mean 1502.8381 (1518.8872) lr 1.8443e-03 eta 0:13:57
epoch [11/50] batch [80/181] time 0.179 (0.113) data 0.000 (0.003) loss 1.4794 (1.3450) teacher_loss 0.5323 (0.3449) loss_zs_kd 0.0190 (0.0140) loss_oracle 0.5358 (0.5047) kd_loss 0.6697 (0.7407) acc 81.2500 (87.3438) gate/entropy 0.9927 (0.9934) gate/usage_max 0.5580 (0.5573) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1589 (0.1584) teacher/entropy 0.0565 (0.0650) teacher/usage_max 0.8457 (0.7618) teacher/usage_min 0.0530 (0.0539) teacher/usage_std 0.3628 (0.3104) nleep/row_max_mean 1546.6104 (1545.5561) nleep/row_max_std 63.1936 (57.0808) nleep/row_min_mean 1514.2529 (1518.4975) lr 1.8443e-03 eta 0:13:30
epoch [11/50] batch [100/181] time 0.083 (0.112) data 0.000 (0.003) loss 1.1186 (1.3386) teacher_loss 0.2010 (0.3409) loss_zs_kd 0.0094 (0.0138) loss_oracle 0.4683 (0.5047) kd_loss 0.6787 (0.7384) acc 90.6250 (87.3125) gate/entropy 0.9922 (0.9932) gate/usage_max 0.5585 (0.5575) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1593 (0.1585) teacher/entropy 0.0545 (0.0642) teacher/usage_max 0.8383 (0.7649) teacher/usage_min 0.0328 (0.0528) teacher/usage_std 0.3592 (0.3127) nleep/row_max_mean 1545.0963 (1545.7793) nleep/row_max_std 54.0942 (56.3862) nleep/row_min_mean 1519.8887 (1518.5701) lr 1.8443e-03 eta 0:13:18
epoch [11/50] batch [120/181] time 0.170 (0.114) data 0.000 (0.002) loss 1.3315 (1.3436) teacher_loss 0.3288 (0.3441) loss_zs_kd 0.0259 (0.0139) loss_oracle 0.4537 (0.5020) kd_loss 0.7629 (0.7416) acc 87.5000 (87.0573) gate/entropy 0.9922 (0.9930) gate/usage_max 0.5586 (0.5577) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1593 (0.1587) teacher/entropy 0.0803 (0.0630) teacher/usage_max 0.7217 (0.7626) teacher/usage_min 0.0185 (0.0517) teacher/usage_std 0.2918 (0.3114) nleep/row_max_mean 1537.7140 (1545.6672) nleep/row_max_std 66.1459 (56.3020) nleep/row_min_mean 1509.4192 (1518.3975) lr 1.8443e-03 eta 0:13:30
epoch [11/50] batch [140/181] time 0.139 (0.116) data 0.000 (0.002) loss 1.2196 (1.3494) teacher_loss 0.2302 (0.3426) loss_zs_kd 0.0131 (0.0144) loss_oracle 0.5503 (0.5123) kd_loss 0.7077 (0.7435) acc 90.6250 (86.9643) gate/entropy 0.9917 (0.9928) gate/usage_max 0.5591 (0.5579) gate/usage_min 0.2171 (0.2173) gate/usage_std 0.1597 (0.1588) teacher/entropy 0.0248 (0.0620) teacher/usage_max 0.8356 (0.7615) teacher/usage_min 0.0389 (0.0518) teacher/usage_std 0.3569 (0.3106) nleep/row_max_mean 1550.8302 (1545.5859) nleep/row_max_std 49.9290 (56.7449) nleep/row_min_mean 1523.3193 (1518.2516) lr 1.8443e-03 eta 0:13:40
epoch [11/50] batch [160/181] time 0.144 (0.115) data 0.000 (0.002) loss 1.4187 (1.3539) teacher_loss 0.2752 (0.3419) loss_zs_kd 0.0022 (0.0145) loss_oracle 0.6711 (0.5198) kd_loss 0.8068 (0.7449) acc 87.5000 (87.0117) gate/entropy 0.9915 (0.9927) gate/usage_max 0.5593 (0.5580) gate/usage_min 0.2170 (0.2173) gate/usage_std 0.1598 (0.1589) teacher/entropy 0.0564 (0.0633) teacher/usage_max 0.6968 (0.7583) teacher/usage_min 0.1241 (0.0564) teacher/usage_std 0.2580 (0.3078) nleep/row_max_mean 1546.2664 (1544.6329) nleep/row_max_std 60.5743 (57.7223) nleep/row_min_mean 1520.5376 (1517.3009) lr 1.8443e-03 eta 0:13:30
epoch [11/50] batch [180/181] time 0.170 (0.118) data 0.000 (0.002) loss 1.3446 (1.3525) teacher_loss 0.2614 (0.3357) loss_zs_kd 0.0227 (0.0144) loss_oracle 0.5858 (0.5321) kd_loss 0.7789 (0.7435) acc 90.6250 (87.3264) gate/entropy 0.9912 (0.9925) gate/usage_max 0.5596 (0.5582) gate/usage_min 0.2169 (0.2173) gate/usage_std 0.1600 (0.1590) teacher/entropy 0.0060 (0.0625) teacher/usage_max 0.7813 (0.7604) teacher/usage_min 0.0618 (0.0569) teacher/usage_std 0.3192 (0.3089) nleep/row_max_mean 1547.7048 (1544.6508) nleep/row_max_std 58.4686 (58.1596) nleep/row_min_mean 1517.8328 (1517.3217) lr 1.8443e-03 eta 0:13:50
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [12/50] batch [20/181] time 0.138 (0.170) data 0.000 (0.014) loss 1.1237 (1.3110) teacher_loss 0.1418 (0.3078) loss_zs_kd 0.0155 (0.0180) loss_oracle 0.5710 (0.5951) kd_loss 0.6886 (0.6966) acc 96.8750 (89.0625) gate/entropy 0.9910 (0.9912) gate/usage_max 0.5598 (0.5597) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1602 (0.1601) teacher/entropy 0.0656 (0.0825) teacher/usage_max 0.8126 (0.7866) teacher/usage_min 0.0897 (0.0751) teacher/usage_std 0.3389 (0.3222) nleep/row_max_mean 1545.2611 (1544.2617) nleep/row_max_std 68.1878 (60.1928) nleep/row_min_mean 1516.6602 (1517.4033) lr 1.8090e-03 eta 0:19:54
epoch [12/50] batch [40/181] time 0.160 (0.161) data 0.000 (0.007) loss 1.3456 (1.3466) teacher_loss 0.3754 (0.3115) loss_zs_kd 0.0284 (0.0157) loss_oracle 0.6162 (0.6135) kd_loss 0.6479 (0.7205) acc 87.5000 (89.0625) gate/entropy 0.9909 (0.9912) gate/usage_max 0.5600 (0.5597) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1603 (0.1601) teacher/entropy 0.0610 (0.0849) teacher/usage_max 0.8607 (0.7584) teacher/usage_min 0.0469 (0.0823) teacher/usage_std 0.3734 (0.3034) nleep/row_max_mean 1529.7571 (1538.9506) nleep/row_max_std 56.6256 (60.6892) nleep/row_min_mean 1506.8113 (1512.8167) lr 1.8090e-03 eta 0:18:49
epoch [12/50] batch [60/181] time 0.184 (0.159) data 0.000 (0.005) loss 1.3362 (1.3515) teacher_loss 0.3518 (0.3177) loss_zs_kd 0.0113 (0.0155) loss_oracle 0.6024 (0.6162) kd_loss 0.6776 (0.7180) acc 87.5000 (88.5417) gate/entropy 0.9907 (0.9911) gate/usage_max 0.5601 (0.5597) gate/usage_min 0.2166 (0.2168) gate/usage_std 0.1604 (0.1601) teacher/entropy 0.0538 (0.0831) teacher/usage_max 0.8354 (0.7629) teacher/usage_min 0.0553 (0.0818) teacher/usage_std 0.3557 (0.3063) nleep/row_max_mean 1537.0646 (1538.2234) nleep/row_max_std 52.5940 (59.3454) nleep/row_min_mean 1511.4021 (1512.5800) lr 1.8090e-03 eta 0:18:30
epoch [12/50] batch [80/181] time 0.153 (0.158) data 0.000 (0.004) loss 1.1989 (1.3552) teacher_loss 0.2387 (0.3183) loss_zs_kd 0.0170 (0.0150) loss_oracle 0.6267 (0.6215) kd_loss 0.6384 (0.7186) acc 87.5000 (88.3984) gate/entropy 0.9910 (0.9910) gate/usage_max 0.5599 (0.5598) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1602 (0.1602) teacher/entropy 0.0956 (0.0829) teacher/usage_max 0.8366 (0.7622) teacher/usage_min 0.0191 (0.0847) teacher/usage_std 0.3595 (0.3054) nleep/row_max_mean 1524.3042 (1538.6422) nleep/row_max_std 70.0041 (59.6385) nleep/row_min_mean 1500.5027 (1512.7382) lr 1.8090e-03 eta 0:18:25
epoch [12/50] batch [100/181] time 0.098 (0.149) data 0.000 (0.003) loss 1.2098 (1.3591) teacher_loss 0.2975 (0.3198) loss_zs_kd 0.0117 (0.0146) loss_oracle 0.4784 (0.6273) kd_loss 0.6672 (0.7184) acc 90.6250 (88.3125) gate/entropy 0.9905 (0.9910) gate/usage_max 0.5603 (0.5599) gate/usage_min 0.2164 (0.2167) gate/usage_std 0.1605 (0.1602) teacher/entropy 0.0841 (0.0845) teacher/usage_max 0.8153 (0.7605) teacher/usage_min 0.0672 (0.0877) teacher/usage_std 0.3414 (0.3040) nleep/row_max_mean 1551.2742 (1538.9199) nleep/row_max_std 70.3874 (60.0051) nleep/row_min_mean 1521.5757 (1512.9359) lr 1.8090e-03 eta 0:17:13
epoch [12/50] batch [120/181] time 0.103 (0.142) data 0.000 (0.002) loss 1.3908 (1.3638) teacher_loss 0.4236 (0.3281) loss_zs_kd 0.0099 (0.0144) loss_oracle 0.5750 (0.6246) kd_loss 0.6748 (0.7162) acc 84.3750 (87.7604) gate/entropy 0.9905 (0.9909) gate/usage_max 0.5604 (0.5599) gate/usage_min 0.2163 (0.2166) gate/usage_std 0.1606 (0.1603) teacher/entropy 0.0649 (0.0807) teacher/usage_max 0.8271 (0.7668) teacher/usage_min 0.0813 (0.0849) teacher/usage_std 0.3492 (0.3083) nleep/row_max_mean 1556.8108 (1539.7845) nleep/row_max_std 67.7835 (60.1701) nleep/row_min_mean 1524.5510 (1513.3310) lr 1.8090e-03 eta 0:16:28
epoch [12/50] batch [140/181] time 0.080 (0.143) data 0.001 (0.002) loss 1.4894 (1.3607) teacher_loss 0.4102 (0.3286) loss_zs_kd 0.0150 (0.0149) loss_oracle 0.6258 (0.6179) kd_loss 0.7588 (0.7158) acc 81.2500 (87.8795) gate/entropy 0.9906 (0.9908) gate/usage_max 0.5603 (0.5600) gate/usage_min 0.2163 (0.2166) gate/usage_std 0.1605 (0.1603) teacher/entropy 0.0281 (0.0788) teacher/usage_max 0.7786 (0.7693) teacher/usage_min 0.0622 (0.0845) teacher/usage_std 0.3173 (0.3100) nleep/row_max_mean 1533.3331 (1539.6839) nleep/row_max_std 59.4425 (60.1003) nleep/row_min_mean 1508.8467 (1513.1362) lr 1.8090e-03 eta 0:16:27
epoch [12/50] batch [160/181] time 0.079 (0.139) data 0.000 (0.002) loss 1.5859 (1.3579) teacher_loss 0.5328 (0.3334) loss_zs_kd 0.0209 (0.0154) loss_oracle 0.6077 (0.6088) kd_loss 0.7389 (0.7124) acc 84.3750 (87.7148) gate/entropy 0.9902 (0.9907) gate/usage_max 0.5607 (0.5601) gate/usage_min 0.2161 (0.2165) gate/usage_std 0.1608 (0.1604) teacher/entropy 0.0563 (0.0760) teacher/usage_max 0.7669 (0.7759) teacher/usage_min 0.0798 (0.0817) teacher/usage_std 0.3080 (0.3146) nleep/row_max_mean 1530.4008 (1540.0031) nleep/row_max_std 64.6823 (59.9658) nleep/row_min_mean 1506.1890 (1513.1635) lr 1.8090e-03 eta 0:16:00
epoch [12/50] batch [180/181] time 0.084 (0.135) data 0.000 (0.002) loss 1.1391 (1.3528) teacher_loss 0.1233 (0.3329) loss_zs_kd 0.0060 (0.0151) loss_oracle 0.5696 (0.6054) kd_loss 0.7280 (0.7096) acc 96.8750 (87.6562) gate/entropy 0.9901 (0.9907) gate/usage_max 0.5608 (0.5602) gate/usage_min 0.2161 (0.2165) gate/usage_std 0.1609 (0.1604) teacher/entropy 0.0747 (0.0740) teacher/usage_max 0.7599 (0.7810) teacher/usage_min 0.1142 (0.0789) teacher/usage_std 0.3016 (0.3182) nleep/row_max_mean 1544.0103 (1540.0556) nleep/row_max_std 68.8624 (60.3093) nleep/row_min_mean 1516.4871 (1512.9251) lr 1.8090e-03 eta 0:15:27
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [13/50] batch [20/181] time 0.076 (0.141) data 0.000 (0.017) loss 1.3008 (1.2884) teacher_loss 0.3525 (0.3498) loss_zs_kd 0.0124 (0.0148) loss_oracle 0.5777 (0.5449) kd_loss 0.6533 (0.6588) acc 87.5000 (87.5000) gate/entropy 0.9902 (0.9899) gate/usage_max 0.5606 (0.5611) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1608 (0.1611) teacher/entropy 0.0982 (0.0638) teacher/usage_max 0.8171 (0.8458) teacher/usage_min 0.0428 (0.0515) teacher/usage_std 0.3443 (0.3633) nleep/row_max_mean 1530.2095 (1540.6755) nleep/row_max_std 71.3725 (65.1097) nleep/row_min_mean 1503.0438 (1511.2034) lr 1.7705e-03 eta 0:16:03
epoch [13/50] batch [40/181] time 0.135 (0.136) data 0.000 (0.009) loss 1.5114 (1.2947) teacher_loss 0.4296 (0.3457) loss_zs_kd 0.0168 (0.0161) loss_oracle 0.6227 (0.5684) kd_loss 0.7620 (0.6567) acc 84.3750 (86.7969) gate/entropy 0.9897 (0.9897) gate/usage_max 0.5613 (0.5612) gate/usage_min 0.2159 (0.2159) gate/usage_std 0.1612 (0.1612) teacher/entropy 0.0611 (0.0700) teacher/usage_max 0.7405 (0.8414) teacher/usage_min 0.0412 (0.0460) teacher/usage_std 0.2969 (0.3609) nleep/row_max_mean 1531.7878 (1539.7430) nleep/row_max_std 63.9837 (65.0258) nleep/row_min_mean 1505.9731 (1510.7919) lr 1.7705e-03 eta 0:15:28
epoch [13/50] batch [60/181] time 0.162 (0.144) data 0.001 (0.006) loss 1.3614 (1.2931) teacher_loss 0.5357 (0.3318) loss_zs_kd 0.0099 (0.0161) loss_oracle 0.5177 (0.5851) kd_loss 0.5619 (0.6607) acc 84.3750 (87.3438) gate/entropy 0.9890 (0.9896) gate/usage_max 0.5620 (0.5613) gate/usage_min 0.2157 (0.2159) gate/usage_std 0.1617 (0.1612) teacher/entropy 0.0179 (0.0698) teacher/usage_max 0.9962 (0.8372) teacher/usage_min 0.0013 (0.0491) teacher/usage_std 0.4687 (0.3578) nleep/row_max_mean 1553.9431 (1539.0095) nleep/row_max_std 69.2595 (66.0339) nleep/row_min_mean 1519.6323 (1510.4597) lr 1.7705e-03 eta 0:16:19
epoch [13/50] batch [80/181] time 0.174 (0.149) data 0.000 (0.005) loss 1.1304 (1.2876) teacher_loss 0.1312 (0.3267) loss_zs_kd 0.0166 (0.0152) loss_oracle 0.6175 (0.5939) kd_loss 0.6821 (0.6564) acc 100.0000 (87.7344) gate/entropy 0.9897 (0.9896) gate/usage_max 0.5613 (0.5614) gate/usage_min 0.2159 (0.2159) gate/usage_std 0.1612 (0.1613) teacher/entropy 0.0702 (0.0704) teacher/usage_max 0.8156 (0.8410) teacher/usage_min 0.0197 (0.0480) teacher/usage_std 0.3461 (0.3604) nleep/row_max_mean 1524.9792 (1539.3363) nleep/row_max_std 56.9966 (65.0137) nleep/row_min_mean 1501.1564 (1511.1360) lr 1.7705e-03 eta 0:16:51
epoch [13/50] batch [100/181] time 0.147 (0.153) data 0.000 (0.004) loss 1.2452 (1.2959) teacher_loss 0.2680 (0.3343) loss_zs_kd 0.0039 (0.0150) loss_oracle 0.5694 (0.5960) kd_loss 0.6905 (0.6561) acc 87.5000 (87.5625) gate/entropy 0.9891 (0.9895) gate/usage_max 0.5619 (0.5615) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1616 (0.1613) teacher/entropy 0.0609 (0.0722) teacher/usage_max 0.8159 (0.8392) teacher/usage_min 0.0201 (0.0495) teacher/usage_std 0.3462 (0.3592) nleep/row_max_mean 1547.1506 (1539.1220) nleep/row_max_std 49.2722 (64.5568) nleep/row_min_mean 1520.5916 (1511.3454) lr 1.7705e-03 eta 0:17:14
epoch [13/50] batch [120/181] time 0.163 (0.155) data 0.000 (0.003) loss 1.3222 (1.3107) teacher_loss 0.3918 (0.3388) loss_zs_kd 0.0083 (0.0151) loss_oracle 0.5394 (0.6027) kd_loss 0.6565 (0.6630) acc 81.2500 (87.0573) gate/entropy 0.9888 (0.9894) gate/usage_max 0.5622 (0.5616) gate/usage_min 0.2155 (0.2158) gate/usage_std 0.1619 (0.1614) teacher/entropy 0.0959 (0.0744) teacher/usage_max 0.8122 (0.8294) teacher/usage_min 0.0808 (0.0554) teacher/usage_std 0.3388 (0.3522) nleep/row_max_mean 1552.9497 (1539.9522) nleep/row_max_std 61.9342 (63.7565) nleep/row_min_mean 1523.7335 (1512.4252) lr 1.7705e-03 eta 0:17:27
epoch [13/50] batch [140/181] time 0.180 (0.158) data 0.000 (0.003) loss 1.0200 (1.3138) teacher_loss 0.1796 (0.3417) loss_zs_kd 0.0024 (0.0147) loss_oracle 0.5550 (0.6045) kd_loss 0.5617 (0.6625) acc 90.6250 (86.8527) gate/entropy 0.9889 (0.9893) gate/usage_max 0.5621 (0.5617) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1618 (0.1615) teacher/entropy 0.0966 (0.0747) teacher/usage_max 0.9123 (0.8294) teacher/usage_min 0.0397 (0.0563) teacher/usage_std 0.4094 (0.3521) nleep/row_max_mean 1556.8112 (1540.9674) nleep/row_max_std 63.8524 (62.8731) nleep/row_min_mean 1528.6846 (1513.6502) lr 1.7705e-03 eta 0:17:44
epoch [13/50] batch [160/181] time 0.071 (0.159) data 0.000 (0.002) loss 1.2756 (1.3145) teacher_loss 0.2927 (0.3396) loss_zs_kd 0.0022 (0.0147) loss_oracle 0.5823 (0.6062) kd_loss 0.6906 (0.6645) acc 93.7500 (86.8945) gate/entropy 0.9887 (0.9892) gate/usage_max 0.5623 (0.5617) gate/usage_min 0.2154 (0.2157) gate/usage_std 0.1619 (0.1615) teacher/entropy 0.0898 (0.0775) teacher/usage_max 0.7822 (0.8242) teacher/usage_min 0.1008 (0.0592) teacher/usage_std 0.3174 (0.3484) nleep/row_max_mean 1559.2871 (1541.9038) nleep/row_max_std 68.0381 (62.4097) nleep/row_min_mean 1532.9800 (1514.8935) lr 1.7705e-03 eta 0:17:49
epoch [13/50] batch [180/181] time 0.165 (0.152) data 0.000 (0.002) loss 1.5411 (1.3261) teacher_loss 0.3763 (0.3401) loss_zs_kd 0.0210 (0.0147) loss_oracle 0.7479 (0.6159) kd_loss 0.7804 (0.6707) acc 84.3750 (87.0312) gate/entropy 0.9885 (0.9892) gate/usage_max 0.5625 (0.5618) gate/usage_min 0.2152 (0.2157) gate/usage_std 0.1621 (0.1616) teacher/entropy 0.1129 (0.0783) teacher/usage_max 0.6625 (0.8165) teacher/usage_min 0.1471 (0.0627) teacher/usage_std 0.2334 (0.3430) nleep/row_max_mean 1558.1777 (1542.7581) nleep/row_max_std 51.1549 (62.2717) nleep/row_min_mean 1534.1080 (1515.9463) lr 1.7705e-03 eta 0:17:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [14/50] batch [20/181] time 0.098 (0.131) data 0.000 (0.018) loss 1.3185 (1.4200) teacher_loss 0.3092 (0.3490) loss_zs_kd 0.0256 (0.0193) loss_oracle 0.6474 (0.6643) kd_loss 0.6728 (0.7293) acc 90.6250 (87.3438) gate/entropy 0.9890 (0.9886) gate/usage_max 0.5620 (0.5624) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1617 (0.1620) teacher/entropy 0.0963 (0.0993) teacher/usage_max 0.7956 (0.7298) teacher/usage_min 0.0720 (0.0914) teacher/usage_std 0.3278 (0.2836) nleep/row_max_mean 1537.2876 (1547.6850) nleep/row_max_std 56.9828 (61.5937) nleep/row_min_mean 1515.0405 (1523.4292) lr 1.7290e-03 eta 0:14:32
epoch [14/50] batch [40/181] time 0.092 (0.119) data 0.000 (0.009) loss 1.4168 (1.4028) teacher_loss 0.3917 (0.3483) loss_zs_kd 0.0091 (0.0171) loss_oracle 0.5890 (0.6547) kd_loss 0.7261 (0.7186) acc 84.3750 (86.7969) gate/entropy 0.9887 (0.9886) gate/usage_max 0.5623 (0.5624) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1619 (0.1620) teacher/entropy 0.1045 (0.0982) teacher/usage_max 0.7266 (0.7428) teacher/usage_min 0.1110 (0.0948) teacher/usage_std 0.2789 (0.2917) nleep/row_max_mean 1540.6121 (1547.1894) nleep/row_max_std 79.7927 (62.1479) nleep/row_min_mean 1516.3088 (1522.9387) lr 1.7290e-03 eta 0:13:14
epoch [14/50] batch [60/181] time 0.077 (0.119) data 0.001 (0.006) loss 1.2394 (1.4036) teacher_loss 0.1706 (0.3531) loss_zs_kd 0.0119 (0.0164) loss_oracle 0.5649 (0.6424) kd_loss 0.7804 (0.7212) acc 96.8750 (86.3021) gate/entropy 0.9882 (0.9886) gate/usage_max 0.5628 (0.5624) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1623 (0.1620) teacher/entropy 0.0527 (0.0937) teacher/usage_max 0.7279 (0.7453) teacher/usage_min 0.0816 (0.0920) teacher/usage_std 0.2825 (0.2938) nleep/row_max_mean 1565.6370 (1547.3872) nleep/row_max_std 51.3619 (61.5060) nleep/row_min_mean 1539.6364 (1522.9196) lr 1.7290e-03 eta 0:13:11
epoch [14/50] batch [80/181] time 0.095 (0.119) data 0.000 (0.005) loss 1.2903 (1.3981) teacher_loss 0.1034 (0.3452) loss_zs_kd 0.0051 (0.0153) loss_oracle 0.6806 (0.6347) kd_loss 0.8440 (0.7278) acc 100.0000 (86.9922) gate/entropy 0.9888 (0.9886) gate/usage_max 0.5621 (0.5624) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1618 (0.1620) teacher/entropy 0.0542 (0.0931) teacher/usage_max 0.6601 (0.7391) teacher/usage_min 0.0946 (0.0939) teacher/usage_std 0.2391 (0.2896) nleep/row_max_mean 1553.6724 (1547.7447) nleep/row_max_std 68.3637 (62.8788) nleep/row_min_mean 1529.0464 (1523.2877) lr 1.7290e-03 eta 0:13:09
epoch [14/50] batch [100/181] time 0.082 (0.119) data 0.000 (0.004) loss 1.4269 (1.4070) teacher_loss 0.3539 (0.3404) loss_zs_kd 0.0277 (0.0158) loss_oracle 0.6563 (0.6443) kd_loss 0.7311 (0.7365) acc 87.5000 (87.4375) gate/entropy 0.9884 (0.9886) gate/usage_max 0.5626 (0.5624) gate/usage_min 0.2149 (0.2151) gate/usage_std 0.1621 (0.1620) teacher/entropy 0.1032 (0.0956) teacher/usage_max 0.7244 (0.7271) teacher/usage_min 0.1270 (0.1011) teacher/usage_std 0.2767 (0.2810) nleep/row_max_mean 1546.2754 (1546.8441) nleep/row_max_std 68.8034 (63.2822) nleep/row_min_mean 1523.4290 (1522.6337) lr 1.7290e-03 eta 0:13:04
epoch [14/50] batch [120/181] time 0.145 (0.120) data 0.000 (0.003) loss 1.5675 (1.4052) teacher_loss 0.5599 (0.3308) loss_zs_kd 0.0070 (0.0153) loss_oracle 0.5590 (0.6443) kd_loss 0.7246 (0.7446) acc 81.2500 (87.8385) gate/entropy 0.9880 (0.9886) gate/usage_max 0.5630 (0.5624) gate/usage_min 0.2147 (0.2151) gate/usage_std 0.1624 (0.1620) teacher/entropy 0.0303 (0.0942) teacher/usage_max 0.8079 (0.7201) teacher/usage_min 0.0928 (0.1023) teacher/usage_std 0.3356 (0.2768) nleep/row_max_mean 1578.6528 (1546.2511) nleep/row_max_std 64.7680 (63.4397) nleep/row_min_mean 1545.8484 (1522.0856) lr 1.7290e-03 eta 0:13:12
epoch [14/50] batch [140/181] time 0.174 (0.127) data 0.000 (0.003) loss 1.2966 (1.4049) teacher_loss 0.2897 (0.3336) loss_zs_kd 0.0257 (0.0157) loss_oracle 0.5541 (0.6444) kd_loss 0.7171 (0.7413) acc 84.3750 (87.6339) gate/entropy 0.9887 (0.9886) gate/usage_max 0.5623 (0.5624) gate/usage_min 0.2149 (0.2151) gate/usage_std 0.1620 (0.1620) teacher/entropy 0.0625 (0.0937) teacher/usage_max 0.7848 (0.7241) teacher/usage_min 0.0611 (0.0998) teacher/usage_std 0.3215 (0.2797) nleep/row_max_mean 1537.9061 (1546.3489) nleep/row_max_std 65.1230 (63.4582) nleep/row_min_mean 1513.0638 (1521.9500) lr 1.7290e-03 eta 0:13:50
epoch [14/50] batch [160/181] time 0.178 (0.133) data 0.000 (0.002) loss 1.4456 (1.4038) teacher_loss 0.2913 (0.3316) loss_zs_kd 0.0156 (0.0160) loss_oracle 0.6296 (0.6421) kd_loss 0.8318 (0.7432) acc 84.3750 (87.5977) gate/entropy 0.9887 (0.9886) gate/usage_max 0.5623 (0.5624) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1619 (0.1620) teacher/entropy 0.1056 (0.0922) teacher/usage_max 0.6188 (0.7238) teacher/usage_min 0.1078 (0.0996) teacher/usage_std 0.2129 (0.2795) nleep/row_max_mean 1536.2466 (1546.3747) nleep/row_max_std 64.1245 (63.3591) nleep/row_min_mean 1512.8657 (1521.7341) lr 1.7290e-03 eta 0:14:30
epoch [14/50] batch [180/181] time 0.135 (0.137) data 0.000 (0.002) loss 1.4981 (1.4052) teacher_loss 0.3299 (0.3285) loss_zs_kd 0.0216 (0.0162) loss_oracle 0.6216 (0.6415) kd_loss 0.8466 (0.7478) acc 90.6250 (87.5521) gate/entropy 0.9886 (0.9886) gate/usage_max 0.5624 (0.5624) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1620 (0.1620) teacher/entropy 0.0876 (0.0902) teacher/usage_max 0.6208 (0.7210) teacher/usage_min 0.1386 (0.1014) teacher/usage_std 0.2075 (0.2775) nleep/row_max_mean 1552.7623 (1546.2780) nleep/row_max_std 54.5891 (63.2411) nleep/row_min_mean 1526.6091 (1521.4552) lr 1.7290e-03 eta 0:14:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [15/50] batch [20/181] time 0.170 (0.177) data 0.000 (0.014) loss 1.6248 (1.3670) teacher_loss 0.4395 (0.3006) loss_zs_kd 0.0067 (0.0144) loss_oracle 0.5956 (0.5822) kd_loss 0.8841 (0.7681) acc 84.3750 (89.3750) gate/entropy 0.9888 (0.9884) gate/usage_max 0.5622 (0.5626) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1618 (0.1621) teacher/entropy 0.0644 (0.0716) teacher/usage_max 0.6035 (0.7193) teacher/usage_min 0.1725 (0.1028) teacher/usage_std 0.1922 (0.2756) nleep/row_max_mean 1532.7463 (1551.8541) nleep/row_max_std 74.2222 (64.4564) nleep/row_min_mean 1505.5579 (1524.1623) lr 1.6845e-03 eta 0:19:08
epoch [15/50] batch [40/181] time 0.098 (0.151) data 0.000 (0.007) loss 1.3851 (1.4028) teacher_loss 0.4022 (0.3299) loss_zs_kd 0.0256 (0.0164) loss_oracle 0.4828 (0.5763) kd_loss 0.7287 (0.7765) acc 84.3750 (87.4219) gate/entropy 0.9879 (0.9884) gate/usage_max 0.5631 (0.5626) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1625 (0.1622) teacher/entropy 0.0450 (0.0808) teacher/usage_max 0.7902 (0.7013) teacher/usage_min 0.0626 (0.1000) teacher/usage_std 0.3249 (0.2652) nleep/row_max_mean 1553.0715 (1547.7064) nleep/row_max_std 54.8935 (61.5232) nleep/row_min_mean 1526.5394 (1521.0220) lr 1.6845e-03 eta 0:16:15
epoch [15/50] batch [60/181] time 0.089 (0.135) data 0.000 (0.005) loss 1.4042 (1.3930) teacher_loss 0.4526 (0.3151) loss_zs_kd 0.0317 (0.0173) loss_oracle 0.5073 (0.5712) kd_loss 0.6821 (0.7837) acc 81.2500 (88.2292) gate/entropy 0.9883 (0.9884) gate/usage_max 0.5627 (0.5626) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1622 (0.1622) teacher/entropy 0.0991 (0.0822) teacher/usage_max 0.7810 (0.6920) teacher/usage_min 0.1024 (0.1046) teacher/usage_std 0.3166 (0.2589) nleep/row_max_mean 1542.3276 (1545.9505) nleep/row_max_std 58.5351 (61.2003) nleep/row_min_mean 1514.9331 (1519.7673) lr 1.6845e-03 eta 0:14:30
epoch [15/50] batch [80/181] time 0.101 (0.127) data 0.000 (0.004) loss 1.4139 (1.3959) teacher_loss 0.3056 (0.3124) loss_zs_kd 0.0162 (0.0177) loss_oracle 0.5068 (0.5610) kd_loss 0.8468 (0.7942) acc 87.5000 (88.2031) gate/entropy 0.9881 (0.9883) gate/usage_max 0.5629 (0.5627) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1623 (0.1622) teacher/entropy 0.0342 (0.0819) teacher/usage_max 0.6803 (0.6817) teacher/usage_min 0.0385 (0.1025) teacher/usage_std 0.2646 (0.2536) nleep/row_max_mean 1549.8406 (1545.1478) nleep/row_max_std 58.0480 (61.0419) nleep/row_min_mean 1520.4482 (1518.9370) lr 1.6845e-03 eta 0:13:36
epoch [15/50] batch [100/181] time 0.182 (0.126) data 0.000 (0.003) loss 1.3331 (1.3796) teacher_loss 0.3053 (0.3057) loss_zs_kd 0.0311 (0.0174) loss_oracle 0.5268 (0.5540) kd_loss 0.7489 (0.7882) acc 87.5000 (88.4688) gate/entropy 0.9882 (0.9883) gate/usage_max 0.5628 (0.5627) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1623 (0.1622) teacher/entropy 0.0605 (0.0814) teacher/usage_max 0.7524 (0.6889) teacher/usage_min 0.0942 (0.0935) teacher/usage_std 0.2973 (0.2595) nleep/row_max_mean 1534.4521 (1545.7687) nleep/row_max_std 77.9377 (60.9511) nleep/row_min_mean 1504.8785 (1519.1467) lr 1.6845e-03 eta 0:13:28
epoch [15/50] batch [120/181] time 0.161 (0.126) data 0.000 (0.003) loss 1.5529 (1.3776) teacher_loss 0.3662 (0.3071) loss_zs_kd 0.0256 (0.0173) loss_oracle 0.5569 (0.5532) kd_loss 0.8954 (0.7852) acc 84.3750 (88.3333) gate/entropy 0.9880 (0.9882) gate/usage_max 0.5630 (0.5628) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1624 (0.1623) teacher/entropy 0.1023 (0.0788) teacher/usage_max 0.5580 (0.6950) teacher/usage_min 0.0296 (0.0863) teacher/usage_std 0.2229 (0.2647) nleep/row_max_mean 1540.7996 (1546.9145) nleep/row_max_std 59.1787 (61.0281) nleep/row_min_mean 1514.7029 (1519.7575) lr 1.6845e-03 eta 0:13:22
epoch [15/50] batch [140/181] time 0.092 (0.121) data 0.000 (0.002) loss 1.3120 (1.3745) teacher_loss 0.3656 (0.3048) loss_zs_kd 0.0083 (0.0178) loss_oracle 0.5332 (0.5527) kd_loss 0.6757 (0.7844) acc 84.3750 (88.4152) gate/entropy 0.9875 (0.9881) gate/usage_max 0.5636 (0.5629) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1629 (0.1623) teacher/entropy 0.1143 (0.0782) teacher/usage_max 0.7725 (0.6966) teacher/usage_min 0.0679 (0.0815) teacher/usage_std 0.3128 (0.2664) nleep/row_max_mean 1556.1261 (1547.1095) nleep/row_max_std 71.0120 (61.7012) nleep/row_min_mean 1523.0701 (1519.4695) lr 1.6845e-03 eta 0:12:52
epoch [15/50] batch [160/181] time 0.089 (0.121) data 0.000 (0.002) loss 1.7842 (1.3735) teacher_loss 0.5909 (0.3049) loss_zs_kd 0.0394 (0.0179) loss_oracle 0.5473 (0.5531) kd_loss 0.8999 (0.7831) acc 78.1250 (88.4766) gate/entropy 0.9875 (0.9881) gate/usage_max 0.5635 (0.5629) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1628 (0.1624) teacher/entropy 0.0436 (0.0765) teacher/usage_max 0.6145 (0.6999) teacher/usage_min 0.0160 (0.0765) teacher/usage_std 0.2457 (0.2695) nleep/row_max_mean 1543.5432 (1547.2551) nleep/row_max_std 59.5874 (62.2483) nleep/row_min_mean 1509.8613 (1519.1346) lr 1.6845e-03 eta 0:12:49
epoch [15/50] batch [180/181] time 0.080 (0.120) data 0.000 (0.002) loss 1.1779 (1.3703) teacher_loss 0.2406 (0.3044) loss_zs_kd 0.0160 (0.0185) loss_oracle 0.4786 (0.5543) kd_loss 0.6900 (0.7795) acc 87.5000 (88.5590) gate/entropy 0.9869 (0.9880) gate/usage_max 0.5642 (0.5630) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1633 (0.1625) teacher/entropy 0.0017 (0.0754) teacher/usage_max 0.8750 (0.7050) teacher/usage_min 0.0315 (0.0718) teacher/usage_std 0.3838 (0.2734) nleep/row_max_mean 1573.2581 (1547.3947) nleep/row_max_std 56.5503 (62.5011) nleep/row_min_mean 1531.1873 (1518.6951) lr 1.6845e-03 eta 0:12:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [16/50] batch [20/181] time 0.135 (0.158) data 0.000 (0.014) loss 1.4729 (1.4010) teacher_loss 0.4057 (0.2996) loss_zs_kd 0.0219 (0.0206) loss_oracle 0.5472 (0.5993) kd_loss 0.7826 (0.7914) acc 81.2500 (87.9688) gate/entropy 0.9867 (0.9872) gate/usage_max 0.5644 (0.5639) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1634 (0.1631) teacher/entropy 0.0850 (0.0495) teacher/usage_max 0.6928 (0.7207) teacher/usage_min 0.0304 (0.0284) teacher/usage_std 0.2734 (0.2915) nleep/row_max_mean 1560.7102 (1543.6388) nleep/row_max_std 55.5858 (63.8945) nleep/row_min_mean 1526.2051 (1512.3182) lr 1.6374e-03 eta 0:16:39
epoch [16/50] batch [40/181] time 0.151 (0.159) data 0.000 (0.007) loss 1.3110 (1.4063) teacher_loss 0.2489 (0.3072) loss_zs_kd 0.0255 (0.0190) loss_oracle 0.6464 (0.6120) kd_loss 0.7261 (0.7837) acc 96.8750 (87.9688) gate/entropy 0.9867 (0.9871) gate/usage_max 0.5644 (0.5640) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1634 (0.1631) teacher/entropy 0.0247 (0.0542) teacher/usage_max 0.8130 (0.7233) teacher/usage_min 0.0476 (0.0384) teacher/usage_std 0.3412 (0.2910) nleep/row_max_mean 1566.1331 (1545.5263) nleep/row_max_std 54.3963 (66.5836) nleep/row_min_mean 1530.4152 (1513.8425) lr 1.6374e-03 eta 0:16:43
epoch [16/50] batch [60/181] time 0.164 (0.158) data 0.000 (0.005) loss 1.6996 (1.4199) teacher_loss 0.4461 (0.3126) loss_zs_kd 0.0282 (0.0204) loss_oracle 0.7315 (0.6309) kd_loss 0.8736 (0.7816) acc 78.1250 (87.9167) gate/entropy 0.9869 (0.9871) gate/usage_max 0.5643 (0.5640) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1633 (0.1632) teacher/entropy 0.0590 (0.0540) teacher/usage_max 0.6233 (0.7253) teacher/usage_min 0.0673 (0.0458) teacher/usage_std 0.2276 (0.2899) nleep/row_max_mean 1550.8357 (1546.1589) nleep/row_max_std 67.2406 (66.8449) nleep/row_min_mean 1522.5880 (1514.7877) lr 1.6374e-03 eta 0:16:34
epoch [16/50] batch [80/181] time 0.174 (0.160) data 0.000 (0.004) loss 1.1147 (1.4276) teacher_loss 0.0960 (0.3066) loss_zs_kd 0.0141 (0.0211) loss_oracle 0.5877 (0.6348) kd_loss 0.7179 (0.7930) acc 100.0000 (88.3594) gate/entropy 0.9869 (0.9870) gate/usage_max 0.5642 (0.5641) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1633 (0.1632) teacher/entropy 0.0984 (0.0584) teacher/usage_max 0.7445 (0.7084) teacher/usage_min 0.0811 (0.0560) teacher/usage_std 0.2933 (0.2783) nleep/row_max_mean 1544.8011 (1546.9834) nleep/row_max_std 77.7146 (65.7179) nleep/row_min_mean 1517.2217 (1516.4048) lr 1.6374e-03 eta 0:16:40
epoch [16/50] batch [100/181] time 0.189 (0.162) data 0.000 (0.003) loss 1.3420 (1.4370) teacher_loss 0.0810 (0.3061) loss_zs_kd 0.0081 (0.0218) loss_oracle 0.6838 (0.6334) kd_loss 0.9150 (0.8032) acc 96.8750 (88.1875) gate/entropy 0.9870 (0.9870) gate/usage_max 0.5641 (0.5641) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1632 (0.1632) teacher/entropy 0.0643 (0.0571) teacher/usage_max 0.5714 (0.6988) teacher/usage_min 0.1895 (0.0670) teacher/usage_std 0.1696 (0.2708) nleep/row_max_mean 1557.2700 (1548.3382) nleep/row_max_std 62.4096 (65.2024) nleep/row_min_mean 1529.1084 (1518.0958) lr 1.6374e-03 eta 0:16:49
epoch [16/50] batch [120/181] time 0.142 (0.161) data 0.000 (0.003) loss 1.4927 (1.4379) teacher_loss 0.4588 (0.3050) loss_zs_kd 0.0226 (0.0218) loss_oracle 0.5259 (0.6273) kd_loss 0.7596 (0.8084) acc 84.3750 (88.4115) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5643 (0.5641) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0611 (0.0567) teacher/usage_max 0.7392 (0.6936) teacher/usage_min 0.0746 (0.0714) teacher/usage_std 0.2906 (0.2669) nleep/row_max_mean 1539.2471 (1549.4858) nleep/row_max_std 68.0029 (64.2746) nleep/row_min_mean 1512.4088 (1519.6086) lr 1.6374e-03 eta 0:16:40
epoch [16/50] batch [140/181] time 0.102 (0.156) data 0.000 (0.002) loss 1.4635 (1.4435) teacher_loss 0.2500 (0.3043) loss_zs_kd 0.0316 (0.0221) loss_oracle 0.6804 (0.6275) kd_loss 0.8575 (0.8144) acc 90.6250 (88.5045) gate/entropy 0.9872 (0.9869) gate/usage_max 0.5639 (0.5642) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1631 (0.1632) teacher/entropy 0.1042 (0.0577) teacher/usage_max 0.5910 (0.6861) teacher/usage_min 0.1585 (0.0777) teacher/usage_std 0.1860 (0.2611) nleep/row_max_mean 1527.0547 (1549.5289) nleep/row_max_std 61.6913 (63.7420) nleep/row_min_mean 1505.3706 (1520.1561) lr 1.6374e-03 eta 0:16:09
epoch [16/50] batch [160/181] time 0.080 (0.151) data 0.000 (0.002) loss 1.2789 (1.4470) teacher_loss 0.3207 (0.3036) loss_zs_kd 0.0162 (0.0221) loss_oracle 0.5317 (0.6292) kd_loss 0.6842 (0.8178) acc 87.5000 (88.4766) gate/entropy 0.9863 (0.9869) gate/usage_max 0.5648 (0.5642) gate/usage_min 0.2144 (0.2146) gate/usage_std 0.1637 (0.1633) teacher/entropy 0.0385 (0.0578) teacher/usage_max 0.8415 (0.6822) teacher/usage_min 0.0384 (0.0851) teacher/usage_std 0.3609 (0.2573) nleep/row_max_mean 1570.6528 (1549.3610) nleep/row_max_std 60.3212 (63.5178) nleep/row_min_mean 1540.6138 (1520.3545) lr 1.6374e-03 eta 0:15:30
epoch [16/50] batch [180/181] time 0.092 (0.147) data 0.000 (0.002) loss 1.4812 (1.4547) teacher_loss 0.4054 (0.3016) loss_zs_kd 0.0206 (0.0221) loss_oracle 0.6415 (0.6369) kd_loss 0.7448 (0.8235) acc 90.6250 (88.5764) gate/entropy 0.9866 (0.9869) gate/usage_max 0.5645 (0.5642) gate/usage_min 0.2144 (0.2146) gate/usage_std 0.1635 (0.1633) teacher/entropy 0.0419 (0.0574) teacher/usage_max 0.7726 (0.6763) teacher/usage_min 0.0973 (0.0916) teacher/usage_std 0.3109 (0.2526) nleep/row_max_mean 1561.9475 (1548.9317) nleep/row_max_std 52.6461 (63.0790) nleep/row_min_mean 1530.6350 (1520.1692) lr 1.6374e-03 eta 0:15:04
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,396
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [17/50] batch [20/181] time 0.200 (0.108) data 0.000 (0.013) loss 1.0719 (1.4290) teacher_loss 0.1032 (0.2387) loss_zs_kd 0.0245 (0.0254) loss_oracle 0.4733 (0.6441) kd_loss 0.7198 (0.8555) acc 96.8750 (90.7812) gate/entropy 0.9864 (0.9868) gate/usage_max 0.5647 (0.5643) gate/usage_min 0.2143 (0.2145) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0561 (0.0641) teacher/usage_max 0.7843 (0.6334) teacher/usage_min 0.0936 (0.1515) teacher/usage_std 0.3191 (0.2149) nleep/row_max_mean 1568.2400 (1546.1746) nleep/row_max_std 53.3186 (61.5494) nleep/row_min_mean 1535.8258 (1518.4555) lr 1.5878e-03 eta 0:11:01
epoch [17/50] batch [40/181] time 0.094 (0.110) data 0.000 (0.007) loss 1.4975 (1.4675) teacher_loss 0.1684 (0.2635) loss_zs_kd 0.0333 (0.0250) loss_oracle 0.7178 (0.6625) kd_loss 0.9535 (0.8602) acc 93.7500 (90.2344) gate/entropy 0.9870 (0.9869) gate/usage_max 0.5641 (0.5642) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1632 (0.1633) teacher/entropy 0.0695 (0.0582) teacher/usage_max 0.5259 (0.6344) teacher/usage_min 0.1929 (0.1450) teacher/usage_std 0.1408 (0.2164) nleep/row_max_mean 1535.9899 (1545.7681) nleep/row_max_std 62.4344 (63.1710) nleep/row_min_mean 1509.8315 (1517.5611) lr 1.5878e-03 eta 0:11:15
epoch [17/50] batch [60/181] time 0.154 (0.114) data 0.000 (0.004) loss 1.4614 (1.5012) teacher_loss 0.2721 (0.2770) loss_zs_kd 0.0197 (0.0243) loss_oracle 0.7727 (0.6861) kd_loss 0.7931 (0.8689) acc 96.8750 (89.8438) gate/entropy 0.9867 (0.9869) gate/usage_max 0.5644 (0.5642) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1634 (0.1633) teacher/entropy 0.1138 (0.0599) teacher/usage_max 0.6445 (0.6232) teacher/usage_min 0.1076 (0.1486) teacher/usage_std 0.2273 (0.2091) nleep/row_max_mean 1542.0112 (1544.4109) nleep/row_max_std 64.3747 (62.7518) nleep/row_min_mean 1514.1244 (1515.9934) lr 1.5878e-03 eta 0:11:32
epoch [17/50] batch [80/181] time 0.079 (0.118) data 0.000 (0.003) loss 1.4717 (1.5002) teacher_loss 0.3167 (0.2827) loss_zs_kd 0.0182 (0.0252) loss_oracle 0.6328 (0.6920) kd_loss 0.8294 (0.8589) acc 87.5000 (89.3750) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5643 (0.5642) gate/usage_min 0.2142 (0.2144) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0490 (0.0590) teacher/usage_max 0.6755 (0.6345) teacher/usage_min 0.1317 (0.1409) teacher/usage_std 0.2432 (0.2178) nleep/row_max_mean 1561.3384 (1544.3047) nleep/row_max_std 51.7930 (61.8331) nleep/row_min_mean 1526.6926 (1515.3179) lr 1.5878e-03 eta 0:11:54
epoch [17/50] batch [100/181] time 0.152 (0.117) data 0.000 (0.003) loss 1.4743 (1.5127) teacher_loss 0.4501 (0.2944) loss_zs_kd 0.0568 (0.0256) loss_oracle 0.5702 (0.6868) kd_loss 0.7107 (0.8621) acc 81.2500 (89.0312) gate/entropy 0.9871 (0.9869) gate/usage_max 0.5640 (0.5641) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1631 (0.1632) teacher/entropy 0.1388 (0.0619) teacher/usage_max 0.7066 (0.6279) teacher/usage_min 0.1195 (0.1420) teacher/usage_std 0.2649 (0.2137) nleep/row_max_mean 1524.1294 (1543.0058) nleep/row_max_std 59.2399 (61.5086) nleep/row_min_mean 1498.8204 (1513.9510) lr 1.5878e-03 eta 0:11:49
epoch [17/50] batch [120/181] time 0.172 (0.125) data 0.000 (0.002) loss 1.6469 (1.5055) teacher_loss 0.2008 (0.2934) loss_zs_kd 0.0329 (0.0254) loss_oracle 0.8502 (0.6827) kd_loss 1.0045 (0.8581) acc 90.6250 (89.0104) gate/entropy 0.9873 (0.9870) gate/usage_max 0.5637 (0.5641) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1629 (0.1632) teacher/entropy 0.0786 (0.0642) teacher/usage_max 0.4601 (0.6298) teacher/usage_min 0.2203 (0.1413) teacher/usage_std 0.0984 (0.2149) nleep/row_max_mean 1520.1300 (1543.1056) nleep/row_max_std 59.7763 (61.5741) nleep/row_min_mean 1499.4766 (1514.0878) lr 1.5878e-03 eta 0:12:32
epoch [17/50] batch [140/181] time 0.165 (0.131) data 0.000 (0.002) loss 1.4697 (1.5021) teacher_loss 0.2710 (0.2993) loss_zs_kd 0.0259 (0.0249) loss_oracle 0.6312 (0.6732) kd_loss 0.8701 (0.8538) acc 93.7500 (88.7500) gate/entropy 0.9874 (0.9870) gate/usage_max 0.5636 (0.5641) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1629 (0.1632) teacher/entropy 0.0569 (0.0655) teacher/usage_max 0.6292 (0.6329) teacher/usage_min 0.1040 (0.1407) teacher/usage_std 0.2195 (0.2168) nleep/row_max_mean 1537.8445 (1542.8329) nleep/row_max_std 57.3586 (62.0080) nleep/row_min_mean 1510.8147 (1513.8594) lr 1.5878e-03 eta 0:13:06
epoch [17/50] batch [160/181] time 0.192 (0.136) data 0.000 (0.002) loss 1.4647 (1.5013) teacher_loss 0.2504 (0.3008) loss_zs_kd 0.0293 (0.0248) loss_oracle 0.5993 (0.6668) kd_loss 0.9001 (0.8547) acc 93.7500 (88.7695) gate/entropy 0.9875 (0.9871) gate/usage_max 0.5635 (0.5640) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1628 (0.1631) teacher/entropy 0.0487 (0.0646) teacher/usage_max 0.6015 (0.6330) teacher/usage_min 0.1853 (0.1421) teacher/usage_std 0.1900 (0.2165) nleep/row_max_mean 1523.6233 (1542.1932) nleep/row_max_std 70.7603 (62.4305) nleep/row_min_mean 1498.4614 (1513.3446) lr 1.5878e-03 eta 0:13:35
epoch [17/50] batch [180/181] time 0.159 (0.139) data 0.000 (0.002) loss 1.3291 (1.4935) teacher_loss 0.2983 (0.3007) loss_zs_kd 0.0045 (0.0252) loss_oracle 0.5436 (0.6574) kd_loss 0.7568 (0.8515) acc 90.6250 (88.7674) gate/entropy 0.9877 (0.9871) gate/usage_max 0.5634 (0.5640) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1627 (0.1631) teacher/entropy 0.1193 (0.0664) teacher/usage_max 0.6822 (0.6346) teacher/usage_min 0.1017 (0.1415) teacher/usage_std 0.2511 (0.2176) nleep/row_max_mean 1530.2217 (1541.7313) nleep/row_max_std 71.5339 (62.6065) nleep/row_min_mean 1504.4703 (1513.0636) lr 1.5878e-03 eta 0:13:48
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [18/50] batch [20/181] time 0.087 (0.151) data 0.000 (0.017) loss 1.3492 (1.3731) teacher_loss 0.2983 (0.2850) loss_zs_kd 0.0134 (0.0238) loss_oracle 0.5226 (0.5411) kd_loss 0.7828 (0.8056) acc 84.3750 (88.5938) gate/entropy 0.9872 (0.9874) gate/usage_max 0.5639 (0.5637) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1631 (0.1629) teacher/entropy 0.0970 (0.0624) teacher/usage_max 0.6739 (0.6889) teacher/usage_min 0.1284 (0.1060) teacher/usage_std 0.2425 (0.2563) nleep/row_max_mean 1550.3802 (1547.3299) nleep/row_max_std 60.4941 (64.7381) nleep/row_min_mean 1525.3381 (1518.5335) lr 1.5358e-03 eta 0:14:57
epoch [18/50] batch [40/181] time 0.163 (0.130) data 0.000 (0.009) loss 1.2492 (1.3796) teacher_loss 0.2215 (0.3060) loss_zs_kd 0.0159 (0.0248) loss_oracle 0.5264 (0.5255) kd_loss 0.7566 (0.7985) acc 93.7500 (88.0469) gate/entropy 0.9867 (0.9874) gate/usage_max 0.5644 (0.5637) gate/usage_min 0.2139 (0.2141) gate/usage_std 0.1634 (0.1629) teacher/entropy 0.0368 (0.0679) teacher/usage_max 0.7681 (0.6909) teacher/usage_min 0.0763 (0.1060) teacher/usage_std 0.3091 (0.2573) nleep/row_max_mean 1571.7485 (1545.9775) nleep/row_max_std 55.9934 (64.2659) nleep/row_min_mean 1540.8186 (1517.8715) lr 1.5358e-03 eta 0:12:51
epoch [18/50] batch [60/181] time 0.069 (0.125) data 0.001 (0.006) loss 1.3621 (1.3583) teacher_loss 0.3055 (0.2865) loss_zs_kd 0.0329 (0.0247) loss_oracle 0.5270 (0.5357) kd_loss 0.7766 (0.7916) acc 90.6250 (89.0104) gate/entropy 0.9869 (0.9873) gate/usage_max 0.5641 (0.5637) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1632 (0.1629) teacher/entropy 0.0556 (0.0739) teacher/usage_max 0.7252 (0.6916) teacher/usage_min 0.1370 (0.1110) teacher/usage_std 0.2771 (0.2572) nleep/row_max_mean 1559.6277 (1545.4444) nleep/row_max_std 58.3048 (64.3723) nleep/row_min_mean 1530.3738 (1517.7732) lr 1.5358e-03 eta 0:12:20
epoch [18/50] batch [80/181] time 0.079 (0.121) data 0.000 (0.004) loss 1.5413 (1.3704) teacher_loss 0.3744 (0.2875) loss_zs_kd 0.0226 (0.0255) loss_oracle 0.6437 (0.5396) kd_loss 0.8338 (0.8003) acc 84.3750 (89.2969) gate/entropy 0.9876 (0.9873) gate/usage_max 0.5634 (0.5637) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1627 (0.1629) teacher/entropy 0.1309 (0.0762) teacher/usage_max 0.5897 (0.6806) teacher/usage_min 0.1105 (0.1047) teacher/usage_std 0.1971 (0.2521) nleep/row_max_mean 1521.3306 (1543.8403) nleep/row_max_std 65.3786 (65.1464) nleep/row_min_mean 1499.7969 (1516.4569) lr 1.5358e-03 eta 0:11:55
epoch [18/50] batch [100/181] time 0.082 (0.118) data 0.000 (0.004) loss 1.3886 (1.3767) teacher_loss 0.1307 (0.2854) loss_zs_kd 0.0279 (0.0245) loss_oracle 0.8705 (0.5623) kd_loss 0.8086 (0.7979) acc 96.8750 (89.2188) gate/entropy 0.9874 (0.9873) gate/usage_max 0.5637 (0.5638) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.0781 (0.0777) teacher/usage_max 0.6710 (0.6817) teacher/usage_min 0.1034 (0.1024) teacher/usage_std 0.2439 (0.2530) nleep/row_max_mean 1542.1384 (1544.4740) nleep/row_max_std 66.5639 (65.5717) nleep/row_min_mean 1513.8176 (1517.0093) lr 1.5358e-03 eta 0:11:34
epoch [18/50] batch [120/181] time 0.118 (0.114) data 0.000 (0.003) loss 1.4022 (1.3926) teacher_loss 0.2171 (0.2799) loss_zs_kd 0.0152 (0.0238) loss_oracle 0.7701 (0.5961) kd_loss 0.7925 (0.8027) acc 90.6250 (89.4271) gate/entropy 0.9874 (0.9873) gate/usage_max 0.5637 (0.5638) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.1211 (0.0780) teacher/usage_max 0.6436 (0.6767) teacher/usage_min 0.1024 (0.0981) teacher/usage_std 0.2279 (0.2516) nleep/row_max_mean 1527.7898 (1543.7241) nleep/row_max_std 63.2903 (65.6717) nleep/row_min_mean 1503.7771 (1516.4254) lr 1.5358e-03 eta 0:11:08
epoch [18/50] batch [140/181] time 0.084 (0.114) data 0.000 (0.003) loss 1.6623 (1.4057) teacher_loss 0.3456 (0.2748) loss_zs_kd 0.0233 (0.0235) loss_oracle 0.7416 (0.6234) kd_loss 0.9342 (0.8075) acc 87.5000 (89.6205) gate/entropy 0.9876 (0.9873) gate/usage_max 0.5634 (0.5638) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1627 (0.1630) teacher/entropy 0.1604 (0.0805) teacher/usage_max 0.4565 (0.6692) teacher/usage_min 0.1034 (0.1002) teacher/usage_std 0.1627 (0.2468) nleep/row_max_mean 1516.5144 (1543.7761) nleep/row_max_std 65.8703 (65.0340) nleep/row_min_mean 1494.0753 (1516.8002) lr 1.5358e-03 eta 0:11:03
epoch [18/50] batch [160/181] time 0.078 (0.114) data 0.000 (0.002) loss 1.5706 (1.4139) teacher_loss 0.4274 (0.2835) loss_zs_kd 0.0389 (0.0234) loss_oracle 0.6093 (0.6285) kd_loss 0.8191 (0.8044) acc 84.3750 (89.2383) gate/entropy 0.9873 (0.9873) gate/usage_max 0.5638 (0.5638) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0706 (0.0843) teacher/usage_max 0.6664 (0.6684) teacher/usage_min 0.1373 (0.1015) teacher/usage_std 0.2368 (0.2463) nleep/row_max_mean 1537.7499 (1543.8177) nleep/row_max_std 53.0156 (64.0666) nleep/row_min_mean 1515.2424 (1517.1837) lr 1.5358e-03 eta 0:11:04
epoch [18/50] batch [180/181] time 0.083 (0.114) data 0.000 (0.002) loss 1.5125 (1.4191) teacher_loss 0.2454 (0.2850) loss_zs_kd 0.0165 (0.0238) loss_oracle 0.5648 (0.6267) kd_loss 0.9765 (0.8089) acc 93.7500 (89.3056) gate/entropy 0.9876 (0.9873) gate/usage_max 0.5634 (0.5638) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1627 (0.1630) teacher/entropy 0.1086 (0.0868) teacher/usage_max 0.4615 (0.6613) teacher/usage_min 0.2226 (0.1028) teacher/usage_std 0.0983 (0.2419) nleep/row_max_mean 1531.4614 (1543.0107) nleep/row_max_std 66.1343 (63.2013) nleep/row_min_mean 1510.2144 (1516.7328) lr 1.5358e-03 eta 0:11:02
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,386
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [19/50] batch [20/181] time 0.136 (0.168) data 0.000 (0.014) loss 1.7228 (1.4771) teacher_loss 0.5630 (0.3527) loss_zs_kd 0.0238 (0.0285) loss_oracle 0.6113 (0.5870) kd_loss 0.8423 (0.8167) acc 84.3750 (87.0312) gate/entropy 0.9872 (0.9873) gate/usage_max 0.5638 (0.5637) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0765 (0.0897) teacher/usage_max 0.6365 (0.6507) teacher/usage_min 0.1300 (0.1032) teacher/usage_std 0.2185 (0.2334) nleep/row_max_mean 1541.2902 (1540.4386) nleep/row_max_std 57.0108 (55.9824) nleep/row_min_mean 1516.3704 (1514.7232) lr 1.4818e-03 eta 0:16:11
epoch [19/50] batch [40/181] time 0.165 (0.161) data 0.000 (0.007) loss 1.3790 (1.4482) teacher_loss 0.3860 (0.3359) loss_zs_kd 0.0138 (0.0277) loss_oracle 0.4889 (0.5693) kd_loss 0.7417 (0.8138) acc 84.3750 (87.6562) gate/entropy 0.9874 (0.9872) gate/usage_max 0.5636 (0.5638) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.1276 (0.0829) teacher/usage_max 0.6908 (0.6608) teacher/usage_min 0.0516 (0.1007) teacher/usage_std 0.2664 (0.2402) nleep/row_max_mean 1537.8889 (1543.2389) nleep/row_max_std 60.7452 (55.8131) nleep/row_min_mean 1513.9607 (1516.9859) lr 1.4818e-03 eta 0:15:24
epoch [19/50] batch [60/181] time 0.158 (0.161) data 0.000 (0.005) loss 1.4742 (1.4385) teacher_loss 0.4623 (0.3316) loss_zs_kd 0.0256 (0.0273) loss_oracle 0.4383 (0.5582) kd_loss 0.7800 (0.8142) acc 87.5000 (87.8125) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5642 (0.5638) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0358 (0.0810) teacher/usage_max 0.7444 (0.6624) teacher/usage_min 0.0667 (0.0953) teacher/usage_std 0.2949 (0.2434) nleep/row_max_mean 1553.6774 (1544.4874) nleep/row_max_std 54.4686 (56.9614) nleep/row_min_mean 1524.1006 (1518.1564) lr 1.4818e-03 eta 0:15:22
epoch [19/50] batch [80/181] time 0.146 (0.155) data 0.000 (0.004) loss 1.4040 (1.4115) teacher_loss 0.3202 (0.3155) loss_zs_kd 0.0126 (0.0260) loss_oracle 0.5164 (0.5423) kd_loss 0.8192 (0.8118) acc 90.6250 (88.1250) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5641 (0.5639) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1632 (0.1630) teacher/entropy 0.0480 (0.0840) teacher/usage_max 0.6916 (0.6618) teacher/usage_min 0.0887 (0.0958) teacher/usage_std 0.2589 (0.2428) nleep/row_max_mean 1553.3444 (1545.9656) nleep/row_max_std 57.0800 (57.9671) nleep/row_min_mean 1525.8831 (1519.5104) lr 1.4818e-03 eta 0:14:46
epoch [19/50] batch [100/181] time 0.158 (0.154) data 0.000 (0.003) loss 1.2970 (1.4038) teacher_loss 0.2175 (0.3035) loss_zs_kd 0.0120 (0.0250) loss_oracle 0.4757 (0.5409) kd_loss 0.8356 (0.8174) acc 90.6250 (88.5000) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5639 (0.5639) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.1376 (0.0855) teacher/usage_max 0.5810 (0.6544) teacher/usage_min 0.1282 (0.0966) teacher/usage_std 0.1873 (0.2386) nleep/row_max_mean 1537.0996 (1545.9275) nleep/row_max_std 62.3419 (58.7977) nleep/row_min_mean 1515.5728 (1519.5424) lr 1.4818e-03 eta 0:14:36
epoch [19/50] batch [120/181] time 0.157 (0.154) data 0.000 (0.002) loss 1.3221 (1.4054) teacher_loss 0.0978 (0.2985) loss_zs_kd 0.0278 (0.0246) loss_oracle 0.6116 (0.5364) kd_loss 0.9047 (0.8264) acc 93.7500 (88.7500) gate/entropy 0.9871 (0.9871) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0298 (0.0865) teacher/usage_max 0.6229 (0.6441) teacher/usage_min 0.0664 (0.0971) teacher/usage_std 0.2278 (0.2337) nleep/row_max_mean 1545.0046 (1546.0645) nleep/row_max_std 51.9625 (58.8996) nleep/row_min_mean 1518.0442 (1519.6572) lr 1.4818e-03 eta 0:14:33
epoch [19/50] batch [140/181] time 0.104 (0.150) data 0.000 (0.002) loss 1.5826 (1.4106) teacher_loss 0.3856 (0.2958) loss_zs_kd 0.0277 (0.0242) loss_oracle 0.4698 (0.5351) kd_loss 0.9482 (0.8352) acc 87.5000 (88.7723) gate/entropy 0.9870 (0.9871) gate/usage_max 0.5641 (0.5640) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.0513 (0.0885) teacher/usage_max 0.5549 (0.6330) teacher/usage_min 0.0850 (0.0981) teacher/usage_std 0.1928 (0.2281) nleep/row_max_mean 1535.3333 (1545.9839) nleep/row_max_std 71.9959 (59.3045) nleep/row_min_mean 1509.5898 (1519.8017) lr 1.4818e-03 eta 0:14:10
epoch [19/50] batch [160/181] time 0.184 (0.146) data 0.001 (0.002) loss 1.5515 (1.4218) teacher_loss 0.3876 (0.2989) loss_zs_kd 0.0163 (0.0236) loss_oracle 0.5687 (0.5329) kd_loss 0.8714 (0.8447) acc 90.6250 (88.6719) gate/entropy 0.9870 (0.9871) gate/usage_max 0.5641 (0.5640) gate/usage_min 0.2141 (0.2140) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.1123 (0.0875) teacher/usage_max 0.5711 (0.6256) teacher/usage_min 0.0714 (0.0944) teacher/usage_std 0.2047 (0.2258) nleep/row_max_mean 1536.1171 (1546.1967) nleep/row_max_std 75.8907 (59.8262) nleep/row_min_mean 1509.5487 (1519.9842) lr 1.4818e-03 eta 0:13:42
epoch [19/50] batch [180/181] time 0.125 (0.143) data 0.000 (0.002) loss 1.3912 (1.4280) teacher_loss 0.2778 (0.2987) loss_zs_kd 0.0226 (0.0235) loss_oracle 0.5446 (0.5334) kd_loss 0.8298 (0.8508) acc 87.5000 (88.6979) gate/entropy 0.9870 (0.9871) gate/usage_max 0.5640 (0.5640) gate/usage_min 0.2141 (0.2140) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.1529 (0.0875) teacher/usage_max 0.5739 (0.6204) teacher/usage_min 0.0403 (0.0913) teacher/usage_std 0.2210 (0.2248) nleep/row_max_mean 1538.5059 (1546.0671) nleep/row_max_std 67.7521 (60.0022) nleep/row_min_mean 1513.8746 (1519.8451) lr 1.4818e-03 eta 0:13:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,390
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [20/50] batch [20/181] time 0.197 (0.135) data 0.000 (0.013) loss 1.2953 (1.4640) teacher_loss 0.1457 (0.3000) loss_zs_kd 0.0100 (0.0167) loss_oracle 0.4909 (0.4848) kd_loss 0.8992 (0.9132) acc 93.7500 (88.9062) gate/entropy 0.9869 (0.9868) gate/usage_max 0.5641 (0.5643) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1632 (0.1633) teacher/entropy 0.0292 (0.0736) teacher/usage_max 0.6306 (0.5724) teacher/usage_min 0.0017 (0.0823) teacher/usage_std 0.2579 (0.2050) nleep/row_max_mean 1557.9016 (1553.3417) nleep/row_max_std 63.2635 (60.5621) nleep/row_min_mean 1529.0061 (1526.5980) lr 1.4258e-03 eta 0:12:34
epoch [20/50] batch [40/181] time 0.087 (0.126) data 0.000 (0.006) loss 1.3104 (1.4672) teacher_loss 0.2540 (0.3021) loss_zs_kd 0.0269 (0.0211) loss_oracle 0.4260 (0.4798) kd_loss 0.8300 (0.9146) acc 87.5000 (88.7500) gate/entropy 0.9862 (0.9868) gate/usage_max 0.5649 (0.5643) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1638 (0.1633) teacher/entropy 0.0359 (0.0733) teacher/usage_max 0.6941 (0.5735) teacher/usage_min 0.0301 (0.0913) teacher/usage_std 0.2741 (0.2029) nleep/row_max_mean 1574.0586 (1553.2184) nleep/row_max_std 53.3434 (59.3662) nleep/row_min_mean 1544.9564 (1525.8581) lr 1.4258e-03 eta 0:11:41
epoch [20/50] batch [60/181] time 0.199 (0.127) data 0.000 (0.004) loss 1.3809 (1.4621) teacher_loss 0.3274 (0.3003) loss_zs_kd 0.0299 (0.0232) loss_oracle 0.4984 (0.4755) kd_loss 0.7894 (0.9125) acc 90.6250 (89.3229) gate/entropy 0.9866 (0.9868) gate/usage_max 0.5645 (0.5643) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1635 (0.1634) teacher/entropy 0.0847 (0.0744) teacher/usage_max 0.6847 (0.5766) teacher/usage_min 0.0768 (0.0857) teacher/usage_std 0.2571 (0.2063) nleep/row_max_mean 1553.7134 (1553.5373) nleep/row_max_std 66.3636 (60.3489) nleep/row_min_mean 1524.2295 (1525.7875) lr 1.4258e-03 eta 0:11:43
epoch [20/50] batch [80/181] time 0.165 (0.130) data 0.000 (0.003) loss 1.6474 (1.4552) teacher_loss 0.3793 (0.2879) loss_zs_kd 0.0221 (0.0230) loss_oracle 0.5599 (0.4778) kd_loss 0.9772 (0.9170) acc 84.3750 (89.5703) gate/entropy 0.9863 (0.9867) gate/usage_max 0.5648 (0.5644) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1637 (0.1634) teacher/entropy 0.0465 (0.0739) teacher/usage_max 0.5309 (0.5719) teacher/usage_min 0.0387 (0.0830) teacher/usage_std 0.2123 (0.2061) nleep/row_max_mean 1562.9614 (1553.8024) nleep/row_max_std 62.8651 (60.7381) nleep/row_min_mean 1530.3486 (1525.7705) lr 1.4258e-03 eta 0:11:58
epoch [20/50] batch [100/181] time 0.153 (0.132) data 0.000 (0.003) loss 1.5877 (1.4722) teacher_loss 0.3772 (0.2890) loss_zs_kd 0.0464 (0.0239) loss_oracle 0.4554 (0.4843) kd_loss 0.9596 (0.9290) acc 84.3750 (89.5938) gate/entropy 0.9863 (0.9867) gate/usage_max 0.5648 (0.5644) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1637 (0.1634) teacher/entropy 0.0940 (0.0739) teacher/usage_max 0.5006 (0.5627) teacher/usage_min 0.0267 (0.0836) teacher/usage_std 0.2171 (0.2024) nleep/row_max_mean 1553.3088 (1553.6429) nleep/row_max_std 58.4034 (60.2200) nleep/row_min_mean 1523.9138 (1525.6283) lr 1.4258e-03 eta 0:12:07
epoch [20/50] batch [120/181] time 0.162 (0.137) data 0.000 (0.002) loss 1.4017 (1.4834) teacher_loss 0.1037 (0.2867) loss_zs_kd 0.0130 (0.0247) loss_oracle 0.4043 (0.4827) kd_loss 1.0893 (0.9429) acc 100.0000 (89.5312) gate/entropy 0.9870 (0.9867) gate/usage_max 0.5641 (0.5644) gate/usage_min 0.2145 (0.2142) gate/usage_std 0.1632 (0.1634) teacher/entropy 0.0538 (0.0732) teacher/usage_max 0.5750 (0.5557) teacher/usage_min 0.0170 (0.0836) teacher/usage_std 0.2339 (0.1999) nleep/row_max_mean 1558.4243 (1553.4943) nleep/row_max_std 53.5563 (59.4014) nleep/row_min_mean 1527.3877 (1525.5717) lr 1.4258e-03 eta 0:12:31
epoch [20/50] batch [140/181] time 0.170 (0.141) data 0.000 (0.002) loss 1.6112 (1.4924) teacher_loss 0.3392 (0.2920) loss_zs_kd 0.0149 (0.0250) loss_oracle 0.4163 (0.4794) kd_loss 1.0564 (0.9482) acc 84.3750 (89.1741) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2144 (0.2142) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0366 (0.0724) teacher/usage_max 0.5321 (0.5531) teacher/usage_min 0.0080 (0.0809) teacher/usage_std 0.2319 (0.2005) nleep/row_max_mean 1530.7612 (1553.7342) nleep/row_max_std 64.6770 (58.9127) nleep/row_min_mean 1501.4724 (1525.8244) lr 1.4258e-03 eta 0:12:49
epoch [20/50] batch [160/181] time 0.168 (0.144) data 0.000 (0.002) loss 1.5074 (1.4921) teacher_loss 0.3120 (0.2853) loss_zs_kd 0.0328 (0.0248) loss_oracle 0.4664 (0.4814) kd_loss 0.9459 (0.9537) acc 87.5000 (89.3555) gate/entropy 0.9862 (0.9866) gate/usage_max 0.5650 (0.5645) gate/usage_min 0.2143 (0.2142) gate/usage_std 0.1638 (0.1635) teacher/entropy 0.0611 (0.0707) teacher/usage_max 0.5486 (0.5521) teacher/usage_min 0.0240 (0.0812) teacher/usage_std 0.2242 (0.2000) nleep/row_max_mean 1553.5348 (1553.4471) nleep/row_max_std 51.8606 (58.8512) nleep/row_min_mean 1526.7158 (1525.5284) lr 1.4258e-03 eta 0:13:04
epoch [20/50] batch [180/181] time 0.167 (0.146) data 0.000 (0.002) loss 1.5874 (1.4953) teacher_loss 0.3703 (0.2851) loss_zs_kd 0.0475 (0.0249) loss_oracle 0.4123 (0.4828) kd_loss 0.9871 (0.9563) acc 84.3750 (89.1667) gate/entropy 0.9862 (0.9866) gate/usage_max 0.5649 (0.5645) gate/usage_min 0.2144 (0.2143) gate/usage_std 0.1638 (0.1635) teacher/entropy 0.0914 (0.0703) teacher/usage_max 0.4709 (0.5514) teacher/usage_min 0.1822 (0.0824) teacher/usage_std 0.1182 (0.1990) nleep/row_max_mean 1547.6802 (1553.1799) nleep/row_max_std 57.0726 (58.6498) nleep/row_min_mean 1522.2991 (1525.3202) lr 1.4258e-03 eta 0:13:11
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,379
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [21/50] batch [20/181] time 0.191 (0.128) data 0.000 (0.015) loss 1.5247 (1.5131) teacher_loss 0.3171 (0.2982) loss_zs_kd 0.0247 (0.0261) loss_oracle 0.4627 (0.4795) kd_loss 0.9639 (0.9620) acc 84.3750 (88.2812) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0762 (0.0597) teacher/usage_max 0.5121 (0.5555) teacher/usage_min 0.0797 (0.0771) teacher/usage_std 0.1843 (0.2033) nleep/row_max_mean 1545.1499 (1550.2032) nleep/row_max_std 63.9212 (53.4218) nleep/row_min_mean 1516.7329 (1521.6989) lr 1.3681e-03 eta 0:11:34
epoch [21/50] batch [40/181] time 0.078 (0.120) data 0.000 (0.007) loss 1.3758 (1.4997) teacher_loss 0.1934 (0.2861) loss_zs_kd 0.0380 (0.0277) loss_oracle 0.4780 (0.4882) kd_loss 0.9243 (0.9556) acc 93.7500 (89.1406) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0281 (0.0547) teacher/usage_max 0.6038 (0.5624) teacher/usage_min 0.0621 (0.0806) teacher/usage_std 0.2212 (0.2031) nleep/row_max_mean 1557.9629 (1549.9444) nleep/row_max_std 54.4335 (54.0648) nleep/row_min_mean 1524.5568 (1521.3266) lr 1.3681e-03 eta 0:10:44
epoch [21/50] batch [60/181] time 0.072 (0.120) data 0.000 (0.005) loss 1.4220 (1.5001) teacher_loss 0.1706 (0.2827) loss_zs_kd 0.0226 (0.0269) loss_oracle 0.4562 (0.5017) kd_loss 1.0120 (0.9531) acc 90.6250 (89.4271) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5645 (0.5648) gate/usage_min 0.2147 (0.2145) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0530 (0.0572) teacher/usage_max 0.4870 (0.5606) teacher/usage_min 0.0613 (0.0799) teacher/usage_std 0.1929 (0.2033) nleep/row_max_mean 1541.7393 (1548.2748) nleep/row_max_std 51.5548 (56.6702) nleep/row_min_mean 1514.7805 (1519.6265) lr 1.3681e-03 eta 0:10:43
epoch [21/50] batch [80/181] time 0.148 (0.121) data 0.001 (0.004) loss 1.6767 (1.5092) teacher_loss 0.3956 (0.2770) loss_zs_kd 0.0206 (0.0278) loss_oracle 0.5243 (0.5070) kd_loss 1.0086 (0.9647) acc 90.6250 (89.6094) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2146 (0.2145) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0700 (0.0593) teacher/usage_max 0.4719 (0.5560) teacher/usage_min 0.0975 (0.0808) teacher/usage_std 0.1676 (0.2015) nleep/row_max_mean 1535.7744 (1546.2173) nleep/row_max_std 56.0581 (57.4505) nleep/row_min_mean 1513.8394 (1518.1678) lr 1.3681e-03 eta 0:10:45
epoch [21/50] batch [100/181] time 0.093 (0.118) data 0.000 (0.003) loss 1.5406 (1.5037) teacher_loss 0.1249 (0.2734) loss_zs_kd 0.0124 (0.0279) loss_oracle 0.6529 (0.5091) kd_loss 1.0830 (0.9618) acc 96.8750 (89.7188) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5647 (0.5648) gate/usage_min 0.2147 (0.2145) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0257 (0.0577) teacher/usage_max 0.4403 (0.5564) teacher/usage_min 0.1223 (0.0770) teacher/usage_std 0.1493 (0.2034) nleep/row_max_mean 1543.6868 (1546.4740) nleep/row_max_std 56.2983 (57.4396) nleep/row_min_mean 1515.7137 (1518.2585) lr 1.3681e-03 eta 0:10:31
epoch [21/50] batch [120/181] time 0.100 (0.117) data 0.000 (0.003) loss 1.3536 (1.5014) teacher_loss 0.1891 (0.2671) loss_zs_kd 0.0210 (0.0270) loss_oracle 0.6026 (0.5210) kd_loss 0.8527 (0.9603) acc 90.6250 (89.9219) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0905 (0.0563) teacher/usage_max 0.6098 (0.5567) teacher/usage_min 0.1570 (0.0781) teacher/usage_std 0.1980 (0.2033) nleep/row_max_mean 1557.3372 (1546.8180) nleep/row_max_std 49.0007 (57.3036) nleep/row_min_mean 1532.0565 (1518.6640) lr 1.3681e-03 eta 0:10:20
epoch [21/50] batch [140/181] time 0.186 (0.116) data 0.000 (0.002) loss 1.3778 (1.5033) teacher_loss 0.2668 (0.2658) loss_zs_kd 0.0259 (0.0264) loss_oracle 0.4604 (0.5313) kd_loss 0.8679 (0.9586) acc 90.6250 (89.9330) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5650 (0.5648) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.1014 (0.0564) teacher/usage_max 0.5849 (0.5556) teacher/usage_min 0.0709 (0.0762) teacher/usage_std 0.2100 (0.2034) nleep/row_max_mean 1566.2778 (1547.1255) nleep/row_max_std 42.5719 (57.0889) nleep/row_min_mean 1535.5122 (1519.1029) lr 1.3681e-03 eta 0:10:15
epoch [21/50] batch [160/181] time 0.115 (0.115) data 0.000 (0.002) loss 1.6266 (1.5053) teacher_loss 0.2108 (0.2659) loss_zs_kd 0.0106 (0.0264) loss_oracle 0.6778 (0.5373) kd_loss 1.0716 (0.9576) acc 90.6250 (89.9219) gate/entropy 0.9864 (0.9863) gate/usage_max 0.5648 (0.5649) gate/usage_min 0.2148 (0.2146) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0127 (0.0556) teacher/usage_max 0.4663 (0.5558) teacher/usage_min 0.0961 (0.0770) teacher/usage_std 0.1682 (0.2031) nleep/row_max_mean 1547.9524 (1547.2628) nleep/row_max_std 36.0832 (57.4700) nleep/row_min_mean 1518.6769 (1519.1140) lr 1.3681e-03 eta 0:10:08
epoch [21/50] batch [180/181] time 0.145 (0.115) data 0.000 (0.002) loss 1.6866 (1.5055) teacher_loss 0.3605 (0.2614) loss_zs_kd 0.0254 (0.0266) loss_oracle 0.6075 (0.5453) kd_loss 1.0097 (0.9581) acc 87.5000 (90.1389) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5648 (0.5649) gate/usage_min 0.2148 (0.2146) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0553 (0.0552) teacher/usage_max 0.4855 (0.5541) teacher/usage_min 0.1137 (0.0799) teacher/usage_std 0.1591 (0.2010) nleep/row_max_mean 1546.0116 (1547.4392) nleep/row_max_std 52.5206 (57.8518) nleep/row_min_mean 1517.5173 (1519.2351) lr 1.3681e-03 eta 0:10:01
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,382
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [22/50] batch [20/181] time 0.152 (0.166) data 0.000 (0.017) loss 1.5901 (1.6169) teacher_loss 0.2481 (0.2860) loss_zs_kd 0.0233 (0.0283) loss_oracle 0.6000 (0.6132) kd_loss 1.0303 (1.0101) acc 90.6250 (88.7500) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5651 (0.5648) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0206 (0.0485) teacher/usage_max 0.4988 (0.5228) teacher/usage_min 0.1601 (0.1161) teacher/usage_std 0.1384 (0.1718) nleep/row_max_mean 1555.5825 (1544.8351) nleep/row_max_std 65.1033 (62.6891) nleep/row_min_mean 1525.5601 (1516.6590) lr 1.3090e-03 eta 0:14:27
epoch [22/50] batch [40/181] time 0.150 (0.157) data 0.000 (0.008) loss 1.5277 (1.5883) teacher_loss 0.2360 (0.2747) loss_zs_kd 0.0459 (0.0313) loss_oracle 0.5840 (0.5844) kd_loss 0.9767 (1.0057) acc 87.5000 (89.6875) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5647 (0.5649) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0303 (0.0538) teacher/usage_max 0.5446 (0.5082) teacher/usage_min 0.1744 (0.1342) teacher/usage_std 0.1556 (0.1582) nleep/row_max_mean 1548.0762 (1549.1883) nleep/row_max_std 63.6901 (61.2266) nleep/row_min_mean 1520.6243 (1520.7145) lr 1.3090e-03 eta 0:13:38
epoch [22/50] batch [60/181] time 0.137 (0.155) data 0.000 (0.006) loss 1.4417 (1.5651) teacher_loss 0.3183 (0.2630) loss_zs_kd 0.0212 (0.0306) loss_oracle 0.5318 (0.5692) kd_loss 0.8469 (1.0023) acc 87.5000 (90.3125) gate/entropy 0.9862 (0.9863) gate/usage_max 0.5649 (0.5649) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1638 (0.1637) teacher/entropy 0.0602 (0.0569) teacher/usage_max 0.6491 (0.5073) teacher/usage_min 0.1059 (0.1385) teacher/usage_std 0.2304 (0.1567) nleep/row_max_mean 1571.8533 (1550.8096) nleep/row_max_std 46.5876 (60.2044) nleep/row_min_mean 1539.1288 (1522.1328) lr 1.3090e-03 eta 0:13:22
epoch [22/50] batch [80/181] time 0.148 (0.153) data 0.000 (0.004) loss 1.4431 (1.5374) teacher_loss 0.2384 (0.2527) loss_zs_kd 0.0301 (0.0302) loss_oracle 0.5781 (0.5614) kd_loss 0.9006 (0.9890) acc 87.5000 (90.5859) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.1038 (0.0565) teacher/usage_max 0.5468 (0.5183) teacher/usage_min 0.1268 (0.1303) teacher/usage_std 0.1715 (0.1645) nleep/row_max_mean 1554.2950 (1550.4571) nleep/row_max_std 63.4366 (61.0000) nleep/row_min_mean 1525.7913 (1521.7779) lr 1.3090e-03 eta 0:13:12
epoch [22/50] batch [100/181] time 0.194 (0.154) data 0.000 (0.003) loss 1.6325 (1.5352) teacher_loss 0.2086 (0.2570) loss_zs_kd 0.0225 (0.0308) loss_oracle 0.7098 (0.5691) kd_loss 1.0578 (0.9783) acc 90.6250 (90.3125) gate/entropy 0.9865 (0.9863) gate/usage_max 0.5647 (0.5648) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1636 (0.1637) teacher/entropy 0.0777 (0.0557) teacher/usage_max 0.4686 (0.5285) teacher/usage_min 0.1186 (0.1209) teacher/usage_std 0.1536 (0.1724) nleep/row_max_mean 1548.0869 (1550.7967) nleep/row_max_std 63.5471 (60.1803) nleep/row_min_mean 1518.6667 (1521.7827) lr 1.3090e-03 eta 0:13:13
epoch [22/50] batch [120/181] time 0.082 (0.151) data 0.000 (0.003) loss 1.5652 (1.5301) teacher_loss 0.3134 (0.2545) loss_zs_kd 0.0311 (0.0307) loss_oracle 0.6263 (0.5749) kd_loss 0.9231 (0.9728) acc 84.3750 (90.3646) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5652 (0.5648) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.1041 (0.0552) teacher/usage_max 0.5236 (0.5329) teacher/usage_min 0.1557 (0.1187) teacher/usage_std 0.1505 (0.1751) nleep/row_max_mean 1559.0027 (1550.6007) nleep/row_max_std 58.4354 (60.5414) nleep/row_min_mean 1531.1877 (1521.4883) lr 1.3090e-03 eta 0:12:52
epoch [22/50] batch [140/181] time 0.174 (0.144) data 0.000 (0.003) loss 1.5257 (1.5285) teacher_loss 0.3356 (0.2538) loss_zs_kd 0.0571 (0.0314) loss_oracle 0.5738 (0.5782) kd_loss 0.8746 (0.9699) acc 90.6250 (90.3795) gate/entropy 0.9860 (0.9863) gate/usage_max 0.5652 (0.5648) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1640 (0.1637) teacher/entropy 0.0642 (0.0558) teacher/usage_max 0.6140 (0.5341) teacher/usage_min 0.1579 (0.1217) teacher/usage_std 0.2005 (0.1747) nleep/row_max_mean 1548.9034 (1550.6365) nleep/row_max_std 73.3609 (60.6683) nleep/row_min_mean 1516.5840 (1521.3019) lr 1.3090e-03 eta 0:12:18
epoch [22/50] batch [160/181] time 0.092 (0.140) data 0.000 (0.002) loss 1.5518 (1.5280) teacher_loss 0.1348 (0.2510) loss_zs_kd 0.0250 (0.0313) loss_oracle 0.6677 (0.5819) kd_loss 1.0706 (0.9705) acc 93.7500 (90.5273) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5645 (0.5648) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0773 (0.0571) teacher/usage_max 0.4797 (0.5318) teacher/usage_min 0.1211 (0.1252) teacher/usage_std 0.1536 (0.1720) nleep/row_max_mean 1527.6143 (1549.7096) nleep/row_max_std 63.2818 (60.7535) nleep/row_min_mean 1500.8868 (1520.4316) lr 1.3090e-03 eta 0:11:51
epoch [22/50] batch [180/181] time 0.085 (0.135) data 0.000 (0.002) loss 1.5382 (1.5279) teacher_loss 0.1397 (0.2485) loss_zs_kd 0.0253 (0.0311) loss_oracle 0.7977 (0.5917) kd_loss 0.9870 (0.9680) acc 93.7500 (90.5556) gate/entropy 0.9863 (0.9863) gate/usage_max 0.5648 (0.5648) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1637 (0.1637) teacher/entropy 0.0969 (0.0581) teacher/usage_max 0.4637 (0.5326) teacher/usage_min 0.1608 (0.1281) teacher/usage_std 0.1272 (0.1713) nleep/row_max_mean 1548.4897 (1549.1180) nleep/row_max_std 67.0505 (60.6108) nleep/row_min_mean 1518.1343 (1519.8101) lr 1.3090e-03 eta 0:11:25
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [23/50] batch [20/181] time 0.179 (0.119) data 0.000 (0.015) loss 1.5589 (1.5154) teacher_loss 0.2322 (0.2145) loss_zs_kd 0.0266 (0.0321) loss_oracle 0.6335 (0.6465) kd_loss 0.9966 (0.9616) acc 90.6250 (92.3438) gate/entropy 0.9865 (0.9864) gate/usage_max 0.5646 (0.5647) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1636 (0.1636) teacher/entropy 0.0618 (0.0522) teacher/usage_max 0.4908 (0.5518) teacher/usage_min 0.1611 (0.1333) teacher/usage_std 0.1350 (0.1781) nleep/row_max_mean 1539.4661 (1546.2600) nleep/row_max_std 64.9015 (60.4916) nleep/row_min_mean 1509.1449 (1516.4113) lr 1.2487e-03 eta 0:10:01
epoch [23/50] batch [40/181] time 0.096 (0.115) data 0.000 (0.007) loss 1.3334 (1.5130) teacher_loss 0.1403 (0.2076) loss_zs_kd 0.0243 (0.0296) loss_oracle 0.5671 (0.6426) kd_loss 0.8974 (0.9693) acc 96.8750 (92.5000) gate/entropy 0.9863 (0.9865) gate/usage_max 0.5648 (0.5647) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1637 (0.1636) teacher/entropy 0.0546 (0.0512) teacher/usage_max 0.6023 (0.5426) teacher/usage_min 0.1177 (0.1270) teacher/usage_std 0.2014 (0.1759) nleep/row_max_mean 1538.5732 (1545.2993) nleep/row_max_std 65.1068 (60.8033) nleep/row_min_mean 1509.6226 (1515.2468) lr 1.2487e-03 eta 0:09:39
epoch [23/50] batch [60/181] time 0.184 (0.120) data 0.000 (0.005) loss 1.4931 (1.5062) teacher_loss 0.2022 (0.2163) loss_zs_kd 0.0274 (0.0297) loss_oracle 0.6752 (0.6383) kd_loss 0.9395 (0.9559) acc 93.7500 (92.1354) gate/entropy 0.9867 (0.9865) gate/usage_max 0.5645 (0.5647) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1634 (0.1636) teacher/entropy 0.0420 (0.0508) teacher/usage_max 0.5710 (0.5531) teacher/usage_min 0.1566 (0.1267) teacher/usage_std 0.1746 (0.1810) nleep/row_max_mean 1539.9055 (1545.7961) nleep/row_max_std 52.4264 (60.8367) nleep/row_min_mean 1508.6965 (1515.6007) lr 1.2487e-03 eta 0:10:03
epoch [23/50] batch [80/181] time 0.104 (0.119) data 0.000 (0.004) loss 1.4609 (1.5175) teacher_loss 0.2159 (0.2180) loss_zs_kd 0.0324 (0.0305) loss_oracle 0.6143 (0.6393) kd_loss 0.9216 (0.9647) acc 90.6250 (91.9531) gate/entropy 0.9863 (0.9865) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1637 (0.1636) teacher/entropy 0.0641 (0.0487) teacher/usage_max 0.5656 (0.5458) teacher/usage_min 0.1948 (0.1304) teacher/usage_std 0.1653 (0.1758) nleep/row_max_mean 1546.4233 (1544.9391) nleep/row_max_std 59.6922 (61.4234) nleep/row_min_mean 1520.4640 (1514.9540) lr 1.2487e-03 eta 0:09:51
epoch [23/50] batch [100/181] time 0.155 (0.123) data 0.000 (0.003) loss 1.5981 (1.5277) teacher_loss 0.1286 (0.2178) loss_zs_kd 0.0310 (0.0303) loss_oracle 0.6417 (0.6365) kd_loss 1.1331 (0.9765) acc 93.7500 (91.9688) gate/entropy 0.9868 (0.9865) gate/usage_max 0.5643 (0.5646) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1634 (0.1636) teacher/entropy 0.0551 (0.0455) teacher/usage_max 0.4787 (0.5410) teacher/usage_min 0.1647 (0.1356) teacher/usage_std 0.1292 (0.1715) nleep/row_max_mean 1521.2036 (1544.1473) nleep/row_max_std 71.7678 (61.4906) nleep/row_min_mean 1492.6997 (1514.2256) lr 1.2487e-03 eta 0:10:11
epoch [23/50] batch [120/181] time 0.168 (0.130) data 0.000 (0.003) loss 1.5382 (1.5266) teacher_loss 0.1847 (0.2115) loss_zs_kd 0.0430 (0.0312) loss_oracle 0.6933 (0.6368) kd_loss 0.9853 (0.9811) acc 93.7500 (92.4219) gate/entropy 0.9868 (0.9865) gate/usage_max 0.5643 (0.5646) gate/usage_min 0.2152 (0.2150) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0462 (0.0444) teacher/usage_max 0.5182 (0.5369) teacher/usage_min 0.1860 (0.1370) teacher/usage_std 0.1382 (0.1694) nleep/row_max_mean 1530.2949 (1543.3227) nleep/row_max_std 59.8651 (61.8083) nleep/row_min_mean 1499.7239 (1513.4698) lr 1.2487e-03 eta 0:10:44
epoch [23/50] batch [140/181] time 0.189 (0.135) data 0.000 (0.002) loss 1.5111 (1.5289) teacher_loss 0.1356 (0.2109) loss_zs_kd 0.0307 (0.0320) loss_oracle 0.6566 (0.6412) kd_loss 1.0319 (0.9814) acc 93.7500 (92.5000) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5645 (0.5646) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0190 (0.0430) teacher/usage_max 0.4984 (0.5372) teacher/usage_min 0.1596 (0.1397) teacher/usage_std 0.1385 (0.1685) nleep/row_max_mean 1541.9045 (1543.7476) nleep/row_max_std 71.3988 (61.7792) nleep/row_min_mean 1512.6974 (1513.7337) lr 1.2487e-03 eta 0:11:05
epoch [23/50] batch [160/181] time 0.129 (0.136) data 0.000 (0.002) loss 1.6129 (1.5320) teacher_loss 0.2437 (0.2068) loss_zs_kd 0.0378 (0.0331) loss_oracle 0.6780 (0.6478) kd_loss 1.0114 (0.9847) acc 90.6250 (92.6367) gate/entropy 0.9864 (0.9866) gate/usage_max 0.5647 (0.5646) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0516 (0.0418) teacher/usage_max 0.4868 (0.5336) teacher/usage_min 0.1555 (0.1428) teacher/usage_std 0.1363 (0.1658) nleep/row_max_mean 1559.7130 (1544.2866) nleep/row_max_std 44.4824 (61.3210) nleep/row_min_mean 1530.2415 (1514.2063) lr 1.2487e-03 eta 0:11:08
epoch [23/50] batch [180/181] time 0.148 (0.137) data 0.000 (0.002) loss 1.6088 (1.5403) teacher_loss 0.1635 (0.2046) loss_zs_kd 0.0287 (0.0341) loss_oracle 0.6787 (0.6518) kd_loss 1.0916 (0.9927) acc 93.7500 (92.6736) gate/entropy 0.9868 (0.9866) gate/usage_max 0.5644 (0.5645) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0272 (0.0401) teacher/usage_max 0.4258 (0.5289) teacher/usage_min 0.2610 (0.1452) teacher/usage_std 0.0687 (0.1627) nleep/row_max_mean 1555.6110 (1544.3758) nleep/row_max_std 56.1339 (61.1716) nleep/row_min_mean 1523.6228 (1514.1866) lr 1.2487e-03 eta 0:11:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,404
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [24/50] batch [20/181] time 0.088 (0.147) data 0.000 (0.014) loss 1.4596 (1.6121) teacher_loss 0.1311 (0.2001) loss_zs_kd 0.0338 (0.0403) loss_oracle 0.6358 (0.6834) kd_loss 0.9937 (1.0501) acc 93.7500 (91.2500) gate/entropy 0.9870 (0.9868) gate/usage_max 0.5641 (0.5643) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1632 (0.1633) teacher/entropy 0.0440 (0.0290) teacher/usage_max 0.5137 (0.5072) teacher/usage_min 0.1034 (0.1456) teacher/usage_std 0.1711 (0.1539) nleep/row_max_mean 1543.8406 (1544.2116) nleep/row_max_std 50.4143 (54.2620) nleep/row_min_mean 1513.4204 (1513.3280) lr 1.1874e-03 eta 0:11:56
epoch [24/50] batch [40/181] time 0.069 (0.125) data 0.000 (0.007) loss 1.4543 (1.5789) teacher_loss 0.0437 (0.1894) loss_zs_kd 0.0285 (0.0405) loss_oracle 0.6517 (0.6675) kd_loss 1.0705 (1.0355) acc 96.8750 (92.0312) gate/entropy 0.9873 (0.9868) gate/usage_max 0.5638 (0.5643) gate/usage_min 0.2154 (0.2152) gate/usage_std 0.1630 (0.1633) teacher/entropy 0.0110 (0.0269) teacher/usage_max 0.4677 (0.5134) teacher/usage_min 0.1248 (0.1413) teacher/usage_std 0.1495 (0.1579) nleep/row_max_mean 1533.4813 (1543.5872) nleep/row_max_std 51.2156 (53.2620) nleep/row_min_mean 1503.6888 (1512.8780) lr 1.1874e-03 eta 0:10:03
epoch [24/50] batch [60/181] time 0.076 (0.120) data 0.000 (0.005) loss 1.5774 (1.5742) teacher_loss 0.1504 (0.1954) loss_zs_kd 0.0384 (0.0427) loss_oracle 0.6817 (0.6680) kd_loss 1.0669 (1.0234) acc 93.7500 (91.8229) gate/entropy 0.9871 (0.9868) gate/usage_max 0.5640 (0.5643) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1631 (0.1633) teacher/entropy 0.0646 (0.0275) teacher/usage_max 0.4149 (0.5164) teacher/usage_min 0.1753 (0.1504) teacher/usage_std 0.1118 (0.1560) nleep/row_max_mean 1547.3140 (1545.4666) nleep/row_max_std 42.4208 (52.6297) nleep/row_min_mean 1515.0295 (1514.4700) lr 1.1874e-03 eta 0:09:41
epoch [24/50] batch [80/181] time 0.068 (0.118) data 0.000 (0.004) loss 1.7148 (1.5885) teacher_loss 0.0955 (0.1915) loss_zs_kd 0.0234 (0.0414) loss_oracle 0.8379 (0.6819) kd_loss 1.1886 (1.0353) acc 93.7500 (92.0703) gate/entropy 0.9872 (0.9869) gate/usage_max 0.5639 (0.5643) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1630 (0.1633) teacher/entropy 0.0369 (0.0269) teacher/usage_max 0.4035 (0.5079) teacher/usage_min 0.2813 (0.1610) teacher/usage_std 0.0515 (0.1477) nleep/row_max_mean 1535.7290 (1545.0746) nleep/row_max_std 53.5569 (53.8353) nleep/row_min_mean 1507.9817 (1513.8347) lr 1.1874e-03 eta 0:09:29
epoch [24/50] batch [100/181] time 0.083 (0.117) data 0.000 (0.003) loss 1.5198 (1.5913) teacher_loss 0.2004 (0.1892) loss_zs_kd 0.0591 (0.0418) loss_oracle 0.6917 (0.6862) kd_loss 0.9440 (1.0381) acc 93.7500 (92.3438) gate/entropy 0.9871 (0.9869) gate/usage_max 0.5640 (0.5642) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1631 (0.1633) teacher/entropy 0.0217 (0.0269) teacher/usage_max 0.5862 (0.5040) teacher/usage_min 0.1621 (0.1610) teacher/usage_std 0.1825 (0.1462) nleep/row_max_mean 1546.2667 (1544.4151) nleep/row_max_std 67.5504 (54.3414) nleep/row_min_mean 1510.6426 (1513.3698) lr 1.1874e-03 eta 0:09:19
epoch [24/50] batch [120/181] time 0.071 (0.112) data 0.000 (0.002) loss 1.4232 (1.5892) teacher_loss 0.2740 (0.1902) loss_zs_kd 0.0348 (0.0426) loss_oracle 0.6111 (0.6829) kd_loss 0.8262 (1.0363) acc 90.6250 (92.3177) gate/entropy 0.9866 (0.9869) gate/usage_max 0.5645 (0.5642) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1635 (0.1633) teacher/entropy 0.0240 (0.0266) teacher/usage_max 0.7091 (0.5035) teacher/usage_min 0.1034 (0.1652) teacher/usage_std 0.2679 (0.1438) nleep/row_max_mean 1568.0344 (1545.2287) nleep/row_max_std 42.2193 (54.5556) nleep/row_min_mean 1536.0883 (1514.0219) lr 1.1874e-03 eta 0:08:53
epoch [24/50] batch [140/181] time 0.084 (0.112) data 0.000 (0.002) loss 1.7009 (1.5817) teacher_loss 0.2214 (0.1882) loss_zs_kd 0.0520 (0.0424) loss_oracle 0.6948 (0.6748) kd_loss 1.1061 (1.0349) acc 87.5000 (92.4107) gate/entropy 0.9874 (0.9870) gate/usage_max 0.5637 (0.5642) gate/usage_min 0.2154 (0.2152) gate/usage_std 0.1629 (0.1632) teacher/entropy 0.0224 (0.0257) teacher/usage_max 0.4259 (0.5051) teacher/usage_min 0.1563 (0.1621) teacher/usage_std 0.1252 (0.1461) nleep/row_max_mean 1529.6384 (1545.0854) nleep/row_max_std 76.1475 (55.6280) nleep/row_min_mean 1496.9927 (1513.7252) lr 1.1874e-03 eta 0:08:53
epoch [24/50] batch [160/181] time 0.085 (0.113) data 0.000 (0.002) loss 1.7037 (1.5754) teacher_loss 0.2290 (0.1842) loss_zs_kd 0.0343 (0.0427) loss_oracle 0.6576 (0.6722) kd_loss 1.1287 (1.0338) acc 90.6250 (92.5391) gate/entropy 0.9876 (0.9870) gate/usage_max 0.5635 (0.5641) gate/usage_min 0.2155 (0.2152) gate/usage_std 0.1627 (0.1632) teacher/entropy 0.0235 (0.0255) teacher/usage_max 0.4995 (0.5070) teacher/usage_min 0.1058 (0.1633) teacher/usage_std 0.1665 (0.1465) nleep/row_max_mean 1530.1270 (1545.6453) nleep/row_max_std 55.7676 (55.7842) nleep/row_min_mean 1498.2700 (1514.1603) lr 1.1874e-03 eta 0:08:52
epoch [24/50] batch [180/181] time 0.186 (0.113) data 0.000 (0.002) loss 1.3746 (1.5686) teacher_loss 0.1463 (0.1829) loss_zs_kd 0.0461 (0.0434) loss_oracle 0.5612 (0.6647) kd_loss 0.9246 (1.0317) acc 96.8750 (92.7083) gate/entropy 0.9872 (0.9870) gate/usage_max 0.5639 (0.5641) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1630 (0.1632) teacher/entropy 0.0302 (0.0246) teacher/usage_max 0.5997 (0.5084) teacher/usage_min 0.1175 (0.1622) teacher/usage_std 0.2001 (0.1474) nleep/row_max_mean 1544.3325 (1545.9320) nleep/row_max_std 57.8157 (56.1326) nleep/row_min_mean 1513.4041 (1514.3033) lr 1.1874e-03 eta 0:08:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,403
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [25/50] batch [20/181] time 0.134 (0.174) data 0.000 (0.014) loss 1.4647 (1.4952) teacher_loss 0.0761 (0.1455) loss_zs_kd 0.0232 (0.0332) loss_oracle 0.5141 (0.5916) kd_loss 1.1200 (1.0373) acc 100.0000 (94.6875) gate/entropy 0.9875 (0.9873) gate/usage_max 0.5636 (0.5638) gate/usage_min 0.2155 (0.2154) gate/usage_std 0.1628 (0.1630) teacher/entropy 0.0393 (0.0230) teacher/usage_max 0.5182 (0.5076) teacher/usage_min 0.0939 (0.1564) teacher/usage_std 0.1775 (0.1472) nleep/row_max_mean 1538.8256 (1546.1609) nleep/row_max_std 58.8616 (59.1095) nleep/row_min_mean 1509.1630 (1514.0782) lr 1.1253e-03 eta 0:13:35
epoch [25/50] batch [40/181] time 0.171 (0.168) data 0.000 (0.007) loss 1.2586 (1.5348) teacher_loss 0.0959 (0.1885) loss_zs_kd 0.0300 (0.0373) loss_oracle 0.5047 (0.5940) kd_loss 0.8954 (1.0307) acc 96.8750 (92.4219) gate/entropy 0.9870 (0.9873) gate/usage_max 0.5641 (0.5638) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1632 (0.1630) teacher/entropy 0.0833 (0.0230) teacher/usage_max 0.5745 (0.5068) teacher/usage_min 0.1007 (0.1548) teacher/usage_std 0.1935 (0.1491) nleep/row_max_mean 1550.3997 (1547.2745) nleep/row_max_std 61.9027 (58.9156) nleep/row_min_mean 1515.6411 (1514.5062) lr 1.1253e-03 eta 0:13:04
epoch [25/50] batch [60/181] time 0.173 (0.166) data 0.000 (0.005) loss 1.7129 (1.5347) teacher_loss 0.2185 (0.1847) loss_zs_kd 0.0280 (0.0391) loss_oracle 0.7115 (0.6085) kd_loss 1.1246 (1.0261) acc 93.7500 (92.7083) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1631 (0.1630) teacher/entropy 0.0118 (0.0273) teacher/usage_max 0.4069 (0.5091) teacher/usage_min 0.2815 (0.1593) teacher/usage_std 0.0535 (0.1482) nleep/row_max_mean 1546.9209 (1547.4968) nleep/row_max_std 72.4904 (59.2418) nleep/row_min_mean 1516.1294 (1515.0410) lr 1.1253e-03 eta 0:12:52
epoch [25/50] batch [80/181] time 0.149 (0.165) data 0.000 (0.004) loss 1.5748 (1.5413) teacher_loss 0.2998 (0.1866) loss_zs_kd 0.0316 (0.0382) loss_oracle 0.5704 (0.6129) kd_loss 0.9740 (1.0291) acc 87.5000 (92.6172) gate/entropy 0.9868 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1634 (0.1630) teacher/entropy 0.0162 (0.0252) teacher/usage_max 0.5624 (0.5089) teacher/usage_min 0.1516 (0.1580) teacher/usage_std 0.1710 (0.1486) nleep/row_max_mean 1559.9275 (1547.9594) nleep/row_max_std 58.2569 (59.3476) nleep/row_min_mean 1526.7324 (1515.5366) lr 1.1253e-03 eta 0:12:43
epoch [25/50] batch [100/181] time 0.166 (0.162) data 0.000 (0.003) loss 1.5711 (1.5530) teacher_loss 0.3380 (0.1891) loss_zs_kd 0.0544 (0.0400) loss_oracle 0.4634 (0.6174) kd_loss 0.9742 (1.0353) acc 87.5000 (92.6250) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5639 (0.5639) gate/usage_min 0.2155 (0.2154) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0408 (0.0248) teacher/usage_max 0.5364 (0.5027) teacher/usage_min 0.1458 (0.1606) teacher/usage_std 0.1599 (0.1450) nleep/row_max_mean 1535.6973 (1547.5147) nleep/row_max_std 55.9460 (59.0087) nleep/row_min_mean 1506.3818 (1515.0869) lr 1.1253e-03 eta 0:12:26
epoch [25/50] batch [120/181] time 0.156 (0.161) data 0.000 (0.003) loss 1.5197 (1.5486) teacher_loss 0.1094 (0.1904) loss_zs_kd 0.0296 (0.0394) loss_oracle 0.5936 (0.6105) kd_loss 1.0987 (1.0333) acc 96.8750 (92.6823) gate/entropy 0.9875 (0.9872) gate/usage_max 0.5636 (0.5639) gate/usage_min 0.2156 (0.2155) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.0320 (0.0248) teacher/usage_max 0.4151 (0.5061) teacher/usage_min 0.1824 (0.1588) teacher/usage_std 0.1069 (0.1476) nleep/row_max_mean 1548.4523 (1547.8874) nleep/row_max_std 58.6518 (58.9978) nleep/row_min_mean 1516.8807 (1515.3731) lr 1.1253e-03 eta 0:12:16
epoch [25/50] batch [140/181] time 0.096 (0.150) data 0.000 (0.002) loss 1.3347 (1.5453) teacher_loss 0.1874 (0.1929) loss_zs_kd 0.0742 (0.0398) loss_oracle 0.5070 (0.6037) kd_loss 0.8568 (1.0308) acc 93.7500 (92.7009) gate/entropy 0.9868 (0.9872) gate/usage_max 0.5644 (0.5639) gate/usage_min 0.2154 (0.2155) gate/usage_std 0.1634 (0.1630) teacher/entropy 0.0186 (0.0258) teacher/usage_max 0.6822 (0.5085) teacher/usage_min 0.1259 (0.1563) teacher/usage_std 0.2481 (0.1495) nleep/row_max_mean 1560.1763 (1547.7525) nleep/row_max_std 56.5767 (58.5270) nleep/row_min_mean 1522.8749 (1515.1650) lr 1.1253e-03 eta 0:11:26
epoch [25/50] batch [160/181] time 0.076 (0.147) data 0.000 (0.002) loss 1.6300 (1.5343) teacher_loss 0.4443 (0.1960) loss_zs_kd 0.0464 (0.0401) loss_oracle 0.4720 (0.5948) kd_loss 0.9266 (1.0209) acc 84.3750 (92.4805) gate/entropy 0.9870 (0.9872) gate/usage_max 0.5641 (0.5639) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1632 (0.1630) teacher/entropy 0.0036 (0.0256) teacher/usage_max 0.6247 (0.5173) teacher/usage_min 0.0936 (0.1516) teacher/usage_std 0.2199 (0.1554) nleep/row_max_mean 1548.3275 (1547.9456) nleep/row_max_std 65.4825 (58.7703) nleep/row_min_mean 1512.6669 (1515.0919) lr 1.1253e-03 eta 0:11:06
epoch [25/50] batch [180/181] time 0.075 (0.143) data 0.000 (0.002) loss 1.4219 (1.5289) teacher_loss 0.1496 (0.1974) loss_zs_kd 0.0505 (0.0397) loss_oracle 0.5056 (0.5877) kd_loss 0.9942 (1.0178) acc 96.8750 (92.5347) gate/entropy 0.9873 (0.9873) gate/usage_max 0.5638 (0.5639) gate/usage_min 0.2157 (0.2155) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0367 (0.0259) teacher/usage_max 0.5210 (0.5188) teacher/usage_min 0.0727 (0.1468) teacher/usage_std 0.1902 (0.1580) nleep/row_max_mean 1543.3345 (1547.6799) nleep/row_max_std 80.7792 (59.2821) nleep/row_min_mean 1507.0979 (1514.6222) lr 1.1253e-03 eta 0:10:46
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [26/50] batch [20/181] time 0.095 (0.136) data 0.000 (0.014) loss 1.2768 (1.4790) teacher_loss 0.2119 (0.1852) loss_zs_kd 0.0309 (0.0342) loss_oracle 0.4423 (0.5352) kd_loss 0.8283 (1.0091) acc 87.5000 (92.8125) gate/entropy 0.9867 (0.9873) gate/usage_max 0.5645 (0.5638) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1635 (0.1630) teacher/entropy 0.0328 (0.0368) teacher/usage_max 0.6974 (0.5170) teacher/usage_min 0.0633 (0.1292) teacher/usage_std 0.2673 (0.1663) nleep/row_max_mean 1572.0979 (1550.3029) nleep/row_max_std 53.0830 (60.3408) nleep/row_min_mean 1536.3185 (1516.7088) lr 1.0628e-03 eta 0:10:10
epoch [26/50] batch [40/181] time 0.156 (0.127) data 0.000 (0.007) loss 1.4849 (1.4860) teacher_loss 0.3716 (0.2168) loss_zs_kd 0.0227 (0.0350) loss_oracle 0.6098 (0.5327) kd_loss 0.7970 (0.9854) acc 84.3750 (91.7188) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0622 (0.0301) teacher/usage_max 0.6984 (0.5477) teacher/usage_min 0.1248 (0.1172) teacher/usage_std 0.2590 (0.1853) nleep/row_max_mean 1569.8838 (1553.1519) nleep/row_max_std 59.0286 (58.3711) nleep/row_min_mean 1536.6663 (1518.8688) lr 1.0628e-03 eta 0:09:28
epoch [26/50] batch [60/181] time 0.079 (0.118) data 0.001 (0.005) loss 1.3907 (1.4880) teacher_loss 0.1669 (0.2219) loss_zs_kd 0.0627 (0.0368) loss_oracle 0.6091 (0.5350) kd_loss 0.8879 (0.9801) acc 93.7500 (91.4583) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2157 (0.2157) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0150 (0.0292) teacher/usage_max 0.6523 (0.5524) teacher/usage_min 0.1563 (0.1142) teacher/usage_std 0.2260 (0.1893) nleep/row_max_mean 1554.0873 (1551.5225) nleep/row_max_std 55.5106 (59.7293) nleep/row_min_mean 1517.3545 (1517.3925) lr 1.0628e-03 eta 0:08:45
epoch [26/50] batch [80/181] time 0.090 (0.113) data 0.000 (0.004) loss 1.5607 (1.4861) teacher_loss 0.2165 (0.2193) loss_zs_kd 0.0522 (0.0369) loss_oracle 0.5557 (0.5421) kd_loss 1.0402 (0.9773) acc 93.7500 (91.8359) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2158 (0.2157) gate/usage_std 0.1631 (0.1630) teacher/entropy 0.0069 (0.0277) teacher/usage_max 0.5014 (0.5573) teacher/usage_min 0.1549 (0.1101) teacher/usage_std 0.1417 (0.1919) nleep/row_max_mean 1547.4927 (1550.2816) nleep/row_max_std 63.2898 (60.4693) nleep/row_min_mean 1509.7701 (1515.9002) lr 1.0628e-03 eta 0:08:24
epoch [26/50] batch [100/181] time 0.164 (0.122) data 0.000 (0.003) loss 1.7270 (1.4867) teacher_loss 0.3670 (0.2166) loss_zs_kd 0.0478 (0.0376) loss_oracle 0.5795 (0.5423) kd_loss 1.0463 (0.9802) acc 87.5000 (91.9062) gate/entropy 0.9868 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2157 (0.2157) gate/usage_std 0.1633 (0.1631) teacher/entropy 0.0030 (0.0278) teacher/usage_max 0.5005 (0.5523) teacher/usage_min 0.1561 (0.1134) teacher/usage_std 0.1408 (0.1882) nleep/row_max_mean 1569.6512 (1550.3471) nleep/row_max_std 55.8457 (60.8935) nleep/row_min_mean 1532.5665 (1515.8365) lr 1.0628e-03 eta 0:09:00
epoch [26/50] batch [120/181] time 0.158 (0.129) data 0.000 (0.003) loss 1.5076 (1.4835) teacher_loss 0.1478 (0.2116) loss_zs_kd 0.0376 (0.0371) loss_oracle 0.5492 (0.5400) kd_loss 1.0664 (0.9833) acc 96.8750 (92.0052) gate/entropy 0.9868 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2157 (0.2157) gate/usage_std 0.1633 (0.1631) teacher/entropy 0.0107 (0.0265) teacher/usage_max 0.4695 (0.5489) teacher/usage_min 0.2476 (0.1198) teacher/usage_std 0.0974 (0.1837) nleep/row_max_mean 1552.8230 (1550.4806) nleep/row_max_std 62.3891 (61.4396) nleep/row_min_mean 1518.1477 (1516.0391) lr 1.0628e-03 eta 0:09:27
epoch [26/50] batch [140/181] time 0.160 (0.134) data 0.000 (0.002) loss 1.2717 (1.4825) teacher_loss 0.1792 (0.2054) loss_zs_kd 0.0253 (0.0365) loss_oracle 0.5022 (0.5408) kd_loss 0.8288 (0.9885) acc 93.7500 (92.1205) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5639 (0.5639) gate/usage_min 0.2159 (0.2158) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0609 (0.0267) teacher/usage_max 0.6663 (0.5439) teacher/usage_min 0.1105 (0.1243) teacher/usage_std 0.2399 (0.1797) nleep/row_max_mean 1554.2490 (1549.5195) nleep/row_max_std 56.1387 (60.5875) nleep/row_min_mean 1518.4965 (1515.3198) lr 1.0628e-03 eta 0:09:46
epoch [26/50] batch [160/181] time 0.161 (0.137) data 0.000 (0.002) loss 1.5266 (1.4848) teacher_loss 0.1313 (0.2022) loss_zs_kd 0.0319 (0.0363) loss_oracle 0.6169 (0.5419) kd_loss 1.0709 (0.9935) acc 96.8750 (92.1875) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2159 (0.2158) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0214 (0.0273) teacher/usage_max 0.4564 (0.5391) teacher/usage_min 0.0937 (0.1281) teacher/usage_std 0.1694 (0.1759) nleep/row_max_mean 1542.4622 (1549.1234) nleep/row_max_std 45.9312 (60.0589) nleep/row_min_mean 1510.9409 (1515.2116) lr 1.0628e-03 eta 0:09:59
epoch [26/50] batch [180/181] time 0.191 (0.140) data 0.000 (0.002) loss 1.4223 (1.4887) teacher_loss 0.1795 (0.2004) loss_zs_kd 0.0364 (0.0369) loss_oracle 0.5396 (0.5464) kd_loss 0.9549 (0.9967) acc 93.7500 (92.1875) gate/entropy 0.9870 (0.9872) gate/usage_max 0.5642 (0.5639) gate/usage_min 0.2158 (0.2158) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.0583 (0.0271) teacher/usage_max 0.5388 (0.5360) teacher/usage_min 0.1089 (0.1309) teacher/usage_std 0.1760 (0.1733) nleep/row_max_mean 1555.1447 (1549.1649) nleep/row_max_std 53.3459 (59.5683) nleep/row_min_mean 1523.6531 (1515.4204) lr 1.0628e-03 eta 0:10:09
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.4%, epoch: 7 *******
******* Domain p best val test acc: 99.9%, epoch: 7 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [27/50] batch [20/181] time 0.137 (0.119) data 0.000 (0.015) loss 1.5159 (1.5089) teacher_loss 0.0907 (0.1663) loss_zs_kd 0.0413 (0.0364) loss_oracle 0.6050 (0.6014) kd_loss 1.1020 (1.0238) acc 96.8750 (94.0625) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0077 (0.0153) teacher/usage_max 0.4362 (0.5184) teacher/usage_min 0.1877 (0.1347) teacher/usage_std 0.1059 (0.1625) nleep/row_max_mean 1558.8550 (1553.6729) nleep/row_max_std 64.0113 (55.1797) nleep/row_min_mean 1526.0732 (1519.8980) lr 1.0000e-03 eta 0:08:33
epoch [27/50] batch [40/181] time 0.172 (0.117) data 0.000 (0.008) loss 1.4049 (1.5027) teacher_loss 0.1083 (0.1694) loss_zs_kd 0.0376 (0.0367) loss_oracle 0.5811 (0.5845) kd_loss 0.9872 (1.0227) acc 96.8750 (93.4375) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5642 (0.5639) gate/usage_min 0.2159 (0.2160) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0020 (0.0176) teacher/usage_max 0.5625 (0.5209) teacher/usage_min 0.1562 (0.1420) teacher/usage_std 0.1699 (0.1600) nleep/row_max_mean 1567.6619 (1553.7462) nleep/row_max_std 51.3083 (54.1360) nleep/row_min_mean 1530.5103 (1520.5457) lr 1.0000e-03 eta 0:08:24
epoch [27/50] batch [60/181] time 0.070 (0.118) data 0.000 (0.005) loss 1.5576 (1.5094) teacher_loss 0.1789 (0.1756) loss_zs_kd 0.0455 (0.0397) loss_oracle 0.5577 (0.5873) kd_loss 1.0771 (1.0203) acc 93.7500 (93.2812) gate/entropy 0.9874 (0.9872) gate/usage_max 0.5637 (0.5639) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1629 (0.1631) teacher/entropy 0.0032 (0.0199) teacher/usage_max 0.4687 (0.5216) teacher/usage_min 0.0630 (0.1421) teacher/usage_std 0.1911 (0.1611) nleep/row_max_mean 1547.4280 (1553.9966) nleep/row_max_std 57.6185 (54.6226) nleep/row_min_mean 1515.2097 (1520.7661) lr 1.0000e-03 eta 0:08:24
epoch [27/50] batch [80/181] time 0.107 (0.115) data 0.000 (0.004) loss 1.4916 (1.5156) teacher_loss 0.1356 (0.1813) loss_zs_kd 0.0451 (0.0398) loss_oracle 0.5836 (0.5877) kd_loss 1.0416 (1.0206) acc 96.8750 (92.9688) gate/entropy 0.9869 (0.9872) gate/usage_max 0.5642 (0.5639) gate/usage_min 0.2159 (0.2160) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.0071 (0.0199) teacher/usage_max 0.5004 (0.5213) teacher/usage_min 0.1250 (0.1453) teacher/usage_std 0.1560 (0.1596) nleep/row_max_mean 1552.4825 (1553.9583) nleep/row_max_std 62.4221 (54.6132) nleep/row_min_mean 1518.8510 (1520.7932) lr 1.0000e-03 eta 0:08:08
epoch [27/50] batch [100/181] time 0.096 (0.115) data 0.000 (0.003) loss 1.4573 (1.5176) teacher_loss 0.0660 (0.1779) loss_zs_kd 0.0309 (0.0396) loss_oracle 0.6660 (0.5908) kd_loss 1.0428 (1.0246) acc 100.0000 (92.8750) gate/entropy 0.9874 (0.9872) gate/usage_max 0.5637 (0.5639) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1629 (0.1631) teacher/entropy 0.0352 (0.0212) teacher/usage_max 0.4697 (0.5163) teacher/usage_min 0.1612 (0.1491) teacher/usage_std 0.1285 (0.1559) nleep/row_max_mean 1546.1155 (1553.1213) nleep/row_max_std 49.7219 (55.2573) nleep/row_min_mean 1513.3765 (1520.2069) lr 1.0000e-03 eta 0:08:06
epoch [27/50] batch [120/181] time 0.170 (0.114) data 0.000 (0.003) loss 1.6942 (1.5265) teacher_loss 0.4162 (0.1805) loss_zs_kd 0.0562 (0.0397) loss_oracle 0.5653 (0.5927) kd_loss 0.9673 (1.0298) acc 81.2500 (92.9167) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5639 (0.5639) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1630 (0.1631) teacher/entropy 0.0213 (0.0203) teacher/usage_max 0.5625 (0.5118) teacher/usage_min 0.1445 (0.1504) teacher/usage_std 0.1730 (0.1537) nleep/row_max_mean 1549.3018 (1552.5922) nleep/row_max_std 66.1415 (55.7386) nleep/row_min_mean 1515.5392 (1519.6779) lr 1.0000e-03 eta 0:08:02
epoch [27/50] batch [140/181] time 0.182 (0.114) data 0.000 (0.002) loss 1.8446 (1.5291) teacher_loss 0.2222 (0.1785) loss_zs_kd 0.0683 (0.0403) loss_oracle 0.8857 (0.5965) kd_loss 1.1454 (1.0322) acc 90.6250 (92.9688) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5639 (0.5639) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0253 (0.0217) teacher/usage_max 0.3697 (0.5087) teacher/usage_min 0.3143 (0.1532) teacher/usage_std 0.0257 (0.1510) nleep/row_max_mean 1555.0181 (1552.0145) nleep/row_max_std 56.8926 (55.6257) nleep/row_min_mean 1522.8712 (1519.3761) lr 1.0000e-03 eta 0:08:00
epoch [27/50] batch [160/181] time 0.095 (0.114) data 0.000 (0.002) loss 1.5849 (1.5315) teacher_loss 0.1346 (0.1759) loss_zs_kd 0.0460 (0.0407) loss_oracle 0.7259 (0.6010) kd_loss 1.0644 (1.0349) acc 93.7500 (92.9492) gate/entropy 0.9874 (0.9873) gate/usage_max 0.5638 (0.5639) gate/usage_min 0.2162 (0.2160) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.0304 (0.0226) teacher/usage_max 0.4516 (0.5074) teacher/usage_min 0.2187 (0.1554) teacher/usage_std 0.0951 (0.1495) nleep/row_max_mean 1544.4722 (1551.1716) nleep/row_max_std 54.5930 (55.4122) nleep/row_min_mean 1517.1461 (1518.7189) lr 1.0000e-03 eta 0:07:57
epoch [27/50] batch [180/181] time 0.144 (0.115) data 0.000 (0.002) loss 1.3635 (1.5318) teacher_loss 0.1096 (0.1757) loss_zs_kd 0.0521 (0.0409) loss_oracle 0.4701 (0.6038) kd_loss 0.9928 (1.0337) acc 96.8750 (93.0382) gate/entropy 0.9876 (0.9873) gate/usage_max 0.5635 (0.5639) gate/usage_min 0.2163 (0.2161) gate/usage_std 0.1628 (0.1630) teacher/entropy 0.0467 (0.0237) teacher/usage_max 0.5105 (0.5067) teacher/usage_min 0.0967 (0.1557) teacher/usage_std 0.1741 (0.1491) nleep/row_max_mean 1542.5669 (1551.0174) nleep/row_max_std 62.6755 (55.1196) nleep/row_min_mean 1512.6960 (1518.6507) lr 1.0000e-03 eta 0:07:59
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,407
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 27 *******
******* Domain p best val test acc: 99.8%, epoch: 27 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [28/50] batch [20/181] time 0.138 (0.171) data 0.000 (0.018) loss 1.5831 (1.5684) teacher_loss 0.1257 (0.1516) loss_zs_kd 0.0424 (0.0434) loss_oracle 0.6359 (0.6513) kd_loss 1.1182 (1.0694) acc 96.8750 (94.5312) gate/entropy 0.9874 (0.9875) gate/usage_max 0.5637 (0.5636) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0189 (0.0252) teacher/usage_max 0.4107 (0.4982) teacher/usage_min 0.1821 (0.1621) teacher/usage_std 0.1070 (0.1426) nleep/row_max_mean 1543.3112 (1543.6419) nleep/row_max_std 60.4377 (57.7556) nleep/row_min_mean 1513.7466 (1512.8633) lr 9.3721e-04 eta 0:11:47
epoch [28/50] batch [40/181] time 0.147 (0.160) data 0.000 (0.009) loss 1.7108 (1.5800) teacher_loss 0.2459 (0.1685) loss_zs_kd 0.0317 (0.0448) loss_oracle 0.7212 (0.6606) kd_loss 1.0884 (1.0588) acc 93.7500 (93.9844) gate/entropy 0.9876 (0.9875) gate/usage_max 0.5635 (0.5636) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1628 (0.1629) teacher/entropy 0.0551 (0.0297) teacher/usage_max 0.3994 (0.4890) teacher/usage_min 0.2149 (0.1674) teacher/usage_std 0.0839 (0.1367) nleep/row_max_mean 1544.8026 (1546.1830) nleep/row_max_std 73.6402 (58.4491) nleep/row_min_mean 1513.3972 (1515.0198) lr 9.3721e-04 eta 0:11:00
epoch [28/50] batch [60/181] time 0.182 (0.165) data 0.001 (0.006) loss 1.6549 (1.5775) teacher_loss 0.1073 (0.1673) loss_zs_kd 0.0636 (0.0451) loss_oracle 0.6389 (0.6572) kd_loss 1.1963 (1.0590) acc 93.7500 (93.8021) gate/entropy 0.9879 (0.9875) gate/usage_max 0.5631 (0.5636) gate/usage_min 0.2165 (0.2163) gate/usage_std 0.1625 (0.1628) teacher/entropy 0.0013 (0.0293) teacher/usage_max 0.4686 (0.4870) teacher/usage_min 0.1875 (0.1696) teacher/usage_std 0.1150 (0.1347) nleep/row_max_mean 1538.9849 (1546.6347) nleep/row_max_std 58.0802 (58.6484) nleep/row_min_mean 1509.7996 (1515.3582) lr 9.3721e-04 eta 0:11:16
epoch [28/50] batch [80/181] time 0.165 (0.166) data 0.000 (0.005) loss 1.7763 (1.5731) teacher_loss 0.2374 (0.1718) loss_zs_kd 0.0443 (0.0460) loss_oracle 0.6644 (0.6551) kd_loss 1.1846 (1.0507) acc 90.6250 (93.4766) gate/entropy 0.9875 (0.9875) gate/usage_max 0.5636 (0.5636) gate/usage_min 0.2163 (0.2163) gate/usage_std 0.1628 (0.1628) teacher/entropy 0.0123 (0.0291) teacher/usage_max 0.4982 (0.4918) teacher/usage_min 0.1565 (0.1726) teacher/usage_std 0.1398 (0.1362) nleep/row_max_mean 1544.2166 (1547.7883) nleep/row_max_std 50.8570 (58.1594) nleep/row_min_mean 1512.8958 (1516.4060) lr 9.3721e-04 eta 0:11:17
epoch [28/50] batch [100/181] time 0.173 (0.165) data 0.000 (0.004) loss 1.6150 (1.5681) teacher_loss 0.2572 (0.1710) loss_zs_kd 0.0678 (0.0451) loss_oracle 0.6474 (0.6578) kd_loss 1.0002 (1.0457) acc 87.5000 (93.5000) gate/entropy 0.9873 (0.9875) gate/usage_max 0.5638 (0.5636) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1630 (0.1628) teacher/entropy 0.0235 (0.0299) teacher/usage_max 0.5251 (0.4936) teacher/usage_min 0.2205 (0.1743) teacher/usage_std 0.1363 (0.1371) nleep/row_max_mean 1557.3771 (1547.5145) nleep/row_max_std 58.1744 (57.8425) nleep/row_min_mean 1523.1545 (1516.1441) lr 9.3721e-04 eta 0:11:12
epoch [28/50] batch [120/181] time 0.088 (0.155) data 0.000 (0.003) loss 1.3919 (1.5684) teacher_loss 0.1402 (0.1702) loss_zs_kd 0.0361 (0.0442) loss_oracle 0.6292 (0.6603) kd_loss 0.9191 (1.0459) acc 93.7500 (93.5677) gate/entropy 0.9877 (0.9875) gate/usage_max 0.5634 (0.5636) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1627 (0.1628) teacher/entropy 0.0376 (0.0302) teacher/usage_max 0.5960 (0.4915) teacher/usage_min 0.1253 (0.1762) teacher/usage_std 0.1960 (0.1350) nleep/row_max_mean 1558.3616 (1547.3638) nleep/row_max_std 43.9663 (57.9821) nleep/row_min_mean 1527.9703 (1516.0336) lr 9.3721e-04 eta 0:10:27
epoch [28/50] batch [140/181] time 0.091 (0.147) data 0.000 (0.003) loss 1.4379 (1.5740) teacher_loss 0.1003 (0.1739) loss_zs_kd 0.0428 (0.0448) loss_oracle 0.6576 (0.6670) kd_loss 0.9874 (1.0443) acc 100.0000 (93.5714) gate/entropy 0.9874 (0.9876) gate/usage_max 0.5637 (0.5635) gate/usage_min 0.2163 (0.2163) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0015 (0.0307) teacher/usage_max 0.5627 (0.4947) teacher/usage_min 0.1248 (0.1749) teacher/usage_std 0.1794 (0.1372) nleep/row_max_mean 1555.7948 (1547.0637) nleep/row_max_std 70.6155 (58.0837) nleep/row_min_mean 1520.6246 (1515.7364) lr 9.3721e-04 eta 0:09:51
epoch [28/50] batch [160/181] time 0.070 (0.142) data 0.000 (0.002) loss 1.7413 (1.5792) teacher_loss 0.2229 (0.1745) loss_zs_kd 0.0359 (0.0450) loss_oracle 0.7190 (0.6717) kd_loss 1.1409 (1.0462) acc 90.6250 (93.5742) gate/entropy 0.9878 (0.9876) gate/usage_max 0.5633 (0.5635) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1626 (0.1628) teacher/entropy 0.0436 (0.0305) teacher/usage_max 0.5146 (0.4919) teacher/usage_min 0.1267 (0.1756) teacher/usage_std 0.1594 (0.1355) nleep/row_max_mean 1535.8110 (1546.9984) nleep/row_max_std 62.0797 (58.2288) nleep/row_min_mean 1506.3325 (1515.5776) lr 9.3721e-04 eta 0:09:29
epoch [28/50] batch [180/181] time 0.077 (0.139) data 0.000 (0.002) loss 1.6613 (1.5827) teacher_loss 0.2148 (0.1738) loss_zs_kd 0.0268 (0.0455) loss_oracle 0.6921 (0.6747) kd_loss 1.0871 (1.0487) acc 90.6250 (93.5417) gate/entropy 0.9885 (0.9876) gate/usage_max 0.5626 (0.5635) gate/usage_min 0.2167 (0.2163) gate/usage_std 0.1621 (0.1628) teacher/entropy 0.0222 (0.0291) teacher/usage_max 0.4359 (0.4902) teacher/usage_min 0.1900 (0.1756) teacher/usage_std 0.1044 (0.1348) nleep/row_max_mean 1539.2612 (1547.2332) nleep/row_max_std 56.8034 (58.3711) nleep/row_min_mean 1510.7471 (1515.6554) lr 9.3721e-04 eta 0:09:13
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,411
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [29/50] batch [20/181] time 0.125 (0.154) data 0.000 (0.017) loss 1.4823 (1.5788) teacher_loss 0.1703 (0.1537) loss_zs_kd 0.0416 (0.0434) loss_oracle 0.5990 (0.6836) kd_loss 0.9918 (1.0616) acc 93.7500 (93.9062) gate/entropy 0.9878 (0.9879) gate/usage_max 0.5632 (0.5632) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0395 (0.0288) teacher/usage_max 0.5180 (0.4783) teacher/usage_min 0.1563 (0.1862) teacher/usage_std 0.1478 (0.1251) nleep/row_max_mean 1556.5286 (1553.5585) nleep/row_max_std 64.3459 (58.2297) nleep/row_min_mean 1521.9032 (1520.5381) lr 8.7467e-04 eta 0:10:09
epoch [29/50] batch [40/181] time 0.095 (0.139) data 0.000 (0.009) loss 1.5027 (1.5795) teacher_loss 0.1360 (0.1612) loss_zs_kd 0.0473 (0.0454) loss_oracle 0.6237 (0.6788) kd_loss 1.0313 (1.0561) acc 93.7500 (93.2812) gate/entropy 0.9872 (0.9879) gate/usage_max 0.5639 (0.5632) gate/usage_min 0.2162 (0.2165) gate/usage_std 0.1630 (0.1626) teacher/entropy 0.0147 (0.0262) teacher/usage_max 0.5039 (0.4765) teacher/usage_min 0.0940 (0.1912) teacher/usage_std 0.1742 (0.1223) nleep/row_max_mean 1566.1125 (1553.2047) nleep/row_max_std 53.6776 (59.0353) nleep/row_min_mean 1532.8818 (1520.4182) lr 8.7467e-04 eta 0:09:09
epoch [29/50] batch [60/181] time 0.149 (0.132) data 0.000 (0.006) loss 1.6728 (1.5723) teacher_loss 0.2485 (0.1602) loss_zs_kd 0.0456 (0.0457) loss_oracle 0.6301 (0.6760) kd_loss 1.0864 (1.0512) acc 87.5000 (93.6458) gate/entropy 0.9882 (0.9879) gate/usage_max 0.5628 (0.5632) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1623 (0.1625) teacher/entropy 0.0363 (0.0290) teacher/usage_max 0.4200 (0.4796) teacher/usage_min 0.2827 (0.1880) teacher/usage_std 0.0616 (0.1253) nleep/row_max_mean 1534.1536 (1551.7221) nleep/row_max_std 55.2703 (59.2107) nleep/row_min_mean 1504.0092 (1519.0546) lr 8.7467e-04 eta 0:08:37
epoch [29/50] batch [80/181] time 0.158 (0.138) data 0.000 (0.005) loss 1.5989 (1.5665) teacher_loss 0.2238 (0.1546) loss_zs_kd 0.0519 (0.0437) loss_oracle 0.6076 (0.6667) kd_loss 1.0453 (1.0568) acc 93.7500 (93.9453) gate/entropy 0.9878 (0.9879) gate/usage_max 0.5633 (0.5631) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1626 (0.1625) teacher/entropy 0.0411 (0.0268) teacher/usage_max 0.4601 (0.4797) teacher/usage_min 0.1755 (0.1827) teacher/usage_std 0.1182 (0.1274) nleep/row_max_mean 1547.8020 (1550.5141) nleep/row_max_std 52.4041 (58.3526) nleep/row_min_mean 1516.6932 (1518.1827) lr 8.7467e-04 eta 0:08:59
epoch [29/50] batch [100/181] time 0.168 (0.143) data 0.000 (0.004) loss 1.5737 (1.5591) teacher_loss 0.1266 (0.1498) loss_zs_kd 0.0635 (0.0443) loss_oracle 0.8013 (0.6679) kd_loss 1.0147 (1.0533) acc 93.7500 (94.1562) gate/entropy 0.9881 (0.9880) gate/usage_max 0.5630 (0.5631) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1624 (0.1625) teacher/entropy 0.0696 (0.0268) teacher/usage_max 0.4613 (0.4875) teacher/usage_min 0.2335 (0.1805) teacher/usage_std 0.0951 (0.1314) nleep/row_max_mean 1552.9692 (1549.6222) nleep/row_max_std 60.9366 (57.6500) nleep/row_min_mean 1518.4734 (1517.3684) lr 8.7467e-04 eta 0:09:16
epoch [29/50] batch [120/181] time 0.159 (0.146) data 0.000 (0.003) loss 1.5524 (1.5609) teacher_loss 0.1031 (0.1515) loss_zs_kd 0.0282 (0.0442) loss_oracle 0.6734 (0.6686) kd_loss 1.0986 (1.0531) acc 93.7500 (94.1146) gate/entropy 0.9877 (0.9880) gate/usage_max 0.5634 (0.5631) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1627 (0.1625) teacher/entropy 0.0071 (0.0277) teacher/usage_max 0.4375 (0.4857) teacher/usage_min 0.2204 (0.1788) teacher/usage_std 0.0889 (0.1313) nleep/row_max_mean 1559.6776 (1548.8748) nleep/row_max_std 50.6393 (57.0497) nleep/row_min_mean 1530.7063 (1516.7667) lr 8.7467e-04 eta 0:09:25
epoch [29/50] batch [140/181] time 0.150 (0.148) data 0.000 (0.003) loss 1.5871 (1.5559) teacher_loss 0.1171 (0.1512) loss_zs_kd 0.0634 (0.0448) loss_oracle 0.7321 (0.6667) kd_loss 1.0723 (1.0489) acc 96.8750 (94.1071) gate/entropy 0.9882 (0.9880) gate/usage_max 0.5629 (0.5630) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1623 (0.1624) teacher/entropy 0.0030 (0.0268) teacher/usage_max 0.4693 (0.4913) teacher/usage_min 0.2500 (0.1747) teacher/usage_std 0.0970 (0.1353) nleep/row_max_mean 1553.4463 (1548.1311) nleep/row_max_std 66.3706 (56.8234) nleep/row_min_mean 1516.5951 (1515.9617) lr 8.7467e-04 eta 0:09:30
epoch [29/50] batch [160/181] time 0.151 (0.149) data 0.000 (0.002) loss 1.7604 (1.5571) teacher_loss 0.1840 (0.1511) loss_zs_kd 0.0375 (0.0445) loss_oracle 0.6897 (0.6676) kd_loss 1.2129 (1.0500) acc 93.7500 (94.0820) gate/entropy 0.9888 (0.9881) gate/usage_max 0.5622 (0.5630) gate/usage_min 0.2170 (0.2166) gate/usage_std 0.1619 (0.1624) teacher/entropy 0.0118 (0.0261) teacher/usage_max 0.4074 (0.4898) teacher/usage_min 0.2797 (0.1745) teacher/usage_std 0.0541 (0.1349) nleep/row_max_mean 1527.3699 (1548.1032) nleep/row_max_std 61.9823 (56.7372) nleep/row_min_mean 1498.7461 (1515.7953) lr 8.7467e-04 eta 0:09:31
epoch [29/50] batch [180/181] time 0.165 (0.150) data 0.000 (0.002) loss 1.4923 (1.5567) teacher_loss 0.0251 (0.1513) loss_zs_kd 0.0338 (0.0449) loss_oracle 0.5899 (0.6659) kd_loss 1.1553 (1.0501) acc 100.0000 (94.0799) gate/entropy 0.9884 (0.9881) gate/usage_max 0.5626 (0.5630) gate/usage_min 0.2169 (0.2166) gate/usage_std 0.1622 (0.1624) teacher/entropy 0.0107 (0.0257) teacher/usage_max 0.4662 (0.4889) teacher/usage_min 0.1565 (0.1721) teacher/usage_std 0.1302 (0.1358) nleep/row_max_mean 1535.2358 (1547.5805) nleep/row_max_std 55.7535 (56.5947) nleep/row_min_mean 1505.1780 (1515.3453) lr 8.7467e-04 eta 0:09:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,405
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [30/50] batch [20/181] time 0.082 (0.137) data 0.000 (0.016) loss 1.3530 (1.5584) teacher_loss 0.1350 (0.1944) loss_zs_kd 0.0355 (0.0429) loss_oracle 0.5796 (0.6454) kd_loss 0.9104 (1.0199) acc 90.6250 (92.9688) gate/entropy 0.9880 (0.9882) gate/usage_max 0.5631 (0.5628) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1625 (0.1623) teacher/entropy 0.0370 (0.0312) teacher/usage_max 0.6051 (0.5216) teacher/usage_min 0.1529 (0.1508) teacher/usage_std 0.1956 (0.1568) nleep/row_max_mean 1558.6831 (1544.8913) nleep/row_max_std 71.7513 (59.2540) nleep/row_min_mean 1520.3252 (1511.9954) lr 8.1262e-04 eta 0:08:38
epoch [30/50] batch [40/181] time 0.194 (0.140) data 0.000 (0.008) loss 1.6237 (1.5688) teacher_loss 0.3201 (0.2038) loss_zs_kd 0.0571 (0.0409) loss_oracle 0.5432 (0.6306) kd_loss 1.0034 (1.0292) acc 87.5000 (92.4219) gate/entropy 0.9885 (0.9883) gate/usage_max 0.5625 (0.5627) gate/usage_min 0.2170 (0.2169) gate/usage_std 0.1621 (0.1622) teacher/entropy 0.0606 (0.0312) teacher/usage_max 0.4843 (0.5102) teacher/usage_min 0.0728 (0.1487) teacher/usage_std 0.1850 (0.1554) nleep/row_max_mean 1531.5425 (1542.1156) nleep/row_max_std 65.1938 (60.0825) nleep/row_min_mean 1500.6438 (1509.7842) lr 8.1262e-04 eta 0:08:45
epoch [30/50] batch [60/181] time 0.113 (0.131) data 0.001 (0.006) loss 1.6542 (1.5691) teacher_loss 0.2467 (0.1942) loss_zs_kd 0.0265 (0.0417) loss_oracle 0.7233 (0.6376) kd_loss 1.0325 (1.0353) acc 87.5000 (92.5521) gate/entropy 0.9882 (0.9883) gate/usage_max 0.5628 (0.5627) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1623 (0.1622) teacher/entropy 0.0553 (0.0312) teacher/usage_max 0.4578 (0.5019) teacher/usage_min 0.1886 (0.1560) teacher/usage_std 0.1108 (0.1485) nleep/row_max_mean 1542.8944 (1542.6855) nleep/row_max_std 52.2784 (59.7273) nleep/row_min_mean 1512.1107 (1510.4211) lr 8.1262e-04 eta 0:08:11
epoch [30/50] batch [80/181] time 0.080 (0.126) data 0.000 (0.004) loss 1.4465 (1.5656) teacher_loss 0.0572 (0.1858) loss_zs_kd 0.0062 (0.0417) loss_oracle 0.6755 (0.6426) kd_loss 1.0484 (1.0376) acc 100.0000 (92.8516) gate/entropy 0.9890 (0.9883) gate/usage_max 0.5620 (0.5627) gate/usage_min 0.2172 (0.2169) gate/usage_std 0.1617 (0.1622) teacher/entropy 0.0610 (0.0314) teacher/usage_max 0.4349 (0.5012) teacher/usage_min 0.1567 (0.1616) teacher/usage_std 0.1253 (0.1455) nleep/row_max_mean 1533.7845 (1542.3821) nleep/row_max_std 67.0670 (59.1688) nleep/row_min_mean 1503.0111 (1510.3995) lr 8.1262e-04 eta 0:07:50
epoch [30/50] batch [100/181] time 0.188 (0.126) data 0.000 (0.003) loss 1.5197 (1.5630) teacher_loss 0.2116 (0.1821) loss_zs_kd 0.0314 (0.0419) loss_oracle 0.5463 (0.6443) kd_loss 1.0193 (1.0378) acc 93.7500 (92.8125) gate/entropy 0.9880 (0.9884) gate/usage_max 0.5631 (0.5627) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1625 (0.1622) teacher/entropy 0.0481 (0.0315) teacher/usage_max 0.4807 (0.4985) teacher/usage_min 0.1189 (0.1672) teacher/usage_std 0.1551 (0.1417) nleep/row_max_mean 1542.2156 (1541.8653) nleep/row_max_std 64.8928 (59.5891) nleep/row_min_mean 1509.7974 (1509.9895) lr 8.1262e-04 eta 0:07:45
epoch [30/50] batch [120/181] time 0.088 (0.125) data 0.000 (0.003) loss 1.6248 (1.5577) teacher_loss 0.1584 (0.1801) loss_zs_kd 0.0619 (0.0423) loss_oracle 0.7668 (0.6429) kd_loss 1.0520 (1.0350) acc 93.7500 (92.9427) gate/entropy 0.9882 (0.9884) gate/usage_max 0.5629 (0.5627) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1623 (0.1622) teacher/entropy 0.0263 (0.0321) teacher/usage_max 0.4678 (0.4994) teacher/usage_min 0.1973 (0.1681) teacher/usage_std 0.1104 (0.1419) nleep/row_max_mean 1541.3785 (1540.9770) nleep/row_max_std 63.1946 (60.1741) nleep/row_min_mean 1507.6692 (1509.0897) lr 8.1262e-04 eta 0:07:39
epoch [30/50] batch [140/181] time 0.167 (0.126) data 0.000 (0.003) loss 1.5525 (1.5559) teacher_loss 0.2217 (0.1817) loss_zs_kd 0.0523 (0.0429) loss_oracle 0.6018 (0.6401) kd_loss 1.0037 (1.0327) acc 93.7500 (93.1920) gate/entropy 0.9884 (0.9884) gate/usage_max 0.5627 (0.5627) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1622 (0.1622) teacher/entropy 0.0365 (0.0312) teacher/usage_max 0.5091 (0.5018) teacher/usage_min 0.1150 (0.1695) teacher/usage_std 0.1637 (0.1421) nleep/row_max_mean 1542.8374 (1541.4503) nleep/row_max_std 55.9484 (60.6261) nleep/row_min_mean 1512.7441 (1509.5266) lr 8.1262e-04 eta 0:07:41
epoch [30/50] batch [160/181] time 0.142 (0.129) data 0.000 (0.002) loss 1.5502 (1.5576) teacher_loss 0.1434 (0.1821) loss_zs_kd 0.0434 (0.0433) loss_oracle 0.6933 (0.6395) kd_loss 1.0385 (1.0341) acc 93.7500 (93.1836) gate/entropy 0.9885 (0.9884) gate/usage_max 0.5625 (0.5627) gate/usage_min 0.2170 (0.2169) gate/usage_std 0.1621 (0.1622) teacher/entropy 0.0094 (0.0308) teacher/usage_max 0.4997 (0.5018) teacher/usage_min 0.1575 (0.1678) teacher/usage_std 0.1398 (0.1427) nleep/row_max_mean 1544.2711 (1541.2621) nleep/row_max_std 69.5287 (61.0257) nleep/row_min_mean 1512.2123 (1509.2897) lr 8.1262e-04 eta 0:07:49
epoch [30/50] batch [180/181] time 0.148 (0.131) data 0.000 (0.002) loss 1.5226 (1.5542) teacher_loss 0.1781 (0.1812) loss_zs_kd 0.0251 (0.0430) loss_oracle 0.5681 (0.6376) kd_loss 1.0479 (1.0327) acc 93.7500 (93.3507) gate/entropy 0.9888 (0.9884) gate/usage_max 0.5623 (0.5626) gate/usage_min 0.2172 (0.2169) gate/usage_std 0.1619 (0.1621) teacher/entropy 0.0011 (0.0311) teacher/usage_max 0.5001 (0.5024) teacher/usage_min 0.0313 (0.1648) teacher/usage_std 0.2140 (0.1442) nleep/row_max_mean 1540.7261 (1541.4409) nleep/row_max_std 58.3970 (60.7015) nleep/row_min_mean 1505.7661 (1509.3869) lr 8.1262e-04 eta 0:07:53
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [31/50] batch [20/181] time 0.152 (0.166) data 0.000 (0.014) loss 1.5114 (1.5366) teacher_loss 0.2373 (0.1875) loss_zs_kd 0.0424 (0.0402) loss_oracle 0.5246 (0.6241) kd_loss 0.9906 (1.0170) acc 96.8750 (93.7500) gate/entropy 0.9885 (0.9886) gate/usage_max 0.5626 (0.5624) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.1621 (0.1620) teacher/entropy 0.0708 (0.0309) teacher/usage_max 0.4857 (0.5153) teacher/usage_min 0.1659 (0.1619) teacher/usage_std 0.1310 (0.1490) nleep/row_max_mean 1544.6204 (1546.8342) nleep/row_max_std 67.3603 (54.7287) nleep/row_min_mean 1510.6312 (1513.7553) lr 7.5131e-04 eta 0:09:58
epoch [31/50] batch [40/181] time 0.110 (0.156) data 0.000 (0.007) loss 1.3471 (1.5166) teacher_loss 0.1588 (0.1989) loss_zs_kd 0.0234 (0.0372) loss_oracle 0.5823 (0.6134) kd_loss 0.8855 (0.9924) acc 90.6250 (92.7344) gate/entropy 0.9887 (0.9886) gate/usage_max 0.5623 (0.5625) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.1619 (0.1620) teacher/entropy 0.0407 (0.0300) teacher/usage_max 0.6290 (0.5347) teacher/usage_min 0.1525 (0.1480) teacher/usage_std 0.2108 (0.1637) nleep/row_max_mean 1554.4485 (1547.9164) nleep/row_max_std 40.8520 (55.4243) nleep/row_min_mean 1517.7522 (1514.0980) lr 7.5131e-04 eta 0:09:19
epoch [31/50] batch [60/181] time 0.131 (0.152) data 0.000 (0.005) loss 1.4687 (1.5264) teacher_loss 0.1814 (0.2114) loss_zs_kd 0.0387 (0.0377) loss_oracle 0.6064 (0.6083) kd_loss 0.9648 (0.9921) acc 93.7500 (92.2917) gate/entropy 0.9885 (0.9886) gate/usage_max 0.5625 (0.5624) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.1621 (0.1620) teacher/entropy 0.0355 (0.0325) teacher/usage_max 0.5514 (0.5352) teacher/usage_min 0.0909 (0.1428) teacher/usage_std 0.1888 (0.1656) nleep/row_max_mean 1554.8073 (1547.1322) nleep/row_max_std 59.4173 (57.1987) nleep/row_min_mean 1518.9683 (1513.4577) lr 7.5131e-04 eta 0:09:02
epoch [31/50] batch [80/181] time 0.092 (0.144) data 0.000 (0.004) loss 1.3950 (1.5225) teacher_loss 0.1906 (0.2102) loss_zs_kd 0.0426 (0.0362) loss_oracle 0.4997 (0.6025) kd_loss 0.9333 (0.9929) acc 93.7500 (92.3828) gate/entropy 0.9886 (0.9886) gate/usage_max 0.5624 (0.5624) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.1620 (0.1620) teacher/entropy 0.0549 (0.0358) teacher/usage_max 0.5633 (0.5314) teacher/usage_min 0.1199 (0.1378) teacher/usage_std 0.1814 (0.1663) nleep/row_max_mean 1547.4843 (1547.4560) nleep/row_max_std 59.5274 (57.2505) nleep/row_min_mean 1514.9158 (1513.8673) lr 7.5131e-04 eta 0:08:28
epoch [31/50] batch [100/181] time 0.088 (0.138) data 0.000 (0.003) loss 1.6289 (1.5192) teacher_loss 0.2882 (0.2190) loss_zs_kd 0.0412 (0.0356) loss_oracle 0.5539 (0.5965) kd_loss 1.0431 (0.9841) acc 87.5000 (92.0938) gate/entropy 0.9889 (0.9886) gate/usage_max 0.5621 (0.5624) gate/usage_min 0.2173 (0.2171) gate/usage_std 0.1618 (0.1620) teacher/entropy 0.0642 (0.0363) teacher/usage_max 0.4677 (0.5382) teacher/usage_min 0.0938 (0.1307) teacher/usage_std 0.1698 (0.1723) nleep/row_max_mean 1534.1487 (1547.5594) nleep/row_max_std 71.5705 (57.5431) nleep/row_min_mean 1503.0510 (1513.7474) lr 7.5131e-04 eta 0:08:04
epoch [31/50] batch [120/181] time 0.092 (0.135) data 0.000 (0.003) loss 1.7107 (1.5033) teacher_loss 0.3307 (0.2215) loss_zs_kd 0.0215 (0.0349) loss_oracle 0.6807 (0.5895) kd_loss 1.0289 (0.9695) acc 81.2500 (91.8750) gate/entropy 0.9892 (0.9886) gate/usage_max 0.5618 (0.5624) gate/usage_min 0.2175 (0.2172) gate/usage_std 0.1616 (0.1620) teacher/entropy 0.0511 (0.0372) teacher/usage_max 0.4957 (0.5515) teacher/usage_min 0.0380 (0.1196) teacher/usage_std 0.2092 (0.1822) nleep/row_max_mean 1532.0486 (1548.0418) nleep/row_max_std 65.4131 (57.6418) nleep/row_min_mean 1497.1780 (1513.9018) lr 7.5131e-04 eta 0:07:51
epoch [31/50] batch [140/181] time 0.156 (0.132) data 0.000 (0.002) loss 1.3773 (1.4954) teacher_loss 0.3593 (0.2257) loss_zs_kd 0.0401 (0.0339) loss_oracle 0.5605 (0.5835) kd_loss 0.7177 (0.9609) acc 81.2500 (91.6741) gate/entropy 0.9882 (0.9886) gate/usage_max 0.5629 (0.5624) gate/usage_min 0.2171 (0.2172) gate/usage_std 0.1623 (0.1620) teacher/entropy 0.0404 (0.0388) teacher/usage_max 0.8055 (0.5579) teacher/usage_min 0.0353 (0.1115) teacher/usage_std 0.3377 (0.1882) nleep/row_max_mean 1554.6399 (1547.3940) nleep/row_max_std 47.5673 (57.8453) nleep/row_min_mean 1516.5338 (1513.1642) lr 7.5131e-04 eta 0:07:40
epoch [31/50] batch [160/181] time 0.091 (0.129) data 0.000 (0.002) loss 1.4366 (1.4876) teacher_loss 0.4164 (0.2374) loss_zs_kd 0.0484 (0.0329) loss_oracle 0.4503 (0.5747) kd_loss 0.7708 (0.9464) acc 84.3750 (91.1523) gate/entropy 0.9885 (0.9886) gate/usage_max 0.5626 (0.5624) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1621 (0.1620) teacher/entropy 0.0548 (0.0391) teacher/usage_max 0.7350 (0.5721) teacher/usage_min 0.0193 (0.1021) teacher/usage_std 0.2986 (0.1981) nleep/row_max_mean 1537.3278 (1547.1509) nleep/row_max_std 68.3977 (57.9913) nleep/row_min_mean 1498.5028 (1512.6682) lr 7.5131e-04 eta 0:07:25
epoch [31/50] batch [180/181] time 0.073 (0.125) data 0.000 (0.002) loss 1.4741 (1.4840) teacher_loss 0.3046 (0.2441) loss_zs_kd 0.0329 (0.0319) loss_oracle 0.5075 (0.5701) kd_loss 0.8993 (0.9389) acc 87.5000 (90.7986) gate/entropy 0.9880 (0.9886) gate/usage_max 0.5630 (0.5625) gate/usage_min 0.2171 (0.2172) gate/usage_std 0.1624 (0.1620) teacher/entropy 0.0006 (0.0409) teacher/usage_max 0.6563 (0.5775) teacher/usage_min 0.0000 (0.0949) teacher/usage_std 0.2680 (0.2030) nleep/row_max_mean 1559.7678 (1546.5052) nleep/row_max_std 48.4576 (58.5200) nleep/row_min_mean 1516.6189 (1511.8100) lr 7.5131e-04 eta 0:07:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,373
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [32/50] batch [20/181] time 0.162 (0.125) data 0.000 (0.016) loss 1.3722 (1.4341) teacher_loss 0.2866 (0.2924) loss_zs_kd 0.0260 (0.0254) loss_oracle 0.5174 (0.5516) kd_loss 0.8139 (0.8532) acc 87.5000 (87.9688) gate/entropy 0.9879 (0.9882) gate/usage_max 0.5632 (0.5628) gate/usage_min 0.2171 (0.2173) gate/usage_std 0.1626 (0.1623) teacher/entropy 0.0418 (0.0440) teacher/usage_max 0.7030 (0.6594) teacher/usage_min 0.0001 (0.0267) teacher/usage_std 0.2881 (0.2647) nleep/row_max_mean 1567.8230 (1545.8139) nleep/row_max_std 57.3432 (57.4918) nleep/row_min_mean 1524.5518 (1507.9830) lr 6.9098e-04 eta 0:07:06
epoch [32/50] batch [40/181] time 0.136 (0.134) data 0.000 (0.008) loss 1.4219 (1.4066) teacher_loss 0.2009 (0.2594) loss_zs_kd 0.0341 (0.0268) loss_oracle 0.5551 (0.5585) kd_loss 0.9264 (0.8545) acc 93.7500 (90.0781) gate/entropy 0.9882 (0.9883) gate/usage_max 0.5629 (0.5628) gate/usage_min 0.2173 (0.2173) gate/usage_std 0.1623 (0.1623) teacher/entropy 0.0422 (0.0462) teacher/usage_max 0.5846 (0.6575) teacher/usage_min 0.0000 (0.0240) teacher/usage_std 0.2456 (0.2649) nleep/row_max_mean 1548.8313 (1544.2647) nleep/row_max_std 62.3748 (59.5414) nleep/row_min_mean 1507.8367 (1505.7338) lr 6.9098e-04 eta 0:07:36
epoch [32/50] batch [60/181] time 0.164 (0.140) data 0.001 (0.006) loss 1.6283 (1.4217) teacher_loss 0.5440 (0.2787) loss_zs_kd 0.0362 (0.0260) loss_oracle 0.5260 (0.5599) kd_loss 0.8032 (0.8500) acc 78.1250 (89.3229) gate/entropy 0.9885 (0.9883) gate/usage_max 0.5625 (0.5628) gate/usage_min 0.2175 (0.2173) gate/usage_std 0.1621 (0.1622) teacher/entropy 0.0280 (0.0478) teacher/usage_max 0.7292 (0.6599) teacher/usage_min 0.0000 (0.0231) teacher/usage_std 0.3010 (0.2654) nleep/row_max_mean 1539.3557 (1543.8944) nleep/row_max_std 55.2312 (59.6294) nleep/row_min_mean 1500.9741 (1504.9493) lr 6.9098e-04 eta 0:07:51
epoch [32/50] batch [80/181] time 0.117 (0.141) data 0.000 (0.004) loss 1.6218 (1.4222) teacher_loss 0.3142 (0.2862) loss_zs_kd 0.0151 (0.0265) loss_oracle 0.5880 (0.5533) kd_loss 1.0061 (0.8462) acc 84.3750 (88.9453) gate/entropy 0.9882 (0.9882) gate/usage_max 0.5629 (0.5628) gate/usage_min 0.2174 (0.2173) gate/usage_std 0.1623 (0.1623) teacher/entropy 0.0313 (0.0452) teacher/usage_max 0.5127 (0.6664) teacher/usage_min 0.0200 (0.0230) teacher/usage_std 0.2223 (0.2690) nleep/row_max_mean 1538.2356 (1545.4380) nleep/row_max_std 52.5037 (58.7413) nleep/row_min_mean 1501.0146 (1505.9612) lr 6.9098e-04 eta 0:07:53
epoch [32/50] batch [100/181] time 0.155 (0.143) data 0.000 (0.003) loss 1.1697 (1.4224) teacher_loss 0.1458 (0.2803) loss_zs_kd 0.0154 (0.0255) loss_oracle 0.4917 (0.5563) kd_loss 0.7703 (0.8512) acc 90.6250 (89.3125) gate/entropy 0.9884 (0.9882) gate/usage_max 0.5627 (0.5628) gate/usage_min 0.2175 (0.2173) gate/usage_std 0.1622 (0.1623) teacher/entropy 0.0439 (0.0447) teacher/usage_max 0.7472 (0.6615) teacher/usage_min 0.0057 (0.0208) teacher/usage_std 0.3088 (0.2681) nleep/row_max_mean 1545.3236 (1545.9150) nleep/row_max_std 65.0882 (59.1799) nleep/row_min_mean 1506.3179 (1505.9386) lr 6.9098e-04 eta 0:07:58
epoch [32/50] batch [120/181] time 0.149 (0.144) data 0.000 (0.003) loss 1.2412 (1.4262) teacher_loss 0.2264 (0.2848) loss_zs_kd 0.0222 (0.0253) loss_oracle 0.4803 (0.5577) kd_loss 0.7635 (0.8499) acc 93.7500 (89.0365) gate/entropy 0.9883 (0.9882) gate/usage_max 0.5627 (0.5628) gate/usage_min 0.2175 (0.2174) gate/usage_std 0.1622 (0.1623) teacher/entropy 0.0862 (0.0462) teacher/usage_max 0.7094 (0.6612) teacher/usage_min 0.0307 (0.0200) teacher/usage_std 0.2819 (0.2680) nleep/row_max_mean 1535.9323 (1544.9307) nleep/row_max_std 63.8747 (60.0056) nleep/row_min_mean 1498.8217 (1504.6883) lr 6.9098e-04 eta 0:07:58
epoch [32/50] batch [140/181] time 0.138 (0.145) data 0.000 (0.003) loss 1.4044 (1.4259) teacher_loss 0.2487 (0.2847) loss_zs_kd 0.0239 (0.0256) loss_oracle 0.5692 (0.5604) kd_loss 0.8593 (0.8482) acc 90.6250 (89.0625) gate/entropy 0.9874 (0.9882) gate/usage_max 0.5637 (0.5629) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1629 (0.1623) teacher/entropy 0.0240 (0.0464) teacher/usage_max 0.6734 (0.6629) teacher/usage_min 0.0000 (0.0184) teacher/usage_std 0.2749 (0.2701) nleep/row_max_mean 1564.3363 (1545.0780) nleep/row_max_std 48.1401 (60.1036) nleep/row_min_mean 1523.9900 (1504.4351) lr 6.9098e-04 eta 0:07:58
epoch [32/50] batch [160/181] time 0.131 (0.146) data 0.000 (0.002) loss 1.2519 (1.4208) teacher_loss 0.2245 (0.2783) loss_zs_kd 0.0350 (0.0252) loss_oracle 0.5609 (0.5630) kd_loss 0.7295 (0.8484) acc 90.6250 (89.2773) gate/entropy 0.9876 (0.9882) gate/usage_max 0.5635 (0.5629) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1628 (0.1623) teacher/entropy 0.0499 (0.0453) teacher/usage_max 0.7832 (0.6637) teacher/usage_min 0.0000 (0.0172) teacher/usage_std 0.3302 (0.2711) nleep/row_max_mean 1560.5463 (1545.4584) nleep/row_max_std 57.4944 (59.8126) nleep/row_min_mean 1517.7261 (1504.6679) lr 6.9098e-04 eta 0:07:57
epoch [32/50] batch [180/181] time 0.080 (0.143) data 0.000 (0.002) loss 1.5715 (1.4213) teacher_loss 0.3165 (0.2788) loss_zs_kd 0.0214 (0.0249) loss_oracle 0.6759 (0.5637) kd_loss 0.9063 (0.8482) acc 90.6250 (89.3229) gate/entropy 0.9877 (0.9882) gate/usage_max 0.5634 (0.5629) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1627 (0.1623) teacher/entropy 0.0252 (0.0445) teacher/usage_max 0.6222 (0.6648) teacher/usage_min 0.0000 (0.0160) teacher/usage_std 0.2560 (0.2717) nleep/row_max_mean 1556.3955 (1545.7621) nleep/row_max_std 60.7663 (59.4937) nleep/row_min_mean 1507.6758 (1504.7236) lr 6.9098e-04 eta 0:07:47
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,384
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [33/50] batch [20/181] time 0.071 (0.144) data 0.000 (0.018) loss 1.5523 (1.4497) teacher_loss 0.4977 (0.3019) loss_zs_kd 0.0194 (0.0231) loss_oracle 0.5633 (0.5703) kd_loss 0.7632 (0.8511) acc 84.3750 (89.0625) gate/entropy 0.9876 (0.9878) gate/usage_max 0.5635 (0.5632) gate/usage_min 0.2174 (0.2175) gate/usage_std 0.1627 (0.1626) teacher/entropy 0.0904 (0.0514) teacher/usage_max 0.7050 (0.6618) teacher/usage_min 0.0312 (0.0062) teacher/usage_std 0.2794 (0.2731) nleep/row_max_mean 1559.3104 (1547.4900) nleep/row_max_std 69.6757 (60.2123) nleep/row_min_mean 1510.3123 (1504.2240) lr 6.3188e-04 eta 0:07:46
epoch [33/50] batch [40/181] time 0.103 (0.126) data 0.000 (0.009) loss 1.3746 (1.4293) teacher_loss 0.3211 (0.2922) loss_zs_kd 0.0295 (0.0243) loss_oracle 0.5721 (0.5709) kd_loss 0.7527 (0.8395) acc 84.3750 (88.5938) gate/entropy 0.9877 (0.9879) gate/usage_max 0.5634 (0.5632) gate/usage_min 0.2175 (0.2175) gate/usage_std 0.1627 (0.1625) teacher/entropy 0.1211 (0.0501) teacher/usage_max 0.6836 (0.6712) teacher/usage_min 0.0339 (0.0064) teacher/usage_std 0.2676 (0.2772) nleep/row_max_mean 1544.7516 (1544.9531) nleep/row_max_std 60.0485 (59.6352) nleep/row_min_mean 1507.6095 (1502.0868) lr 6.3188e-04 eta 0:06:44
epoch [33/50] batch [60/181] time 0.089 (0.125) data 0.001 (0.006) loss 1.6146 (1.4232) teacher_loss 0.4217 (0.2893) loss_zs_kd 0.0299 (0.0239) loss_oracle 0.5430 (0.5694) kd_loss 0.9065 (0.8372) acc 81.2500 (88.9062) gate/entropy 0.9877 (0.9879) gate/usage_max 0.5634 (0.5632) gate/usage_min 0.2175 (0.2176) gate/usage_std 0.1627 (0.1625) teacher/entropy 0.0291 (0.0493) teacher/usage_max 0.6183 (0.6730) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2547 (0.2776) nleep/row_max_mean 1546.2661 (1544.9934) nleep/row_max_std 47.2007 (59.9003) nleep/row_min_mean 1503.9656 (1502.0520) lr 6.3188e-04 eta 0:06:39
epoch [33/50] batch [80/181] time 0.078 (0.121) data 0.000 (0.005) loss 1.3834 (1.4233) teacher_loss 0.1778 (0.2829) loss_zs_kd 0.0351 (0.0244) loss_oracle 0.5636 (0.5745) kd_loss 0.9063 (0.8409) acc 93.7500 (89.1406) gate/entropy 0.9880 (0.9879) gate/usage_max 0.5630 (0.5632) gate/usage_min 0.2177 (0.2176) gate/usage_std 0.1624 (0.1626) teacher/entropy 0.0392 (0.0469) teacher/usage_max 0.6081 (0.6716) teacher/usage_min 0.0000 (0.0088) teacher/usage_std 0.2517 (0.2765) nleep/row_max_mean 1540.1672 (1545.3362) nleep/row_max_std 62.4195 (59.9932) nleep/row_min_mean 1497.2133 (1502.0053) lr 6.3188e-04 eta 0:06:24
epoch [33/50] batch [100/181] time 0.102 (0.119) data 0.000 (0.004) loss 1.4954 (1.4121) teacher_loss 0.1763 (0.2746) loss_zs_kd 0.0111 (0.0238) loss_oracle 0.6620 (0.5749) kd_loss 0.9826 (0.8382) acc 90.6250 (89.1562) gate/entropy 0.9883 (0.9879) gate/usage_max 0.5628 (0.5632) gate/usage_min 0.2179 (0.2176) gate/usage_std 0.1623 (0.1626) teacher/entropy 0.0565 (0.0474) teacher/usage_max 0.5086 (0.6733) teacher/usage_min 0.0239 (0.0095) teacher/usage_std 0.2194 (0.2769) nleep/row_max_mean 1524.5112 (1545.7455) nleep/row_max_std 61.7322 (60.3056) nleep/row_min_mean 1482.1938 (1502.0625) lr 6.3188e-04 eta 0:06:16
epoch [33/50] batch [120/181] time 0.091 (0.122) data 0.000 (0.003) loss 1.6497 (1.4091) teacher_loss 0.5880 (0.2713) loss_zs_kd 0.0463 (0.0240) loss_oracle 0.5391 (0.5732) kd_loss 0.7690 (0.8391) acc 81.2500 (89.6094) gate/entropy 0.9880 (0.9878) gate/usage_max 0.5631 (0.5633) gate/usage_min 0.2178 (0.2176) gate/usage_std 0.1625 (0.1626) teacher/entropy 0.0738 (0.0479) teacher/usage_max 0.7159 (0.6714) teacher/usage_min 0.0242 (0.0113) teacher/usage_std 0.2871 (0.2752) nleep/row_max_mean 1534.0883 (1545.8297) nleep/row_max_std 62.7355 (60.2109) nleep/row_min_mean 1492.2445 (1502.3784) lr 6.3188e-04 eta 0:06:21
epoch [33/50] batch [140/181] time 0.157 (0.123) data 0.000 (0.003) loss 1.4956 (1.4086) teacher_loss 0.5015 (0.2704) loss_zs_kd 0.0364 (0.0239) loss_oracle 0.5366 (0.5740) kd_loss 0.7075 (0.8392) acc 78.1250 (89.6429) gate/entropy 0.9877 (0.9878) gate/usage_max 0.5634 (0.5633) gate/usage_min 0.2177 (0.2176) gate/usage_std 0.1627 (0.1626) teacher/entropy 0.0469 (0.0492) teacher/usage_max 0.8091 (0.6703) teacher/usage_min 0.0000 (0.0102) teacher/usage_std 0.3454 (0.2751) nleep/row_max_mean 1545.4868 (1545.6057) nleep/row_max_std 59.3346 (60.5755) nleep/row_min_mean 1499.7295 (1501.9709) lr 6.3188e-04 eta 0:06:24
epoch [33/50] batch [160/181] time 0.171 (0.128) data 0.000 (0.002) loss 1.2849 (1.4062) teacher_loss 0.2806 (0.2722) loss_zs_kd 0.0317 (0.0239) loss_oracle 0.4962 (0.5707) kd_loss 0.7403 (0.8367) acc 93.7500 (89.6094) gate/entropy 0.9872 (0.9878) gate/usage_max 0.5639 (0.5633) gate/usage_min 0.2175 (0.2176) gate/usage_std 0.1630 (0.1626) teacher/entropy 0.0692 (0.0483) teacher/usage_max 0.7507 (0.6736) teacher/usage_min 0.0003 (0.0094) teacher/usage_std 0.3121 (0.2769) nleep/row_max_mean 1553.9360 (1546.3052) nleep/row_max_std 63.0567 (60.1244) nleep/row_min_mean 1510.3511 (1502.4541) lr 6.3188e-04 eta 0:06:36
epoch [33/50] batch [180/181] time 0.164 (0.132) data 0.000 (0.002) loss 1.3455 (1.3965) teacher_loss 0.1914 (0.2665) loss_zs_kd 0.0372 (0.0236) loss_oracle 0.5640 (0.5667) kd_loss 0.8535 (0.8349) acc 93.7500 (89.8958) gate/entropy 0.9876 (0.9878) gate/usage_max 0.5636 (0.5633) gate/usage_min 0.2177 (0.2176) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0241 (0.0473) teacher/usage_max 0.6793 (0.6763) teacher/usage_min 0.0000 (0.0092) teacher/usage_std 0.2775 (0.2778) nleep/row_max_mean 1552.5107 (1547.0352) nleep/row_max_std 49.6166 (59.9250) nleep/row_min_mean 1502.2007 (1503.0980) lr 6.3188e-04 eta 0:06:45
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,394
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [34/50] batch [20/181] time 0.164 (0.179) data 0.000 (0.014) loss 1.4125 (1.3709) teacher_loss 0.1645 (0.2397) loss_zs_kd 0.0151 (0.0284) loss_oracle 0.6928 (0.5721) kd_loss 0.8941 (0.8309) acc 96.8750 (92.3438) gate/entropy 0.9878 (0.9876) gate/usage_max 0.5633 (0.5636) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1626 (0.1628) teacher/entropy 0.0476 (0.0312) teacher/usage_max 0.6109 (0.6953) teacher/usage_min 0.0002 (0.0040) teacher/usage_std 0.2524 (0.2878) nleep/row_max_mean 1548.0430 (1546.9462) nleep/row_max_std 56.7288 (59.9357) nleep/row_min_mean 1499.8657 (1501.6464) lr 5.7422e-04 eta 0:09:06
epoch [34/50] batch [40/181] time 0.157 (0.170) data 0.000 (0.007) loss 1.3340 (1.3816) teacher_loss 0.3274 (0.2685) loss_zs_kd 0.0200 (0.0254) loss_oracle 0.5189 (0.5560) kd_loss 0.7371 (0.8224) acc 90.6250 (90.8594) gate/entropy 0.9878 (0.9876) gate/usage_max 0.5633 (0.5635) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1626 (0.1628) teacher/entropy 0.0182 (0.0297) teacher/usage_max 0.8082 (0.7060) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.3448 (0.2926) nleep/row_max_mean 1545.4082 (1546.5083) nleep/row_max_std 63.5168 (60.6133) nleep/row_min_mean 1497.9688 (1500.8330) lr 5.7422e-04 eta 0:08:34
epoch [34/50] batch [60/181] time 0.095 (0.157) data 0.001 (0.005) loss 1.5498 (1.4013) teacher_loss 0.4205 (0.2767) loss_zs_kd 0.0417 (0.0263) loss_oracle 0.5606 (0.5574) kd_loss 0.8281 (0.8327) acc 81.2500 (90.3125) gate/entropy 0.9879 (0.9875) gate/usage_max 0.5632 (0.5636) gate/usage_min 0.2180 (0.2177) gate/usage_std 0.1625 (0.1628) teacher/entropy 0.0200 (0.0279) teacher/usage_max 0.7094 (0.6969) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2912 (0.2882) nleep/row_max_mean 1529.7620 (1546.6445) nleep/row_max_std 52.6622 (59.1512) nleep/row_min_mean 1486.0659 (1501.0003) lr 5.7422e-04 eta 0:07:52
epoch [34/50] batch [80/181] time 0.159 (0.145) data 0.000 (0.004) loss 1.2396 (1.3957) teacher_loss 0.2395 (0.2765) loss_zs_kd 0.0179 (0.0262) loss_oracle 0.5808 (0.5557) kd_loss 0.7008 (0.8283) acc 90.6250 (90.3516) gate/entropy 0.9872 (0.9875) gate/usage_max 0.5639 (0.5636) gate/usage_min 0.2177 (0.2177) gate/usage_std 0.1631 (0.1628) teacher/entropy 0.0383 (0.0266) teacher/usage_max 0.8243 (0.7029) teacher/usage_min 0.0011 (0.0050) teacher/usage_std 0.3543 (0.2913) nleep/row_max_mean 1553.7505 (1547.1658) nleep/row_max_std 67.9565 (59.4144) nleep/row_min_mean 1511.9597 (1501.4595) lr 5.7422e-04 eta 0:07:14
epoch [34/50] batch [100/181] time 0.179 (0.141) data 0.000 (0.003) loss 1.3453 (1.3882) teacher_loss 0.2044 (0.2666) loss_zs_kd 0.0322 (0.0261) loss_oracle 0.5191 (0.5549) kd_loss 0.8653 (0.8311) acc 93.7500 (90.6562) gate/entropy 0.9874 (0.9874) gate/usage_max 0.5638 (0.5637) gate/usage_min 0.2178 (0.2177) gate/usage_std 0.1629 (0.1629) teacher/entropy 0.0037 (0.0258) teacher/usage_max 0.6883 (0.7007) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2814 (0.2900) nleep/row_max_mean 1538.3796 (1547.5198) nleep/row_max_std 57.7904 (59.1483) nleep/row_min_mean 1495.0448 (1501.8913) lr 5.7422e-04 eta 0:07:00
epoch [34/50] batch [120/181] time 0.237 (0.140) data 0.000 (0.003) loss 1.3608 (1.3887) teacher_loss 0.2726 (0.2688) loss_zs_kd 0.0335 (0.0263) loss_oracle 0.4959 (0.5540) kd_loss 0.8235 (0.8297) acc 93.7500 (90.4167) gate/entropy 0.9877 (0.9874) gate/usage_max 0.5634 (0.5637) gate/usage_min 0.2180 (0.2177) gate/usage_std 0.1627 (0.1629) teacher/entropy 0.0144 (0.0255) teacher/usage_max 0.7206 (0.7025) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2966 (0.2907) nleep/row_max_mean 1529.6283 (1547.9096) nleep/row_max_std 59.9278 (58.6343) nleep/row_min_mean 1485.9139 (1502.4119) lr 5.7422e-04 eta 0:06:54
epoch [34/50] batch [140/181] time 0.092 (0.135) data 0.000 (0.002) loss 1.4754 (1.3915) teacher_loss 0.4313 (0.2725) loss_zs_kd 0.0489 (0.0258) loss_oracle 0.6430 (0.5538) kd_loss 0.6982 (0.8291) acc 84.3750 (90.0893) gate/entropy 0.9869 (0.9874) gate/usage_max 0.5642 (0.5637) gate/usage_min 0.2176 (0.2177) gate/usage_std 0.1633 (0.1629) teacher/entropy 0.0311 (0.0267) teacher/usage_max 0.8335 (0.7018) teacher/usage_min 0.0032 (0.0064) teacher/usage_std 0.3596 (0.2900) nleep/row_max_mean 1566.5715 (1548.4344) nleep/row_max_std 52.9790 (58.7759) nleep/row_min_mean 1520.5571 (1502.9758) lr 5.7422e-04 eta 0:06:37
epoch [34/50] batch [160/181] time 0.076 (0.134) data 0.000 (0.002) loss 1.4807 (1.3906) teacher_loss 0.2691 (0.2760) loss_zs_kd 0.0428 (0.0257) loss_oracle 0.5361 (0.5518) kd_loss 0.9221 (0.8259) acc 90.6250 (89.8047) gate/entropy 0.9876 (0.9874) gate/usage_max 0.5635 (0.5638) gate/usage_min 0.2180 (0.2177) gate/usage_std 0.1627 (0.1629) teacher/entropy 0.0587 (0.0268) teacher/usage_max 0.5699 (0.7050) teacher/usage_min 0.0297 (0.0071) teacher/usage_std 0.2256 (0.2912) nleep/row_max_mean 1520.5425 (1548.2151) nleep/row_max_std 55.3350 (58.8620) nleep/row_min_mean 1489.3296 (1503.0090) lr 5.7422e-04 eta 0:06:29
epoch [34/50] batch [180/181] time 0.077 (0.131) data 0.000 (0.002) loss 1.3207 (1.3840) teacher_loss 0.2585 (0.2711) loss_zs_kd 0.0188 (0.0255) loss_oracle 0.4709 (0.5510) kd_loss 0.8173 (0.8247) acc 87.5000 (89.8438) gate/entropy 0.9878 (0.9873) gate/usage_max 0.5633 (0.5638) gate/usage_min 0.2181 (0.2177) gate/usage_std 0.1626 (0.1630) teacher/entropy 0.0417 (0.0274) teacher/usage_max 0.6992 (0.7057) teacher/usage_min 0.0044 (0.0075) teacher/usage_std 0.2849 (0.2915) nleep/row_max_mean 1524.6741 (1547.8448) nleep/row_max_std 69.2495 (58.3940) nleep/row_min_mean 1480.9122 (1502.8307) lr 5.7422e-04 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,381
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [35/50] batch [20/181] time 0.134 (0.158) data 0.000 (0.015) loss 1.5143 (1.3417) teacher_loss 0.3522 (0.2427) loss_zs_kd 0.0139 (0.0197) loss_oracle 0.5903 (0.5366) kd_loss 0.8600 (0.8208) acc 84.3750 (91.7188) gate/entropy 0.9869 (0.9871) gate/usage_max 0.5643 (0.5640) gate/usage_min 0.2177 (0.2178) gate/usage_std 0.1633 (0.1631) teacher/entropy 0.0261 (0.0270) teacher/usage_max 0.6690 (0.7099) teacher/usage_min 0.0311 (0.0060) teacher/usage_std 0.2615 (0.2939) nleep/row_max_mean 1555.3030 (1539.4203) nleep/row_max_std 54.7654 (61.4328) nleep/row_min_mean 1509.6362 (1497.7028) lr 5.1825e-04 eta 0:07:33
epoch [35/50] batch [40/181] time 0.136 (0.154) data 0.000 (0.007) loss 1.4698 (1.3743) teacher_loss 0.3747 (0.2555) loss_zs_kd 0.0085 (0.0199) loss_oracle 0.4911 (0.5514) kd_loss 0.8453 (0.8331) acc 84.3750 (90.4688) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5640 (0.5640) gate/usage_min 0.2178 (0.2178) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0331 (0.0281) teacher/usage_max 0.6777 (0.6957) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.2768 (0.2878) nleep/row_max_mean 1531.5449 (1538.7809) nleep/row_max_std 73.1016 (62.3987) nleep/row_min_mean 1492.2351 (1497.1227) lr 5.1825e-04 eta 0:07:18
epoch [35/50] batch [60/181] time 0.147 (0.153) data 0.000 (0.005) loss 1.4774 (1.3779) teacher_loss 0.2991 (0.2587) loss_zs_kd 0.0246 (0.0205) loss_oracle 0.6449 (0.5485) kd_loss 0.8436 (0.8346) acc 87.5000 (89.8438) gate/entropy 0.9871 (0.9871) gate/usage_max 0.5641 (0.5640) gate/usage_min 0.2178 (0.2178) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0381 (0.0286) teacher/usage_max 0.6747 (0.6937) teacher/usage_min 0.0313 (0.0076) teacher/usage_std 0.2642 (0.2873) nleep/row_max_mean 1544.0250 (1540.0694) nleep/row_max_std 54.0178 (62.5540) nleep/row_min_mean 1499.7683 (1497.9131) lr 5.1825e-04 eta 0:07:12
epoch [35/50] batch [80/181] time 0.147 (0.152) data 0.000 (0.004) loss 1.4831 (1.3903) teacher_loss 0.2098 (0.2651) loss_zs_kd 0.0389 (0.0214) loss_oracle 0.5568 (0.5528) kd_loss 0.9755 (0.8382) acc 90.6250 (89.5312) gate/entropy 0.9869 (0.9871) gate/usage_max 0.5642 (0.5641) gate/usage_min 0.2178 (0.2178) gate/usage_std 0.1633 (0.1631) teacher/entropy 0.0490 (0.0278) teacher/usage_max 0.5232 (0.6907) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2364 (0.2861) nleep/row_max_mean 1539.7542 (1541.0433) nleep/row_max_std 53.3964 (61.2938) nleep/row_min_mean 1497.2102 (1498.7258) lr 5.1825e-04 eta 0:07:06
epoch [35/50] batch [100/181] time 0.140 (0.151) data 0.000 (0.003) loss 1.2693 (1.3858) teacher_loss 0.1854 (0.2561) loss_zs_kd 0.0268 (0.0221) loss_oracle 0.5429 (0.5521) kd_loss 0.7990 (0.8425) acc 96.8750 (90.0625) gate/entropy 0.9868 (0.9871) gate/usage_max 0.5643 (0.5641) gate/usage_min 0.2178 (0.2178) gate/usage_std 0.1633 (0.1632) teacher/entropy 0.0241 (0.0289) teacher/usage_max 0.7354 (0.6850) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.3041 (0.2827) nleep/row_max_mean 1548.8037 (1541.1391) nleep/row_max_std 52.0621 (60.6421) nleep/row_min_mean 1506.8802 (1498.6189) lr 5.1825e-04 eta 0:07:02
epoch [35/50] batch [120/181] time 0.163 (0.152) data 0.000 (0.003) loss 1.4325 (1.3904) teacher_loss 0.1870 (0.2566) loss_zs_kd 0.0180 (0.0232) loss_oracle 0.5659 (0.5515) kd_loss 0.9535 (0.8465) acc 96.8750 (90.0260) gate/entropy 0.9874 (0.9870) gate/usage_max 0.5637 (0.5641) gate/usage_min 0.2181 (0.2178) gate/usage_std 0.1629 (0.1632) teacher/entropy 0.0043 (0.0281) teacher/usage_max 0.5938 (0.6823) teacher/usage_min 0.0000 (0.0077) teacher/usage_std 0.2478 (0.2816) nleep/row_max_mean 1538.8657 (1541.9207) nleep/row_max_std 60.7854 (60.1978) nleep/row_min_mean 1493.9114 (1499.0777) lr 5.1825e-04 eta 0:07:00
epoch [35/50] batch [140/181] time 0.056 (0.153) data 0.000 (0.002) loss 1.3554 (1.3860) teacher_loss 0.1779 (0.2575) loss_zs_kd 0.0102 (0.0232) loss_oracle 0.5133 (0.5484) kd_loss 0.9157 (0.8427) acc 93.7500 (89.9107) gate/entropy 0.9871 (0.9870) gate/usage_max 0.5640 (0.5641) gate/usage_min 0.2180 (0.2178) gate/usage_std 0.1631 (0.1632) teacher/entropy 0.0105 (0.0277) teacher/usage_max 0.6270 (0.6865) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.2575 (0.2836) nleep/row_max_mean 1547.9928 (1542.3862) nleep/row_max_std 61.6629 (59.9312) nleep/row_min_mean 1503.0774 (1499.4470) lr 5.1825e-04 eta 0:07:00
epoch [35/50] batch [160/181] time 0.064 (0.142) data 0.000 (0.002) loss 1.2433 (1.3949) teacher_loss 0.1592 (0.2629) loss_zs_kd 0.0380 (0.0230) loss_oracle 0.5465 (0.5488) kd_loss 0.7919 (0.8461) acc 96.8750 (89.7266) gate/entropy 0.9870 (0.9870) gate/usage_max 0.5642 (0.5641) gate/usage_min 0.2179 (0.2178) gate/usage_std 0.1632 (0.1632) teacher/entropy 0.0230 (0.0276) teacher/usage_max 0.7444 (0.6833) teacher/usage_min 0.0001 (0.0072) teacher/usage_std 0.3088 (0.2822) nleep/row_max_mean 1540.2140 (1542.0731) nleep/row_max_std 53.0537 (59.5870) nleep/row_min_mean 1498.4015 (1499.2458) lr 5.1825e-04 eta 0:06:28
epoch [35/50] batch [180/181] time 0.171 (0.136) data 0.000 (0.002) loss 1.6626 (1.3959) teacher_loss 0.4367 (0.2621) loss_zs_kd 0.0497 (0.0231) loss_oracle 0.6372 (0.5505) kd_loss 0.8825 (0.8470) acc 84.3750 (89.8264) gate/entropy 0.9869 (0.9870) gate/usage_max 0.5642 (0.5642) gate/usage_min 0.2179 (0.2178) gate/usage_std 0.1632 (0.1632) teacher/entropy 0.0308 (0.0286) teacher/usage_max 0.6402 (0.6811) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.2620 (0.2811) nleep/row_max_mean 1540.7520 (1542.2525) nleep/row_max_std 50.8094 (59.0772) nleep/row_min_mean 1497.1000 (1499.3722) lr 5.1825e-04 eta 0:06:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,394
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [36/50] batch [20/181] time 0.080 (0.109) data 0.000 (0.016) loss 1.3442 (1.4193) teacher_loss 0.2628 (0.2609) loss_zs_kd 0.0112 (0.0239) loss_oracle 0.4794 (0.5691) kd_loss 0.8362 (0.8619) acc 87.5000 (90.7812) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2178 (0.2178) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0236 (0.0291) teacher/usage_max 0.6976 (0.6638) teacher/usage_min 0.0005 (0.0062) teacher/usage_std 0.2854 (0.2708) nleep/row_max_mean 1546.1534 (1539.3396) nleep/row_max_std 48.2276 (57.2832) nleep/row_min_mean 1505.9282 (1496.4820) lr 4.6417e-04 eta 0:04:54
epoch [36/50] batch [40/181] time 0.111 (0.107) data 0.000 (0.008) loss 1.3258 (1.4258) teacher_loss 0.1963 (0.2613) loss_zs_kd 0.0192 (0.0225) loss_oracle 0.6008 (0.5734) kd_loss 0.8195 (0.8666) acc 93.7500 (90.5469) gate/entropy 0.9872 (0.9869) gate/usage_max 0.5640 (0.5643) gate/usage_min 0.2179 (0.2178) gate/usage_std 0.1631 (0.1633) teacher/entropy 0.0329 (0.0258) teacher/usage_max 0.7044 (0.6623) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.2888 (0.2731) nleep/row_max_mean 1532.1958 (1539.6811) nleep/row_max_std 62.7414 (56.9738) nleep/row_min_mean 1487.6917 (1496.6740) lr 4.6417e-04 eta 0:04:45
epoch [36/50] batch [60/181] time 0.142 (0.109) data 0.001 (0.006) loss 1.6394 (1.4212) teacher_loss 0.4983 (0.2709) loss_zs_kd 0.0315 (0.0235) loss_oracle 0.5754 (0.5635) kd_loss 0.8377 (0.8568) acc 81.2500 (89.5312) gate/entropy 0.9871 (0.9868) gate/usage_max 0.5641 (0.5643) gate/usage_min 0.2179 (0.2178) gate/usage_std 0.1631 (0.1633) teacher/entropy 0.0013 (0.0244) teacher/usage_max 0.7187 (0.6740) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2957 (0.2788) nleep/row_max_mean 1525.6418 (1539.6251) nleep/row_max_std 72.1388 (57.6876) nleep/row_min_mean 1477.4448 (1496.9324) lr 4.6417e-04 eta 0:04:49
epoch [36/50] batch [80/181] time 0.084 (0.111) data 0.000 (0.004) loss 1.2687 (1.4188) teacher_loss 0.2453 (0.2603) loss_zs_kd 0.0279 (0.0230) loss_oracle 0.5218 (0.5669) kd_loss 0.7485 (0.8635) acc 87.5000 (90.2734) gate/entropy 0.9869 (0.9869) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2177 (0.2178) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0678 (0.0245) teacher/usage_max 0.7416 (0.6689) teacher/usage_min 0.0026 (0.0042) teacher/usage_std 0.3066 (0.2766) nleep/row_max_mean 1538.9366 (1539.0312) nleep/row_max_std 62.9327 (58.4534) nleep/row_min_mean 1500.7637 (1496.5246) lr 4.6417e-04 eta 0:04:52
epoch [36/50] batch [100/181] time 0.093 (0.112) data 0.000 (0.003) loss 1.5367 (1.4256) teacher_loss 0.5454 (0.2679) loss_zs_kd 0.0332 (0.0230) loss_oracle 0.5102 (0.5682) kd_loss 0.7195 (0.8621) acc 78.1250 (89.8438) gate/entropy 0.9860 (0.9868) gate/usage_max 0.5652 (0.5643) gate/usage_min 0.2172 (0.2177) gate/usage_std 0.1640 (0.1633) teacher/entropy 0.0446 (0.0237) teacher/usage_max 0.7968 (0.6708) teacher/usage_min 0.0020 (0.0037) teacher/usage_std 0.3377 (0.2777) nleep/row_max_mean 1556.7764 (1539.8472) nleep/row_max_std 58.5982 (59.1376) nleep/row_min_mean 1512.1956 (1497.0679) lr 4.6417e-04 eta 0:04:54
epoch [36/50] batch [120/181] time 0.161 (0.115) data 0.000 (0.003) loss 1.6853 (1.4313) teacher_loss 0.5622 (0.2757) loss_zs_kd 0.0269 (0.0231) loss_oracle 0.5119 (0.5700) kd_loss 0.8537 (0.8590) acc 84.3750 (89.4792) gate/entropy 0.9861 (0.9868) gate/usage_max 0.5651 (0.5644) gate/usage_min 0.2172 (0.2177) gate/usage_std 0.1639 (0.1634) teacher/entropy 0.0316 (0.0255) teacher/usage_max 0.6697 (0.6718) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2734 (0.2770) nleep/row_max_mean 1554.9015 (1540.9781) nleep/row_max_std 50.6735 (58.9754) nleep/row_min_mean 1514.0344 (1498.0263) lr 4.6417e-04 eta 0:04:57
epoch [36/50] batch [140/181] time 0.158 (0.120) data 0.000 (0.002) loss 1.3828 (1.4338) teacher_loss 0.2921 (0.2768) loss_zs_kd 0.0284 (0.0232) loss_oracle 0.5752 (0.5689) kd_loss 0.7890 (0.8609) acc 87.5000 (89.4420) gate/entropy 0.9866 (0.9868) gate/usage_max 0.5645 (0.5644) gate/usage_min 0.2175 (0.2177) gate/usage_std 0.1635 (0.1634) teacher/entropy 0.0334 (0.0266) teacher/usage_max 0.7353 (0.6685) teacher/usage_min 0.0116 (0.0062) teacher/usage_std 0.3008 (0.2755) nleep/row_max_mean 1545.1921 (1541.0727) nleep/row_max_std 63.5197 (59.1125) nleep/row_min_mean 1501.7937 (1498.0876) lr 4.6417e-04 eta 0:05:09
epoch [36/50] batch [160/181] time 0.162 (0.126) data 0.000 (0.002) loss 1.2107 (1.4315) teacher_loss 0.1378 (0.2719) loss_zs_kd 0.0267 (0.0239) loss_oracle 0.4591 (0.5694) kd_loss 0.8300 (0.8630) acc 90.6250 (89.5703) gate/entropy 0.9871 (0.9868) gate/usage_max 0.5641 (0.5644) gate/usage_min 0.2177 (0.2177) gate/usage_std 0.1632 (0.1634) teacher/entropy 0.0111 (0.0263) teacher/usage_max 0.7169 (0.6665) teacher/usage_min 0.0308 (0.0070) teacher/usage_std 0.2859 (0.2740) nleep/row_max_mean 1526.8542 (1541.3392) nleep/row_max_std 74.0952 (59.4273) nleep/row_min_mean 1486.0303 (1498.3312) lr 4.6417e-04 eta 0:05:20
epoch [36/50] batch [180/181] time 0.162 (0.127) data 0.000 (0.002) loss 1.2418 (1.4244) teacher_loss 0.0799 (0.2669) loss_zs_kd 0.0142 (0.0237) loss_oracle 0.5267 (0.5681) kd_loss 0.8914 (0.8616) acc 96.8750 (89.7917) gate/entropy 0.9869 (0.9868) gate/usage_max 0.5642 (0.5644) gate/usage_min 0.2176 (0.2176) gate/usage_std 0.1633 (0.1634) teacher/entropy 0.0061 (0.0263) teacher/usage_max 0.6569 (0.6678) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.2683 (0.2745) nleep/row_max_mean 1547.3590 (1542.0862) nleep/row_max_std 64.7526 (59.4601) nleep/row_min_mean 1500.1165 (1498.8417) lr 4.6417e-04 eta 0:05:21
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,398
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [37/50] batch [20/181] time 0.169 (0.175) data 0.000 (0.014) loss 1.4647 (1.4181) teacher_loss 0.3103 (0.2568) loss_zs_kd 0.0196 (0.0256) loss_oracle 0.5740 (0.5510) kd_loss 0.8576 (0.8729) acc 84.3750 (90.6250) gate/entropy 0.9865 (0.9867) gate/usage_max 0.5646 (0.5645) gate/usage_min 0.2174 (0.2175) gate/usage_std 0.1636 (0.1634) teacher/entropy 0.0379 (0.0264) teacher/usage_max 0.6585 (0.6546) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2689 (0.2722) nleep/row_max_mean 1551.2644 (1544.9563) nleep/row_max_std 51.6101 (59.5101) nleep/row_min_mean 1507.8932 (1501.0368) lr 4.1221e-04 eta 0:07:20
epoch [37/50] batch [40/181] time 0.070 (0.161) data 0.000 (0.007) loss 1.4758 (1.4380) teacher_loss 0.3822 (0.2758) loss_zs_kd 0.0482 (0.0246) loss_oracle 0.4820 (0.5501) kd_loss 0.8284 (0.8749) acc 87.5000 (89.6094) gate/entropy 0.9862 (0.9866) gate/usage_max 0.5650 (0.5646) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1638 (0.1635) teacher/entropy 0.0492 (0.0280) teacher/usage_max 0.6777 (0.6508) teacher/usage_min 0.0001 (0.0054) teacher/usage_std 0.2768 (0.2701) nleep/row_max_mean 1554.0203 (1547.4137) nleep/row_max_std 47.5451 (57.4438) nleep/row_min_mean 1508.4072 (1502.7770) lr 4.1221e-04 eta 0:06:42
epoch [37/50] batch [60/181] time 0.081 (0.133) data 0.001 (0.005) loss 1.2927 (1.4292) teacher_loss 0.1276 (0.2591) loss_zs_kd 0.0244 (0.0235) loss_oracle 0.5727 (0.5587) kd_loss 0.8665 (0.8790) acc 96.8750 (90.1562) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5647 (0.5646) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0227 (0.0286) teacher/usage_max 0.6650 (0.6476) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.2715 (0.2685) nleep/row_max_mean 1563.0798 (1547.6851) nleep/row_max_std 53.3735 (55.7508) nleep/row_min_mean 1513.9343 (1503.3982) lr 4.1221e-04 eta 0:05:29
epoch [37/50] batch [80/181] time 0.173 (0.127) data 0.000 (0.004) loss 1.5312 (1.4510) teacher_loss 0.3718 (0.2663) loss_zs_kd 0.0164 (0.0231) loss_oracle 0.5538 (0.5606) kd_loss 0.8743 (0.8928) acc 84.3750 (89.7656) gate/entropy 0.9867 (0.9866) gate/usage_max 0.5644 (0.5645) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0612 (0.0330) teacher/usage_max 0.6159 (0.6309) teacher/usage_min 0.0001 (0.0061) teacher/usage_std 0.2539 (0.2633) nleep/row_max_mean 1558.8269 (1547.4563) nleep/row_max_std 54.0624 (54.8292) nleep/row_min_mean 1511.4198 (1503.5384) lr 4.1221e-04 eta 0:05:11
epoch [37/50] batch [100/181] time 0.169 (0.123) data 0.000 (0.003) loss 1.4127 (1.4526) teacher_loss 0.3296 (0.2606) loss_zs_kd 0.0269 (0.0233) loss_oracle 0.5174 (0.5640) kd_loss 0.8111 (0.8984) acc 84.3750 (90.0625) gate/entropy 0.9863 (0.9866) gate/usage_max 0.5649 (0.5645) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1637 (0.1635) teacher/entropy 0.0398 (0.0336) teacher/usage_max 0.7051 (0.6242) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2891 (0.2605) nleep/row_max_mean 1551.4102 (1547.1394) nleep/row_max_std 45.5431 (54.3115) nleep/row_min_mean 1509.2249 (1503.3604) lr 4.1221e-04 eta 0:04:58
epoch [37/50] batch [120/181] time 0.173 (0.121) data 0.000 (0.003) loss 1.4640 (1.4580) teacher_loss 0.2372 (0.2608) loss_zs_kd 0.0289 (0.0233) loss_oracle 0.5837 (0.5696) kd_loss 0.9205 (0.9008) acc 90.6250 (90.0260) gate/entropy 0.9871 (0.9866) gate/usage_max 0.5641 (0.5645) gate/usage_min 0.2175 (0.2174) gate/usage_std 0.1631 (0.1635) teacher/entropy 0.0550 (0.0346) teacher/usage_max 0.5745 (0.6231) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.2434 (0.2597) nleep/row_max_mean 1522.8888 (1546.1948) nleep/row_max_std 47.3309 (53.3257) nleep/row_min_mean 1484.0068 (1502.4299) lr 4.1221e-04 eta 0:04:51
epoch [37/50] batch [140/181] time 0.101 (0.119) data 0.000 (0.002) loss 1.1632 (1.4644) teacher_loss 0.0950 (0.2645) loss_zs_kd 0.0096 (0.0238) loss_oracle 0.5469 (0.5730) kd_loss 0.7900 (0.9016) acc 96.8750 (89.8214) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5646 (0.5645) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0396 (0.0355) teacher/usage_max 0.7281 (0.6218) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.3004 (0.2593) nleep/row_max_mean 1554.8788 (1545.1495) nleep/row_max_std 53.1927 (53.0721) nleep/row_min_mean 1510.2228 (1501.3482) lr 4.1221e-04 eta 0:04:43
epoch [37/50] batch [160/181] time 0.097 (0.116) data 0.000 (0.002) loss 1.4620 (1.4708) teacher_loss 0.3480 (0.2674) loss_zs_kd 0.0318 (0.0237) loss_oracle 0.4933 (0.5734) kd_loss 0.8515 (0.9049) acc 84.3750 (89.5312) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5642 (0.5645) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0291 (0.0359) teacher/usage_max 0.6748 (0.6176) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2755 (0.2582) nleep/row_max_mean 1522.3972 (1544.9225) nleep/row_max_std 60.7389 (52.3539) nleep/row_min_mean 1479.7126 (1501.1004) lr 4.1221e-04 eta 0:04:36
epoch [37/50] batch [180/181] time 0.069 (0.116) data 0.000 (0.002) loss 1.5865 (1.4665) teacher_loss 0.3963 (0.2667) loss_zs_kd 0.0188 (0.0236) loss_oracle 0.5915 (0.5720) kd_loss 0.8850 (0.9020) acc 84.3750 (89.6007) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5647 (0.5645) gate/usage_min 0.2171 (0.2173) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0587 (0.0362) teacher/usage_max 0.6071 (0.6196) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.2514 (0.2588) nleep/row_max_mean 1539.0718 (1544.7140) nleep/row_max_std 60.9778 (52.3284) nleep/row_min_mean 1492.3035 (1500.8932) lr 4.1221e-04 eta 0:04:34
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [38/50] batch [20/181] time 0.147 (0.162) data 0.000 (0.015) loss 1.4404 (1.4490) teacher_loss 0.1270 (0.2336) loss_zs_kd 0.0245 (0.0224) loss_oracle 0.6433 (0.5712) kd_loss 0.9795 (0.9186) acc 90.6250 (91.8750) gate/entropy 0.9866 (0.9867) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2172 (0.2172) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0223 (0.0352) teacher/usage_max 0.5465 (0.6000) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2387 (0.2525) nleep/row_max_mean 1537.2098 (1544.7589) nleep/row_max_std 51.5335 (50.7904) nleep/row_min_mean 1492.7942 (1499.0742) lr 3.6258e-04 eta 0:06:18
epoch [38/50] batch [40/181] time 0.159 (0.157) data 0.000 (0.008) loss 1.4166 (1.4589) teacher_loss 0.1089 (0.2382) loss_zs_kd 0.0270 (0.0238) loss_oracle 0.5782 (0.5618) kd_loss 1.0051 (0.9279) acc 96.8750 (91.4844) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5647 (0.5645) gate/usage_min 0.2171 (0.2172) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0334 (0.0381) teacher/usage_max 0.5080 (0.5898) teacher/usage_min 0.0011 (0.0021) teacher/usage_std 0.2350 (0.2499) nleep/row_max_mean 1551.3135 (1545.4882) nleep/row_max_std 57.6423 (50.7371) nleep/row_min_mean 1501.0620 (1499.7792) lr 3.6258e-04 eta 0:06:04
epoch [38/50] batch [60/181] time 0.151 (0.156) data 0.000 (0.005) loss 1.5135 (1.4577) teacher_loss 0.2084 (0.2409) loss_zs_kd 0.0231 (0.0240) loss_oracle 0.6631 (0.5591) kd_loss 0.9619 (0.9252) acc 96.8750 (91.1979) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5642 (0.5645) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0841 (0.0393) teacher/usage_max 0.5006 (0.5908) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2357 (0.2500) nleep/row_max_mean 1531.9689 (1544.7170) nleep/row_max_std 49.8502 (49.9549) nleep/row_min_mean 1490.8713 (1499.6977) lr 3.6258e-04 eta 0:05:58
epoch [38/50] batch [80/181] time 0.153 (0.155) data 0.000 (0.004) loss 1.6672 (1.4515) teacher_loss 0.3011 (0.2466) loss_zs_kd 0.0307 (0.0245) loss_oracle 0.6687 (0.5539) kd_loss 1.0164 (0.9157) acc 87.5000 (91.0156) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5643 (0.5646) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0672 (0.0399) teacher/usage_max 0.5400 (0.6014) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2380 (0.2533) nleep/row_max_mean 1540.3416 (1546.0358) nleep/row_max_std 53.4940 (49.9503) nleep/row_min_mean 1497.0363 (1500.8536) lr 3.6258e-04 eta 0:05:51
epoch [38/50] batch [100/181] time 0.153 (0.154) data 0.000 (0.003) loss 1.1366 (1.4631) teacher_loss 0.1629 (0.2459) loss_zs_kd 0.0262 (0.0251) loss_oracle 0.5280 (0.5617) kd_loss 0.6966 (0.9238) acc 96.8750 (90.9688) gate/entropy 0.9860 (0.9866) gate/usage_max 0.5652 (0.5645) gate/usage_min 0.2168 (0.2171) gate/usage_std 0.1640 (0.1635) teacher/entropy 0.0559 (0.0400) teacher/usage_max 0.8081 (0.6002) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.3448 (0.2532) nleep/row_max_mean 1558.7769 (1545.5321) nleep/row_max_std 56.6265 (49.4068) nleep/row_min_mean 1511.5668 (1500.6283) lr 3.6258e-04 eta 0:05:46
epoch [38/50] batch [120/181] time 0.164 (0.155) data 0.000 (0.003) loss 1.3082 (1.4659) teacher_loss 0.1762 (0.2477) loss_zs_kd 0.0166 (0.0253) loss_oracle 0.5379 (0.5615) kd_loss 0.8548 (0.9248) acc 90.6250 (90.6250) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5646 (0.5646) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0461 (0.0404) teacher/usage_max 0.6524 (0.6005) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.2665 (0.2527) nleep/row_max_mean 1552.7682 (1545.6562) nleep/row_max_std 48.5745 (49.8995) nleep/row_min_mean 1506.6243 (1500.8718) lr 3.6258e-04 eta 0:05:45
epoch [38/50] batch [140/181] time 0.167 (0.156) data 0.000 (0.002) loss 1.7235 (1.4623) teacher_loss 0.5092 (0.2464) loss_zs_kd 0.0345 (0.0249) loss_oracle 0.6184 (0.5621) kd_loss 0.8880 (0.9224) acc 81.2500 (90.7366) gate/entropy 0.9868 (0.9866) gate/usage_max 0.5643 (0.5646) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0083 (0.0403) teacher/usage_max 0.6560 (0.6030) teacher/usage_min 0.0302 (0.0041) teacher/usage_std 0.2559 (0.2535) nleep/row_max_mean 1541.5970 (1545.3197) nleep/row_max_std 53.8345 (50.5663) nleep/row_min_mean 1496.9475 (1500.6451) lr 3.6258e-04 eta 0:05:45
epoch [38/50] batch [160/181] time 0.098 (0.149) data 0.000 (0.002) loss 1.5382 (1.4632) teacher_loss 0.3769 (0.2465) loss_zs_kd 0.0220 (0.0248) loss_oracle 0.5727 (0.5658) kd_loss 0.8639 (0.9214) acc 90.6250 (90.7422) gate/entropy 0.9859 (0.9866) gate/usage_max 0.5653 (0.5646) gate/usage_min 0.2167 (0.2171) gate/usage_std 0.1640 (0.1635) teacher/entropy 0.0233 (0.0399) teacher/usage_max 0.6663 (0.6027) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2720 (0.2532) nleep/row_max_mean 1549.6282 (1545.1235) nleep/row_max_std 50.8759 (50.9842) nleep/row_min_mean 1504.3713 (1500.5461) lr 3.6258e-04 eta 0:05:27
epoch [38/50] batch [180/181] time 0.070 (0.142) data 0.000 (0.002) loss 1.6150 (1.4646) teacher_loss 0.2692 (0.2465) loss_zs_kd 0.0218 (0.0249) loss_oracle 0.5919 (0.5664) kd_loss 1.0390 (0.9225) acc 90.6250 (90.7292) gate/entropy 0.9864 (0.9866) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2169 (0.2171) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0485 (0.0390) teacher/usage_max 0.5440 (0.6020) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.2384 (0.2531) nleep/row_max_mean 1543.3759 (1545.0107) nleep/row_max_std 46.8225 (51.3703) nleep/row_min_mean 1501.6545 (1500.4639) lr 3.6258e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [39/50] batch [20/181] time 0.078 (0.149) data 0.000 (0.016) loss 1.5664 (1.5331) teacher_loss 0.2719 (0.2452) loss_zs_kd 0.0377 (0.0263) loss_oracle 0.6023 (0.6117) kd_loss 0.9745 (0.9690) acc 87.5000 (91.0938) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5642 (0.5646) gate/usage_min 0.2171 (0.2170) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0268 (0.0392) teacher/usage_max 0.5459 (0.5736) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.2387 (0.2448) nleep/row_max_mean 1529.0271 (1535.7005) nleep/row_max_std 57.1249 (52.1603) nleep/row_min_mean 1481.9454 (1493.4387) lr 3.1545e-04 eta 0:05:20
epoch [39/50] batch [40/181] time 0.176 (0.138) data 0.000 (0.008) loss 1.5278 (1.4993) teacher_loss 0.4053 (0.2441) loss_zs_kd 0.0357 (0.0247) loss_oracle 0.5526 (0.5915) kd_loss 0.8284 (0.9471) acc 81.2500 (91.0156) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5646 (0.5645) gate/usage_min 0.2169 (0.2170) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0294 (0.0406) teacher/usage_max 0.6979 (0.5846) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2857 (0.2485) nleep/row_max_mean 1531.4512 (1534.0353) nleep/row_max_std 61.8953 (53.8518) nleep/row_min_mean 1484.6809 (1491.6669) lr 3.1545e-04 eta 0:04:53
epoch [39/50] batch [60/181] time 0.179 (0.136) data 0.000 (0.006) loss 1.5091 (1.4944) teacher_loss 0.3168 (0.2461) loss_zs_kd 0.0216 (0.0242) loss_oracle 0.6022 (0.5817) kd_loss 0.8803 (0.9454) acc 84.3750 (90.6771) gate/entropy 0.9864 (0.9866) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1637 (0.1635) teacher/entropy 0.0860 (0.0382) teacher/usage_max 0.5833 (0.5862) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2453 (0.2495) nleep/row_max_mean 1547.5294 (1535.8413) nleep/row_max_std 52.8147 (54.3496) nleep/row_min_mean 1504.9941 (1493.0200) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [80/181] time 0.092 (0.129) data 0.000 (0.004) loss 1.3271 (1.4927) teacher_loss 0.1958 (0.2476) loss_zs_kd 0.0215 (0.0238) loss_oracle 0.4780 (0.5777) kd_loss 0.8815 (0.9442) acc 93.7500 (90.7031) gate/entropy 0.9864 (0.9866) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1637 (0.1635) teacher/entropy 0.0145 (0.0369) teacher/usage_max 0.6579 (0.5845) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2687 (0.2492) nleep/row_max_mean 1542.7891 (1537.5365) nleep/row_max_std 50.9174 (54.4239) nleep/row_min_mean 1502.0315 (1494.6506) lr 3.1545e-04 eta 0:04:29
epoch [39/50] batch [100/181] time 0.141 (0.133) data 0.000 (0.003) loss 1.5277 (1.4954) teacher_loss 0.1612 (0.2451) loss_zs_kd 0.0282 (0.0245) loss_oracle 0.5237 (0.5747) kd_loss 1.0906 (0.9507) acc 93.7500 (90.9062) gate/entropy 0.9864 (0.9866) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1637 (0.1635) teacher/entropy 0.0231 (0.0362) teacher/usage_max 0.5709 (0.5818) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2427 (0.2484) nleep/row_max_mean 1543.8330 (1537.6559) nleep/row_max_std 43.0822 (54.8861) nleep/row_min_mean 1504.3562 (1494.7840) lr 3.1545e-04 eta 0:04:34
epoch [39/50] batch [120/181] time 0.147 (0.138) data 0.000 (0.003) loss 1.5146 (1.5020) teacher_loss 0.2046 (0.2423) loss_zs_kd 0.0387 (0.0253) loss_oracle 0.5709 (0.5751) kd_loss 1.0053 (0.9595) acc 90.6250 (91.1719) gate/entropy 0.9866 (0.9866) gate/usage_max 0.5646 (0.5646) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1635 (0.1635) teacher/entropy 0.0237 (0.0349) teacher/usage_max 0.5167 (0.5785) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2361 (0.2475) nleep/row_max_mean 1554.0992 (1538.7864) nleep/row_max_std 60.3307 (54.7912) nleep/row_min_mean 1504.0870 (1495.6299) lr 3.1545e-04 eta 0:04:43
epoch [39/50] batch [140/181] time 0.156 (0.140) data 0.000 (0.002) loss 1.4333 (1.5012) teacher_loss 0.1941 (0.2400) loss_zs_kd 0.0149 (0.0249) loss_oracle 0.5509 (0.5773) kd_loss 0.9564 (0.9601) acc 90.6250 (91.1830) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5647 (0.5646) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0004 (0.0335) teacher/usage_max 0.5937 (0.5773) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2478 (0.2467) nleep/row_max_mean 1542.8168 (1539.5679) nleep/row_max_std 52.5525 (55.3858) nleep/row_min_mean 1502.5500 (1496.1432) lr 3.1545e-04 eta 0:04:44
epoch [39/50] batch [160/181] time 0.155 (0.142) data 0.000 (0.002) loss 1.2575 (1.5005) teacher_loss 0.1812 (0.2413) loss_zs_kd 0.0248 (0.0250) loss_oracle 0.4710 (0.5730) kd_loss 0.8284 (0.9601) acc 90.6250 (91.0938) gate/entropy 0.9863 (0.9866) gate/usage_max 0.5648 (0.5646) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1637 (0.1635) teacher/entropy 0.0091 (0.0330) teacher/usage_max 0.7197 (0.5790) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2962 (0.2473) nleep/row_max_mean 1555.1483 (1539.9315) nleep/row_max_std 58.6235 (55.2019) nleep/row_min_mean 1510.2369 (1496.4930) lr 3.1545e-04 eta 0:04:45
epoch [39/50] batch [180/181] time 0.133 (0.141) data 0.000 (0.002) loss 1.4113 (1.4987) teacher_loss 0.0573 (0.2341) loss_zs_kd 0.0137 (0.0256) loss_oracle 0.5600 (0.5769) kd_loss 1.0672 (0.9633) acc 100.0000 (91.5278) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5642 (0.5646) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0110 (0.0327) teacher/usage_max 0.5340 (0.5761) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2373 (0.2464) nleep/row_max_mean 1534.5813 (1540.5502) nleep/row_max_std 56.2871 (55.1736) nleep/row_min_mean 1495.1211 (1496.8512) lr 3.1545e-04 eta 0:04:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,406
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.6%, epoch: 28 *******
******* Domain p best val test acc: 99.8%, epoch: 28 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [40/50] batch [20/181] time 0.083 (0.156) data 0.000 (0.017) loss 1.8950 (1.5280) teacher_loss 0.4018 (0.1836) loss_zs_kd 0.0253 (0.0229) loss_oracle 0.6163 (0.5983) kd_loss 1.1723 (1.0338) acc 81.2500 (93.7500) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5642 (0.5645) gate/usage_min 0.2169 (0.2168) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0452 (0.0279) teacher/usage_max 0.6828 (0.5813) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2790 (0.2461) nleep/row_max_mean 1523.9583 (1545.6193) nleep/row_max_std 52.3846 (56.4280) nleep/row_min_mean 1481.9902 (1498.9245) lr 2.7103e-04 eta 0:05:08
epoch [40/50] batch [40/181] time 0.084 (0.134) data 0.000 (0.009) loss 1.3961 (1.5457) teacher_loss 0.2602 (0.2178) loss_zs_kd 0.0476 (0.0277) loss_oracle 0.5293 (0.5972) kd_loss 0.8475 (1.0154) acc 87.5000 (92.3438) gate/entropy 0.9868 (0.9866) gate/usage_max 0.5643 (0.5646) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1634 (0.1635) teacher/entropy 0.0285 (0.0304) teacher/usage_max 0.6788 (0.5786) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2772 (0.2468) nleep/row_max_mean 1534.7405 (1544.3270) nleep/row_max_std 67.1171 (58.8713) nleep/row_min_mean 1488.8262 (1498.0312) lr 2.7103e-04 eta 0:04:21
epoch [40/50] batch [60/181] time 0.096 (0.131) data 0.001 (0.006) loss 1.6084 (1.5308) teacher_loss 0.2822 (0.2059) loss_zs_kd 0.0227 (0.0276) loss_oracle 0.5714 (0.5983) kd_loss 1.0292 (1.0120) acc 87.5000 (92.8125) gate/entropy 0.9869 (0.9866) gate/usage_max 0.5643 (0.5645) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1633 (0.1635) teacher/entropy 0.0150 (0.0319) teacher/usage_max 0.5011 (0.5718) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2357 (0.2453) nleep/row_max_mean 1535.9098 (1544.0987) nleep/row_max_std 66.3682 (59.6822) nleep/row_min_mean 1490.0720 (1498.0692) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [80/181] time 0.134 (0.128) data 0.000 (0.004) loss 1.6402 (1.5524) teacher_loss 0.2927 (0.2075) loss_zs_kd 0.0226 (0.0284) loss_oracle 0.5907 (0.6062) kd_loss 1.0409 (1.0276) acc 96.8750 (92.7734) gate/entropy 0.9865 (0.9866) gate/usage_max 0.5647 (0.5645) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0425 (0.0335) teacher/usage_max 0.5405 (0.5736) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2380 (0.2461) nleep/row_max_mean 1558.9316 (1543.8327) nleep/row_max_std 60.6128 (59.3124) nleep/row_min_mean 1510.8969 (1497.8289) lr 2.7103e-04 eta 0:04:05
epoch [40/50] batch [100/181] time 0.101 (0.125) data 0.000 (0.004) loss 1.6628 (1.5534) teacher_loss 0.1269 (0.2065) loss_zs_kd 0.0290 (0.0288) loss_oracle 0.8066 (0.6107) kd_loss 1.1181 (1.0271) acc 93.7500 (92.6875) gate/entropy 0.9870 (0.9866) gate/usage_max 0.5642 (0.5645) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1632 (0.1635) teacher/entropy 0.0427 (0.0356) teacher/usage_max 0.6212 (0.5686) teacher/usage_min 0.0013 (0.0022) teacher/usage_std 0.2550 (0.2445) nleep/row_max_mean 1537.5791 (1543.1793) nleep/row_max_std 54.9921 (59.1658) nleep/row_min_mean 1494.7725 (1497.3639) lr 2.7103e-04 eta 0:03:56
epoch [40/50] batch [120/181] time 0.092 (0.123) data 0.000 (0.003) loss 1.8792 (1.5617) teacher_loss 0.4562 (0.2083) loss_zs_kd 0.0344 (0.0286) loss_oracle 0.6834 (0.6132) kd_loss 1.0640 (1.0326) acc 75.0000 (92.4740) gate/entropy 0.9864 (0.9867) gate/usage_max 0.5648 (0.5645) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0078 (0.0367) teacher/usage_max 0.4980 (0.5700) teacher/usage_min 0.0312 (0.0028) teacher/usage_std 0.2139 (0.2449) nleep/row_max_mean 1556.1638 (1543.4785) nleep/row_max_std 49.9102 (57.9068) nleep/row_min_mean 1501.9264 (1497.7874) lr 2.7103e-04 eta 0:03:49
epoch [40/50] batch [140/181] time 0.083 (0.123) data 0.000 (0.003) loss 1.6962 (1.5656) teacher_loss 0.2904 (0.2111) loss_zs_kd 0.0428 (0.0298) loss_oracle 0.6441 (0.6157) kd_loss 1.0624 (1.0317) acc 93.7500 (92.2545) gate/entropy 0.9870 (0.9867) gate/usage_max 0.5642 (0.5645) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1632 (0.1635) teacher/entropy 0.0465 (0.0372) teacher/usage_max 0.5680 (0.5664) teacher/usage_min 0.0002 (0.0026) teacher/usage_std 0.2421 (0.2440) nleep/row_max_mean 1532.7688 (1543.6208) nleep/row_max_std 62.3000 (57.4881) nleep/row_min_mean 1490.5037 (1497.7831) lr 2.7103e-04 eta 0:03:46
epoch [40/50] batch [160/181] time 0.192 (0.123) data 0.000 (0.002) loss 1.2405 (1.5716) teacher_loss 0.0569 (0.2145) loss_zs_kd 0.0290 (0.0296) loss_oracle 0.5615 (0.6151) kd_loss 0.8883 (1.0348) acc 100.0000 (92.0898) gate/entropy 0.9867 (0.9867) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1634 (0.1634) teacher/entropy 0.0538 (0.0380) teacher/usage_max 0.6086 (0.5685) teacher/usage_min 0.0001 (0.0029) teacher/usage_std 0.2518 (0.2445) nleep/row_max_mean 1541.4656 (1542.9622) nleep/row_max_std 59.3244 (57.3665) nleep/row_min_mean 1496.9568 (1497.2409) lr 2.7103e-04 eta 0:03:44
epoch [40/50] batch [180/181] time 0.072 (0.122) data 0.000 (0.002) loss 1.3131 (1.5723) teacher_loss 0.1058 (0.2157) loss_zs_kd 0.0438 (0.0305) loss_oracle 0.5552 (0.6149) kd_loss 0.9078 (1.0339) acc 100.0000 (91.9965) gate/entropy 0.9867 (0.9867) gate/usage_max 0.5645 (0.5645) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1634 (0.1634) teacher/entropy 0.0685 (0.0378) teacher/usage_max 0.5728 (0.5706) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2431 (0.2452) nleep/row_max_mean 1535.3032 (1542.8432) nleep/row_max_std 55.6596 (57.1552) nleep/row_min_mean 1497.8574 (1497.0482) lr 2.7103e-04 eta 0:03:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.7%, epoch: 40 *******
******* Domain p best val test acc: 99.8%, epoch: 40 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [41/50] batch [20/181] time 0.118 (0.169) data 0.000 (0.014) loss 1.7720 (1.6145) teacher_loss 0.3981 (0.2186) loss_zs_kd 0.0523 (0.0331) loss_oracle 0.6726 (0.6701) kd_loss 1.0115 (1.0443) acc 87.5000 (92.3438) gate/entropy 0.9871 (0.9869) gate/usage_max 0.5640 (0.5643) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1631 (0.1633) teacher/entropy 0.0288 (0.0482) teacher/usage_max 0.5041 (0.5689) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2357 (0.2465) nleep/row_max_mean 1537.2904 (1540.2579) nleep/row_max_std 56.7230 (56.4086) nleep/row_min_mean 1487.7593 (1494.9962) lr 2.2949e-04 eta 0:05:02
epoch [41/50] batch [40/181] time 0.173 (0.156) data 0.000 (0.007) loss 1.7032 (1.5908) teacher_loss 0.2580 (0.1961) loss_zs_kd 0.0445 (0.0308) loss_oracle 0.5631 (0.6643) kd_loss 1.1414 (1.0471) acc 87.5000 (92.7344) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1634 (0.1633) teacher/entropy 0.0160 (0.0443) teacher/usage_max 0.6195 (0.5771) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2551 (0.2474) nleep/row_max_mean 1527.0585 (1538.3232) nleep/row_max_std 53.7774 (57.8426) nleep/row_min_mean 1483.7760 (1492.6064) lr 2.2949e-04 eta 0:04:36
epoch [41/50] batch [60/181] time 0.122 (0.154) data 0.001 (0.005) loss 1.5768 (1.5865) teacher_loss 0.1490 (0.2007) loss_zs_kd 0.0299 (0.0319) loss_oracle 0.6623 (0.6570) kd_loss 1.0818 (1.0414) acc 93.7500 (92.6562) gate/entropy 0.9869 (0.9869) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0462 (0.0475) teacher/usage_max 0.5886 (0.5800) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2466 (0.2479) nleep/row_max_mean 1537.7056 (1537.8804) nleep/row_max_std 62.6285 (57.7296) nleep/row_min_mean 1493.7552 (1492.5314) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [80/181] time 0.160 (0.153) data 0.000 (0.004) loss 1.5856 (1.5932) teacher_loss 0.2277 (0.2022) loss_zs_kd 0.0247 (0.0321) loss_oracle 0.7200 (0.6576) kd_loss 0.9855 (1.0462) acc 84.3750 (92.8125) gate/entropy 0.9860 (0.9868) gate/usage_max 0.5652 (0.5643) gate/usage_min 0.2161 (0.2166) gate/usage_std 0.1640 (0.1633) teacher/entropy 0.0000 (0.0451) teacher/usage_max 0.5625 (0.5784) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.2412 (0.2471) nleep/row_max_mean 1567.2373 (1537.9928) nleep/row_max_std 49.1915 (57.4453) nleep/row_min_mean 1515.5157 (1492.7514) lr 2.2949e-04 eta 0:04:24
epoch [41/50] batch [100/181] time 0.147 (0.153) data 0.000 (0.003) loss 1.5699 (1.5877) teacher_loss 0.2342 (0.2021) loss_zs_kd 0.0341 (0.0322) loss_oracle 0.6053 (0.6515) kd_loss 1.0160 (1.0437) acc 90.6250 (92.8125) gate/entropy 0.9865 (0.9868) gate/usage_max 0.5646 (0.5643) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0587 (0.0483) teacher/usage_max 0.5320 (0.5795) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2371 (0.2476) nleep/row_max_mean 1541.7413 (1538.1318) nleep/row_max_std 65.0802 (57.2408) nleep/row_min_mean 1494.9841 (1492.9823) lr 2.2949e-04 eta 0:04:21
epoch [41/50] batch [120/181] time 0.079 (0.152) data 0.000 (0.002) loss 1.5275 (1.5866) teacher_loss 0.0968 (0.2030) loss_zs_kd 0.0223 (0.0324) loss_oracle 0.6461 (0.6450) kd_loss 1.0965 (1.0448) acc 96.8750 (92.7604) gate/entropy 0.9868 (0.9868) gate/usage_max 0.5644 (0.5643) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1634 (0.1633) teacher/entropy 0.0449 (0.0486) teacher/usage_max 0.6024 (0.5783) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2501 (0.2475) nleep/row_max_mean 1545.2799 (1538.9287) nleep/row_max_std 55.0526 (57.5323) nleep/row_min_mean 1499.0876 (1493.5104) lr 2.2949e-04 eta 0:04:17
epoch [41/50] batch [140/181] time 0.106 (0.143) data 0.000 (0.002) loss 1.4550 (1.5884) teacher_loss 0.2280 (0.2075) loss_zs_kd 0.0401 (0.0325) loss_oracle 0.5448 (0.6432) kd_loss 0.9345 (1.0430) acc 90.6250 (92.5000) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5644 (0.5643) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1634 (0.1633) teacher/entropy 0.0795 (0.0492) teacher/usage_max 0.5311 (0.5768) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.2371 (0.2470) nleep/row_max_mean 1547.4373 (1538.8652) nleep/row_max_std 62.0566 (58.0678) nleep/row_min_mean 1500.1740 (1493.3871) lr 2.2949e-04 eta 0:03:58
epoch [41/50] batch [160/181] time 0.073 (0.140) data 0.000 (0.002) loss 1.7440 (1.5838) teacher_loss 0.3596 (0.2080) loss_zs_kd 0.0556 (0.0324) loss_oracle 0.6635 (0.6363) kd_loss 1.0249 (1.0415) acc 87.5000 (92.5000) gate/entropy 0.9868 (0.9869) gate/usage_max 0.5643 (0.5643) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1633 (0.1633) teacher/entropy 0.0316 (0.0489) teacher/usage_max 0.5145 (0.5772) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2360 (0.2471) nleep/row_max_mean 1557.8577 (1539.7321) nleep/row_max_std 58.0354 (58.2677) nleep/row_min_mean 1503.5364 (1494.1512) lr 2.2949e-04 eta 0:03:51
epoch [41/50] batch [180/181] time 0.147 (0.137) data 0.000 (0.002) loss 1.6274 (1.5804) teacher_loss 0.3225 (0.2043) loss_zs_kd 0.0162 (0.0321) loss_oracle 0.5698 (0.6349) kd_loss 1.0119 (1.0426) acc 90.6250 (92.7083) gate/entropy 0.9870 (0.9869) gate/usage_max 0.5641 (0.5643) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1632 (0.1633) teacher/entropy 0.0487 (0.0494) teacher/usage_max 0.5104 (0.5795) teacher/usage_min 0.0069 (0.0019) teacher/usage_std 0.2311 (0.2478) nleep/row_max_mean 1547.5854 (1539.7176) nleep/row_max_std 65.8114 (59.1640) nleep/row_min_mean 1499.2896 (1494.2351) lr 2.2949e-04 eta 0:03:43
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.7%, epoch: 40 *******
******* Domain p best val test acc: 99.8%, epoch: 40 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [42/50] batch [20/181] time 0.160 (0.126) data 0.000 (0.014) loss 1.3889 (1.6375) teacher_loss 0.2175 (0.2159) loss_zs_kd 0.0308 (0.0352) loss_oracle 0.5353 (0.6569) kd_loss 0.8883 (1.0756) acc 90.6250 (92.6562) gate/entropy 0.9863 (0.9869) gate/usage_max 0.5648 (0.5642) gate/usage_min 0.2162 (0.2165) gate/usage_std 0.1637 (0.1633) teacher/entropy 0.0262 (0.0405) teacher/usage_max 0.6364 (0.6116) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2607 (0.2570) nleep/row_max_mean 1566.3767 (1548.1189) nleep/row_max_std 67.3394 (60.6881) nleep/row_min_mean 1512.4502 (1501.0161) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [40/181] time 0.163 (0.122) data 0.000 (0.007) loss 1.8578 (1.6291) teacher_loss 0.4303 (0.2134) loss_zs_kd 0.0489 (0.0358) loss_oracle 0.6355 (0.6519) kd_loss 1.0853 (1.0719) acc 84.3750 (92.8906) gate/entropy 0.9873 (0.9870) gate/usage_max 0.5638 (0.5642) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1630 (0.1632) teacher/entropy 0.1032 (0.0400) teacher/usage_max 0.6532 (0.5943) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2668 (0.2527) nleep/row_max_mean 1523.5560 (1544.2391) nleep/row_max_std 63.9413 (60.2293) nleep/row_min_mean 1479.3975 (1498.3110) lr 1.9098e-04 eta 0:03:13
epoch [42/50] batch [60/181] time 0.126 (0.120) data 0.000 (0.005) loss 1.4417 (1.6232) teacher_loss 0.0452 (0.2128) loss_zs_kd 0.0242 (0.0346) loss_oracle 0.6789 (0.6580) kd_loss 1.0449 (1.0641) acc 100.0000 (92.8125) gate/entropy 0.9869 (0.9869) gate/usage_max 0.5642 (0.5642) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1633 (0.1632) teacher/entropy 0.0208 (0.0419) teacher/usage_max 0.5239 (0.5882) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2365 (0.2508) nleep/row_max_mean 1554.0536 (1546.0189) nleep/row_max_std 52.7270 (59.7311) nleep/row_min_mean 1506.8513 (1499.6946) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [80/181] time 0.189 (0.121) data 0.000 (0.004) loss 1.6879 (1.6168) teacher_loss 0.2579 (0.2114) loss_zs_kd 0.0194 (0.0338) loss_oracle 0.7714 (0.6569) kd_loss 1.0346 (1.0600) acc 87.5000 (92.9297) gate/entropy 0.9875 (0.9870) gate/usage_max 0.5636 (0.5641) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1628 (0.1632) teacher/entropy 0.0884 (0.0460) teacher/usage_max 0.5850 (0.5880) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2457 (0.2503) nleep/row_max_mean 1540.2324 (1546.1532) nleep/row_max_std 62.0633 (59.4641) nleep/row_min_mean 1489.1536 (1499.6723) lr 1.9098e-04 eta 0:03:07
epoch [42/50] batch [100/181] time 0.143 (0.128) data 0.000 (0.003) loss 1.8094 (1.6175) teacher_loss 0.2133 (0.2091) loss_zs_kd 0.0498 (0.0344) loss_oracle 0.7170 (0.6575) kd_loss 1.2127 (1.0625) acc 93.7500 (92.8438) gate/entropy 0.9870 (0.9870) gate/usage_max 0.5642 (0.5641) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1632 (0.1632) teacher/entropy 0.0079 (0.0451) teacher/usage_max 0.6867 (0.5880) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2807 (0.2503) nleep/row_max_mean 1542.2949 (1546.3785) nleep/row_max_std 42.3494 (58.9447) nleep/row_min_mean 1501.5719 (1499.8646) lr 1.9098e-04 eta 0:03:16
epoch [42/50] batch [120/181] time 0.149 (0.134) data 0.000 (0.002) loss 1.7283 (1.6150) teacher_loss 0.2306 (0.2103) loss_zs_kd 0.0293 (0.0343) loss_oracle 0.6792 (0.6569) kd_loss 1.1434 (1.0591) acc 87.5000 (92.7083) gate/entropy 0.9868 (0.9870) gate/usage_max 0.5644 (0.5641) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0436 (0.0468) teacher/usage_max 0.6200 (0.5853) teacher/usage_min 0.0312 (0.0026) teacher/usage_std 0.2406 (0.2491) nleep/row_max_mean 1553.6770 (1546.1235) nleep/row_max_std 66.8838 (59.4320) nleep/row_min_mean 1504.1384 (1499.6282) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [140/181] time 0.160 (0.138) data 0.000 (0.002) loss 1.9621 (1.6198) teacher_loss 0.5276 (0.2133) loss_zs_kd 0.0552 (0.0345) loss_oracle 0.6278 (0.6556) kd_loss 1.0930 (1.0614) acc 81.2500 (92.6116) gate/entropy 0.9867 (0.9870) gate/usage_max 0.5644 (0.5641) gate/usage_min 0.2162 (0.2165) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0080 (0.0465) teacher/usage_max 0.5611 (0.5875) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2409 (0.2496) nleep/row_max_mean 1558.2212 (1545.6403) nleep/row_max_std 57.7186 (59.6597) nleep/row_min_mean 1507.2444 (1499.2548) lr 1.9098e-04 eta 0:03:25
epoch [42/50] batch [160/181] time 0.141 (0.140) data 0.000 (0.002) loss 1.6259 (1.6184) teacher_loss 0.1762 (0.2126) loss_zs_kd 0.0255 (0.0343) loss_oracle 0.6856 (0.6527) kd_loss 1.0942 (1.0623) acc 93.7500 (92.5391) gate/entropy 0.9873 (0.9871) gate/usage_max 0.5638 (0.5641) gate/usage_min 0.2165 (0.2164) gate/usage_std 0.1630 (0.1632) teacher/entropy 0.0386 (0.0473) teacher/usage_max 0.5952 (0.5874) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2482 (0.2495) nleep/row_max_mean 1549.7671 (1545.9688) nleep/row_max_std 54.6809 (59.2773) nleep/row_min_mean 1500.1733 (1499.6047) lr 1.9098e-04 eta 0:03:25
epoch [42/50] batch [180/181] time 0.166 (0.141) data 0.000 (0.002) loss 1.6029 (1.6127) teacher_loss 0.3370 (0.2073) loss_zs_kd 0.0197 (0.0338) loss_oracle 0.6462 (0.6517) kd_loss 0.9330 (1.0626) acc 87.5000 (92.6736) gate/entropy 0.9871 (0.9871) gate/usage_max 0.5640 (0.5641) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1631 (0.1632) teacher/entropy 0.0387 (0.0476) teacher/usage_max 0.5762 (0.5877) teacher/usage_min 0.0001 (0.0026) teacher/usage_std 0.2437 (0.2495) nleep/row_max_mean 1548.2769 (1545.6667) nleep/row_max_std 58.7923 (59.0408) nleep/row_min_mean 1500.7203 (1499.4226) lr 1.9098e-04 eta 0:03:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [43/50] batch [20/181] time 0.088 (0.122) data 0.000 (0.014) loss 1.8000 (1.6390) teacher_loss 0.2308 (0.2087) loss_zs_kd 0.0623 (0.0373) loss_oracle 0.7310 (0.6491) kd_loss 1.1726 (1.0871) acc 90.6250 (92.6562) gate/entropy 0.9872 (0.9871) gate/usage_max 0.5639 (0.5640) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1630 (0.1631) teacher/entropy 0.0414 (0.0382) teacher/usage_max 0.6349 (0.5934) teacher/usage_min 0.0464 (0.0025) teacher/usage_std 0.2405 (0.2522) nleep/row_max_mean 1542.1042 (1549.9562) nleep/row_max_std 63.2657 (56.4538) nleep/row_min_mean 1495.7983 (1502.1949) lr 1.5567e-04 eta 0:02:54
epoch [43/50] batch [40/181] time 0.092 (0.119) data 0.000 (0.007) loss 1.6688 (1.6260) teacher_loss 0.2381 (0.1978) loss_zs_kd 0.0376 (0.0354) loss_oracle 0.6856 (0.6451) kd_loss 1.0691 (1.0879) acc 93.7500 (93.1250) gate/entropy 0.9873 (0.9872) gate/usage_max 0.5638 (0.5640) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1630 (0.1631) teacher/entropy 0.0808 (0.0419) teacher/usage_max 0.6135 (0.5964) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2533 (0.2528) nleep/row_max_mean 1541.9431 (1549.6612) nleep/row_max_std 67.7145 (57.9219) nleep/row_min_mean 1492.9087 (1502.2820) lr 1.5567e-04 eta 0:02:48
epoch [43/50] batch [60/181] time 0.093 (0.119) data 0.001 (0.005) loss 1.5910 (1.6271) teacher_loss 0.2121 (0.2024) loss_zs_kd 0.0361 (0.0366) loss_oracle 0.6641 (0.6484) kd_loss 1.0288 (1.0822) acc 93.7500 (92.9688) gate/entropy 0.9873 (0.9872) gate/usage_max 0.5638 (0.5639) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1630 (0.1631) teacher/entropy 0.0338 (0.0423) teacher/usage_max 0.5200 (0.5969) teacher/usage_min 0.0018 (0.0017) teacher/usage_std 0.2350 (0.2533) nleep/row_max_mean 1545.6140 (1548.4322) nleep/row_max_std 59.3686 (57.2057) nleep/row_min_mean 1499.8242 (1501.5387) lr 1.5567e-04 eta 0:02:45
epoch [43/50] batch [80/181] time 0.100 (0.119) data 0.000 (0.004) loss 1.6984 (1.6228) teacher_loss 0.2281 (0.2025) loss_zs_kd 0.0430 (0.0358) loss_oracle 0.6525 (0.6477) kd_loss 1.1226 (1.0785) acc 93.7500 (93.0078) gate/entropy 0.9875 (0.9872) gate/usage_max 0.5636 (0.5639) gate/usage_min 0.2165 (0.2164) gate/usage_std 0.1628 (0.1630) teacher/entropy 0.0374 (0.0426) teacher/usage_max 0.6251 (0.5967) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2569 (0.2533) nleep/row_max_mean 1533.6323 (1547.2528) nleep/row_max_std 53.2114 (57.3190) nleep/row_min_mean 1487.7048 (1500.4826) lr 1.5567e-04 eta 0:02:42
epoch [43/50] batch [100/181] time 0.140 (0.120) data 0.000 (0.003) loss 1.5026 (1.6212) teacher_loss 0.1776 (0.2054) loss_zs_kd 0.0530 (0.0355) loss_oracle 0.6685 (0.6446) kd_loss 0.9642 (1.0757) acc 90.6250 (92.6250) gate/entropy 0.9871 (0.9873) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1631 (0.1630) teacher/entropy 0.0420 (0.0447) teacher/usage_max 0.5383 (0.5966) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2378 (0.2531) nleep/row_max_mean 1554.8145 (1545.9265) nleep/row_max_std 59.8582 (57.8344) nleep/row_min_mean 1501.6346 (1499.5499) lr 1.5567e-04 eta 0:02:42
epoch [43/50] batch [120/181] time 0.192 (0.121) data 0.000 (0.003) loss 1.5566 (1.6201) teacher_loss 0.1917 (0.2074) loss_zs_kd 0.0414 (0.0359) loss_oracle 0.6956 (0.6472) kd_loss 0.9964 (1.0711) acc 93.7500 (92.5000) gate/entropy 0.9869 (0.9873) gate/usage_max 0.5643 (0.5639) gate/usage_min 0.2161 (0.2164) gate/usage_std 0.1633 (0.1630) teacher/entropy 0.0281 (0.0439) teacher/usage_max 0.5196 (0.5940) teacher/usage_min 0.0002 (0.0020) teacher/usage_std 0.2361 (0.2519) nleep/row_max_mean 1549.4886 (1545.6346) nleep/row_max_std 45.8997 (57.1586) nleep/row_min_mean 1505.1157 (1499.3741) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [140/181] time 0.089 (0.121) data 0.000 (0.002) loss 1.7042 (1.6265) teacher_loss 0.1623 (0.2111) loss_zs_kd 0.0334 (0.0358) loss_oracle 0.7481 (0.6481) kd_loss 1.1511 (1.0734) acc 93.7500 (92.3214) gate/entropy 0.9873 (0.9873) gate/usage_max 0.5638 (0.5639) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0108 (0.0422) teacher/usage_max 0.6265 (0.5945) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2573 (0.2520) nleep/row_max_mean 1557.4913 (1545.9516) nleep/row_max_std 55.0158 (56.9162) nleep/row_min_mean 1505.8086 (1499.7941) lr 1.5567e-04 eta 0:02:38
epoch [43/50] batch [160/181] time 0.166 (0.121) data 0.000 (0.002) loss 1.6859 (1.6245) teacher_loss 0.2919 (0.2077) loss_zs_kd 0.0433 (0.0355) loss_oracle 0.6432 (0.6489) kd_loss 1.0507 (1.0746) acc 87.5000 (92.4219) gate/entropy 0.9876 (0.9873) gate/usage_max 0.5635 (0.5638) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1628 (0.1630) teacher/entropy 0.0824 (0.0416) teacher/usage_max 0.5766 (0.5965) teacher/usage_min 0.0196 (0.0028) teacher/usage_std 0.2328 (0.2522) nleep/row_max_mean 1527.2545 (1546.0092) nleep/row_max_std 69.0155 (57.0074) nleep/row_min_mean 1486.9561 (1499.8763) lr 1.5567e-04 eta 0:02:35
epoch [43/50] batch [180/181] time 0.132 (0.126) data 0.000 (0.002) loss 1.4194 (1.6219) teacher_loss 0.2214 (0.2082) loss_zs_kd 0.0225 (0.0350) loss_oracle 0.6611 (0.6495) kd_loss 0.8562 (1.0714) acc 93.7500 (92.3438) gate/entropy 0.9871 (0.9873) gate/usage_max 0.5640 (0.5638) gate/usage_min 0.2162 (0.2164) gate/usage_std 0.1631 (0.1630) teacher/entropy 0.0140 (0.0411) teacher/usage_max 0.6838 (0.5972) teacher/usage_min 0.0023 (0.0027) teacher/usage_std 0.2786 (0.2524) nleep/row_max_mean 1561.9586 (1546.1296) nleep/row_max_std 63.7699 (57.5176) nleep/row_min_mean 1509.0656 (1499.9978) lr 1.5567e-04 eta 0:02:39
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,416
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [44/50] batch [20/181] time 0.133 (0.174) data 0.000 (0.017) loss 1.5886 (1.5889) teacher_loss 0.1589 (0.1944) loss_zs_kd 0.0367 (0.0383) loss_oracle 0.6951 (0.6648) kd_loss 1.0638 (1.0430) acc 93.7500 (92.8125) gate/entropy 0.9875 (0.9873) gate/usage_max 0.5636 (0.5638) gate/usage_min 0.2163 (0.2163) gate/usage_std 0.1628 (0.1630) teacher/entropy 0.0686 (0.0439) teacher/usage_max 0.5962 (0.5891) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2484 (0.2499) nleep/row_max_mean 1543.1545 (1545.0758) nleep/row_max_std 59.6573 (58.2148) nleep/row_min_mean 1499.5488 (1499.5175) lr 1.2369e-04 eta 0:03:36
epoch [44/50] batch [40/181] time 0.162 (0.168) data 0.000 (0.009) loss 1.5318 (1.5989) teacher_loss 0.0997 (0.1978) loss_zs_kd 0.0223 (0.0357) loss_oracle 0.7048 (0.6695) kd_loss 1.0687 (1.0485) acc 96.8750 (92.6562) gate/entropy 0.9876 (0.9874) gate/usage_max 0.5635 (0.5637) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1628 (0.1629) teacher/entropy 0.0233 (0.0404) teacher/usage_max 0.5532 (0.5787) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2397 (0.2473) nleep/row_max_mean 1551.3188 (1543.7896) nleep/row_max_std 60.5666 (56.8517) nleep/row_min_mean 1502.2074 (1498.5981) lr 1.2369e-04 eta 0:03:25
epoch [44/50] batch [60/181] time 0.154 (0.165) data 0.000 (0.006) loss 1.2128 (1.5816) teacher_loss 0.0450 (0.1968) loss_zs_kd 0.0166 (0.0343) loss_oracle 0.5741 (0.6540) kd_loss 0.8724 (1.0406) acc 100.0000 (92.6562) gate/entropy 0.9879 (0.9874) gate/usage_max 0.5632 (0.5637) gate/usage_min 0.2165 (0.2163) gate/usage_std 0.1625 (0.1629) teacher/entropy 0.0621 (0.0399) teacher/usage_max 0.6158 (0.5768) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.2539 (0.2461) nleep/row_max_mean 1529.7040 (1545.6897) nleep/row_max_std 76.1049 (58.4179) nleep/row_min_mean 1486.0422 (1500.2839) lr 1.2369e-04 eta 0:03:18
epoch [44/50] batch [80/181] time 0.164 (0.161) data 0.000 (0.004) loss 1.4331 (1.5815) teacher_loss 0.1474 (0.1976) loss_zs_kd 0.0264 (0.0347) loss_oracle 0.5467 (0.6520) kd_loss 0.9991 (1.0406) acc 96.8750 (92.6172) gate/entropy 0.9878 (0.9874) gate/usage_max 0.5632 (0.5638) gate/usage_min 0.2165 (0.2163) gate/usage_std 0.1626 (0.1629) teacher/entropy 0.0559 (0.0394) teacher/usage_max 0.5138 (0.5706) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2360 (0.2446) nleep/row_max_mean 1531.2296 (1545.0696) nleep/row_max_std 62.6358 (58.8714) nleep/row_min_mean 1494.3668 (1500.0696) lr 1.2369e-04 eta 0:03:11
epoch [44/50] batch [100/181] time 0.133 (0.155) data 0.000 (0.004) loss 1.5649 (1.5814) teacher_loss 0.0750 (0.1960) loss_zs_kd 0.0243 (0.0348) loss_oracle 0.6803 (0.6508) kd_loss 1.1376 (1.0426) acc 96.8750 (92.4688) gate/entropy 0.9877 (0.9874) gate/usage_max 0.5633 (0.5637) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1626 (0.1629) teacher/entropy 0.0582 (0.0403) teacher/usage_max 0.6356 (0.5743) teacher/usage_min 0.0270 (0.0036) teacher/usage_std 0.2484 (0.2450) nleep/row_max_mean 1534.4138 (1543.9109) nleep/row_max_std 60.1105 (59.4619) nleep/row_min_mean 1495.8562 (1499.1962) lr 1.2369e-04 eta 0:03:00
epoch [44/50] batch [120/181] time 0.121 (0.147) data 0.000 (0.003) loss 1.6405 (1.5801) teacher_loss 0.1557 (0.1945) loss_zs_kd 0.0306 (0.0340) loss_oracle 0.6665 (0.6490) kd_loss 1.1362 (1.0440) acc 93.7500 (92.5000) gate/entropy 0.9877 (0.9874) gate/usage_max 0.5634 (0.5637) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1627 (0.1629) teacher/entropy 0.0338 (0.0389) teacher/usage_max 0.6021 (0.5734) teacher/usage_min 0.0313 (0.0036) teacher/usage_std 0.2342 (0.2445) nleep/row_max_mean 1536.9877 (1543.9080) nleep/row_max_std 55.3985 (59.6604) nleep/row_min_mean 1493.8446 (1499.2453) lr 1.2369e-04 eta 0:02:48
epoch [44/50] batch [140/181] time 0.084 (0.143) data 0.000 (0.003) loss 1.6010 (1.5866) teacher_loss 0.1043 (0.1965) loss_zs_kd 0.0437 (0.0339) loss_oracle 0.6530 (0.6500) kd_loss 1.1484 (1.0481) acc 100.0000 (92.7009) gate/entropy 0.9878 (0.9874) gate/usage_max 0.5633 (0.5637) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1626 (0.1629) teacher/entropy 0.0324 (0.0406) teacher/usage_max 0.6471 (0.5745) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.2646 (0.2445) nleep/row_max_mean 1533.2434 (1543.2444) nleep/row_max_std 58.7106 (59.8389) nleep/row_min_mean 1493.4171 (1498.7754) lr 1.2369e-04 eta 0:02:41
epoch [44/50] batch [160/181] time 0.095 (0.140) data 0.000 (0.002) loss 1.8807 (1.5863) teacher_loss 0.4919 (0.1979) loss_zs_kd 0.0540 (0.0342) loss_oracle 0.6673 (0.6491) kd_loss 1.0282 (1.0468) acc 84.3750 (92.6172) gate/entropy 0.9874 (0.9874) gate/usage_max 0.5637 (0.5637) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1629 (0.1629) teacher/entropy 0.0496 (0.0402) teacher/usage_max 0.5347 (0.5743) teacher/usage_min 0.0032 (0.0042) teacher/usage_std 0.2353 (0.2443) nleep/row_max_mean 1544.3447 (1543.1654) nleep/row_max_std 54.0748 (59.3752) nleep/row_min_mean 1503.0437 (1498.7637) lr 1.2369e-04 eta 0:02:35
epoch [44/50] batch [180/181] time 0.085 (0.135) data 0.000 (0.002) loss 1.7458 (1.5883) teacher_loss 0.2294 (0.1952) loss_zs_kd 0.0441 (0.0339) loss_oracle 0.7091 (0.6498) kd_loss 1.1398 (1.0513) acc 90.6250 (92.7431) gate/entropy 0.9880 (0.9874) gate/usage_max 0.5631 (0.5637) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1625 (0.1629) teacher/entropy 0.0265 (0.0397) teacher/usage_max 0.6320 (0.5760) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.2592 (0.2450) nleep/row_max_mean 1532.1133 (1543.1313) nleep/row_max_std 57.4261 (59.0134) nleep/row_min_mean 1484.8276 (1498.6801) lr 1.2369e-04 eta 0:02:27
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,417
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [45/50] batch [20/181] time 0.089 (0.132) data 0.000 (0.015) loss 1.4527 (1.5515) teacher_loss 0.1653 (0.1814) loss_zs_kd 0.0253 (0.0316) loss_oracle 0.6407 (0.6499) kd_loss 0.9544 (1.0293) acc 93.7500 (93.2812) gate/entropy 0.9875 (0.9875) gate/usage_max 0.5636 (0.5636) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1628 (0.1628) teacher/entropy 0.0399 (0.0471) teacher/usage_max 0.5515 (0.5698) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2394 (0.2436) nleep/row_max_mean 1552.0206 (1546.6368) nleep/row_max_std 64.6668 (59.0733) nleep/row_min_mean 1506.1772 (1502.6393) lr 9.5173e-05 eta 0:02:20
epoch [45/50] batch [40/181] time 0.124 (0.130) data 0.000 (0.007) loss 1.4960 (1.5441) teacher_loss 0.1206 (0.1667) loss_zs_kd 0.0372 (0.0330) loss_oracle 0.6612 (0.6521) kd_loss 1.0262 (1.0348) acc 96.8750 (93.8281) gate/entropy 0.9874 (0.9875) gate/usage_max 0.5637 (0.5636) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0885 (0.0473) teacher/usage_max 0.5434 (0.5650) teacher/usage_min 0.0327 (0.0058) teacher/usage_std 0.2181 (0.2411) nleep/row_max_mean 1537.2506 (1546.7880) nleep/row_max_std 64.5301 (57.4448) nleep/row_min_mean 1498.9856 (1502.5980) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [60/181] time 0.153 (0.135) data 0.001 (0.005) loss 1.5395 (1.5461) teacher_loss 0.1903 (0.1704) loss_zs_kd 0.0298 (0.0333) loss_oracle 0.6500 (0.6487) kd_loss 1.0093 (1.0347) acc 90.6250 (93.4896) gate/entropy 0.9875 (0.9875) gate/usage_max 0.5636 (0.5635) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0028 (0.0438) teacher/usage_max 0.5317 (0.5654) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.2371 (0.2422) nleep/row_max_mean 1544.8774 (1544.7387) nleep/row_max_std 49.6243 (57.9719) nleep/row_min_mean 1503.7727 (1500.4697) lr 9.5173e-05 eta 0:02:18
epoch [45/50] batch [80/181] time 0.159 (0.139) data 0.000 (0.004) loss 1.6738 (1.5528) teacher_loss 0.2338 (0.1664) loss_zs_kd 0.0397 (0.0333) loss_oracle 0.5911 (0.6535) kd_loss 1.1247 (1.0430) acc 93.7500 (93.5938) gate/entropy 0.9873 (0.9876) gate/usage_max 0.5638 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1630 (0.1628) teacher/entropy 0.0080 (0.0420) teacher/usage_max 0.5960 (0.5674) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2484 (0.2426) nleep/row_max_mean 1545.3492 (1543.1933) nleep/row_max_std 54.7500 (58.7229) nleep/row_min_mean 1503.5646 (1499.3050) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [100/181] time 0.146 (0.139) data 0.000 (0.003) loss 1.4790 (1.5559) teacher_loss 0.1270 (0.1692) loss_zs_kd 0.0405 (0.0341) loss_oracle 0.6247 (0.6502) kd_loss 1.0194 (1.0445) acc 96.8750 (93.5312) gate/entropy 0.9874 (0.9876) gate/usage_max 0.5637 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0326 (0.0408) teacher/usage_max 0.4904 (0.5675) teacher/usage_min 0.0312 (0.0048) teacher/usage_std 0.2137 (0.2426) nleep/row_max_mean 1545.2396 (1542.4361) nleep/row_max_std 47.9234 (58.9325) nleep/row_min_mean 1503.5040 (1498.5922) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [120/181] time 0.197 (0.142) data 0.000 (0.003) loss 1.5725 (1.5626) teacher_loss 0.1737 (0.1774) loss_zs_kd 0.0574 (0.0351) loss_oracle 0.7205 (0.6502) kd_loss 1.0099 (1.0426) acc 90.6250 (93.2031) gate/entropy 0.9871 (0.9875) gate/usage_max 0.5640 (0.5636) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1631 (0.1628) teacher/entropy 0.0449 (0.0412) teacher/usage_max 0.4885 (0.5669) teacher/usage_min 0.0623 (0.0051) teacher/usage_std 0.1923 (0.2424) nleep/row_max_mean 1557.8829 (1542.7090) nleep/row_max_std 49.2179 (59.3766) nleep/row_min_mean 1513.0515 (1498.8748) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [140/181] time 0.143 (0.144) data 0.000 (0.002) loss 1.8718 (1.5647) teacher_loss 0.3322 (0.1813) loss_zs_kd 0.0606 (0.0352) loss_oracle 0.7261 (0.6492) kd_loss 1.1463 (1.0412) acc 87.5000 (92.9464) gate/entropy 0.9876 (0.9875) gate/usage_max 0.5635 (0.5636) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1628 (0.1628) teacher/entropy 0.0107 (0.0407) teacher/usage_max 0.6218 (0.5672) teacher/usage_min 0.0001 (0.0054) teacher/usage_std 0.2558 (0.2422) nleep/row_max_mean 1548.4241 (1542.8328) nleep/row_max_std 49.3611 (59.6700) nleep/row_min_mean 1501.0591 (1498.9700) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [160/181] time 0.155 (0.145) data 0.000 (0.002) loss 1.7107 (1.5608) teacher_loss 0.2827 (0.1829) loss_zs_kd 0.0438 (0.0349) loss_oracle 0.7284 (0.6460) kd_loss 1.0419 (1.0374) acc 90.6250 (92.8516) gate/entropy 0.9879 (0.9876) gate/usage_max 0.5632 (0.5635) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1625 (0.1628) teacher/entropy 0.0421 (0.0414) teacher/usage_max 0.5242 (0.5673) teacher/usage_min 0.0199 (0.0053) teacher/usage_std 0.2234 (0.2421) nleep/row_max_mean 1538.0747 (1542.5443) nleep/row_max_std 54.7183 (60.0469) nleep/row_min_mean 1489.6879 (1498.6791) lr 9.5173e-05 eta 0:02:14
epoch [45/50] batch [180/181] time 0.138 (0.145) data 0.000 (0.002) loss 1.6258 (1.5584) teacher_loss 0.2237 (0.1844) loss_zs_kd 0.0428 (0.0353) loss_oracle 0.6920 (0.6450) kd_loss 1.0347 (1.0339) acc 90.6250 (92.7951) gate/entropy 0.9875 (0.9876) gate/usage_max 0.5636 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1629 (0.1628) teacher/entropy 0.0704 (0.0422) teacher/usage_max 0.5672 (0.5651) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2420 (0.2418) nleep/row_max_mean 1530.2988 (1542.7389) nleep/row_max_std 56.8292 (60.2715) nleep/row_min_mean 1491.8961 (1498.8405) lr 9.5173e-05 eta 0:02:11
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [46/50] batch [20/181] time 0.172 (0.149) data 0.000 (0.015) loss 1.7260 (1.5671) teacher_loss 0.0778 (0.1605) loss_zs_kd 0.0172 (0.0322) loss_oracle 0.7394 (0.6562) kd_loss 1.2699 (1.0625) acc 96.8750 (94.0625) gate/entropy 0.9877 (0.9876) gate/usage_max 0.5634 (0.5635) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1627 (0.1628) teacher/entropy 0.0099 (0.0374) teacher/usage_max 0.7517 (0.5842) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.3127 (0.2469) nleep/row_max_mean 1554.1731 (1543.6616) nleep/row_max_std 46.9543 (56.3261) nleep/row_min_mean 1505.6677 (1500.2417) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [40/181] time 0.079 (0.134) data 0.000 (0.007) loss 1.6672 (1.5867) teacher_loss 0.3089 (0.1905) loss_zs_kd 0.0364 (0.0356) loss_oracle 0.6167 (0.6615) kd_loss 1.0318 (1.0477) acc 84.3750 (92.5000) gate/entropy 0.9878 (0.9876) gate/usage_max 0.5633 (0.5635) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1626 (0.1628) teacher/entropy 0.0315 (0.0388) teacher/usage_max 0.5223 (0.5753) teacher/usage_min 0.0013 (0.0077) teacher/usage_std 0.2356 (0.2430) nleep/row_max_mean 1543.5413 (1544.9548) nleep/row_max_std 62.8794 (57.2051) nleep/row_min_mean 1498.3188 (1500.9617) lr 7.0224e-05 eta 0:01:55
epoch [46/50] batch [60/181] time 0.178 (0.124) data 0.000 (0.005) loss 1.4710 (1.5790) teacher_loss 0.1179 (0.1934) loss_zs_kd 0.0311 (0.0354) loss_oracle 0.6257 (0.6557) kd_loss 1.0247 (1.0400) acc 93.7500 (92.5000) gate/entropy 0.9877 (0.9876) gate/usage_max 0.5634 (0.5635) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0202 (0.0398) teacher/usage_max 0.5015 (0.5748) teacher/usage_min 0.0020 (0.0086) teacher/usage_std 0.2343 (0.2422) nleep/row_max_mean 1534.6519 (1545.3818) nleep/row_max_std 53.8070 (58.0706) nleep/row_min_mean 1492.7775 (1501.1337) lr 7.0224e-05 eta 0:01:45
epoch [46/50] batch [80/181] time 0.094 (0.121) data 0.000 (0.004) loss 1.4691 (1.5798) teacher_loss 0.1709 (0.1999) loss_zs_kd 0.0245 (0.0354) loss_oracle 0.6711 (0.6508) kd_loss 0.9504 (1.0367) acc 96.8750 (92.3438) gate/entropy 0.9881 (0.9876) gate/usage_max 0.5630 (0.5635) gate/usage_min 0.2164 (0.2162) gate/usage_std 0.1624 (0.1628) teacher/entropy 0.0359 (0.0401) teacher/usage_max 0.5584 (0.5723) teacher/usage_min 0.0000 (0.0073) teacher/usage_std 0.2405 (0.2424) nleep/row_max_mean 1525.2708 (1545.0571) nleep/row_max_std 57.9617 (57.1937) nleep/row_min_mean 1485.2157 (1501.0426) lr 7.0224e-05 eta 0:01:39
epoch [46/50] batch [100/181] time 0.085 (0.118) data 0.000 (0.003) loss 1.5754 (1.5729) teacher_loss 0.2368 (0.1942) loss_zs_kd 0.0576 (0.0352) loss_oracle 0.6794 (0.6489) kd_loss 0.9701 (1.0366) acc 90.6250 (92.5312) gate/entropy 0.9873 (0.9876) gate/usage_max 0.5638 (0.5635) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1629 (0.1627) teacher/entropy 0.0279 (0.0390) teacher/usage_max 0.5470 (0.5698) teacher/usage_min 0.0298 (0.0079) teacher/usage_std 0.2205 (0.2415) nleep/row_max_mean 1553.5972 (1545.1105) nleep/row_max_std 48.9318 (56.5082) nleep/row_min_mean 1504.8304 (1501.3014) lr 7.0224e-05 eta 0:01:34
epoch [46/50] batch [120/181] time 0.179 (0.118) data 0.000 (0.003) loss 1.3041 (1.5799) teacher_loss 0.0628 (0.1971) loss_zs_kd 0.0162 (0.0354) loss_oracle 0.6021 (0.6542) kd_loss 0.9321 (1.0381) acc 100.0000 (92.3438) gate/entropy 0.9876 (0.9876) gate/usage_max 0.5635 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1628 (0.1627) teacher/entropy 0.0173 (0.0384) teacher/usage_max 0.5985 (0.5726) teacher/usage_min 0.0001 (0.0080) teacher/usage_std 0.2490 (0.2419) nleep/row_max_mean 1555.3486 (1546.0223) nleep/row_max_std 54.5082 (56.1918) nleep/row_min_mean 1510.9592 (1502.1246) lr 7.0224e-05 eta 0:01:32
epoch [46/50] batch [140/181] time 0.092 (0.117) data 0.000 (0.002) loss 1.4592 (1.5749) teacher_loss 0.1209 (0.1932) loss_zs_kd 0.0579 (0.0357) loss_oracle 0.6300 (0.6520) kd_loss 0.9944 (1.0379) acc 93.7500 (92.2991) gate/entropy 0.9876 (0.9876) gate/usage_max 0.5635 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0169 (0.0377) teacher/usage_max 0.5316 (0.5733) teacher/usage_min 0.0000 (0.0071) teacher/usage_std 0.2371 (0.2425) nleep/row_max_mean 1547.6802 (1546.1413) nleep/row_max_std 62.3419 (55.8405) nleep/row_min_mean 1496.1941 (1502.0476) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [160/181] time 0.190 (0.122) data 0.000 (0.002) loss 1.5011 (1.5685) teacher_loss 0.0189 (0.1913) loss_zs_kd 0.0102 (0.0358) loss_oracle 0.7532 (0.6524) kd_loss 1.1005 (1.0330) acc 100.0000 (92.3828) gate/entropy 0.9880 (0.9876) gate/usage_max 0.5630 (0.5635) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1624 (0.1627) teacher/entropy 0.0780 (0.0390) teacher/usage_max 0.6181 (0.5694) teacher/usage_min 0.0254 (0.0070) teacher/usage_std 0.2425 (0.2418) nleep/row_max_mean 1522.7278 (1545.7462) nleep/row_max_std 59.0802 (56.0583) nleep/row_min_mean 1482.9370 (1501.6425) lr 7.0224e-05 eta 0:01:30
epoch [46/50] batch [180/181] time 0.149 (0.125) data 0.000 (0.002) loss 1.5447 (1.5727) teacher_loss 0.2724 (0.1936) loss_zs_kd 0.0500 (0.0359) loss_oracle 0.6206 (0.6520) kd_loss 0.9370 (1.0351) acc 87.5000 (92.2743) gate/entropy 0.9877 (0.9876) gate/usage_max 0.5634 (0.5635) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0227 (0.0374) teacher/usage_max 0.5868 (0.5704) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.2461 (0.2423) nleep/row_max_mean 1552.6840 (1545.3743) nleep/row_max_std 63.4258 (55.8486) nleep/row_min_mean 1504.0518 (1501.2652) lr 7.0224e-05 eta 0:01:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [47/50] batch [20/181] time 0.154 (0.182) data 0.000 (0.015) loss 1.7108 (1.5760) teacher_loss 0.3311 (0.1976) loss_zs_kd 0.0546 (0.0358) loss_oracle 0.6939 (0.6557) kd_loss 1.0055 (1.0326) acc 87.5000 (92.1875) gate/entropy 0.9878 (0.9877) gate/usage_max 0.5633 (0.5634) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1626 (0.1627) teacher/entropy 0.0051 (0.0437) teacher/usage_max 0.5319 (0.5544) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2371 (0.2416) nleep/row_max_mean 1555.5413 (1543.0675) nleep/row_max_std 59.1726 (58.7873) nleep/row_min_mean 1503.0403 (1499.3432) lr 4.8943e-05 eta 0:02:08
epoch [47/50] batch [40/181] time 0.159 (0.169) data 0.000 (0.008) loss 1.5261 (1.5572) teacher_loss 0.3505 (0.1874) loss_zs_kd 0.0513 (0.0358) loss_oracle 0.4908 (0.6493) kd_loss 0.9045 (1.0273) acc 78.1250 (92.3438) gate/entropy 0.9872 (0.9877) gate/usage_max 0.5639 (0.5634) gate/usage_min 0.2159 (0.2161) gate/usage_std 0.1631 (0.1627) teacher/entropy 0.0383 (0.0423) teacher/usage_max 0.6060 (0.5628) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2511 (0.2418) nleep/row_max_mean 1558.8226 (1542.6234) nleep/row_max_std 66.8870 (60.6196) nleep/row_min_mean 1511.3622 (1497.8716) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [60/181] time 0.164 (0.167) data 0.000 (0.005) loss 1.4578 (1.5609) teacher_loss 0.1565 (0.1957) loss_zs_kd 0.0359 (0.0378) loss_oracle 0.7005 (0.6482) kd_loss 0.9331 (1.0222) acc 96.8750 (92.3958) gate/entropy 0.9875 (0.9877) gate/usage_max 0.5636 (0.5634) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1628 (0.1627) teacher/entropy 0.0375 (0.0402) teacher/usage_max 0.5752 (0.5598) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2436 (0.2404) nleep/row_max_mean 1564.0336 (1544.8867) nleep/row_max_std 58.4379 (61.0418) nleep/row_min_mean 1513.7466 (1499.5356) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [80/181] time 0.091 (0.153) data 0.000 (0.004) loss 1.3397 (1.5647) teacher_loss 0.1392 (0.1904) loss_zs_kd 0.0369 (0.0376) loss_oracle 0.4740 (0.6512) kd_loss 0.9450 (1.0299) acc 93.7500 (92.8516) gate/entropy 0.9875 (0.9877) gate/usage_max 0.5636 (0.5634) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1628 (0.1627) teacher/entropy 0.0670 (0.0400) teacher/usage_max 0.5329 (0.5623) teacher/usage_min 0.0115 (0.0057) teacher/usage_std 0.2297 (0.2409) nleep/row_max_mean 1555.0349 (1545.0425) nleep/row_max_std 57.8316 (61.6169) nleep/row_min_mean 1514.4980 (1499.8503) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [100/181] time 0.086 (0.143) data 0.000 (0.003) loss 1.3056 (1.5522) teacher_loss 0.1078 (0.1819) loss_zs_kd 0.0337 (0.0361) loss_oracle 0.6044 (0.6525) kd_loss 0.8787 (1.0260) acc 93.7500 (93.2188) gate/entropy 0.9873 (0.9877) gate/usage_max 0.5638 (0.5634) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1629 (0.1627) teacher/entropy 0.0119 (0.0401) teacher/usage_max 0.6602 (0.5635) teacher/usage_min 0.0000 (0.0064) teacher/usage_std 0.2696 (0.2406) nleep/row_max_mean 1566.5977 (1546.2108) nleep/row_max_std 55.0166 (61.2214) nleep/row_min_mean 1517.7544 (1501.0293) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [120/181] time 0.086 (0.137) data 0.000 (0.003) loss 1.8808 (1.5605) teacher_loss 0.3230 (0.1882) loss_zs_kd 0.0592 (0.0360) loss_oracle 0.8594 (0.6523) kd_loss 1.0985 (1.0281) acc 90.6250 (93.0729) gate/entropy 0.9877 (0.9877) gate/usage_max 0.5634 (0.5634) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0000 (0.0399) teacher/usage_max 0.5625 (0.5637) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.2412 (0.2412) nleep/row_max_mean 1552.4253 (1546.1102) nleep/row_max_std 50.8262 (60.8052) nleep/row_min_mean 1506.1776 (1501.0546) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [140/181] time 0.082 (0.134) data 0.000 (0.002) loss 1.5561 (1.5697) teacher_loss 0.1304 (0.1879) loss_zs_kd 0.0248 (0.0362) loss_oracle 0.7139 (0.6582) kd_loss 1.0563 (1.0346) acc 100.0000 (92.9688) gate/entropy 0.9880 (0.9877) gate/usage_max 0.5631 (0.5634) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1625 (0.1627) teacher/entropy 0.0383 (0.0394) teacher/usage_max 0.5254 (0.5669) teacher/usage_min 0.0302 (0.0064) teacher/usage_std 0.2169 (0.2415) nleep/row_max_mean 1547.7528 (1546.4427) nleep/row_max_std 60.0953 (60.3173) nleep/row_min_mean 1500.8749 (1501.3540) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [160/181] time 0.083 (0.131) data 0.000 (0.002) loss 1.5732 (1.5728) teacher_loss 0.2305 (0.1909) loss_zs_kd 0.0330 (0.0362) loss_oracle 0.6520 (0.6569) kd_loss 1.0001 (1.0354) acc 87.5000 (92.7148) gate/entropy 0.9876 (0.9877) gate/usage_max 0.5635 (0.5634) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1628 (0.1627) teacher/entropy 0.0170 (0.0387) teacher/usage_max 0.5258 (0.5664) teacher/usage_min 0.0000 (0.0063) teacher/usage_std 0.2366 (0.2416) nleep/row_max_mean 1559.5540 (1546.7094) nleep/row_max_std 54.0186 (60.1507) nleep/row_min_mean 1516.1267 (1501.7032) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [180/181] time 0.130 (0.128) data 0.000 (0.002) loss 1.6096 (1.5708) teacher_loss 0.1120 (0.1896) loss_zs_kd 0.0337 (0.0357) loss_oracle 0.7274 (0.6548) kd_loss 1.1171 (1.0360) acc 93.7500 (92.8299) gate/entropy 0.9881 (0.9877) gate/usage_max 0.5630 (0.5634) gate/usage_min 0.2163 (0.2161) gate/usage_std 0.1624 (0.1627) teacher/entropy 0.0265 (0.0394) teacher/usage_max 0.6081 (0.5664) teacher/usage_min 0.0001 (0.0064) teacher/usage_std 0.2516 (0.2415) nleep/row_max_mean 1541.4088 (1546.7928) nleep/row_max_std 54.6520 (60.0736) nleep/row_min_mean 1499.3743 (1501.9168) lr 4.8943e-05 eta 0:01:09
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [48/50] batch [20/181] time 0.088 (0.131) data 0.000 (0.016) loss 1.8642 (1.5651) teacher_loss 0.3595 (0.2055) loss_zs_kd 0.0472 (0.0382) loss_oracle 0.7072 (0.6442) kd_loss 1.1275 (1.0185) acc 81.2500 (91.5625) gate/entropy 0.9879 (0.9877) gate/usage_max 0.5632 (0.5634) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1625 (0.1627) teacher/entropy 0.0025 (0.0400) teacher/usage_max 0.5942 (0.5683) teacher/usage_min 0.0000 (0.0081) teacher/usage_std 0.2479 (0.2403) nleep/row_max_mean 1536.4596 (1545.0635) nleep/row_max_std 49.3472 (54.2699) nleep/row_min_mean 1493.2839 (1501.9204) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [40/181] time 0.153 (0.122) data 0.000 (0.008) loss 1.5798 (1.5659) teacher_loss 0.2368 (0.2069) loss_zs_kd 0.0614 (0.0382) loss_oracle 0.6217 (0.6525) kd_loss 1.0014 (1.0137) acc 90.6250 (91.3281) gate/entropy 0.9877 (0.9877) gate/usage_max 0.5634 (0.5634) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1627 (0.1627) teacher/entropy 0.0775 (0.0404) teacher/usage_max 0.5383 (0.5682) teacher/usage_min 0.0008 (0.0063) teacher/usage_std 0.2372 (0.2408) nleep/row_max_mean 1547.6409 (1545.7439) nleep/row_max_std 55.5704 (54.0254) nleep/row_min_mean 1506.4867 (1501.9455) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [60/181] time 0.151 (0.131) data 0.000 (0.006) loss 1.6400 (1.5788) teacher_loss 0.1341 (0.2070) loss_zs_kd 0.0433 (0.0381) loss_oracle 0.7670 (0.6648) kd_loss 1.1008 (1.0203) acc 93.7500 (91.4583) gate/entropy 0.9877 (0.9878) gate/usage_max 0.5633 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0405 (0.0393) teacher/usage_max 0.6064 (0.5655) teacher/usage_min 0.0000 (0.0063) teacher/usage_std 0.2512 (0.2407) nleep/row_max_mean 1548.8137 (1545.0429) nleep/row_max_std 58.2029 (54.6670) nleep/row_min_mean 1505.8495 (1500.7524) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [80/181] time 0.155 (0.135) data 0.000 (0.004) loss 1.6555 (1.5772) teacher_loss 0.1184 (0.2039) loss_zs_kd 0.0323 (0.0377) loss_oracle 0.7442 (0.6618) kd_loss 1.1489 (1.0235) acc 93.7500 (91.5625) gate/entropy 0.9879 (0.9878) gate/usage_max 0.5632 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0132 (0.0388) teacher/usage_max 0.6287 (0.5728) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2581 (0.2422) nleep/row_max_mean 1544.0039 (1545.1007) nleep/row_max_std 55.1016 (55.3854) nleep/row_min_mean 1495.5708 (1500.3472) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [100/181] time 0.182 (0.138) data 0.000 (0.003) loss 1.3054 (1.5719) teacher_loss 0.1015 (0.2000) loss_zs_kd 0.0298 (0.0379) loss_oracle 0.6218 (0.6585) kd_loss 0.8781 (1.0237) acc 93.7500 (91.7812) gate/entropy 0.9875 (0.9878) gate/usage_max 0.5636 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.1164 (0.0397) teacher/usage_max 0.5503 (0.5724) teacher/usage_min 0.0000 (0.0067) teacher/usage_std 0.2393 (0.2420) nleep/row_max_mean 1546.3325 (1545.6304) nleep/row_max_std 59.4217 (55.5093) nleep/row_min_mean 1505.2788 (1500.8493) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [120/181] time 0.147 (0.140) data 0.000 (0.003) loss 1.4715 (1.5738) teacher_loss 0.1258 (0.1946) loss_zs_kd 0.0359 (0.0383) loss_oracle 0.6397 (0.6594) kd_loss 1.0079 (1.0303) acc 93.7500 (92.1094) gate/entropy 0.9883 (0.9878) gate/usage_max 0.5628 (0.5633) gate/usage_min 0.2163 (0.2161) gate/usage_std 0.1623 (0.1626) teacher/entropy 0.0702 (0.0384) teacher/usage_max 0.5364 (0.5748) teacher/usage_min 0.0028 (0.0066) teacher/usage_std 0.2358 (0.2429) nleep/row_max_mean 1535.7865 (1545.3746) nleep/row_max_std 56.9705 (55.6234) nleep/row_min_mean 1494.4033 (1500.7836) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [140/181] time 0.146 (0.140) data 0.000 (0.002) loss 1.7348 (1.5728) teacher_loss 0.3086 (0.1936) loss_zs_kd 0.0366 (0.0379) loss_oracle 0.6836 (0.6585) kd_loss 1.0661 (1.0309) acc 84.3750 (92.1429) gate/entropy 0.9876 (0.9878) gate/usage_max 0.5635 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0248 (0.0385) teacher/usage_max 0.4893 (0.5718) teacher/usage_min 0.0617 (0.0062) teacher/usage_std 0.1927 (0.2425) nleep/row_max_mean 1550.8787 (1544.8221) nleep/row_max_std 57.5358 (56.1249) nleep/row_min_mean 1507.0314 (1500.3201) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [160/181] time 0.157 (0.140) data 0.000 (0.002) loss 1.5883 (1.5728) teacher_loss 0.1326 (0.1948) loss_zs_kd 0.0185 (0.0374) loss_oracle 0.7054 (0.6551) kd_loss 1.0937 (1.0318) acc 93.7500 (92.0312) gate/entropy 0.9875 (0.9878) gate/usage_max 0.5636 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0353 (0.0388) teacher/usage_max 0.5929 (0.5700) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2476 (0.2422) nleep/row_max_mean 1539.8376 (1545.1273) nleep/row_max_std 56.5689 (56.4633) nleep/row_min_mean 1502.1779 (1500.7059) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [180/181] time 0.165 (0.141) data 0.000 (0.002) loss 1.7773 (1.5744) teacher_loss 0.1977 (0.1957) loss_zs_kd 0.0358 (0.0373) loss_oracle 0.7709 (0.6571) kd_loss 1.1762 (1.0315) acc 93.7500 (92.0833) gate/entropy 0.9879 (0.9878) gate/usage_max 0.5632 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0377 (0.0390) teacher/usage_max 0.6838 (0.5701) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2794 (0.2425) nleep/row_max_mean 1545.5894 (1545.6692) nleep/row_max_std 57.6131 (56.8516) nleep/row_min_mean 1498.3363 (1501.1849) lr 3.1417e-05 eta 0:00:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [49/50] batch [20/181] time 0.169 (0.144) data 0.000 (0.019) loss 1.7014 (1.5424) teacher_loss 0.2183 (0.1514) loss_zs_kd 0.0377 (0.0377) loss_oracle 0.7509 (0.6532) kd_loss 1.0889 (1.0455) acc 93.7500 (94.3750) gate/entropy 0.9883 (0.9878) gate/usage_max 0.5627 (0.5632) gate/usage_min 0.2163 (0.2161) gate/usage_std 0.1622 (0.1626) teacher/entropy 0.0525 (0.0434) teacher/usage_max 0.6078 (0.5528) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.2516 (0.2392) nleep/row_max_mean 1524.7092 (1544.1144) nleep/row_max_std 59.4247 (60.5104) nleep/row_min_mean 1485.3984 (1499.4694) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [40/181] time 0.088 (0.128) data 0.000 (0.010) loss 1.4692 (1.5688) teacher_loss 0.2451 (0.1754) loss_zs_kd 0.0227 (0.0379) loss_oracle 0.5773 (0.6740) kd_loss 0.9241 (1.0374) acc 93.7500 (93.3594) gate/entropy 0.9881 (0.9878) gate/usage_max 0.5629 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1624 (0.1626) teacher/entropy 0.0906 (0.0385) teacher/usage_max 0.5304 (0.5480) teacher/usage_min 0.0167 (0.0060) teacher/usage_std 0.2261 (0.2370) nleep/row_max_mean 1521.8143 (1543.3022) nleep/row_max_std 65.9398 (58.0821) nleep/row_min_mean 1485.7034 (1499.1241) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [60/181] time 0.096 (0.117) data 0.001 (0.006) loss 1.5507 (1.5700) teacher_loss 0.0964 (0.1739) loss_zs_kd 0.0182 (0.0371) loss_oracle 0.7204 (0.6740) kd_loss 1.0851 (1.0405) acc 93.7500 (93.3854) gate/entropy 0.9881 (0.9878) gate/usage_max 0.5630 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1624 (0.1626) teacher/entropy 0.0360 (0.0350) teacher/usage_max 0.5533 (0.5568) teacher/usage_min 0.0312 (0.0051) teacher/usage_std 0.2209 (0.2397) nleep/row_max_mean 1548.3436 (1545.0344) nleep/row_max_std 54.5988 (56.3837) nleep/row_min_mean 1503.6881 (1500.4043) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [80/181] time 0.080 (0.116) data 0.000 (0.005) loss 1.4180 (1.5619) teacher_loss 0.1602 (0.1751) loss_zs_kd 0.0313 (0.0359) loss_oracle 0.5311 (0.6689) kd_loss 0.9765 (1.0344) acc 93.7500 (93.5156) gate/entropy 0.9878 (0.9878) gate/usage_max 0.5633 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0799 (0.0384) teacher/usage_max 0.5155 (0.5598) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.2360 (0.2402) nleep/row_max_mean 1550.9626 (1546.0189) nleep/row_max_std 53.6139 (56.1511) nleep/row_min_mean 1510.9011 (1501.7135) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [100/181] time 0.123 (0.115) data 0.000 (0.004) loss 1.5522 (1.5574) teacher_loss 0.2309 (0.1753) loss_zs_kd 0.0312 (0.0360) loss_oracle 0.5769 (0.6624) kd_loss 1.0173 (1.0329) acc 93.7500 (93.2188) gate/entropy 0.9876 (0.9878) gate/usage_max 0.5635 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0483 (0.0372) teacher/usage_max 0.5245 (0.5594) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.2366 (0.2407) nleep/row_max_mean 1554.9407 (1547.3691) nleep/row_max_std 48.3555 (55.4847) nleep/row_min_mean 1510.7126 (1502.5947) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [120/181] time 0.073 (0.113) data 0.000 (0.003) loss 1.6091 (1.5586) teacher_loss 0.1489 (0.1772) loss_zs_kd 0.0283 (0.0361) loss_oracle 0.6971 (0.6627) kd_loss 1.0975 (1.0320) acc 93.7500 (93.1771) gate/entropy 0.9881 (0.9878) gate/usage_max 0.5629 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1623 (0.1626) teacher/entropy 0.0760 (0.0389) teacher/usage_max 0.6330 (0.5640) teacher/usage_min 0.0081 (0.0048) teacher/usage_std 0.2558 (0.2418) nleep/row_max_mean 1548.6658 (1547.2914) nleep/row_max_std 48.8963 (55.3529) nleep/row_min_mean 1506.2281 (1502.4671) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [140/181] time 0.102 (0.112) data 0.000 (0.003) loss 1.5735 (1.5574) teacher_loss 0.1803 (0.1797) loss_zs_kd 0.0328 (0.0360) loss_oracle 0.6646 (0.6614) kd_loss 1.0445 (1.0291) acc 93.7500 (93.0804) gate/entropy 0.9880 (0.9878) gate/usage_max 0.5631 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1625 (0.1626) teacher/entropy 0.0379 (0.0395) teacher/usage_max 0.5436 (0.5619) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2384 (0.2408) nleep/row_max_mean 1534.2708 (1548.2803) nleep/row_max_std 52.7558 (55.0202) nleep/row_min_mean 1493.8877 (1503.4550) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [160/181] time 0.171 (0.113) data 0.000 (0.003) loss 1.4747 (1.5608) teacher_loss 0.1690 (0.1821) loss_zs_kd 0.0499 (0.0363) loss_oracle 0.6322 (0.6604) kd_loss 0.9647 (1.0304) acc 90.6250 (93.0078) gate/entropy 0.9879 (0.9878) gate/usage_max 0.5631 (0.5633) gate/usage_min 0.2162 (0.2161) gate/usage_std 0.1625 (0.1626) teacher/entropy 0.0203 (0.0391) teacher/usage_max 0.5615 (0.5611) teacher/usage_min 0.0293 (0.0055) teacher/usage_std 0.2238 (0.2406) nleep/row_max_mean 1542.3898 (1548.4723) nleep/row_max_std 71.5680 (54.7421) nleep/row_min_mean 1499.3901 (1503.6400) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [180/181] time 0.162 (0.119) data 0.000 (0.002) loss 1.7237 (1.5648) teacher_loss 0.4333 (0.1866) loss_zs_kd 0.0502 (0.0363) loss_oracle 0.6494 (0.6591) kd_loss 0.9406 (1.0305) acc 87.5000 (92.7431) gate/entropy 0.9878 (0.9878) gate/usage_max 0.5632 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0163 (0.0385) teacher/usage_max 0.5890 (0.5624) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.2466 (0.2410) nleep/row_max_mean 1551.3762 (1549.0008) nleep/row_max_std 56.1296 (54.4228) nleep/row_min_mean 1500.5707 (1504.0337) lr 1.7713e-05 eta 0:00:21
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [50/50] batch [20/181] time 0.172 (0.182) data 0.000 (0.015) loss 1.3470 (1.5853) teacher_loss 0.1614 (0.2024) loss_zs_kd 0.0607 (0.0374) loss_oracle 0.5984 (0.6579) kd_loss 0.8560 (1.0352) acc 93.7500 (91.7188) gate/entropy 0.9874 (0.9877) gate/usage_max 0.5637 (0.5634) gate/usage_min 0.2159 (0.2160) gate/usage_std 0.1629 (0.1627) teacher/entropy 0.0131 (0.0336) teacher/usage_max 0.6840 (0.5759) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2795 (0.2427) nleep/row_max_mean 1564.1995 (1555.5605) nleep/row_max_std 60.1694 (57.9338) nleep/row_min_mean 1509.4592 (1508.8967) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [40/181] time 0.169 (0.172) data 0.000 (0.007) loss 1.5671 (1.5785) teacher_loss 0.1706 (0.1959) loss_zs_kd 0.0251 (0.0383) loss_oracle 0.7306 (0.6641) kd_loss 1.0186 (1.0314) acc 90.6250 (91.7969) gate/entropy 0.9880 (0.9878) gate/usage_max 0.5631 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1625 (0.1626) teacher/entropy 0.0196 (0.0378) teacher/usage_max 0.5029 (0.5641) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.2357 (0.2415) nleep/row_max_mean 1555.6919 (1550.7932) nleep/row_max_std 57.8139 (58.9201) nleep/row_min_mean 1504.0593 (1505.3155) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [60/181] time 0.174 (0.171) data 0.001 (0.005) loss 1.6562 (1.5800) teacher_loss 0.1355 (0.1959) loss_zs_kd 0.0137 (0.0374) loss_oracle 0.7653 (0.6676) kd_loss 1.1311 (1.0316) acc 93.7500 (92.1354) gate/entropy 0.9879 (0.9878) gate/usage_max 0.5632 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0209 (0.0401) teacher/usage_max 0.6176 (0.5690) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.2545 (0.2424) nleep/row_max_mean 1547.4377 (1548.2647) nleep/row_max_std 64.3975 (59.6387) nleep/row_min_mean 1502.9735 (1503.4423) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [80/181] time 0.083 (0.161) data 0.000 (0.004) loss 1.5763 (1.5769) teacher_loss 0.2416 (0.1879) loss_zs_kd 0.0432 (0.0376) loss_oracle 0.6800 (0.6655) kd_loss 0.9731 (1.0374) acc 87.5000 (92.6172) gate/entropy 0.9875 (0.9878) gate/usage_max 0.5636 (0.5633) gate/usage_min 0.2159 (0.2161) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0330 (0.0385) teacher/usage_max 0.5386 (0.5660) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.2378 (0.2417) nleep/row_max_mean 1554.7686 (1547.8842) nleep/row_max_std 45.7614 (58.9838) nleep/row_min_mean 1513.1736 (1503.2445) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [100/181] time 0.184 (0.151) data 0.000 (0.003) loss 1.7491 (1.5743) teacher_loss 0.1966 (0.1892) loss_zs_kd 0.0455 (0.0380) loss_oracle 0.6668 (0.6632) kd_loss 1.1964 (1.0345) acc 93.7500 (92.4062) gate/entropy 0.9877 (0.9878) gate/usage_max 0.5634 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1627 (0.1626) teacher/entropy 0.0241 (0.0384) teacher/usage_max 0.6904 (0.5666) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.2824 (0.2421) nleep/row_max_mean 1548.6802 (1546.6721) nleep/row_max_std 45.7405 (59.0142) nleep/row_min_mean 1501.8835 (1502.0771) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [120/181] time 0.073 (0.145) data 0.000 (0.003) loss 1.6655 (1.5734) teacher_loss 0.1458 (0.1875) loss_zs_kd 0.0273 (0.0378) loss_oracle 0.7061 (0.6624) kd_loss 1.1530 (1.0358) acc 93.7500 (92.5521) gate/entropy 0.9878 (0.9878) gate/usage_max 0.5633 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0233 (0.0387) teacher/usage_max 0.6437 (0.5673) teacher/usage_min 0.0000 (0.0057) teacher/usage_std 0.2633 (0.2424) nleep/row_max_mean 1545.5803 (1545.7517) nleep/row_max_std 64.1190 (59.8661) nleep/row_min_mean 1501.5037 (1501.1304) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [140/181] time 0.086 (0.141) data 0.000 (0.002) loss 1.7656 (1.5764) teacher_loss 0.3230 (0.1904) loss_zs_kd 0.0433 (0.0376) loss_oracle 0.6563 (0.6600) kd_loss 1.0929 (1.0372) acc 81.2500 (92.5670) gate/entropy 0.9877 (0.9878) gate/usage_max 0.5634 (0.5633) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1627 (0.1626) teacher/entropy 0.0100 (0.0380) teacher/usage_max 0.5655 (0.5688) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2417 (0.2427) nleep/row_max_mean 1550.6981 (1545.5547) nleep/row_max_std 44.9299 (59.4231) nleep/row_min_mean 1505.1877 (1500.9565) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [160/181] time 0.085 (0.135) data 0.000 (0.002) loss 1.4693 (1.5768) teacher_loss 0.0943 (0.1928) loss_zs_kd 0.0222 (0.0374) loss_oracle 0.6875 (0.6571) kd_loss 1.0201 (1.0368) acc 96.8750 (92.4023) gate/entropy 0.9879 (0.9878) gate/usage_max 0.5631 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1625 (0.1626) teacher/entropy 0.0608 (0.0382) teacher/usage_max 0.5361 (0.5679) teacher/usage_min 0.0061 (0.0058) teacher/usage_std 0.2336 (0.2425) nleep/row_max_mean 1552.8151 (1545.0080) nleep/row_max_std 54.3083 (59.4906) nleep/row_min_mean 1504.0762 (1500.5900) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [180/181] time 0.120 (0.131) data 0.000 (0.002) loss 1.7103 (1.5746) teacher_loss 0.2596 (0.1947) loss_zs_kd 0.0565 (0.0372) loss_oracle 0.7209 (0.6553) kd_loss 1.0620 (1.0337) acc 87.5000 (92.2743) gate/entropy 0.9878 (0.9878) gate/usage_max 0.5633 (0.5633) gate/usage_min 0.2161 (0.2161) gate/usage_std 0.1626 (0.1626) teacher/entropy 0.0110 (0.0377) teacher/usage_max 0.5347 (0.5676) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2374 (0.2425) nleep/row_max_mean 1551.5879 (1544.8762) nleep/row_max_std 56.1879 (59.1913) nleep/row_min_mean 1501.5193 (1500.4563) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      96.9%, epoch: 42 *******
******* Domain p best val test acc: 99.8%, epoch: 42 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:25:15

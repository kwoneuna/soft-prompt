Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------
Dataset    SPG_PACS
Source     ['cartoon', 'photo', 'sketch']
Target     ['art_painting']
# classes  7
# train_x  5,557
# val      2,385
# test     2,048
---------  ------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/173] time 0.078 (0.115) data 0.000 (0.015) loss 0.8678 (1.1399) teacher_loss 0.3331 (0.4601) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0001 (-0.0000) kd_loss 0.5346 (0.6798) acc 90.6250 (83.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.5642 (0.4188) teacher/usage_max 0.3938 (0.4336) teacher/usage_min 0.3017 (0.2583) teacher/usage_std 0.0427 (0.0755) nleep/row_max_mean 1585.6744 (1594.1490) nleep/row_max_std 156.8691 (114.1180) nleep/row_min_mean 1581.6885 (1587.4194) lr 1.0000e-05 eta 0:16:35
epoch [1/50] batch [40/173] time 0.108 (0.108) data 0.000 (0.008) loss 1.1621 (1.0721) teacher_loss 0.5270 (0.4497) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0021 (0.0004) kd_loss 0.6340 (0.6222) acc 78.1250 (84.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.4651 (0.4764) teacher/usage_max 0.4051 (0.4247) teacher/usage_min 0.2574 (0.2594) teacher/usage_std 0.0604 (0.0709) nleep/row_max_mean 1586.2725 (1590.5280) nleep/row_max_std 111.2884 (114.9749) nleep/row_min_mean 1580.9990 (1584.7759) lr 1.0000e-05 eta 0:15:28
epoch [1/50] batch [60/173] time 0.157 (0.109) data 0.000 (0.005) loss 1.0166 (1.0341) teacher_loss 0.5017 (0.4498) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0043 (0.0012) kd_loss 0.5126 (0.5837) acc 81.2500 (83.8021) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3346) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.5868 (0.5149) teacher/usage_max 0.4073 (0.4253) teacher/usage_min 0.2486 (0.2596) teacher/usage_std 0.0652 (0.0709) nleep/row_max_mean 1596.6816 (1590.8447) nleep/row_max_std 84.0587 (112.1010) nleep/row_min_mean 1592.8999 (1585.7436) lr 1.0000e-05 eta 0:15:39
epoch [1/50] batch [80/173] time 0.077 (0.112) data 0.000 (0.004) loss 0.9074 (0.9982) teacher_loss 0.4746 (0.4515) loss_zs_kd 0.0015 (0.0001) loss_oracle 0.0133 (0.0024) kd_loss 0.4255 (0.5454) acc 84.3750 (83.2812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3317 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.6738 (0.5533) teacher/usage_max 0.4174 (0.4207) teacher/usage_min 0.2379 (0.2599) teacher/usage_std 0.0737 (0.0688) nleep/row_max_mean 1580.1638 (1590.2056) nleep/row_max_std 105.6360 (110.4425) nleep/row_min_mean 1576.7888 (1585.6187) lr 1.0000e-05 eta 0:15:59
epoch [1/50] batch [100/173] time 0.074 (0.112) data 0.000 (0.003) loss 0.9840 (0.9574) teacher_loss 0.5716 (0.4409) loss_zs_kd 0.0012 (0.0002) loss_oracle 0.0085 (0.0040) kd_loss 0.4075 (0.5144) acc 75.0000 (83.8438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.6915 (0.5844) teacher/usage_max 0.4817 (0.4216) teacher/usage_min 0.2154 (0.2576) teacher/usage_std 0.1108 (0.0703) nleep/row_max_mean 1619.8508 (1589.8606) nleep/row_max_std 71.7584 (107.4270) nleep/row_min_mean 1616.8213 (1585.6467) lr 1.0000e-05 eta 0:15:55
epoch [1/50] batch [120/173] time 0.179 (0.111) data 0.000 (0.003) loss 0.7145 (0.9334) teacher_loss 0.3884 (0.4456) loss_zs_kd 0.0010 (0.0004) loss_oracle 0.0299 (0.0061) kd_loss 0.3106 (0.4845) acc 84.3750 (83.7760) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3346) gate/usage_min 0.3317 (0.3318) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.7885 (0.6144) teacher/usage_max 0.4715 (0.4283) teacher/usage_min 0.1902 (0.2519) teacher/usage_std 0.1149 (0.0753) nleep/row_max_mean 1591.9651 (1588.8282) nleep/row_max_std 67.3862 (105.1232) nleep/row_min_mean 1589.7229 (1584.9012) lr 1.0000e-05 eta 0:15:43
epoch [1/50] batch [140/173] time 0.079 (0.110) data 0.000 (0.002) loss 0.6695 (0.9123) teacher_loss 0.3079 (0.4429) loss_zs_kd 0.0018 (0.0006) loss_oracle 0.0255 (0.0089) kd_loss 0.3480 (0.4647) acc 90.6250 (83.9509) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3318 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.7511 (0.6342) teacher/usage_max 0.5348 (0.4374) teacher/usage_min 0.1612 (0.2455) teacher/usage_std 0.1539 (0.0818) nleep/row_max_mean 1600.9058 (1588.9608) nleep/row_max_std 75.1564 (101.7026) nleep/row_min_mean 1598.5310 (1585.2333) lr 1.0000e-05 eta 0:15:39
epoch [1/50] batch [160/173] time 0.084 (0.112) data 0.000 (0.002) loss 0.6552 (0.8954) teacher_loss 0.2637 (0.4332) loss_zs_kd 0.0007 (0.0007) loss_oracle 0.0347 (0.0119) kd_loss 0.3738 (0.4559) acc 90.6250 (84.3555) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3346) gate/usage_min 0.3317 (0.3318) gate/usage_std 0.0012 (0.0012) teacher/entropy 0.7250 (0.6429) teacher/usage_max 0.5679 (0.4527) teacher/usage_min 0.1615 (0.2365) teacher/usage_std 0.1717 (0.0923) nleep/row_max_mean 1576.0896 (1589.0862) nleep/row_max_std 95.7539 (98.2217) nleep/row_min_mean 1573.4849 (1585.4620) lr 1.0000e-05 eta 0:15:47
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,266
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.0%, epoch: 1 *******
******* Domain a best val test acc: 97.6%, epoch: 1 *******
******* Domain a best test acc:     97.6%, epoch: 1 *******
epoch [2/50] batch [20/173] time 0.138 (0.162) data 0.000 (0.015) loss 1.3152 (1.0585) teacher_loss 0.4741 (0.4112) loss_zs_kd 0.0038 (0.0065) loss_oracle 0.2599 (0.2301) kd_loss 0.7093 (0.5290) acc 84.3750 (87.0312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3361 (0.3350) gate/usage_min 0.3309 (0.3313) gate/usage_std 0.0022 (0.0015) teacher/entropy 0.3842 (0.5677) teacher/usage_max 0.7515 (0.6421) teacher/usage_min 0.1132 (0.1464) teacher/usage_std 0.2958 (0.2204) nleep/row_max_mean 1575.1960 (1592.1255) nleep/row_max_std 85.6385 (75.7106) nleep/row_min_mean 1569.5920 (1588.0822) lr 2.0000e-03 eta 0:22:48
epoch [2/50] batch [40/173] time 0.163 (0.153) data 0.000 (0.007) loss 1.2553 (1.0707) teacher_loss 0.3994 (0.3726) loss_zs_kd 0.0062 (0.0059) loss_oracle 0.4240 (0.2602) kd_loss 0.6408 (0.5651) acc 90.6250 (87.9688) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3398 (0.3365) gate/usage_min 0.3296 (0.3308) gate/usage_std 0.0046 (0.0024) teacher/entropy 0.4481 (0.5291) teacher/usage_max 0.6709 (0.6632) teacher/usage_min 0.1485 (0.1353) teacher/usage_std 0.2391 (0.2355) nleep/row_max_mean 1567.1826 (1590.6559) nleep/row_max_std 96.3562 (77.1204) nleep/row_min_mean 1560.8088 (1586.0965) lr 2.0000e-03 eta 0:21:27
epoch [2/50] batch [60/173] time 0.151 (0.152) data 0.000 (0.005) loss 1.2425 (1.1037) teacher_loss 0.3765 (0.3585) loss_zs_kd 0.0203 (0.0074) loss_oracle 0.4494 (0.3186) kd_loss 0.6311 (0.5821) acc 90.6250 (88.0729) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3434 (0.3382) gate/usage_min 0.3283 (0.3302) gate/usage_std 0.0071 (0.0036) teacher/entropy 0.4528 (0.5100) teacher/usage_max 0.6583 (0.6479) teacher/usage_min 0.1373 (0.1446) teacher/usage_std 0.2314 (0.2249) nleep/row_max_mean 1616.3564 (1590.6148) nleep/row_max_std 52.2845 (75.4462) nleep/row_min_mean 1609.3615 (1585.4176) lr 2.0000e-03 eta 0:21:18
epoch [2/50] batch [80/173] time 0.144 (0.151) data 0.000 (0.004) loss 1.4220 (1.1441) teacher_loss 0.2598 (0.3431) loss_zs_kd 0.0138 (0.0080) loss_oracle 0.6811 (0.3633) kd_loss 0.8147 (0.6153) acc 87.5000 (88.3984) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3481 (0.3401) gate/usage_min 0.3255 (0.3294) gate/usage_std 0.0105 (0.0049) teacher/entropy 0.2549 (0.4733) teacher/usage_max 0.7801 (0.6625) teacher/usage_min 0.1035 (0.1404) teacher/usage_std 0.3160 (0.2348) nleep/row_max_mean 1607.0935 (1591.9610) nleep/row_max_std 72.5144 (74.4592) nleep/row_min_mean 1597.1056 (1586.0127) lr 2.0000e-03 eta 0:21:09
epoch [2/50] batch [100/173] time 0.166 (0.152) data 0.000 (0.003) loss 1.0865 (1.1857) teacher_loss 0.1602 (0.3395) loss_zs_kd 0.0081 (0.0087) loss_oracle 0.4548 (0.3927) kd_loss 0.6949 (0.6455) acc 100.0000 (88.4375) gate/entropy 1.0977 (1.0984) gate/usage_max 0.3538 (0.3423) gate/usage_min 0.3226 (0.3283) gate/usage_std 0.0145 (0.0064) teacher/entropy 0.3734 (0.4384) teacher/usage_max 0.6786 (0.6833) teacher/usage_min 0.0913 (0.1313) teacher/usage_std 0.2507 (0.2492) nleep/row_max_mean 1592.4331 (1591.9135) nleep/row_max_std 65.3864 (73.7092) nleep/row_min_mean 1584.8573 (1585.3077) lr 2.0000e-03 eta 0:21:09
epoch [2/50] batch [120/173] time 0.144 (0.151) data 0.000 (0.003) loss 1.3675 (1.2207) teacher_loss 0.1682 (0.3349) loss_zs_kd 0.0078 (0.0091) loss_oracle 0.7043 (0.4269) kd_loss 0.8433 (0.6678) acc 93.7500 (88.6458) gate/entropy 1.0971 (1.0982) gate/usage_max 0.3597 (0.3447) gate/usage_min 0.3194 (0.3271) gate/usage_std 0.0187 (0.0081) teacher/entropy 0.2044 (0.4116) teacher/usage_max 0.7789 (0.6934) teacher/usage_min 0.0533 (0.1264) teacher/usage_std 0.3185 (0.2563) nleep/row_max_mean 1578.3281 (1590.6787) nleep/row_max_std 66.0342 (72.0107) nleep/row_min_mean 1563.4305 (1583.5180) lr 2.0000e-03 eta 0:21:03
epoch [2/50] batch [140/173] time 0.080 (0.149) data 0.000 (0.002) loss 1.1383 (1.2419) teacher_loss 0.1006 (0.3241) loss_zs_kd 0.0116 (0.0099) loss_oracle 0.6513 (0.4633) kd_loss 0.7063 (0.6811) acc 96.8750 (88.9732) gate/entropy 1.0964 (1.0980) gate/usage_max 0.3648 (0.3473) gate/usage_min 0.3164 (0.3257) gate/usage_std 0.0223 (0.0099) teacher/entropy 0.3636 (0.3959) teacher/usage_max 0.5500 (0.6833) teacher/usage_min 0.2024 (0.1310) teacher/usage_std 0.1543 (0.2493) nleep/row_max_mean 1584.8970 (1589.9271) nleep/row_max_std 68.3232 (70.8911) nleep/row_min_mean 1575.3711 (1582.3690) lr 2.0000e-03 eta 0:20:41
epoch [2/50] batch [160/173] time 0.067 (0.143) data 0.000 (0.002) loss 1.4937 (1.2686) teacher_loss 0.2517 (0.3216) loss_zs_kd 0.0216 (0.0108) loss_oracle 0.7518 (0.4874) kd_loss 0.8553 (0.6979) acc 90.6250 (88.9648) gate/entropy 1.0958 (1.0977) gate/usage_max 0.3689 (0.3497) gate/usage_min 0.3135 (0.3244) gate/usage_std 0.0252 (0.0117) teacher/entropy 0.2276 (0.3787) teacher/usage_max 0.4791 (0.6627) teacher/usage_min 0.0876 (0.1344) teacher/usage_std 0.1748 (0.2372) nleep/row_max_mean 1571.8816 (1589.0582) nleep/row_max_std 79.5985 (70.5022) nleep/row_min_mean 1557.2280 (1580.9821) lr 2.0000e-03 eta 0:19:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,261
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,997
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.4%
******* Domain a best val acc:      95.0%, epoch: 1 *******
******* Domain a best val test acc: 97.6%, epoch: 1 *******
******* Domain a best test acc:     97.6%, epoch: 1 *******
epoch [3/50] batch [20/173] time 0.083 (0.120) data 0.000 (0.014) loss 1.4098 (1.4174) teacher_loss 0.1454 (0.2025) loss_zs_kd 0.0191 (0.0181) loss_oracle 0.6086 (0.5530) kd_loss 0.9506 (0.9294) acc 96.8750 (92.1875) gate/entropy 1.0951 (1.0953) gate/usage_max 0.3728 (0.3718) gate/usage_min 0.3076 (0.3094) gate/usage_std 0.0284 (0.0275) teacher/entropy 0.0995 (0.1459) teacher/usage_max 0.5942 (0.5548) teacher/usage_min 0.0273 (0.0393) teacher/usage_std 0.2336 (0.2204) nleep/row_max_mean 1589.4104 (1584.4434) nleep/row_max_std 58.8050 (63.2990) nleep/row_min_mean 1572.9843 (1568.5292) lr 1.9980e-03 eta 0:16:30
epoch [3/50] batch [40/173] time 0.081 (0.122) data 0.000 (0.007) loss 1.8315 (1.4812) teacher_loss 0.5008 (0.2271) loss_zs_kd 0.0278 (0.0224) loss_oracle 0.6067 (0.5909) kd_loss 1.0134 (0.9474) acc 84.3750 (92.3438) gate/entropy 1.0946 (1.0950) gate/usage_max 0.3747 (0.3728) gate/usage_min 0.3040 (0.3075) gate/usage_std 0.0301 (0.0284) teacher/entropy 0.0680 (0.1298) teacher/usage_max 0.5340 (0.5537) teacher/usage_min 0.0866 (0.0483) teacher/usage_std 0.1855 (0.2147) nleep/row_max_mean 1576.1699 (1583.1195) nleep/row_max_std 69.5626 (64.5685) nleep/row_min_mean 1559.0088 (1566.9728) lr 1.9980e-03 eta 0:16:44
epoch [3/50] batch [60/173] time 0.183 (0.122) data 0.000 (0.005) loss 1.5582 (1.4994) teacher_loss 0.2440 (0.2312) loss_zs_kd 0.0266 (0.0250) loss_oracle 0.5191 (0.5876) kd_loss 1.0413 (0.9620) acc 93.7500 (92.2396) gate/entropy 1.0942 (1.0948) gate/usage_max 0.3762 (0.3737) gate/usage_min 0.3006 (0.3058) gate/usage_std 0.0317 (0.0292) teacher/entropy 0.0456 (0.1186) teacher/usage_max 0.7110 (0.5785) teacher/usage_min 0.0072 (0.0505) teacher/usage_std 0.2896 (0.2233) nleep/row_max_mean 1603.5543 (1581.1728) nleep/row_max_std 57.5163 (63.5062) nleep/row_min_mean 1586.8621 (1564.7791) lr 1.9980e-03 eta 0:16:45
epoch [3/50] batch [80/173] time 0.085 (0.118) data 0.000 (0.004) loss 1.9957 (1.5316) teacher_loss 0.6743 (0.2449) loss_zs_kd 0.0273 (0.0258) loss_oracle 0.6503 (0.6093) kd_loss 0.9826 (0.9692) acc 84.3750 (91.8750) gate/entropy 1.0937 (1.0946) gate/usage_max 0.3772 (0.3745) gate/usage_min 0.2974 (0.3041) gate/usage_std 0.0331 (0.0300) teacher/entropy 0.1007 (0.1115) teacher/usage_max 0.7284 (0.5974) teacher/usage_min 0.0042 (0.0460) teacher/usage_std 0.2993 (0.2327) nleep/row_max_mean 1564.2322 (1579.7476) nleep/row_max_std 52.7833 (62.1647) nleep/row_min_mean 1548.2976 (1563.1539) lr 1.9980e-03 eta 0:16:13
epoch [3/50] batch [100/173] time 0.166 (0.124) data 0.000 (0.003) loss 1.4410 (1.5417) teacher_loss 0.0958 (0.2478) loss_zs_kd 0.0186 (0.0251) loss_oracle 0.6352 (0.6160) kd_loss 1.0182 (0.9734) acc 96.8750 (91.6875) gate/entropy 1.0932 (1.0944) gate/usage_max 0.3788 (0.3752) gate/usage_min 0.2938 (0.3023) gate/usage_std 0.0349 (0.0308) teacher/entropy 0.0503 (0.1061) teacher/usage_max 0.6310 (0.6141) teacher/usage_min 0.0243 (0.0396) teacher/usage_std 0.2478 (0.2417) nleep/row_max_mean 1571.0175 (1578.4475) nleep/row_max_std 50.1419 (60.7444) nleep/row_min_mean 1553.0681 (1561.6263) lr 1.9980e-03 eta 0:16:54
epoch [3/50] batch [120/173] time 0.152 (0.129) data 0.000 (0.003) loss 1.5177 (1.5419) teacher_loss 0.2135 (0.2451) loss_zs_kd 0.0210 (0.0249) loss_oracle 0.5770 (0.6119) kd_loss 1.0051 (0.9784) acc 93.7500 (91.6146) gate/entropy 1.0925 (1.0941) gate/usage_max 0.3801 (0.3759) gate/usage_min 0.2903 (0.3006) gate/usage_std 0.0368 (0.0317) teacher/entropy 0.0638 (0.0988) teacher/usage_max 0.7147 (0.6226) teacher/usage_min 0.0005 (0.0337) teacher/usage_std 0.2936 (0.2474) nleep/row_max_mean 1571.9089 (1577.3736) nleep/row_max_std 58.4859 (59.6454) nleep/row_min_mean 1550.1965 (1560.1198) lr 1.9980e-03 eta 0:17:39
epoch [3/50] batch [140/173] time 0.144 (0.133) data 0.000 (0.002) loss 1.5198 (1.5484) teacher_loss 0.1896 (0.2478) loss_zs_kd 0.0250 (0.0244) loss_oracle 0.6104 (0.6148) kd_loss 1.0125 (0.9810) acc 93.7500 (91.5848) gate/entropy 1.0919 (1.0938) gate/usage_max 0.3814 (0.3766) gate/usage_min 0.2868 (0.2989) gate/usage_std 0.0386 (0.0325) teacher/entropy 0.0540 (0.0941) teacher/usage_max 0.7366 (0.6317) teacher/usage_min 0.0008 (0.0293) teacher/usage_std 0.3045 (0.2526) nleep/row_max_mean 1567.7141 (1577.2086) nleep/row_max_std 45.7586 (58.3994) nleep/row_min_mean 1545.0111 (1559.2725) lr 1.9980e-03 eta 0:18:05
epoch [3/50] batch [160/173] time 0.146 (0.135) data 0.000 (0.002) loss 1.5393 (1.5578) teacher_loss 0.2075 (0.2549) loss_zs_kd 0.0529 (0.0252) loss_oracle 0.6249 (0.6138) kd_loss 0.9929 (0.9834) acc 96.8750 (91.3477) gate/entropy 1.0913 (1.0935) gate/usage_max 0.3819 (0.3773) gate/usage_min 0.2833 (0.2971) gate/usage_std 0.0403 (0.0334) teacher/entropy 0.0670 (0.0907) teacher/usage_max 0.7395 (0.6483) teacher/usage_min 0.0007 (0.0260) teacher/usage_std 0.3061 (0.2614) nleep/row_max_mean 1563.5669 (1576.5006) nleep/row_max_std 57.2685 (57.6542) nleep/row_min_mean 1538.9133 (1557.8939) lr 1.9980e-03 eta 0:18:16
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,292
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [4/50] batch [20/173] time 0.086 (0.157) data 0.000 (0.015) loss 1.4147 (1.5910) teacher_loss 0.1211 (0.2754) loss_zs_kd 0.0144 (0.0230) loss_oracle 0.6871 (0.6525) kd_loss 0.9429 (0.9779) acc 96.8750 (90.4688) gate/entropy 1.0902 (1.0905) gate/usage_max 0.3821 (0.3820) gate/usage_min 0.2774 (0.2791) gate/usage_std 0.0430 (0.0422) teacher/entropy 0.1096 (0.0797) teacher/usage_max 0.7863 (0.7939) teacher/usage_min 0.0001 (0.0018) teacher/usage_std 0.3319 (0.3384) nleep/row_max_mean 1585.6525 (1573.8049) nleep/row_max_std 44.8917 (51.6252) nleep/row_min_mean 1560.7999 (1548.5779) lr 1.9921e-03 eta 0:21:13
epoch [4/50] batch [40/173] time 0.153 (0.128) data 0.000 (0.007) loss 1.5286 (1.6147) teacher_loss 0.2358 (0.3007) loss_zs_kd 0.0166 (0.0233) loss_oracle 0.5266 (0.6464) kd_loss 1.0212 (0.9791) acc 90.6250 (89.2969) gate/entropy 1.0895 (1.0902) gate/usage_max 0.3818 (0.3820) gate/usage_min 0.2741 (0.2774) gate/usage_std 0.0446 (0.0430) teacher/entropy 0.0390 (0.0769) teacher/usage_max 0.9327 (0.8144) teacher/usage_min 0.0012 (0.0022) teacher/usage_std 0.4246 (0.3504) nleep/row_max_mean 1567.1106 (1574.8151) nleep/row_max_std 51.3259 (52.3303) nleep/row_min_mean 1541.9272 (1549.2895) lr 1.9921e-03 eta 0:17:14
epoch [4/50] batch [60/173] time 0.166 (0.124) data 0.000 (0.005) loss 1.5451 (1.5999) teacher_loss 0.2600 (0.2936) loss_zs_kd 0.0311 (0.0228) loss_oracle 0.5780 (0.6305) kd_loss 0.9806 (0.9797) acc 90.6250 (89.4792) gate/entropy 1.0887 (1.0898) gate/usage_max 0.3809 (0.3817) gate/usage_min 0.2706 (0.2758) gate/usage_std 0.0463 (0.0438) teacher/entropy 0.0679 (0.0751) teacher/usage_max 0.8945 (0.8389) teacher/usage_min 0.0109 (0.0038) teacher/usage_std 0.3983 (0.3652) nleep/row_max_mean 1580.0393 (1572.9627) nleep/row_max_std 58.5724 (53.0874) nleep/row_min_mean 1553.8258 (1547.4110) lr 1.9921e-03 eta 0:16:38
epoch [4/50] batch [80/173] time 0.070 (0.121) data 0.000 (0.004) loss 1.8006 (1.5987) teacher_loss 0.4405 (0.2945) loss_zs_kd 0.0223 (0.0218) loss_oracle 0.6786 (0.6252) kd_loss 1.0096 (0.9807) acc 81.2500 (89.3750) gate/entropy 1.0881 (1.0895) gate/usage_max 0.3790 (0.3812) gate/usage_min 0.2679 (0.2741) gate/usage_std 0.0475 (0.0446) teacher/entropy 0.0280 (0.0720) teacher/usage_max 0.9506 (0.8598) teacher/usage_min 0.0010 (0.0067) teacher/usage_std 0.4369 (0.3782) nleep/row_max_mean 1569.6836 (1571.8575) nleep/row_max_std 45.2212 (53.0915) nleep/row_min_mean 1540.3970 (1546.0544) lr 1.9921e-03 eta 0:16:10
epoch [4/50] batch [100/173] time 0.085 (0.119) data 0.000 (0.003) loss 1.5431 (1.6013) teacher_loss 0.2789 (0.2992) loss_zs_kd 0.0120 (0.0215) loss_oracle 0.5868 (0.6242) kd_loss 0.9648 (0.9792) acc 84.3750 (88.8125) gate/entropy 1.0873 (1.0891) gate/usage_max 0.3771 (0.3806) gate/usage_min 0.2646 (0.2725) gate/usage_std 0.0492 (0.0453) teacher/entropy 0.0759 (0.0696) teacher/usage_max 0.9445 (0.8720) teacher/usage_min 0.0076 (0.0079) teacher/usage_std 0.4325 (0.3858) nleep/row_max_mean 1563.3578 (1573.1256) nleep/row_max_std 53.5551 (51.9168) nleep/row_min_mean 1536.1768 (1547.0603) lr 1.9921e-03 eta 0:15:57
epoch [4/50] batch [120/173] time 0.187 (0.118) data 0.000 (0.003) loss 1.7104 (1.5983) teacher_loss 0.4612 (0.3000) loss_zs_kd 0.0158 (0.0205) loss_oracle 0.5155 (0.6223) kd_loss 0.9835 (0.9770) acc 84.3750 (88.8021) gate/entropy 1.0864 (1.0887) gate/usage_max 0.3750 (0.3799) gate/usage_min 0.2614 (0.2709) gate/usage_std 0.0511 (0.0462) teacher/entropy 0.0291 (0.0674) teacher/usage_max 0.9915 (0.8832) teacher/usage_min 0.0037 (0.0085) teacher/usage_std 0.4654 (0.3930) nleep/row_max_mean 1569.6021 (1573.6477) nleep/row_max_std 57.8013 (51.7039) nleep/row_min_mean 1542.6188 (1547.5567) lr 1.9921e-03 eta 0:15:43
epoch [4/50] batch [140/173] time 0.077 (0.118) data 0.000 (0.002) loss 1.5020 (1.5983) teacher_loss 0.2115 (0.3070) loss_zs_kd 0.0070 (0.0198) loss_oracle 0.6533 (0.6202) kd_loss 0.9604 (0.9713) acc 93.7500 (88.7723) gate/entropy 1.0854 (1.0883) gate/usage_max 0.3725 (0.3790) gate/usage_min 0.2584 (0.2693) gate/usage_std 0.0530 (0.0470) teacher/entropy 0.0382 (0.0681) teacher/usage_max 0.9879 (0.8906) teacher/usage_min 0.0051 (0.0095) teacher/usage_std 0.4628 (0.3977) nleep/row_max_mean 1560.4401 (1573.4516) nleep/row_max_std 62.5918 (51.7478) nleep/row_min_mean 1534.2109 (1547.4811) lr 1.9921e-03 eta 0:15:45
epoch [4/50] batch [160/173] time 0.076 (0.118) data 0.000 (0.002) loss 1.5330 (1.5937) teacher_loss 0.2274 (0.3073) loss_zs_kd 0.0183 (0.0188) loss_oracle 0.6857 (0.6181) kd_loss 0.9536 (0.9680) acc 90.6250 (88.7109) gate/entropy 1.0842 (1.0879) gate/usage_max 0.3748 (0.3782) gate/usage_min 0.2550 (0.2677) gate/usage_std 0.0554 (0.0479) teacher/entropy 0.0386 (0.0655) teacher/usage_max 0.9641 (0.8982) teacher/usage_min 0.0087 (0.0092) teacher/usage_std 0.4461 (0.4026) nleep/row_max_mean 1568.1860 (1573.7121) nleep/row_max_std 54.5388 (51.6347) nleep/row_min_mean 1539.5044 (1547.5005) lr 1.9921e-03 eta 0:15:39
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [5/50] batch [20/173] time 0.151 (0.154) data 0.000 (0.013) loss 1.5594 (1.6076) teacher_loss 0.3044 (0.3491) loss_zs_kd 0.0049 (0.0136) loss_oracle 0.6188 (0.6550) kd_loss 0.9431 (0.9243) acc 87.5000 (85.1562) gate/entropy 1.0820 (1.0826) gate/usage_max 0.3834 (0.3810) gate/usage_min 0.2500 (0.2514) gate/usage_std 0.0593 (0.0582) teacher/entropy 0.0157 (0.0454) teacher/usage_max 0.9955 (0.9405) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.4683 (0.4300) nleep/row_max_mean 1583.6587 (1572.2510) nleep/row_max_std 52.4840 (53.1851) nleep/row_min_mean 1550.0481 (1544.7948) lr 1.9823e-03 eta 0:20:24
epoch [5/50] batch [40/173] time 0.123 (0.144) data 0.000 (0.007) loss 1.6628 (1.5936) teacher_loss 0.3949 (0.3415) loss_zs_kd 0.0242 (0.0130) loss_oracle 0.6283 (0.6504) kd_loss 0.9417 (0.9204) acc 84.3750 (86.3281) gate/entropy 1.0805 (1.0819) gate/usage_max 0.3886 (0.3835) gate/usage_min 0.2468 (0.2499) gate/usage_std 0.0619 (0.0594) teacher/entropy 0.0077 (0.0422) teacher/usage_max 0.9360 (0.9512) teacher/usage_min 0.0002 (0.0051) teacher/usage_std 0.4269 (0.4374) nleep/row_max_mean 1577.5759 (1574.1489) nleep/row_max_std 60.5368 (52.8360) nleep/row_min_mean 1549.7217 (1545.8444) lr 1.9823e-03 eta 0:18:58
epoch [5/50] batch [60/173] time 0.124 (0.145) data 0.001 (0.005) loss 1.6737 (1.5888) teacher_loss 0.4462 (0.3513) loss_zs_kd 0.0194 (0.0134) loss_oracle 0.6378 (0.6300) kd_loss 0.8989 (0.9158) acc 84.3750 (86.0417) gate/entropy 1.0791 (1.0812) gate/usage_max 0.3937 (0.3861) gate/usage_min 0.2442 (0.2484) gate/usage_std 0.0643 (0.0607) teacher/entropy 0.0397 (0.0404) teacher/usage_max 0.9214 (0.9559) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4171 (0.4407) nleep/row_max_mean 1577.5925 (1573.3518) nleep/row_max_std 55.4342 (52.9694) nleep/row_min_mean 1547.0132 (1544.7712) lr 1.9823e-03 eta 0:19:02
epoch [5/50] batch [80/173] time 0.144 (0.144) data 0.000 (0.003) loss 1.5577 (1.5639) teacher_loss 0.3342 (0.3428) loss_zs_kd 0.0120 (0.0132) loss_oracle 0.6363 (0.6173) kd_loss 0.8993 (0.9058) acc 84.3750 (86.5234) gate/entropy 1.0774 (1.0805) gate/usage_max 0.3991 (0.3887) gate/usage_min 0.2413 (0.2470) gate/usage_std 0.0671 (0.0619) teacher/entropy 0.0230 (0.0450) teacher/usage_max 0.9643 (0.9485) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4464 (0.4356) nleep/row_max_mean 1574.4839 (1572.4183) nleep/row_max_std 54.1220 (53.4075) nleep/row_min_mean 1547.5779 (1544.2605) lr 1.9823e-03 eta 0:18:51
epoch [5/50] batch [100/173] time 0.118 (0.142) data 0.000 (0.003) loss 1.5093 (1.5471) teacher_loss 0.2945 (0.3358) loss_zs_kd 0.0048 (0.0128) loss_oracle 0.6784 (0.6243) kd_loss 0.8732 (0.8928) acc 90.6250 (87.0000) gate/entropy 1.0758 (1.0797) gate/usage_max 0.4032 (0.3912) gate/usage_min 0.2385 (0.2456) gate/usage_std 0.0695 (0.0632) teacher/entropy 0.0470 (0.0540) teacher/usage_max 0.8994 (0.9304) teacher/usage_min 0.0006 (0.0045) teacher/usage_std 0.4023 (0.4238) nleep/row_max_mean 1566.0277 (1570.1778) nleep/row_max_std 58.6499 (53.6394) nleep/row_min_mean 1542.4720 (1542.8299) lr 1.9823e-03 eta 0:18:33
epoch [5/50] batch [120/173] time 0.138 (0.141) data 0.000 (0.002) loss 1.3211 (1.5307) teacher_loss 0.1377 (0.3288) loss_zs_kd 0.0070 (0.0136) loss_oracle 0.6758 (0.6271) kd_loss 0.8420 (0.8815) acc 96.8750 (87.3958) gate/entropy 1.0745 (1.0790) gate/usage_max 0.4061 (0.3934) gate/usage_min 0.2361 (0.2442) gate/usage_std 0.0715 (0.0644) teacher/entropy 0.1070 (0.0625) teacher/usage_max 0.7196 (0.9127) teacher/usage_min 0.0315 (0.0055) teacher/usage_std 0.2872 (0.4122) nleep/row_max_mean 1568.0483 (1569.8474) nleep/row_max_std 53.9646 (52.7046) nleep/row_min_mean 1545.1145 (1543.2277) lr 1.9823e-03 eta 0:18:27
epoch [5/50] batch [140/173] time 0.154 (0.142) data 0.000 (0.002) loss 1.3518 (1.5229) teacher_loss 0.1574 (0.3250) loss_zs_kd 0.0110 (0.0135) loss_oracle 0.7779 (0.6373) kd_loss 0.7999 (0.8725) acc 93.7500 (87.7232) gate/entropy 1.0732 (1.0782) gate/usage_max 0.4079 (0.3954) gate/usage_min 0.2335 (0.2429) gate/usage_std 0.0734 (0.0656) teacher/entropy 0.1420 (0.0724) teacher/usage_max 0.6770 (0.8795) teacher/usage_min 0.0090 (0.0081) teacher/usage_std 0.2731 (0.3923) nleep/row_max_mean 1565.5375 (1568.6500) nleep/row_max_std 59.0815 (52.3028) nleep/row_min_mean 1545.0334 (1542.9239) lr 1.9823e-03 eta 0:18:28
epoch [5/50] batch [160/173] time 0.086 (0.135) data 0.000 (0.002) loss 1.3210 (1.5124) teacher_loss 0.1221 (0.3177) loss_zs_kd 0.0058 (0.0137) loss_oracle 0.6540 (0.6449) kd_loss 0.8689 (0.8654) acc 93.7500 (88.0078) gate/entropy 1.0723 (1.0775) gate/usage_max 0.4085 (0.3970) gate/usage_min 0.2317 (0.2416) gate/usage_std 0.0746 (0.0666) teacher/entropy 0.0868 (0.0799) teacher/usage_max 0.6182 (0.8548) teacher/usage_min 0.0271 (0.0104) teacher/usage_std 0.2418 (0.3776) nleep/row_max_mean 1555.1399 (1567.8797) nleep/row_max_std 53.1302 (52.1360) nleep/row_min_mean 1536.3005 (1542.8811) lr 1.9823e-03 eta 0:17:33
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [6/50] batch [20/173] time 0.081 (0.109) data 0.000 (0.015) loss 1.3907 (1.4552) teacher_loss 0.2166 (0.2864) loss_zs_kd 0.0165 (0.0228) loss_oracle 0.7379 (0.6446) kd_loss 0.7970 (0.8350) acc 93.7500 (89.5312) gate/entropy 1.0704 (1.0708) gate/usage_max 0.4114 (0.4106) gate/usage_min 0.2282 (0.2289) gate/usage_std 0.0772 (0.0766) teacher/entropy 0.1810 (0.1187) teacher/usage_max 0.5626 (0.7133) teacher/usage_min 0.0712 (0.0581) teacher/usage_std 0.2020 (0.2819) nleep/row_max_mean 1552.8274 (1559.6791) nleep/row_max_std 47.7735 (48.3560) nleep/row_min_mean 1535.2582 (1539.2899) lr 1.9686e-03 eta 0:14:05
epoch [6/50] batch [40/173] time 0.083 (0.105) data 0.000 (0.008) loss 1.5044 (1.4466) teacher_loss 0.3959 (0.2740) loss_zs_kd 0.0193 (0.0227) loss_oracle 0.6859 (0.6582) kd_loss 0.7559 (0.8322) acc 84.3750 (90.3906) gate/entropy 1.0693 (1.0703) gate/usage_max 0.4133 (0.4115) gate/usage_min 0.2264 (0.2281) gate/usage_std 0.0786 (0.0773) teacher/entropy 0.1630 (0.1244) teacher/usage_max 0.8092 (0.7033) teacher/usage_min 0.0205 (0.0641) teacher/usage_std 0.3420 (0.2742) nleep/row_max_mean 1549.4596 (1554.9786) nleep/row_max_std 56.5794 (50.1703) nleep/row_min_mean 1528.4519 (1534.7407) lr 1.9686e-03 eta 0:13:33
epoch [6/50] batch [60/173] time 0.090 (0.105) data 0.001 (0.005) loss 1.5760 (1.4523) teacher_loss 0.4048 (0.2804) loss_zs_kd 0.0246 (0.0232) loss_oracle 0.7242 (0.6589) kd_loss 0.7968 (0.8308) acc 81.2500 (90.1042) gate/entropy 1.0682 (1.0698) gate/usage_max 0.4157 (0.4125) gate/usage_min 0.2248 (0.2272) gate/usage_std 0.0801 (0.0780) teacher/entropy 0.1310 (0.1191) teacher/usage_max 0.8441 (0.7310) teacher/usage_min 0.0577 (0.0607) teacher/usage_std 0.3615 (0.2909) nleep/row_max_mean 1548.1099 (1554.7234) nleep/row_max_std 41.6297 (49.9476) nleep/row_min_mean 1525.0032 (1533.5438) lr 1.9686e-03 eta 0:13:30
epoch [6/50] batch [80/173] time 0.161 (0.109) data 0.000 (0.004) loss 1.3116 (1.4541) teacher_loss 0.2037 (0.2795) loss_zs_kd 0.0303 (0.0232) loss_oracle 0.5899 (0.6568) kd_loss 0.7978 (0.8345) acc 93.7500 (89.8047) gate/entropy 1.0666 (1.0692) gate/usage_max 0.4191 (0.4137) gate/usage_min 0.2225 (0.2263) gate/usage_std 0.0822 (0.0788) teacher/entropy 0.0988 (0.1098) teacher/usage_max 0.9134 (0.7505) teacher/usage_min 0.0284 (0.0578) teacher/usage_std 0.4103 (0.3030) nleep/row_max_mean 1564.2495 (1555.2227) nleep/row_max_std 53.7437 (50.3473) nleep/row_min_mean 1540.3263 (1533.4828) lr 1.9686e-03 eta 0:14:02
epoch [6/50] batch [100/173] time 0.086 (0.109) data 0.000 (0.003) loss 1.3529 (1.4531) teacher_loss 0.2117 (0.2798) loss_zs_kd 0.0340 (0.0232) loss_oracle 0.5051 (0.6511) kd_loss 0.8717 (0.8362) acc 93.7500 (89.8438) gate/entropy 1.0656 (1.0686) gate/usage_max 0.4217 (0.4150) gate/usage_min 0.2213 (0.2255) gate/usage_std 0.0835 (0.0796) teacher/entropy 0.0767 (0.1060) teacher/usage_max 0.8206 (0.7573) teacher/usage_min 0.0624 (0.0580) teacher/usage_std 0.3453 (0.3071) nleep/row_max_mean 1560.4766 (1554.9403) nleep/row_max_std 37.3971 (51.0226) nleep/row_min_mean 1536.1472 (1532.8361) lr 1.9686e-03 eta 0:13:59
epoch [6/50] batch [120/173] time 0.154 (0.114) data 0.000 (0.003) loss 1.5642 (1.4482) teacher_loss 0.3624 (0.2764) loss_zs_kd 0.0310 (0.0227) loss_oracle 0.6176 (0.6442) kd_loss 0.8774 (0.8384) acc 87.5000 (90.0000) gate/entropy 1.0646 (1.0680) gate/usage_max 0.4245 (0.4164) gate/usage_min 0.2201 (0.2247) gate/usage_std 0.0849 (0.0804) teacher/entropy 0.1120 (0.1060) teacher/usage_max 0.6773 (0.7588) teacher/usage_min 0.1564 (0.0634) teacher/usage_std 0.2432 (0.3071) nleep/row_max_mean 1551.3191 (1554.3365) nleep/row_max_std 50.6544 (52.0185) nleep/row_min_mean 1529.2783 (1532.0730) lr 1.9686e-03 eta 0:14:36
epoch [6/50] batch [140/173] time 0.131 (0.119) data 0.000 (0.002) loss 1.4258 (1.4519) teacher_loss 0.2193 (0.2740) loss_zs_kd 0.0140 (0.0229) loss_oracle 0.7491 (0.6453) kd_loss 0.8249 (0.8437) acc 90.6250 (89.9554) gate/entropy 1.0635 (1.0674) gate/usage_max 0.4268 (0.4177) gate/usage_min 0.2189 (0.2239) gate/usage_std 0.0862 (0.0811) teacher/entropy 0.1828 (0.1079) teacher/usage_max 0.6426 (0.7490) teacher/usage_min 0.1705 (0.0700) teacher/usage_std 0.2188 (0.2999) nleep/row_max_mean 1560.5129 (1553.8056) nleep/row_max_std 64.5837 (52.8970) nleep/row_min_mean 1539.8783 (1531.5078) lr 1.9686e-03 eta 0:15:08
epoch [6/50] batch [160/173] time 0.137 (0.123) data 0.000 (0.002) loss 1.6982 (1.4669) teacher_loss 0.2549 (0.2705) loss_zs_kd 0.0330 (0.0234) loss_oracle 0.7387 (0.6509) kd_loss 1.0574 (0.8593) acc 90.6250 (90.1562) gate/entropy 1.0634 (1.0669) gate/usage_max 0.4280 (0.4189) gate/usage_min 0.2190 (0.2233) gate/usage_std 0.0865 (0.0817) teacher/entropy 0.1094 (0.1105) teacher/usage_max 0.4582 (0.7300) teacher/usage_min 0.0930 (0.0706) teacher/usage_std 0.1700 (0.2900) nleep/row_max_mean 1556.6178 (1553.0752) nleep/row_max_std 46.4453 (53.1856) nleep/row_min_mean 1534.4929 (1530.8119) lr 1.9686e-03 eta 0:15:38
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [7/50] batch [20/173] time 0.162 (0.164) data 0.000 (0.015) loss 1.9528 (1.8154) teacher_loss 0.4252 (0.3041) loss_zs_kd 0.0212 (0.0282) loss_oracle 0.7075 (0.6688) kd_loss 1.1632 (1.1629) acc 84.3750 (87.8125) gate/entropy 1.0646 (1.0640) gate/usage_max 0.4275 (0.4279) gate/usage_min 0.2214 (0.2204) gate/usage_std 0.0851 (0.0857) teacher/entropy 0.1030 (0.0915) teacher/usage_max 0.6356 (0.6127) teacher/usage_min 0.0000 (0.0114) teacher/usage_std 0.2604 (0.2541) nleep/row_max_mean 1557.9592 (1555.7678) nleep/row_max_std 46.7444 (49.6777) nleep/row_min_mean 1528.6783 (1528.9263) lr 1.9511e-03 eta 0:20:43
epoch [7/50] batch [40/173] time 0.167 (0.160) data 0.000 (0.007) loss 2.0872 (1.8353) teacher_loss 0.5053 (0.2755) loss_zs_kd 0.0289 (0.0251) loss_oracle 0.7498 (0.6932) kd_loss 1.1925 (1.2006) acc 87.5000 (89.6875) gate/entropy 1.0658 (1.0647) gate/usage_max 0.4265 (0.4274) gate/usage_min 0.2237 (0.2215) gate/usage_std 0.0836 (0.0850) teacher/entropy 0.0990 (0.0774) teacher/usage_max 0.6828 (0.6532) teacher/usage_min 0.0003 (0.0066) teacher/usage_std 0.2789 (0.2721) nleep/row_max_mean 1561.7747 (1555.5092) nleep/row_max_std 46.5401 (50.8544) nleep/row_min_mean 1535.5314 (1528.0595) lr 1.9511e-03 eta 0:20:11
epoch [7/50] batch [60/173] time 0.088 (0.139) data 0.001 (0.005) loss 2.0168 (1.8802) teacher_loss 0.2576 (0.2746) loss_zs_kd 0.0188 (0.0235) loss_oracle 0.8507 (0.7181) kd_loss 1.3244 (1.2349) acc 90.6250 (90.0000) gate/entropy 1.0679 (1.0654) gate/usage_max 0.4237 (0.4266) gate/usage_min 0.2271 (0.2229) gate/usage_std 0.0810 (0.0841) teacher/entropy 0.0879 (0.0721) teacher/usage_max 0.8892 (0.7040) teacher/usage_min 0.0001 (0.0051) teacher/usage_std 0.3956 (0.2964) nleep/row_max_mean 1556.9207 (1556.1412) nleep/row_max_std 50.9409 (51.0697) nleep/row_min_mean 1527.3916 (1527.9779) lr 1.9511e-03 eta 0:17:29
epoch [7/50] batch [80/173] time 0.163 (0.133) data 0.000 (0.004) loss 2.0599 (1.9287) teacher_loss 0.3080 (0.2840) loss_zs_kd 0.0261 (0.0234) loss_oracle 0.7430 (0.7352) kd_loss 1.3673 (1.2653) acc 90.6250 (89.5703) gate/entropy 1.0704 (1.0663) gate/usage_max 0.4197 (0.4254) gate/usage_min 0.2312 (0.2244) gate/usage_std 0.0778 (0.0829) teacher/entropy 0.0391 (0.0674) teacher/usage_max 0.9038 (0.7516) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4053 (0.3221) nleep/row_max_mean 1563.4830 (1558.3384) nleep/row_max_std 49.4546 (50.8758) nleep/row_min_mean 1531.5996 (1529.5179) lr 1.9511e-03 eta 0:16:40
epoch [7/50] batch [100/173] time 0.071 (0.129) data 0.000 (0.003) loss 2.0296 (1.9538) teacher_loss 0.2406 (0.2838) loss_zs_kd 0.0095 (0.0223) loss_oracle 0.8089 (0.7375) kd_loss 1.3798 (1.2901) acc 90.6250 (89.4375) gate/entropy 1.0730 (1.0674) gate/usage_max 0.4152 (0.4238) gate/usage_min 0.2358 (0.2262) gate/usage_std 0.0740 (0.0815) teacher/entropy 0.0299 (0.0608) teacher/usage_max 0.9246 (0.7905) teacher/usage_min 0.0313 (0.0050) teacher/usage_std 0.4182 (0.3445) nleep/row_max_mean 1559.4688 (1559.9424) nleep/row_max_std 56.2628 (51.3779) nleep/row_min_mean 1525.7678 (1530.0132) lr 1.9511e-03 eta 0:16:12
epoch [7/50] batch [120/173] time 0.071 (0.126) data 0.000 (0.003) loss 2.0398 (1.9657) teacher_loss 0.2596 (0.2795) loss_zs_kd 0.0280 (0.0227) loss_oracle 0.8448 (0.7484) kd_loss 1.3438 (1.3007) acc 93.7500 (89.7396) gate/entropy 1.0760 (1.0686) gate/usage_max 0.4098 (0.4219) gate/usage_min 0.2413 (0.2283) gate/usage_std 0.0697 (0.0799) teacher/entropy 0.0298 (0.0573) teacher/usage_max 0.8842 (0.8128) teacher/usage_min 0.0326 (0.0055) teacher/usage_std 0.3901 (0.3569) nleep/row_max_mean 1548.4475 (1560.4372) nleep/row_max_std 48.2079 (51.6315) nleep/row_min_mean 1515.1541 (1530.1794) lr 1.9511e-03 eta 0:15:46
epoch [7/50] batch [140/173] time 0.088 (0.122) data 0.000 (0.002) loss 2.1657 (1.9824) teacher_loss 0.4160 (0.2859) loss_zs_kd 0.0181 (0.0223) loss_oracle 0.6784 (0.7482) kd_loss 1.4015 (1.3113) acc 90.6250 (89.7098) gate/entropy 1.0784 (1.0698) gate/usage_max 0.4051 (0.4199) gate/usage_min 0.2459 (0.2304) gate/usage_std 0.0659 (0.0782) teacher/entropy 0.0011 (0.0521) teacher/usage_max 0.9998 (0.8344) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4713 (0.3697) nleep/row_max_mean 1571.2341 (1561.5361) nleep/row_max_std 43.7441 (51.0536) nleep/row_min_mean 1536.2534 (1530.7027) lr 1.9511e-03 eta 0:15:11
epoch [7/50] batch [160/173] time 0.122 (0.122) data 0.000 (0.002) loss 2.0051 (1.9999) teacher_loss 0.2835 (0.2952) loss_zs_kd 0.0143 (0.0213) loss_oracle 0.7364 (0.7484) kd_loss 1.3462 (1.3198) acc 93.7500 (89.4531) gate/entropy 1.0813 (1.0711) gate/usage_max 0.3994 (0.4177) gate/usage_min 0.2519 (0.2328) gate/usage_std 0.0612 (0.0764) teacher/entropy 0.0158 (0.0464) teacher/usage_max 0.9626 (0.8541) teacher/usage_min 0.0062 (0.0047) teacher/usage_std 0.4451 (0.3817) nleep/row_max_mean 1572.3610 (1562.6154) nleep/row_max_std 44.0622 (50.8136) nleep/row_min_mean 1532.5533 (1530.8406) lr 1.9511e-03 eta 0:15:06
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [8/50] batch [20/173] time 0.156 (0.146) data 0.000 (0.014) loss 1.9408 (2.0752) teacher_loss 0.2120 (0.3476) loss_zs_kd 0.0058 (0.0141) loss_oracle 0.7718 (0.7444) kd_loss 1.3401 (1.3484) acc 93.7500 (87.9688) gate/entropy 1.0854 (1.0843) gate/usage_max 0.3900 (0.3927) gate/usage_min 0.2618 (0.2590) gate/usage_std 0.0534 (0.0556) teacher/entropy 0.0000 (0.0017) teacher/usage_max 1.0000 (0.9978) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4698) nleep/row_max_mean 1585.1030 (1577.7377) nleep/row_max_std 58.0187 (50.9550) nleep/row_min_mean 1536.0409 (1532.0485) lr 1.9298e-03 eta 0:18:06
epoch [8/50] batch [40/173] time 0.163 (0.146) data 0.000 (0.007) loss 2.0752 (2.0747) teacher_loss 0.3444 (0.3476) loss_zs_kd 0.0005 (0.0118) loss_oracle 0.8296 (0.7673) kd_loss 1.3158 (1.3375) acc 84.3750 (87.2656) gate/entropy 1.0878 (1.0855) gate/usage_max 0.3842 (0.3898) gate/usage_min 0.2683 (0.2621) gate/usage_std 0.0484 (0.0532) teacher/entropy 0.0000 (0.0010) teacher/usage_max 1.0000 (0.9988) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4706) nleep/row_max_mean 1582.8813 (1578.8574) nleep/row_max_std 62.9379 (52.0194) nleep/row_min_mean 1531.0367 (1531.5226) lr 1.9298e-03 eta 0:17:57
epoch [8/50] batch [60/173] time 0.149 (0.149) data 0.000 (0.005) loss 2.0284 (2.0715) teacher_loss 0.3696 (0.3539) loss_zs_kd 0.0077 (0.0108) loss_oracle 0.7284 (0.7728) kd_loss 1.2908 (1.3258) acc 84.3750 (86.8750) gate/entropy 1.0900 (1.0867) gate/usage_max 0.3784 (0.3869) gate/usage_min 0.2751 (0.2654) gate/usage_std 0.0432 (0.0507) teacher/entropy 0.0000 (0.0008) teacher/usage_max 1.0000 (0.9992) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4708) nleep/row_max_mean 1571.4374 (1578.7149) nleep/row_max_std 55.4594 (53.8364) nleep/row_min_mean 1520.1709 (1529.9558) lr 1.9298e-03 eta 0:18:22
epoch [8/50] batch [80/173] time 0.165 (0.151) data 0.000 (0.004) loss 2.1359 (2.0517) teacher_loss 0.4305 (0.3439) loss_zs_kd 0.0149 (0.0103) loss_oracle 0.8617 (0.7772) kd_loss 1.2671 (1.3140) acc 84.3750 (87.0312) gate/entropy 1.0919 (1.0877) gate/usage_max 0.3727 (0.3841) gate/usage_min 0.2816 (0.2686) gate/usage_std 0.0382 (0.0482) teacher/entropy 0.0000 (0.0006) teacher/usage_max 1.0000 (0.9994) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4710) nleep/row_max_mean 1573.9304 (1577.7121) nleep/row_max_std 60.7042 (54.8531) nleep/row_min_mean 1518.1589 (1528.1429) lr 1.9298e-03 eta 0:18:31
epoch [8/50] batch [100/173] time 0.155 (0.153) data 0.000 (0.003) loss 1.9559 (2.0390) teacher_loss 0.2854 (0.3432) loss_zs_kd 0.0172 (0.0103) loss_oracle 0.8363 (0.7768) kd_loss 1.2438 (1.3022) acc 87.5000 (87.2500) gate/entropy 1.0936 (1.0888) gate/usage_max 0.3672 (0.3812) gate/usage_min 0.2883 (0.2719) gate/usage_std 0.0332 (0.0457) teacher/entropy 0.0000 (0.0005) teacher/usage_max 1.0000 (0.9995) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4711) nleep/row_max_mean 1575.9698 (1577.2942) nleep/row_max_std 60.3212 (55.0691) nleep/row_min_mean 1522.4099 (1527.0482) lr 1.9298e-03 eta 0:18:39
epoch [8/50] batch [120/173] time 0.151 (0.152) data 0.000 (0.002) loss 2.1066 (2.0229) teacher_loss 0.4767 (0.3401) loss_zs_kd 0.0075 (0.0097) loss_oracle 0.8093 (0.7753) kd_loss 1.2216 (1.2903) acc 75.0000 (87.1615) gate/entropy 1.0950 (1.0897) gate/usage_max 0.3617 (0.3784) gate/usage_min 0.2948 (0.2752) gate/usage_std 0.0283 (0.0431) teacher/entropy 0.0000 (0.0006) teacher/usage_max 1.0000 (0.9992) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4708) nleep/row_max_mean 1570.4674 (1577.3124) nleep/row_max_std 58.7380 (55.3066) nleep/row_min_mean 1519.8768 (1526.4624) lr 1.9298e-03 eta 0:18:32
epoch [8/50] batch [140/173] time 0.154 (0.151) data 0.000 (0.002) loss 1.7967 (2.0112) teacher_loss 0.2380 (0.3423) loss_zs_kd 0.0038 (0.0092) loss_oracle 0.7127 (0.7710) kd_loss 1.2004 (1.2788) acc 90.6250 (86.9420) gate/entropy 1.0961 (1.0905) gate/usage_max 0.3564 (0.3756) gate/usage_min 0.3011 (0.2785) gate/usage_std 0.0235 (0.0407) teacher/entropy 0.0000 (0.0006) teacher/usage_max 1.0000 (0.9991) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4708) nleep/row_max_mean 1589.1812 (1575.8566) nleep/row_max_std 50.0974 (55.9334) nleep/row_min_mean 1534.8424 (1524.7517) lr 1.9298e-03 eta 0:18:21
epoch [8/50] batch [160/173] time 0.072 (0.149) data 0.000 (0.002) loss 1.9597 (1.9991) teacher_loss 0.3944 (0.3415) loss_zs_kd 0.0132 (0.0092) loss_oracle 0.7597 (0.7709) kd_loss 1.1789 (1.2676) acc 84.3750 (87.0703) gate/entropy 1.0970 (1.0913) gate/usage_max 0.3511 (0.3729) gate/usage_min 0.3076 (0.2817) gate/usage_std 0.0186 (0.0382) teacher/entropy 0.0000 (0.0005) teacher/usage_max 1.0000 (0.9992) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4708) nleep/row_max_mean 1579.8322 (1576.3452) nleep/row_max_std 63.2268 (55.7728) nleep/row_min_mean 1521.1898 (1524.5467) lr 1.9298e-03 eta 0:18:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,282
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [9/50] batch [20/173] time 0.093 (0.134) data 0.000 (0.015) loss 2.0180 (1.8794) teacher_loss 0.4829 (0.3317) loss_zs_kd 0.0091 (0.0073) loss_oracle 0.7746 (0.7821) kd_loss 1.1432 (1.1530) acc 81.2500 (88.5938) gate/entropy 1.0981 (1.0979) gate/usage_max 0.3429 (0.3451) gate/usage_min 0.3188 (0.3156) gate/usage_std 0.0105 (0.0128) teacher/entropy 0.0000 (0.0004) teacher/usage_max 1.0000 (0.9999) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4713) nleep/row_max_mean 1587.5430 (1578.8972) nleep/row_max_std 43.5777 (56.6690) nleep/row_min_mean 1530.6697 (1523.0836) lr 1.9048e-03 eta 0:16:13
epoch [9/50] batch [40/173] time 0.161 (0.120) data 0.000 (0.008) loss 2.0161 (1.8604) teacher_loss 0.5611 (0.3298) loss_zs_kd 0.0085 (0.0082) loss_oracle 0.6556 (0.7687) kd_loss 1.1228 (1.1421) acc 84.3750 (88.5938) gate/entropy 1.0985 (1.0981) gate/usage_max 0.3378 (0.3426) gate/usage_min 0.3254 (0.3189) gate/usage_std 0.0056 (0.0104) teacher/entropy 0.0000 (0.0008) teacher/usage_max 1.0000 (0.9977) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4698) nleep/row_max_mean 1566.5081 (1573.9296) nleep/row_max_std 36.0116 (56.8326) nleep/row_min_mean 1512.3092 (1519.5341) lr 1.9048e-03 eta 0:14:30
epoch [9/50] batch [60/173] time 0.078 (0.116) data 0.000 (0.005) loss 1.8236 (1.8631) teacher_loss 0.3202 (0.3460) loss_zs_kd 0.0072 (0.0078) loss_oracle 0.8108 (0.7629) kd_loss 1.0944 (1.1317) acc 93.7500 (88.2292) gate/entropy 1.0986 (1.0982) gate/usage_max 0.3351 (0.3404) gate/usage_min 0.3318 (0.3222) gate/usage_std 0.0013 (0.0080) teacher/entropy 0.0087 (0.0010) teacher/usage_max 0.9976 (0.9983) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4697 (0.4702) nleep/row_max_mean 1571.2954 (1572.8673) nleep/row_max_std 53.9968 (55.0456) nleep/row_min_mean 1518.9236 (1518.7242) lr 1.9048e-03 eta 0:13:56
epoch [9/50] batch [80/173] time 0.100 (0.117) data 0.000 (0.004) loss 1.7848 (1.8481) teacher_loss 0.3223 (0.3401) loss_zs_kd 0.0110 (0.0074) loss_oracle 0.7552 (0.7661) kd_loss 1.0794 (1.1213) acc 87.5000 (88.2422) gate/entropy 1.0985 (1.0983) gate/usage_max 0.3382 (0.3393) gate/usage_min 0.3282 (0.3243) gate/usage_std 0.0041 (0.0065) teacher/entropy 0.0051 (0.0015) teacher/usage_max 0.9677 (0.9968) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4487 (0.4692) nleep/row_max_mean 1579.9551 (1572.9667) nleep/row_max_std 46.1104 (54.8746) nleep/row_min_mean 1527.8324 (1519.0901) lr 1.9048e-03 eta 0:14:02
epoch [9/50] batch [100/173] time 0.100 (0.121) data 0.000 (0.003) loss 1.8239 (1.8292) teacher_loss 0.3663 (0.3325) loss_zs_kd 0.0113 (0.0074) loss_oracle 0.8116 (0.7646) kd_loss 1.0461 (1.1107) acc 87.5000 (88.4375) gate/entropy 1.0983 (1.0983) gate/usage_max 0.3441 (0.3397) gate/usage_min 0.3236 (0.3246) gate/usage_std 0.0084 (0.0065) teacher/entropy 0.0216 (0.0026) teacher/usage_max 0.9750 (0.9963) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4538 (0.4688) nleep/row_max_mean 1562.5229 (1572.1492) nleep/row_max_std 57.8161 (54.8972) nleep/row_min_mean 1514.7667 (1518.7061) lr 1.9048e-03 eta 0:14:25
epoch [9/50] batch [120/173] time 0.130 (0.122) data 0.000 (0.003) loss 1.6912 (1.8221) teacher_loss 0.3071 (0.3394) loss_zs_kd 0.0006 (0.0073) loss_oracle 0.6968 (0.7556) kd_loss 1.0354 (1.1013) acc 84.3750 (88.0990) gate/entropy 1.0979 (1.0983) gate/usage_max 0.3503 (0.3410) gate/usage_min 0.3192 (0.3240) gate/usage_std 0.0129 (0.0072) teacher/entropy 0.0138 (0.0027) teacher/usage_max 0.9951 (0.9955) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4680 (0.4682) nleep/row_max_mean 1569.1003 (1571.1674) nleep/row_max_std 56.0267 (54.6660) nleep/row_min_mean 1516.9855 (1518.1605) lr 1.9048e-03 eta 0:14:33
epoch [9/50] batch [140/173] time 0.156 (0.127) data 0.000 (0.002) loss 1.7190 (1.8154) teacher_loss 0.3304 (0.3443) loss_zs_kd 0.0137 (0.0076) loss_oracle 0.7024 (0.7508) kd_loss 1.0306 (1.0920) acc 87.5000 (87.8125) gate/entropy 1.0972 (1.0982) gate/usage_max 0.3568 (0.3428) gate/usage_min 0.3147 (0.3230) gate/usage_std 0.0175 (0.0084) teacher/entropy 0.0000 (0.0028) teacher/usage_max 1.0000 (0.9958) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4685) nleep/row_max_mean 1575.0917 (1570.8579) nleep/row_max_std 61.3902 (54.3364) nleep/row_min_mean 1520.8815 (1517.8702) lr 1.9048e-03 eta 0:15:04
epoch [9/50] batch [160/173] time 0.151 (0.130) data 0.000 (0.002) loss 1.8358 (1.8050) teacher_loss 0.4799 (0.3455) loss_zs_kd 0.0077 (0.0077) loss_oracle 0.6759 (0.7466) kd_loss 1.0140 (1.0824) acc 84.3750 (87.5586) gate/entropy 1.0964 (1.0980) gate/usage_max 0.3635 (0.3450) gate/usage_min 0.3103 (0.3217) gate/usage_std 0.0223 (0.0098) teacher/entropy 0.0013 (0.0031) teacher/usage_max 0.9690 (0.9954) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4496 (0.4682) nleep/row_max_mean 1562.5144 (1570.0356) nleep/row_max_std 64.8873 (54.6100) nleep/row_min_mean 1510.9620 (1517.2435) lr 1.9048e-03 eta 0:15:22
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [10/50] batch [20/173] time 0.139 (0.155) data 0.000 (0.013) loss 1.5970 (1.6592) teacher_loss 0.1908 (0.3114) loss_zs_kd 0.0072 (0.0073) loss_oracle 0.8370 (0.7117) kd_loss 0.9842 (0.9883) acc 96.8750 (90.0000) gate/entropy 1.0947 (1.0952) gate/usage_max 0.3737 (0.3709) gate/usage_min 0.3034 (0.3053) gate/usage_std 0.0297 (0.0276) teacher/entropy 0.0000 (0.0042) teacher/usage_max 1.0000 (0.9944) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4675) nleep/row_max_mean 1564.6134 (1565.1024) nleep/row_max_std 64.5796 (59.9195) nleep/row_min_mean 1509.5325 (1512.8075) lr 1.8763e-03 eta 0:18:19
epoch [10/50] batch [40/173] time 0.128 (0.146) data 0.000 (0.007) loss 1.5306 (1.6804) teacher_loss 0.1431 (0.3259) loss_zs_kd 0.0061 (0.0080) loss_oracle 0.8476 (0.7415) kd_loss 0.9607 (0.9797) acc 96.8750 (88.5938) gate/entropy 1.0935 (1.0946) gate/usage_max 0.3796 (0.3740) gate/usage_min 0.2994 (0.3033) gate/usage_std 0.0339 (0.0298) teacher/entropy 0.0124 (0.0052) teacher/usage_max 0.9730 (0.9910) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4524 (0.4651) nleep/row_max_mean 1541.8997 (1563.6953) nleep/row_max_std 67.8617 (59.6990) nleep/row_min_mean 1493.7793 (1511.9194) lr 1.8763e-03 eta 0:17:06
epoch [10/50] batch [60/173] time 0.087 (0.139) data 0.001 (0.004) loss 1.5364 (1.6752) teacher_loss 0.2269 (0.3200) loss_zs_kd 0.0063 (0.0077) loss_oracle 0.7126 (0.7582) kd_loss 0.9501 (0.9723) acc 90.6250 (88.6979) gate/entropy 1.0923 (1.0940) gate/usage_max 0.3848 (0.3768) gate/usage_min 0.2954 (0.3013) gate/usage_std 0.0377 (0.0319) teacher/entropy 0.0051 (0.0054) teacher/usage_max 0.9988 (0.9898) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4705 (0.4643) nleep/row_max_mean 1541.7249 (1560.5011) nleep/row_max_std 64.5456 (59.1947) nleep/row_min_mean 1493.6458 (1510.0237) lr 1.8763e-03 eta 0:16:14
epoch [10/50] batch [80/173] time 0.085 (0.130) data 0.000 (0.003) loss 1.8992 (1.6692) teacher_loss 0.6354 (0.3241) loss_zs_kd 0.0151 (0.0083) loss_oracle 0.6329 (0.7517) kd_loss 0.9398 (0.9651) acc 71.8750 (88.2422) gate/entropy 1.0908 (1.0934) gate/usage_max 0.3907 (0.3796) gate/usage_min 0.2916 (0.2993) gate/usage_std 0.0419 (0.0339) teacher/entropy 0.0000 (0.0057) teacher/usage_max 1.0000 (0.9883) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4632) nleep/row_max_mean 1568.1049 (1559.6759) nleep/row_max_std 70.1790 (58.6400) nleep/row_min_mean 1515.1952 (1509.8575) lr 1.8763e-03 eta 0:15:11
epoch [10/50] batch [100/173] time 0.071 (0.127) data 0.000 (0.003) loss 1.7608 (1.6637) teacher_loss 0.4695 (0.3285) loss_zs_kd 0.0077 (0.0080) loss_oracle 0.7118 (0.7463) kd_loss 0.9315 (0.9581) acc 84.3750 (88.1562) gate/entropy 1.0893 (1.0927) gate/usage_max 0.3963 (0.3824) gate/usage_min 0.2877 (0.2974) gate/usage_std 0.0460 (0.0359) teacher/entropy 0.0011 (0.0057) teacher/usage_max 0.9687 (0.9878) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4495 (0.4629) nleep/row_max_mean 1552.3086 (1559.7295) nleep/row_max_std 50.5148 (57.8876) nleep/row_min_mean 1504.4998 (1509.8796) lr 1.8763e-03 eta 0:14:50
epoch [10/50] batch [120/173] time 0.079 (0.124) data 0.000 (0.002) loss 1.8259 (1.6578) teacher_loss 0.5447 (0.3338) loss_zs_kd 0.0146 (0.0080) loss_oracle 0.7281 (0.7384) kd_loss 0.9099 (0.9507) acc 78.1250 (87.8125) gate/entropy 1.0876 (1.0920) gate/usage_max 0.4020 (0.3852) gate/usage_min 0.2840 (0.2954) gate/usage_std 0.0501 (0.0379) teacher/entropy 0.0015 (0.0060) teacher/usage_max 0.9998 (0.9877) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4712 (0.4628) nleep/row_max_mean 1565.0303 (1560.4773) nleep/row_max_std 46.7639 (57.3043) nleep/row_min_mean 1514.1415 (1510.4481) lr 1.8763e-03 eta 0:14:26
epoch [10/50] batch [140/173] time 0.089 (0.123) data 0.000 (0.002) loss 1.6833 (1.6549) teacher_loss 0.3870 (0.3407) loss_zs_kd 0.0055 (0.0078) loss_oracle 0.8134 (0.7329) kd_loss 0.8868 (0.9439) acc 87.5000 (87.3884) gate/entropy 1.0858 (1.0913) gate/usage_max 0.4074 (0.3880) gate/usage_min 0.2806 (0.2936) gate/usage_std 0.0539 (0.0400) teacher/entropy 0.0122 (0.0056) teacher/usage_max 0.9961 (0.9882) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4687 (0.4631) nleep/row_max_mean 1528.7878 (1560.5045) nleep/row_max_std 71.9572 (57.4833) nleep/row_min_mean 1482.3878 (1510.2563) lr 1.8763e-03 eta 0:14:15
epoch [10/50] batch [160/173] time 0.082 (0.120) data 0.000 (0.002) loss 1.6549 (1.6529) teacher_loss 0.4255 (0.3483) loss_zs_kd 0.0114 (0.0077) loss_oracle 0.6800 (0.7275) kd_loss 0.8837 (0.9370) acc 84.3750 (87.0312) gate/entropy 1.0838 (1.0904) gate/usage_max 0.4133 (0.3908) gate/usage_min 0.2770 (0.2917) gate/usage_std 0.0581 (0.0420) teacher/entropy 0.0000 (0.0050) teacher/usage_max 1.0000 (0.9895) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4640) nleep/row_max_mean 1565.0408 (1560.6757) nleep/row_max_std 47.1522 (57.6503) nleep/row_min_mean 1512.6360 (1510.0970) lr 1.8763e-03 eta 0:13:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,284
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [11/50] batch [20/173] time 0.135 (0.134) data 0.000 (0.016) loss 1.4703 (1.5677) teacher_loss 0.2839 (0.3551) loss_zs_kd 0.0044 (0.0066) loss_oracle 0.6447 (0.6865) kd_loss 0.8619 (0.8660) acc 87.5000 (85.9375) gate/entropy 1.0804 (1.0814) gate/usage_max 0.4224 (0.4198) gate/usage_min 0.2715 (0.2730) gate/usage_std 0.0645 (0.0627) teacher/entropy 0.0000 (0.0030) teacher/usage_max 1.0000 (0.9965) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4689) nleep/row_max_mean 1562.7947 (1567.0943) nleep/row_max_std 67.5006 (58.6406) nleep/row_min_mean 1509.4393 (1512.3853) lr 1.8443e-03 eta 0:15:24
epoch [11/50] batch [40/173] time 0.143 (0.138) data 0.000 (0.008) loss 1.4079 (1.5543) teacher_loss 0.2281 (0.3470) loss_zs_kd 0.0050 (0.0064) loss_oracle 0.6570 (0.6896) kd_loss 0.8487 (0.8593) acc 90.6250 (86.0938) gate/entropy 1.0781 (1.0803) gate/usage_max 0.4280 (0.4225) gate/usage_min 0.2682 (0.2714) gate/usage_std 0.0685 (0.0646) teacher/entropy 0.0000 (0.0033) teacher/usage_max 1.0000 (0.9968) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4692) nleep/row_max_mean 1584.4177 (1567.6292) nleep/row_max_std 50.5463 (57.8468) nleep/row_min_mean 1525.6238 (1512.7578) lr 1.8443e-03 eta 0:15:52
epoch [11/50] batch [60/173] time 0.153 (0.139) data 0.001 (0.005) loss 1.5739 (1.5326) teacher_loss 0.3101 (0.3293) loss_zs_kd 0.0078 (0.0071) loss_oracle 0.8447 (0.6925) kd_loss 0.8376 (0.8536) acc 87.5000 (86.9792) gate/entropy 1.0761 (1.0792) gate/usage_max 0.4326 (0.4252) gate/usage_min 0.2653 (0.2698) gate/usage_std 0.0718 (0.0665) teacher/entropy 0.0004 (0.0026) teacher/usage_max 0.9999 (0.9972) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4695) nleep/row_max_mean 1546.9148 (1567.0494) nleep/row_max_std 74.3837 (57.7589) nleep/row_min_mean 1492.2471 (1512.1752) lr 1.8443e-03 eta 0:15:50
epoch [11/50] batch [80/173] time 0.159 (0.142) data 0.000 (0.004) loss 1.3760 (1.5303) teacher_loss 0.2165 (0.3319) loss_zs_kd 0.0034 (0.0070) loss_oracle 0.6613 (0.6948) kd_loss 0.8271 (0.8475) acc 90.6250 (86.7188) gate/entropy 1.0740 (1.0781) gate/usage_max 0.4373 (0.4278) gate/usage_min 0.2625 (0.2683) gate/usage_std 0.0751 (0.0684) teacher/entropy 0.0000 (0.0025) teacher/usage_max 1.0000 (0.9976) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4697) nleep/row_max_mean 1563.7991 (1567.3806) nleep/row_max_std 58.9146 (56.9670) nleep/row_min_mean 1507.8621 (1512.3406) lr 1.8443e-03 eta 0:16:08
epoch [11/50] batch [100/173] time 0.153 (0.144) data 0.000 (0.003) loss 1.3109 (1.5232) teacher_loss 0.1176 (0.3276) loss_zs_kd 0.0000 (0.0067) loss_oracle 0.7573 (0.7002) kd_loss 0.8146 (0.8421) acc 93.7500 (87.1875) gate/entropy 1.0714 (1.0770) gate/usage_max 0.4428 (0.4303) gate/usage_min 0.2592 (0.2668) gate/usage_std 0.0790 (0.0701) teacher/entropy 0.0000 (0.0021) teacher/usage_max 1.0000 (0.9978) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4698) nleep/row_max_mean 1582.5520 (1567.0216) nleep/row_max_std 45.2236 (57.2532) nleep/row_min_mean 1526.5270 (1512.0570) lr 1.8443e-03 eta 0:16:21
epoch [11/50] batch [120/173] time 0.149 (0.145) data 0.000 (0.003) loss 1.3414 (1.5212) teacher_loss 0.2101 (0.3317) loss_zs_kd 0.0090 (0.0069) loss_oracle 0.6453 (0.6988) kd_loss 0.8041 (0.8367) acc 90.6250 (87.0312) gate/entropy 1.0692 (1.0759) gate/usage_max 0.4475 (0.4327) gate/usage_min 0.2564 (0.2653) gate/usage_std 0.0823 (0.0719) teacher/entropy 0.0000 (0.0018) teacher/usage_max 1.0000 (0.9981) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4701) nleep/row_max_mean 1572.6123 (1566.9257) nleep/row_max_std 52.6912 (56.8188) nleep/row_min_mean 1518.6460 (1511.9787) lr 1.8443e-03 eta 0:16:25
epoch [11/50] batch [140/173] time 0.141 (0.146) data 0.000 (0.002) loss 1.4906 (1.5165) teacher_loss 0.3201 (0.3334) loss_zs_kd 0.0105 (0.0067) loss_oracle 0.7305 (0.6971) kd_loss 0.8000 (0.8312) acc 87.5000 (87.0089) gate/entropy 1.0670 (1.0748) gate/usage_max 0.4517 (0.4351) gate/usage_min 0.2539 (0.2638) gate/usage_std 0.0853 (0.0736) teacher/entropy 0.0073 (0.0017) teacher/usage_max 0.9707 (0.9981) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4508 (0.4701) nleep/row_max_mean 1569.6726 (1567.1217) nleep/row_max_std 59.4414 (56.5014) nleep/row_min_mean 1512.4720 (1512.0928) lr 1.8443e-03 eta 0:16:29
epoch [11/50] batch [160/173] time 0.130 (0.147) data 0.000 (0.002) loss 1.2568 (1.5048) teacher_loss 0.1102 (0.3280) loss_zs_kd 0.0015 (0.0068) loss_oracle 0.7239 (0.6947) kd_loss 0.7840 (0.8261) acc 96.8750 (87.3633) gate/entropy 1.0645 (1.0737) gate/usage_max 0.4566 (0.4375) gate/usage_min 0.2513 (0.2624) gate/usage_std 0.0887 (0.0753) teacher/entropy 0.0000 (0.0015) teacher/usage_max 1.0000 (0.9982) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4701) nleep/row_max_mean 1574.0255 (1567.2880) nleep/row_max_std 58.6710 (56.4979) nleep/row_min_mean 1513.0583 (1511.9712) lr 1.8443e-03 eta 0:16:31
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,291
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.1%, epoch: 3 *******
******* Domain a best val test acc: 97.9%, epoch: 3 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [12/50] batch [20/173] time 0.070 (0.123) data 0.000 (0.012) loss 1.4351 (1.4441) teacher_loss 0.3116 (0.3304) loss_zs_kd 0.0078 (0.0076) loss_oracle 0.7006 (0.6762) kd_loss 0.7693 (0.7718) acc 87.5000 (88.5938) gate/entropy 1.0608 (1.0618) gate/usage_max 0.4633 (0.4615) gate/usage_min 0.2475 (0.2485) gate/usage_std 0.0935 (0.0922) teacher/entropy 0.0000 (0.0020) teacher/usage_max 1.0000 (0.9990) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4707) nleep/row_max_mean 1570.9144 (1570.2260) nleep/row_max_std 56.2506 (54.0878) nleep/row_min_mean 1510.5182 (1512.3973) lr 1.8090e-03 eta 0:13:45
epoch [12/50] batch [40/173] time 0.165 (0.117) data 0.000 (0.006) loss 1.9066 (1.4483) teacher_loss 0.7633 (0.3384) loss_zs_kd 0.0168 (0.0074) loss_oracle 0.7570 (0.6768) kd_loss 0.7564 (0.7678) acc 75.0000 (87.9688) gate/entropy 1.0585 (1.0606) gate/usage_max 0.4675 (0.4637) gate/usage_min 0.2454 (0.2474) gate/usage_std 0.0964 (0.0937) teacher/entropy 0.0044 (0.0015) teacher/usage_max 0.9990 (0.9986) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4707 (0.4704) nleep/row_max_mean 1553.2957 (1568.7830) nleep/row_max_std 58.8813 (54.7038) nleep/row_min_mean 1499.2793 (1511.3306) lr 1.8090e-03 eta 0:13:04
epoch [12/50] batch [60/173] time 0.095 (0.107) data 0.001 (0.004) loss 1.5662 (1.4527) teacher_loss 0.3798 (0.3370) loss_zs_kd 0.0138 (0.0076) loss_oracle 0.8554 (0.6977) kd_loss 0.7518 (0.7630) acc 81.2500 (87.7083) gate/entropy 1.0562 (1.0594) gate/usage_max 0.4715 (0.4658) gate/usage_min 0.2433 (0.2463) gate/usage_std 0.0992 (0.0952) teacher/entropy 0.0000 (0.0018) teacher/usage_max 1.0000 (0.9982) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4701) nleep/row_max_mean 1556.9788 (1569.2622) nleep/row_max_std 62.0696 (55.2131) nleep/row_min_mean 1499.5447 (1511.9630) lr 1.8090e-03 eta 0:11:53
epoch [12/50] batch [80/173] time 0.147 (0.108) data 0.000 (0.003) loss 1.4058 (1.4661) teacher_loss 0.2619 (0.3424) loss_zs_kd 0.0179 (0.0075) loss_oracle 0.7819 (0.7225) kd_loss 0.7440 (0.7588) acc 87.5000 (87.7344) gate/entropy 1.0539 (1.0583) gate/usage_max 0.4752 (0.4678) gate/usage_min 0.2411 (0.2452) gate/usage_std 0.1018 (0.0966) teacher/entropy 0.0000 (0.0027) teacher/usage_max 1.0000 (0.9965) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4690) nleep/row_max_mean 1548.5175 (1567.9607) nleep/row_max_std 63.8450 (56.3045) nleep/row_min_mean 1500.3937 (1512.1171) lr 1.8090e-03 eta 0:12:03
epoch [12/50] batch [100/173] time 0.162 (0.108) data 0.000 (0.003) loss 1.4155 (1.4693) teacher_loss 0.2287 (0.3370) loss_zs_kd 0.0038 (0.0075) loss_oracle 0.8562 (0.7482) kd_loss 0.7568 (0.7544) acc 93.7500 (87.8750) gate/entropy 1.0524 (1.0572) gate/usage_max 0.4776 (0.4696) gate/usage_min 0.2395 (0.2442) gate/usage_std 0.1035 (0.0979) teacher/entropy 0.0123 (0.0048) teacher/usage_max 0.9416 (0.9935) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4307 (0.4669) nleep/row_max_mean 1548.7673 (1565.8112) nleep/row_max_std 59.4694 (56.6642) nleep/row_min_mean 1506.1050 (1511.8907) lr 1.8090e-03 eta 0:11:59
epoch [12/50] batch [120/173] time 0.087 (0.109) data 0.000 (0.002) loss 1.3096 (1.4653) teacher_loss 0.1229 (0.3318) loss_zs_kd 0.0027 (0.0073) loss_oracle 0.8841 (0.7567) kd_loss 0.7433 (0.7515) acc 96.8750 (87.8125) gate/entropy 1.0505 (1.0562) gate/usage_max 0.4806 (0.4713) gate/usage_min 0.2376 (0.2432) gate/usage_std 0.1057 (0.0991) teacher/entropy 0.0056 (0.0060) teacher/usage_max 0.9695 (0.9900) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4500 (0.4644) nleep/row_max_mean 1552.2632 (1564.0487) nleep/row_max_std 60.9500 (56.5583) nleep/row_min_mean 1510.7073 (1511.9261) lr 1.8090e-03 eta 0:12:04
epoch [12/50] batch [140/173] time 0.163 (0.111) data 0.000 (0.002) loss 1.3165 (1.4667) teacher_loss 0.2433 (0.3347) loss_zs_kd 0.0044 (0.0074) loss_oracle 0.6538 (0.7588) kd_loss 0.7441 (0.7489) acc 87.5000 (87.6786) gate/entropy 1.0489 (1.0552) gate/usage_max 0.4831 (0.4729) gate/usage_min 0.2359 (0.2423) gate/usage_std 0.1075 (0.1002) teacher/entropy 0.0000 (0.0075) teacher/usage_max 0.9688 (0.9860) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4495 (0.4616) nleep/row_max_mean 1560.3813 (1562.4312) nleep/row_max_std 62.9347 (56.2580) nleep/row_min_mean 1515.7582 (1511.8241) lr 1.8090e-03 eta 0:12:14
epoch [12/50] batch [160/173] time 0.140 (0.116) data 0.000 (0.002) loss 1.4537 (1.4525) teacher_loss 0.4089 (0.3258) loss_zs_kd 0.0112 (0.0074) loss_oracle 0.6380 (0.7538) kd_loss 0.7202 (0.7461) acc 84.3750 (87.9297) gate/entropy 1.0466 (1.0543) gate/usage_max 0.4866 (0.4744) gate/usage_min 0.2340 (0.2413) gate/usage_std 0.1100 (0.1013) teacher/entropy 0.0000 (0.0087) teacher/usage_max 1.0000 (0.9832) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4714 (0.4597) nleep/row_max_mean 1570.8865 (1562.4493) nleep/row_max_std 59.7958 (56.1565) nleep/row_min_mean 1521.5070 (1512.4189) lr 1.8090e-03 eta 0:12:44
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,297
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.3%, epoch: 12 *******
******* Domain a best val test acc: 97.7%, epoch: 12 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [13/50] batch [20/173] time 0.150 (0.157) data 0.000 (0.013) loss 1.4909 (1.4130) teacher_loss 0.4030 (0.3143) loss_zs_kd 0.0213 (0.0091) loss_oracle 0.6958 (0.7452) kd_loss 0.7294 (0.7215) acc 90.6250 (88.1250) gate/entropy 1.0440 (1.0447) gate/usage_max 0.4906 (0.4895) gate/usage_min 0.2317 (0.2323) gate/usage_std 0.1128 (0.1120) teacher/entropy 0.0004 (0.0151) teacher/usage_max 0.9687 (0.9604) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4495 (0.4438) nleep/row_max_mean 1555.4506 (1561.2687) nleep/row_max_std 56.6558 (58.1456) nleep/row_min_mean 1510.3082 (1515.2946) lr 1.7705e-03 eta 0:17:09
epoch [13/50] batch [40/173] time 0.148 (0.149) data 0.000 (0.007) loss 1.6106 (1.4239) teacher_loss 0.4787 (0.3290) loss_zs_kd 0.0028 (0.0089) loss_oracle 0.8108 (0.7442) kd_loss 0.7251 (0.7183) acc 81.2500 (87.5781) gate/entropy 1.0422 (1.0439) gate/usage_max 0.4932 (0.4907) gate/usage_min 0.2302 (0.2316) gate/usage_std 0.1146 (0.1129) teacher/entropy 0.0528 (0.0177) teacher/usage_max 0.8773 (0.9572) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3879 (0.4417) nleep/row_max_mean 1566.9180 (1564.4931) nleep/row_max_std 53.2859 (56.0304) nleep/row_min_mean 1521.2014 (1518.0058) lr 1.7705e-03 eta 0:16:13
epoch [13/50] batch [60/173] time 0.159 (0.149) data 0.000 (0.005) loss 1.5365 (1.4245) teacher_loss 0.3904 (0.3222) loss_zs_kd 0.0039 (0.0083) loss_oracle 0.8193 (0.7517) kd_loss 0.7345 (0.7222) acc 81.2500 (87.7083) gate/entropy 1.0412 (1.0432) gate/usage_max 0.4945 (0.4918) gate/usage_min 0.2291 (0.2309) gate/usage_std 0.1156 (0.1136) teacher/entropy 0.0055 (0.0185) teacher/usage_max 0.9387 (0.9457) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4288 (0.4340) nleep/row_max_mean 1561.6189 (1563.8265) nleep/row_max_std 48.2014 (55.3911) nleep/row_min_mean 1513.9734 (1517.8937) lr 1.7705e-03 eta 0:16:11
epoch [13/50] batch [80/173] time 0.082 (0.146) data 0.000 (0.003) loss 1.3310 (1.4213) teacher_loss 0.3325 (0.3275) loss_zs_kd 0.0055 (0.0083) loss_oracle 0.6096 (0.7402) kd_loss 0.6910 (0.7196) acc 90.6250 (87.3828) gate/entropy 1.0392 (1.0425) gate/usage_max 0.4974 (0.4928) gate/usage_min 0.2274 (0.2303) gate/usage_std 0.1176 (0.1143) teacher/entropy 0.0087 (0.0182) teacher/usage_max 0.9977 (0.9476) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4698 (0.4353) nleep/row_max_mean 1572.8521 (1563.5572) nleep/row_max_std 61.7120 (56.3398) nleep/row_min_mean 1522.4236 (1517.4333) lr 1.7705e-03 eta 0:15:47
epoch [13/50] batch [100/173] time 0.085 (0.138) data 0.000 (0.003) loss 1.2680 (1.4050) teacher_loss 0.2255 (0.3202) loss_zs_kd 0.0069 (0.0081) loss_oracle 0.6916 (0.7290) kd_loss 0.6933 (0.7163) acc 87.5000 (87.9062) gate/entropy 1.0382 (1.0418) gate/usage_max 0.4988 (0.4938) gate/usage_min 0.2265 (0.2297) gate/usage_std 0.1187 (0.1150) teacher/entropy 0.0025 (0.0179) teacher/usage_max 0.9995 (0.9506) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4711 (0.4373) nleep/row_max_mean 1577.7932 (1563.7424) nleep/row_max_std 54.8927 (56.9806) nleep/row_min_mean 1525.7123 (1517.3235) lr 1.7705e-03 eta 0:14:56
epoch [13/50] batch [120/173] time 0.127 (0.135) data 0.000 (0.002) loss 1.0465 (1.4022) teacher_loss 0.0775 (0.3235) loss_zs_kd 0.0051 (0.0081) loss_oracle 0.5891 (0.7220) kd_loss 0.6719 (0.7136) acc 96.8750 (88.1250) gate/entropy 1.0370 (1.0411) gate/usage_max 0.5005 (0.4948) gate/usage_min 0.2256 (0.2291) gate/usage_std 0.1198 (0.1158) teacher/entropy 0.0415 (0.0192) teacher/usage_max 0.9649 (0.9496) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4468 (0.4366) nleep/row_max_mean 1557.4824 (1563.2798) nleep/row_max_std 57.1777 (56.9771) nleep/row_min_mean 1510.4971 (1516.6130) lr 1.7705e-03 eta 0:14:30
epoch [13/50] batch [140/173] time 0.086 (0.132) data 0.000 (0.002) loss 1.4216 (1.4001) teacher_loss 0.3781 (0.3275) loss_zs_kd 0.0088 (0.0082) loss_oracle 0.6657 (0.7147) kd_loss 0.7063 (0.7112) acc 84.3750 (87.8125) gate/entropy 1.0354 (1.0403) gate/usage_max 0.5028 (0.4958) gate/usage_min 0.2245 (0.2285) gate/usage_std 0.1215 (0.1165) teacher/entropy 0.0001 (0.0186) teacher/usage_max 0.9687 (0.9516) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4495 (0.4380) nleep/row_max_mean 1555.4678 (1562.6305) nleep/row_max_std 63.3856 (57.4916) nleep/row_min_mean 1509.1896 (1515.7668) lr 1.7705e-03 eta 0:14:09
epoch [13/50] batch [160/173] time 0.082 (0.129) data 0.000 (0.002) loss 1.3399 (1.3975) teacher_loss 0.2860 (0.3294) loss_zs_kd 0.0134 (0.0082) loss_oracle 0.7139 (0.7110) kd_loss 0.6903 (0.7085) acc 90.6250 (87.7344) gate/entropy 1.0340 (1.0396) gate/usage_max 0.5048 (0.4968) gate/usage_min 0.2236 (0.2279) gate/usage_std 0.1228 (0.1172) teacher/entropy 0.0219 (0.0183) teacher/usage_max 0.9530 (0.9536) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4386 (0.4393) nleep/row_max_mean 1564.6831 (1562.8899) nleep/row_max_std 61.8993 (57.7976) nleep/row_min_mean 1514.7068 (1515.6258) lr 1.7705e-03 eta 0:13:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.3%, epoch: 12 *******
******* Domain a best val test acc: 97.7%, epoch: 12 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [14/50] batch [20/173] time 0.059 (0.122) data 0.000 (0.016) loss 1.2978 (1.3470) teacher_loss 0.2466 (0.3170) loss_zs_kd 0.0014 (0.0089) loss_oracle 0.7143 (0.6774) kd_loss 0.6933 (0.6869) acc 90.6250 (87.9688) gate/entropy 1.0319 (1.0324) gate/usage_max 0.5078 (0.5071) gate/usage_min 0.2223 (0.2226) gate/usage_std 0.1249 (0.1244) teacher/entropy 0.0040 (0.0226) teacher/usage_max 0.9686 (0.9514) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4494 (0.4378) nleep/row_max_mean 1560.4807 (1560.1267) nleep/row_max_std 65.4924 (58.9348) nleep/row_min_mean 1510.6119 (1511.1945) lr 1.7290e-03 eta 0:13:00
epoch [14/50] batch [40/173] time 0.159 (0.116) data 0.000 (0.008) loss 1.3076 (1.3424) teacher_loss 0.2634 (0.3089) loss_zs_kd 0.0075 (0.0084) loss_oracle 0.7463 (0.6895) kd_loss 0.6673 (0.6846) acc 90.6250 (88.4375) gate/entropy 1.0302 (1.0317) gate/usage_max 0.5102 (0.5081) gate/usage_min 0.2212 (0.2222) gate/usage_std 0.1265 (0.1251) teacher/entropy 0.0224 (0.0179) teacher/usage_max 0.9740 (0.9595) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4532 (0.4434) nleep/row_max_mean 1567.0066 (1560.7573) nleep/row_max_std 43.8461 (56.5571) nleep/row_min_mean 1520.1602 (1511.2573) lr 1.7290e-03 eta 0:12:19
epoch [14/50] batch [60/173] time 0.131 (0.125) data 0.001 (0.005) loss 1.3141 (1.3363) teacher_loss 0.2962 (0.3149) loss_zs_kd 0.0196 (0.0084) loss_oracle 0.6142 (0.6691) kd_loss 0.7009 (0.6827) acc 90.6250 (88.0208) gate/entropy 1.0291 (1.0310) gate/usage_max 0.5116 (0.5090) gate/usage_min 0.2207 (0.2218) gate/usage_std 0.1275 (0.1257) teacher/entropy 0.0080 (0.0194) teacher/usage_max 0.9396 (0.9575) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4294 (0.4420) nleep/row_max_mean 1551.9023 (1561.1425) nleep/row_max_std 63.0280 (56.6117) nleep/row_min_mean 1501.7935 (1512.0544) lr 1.7290e-03 eta 0:13:14
epoch [14/50] batch [80/173] time 0.151 (0.131) data 0.000 (0.004) loss 1.2302 (1.3284) teacher_loss 0.2475 (0.3083) loss_zs_kd 0.0073 (0.0078) loss_oracle 0.5862 (0.6692) kd_loss 0.6859 (0.6815) acc 90.6250 (88.4766) gate/entropy 1.0276 (1.0304) gate/usage_max 0.5137 (0.5098) gate/usage_min 0.2199 (0.2214) gate/usage_std 0.1289 (0.1263) teacher/entropy 0.0007 (0.0191) teacher/usage_max 0.9687 (0.9576) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4494 (0.4420) nleep/row_max_mean 1569.4324 (1560.6786) nleep/row_max_std 54.4411 (55.7194) nleep/row_min_mean 1517.4453 (1511.4696) lr 1.7290e-03 eta 0:13:47
epoch [14/50] batch [100/173] time 0.148 (0.135) data 0.000 (0.003) loss 1.4651 (1.3241) teacher_loss 0.4862 (0.3119) loss_zs_kd 0.0152 (0.0080) loss_oracle 0.5752 (0.6555) kd_loss 0.6837 (0.6804) acc 84.3750 (88.3750) gate/entropy 1.0268 (1.0298) gate/usage_max 0.5149 (0.5107) gate/usage_min 0.2195 (0.2211) gate/usage_std 0.1298 (0.1269) teacher/entropy 0.0006 (0.0185) teacher/usage_max 0.9688 (0.9580) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4495 (0.4423) nleep/row_max_mean 1541.6544 (1561.0799) nleep/row_max_std 58.0797 (55.8583) nleep/row_min_mean 1492.2424 (1511.4831) lr 1.7290e-03 eta 0:14:13
epoch [14/50] batch [120/173] time 0.133 (0.137) data 0.000 (0.003) loss 1.3163 (1.3249) teacher_loss 0.3587 (0.3190) loss_zs_kd 0.0037 (0.0081) loss_oracle 0.5911 (0.6471) kd_loss 0.6602 (0.6784) acc 84.3750 (88.0469) gate/entropy 1.0254 (1.0291) gate/usage_max 0.5168 (0.5116) gate/usage_min 0.2190 (0.2208) gate/usage_std 0.1310 (0.1275) teacher/entropy 0.0000 (0.0169) teacher/usage_max 1.0000 (0.9610) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4714 (0.4443) nleep/row_max_mean 1565.7810 (1561.3601) nleep/row_max_std 61.8227 (56.4653) nleep/row_min_mean 1510.8229 (1511.3916) lr 1.7290e-03 eta 0:14:22
epoch [14/50] batch [140/173] time 0.082 (0.137) data 0.000 (0.002) loss 1.5123 (1.3268) teacher_loss 0.4796 (0.3228) loss_zs_kd 0.0073 (0.0084) loss_oracle 0.7507 (0.6451) kd_loss 0.6537 (0.6772) acc 78.1250 (87.7232) gate/entropy 1.0239 (1.0285) gate/usage_max 0.5188 (0.5125) gate/usage_min 0.2185 (0.2205) gate/usage_std 0.1324 (0.1281) teacher/entropy 0.0029 (0.0157) teacher/usage_max 0.9994 (0.9621) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4710 (0.4451) nleep/row_max_mean 1545.4329 (1561.2752) nleep/row_max_std 67.3721 (56.7569) nleep/row_min_mean 1497.0460 (1511.4115) lr 1.7290e-03 eta 0:14:18
epoch [14/50] batch [160/173] time 0.156 (0.138) data 0.000 (0.002) loss 1.4123 (1.3237) teacher_loss 0.3387 (0.3189) loss_zs_kd 0.0152 (0.0082) loss_oracle 0.7285 (0.6504) kd_loss 0.7018 (0.6755) acc 81.2500 (87.8711) gate/entropy 1.0225 (1.0278) gate/usage_max 0.5208 (0.5134) gate/usage_min 0.2179 (0.2202) gate/usage_std 0.1337 (0.1287) teacher/entropy 0.0173 (0.0149) teacher/usage_max 0.9023 (0.9635) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4043 (0.4461) nleep/row_max_mean 1559.0293 (1561.2055) nleep/row_max_std 55.7929 (57.2580) nleep/row_min_mean 1511.9453 (1511.2507) lr 1.7290e-03 eta 0:14:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.3%, epoch: 12 *******
******* Domain a best val test acc: 97.7%, epoch: 12 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [15/50] batch [20/173] time 0.164 (0.132) data 0.000 (0.012) loss 1.3434 (1.3513) teacher_loss 0.3294 (0.3274) loss_zs_kd 0.0068 (0.0077) loss_oracle 0.7288 (0.6932) kd_loss 0.6461 (0.6736) acc 87.5000 (87.5000) gate/entropy 1.0205 (1.0214) gate/usage_max 0.5234 (0.5222) gate/usage_min 0.2170 (0.2174) gate/usage_std 0.1355 (0.1347) teacher/entropy 0.0015 (0.0157) teacher/usage_max 0.9997 (0.9428) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4712 (0.4320) nleep/row_max_mean 1556.0560 (1558.6985) nleep/row_max_std 66.4557 (56.1736) nleep/row_min_mean 1511.9906 (1511.6680) lr 1.6845e-03 eta 0:13:40
epoch [15/50] batch [40/173] time 0.076 (0.124) data 0.000 (0.006) loss 1.3839 (1.3413) teacher_loss 0.3315 (0.3218) loss_zs_kd 0.0087 (0.0084) loss_oracle 0.7440 (0.6834) kd_loss 0.6761 (0.6735) acc 87.5000 (88.3594) gate/entropy 1.0197 (1.0209) gate/usage_max 0.5245 (0.5228) gate/usage_min 0.2166 (0.2172) gate/usage_std 0.1363 (0.1351) teacher/entropy 0.0253 (0.0145) teacher/usage_max 0.9201 (0.9433) teacher/usage_min 0.0002 (0.0011) teacher/usage_std 0.4161 (0.4322) nleep/row_max_mean 1564.8817 (1555.9027) nleep/row_max_std 50.3652 (55.1755) nleep/row_min_mean 1519.8516 (1510.0519) lr 1.6845e-03 eta 0:12:47
epoch [15/50] batch [60/173] time 0.089 (0.117) data 0.000 (0.004) loss 1.4341 (1.3227) teacher_loss 0.4077 (0.3178) loss_zs_kd 0.0121 (0.0091) loss_oracle 0.6890 (0.6625) kd_loss 0.6758 (0.6692) acc 90.6250 (88.5417) gate/entropy 1.0191 (1.0205) gate/usage_max 0.5253 (0.5234) gate/usage_min 0.2165 (0.2170) gate/usage_std 0.1368 (0.1355) teacher/entropy 0.0098 (0.0149) teacher/usage_max 0.9398 (0.9474) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4295 (0.4349) nleep/row_max_mean 1551.6169 (1553.9717) nleep/row_max_std 48.4369 (54.9869) nleep/row_min_mean 1509.0920 (1508.5129) lr 1.6845e-03 eta 0:12:03
epoch [15/50] batch [80/173] time 0.195 (0.117) data 0.000 (0.003) loss 1.1613 (1.2948) teacher_loss 0.2537 (0.3042) loss_zs_kd 0.0064 (0.0088) loss_oracle 0.5294 (0.6425) kd_loss 0.6398 (0.6650) acc 90.6250 (88.7500) gate/entropy 1.0176 (1.0199) gate/usage_max 0.5273 (0.5242) gate/usage_min 0.2161 (0.2168) gate/usage_std 0.1381 (0.1360) teacher/entropy 0.0003 (0.0150) teacher/usage_max 1.0000 (0.9515) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4714 (0.4378) nleep/row_max_mean 1559.1106 (1553.3792) nleep/row_max_std 57.0215 (54.3829) nleep/row_min_mean 1511.7750 (1508.0652) lr 1.6845e-03 eta 0:11:57
epoch [15/50] batch [100/173] time 0.085 (0.115) data 0.000 (0.003) loss 1.1374 (1.2824) teacher_loss 0.1589 (0.2990) loss_zs_kd 0.0100 (0.0091) loss_oracle 0.5972 (0.6329) kd_loss 0.6749 (0.6623) acc 90.6250 (88.7188) gate/entropy 1.0168 (1.0194) gate/usage_max 0.5284 (0.5249) gate/usage_min 0.2160 (0.2167) gate/usage_std 0.1388 (0.1365) teacher/entropy 0.0076 (0.0158) teacher/usage_max 0.9388 (0.9524) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4288 (0.4383) nleep/row_max_mean 1550.6433 (1553.4392) nleep/row_max_std 59.9053 (54.3518) nleep/row_min_mean 1512.1050 (1508.4203) lr 1.6845e-03 eta 0:11:47
epoch [15/50] batch [120/173] time 0.079 (0.115) data 0.000 (0.002) loss 1.1499 (1.2661) teacher_loss 0.1536 (0.2872) loss_zs_kd 0.0123 (0.0092) loss_oracle 0.6421 (0.6269) kd_loss 0.6691 (0.6609) acc 90.6250 (89.0885) gate/entropy 1.0155 (1.0188) gate/usage_max 0.5300 (0.5257) gate/usage_min 0.2157 (0.2165) gate/usage_std 0.1399 (0.1370) teacher/entropy 0.0128 (0.0162) teacher/usage_max 0.9361 (0.9522) teacher/usage_min 0.0001 (0.0013) teacher/usage_std 0.4270 (0.4382) nleep/row_max_mean 1552.9663 (1552.9746) nleep/row_max_std 50.9373 (54.4354) nleep/row_min_mean 1515.3623 (1507.9393) lr 1.6845e-03 eta 0:11:44
epoch [15/50] batch [140/173] time 0.079 (0.115) data 0.000 (0.002) loss 1.2555 (1.2691) teacher_loss 0.3312 (0.2929) loss_zs_kd 0.0097 (0.0092) loss_oracle 0.5309 (0.6255) kd_loss 0.6540 (0.6588) acc 93.7500 (88.8839) gate/entropy 1.0140 (1.0182) gate/usage_max 0.5320 (0.5264) gate/usage_min 0.2154 (0.2164) gate/usage_std 0.1413 (0.1375) teacher/entropy 0.0003 (0.0164) teacher/usage_max 0.9687 (0.9531) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4495 (0.4389) nleep/row_max_mean 1557.1353 (1552.9602) nleep/row_max_std 59.7941 (54.2939) nleep/row_min_mean 1512.2308 (1508.0467) lr 1.6845e-03 eta 0:11:38
epoch [15/50] batch [160/173] time 0.159 (0.120) data 0.000 (0.002) loss 1.1002 (1.2701) teacher_loss 0.1634 (0.2994) loss_zs_kd 0.0125 (0.0093) loss_oracle 0.5831 (0.6188) kd_loss 0.6390 (0.6567) acc 96.8750 (88.7305) gate/entropy 1.0130 (1.0176) gate/usage_max 0.5333 (0.5272) gate/usage_min 0.2152 (0.2163) gate/usage_std 0.1422 (0.1381) teacher/entropy 0.0220 (0.0155) teacher/usage_max 0.9564 (0.9556) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4409 (0.4406) nleep/row_max_mean 1565.0959 (1553.7092) nleep/row_max_std 52.2255 (54.4765) nleep/row_min_mean 1513.1511 (1508.4277) lr 1.6845e-03 eta 0:12:06
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,299
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,993
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.1%
******* Domain a best val acc:      96.4%, epoch: 15 *******
******* Domain a best val test acc: 97.3%, epoch: 15 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [16/50] batch [20/173] time 0.121 (0.155) data 0.000 (0.013) loss 1.3011 (1.2353) teacher_loss 0.3303 (0.3186) loss_zs_kd 0.0075 (0.0092) loss_oracle 0.6153 (0.5719) kd_loss 0.6594 (0.6261) acc 87.5000 (87.8125) gate/entropy 1.0120 (1.0120) gate/usage_max 0.5346 (0.5345) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1430 (0.1430) teacher/entropy 0.0127 (0.0123) teacher/usage_max 0.9393 (0.9844) teacher/usage_min 0.0004 (0.0001) teacher/usage_std 0.4291 (0.4605) nleep/row_max_mean 1534.5334 (1549.4242) nleep/row_max_std 51.2440 (50.6495) nleep/row_min_mean 1493.7085 (1504.6837) lr 1.6374e-03 eta 0:15:36
epoch [16/50] batch [40/173] time 0.160 (0.149) data 0.000 (0.007) loss 1.3076 (1.2220) teacher_loss 0.3562 (0.2916) loss_zs_kd 0.0106 (0.0078) loss_oracle 0.6949 (0.5992) kd_loss 0.5986 (0.6269) acc 84.3750 (89.6094) gate/entropy 1.0104 (1.0116) gate/usage_max 0.5367 (0.5351) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1444 (0.1434) teacher/entropy 0.0406 (0.0118) teacher/usage_max 0.9779 (0.9826) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4559 (0.4593) nleep/row_max_mean 1556.6111 (1549.8130) nleep/row_max_std 51.9542 (51.2997) nleep/row_min_mean 1511.3494 (1504.2526) lr 1.6374e-03 eta 0:14:57
epoch [16/50] batch [60/173] time 0.143 (0.148) data 0.000 (0.005) loss 1.0818 (1.2223) teacher_loss 0.1196 (0.2903) loss_zs_kd 0.0086 (0.0076) loss_oracle 0.6761 (0.5998) kd_loss 0.6198 (0.6283) acc 96.8750 (89.4271) gate/entropy 1.0094 (1.0111) gate/usage_max 0.5379 (0.5358) gate/usage_min 0.2146 (0.2149) gate/usage_std 0.1453 (0.1438) teacher/entropy 0.0003 (0.0113) teacher/usage_max 1.0000 (0.9799) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4714 (0.4574) nleep/row_max_mean 1565.2729 (1552.7931) nleep/row_max_std 51.3475 (50.7824) nleep/row_min_mean 1516.6572 (1506.9488) lr 1.6374e-03 eta 0:14:44
epoch [16/50] batch [80/173] time 0.066 (0.147) data 0.000 (0.003) loss 1.0559 (1.2232) teacher_loss 0.2042 (0.2905) loss_zs_kd 0.0039 (0.0083) loss_oracle 0.4787 (0.6036) kd_loss 0.6104 (0.6268) acc 93.7500 (89.3750) gate/entropy 1.0096 (1.0106) gate/usage_max 0.5377 (0.5364) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1451 (0.1442) teacher/entropy 0.0205 (0.0103) teacher/usage_max 0.9886 (0.9818) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4634 (0.4587) nleep/row_max_mean 1530.9592 (1552.9307) nleep/row_max_std 52.1952 (50.8911) nleep/row_min_mean 1484.8198 (1506.9973) lr 1.6374e-03 eta 0:14:39
epoch [16/50] batch [100/173] time 0.151 (0.137) data 0.000 (0.003) loss 1.0581 (1.2327) teacher_loss 0.2017 (0.3031) loss_zs_kd 0.0024 (0.0082) loss_oracle 0.4764 (0.5994) kd_loss 0.6170 (0.6258) acc 90.6250 (88.8125) gate/entropy 1.0081 (1.0101) gate/usage_max 0.5396 (0.5370) gate/usage_min 0.2145 (0.2148) gate/usage_std 0.1464 (0.1447) teacher/entropy 0.0000 (0.0099) teacher/usage_max 1.0000 (0.9821) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4714 (0.4589) nleep/row_max_mean 1557.3525 (1553.0650) nleep/row_max_std 57.6360 (50.9530) nleep/row_min_mean 1507.5803 (1507.1940) lr 1.6374e-03 eta 0:13:34
epoch [16/50] batch [120/173] time 0.086 (0.133) data 0.000 (0.002) loss 1.0535 (1.2364) teacher_loss 0.0864 (0.3098) loss_zs_kd 0.0123 (0.0082) loss_oracle 0.6430 (0.5960) kd_loss 0.6395 (0.6245) acc 96.8750 (88.4115) gate/entropy 1.0073 (1.0097) gate/usage_max 0.5405 (0.5376) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1470 (0.1450) teacher/entropy 0.0007 (0.0092) teacher/usage_max 0.9688 (0.9832) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4496 (0.4597) nleep/row_max_mean 1539.0404 (1552.6459) nleep/row_max_std 54.4730 (51.5848) nleep/row_min_mean 1497.0725 (1506.6993) lr 1.6374e-03 eta 0:13:08
epoch [16/50] batch [140/173] time 0.190 (0.132) data 0.000 (0.002) loss 1.1198 (1.2333) teacher_loss 0.2685 (0.3114) loss_zs_kd 0.0114 (0.0081) loss_oracle 0.4687 (0.5904) kd_loss 0.6112 (0.6227) acc 87.5000 (88.0804) gate/entropy 1.0056 (1.0092) gate/usage_max 0.5426 (0.5382) gate/usage_min 0.2142 (0.2147) gate/usage_std 0.1484 (0.1454) teacher/entropy 0.0002 (0.0086) teacher/usage_max 1.0000 (0.9850) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4609) nleep/row_max_mean 1557.7299 (1553.4255) nleep/row_max_std 59.3005 (52.1446) nleep/row_min_mean 1508.4053 (1507.2238) lr 1.6374e-03 eta 0:12:57
epoch [16/50] batch [160/173] time 0.171 (0.131) data 0.000 (0.002) loss 1.2023 (1.2319) teacher_loss 0.2889 (0.3113) loss_zs_kd 0.0107 (0.0083) loss_oracle 0.5616 (0.5900) kd_loss 0.6273 (0.6214) acc 87.5000 (88.0273) gate/entropy 1.0050 (1.0087) gate/usage_max 0.5434 (0.5387) gate/usage_min 0.2142 (0.2146) gate/usage_std 0.1490 (0.1458) teacher/entropy 0.0072 (0.0085) teacher/usage_max 0.9692 (0.9854) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4498 (0.4612) nleep/row_max_mean 1568.2039 (1553.7985) nleep/row_max_std 50.1296 (52.3895) nleep/row_min_mean 1519.5479 (1507.4280) lr 1.6374e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.4%, epoch: 15 *******
******* Domain a best val test acc: 97.3%, epoch: 15 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [17/50] batch [20/173] time 0.081 (0.111) data 0.000 (0.016) loss 1.4194 (1.2328) teacher_loss 0.4970 (0.3256) loss_zs_kd 0.0067 (0.0062) loss_oracle 0.5764 (0.5877) kd_loss 0.6308 (0.6103) acc 75.0000 (87.9688) gate/entropy 1.0033 (1.0041) gate/usage_max 0.5455 (0.5445) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1504 (0.1498) teacher/entropy 0.0205 (0.0130) teacher/usage_max 0.9488 (0.9811) teacher/usage_min 0.0199 (0.0010) teacher/usage_std 0.4352 (0.4582) nleep/row_max_mean 1548.6687 (1557.1560) nleep/row_max_std 67.0858 (58.0101) nleep/row_min_mean 1500.4678 (1509.2323) lr 1.5878e-03 eta 0:10:50
epoch [17/50] batch [40/173] time 0.081 (0.115) data 0.000 (0.008) loss 1.3197 (1.2468) teacher_loss 0.3951 (0.3408) loss_zs_kd 0.0127 (0.0076) loss_oracle 0.6267 (0.5890) kd_loss 0.6049 (0.6077) acc 87.5000 (87.6562) gate/entropy 1.0027 (1.0037) gate/usage_max 0.5461 (0.5450) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1508 (0.1501) teacher/entropy 0.0000 (0.0097) teacher/usage_max 1.0000 (0.9873) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4714 (0.4625) nleep/row_max_mean 1555.9600 (1557.3525) nleep/row_max_std 53.2360 (57.0918) nleep/row_min_mean 1508.5447 (1508.7980) lr 1.5878e-03 eta 0:11:12
epoch [17/50] batch [60/173] time 0.130 (0.127) data 0.001 (0.005) loss 1.3617 (1.2391) teacher_loss 0.5002 (0.3290) loss_zs_kd 0.0176 (0.0078) loss_oracle 0.4999 (0.5987) kd_loss 0.6027 (0.6068) acc 84.3750 (88.1250) gate/entropy 1.0017 (1.0033) gate/usage_max 0.5473 (0.5455) gate/usage_min 0.2138 (0.2140) gate/usage_std 0.1517 (0.1504) teacher/entropy 0.0000 (0.0083) teacher/usage_max 1.0000 (0.9890) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4637) nleep/row_max_mean 1563.1375 (1554.8334) nleep/row_max_std 57.9975 (58.6290) nleep/row_min_mean 1513.6863 (1506.7241) lr 1.5878e-03 eta 0:12:20
epoch [17/50] batch [80/173] time 0.177 (0.135) data 0.000 (0.004) loss 0.9929 (1.2371) teacher_loss 0.1238 (0.3230) loss_zs_kd 0.0077 (0.0083) loss_oracle 0.5276 (0.6084) kd_loss 0.6015 (0.6058) acc 96.8750 (88.5938) gate/entropy 1.0012 (1.0029) gate/usage_max 0.5480 (0.5459) gate/usage_min 0.2137 (0.2140) gate/usage_std 0.1521 (0.1507) teacher/entropy 0.0000 (0.0089) teacher/usage_max 1.0000 (0.9887) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4714 (0.4635) nleep/row_max_mean 1577.5817 (1554.0719) nleep/row_max_std 51.5200 (57.8666) nleep/row_min_mean 1523.2181 (1505.9669) lr 1.5878e-03 eta 0:13:05
epoch [17/50] batch [100/173] time 0.143 (0.139) data 0.000 (0.003) loss 1.1819 (1.2330) teacher_loss 0.2466 (0.3164) loss_zs_kd 0.0065 (0.0086) loss_oracle 0.6174 (0.6133) kd_loss 0.6234 (0.6056) acc 90.6250 (88.6875) gate/entropy 1.0011 (1.0026) gate/usage_max 0.5481 (0.5462) gate/usage_min 0.2138 (0.2140) gate/usage_std 0.1522 (0.1509) teacher/entropy 0.0036 (0.0092) teacher/usage_max 0.9694 (0.9878) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4500 (0.4628) nleep/row_max_mean 1543.9653 (1553.2059) nleep/row_max_std 56.5007 (57.9256) nleep/row_min_mean 1498.6489 (1505.2798) lr 1.5878e-03 eta 0:13:25
epoch [17/50] batch [120/173] time 0.149 (0.139) data 0.000 (0.003) loss 1.1855 (1.2358) teacher_loss 0.2518 (0.3160) loss_zs_kd 0.0016 (0.0083) loss_oracle 0.6679 (0.6218) kd_loss 0.5988 (0.6047) acc 87.5000 (88.5417) gate/entropy 1.0000 (1.0023) gate/usage_max 0.5494 (0.5466) gate/usage_min 0.2136 (0.2139) gate/usage_std 0.1531 (0.1512) teacher/entropy 0.0001 (0.0093) teacher/usage_max 1.0000 (0.9880) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4630) nleep/row_max_mean 1557.0103 (1553.5290) nleep/row_max_std 58.7770 (57.3209) nleep/row_min_mean 1513.7577 (1505.7495) lr 1.5878e-03 eta 0:13:22
epoch [17/50] batch [140/173] time 0.152 (0.139) data 0.000 (0.002) loss 1.2240 (1.2359) teacher_loss 0.2905 (0.3158) loss_zs_kd 0.0032 (0.0082) loss_oracle 0.6687 (0.6241) kd_loss 0.5976 (0.6040) acc 87.5000 (88.3929) gate/entropy 0.9999 (1.0020) gate/usage_max 0.5495 (0.5470) gate/usage_min 0.2136 (0.2139) gate/usage_std 0.1531 (0.1515) teacher/entropy 0.0014 (0.0092) teacher/usage_max 0.9998 (0.9881) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4712 (0.4631) nleep/row_max_mean 1555.0862 (1553.6666) nleep/row_max_std 64.4879 (57.2837) nleep/row_min_mean 1506.8342 (1505.8924) lr 1.5878e-03 eta 0:13:19
epoch [17/50] batch [160/173] time 0.132 (0.140) data 0.000 (0.002) loss 1.2577 (1.2352) teacher_loss 0.3477 (0.3142) loss_zs_kd 0.0138 (0.0082) loss_oracle 0.6331 (0.6264) kd_loss 0.5865 (0.6038) acc 84.3750 (88.3789) gate/entropy 0.9991 (1.0017) gate/usage_max 0.5504 (0.5474) gate/usage_min 0.2134 (0.2138) gate/usage_std 0.1538 (0.1517) teacher/entropy 0.0223 (0.0090) teacher/usage_max 0.9861 (0.9878) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4616 (0.4629) nleep/row_max_mean 1568.3406 (1553.1461) nleep/row_max_std 40.1390 (57.5954) nleep/row_min_mean 1521.0271 (1505.4212) lr 1.5878e-03 eta 0:13:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      96.4%, epoch: 17 *******
******* Domain a best val test acc: 97.9%, epoch: 17 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [18/50] batch [20/173] time 0.125 (0.135) data 0.000 (0.015) loss 1.2039 (1.2250) teacher_loss 0.2400 (0.2785) loss_zs_kd 0.0200 (0.0092) loss_oracle 0.7154 (0.6794) kd_loss 0.5962 (0.6023) acc 84.3750 (88.1250) gate/entropy 0.9987 (0.9990) gate/usage_max 0.5509 (0.5505) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1541 (0.1538) teacher/entropy 0.0000 (0.0066) teacher/usage_max 1.0000 (0.9860) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4714 (0.4615) nleep/row_max_mean 1546.1433 (1551.4968) nleep/row_max_std 69.4992 (58.2122) nleep/row_min_mean 1498.9634 (1504.0511) lr 1.5358e-03 eta 0:12:50
epoch [18/50] batch [40/173] time 0.181 (0.122) data 0.000 (0.007) loss 1.2063 (1.2280) teacher_loss 0.2721 (0.2726) loss_zs_kd 0.0099 (0.0088) loss_oracle 0.6166 (0.6969) kd_loss 0.6210 (0.6026) acc 90.6250 (88.9844) gate/entropy 0.9985 (0.9988) gate/usage_max 0.5511 (0.5507) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1543 (0.1540) teacher/entropy 0.0012 (0.0084) teacher/usage_max 0.9689 (0.9830) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4496 (0.4595) nleep/row_max_mean 1534.4733 (1550.0935) nleep/row_max_std 63.5887 (59.6934) nleep/row_min_mean 1488.6996 (1502.7507) lr 1.5358e-03 eta 0:11:33
epoch [18/50] batch [60/173] time 0.064 (0.120) data 0.001 (0.005) loss 1.3895 (1.2338) teacher_loss 0.3726 (0.2764) loss_zs_kd 0.0055 (0.0084) loss_oracle 0.7446 (0.7044) kd_loss 0.6418 (0.6010) acc 78.1250 (88.8021) gate/entropy 0.9978 (0.9986) gate/usage_max 0.5519 (0.5510) gate/usage_min 0.2132 (0.2134) gate/usage_std 0.1548 (0.1542) teacher/entropy 0.0051 (0.0108) teacher/usage_max 0.9374 (0.9815) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4279 (0.4584) nleep/row_max_mean 1565.2324 (1550.3130) nleep/row_max_std 51.3854 (59.4376) nleep/row_min_mean 1516.3354 (1503.4786) lr 1.5358e-03 eta 0:11:20
epoch [18/50] batch [80/173] time 0.092 (0.112) data 0.000 (0.004) loss 1.1646 (1.2415) teacher_loss 0.2606 (0.2810) loss_zs_kd 0.0076 (0.0086) loss_oracle 0.5781 (0.7085) kd_loss 0.6112 (0.6021) acc 90.6250 (88.5938) gate/entropy 0.9981 (0.9984) gate/usage_max 0.5516 (0.5512) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1546 (0.1543) teacher/entropy 0.0386 (0.0152) teacher/usage_max 0.9349 (0.9746) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4262 (0.4537) nleep/row_max_mean 1538.8560 (1549.5396) nleep/row_max_std 65.0275 (59.2250) nleep/row_min_mean 1492.2247 (1503.2979) lr 1.5358e-03 eta 0:10:27
epoch [18/50] batch [100/173] time 0.095 (0.113) data 0.000 (0.003) loss 1.3513 (1.2452) teacher_loss 0.4402 (0.2875) loss_zs_kd 0.0072 (0.0085) loss_oracle 0.5764 (0.7032) kd_loss 0.6193 (0.6018) acc 84.3750 (88.4375) gate/entropy 0.9970 (0.9983) gate/usage_max 0.5528 (0.5514) gate/usage_min 0.2130 (0.2133) gate/usage_std 0.1555 (0.1544) teacher/entropy 0.0001 (0.0160) teacher/usage_max 0.9687 (0.9735) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4495 (0.4529) nleep/row_max_mean 1555.9249 (1549.2193) nleep/row_max_std 52.2423 (59.0209) nleep/row_min_mean 1512.7744 (1503.3286) lr 1.5358e-03 eta 0:10:33
epoch [18/50] batch [120/173] time 0.099 (0.112) data 0.000 (0.003) loss 1.1776 (1.2494) teacher_loss 0.2391 (0.2980) loss_zs_kd 0.0168 (0.0088) loss_oracle 0.5820 (0.6872) kd_loss 0.6391 (0.6034) acc 84.3750 (87.8646) gate/entropy 0.9973 (0.9981) gate/usage_max 0.5525 (0.5516) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1552 (0.1546) teacher/entropy 0.0071 (0.0162) teacher/usage_max 0.9371 (0.9710) teacher/usage_min 0.0003 (0.0013) teacher/usage_std 0.4277 (0.4512) nleep/row_max_mean 1542.6570 (1549.2663) nleep/row_max_std 65.4760 (58.2519) nleep/row_min_mean 1497.4310 (1503.6561) lr 1.5358e-03 eta 0:10:25
epoch [18/50] batch [140/173] time 0.090 (0.114) data 0.000 (0.002) loss 1.3099 (1.2449) teacher_loss 0.4420 (0.2973) loss_zs_kd 0.0091 (0.0087) loss_oracle 0.5686 (0.6808) kd_loss 0.5791 (0.6029) acc 90.6250 (88.0357) gate/entropy 0.9965 (0.9979) gate/usage_max 0.5534 (0.5518) gate/usage_min 0.2129 (0.2132) gate/usage_std 0.1558 (0.1547) teacher/entropy 0.0644 (0.0168) teacher/usage_max 0.9410 (0.9705) teacher/usage_min 0.0123 (0.0014) teacher/usage_std 0.4299 (0.4508) nleep/row_max_mean 1550.7686 (1549.2817) nleep/row_max_std 56.9252 (58.0819) nleep/row_min_mean 1510.8844 (1503.9509) lr 1.5358e-03 eta 0:10:32
epoch [18/50] batch [160/173] time 0.077 (0.114) data 0.000 (0.002) loss 1.1255 (1.2405) teacher_loss 0.0953 (0.2951) loss_zs_kd 0.0040 (0.0087) loss_oracle 0.7795 (0.6765) kd_loss 0.6385 (0.6029) acc 96.8750 (88.1445) gate/entropy 0.9964 (0.9977) gate/usage_max 0.5535 (0.5520) gate/usage_min 0.2129 (0.2132) gate/usage_std 0.1559 (0.1549) teacher/entropy 0.0058 (0.0165) teacher/usage_max 0.9385 (0.9706) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4286 (0.4509) nleep/row_max_mean 1548.5386 (1548.8805) nleep/row_max_std 65.0986 (58.4914) nleep/row_min_mean 1501.8972 (1503.6530) lr 1.5358e-03 eta 0:10:34
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,304
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [19/50] batch [20/173] time 0.164 (0.176) data 0.000 (0.013) loss 1.4189 (1.3345) teacher_loss 0.4378 (0.3402) loss_zs_kd 0.0102 (0.0091) loss_oracle 0.6640 (0.7278) kd_loss 0.6440 (0.6257) acc 81.2500 (88.1250) gate/entropy 0.9959 (0.9961) gate/usage_max 0.5540 (0.5538) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1563 (0.1561) teacher/entropy 0.0003 (0.0185) teacher/usage_max 0.9375 (0.9378) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4280 (0.4284) nleep/row_max_mean 1533.1418 (1543.0052) nleep/row_max_std 56.7617 (60.0684) nleep/row_min_mean 1494.3938 (1501.3780) lr 1.4818e-03 eta 0:16:09
epoch [19/50] batch [40/173] time 0.153 (0.168) data 0.000 (0.007) loss 1.2727 (1.3068) teacher_loss 0.3028 (0.3372) loss_zs_kd 0.0116 (0.0083) loss_oracle 0.6980 (0.6935) kd_loss 0.6151 (0.6187) acc 84.3750 (87.9688) gate/entropy 0.9954 (0.9960) gate/usage_max 0.5546 (0.5540) gate/usage_min 0.2126 (0.2128) gate/usage_std 0.1567 (0.1562) teacher/entropy 0.0053 (0.0184) teacher/usage_max 0.9675 (0.9460) teacher/usage_min 0.0012 (0.0015) teacher/usage_std 0.4486 (0.4340) nleep/row_max_mean 1560.7203 (1543.6789) nleep/row_max_std 50.7365 (57.9987) nleep/row_min_mean 1517.6189 (1502.0958) lr 1.4818e-03 eta 0:15:22
epoch [19/50] batch [60/173] time 0.166 (0.161) data 0.001 (0.004) loss 1.3994 (1.2892) teacher_loss 0.4135 (0.3233) loss_zs_kd 0.0124 (0.0085) loss_oracle 0.6739 (0.6809) kd_loss 0.6428 (0.6211) acc 84.3750 (88.2812) gate/entropy 0.9954 (0.9959) gate/usage_max 0.5546 (0.5541) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1567 (0.1563) teacher/entropy 0.0006 (0.0194) teacher/usage_max 0.9374 (0.9419) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4279 (0.4311) nleep/row_max_mean 1555.5718 (1544.5633) nleep/row_max_std 49.1624 (56.3556) nleep/row_min_mean 1512.1963 (1503.3065) lr 1.4818e-03 eta 0:14:41
epoch [19/50] batch [80/173] time 0.164 (0.161) data 0.000 (0.003) loss 1.1651 (1.2764) teacher_loss 0.2041 (0.3137) loss_zs_kd 0.0170 (0.0084) loss_oracle 0.6797 (0.6807) kd_loss 0.6127 (0.6181) acc 93.7500 (88.7109) gate/entropy 0.9952 (0.9958) gate/usage_max 0.5549 (0.5542) gate/usage_min 0.2125 (0.2127) gate/usage_std 0.1569 (0.1564) teacher/entropy 0.0034 (0.0201) teacher/usage_max 0.9682 (0.9445) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4491 (0.4329) nleep/row_max_mean 1553.5288 (1546.0490) nleep/row_max_std 52.0298 (55.7963) nleep/row_min_mean 1511.3573 (1504.7139) lr 1.4818e-03 eta 0:14:38
epoch [19/50] batch [100/173] time 0.073 (0.159) data 0.000 (0.003) loss 1.2730 (1.2782) teacher_loss 0.2735 (0.3151) loss_zs_kd 0.0204 (0.0085) loss_oracle 0.7054 (0.6811) kd_loss 0.6367 (0.6183) acc 87.5000 (88.3125) gate/entropy 0.9949 (0.9957) gate/usage_max 0.5552 (0.5543) gate/usage_min 0.2125 (0.2127) gate/usage_std 0.1571 (0.1565) teacher/entropy 0.0075 (0.0198) teacher/usage_max 0.9359 (0.9443) teacher/usage_min 0.0011 (0.0021) teacher/usage_std 0.4269 (0.4328) nleep/row_max_mean 1555.5947 (1546.3386) nleep/row_max_std 59.1246 (56.2537) nleep/row_min_mean 1515.1338 (1504.9791) lr 1.4818e-03 eta 0:14:24
epoch [19/50] batch [120/173] time 0.182 (0.152) data 0.000 (0.002) loss 1.2474 (1.2785) teacher_loss 0.2296 (0.3125) loss_zs_kd 0.0079 (0.0085) loss_oracle 0.7415 (0.6871) kd_loss 0.6430 (0.6182) acc 90.6250 (88.5156) gate/entropy 0.9952 (0.9956) gate/usage_max 0.5549 (0.5544) gate/usage_min 0.2125 (0.2126) gate/usage_std 0.1569 (0.1566) teacher/entropy 0.0200 (0.0203) teacher/usage_max 0.9142 (0.9437) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4122 (0.4324) nleep/row_max_mean 1540.1438 (1546.6196) nleep/row_max_std 54.3572 (55.7018) nleep/row_min_mean 1499.6924 (1505.2794) lr 1.4818e-03 eta 0:13:41
epoch [19/50] batch [140/173] time 0.203 (0.147) data 0.000 (0.002) loss 1.4590 (1.2865) teacher_loss 0.4033 (0.3136) loss_zs_kd 0.0111 (0.0084) loss_oracle 0.7087 (0.6981) kd_loss 0.6958 (0.6196) acc 87.5000 (88.4821) gate/entropy 0.9950 (0.9955) gate/usage_max 0.5551 (0.5545) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1570 (0.1566) teacher/entropy 0.0332 (0.0219) teacher/usage_max 0.8373 (0.9400) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3625 (0.4300) nleep/row_max_mean 1539.9436 (1545.9612) nleep/row_max_std 51.6114 (55.4286) nleep/row_min_mean 1503.6931 (1504.9111) lr 1.4818e-03 eta 0:13:14
epoch [19/50] batch [160/173] time 0.077 (0.143) data 0.000 (0.002) loss 1.2473 (1.2841) teacher_loss 0.3535 (0.3119) loss_zs_kd 0.0115 (0.0084) loss_oracle 0.5607 (0.6979) kd_loss 0.6077 (0.6190) acc 84.3750 (88.4375) gate/entropy 0.9947 (0.9954) gate/usage_max 0.5554 (0.5546) gate/usage_min 0.2123 (0.2126) gate/usage_std 0.1572 (0.1567) teacher/entropy 0.0091 (0.0228) teacher/usage_max 0.9666 (0.9395) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4480 (0.4296) nleep/row_max_mean 1549.3330 (1546.0666) nleep/row_max_std 46.3393 (54.7922) nleep/row_min_mean 1508.9771 (1505.0604) lr 1.4818e-03 eta 0:12:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,300
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [20/50] batch [20/173] time 0.075 (0.134) data 0.000 (0.013) loss 1.4788 (1.2861) teacher_loss 0.5424 (0.3045) loss_zs_kd 0.0170 (0.0116) loss_oracle 0.6328 (0.6911) kd_loss 0.6115 (0.6302) acc 84.3750 (88.4375) gate/entropy 0.9944 (0.9946) gate/usage_max 0.5557 (0.5555) gate/usage_min 0.2121 (0.2122) gate/usage_std 0.1575 (0.1573) teacher/entropy 0.0036 (0.0271) teacher/usage_max 0.9680 (0.9199) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4490 (0.4166) nleep/row_max_mean 1560.8330 (1545.6809) nleep/row_max_std 45.7048 (52.0533) nleep/row_min_mean 1514.6821 (1504.5388) lr 1.4258e-03 eta 0:11:53
epoch [20/50] batch [40/173] time 0.171 (0.125) data 0.000 (0.007) loss 1.3848 (1.2979) teacher_loss 0.4262 (0.3064) loss_zs_kd 0.0094 (0.0105) loss_oracle 0.6591 (0.7037) kd_loss 0.6243 (0.6344) acc 87.5000 (89.0625) gate/entropy 0.9943 (0.9947) gate/usage_max 0.5558 (0.5555) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1575 (0.1573) teacher/entropy 0.0151 (0.0305) teacher/usage_max 0.9399 (0.9112) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4296 (0.4108) nleep/row_max_mean 1559.0378 (1544.5633) nleep/row_max_std 52.1261 (51.5847) nleep/row_min_mean 1512.8335 (1503.9457) lr 1.4258e-03 eta 0:11:07
epoch [20/50] batch [60/173] time 0.091 (0.120) data 0.001 (0.005) loss 1.4401 (1.3000) teacher_loss 0.5670 (0.3060) loss_zs_kd 0.0056 (0.0114) loss_oracle 0.5895 (0.6994) kd_loss 0.5756 (0.6386) acc 75.0000 (88.8542) gate/entropy 0.9942 (0.9946) gate/usage_max 0.5559 (0.5555) gate/usage_min 0.2119 (0.2121) gate/usage_std 0.1576 (0.1573) teacher/entropy 0.0360 (0.0334) teacher/usage_max 0.9719 (0.9032) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.4517 (0.4054) nleep/row_max_mean 1558.4268 (1543.1696) nleep/row_max_std 47.4407 (51.4632) nleep/row_min_mean 1516.7152 (1503.1765) lr 1.4258e-03 eta 0:10:35
epoch [20/50] batch [80/173] time 0.140 (0.130) data 0.000 (0.003) loss 1.3674 (1.3008) teacher_loss 0.3396 (0.3009) loss_zs_kd 0.0109 (0.0104) loss_oracle 0.7345 (0.7034) kd_loss 0.6551 (0.6429) acc 87.5000 (88.9062) gate/entropy 0.9949 (0.9946) gate/usage_max 0.5552 (0.5555) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1571 (0.1573) teacher/entropy 0.0365 (0.0343) teacher/usage_max 0.8816 (0.8972) teacher/usage_min 0.0013 (0.0031) teacher/usage_std 0.3905 (0.4014) nleep/row_max_mean 1538.1812 (1543.9141) nleep/row_max_std 56.4363 (50.8368) nleep/row_min_mean 1498.7783 (1504.1238) lr 1.4258e-03 eta 0:11:24
epoch [20/50] batch [100/173] time 0.164 (0.136) data 0.000 (0.003) loss 1.2249 (1.3052) teacher_loss 0.1966 (0.3037) loss_zs_kd 0.0074 (0.0104) loss_oracle 0.7005 (0.7055) kd_loss 0.6743 (0.6436) acc 93.7500 (88.5938) gate/entropy 0.9945 (0.9946) gate/usage_max 0.5556 (0.5555) gate/usage_min 0.2118 (0.2120) gate/usage_std 0.1574 (0.1573) teacher/entropy 0.0346 (0.0346) teacher/usage_max 0.8601 (0.8960) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.3769 (0.4006) nleep/row_max_mean 1540.0577 (1544.4362) nleep/row_max_std 62.0763 (50.9275) nleep/row_min_mean 1500.3916 (1504.7200) lr 1.4258e-03 eta 0:11:58
epoch [20/50] batch [120/173] time 0.167 (0.141) data 0.000 (0.002) loss 1.1534 (1.3043) teacher_loss 0.1614 (0.2996) loss_zs_kd 0.0070 (0.0097) loss_oracle 0.7383 (0.7084) kd_loss 0.6193 (0.6457) acc 96.8750 (88.8021) gate/entropy 0.9949 (0.9946) gate/usage_max 0.5551 (0.5555) gate/usage_min 0.2118 (0.2120) gate/usage_std 0.1570 (0.1573) teacher/entropy 0.0753 (0.0383) teacher/usage_max 0.8773 (0.8894) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.3879 (0.3963) nleep/row_max_mean 1536.2576 (1543.9100) nleep/row_max_std 55.7771 (51.5006) nleep/row_min_mean 1493.8286 (1504.4711) lr 1.4258e-03 eta 0:12:18
epoch [20/50] batch [140/173] time 0.161 (0.144) data 0.000 (0.002) loss 1.2886 (1.3053) teacher_loss 0.3939 (0.3016) loss_zs_kd 0.0102 (0.0098) loss_oracle 0.5427 (0.7017) kd_loss 0.6182 (0.6480) acc 84.3750 (88.7054) gate/entropy 0.9943 (0.9946) gate/usage_max 0.5558 (0.5555) gate/usage_min 0.2116 (0.2119) gate/usage_std 0.1575 (0.1573) teacher/entropy 0.0378 (0.0373) teacher/usage_max 0.9276 (0.8879) teacher/usage_min 0.0102 (0.0033) teacher/usage_std 0.4207 (0.3953) nleep/row_max_mean 1537.7909 (1543.8285) nleep/row_max_std 49.0881 (51.8955) nleep/row_min_mean 1501.2981 (1504.5030) lr 1.4258e-03 eta 0:12:30
epoch [20/50] batch [160/173] time 0.163 (0.146) data 0.000 (0.002) loss 1.3912 (1.3067) teacher_loss 0.2910 (0.3059) loss_zs_kd 0.0127 (0.0099) loss_oracle 0.7456 (0.6938) kd_loss 0.7210 (0.6489) acc 90.6250 (88.5352) gate/entropy 0.9949 (0.9946) gate/usage_max 0.5551 (0.5555) gate/usage_min 0.2116 (0.2119) gate/usage_std 0.1571 (0.1573) teacher/entropy 0.0029 (0.0382) teacher/usage_max 0.8435 (0.8858) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.3663 (0.3939) nleep/row_max_mean 1535.3550 (1544.3416) nleep/row_max_std 63.5904 (52.2422) nleep/row_min_mean 1495.5005 (1504.8903) lr 1.4258e-03 eta 0:12:38
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [21/50] batch [20/173] time 0.165 (0.128) data 0.000 (0.014) loss 1.2541 (1.3710) teacher_loss 0.3573 (0.3291) loss_zs_kd 0.0136 (0.0107) loss_oracle 0.6173 (0.6885) kd_loss 0.5814 (0.6923) acc 87.5000 (87.5000) gate/entropy 0.9941 (0.9946) gate/usage_max 0.5560 (0.5554) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1577 (0.1573) teacher/entropy 0.0920 (0.0558) teacher/usage_max 0.9009 (0.8155) teacher/usage_min 0.0055 (0.0037) teacher/usage_std 0.4029 (0.3506) nleep/row_max_mean 1566.3553 (1547.0675) nleep/row_max_std 60.3872 (52.8379) nleep/row_min_mean 1522.2693 (1507.5190) lr 1.3681e-03 eta 0:11:03
epoch [21/50] batch [40/173] time 0.172 (0.125) data 0.000 (0.007) loss 1.1845 (1.3328) teacher_loss 0.3522 (0.3043) loss_zs_kd 0.0112 (0.0110) loss_oracle 0.4861 (0.6613) kd_loss 0.5837 (0.6924) acc 87.5000 (88.3594) gate/entropy 0.9948 (0.9946) gate/usage_max 0.5551 (0.5554) gate/usage_min 0.2113 (0.2114) gate/usage_std 0.1571 (0.1573) teacher/entropy 0.0850 (0.0549) teacher/usage_max 0.9074 (0.8166) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.4077 (0.3507) nleep/row_max_mean 1543.8433 (1545.4416) nleep/row_max_std 48.8743 (55.0529) nleep/row_min_mean 1508.0903 (1506.1654) lr 1.3681e-03 eta 0:10:45
epoch [21/50] batch [60/173] time 0.076 (0.123) data 0.001 (0.005) loss 1.3260 (1.3384) teacher_loss 0.2373 (0.3078) loss_zs_kd 0.0106 (0.0119) loss_oracle 0.7482 (0.6635) kd_loss 0.7094 (0.6928) acc 93.7500 (88.0208) gate/entropy 0.9952 (0.9947) gate/usage_max 0.5548 (0.5553) gate/usage_min 0.2112 (0.2113) gate/usage_std 0.1568 (0.1572) teacher/entropy 0.1200 (0.0543) teacher/usage_max 0.7220 (0.8166) teacher/usage_min 0.0005 (0.0031) teacher/usage_std 0.2972 (0.3512) nleep/row_max_mean 1527.4226 (1545.0128) nleep/row_max_std 51.0794 (55.6647) nleep/row_min_mean 1489.5496 (1505.4236) lr 1.3681e-03 eta 0:10:31
epoch [21/50] batch [80/173] time 0.083 (0.119) data 0.000 (0.004) loss 1.2904 (1.3476) teacher_loss 0.1048 (0.3022) loss_zs_kd 0.0016 (0.0114) loss_oracle 0.9099 (0.6855) kd_loss 0.7298 (0.6970) acc 96.8750 (88.3984) gate/entropy 0.9951 (0.9948) gate/usage_max 0.5549 (0.5552) gate/usage_min 0.2110 (0.2113) gate/usage_std 0.1569 (0.1572) teacher/entropy 0.0588 (0.0523) teacher/usage_max 0.7687 (0.8142) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3220 (0.3496) nleep/row_max_mean 1551.1415 (1544.6310) nleep/row_max_std 66.5588 (56.4979) nleep/row_min_mean 1508.8235 (1504.7337) lr 1.3681e-03 eta 0:10:05
epoch [21/50] batch [100/173] time 0.096 (0.118) data 0.000 (0.003) loss 1.4427 (1.3453) teacher_loss 0.2722 (0.2932) loss_zs_kd 0.0161 (0.0113) loss_oracle 0.7978 (0.6944) kd_loss 0.7636 (0.6992) acc 90.6250 (88.9688) gate/entropy 0.9954 (0.9948) gate/usage_max 0.5545 (0.5551) gate/usage_min 0.2109 (0.2112) gate/usage_std 0.1567 (0.1571) teacher/entropy 0.0640 (0.0529) teacher/usage_max 0.7244 (0.8108) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2985 (0.3478) nleep/row_max_mean 1544.4854 (1544.2932) nleep/row_max_std 46.7119 (56.4210) nleep/row_min_mean 1506.5968 (1504.3046) lr 1.3681e-03 eta 0:10:01
epoch [21/50] batch [120/173] time 0.080 (0.118) data 0.000 (0.003) loss 1.5253 (1.3648) teacher_loss 0.1854 (0.2979) loss_zs_kd 0.0168 (0.0118) loss_oracle 0.9566 (0.7110) kd_loss 0.8531 (0.7055) acc 90.6250 (88.8021) gate/entropy 0.9958 (0.9949) gate/usage_max 0.5540 (0.5550) gate/usage_min 0.2107 (0.2111) gate/usage_std 0.1563 (0.1570) teacher/entropy 0.0396 (0.0516) teacher/usage_max 0.6466 (0.8052) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2644 (0.3445) nleep/row_max_mean 1538.1382 (1544.3650) nleep/row_max_std 63.9379 (56.6892) nleep/row_min_mean 1497.1259 (1504.2791) lr 1.3681e-03 eta 0:10:00
epoch [21/50] batch [140/173] time 0.175 (0.121) data 0.000 (0.002) loss 1.3125 (1.3741) teacher_loss 0.2192 (0.2967) loss_zs_kd 0.0224 (0.0122) loss_oracle 0.8474 (0.7253) kd_loss 0.6583 (0.7087) acc 93.7500 (88.8839) gate/entropy 0.9959 (0.9950) gate/usage_max 0.5538 (0.5549) gate/usage_min 0.2105 (0.2111) gate/usage_std 0.1562 (0.1570) teacher/entropy 0.0771 (0.0511) teacher/usage_max 0.8315 (0.8021) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3589 (0.3429) nleep/row_max_mean 1551.6931 (1545.2673) nleep/row_max_std 58.4773 (56.8851) nleep/row_min_mean 1511.7100 (1504.7308) lr 1.3681e-03 eta 0:10:09
epoch [21/50] batch [160/173] time 0.194 (0.121) data 0.000 (0.002) loss 1.5564 (1.3829) teacher_loss 0.3057 (0.2924) loss_zs_kd 0.0221 (0.0126) loss_oracle 0.8621 (0.7337) kd_loss 0.8086 (0.7174) acc 87.5000 (89.0234) gate/entropy 0.9964 (0.9952) gate/usage_max 0.5533 (0.5547) gate/usage_min 0.2103 (0.2110) gate/usage_std 0.1559 (0.1568) teacher/entropy 0.0496 (0.0511) teacher/usage_max 0.6867 (0.7920) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2807 (0.3374) nleep/row_max_mean 1538.2561 (1545.3104) nleep/row_max_std 47.1214 (56.3578) nleep/row_min_mean 1500.0896 (1504.7698) lr 1.3681e-03 eta 0:10:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,282
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.7%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [22/50] batch [20/173] time 0.187 (0.169) data 0.000 (0.015) loss 1.1510 (1.4118) teacher_loss 0.0857 (0.2474) loss_zs_kd 0.0032 (0.0121) loss_oracle 0.7635 (0.7814) kd_loss 0.6820 (0.7676) acc 96.8750 (92.1875) gate/entropy 0.9976 (0.9969) gate/usage_max 0.5517 (0.5525) gate/usage_min 0.2099 (0.2100) gate/usage_std 0.1548 (0.1554) teacher/entropy 0.0499 (0.0468) teacher/usage_max 0.8415 (0.7383) teacher/usage_min 0.0312 (0.0029) teacher/usage_std 0.3615 (0.3081) nleep/row_max_mean 1541.8362 (1549.6123) nleep/row_max_std 61.8074 (56.5732) nleep/row_min_mean 1499.2539 (1508.8774) lr 1.3090e-03 eta 0:14:06
epoch [22/50] batch [40/173] time 0.153 (0.154) data 0.000 (0.007) loss 1.5001 (1.4547) teacher_loss 0.3572 (0.2740) loss_zs_kd 0.0123 (0.0134) loss_oracle 0.8402 (0.8058) kd_loss 0.7166 (0.7710) acc 87.5000 (90.7812) gate/entropy 0.9979 (0.9972) gate/usage_max 0.5513 (0.5522) gate/usage_min 0.2096 (0.2099) gate/usage_std 0.1546 (0.1552) teacher/entropy 0.0538 (0.0446) teacher/usage_max 0.7900 (0.7363) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3341 (0.3077) nleep/row_max_mean 1538.0861 (1550.3715) nleep/row_max_std 57.8727 (54.2766) nleep/row_min_mean 1499.3633 (1509.3996) lr 1.3090e-03 eta 0:12:46
epoch [22/50] batch [60/173] time 0.151 (0.152) data 0.001 (0.005) loss 1.4184 (1.4680) teacher_loss 0.0908 (0.2716) loss_zs_kd 0.0104 (0.0135) loss_oracle 0.9100 (0.8261) kd_loss 0.8675 (0.7766) acc 96.8750 (90.8333) gate/entropy 0.9986 (0.9975) gate/usage_max 0.5505 (0.5518) gate/usage_min 0.2093 (0.2097) gate/usage_std 0.1540 (0.1549) teacher/entropy 0.0379 (0.0445) teacher/usage_max 0.6270 (0.7297) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2575 (0.3044) nleep/row_max_mean 1551.0892 (1549.9106) nleep/row_max_std 48.6344 (53.1854) nleep/row_min_mean 1510.3167 (1509.1583) lr 1.3090e-03 eta 0:12:32
epoch [22/50] batch [80/173] time 0.134 (0.151) data 0.000 (0.004) loss 1.4720 (1.4647) teacher_loss 0.3107 (0.2714) loss_zs_kd 0.0177 (0.0140) loss_oracle 0.7772 (0.8158) kd_loss 0.7638 (0.7784) acc 87.5000 (90.3906) gate/entropy 0.9991 (0.9978) gate/usage_max 0.5497 (0.5514) gate/usage_min 0.2090 (0.2096) gate/usage_std 0.1536 (0.1547) teacher/entropy 0.0314 (0.0434) teacher/usage_max 0.7610 (0.7289) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.3178 (0.3038) nleep/row_max_mean 1542.8391 (1548.0619) nleep/row_max_std 44.8162 (53.2209) nleep/row_min_mean 1507.0193 (1507.7396) lr 1.3090e-03 eta 0:12:27
epoch [22/50] batch [100/173] time 0.091 (0.147) data 0.000 (0.003) loss 1.6235 (1.4619) teacher_loss 0.2457 (0.2774) loss_zs_kd 0.0024 (0.0142) loss_oracle 0.9238 (0.8009) kd_loss 0.9147 (0.7770) acc 87.5000 (89.8750) gate/entropy 0.9993 (0.9981) gate/usage_max 0.5494 (0.5510) gate/usage_min 0.2087 (0.2094) gate/usage_std 0.1534 (0.1544) teacher/entropy 0.0681 (0.0419) teacher/usage_max 0.5320 (0.7323) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2371 (0.3059) nleep/row_max_mean 1552.2222 (1547.8834) nleep/row_max_std 58.9977 (53.6011) nleep/row_min_mean 1514.6589 (1507.8705) lr 1.3090e-03 eta 0:12:01
epoch [22/50] batch [120/173] time 0.086 (0.140) data 0.000 (0.003) loss 1.3752 (1.4656) teacher_loss 0.2218 (0.2791) loss_zs_kd 0.0211 (0.0142) loss_oracle 0.7245 (0.8014) kd_loss 0.7805 (0.7787) acc 93.7500 (89.8177) gate/entropy 1.0003 (0.9984) gate/usage_max 0.5483 (0.5507) gate/usage_min 0.2084 (0.2093) gate/usage_std 0.1526 (0.1542) teacher/entropy 0.0214 (0.0404) teacher/usage_max 0.7527 (0.7320) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.3133 (0.3058) nleep/row_max_mean 1528.4462 (1547.2349) nleep/row_max_std 48.1452 (53.3909) nleep/row_min_mean 1491.8317 (1507.3430) lr 1.3090e-03 eta 0:11:27
epoch [22/50] batch [140/173] time 0.099 (0.136) data 0.000 (0.002) loss 1.4103 (1.4673) teacher_loss 0.1299 (0.2783) loss_zs_kd 0.0106 (0.0142) loss_oracle 0.7947 (0.8026) kd_loss 0.8778 (0.7806) acc 93.7500 (89.8884) gate/entropy 1.0009 (0.9987) gate/usage_max 0.5474 (0.5503) gate/usage_min 0.2081 (0.2091) gate/usage_std 0.1521 (0.1540) teacher/entropy 0.0005 (0.0388) teacher/usage_max 0.6563 (0.7315) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2680 (0.3055) nleep/row_max_mean 1544.2119 (1547.2816) nleep/row_max_std 51.7896 (52.9972) nleep/row_min_mean 1505.4651 (1507.5683) lr 1.3090e-03 eta 0:11:05
epoch [22/50] batch [160/173] time 0.078 (0.134) data 0.000 (0.002) loss 1.6671 (1.4625) teacher_loss 0.3653 (0.2796) loss_zs_kd 0.0086 (0.0146) loss_oracle 0.7325 (0.7943) kd_loss 0.9313 (0.7784) acc 81.2500 (89.8047) gate/entropy 1.0010 (0.9990) gate/usage_max 0.5472 (0.5499) gate/usage_min 0.2078 (0.2090) gate/usage_std 0.1520 (0.1537) teacher/entropy 0.0391 (0.0376) teacher/usage_max 0.5423 (0.7356) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2382 (0.3079) nleep/row_max_mean 1548.1274 (1546.8014) nleep/row_max_std 50.3760 (52.4730) nleep/row_min_mean 1514.2247 (1507.1957) lr 1.3090e-03 eta 0:10:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [23/50] batch [20/173] time 0.155 (0.145) data 0.000 (0.018) loss 1.5232 (1.4527) teacher_loss 0.3053 (0.2919) loss_zs_kd 0.0265 (0.0198) loss_oracle 0.8540 (0.7516) kd_loss 0.7777 (0.7751) acc 90.6250 (89.3750) gate/entropy 1.0019 (1.0018) gate/usage_max 0.5460 (0.5462) gate/usage_min 0.2073 (0.2075) gate/usage_std 0.1512 (0.1513) teacher/entropy 0.0307 (0.0380) teacher/usage_max 0.7433 (0.7387) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3083 (0.3084) nleep/row_max_mean 1535.6750 (1540.1941) nleep/row_max_std 57.0484 (50.1581) nleep/row_min_mean 1497.4387 (1502.7746) lr 1.2487e-03 eta 0:11:41
epoch [23/50] batch [40/173] time 0.087 (0.131) data 0.000 (0.009) loss 1.4271 (1.4235) teacher_loss 0.3803 (0.2723) loss_zs_kd 0.0226 (0.0178) loss_oracle 0.6942 (0.7466) kd_loss 0.6884 (0.7690) acc 84.3750 (89.7656) gate/entropy 1.0024 (1.0020) gate/usage_max 0.5453 (0.5458) gate/usage_min 0.2070 (0.2073) gate/usage_std 0.1508 (0.1511) teacher/entropy 0.0385 (0.0342) teacher/usage_max 0.8478 (0.7515) teacher/usage_min 0.0014 (0.0046) teacher/usage_std 0.3689 (0.3142) nleep/row_max_mean 1548.1047 (1538.9876) nleep/row_max_std 43.6228 (51.3614) nleep/row_min_mean 1509.1216 (1501.3244) lr 1.2487e-03 eta 0:10:31
epoch [23/50] batch [60/173] time 0.155 (0.132) data 0.001 (0.006) loss 1.2223 (1.4203) teacher_loss 0.1288 (0.2627) loss_zs_kd 0.0083 (0.0165) loss_oracle 0.7395 (0.7526) kd_loss 0.7195 (0.7731) acc 96.8750 (90.2604) gate/entropy 1.0033 (1.0023) gate/usage_max 0.5440 (0.5454) gate/usage_min 0.2068 (0.2072) gate/usage_std 0.1500 (0.1509) teacher/entropy 0.0231 (0.0323) teacher/usage_max 0.8283 (0.7486) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.3569 (0.3132) nleep/row_max_mean 1542.7543 (1540.9656) nleep/row_max_std 54.0863 (52.2009) nleep/row_min_mean 1504.5745 (1502.7557) lr 1.2487e-03 eta 0:10:32
epoch [23/50] batch [80/173] time 0.164 (0.137) data 0.000 (0.005) loss 1.3583 (1.4341) teacher_loss 0.2136 (0.2741) loss_zs_kd 0.0116 (0.0164) loss_oracle 0.6711 (0.7469) kd_loss 0.8034 (0.7783) acc 93.7500 (89.6094) gate/entropy 1.0036 (1.0026) gate/usage_max 0.5435 (0.5451) gate/usage_min 0.2064 (0.2070) gate/usage_std 0.1497 (0.1506) teacher/entropy 0.0432 (0.0336) teacher/usage_max 0.6957 (0.7402) teacher/usage_min 0.0099 (0.0041) teacher/usage_std 0.2813 (0.3087) nleep/row_max_mean 1550.2485 (1543.0513) nleep/row_max_std 53.7584 (52.4911) nleep/row_min_mean 1512.3015 (1504.6482) lr 1.2487e-03 eta 0:10:52
epoch [23/50] batch [100/173] time 0.156 (0.140) data 0.000 (0.004) loss 1.2802 (1.4177) teacher_loss 0.1087 (0.2636) loss_zs_kd 0.0121 (0.0161) loss_oracle 0.6882 (0.7402) kd_loss 0.8214 (0.7759) acc 96.8750 (89.7500) gate/entropy 1.0040 (1.0029) gate/usage_max 0.5429 (0.5447) gate/usage_min 0.2061 (0.2069) gate/usage_std 0.1494 (0.1504) teacher/entropy 0.0535 (0.0345) teacher/usage_max 0.6573 (0.7420) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2684 (0.3097) nleep/row_max_mean 1555.3208 (1543.7941) nleep/row_max_std 56.5844 (53.8151) nleep/row_min_mean 1518.0300 (1505.1236) lr 1.2487e-03 eta 0:11:05
epoch [23/50] batch [120/173] time 0.169 (0.142) data 0.000 (0.003) loss 1.3925 (1.4208) teacher_loss 0.3009 (0.2646) loss_zs_kd 0.0061 (0.0161) loss_oracle 0.6783 (0.7358) kd_loss 0.7494 (0.7802) acc 87.5000 (89.9479) gate/entropy 1.0047 (1.0031) gate/usage_max 0.5421 (0.5443) gate/usage_min 0.2058 (0.2067) gate/usage_std 0.1488 (0.1502) teacher/entropy 0.0057 (0.0331) teacher/usage_max 0.8125 (0.7381) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3474 (0.3082) nleep/row_max_mean 1541.9147 (1542.9760) nleep/row_max_std 74.9734 (54.8767) nleep/row_min_mean 1501.5938 (1504.4459) lr 1.2487e-03 eta 0:11:12
epoch [23/50] batch [140/173] time 0.161 (0.146) data 0.000 (0.003) loss 1.4399 (1.4208) teacher_loss 0.2953 (0.2657) loss_zs_kd 0.0202 (0.0157) loss_oracle 0.6792 (0.7343) kd_loss 0.7949 (0.7801) acc 90.6250 (89.7768) gate/entropy 1.0053 (1.0034) gate/usage_max 0.5411 (0.5439) gate/usage_min 0.2055 (0.2066) gate/usage_std 0.1482 (0.1499) teacher/entropy 0.0310 (0.0329) teacher/usage_max 0.7230 (0.7385) teacher/usage_min 0.0009 (0.0028) teacher/usage_std 0.2976 (0.3084) nleep/row_max_mean 1532.8004 (1542.8467) nleep/row_max_std 59.5896 (55.7032) nleep/row_min_mean 1497.2539 (1504.3308) lr 1.2487e-03 eta 0:11:24
epoch [23/50] batch [160/173] time 0.164 (0.146) data 0.000 (0.002) loss 1.2735 (1.4245) teacher_loss 0.1186 (0.2685) loss_zs_kd 0.0100 (0.0157) loss_oracle 0.8418 (0.7384) kd_loss 0.7291 (0.7789) acc 93.7500 (89.6680) gate/entropy 1.0060 (1.0036) gate/usage_max 0.5402 (0.5435) gate/usage_min 0.2051 (0.2064) gate/usage_std 0.1476 (0.1497) teacher/entropy 0.0511 (0.0326) teacher/usage_max 0.7809 (0.7405) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.3288 (0.3096) nleep/row_max_mean 1545.9243 (1542.5136) nleep/row_max_std 78.7315 (56.3899) nleep/row_min_mean 1505.3706 (1503.9745) lr 1.2487e-03 eta 0:11:21
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [24/50] batch [20/173] time 0.072 (0.135) data 0.000 (0.015) loss 1.6646 (1.4525) teacher_loss 0.4751 (0.2675) loss_zs_kd 0.0203 (0.0170) loss_oracle 0.7667 (0.7771) kd_loss 0.7960 (0.7880) acc 78.1250 (90.0000) gate/entropy 1.0069 (1.0066) gate/usage_max 0.5388 (0.5392) gate/usage_min 0.2045 (0.2047) gate/usage_std 0.1468 (0.1471) teacher/entropy 0.0087 (0.0211) teacher/usage_max 0.7487 (0.7429) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.3111 (0.3110) nleep/row_max_mean 1541.8428 (1541.8910) nleep/row_max_std 60.6948 (59.1179) nleep/row_min_mean 1503.8447 (1502.5342) lr 1.1874e-03 eta 0:10:28
epoch [24/50] batch [40/173] time 0.075 (0.127) data 0.000 (0.007) loss 1.6397 (1.4789) teacher_loss 0.3976 (0.2862) loss_zs_kd 0.0208 (0.0167) loss_oracle 0.8447 (0.7918) kd_loss 0.8094 (0.7884) acc 84.3750 (89.1406) gate/entropy 1.0075 (1.0069) gate/usage_max 0.5377 (0.5387) gate/usage_min 0.2040 (0.2045) gate/usage_std 0.1462 (0.1468) teacher/entropy 0.0229 (0.0259) teacher/usage_max 0.7104 (0.7357) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.2917 (0.3083) nleep/row_max_mean 1534.8948 (1542.4303) nleep/row_max_std 62.6541 (59.2906) nleep/row_min_mean 1499.2318 (1503.2051) lr 1.1874e-03 eta 0:09:46
epoch [24/50] batch [60/173] time 0.080 (0.123) data 0.000 (0.005) loss 1.4578 (1.4842) teacher_loss 0.2448 (0.2916) loss_zs_kd 0.0204 (0.0161) loss_oracle 0.8133 (0.7941) kd_loss 0.7962 (0.7875) acc 90.6250 (89.1146) gate/entropy 1.0082 (1.0073) gate/usage_max 0.5367 (0.5382) gate/usage_min 0.2036 (0.2042) gate/usage_std 0.1456 (0.1465) teacher/entropy 0.0222 (0.0275) teacher/usage_max 0.7294 (0.7347) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.3011 (0.3073) nleep/row_max_mean 1553.3776 (1543.4394) nleep/row_max_std 56.4667 (58.1450) nleep/row_min_mean 1513.7823 (1504.6563) lr 1.1874e-03 eta 0:09:28
epoch [24/50] batch [80/173] time 0.109 (0.119) data 0.001 (0.004) loss 1.2661 (1.4852) teacher_loss 0.2078 (0.2943) loss_zs_kd 0.0090 (0.0167) loss_oracle 0.7040 (0.7883) kd_loss 0.7018 (0.7884) acc 90.6250 (88.5938) gate/entropy 1.0093 (1.0076) gate/usage_max 0.5349 (0.5375) gate/usage_min 0.2031 (0.2040) gate/usage_std 0.1445 (0.1461) teacher/entropy 0.0117 (0.0271) teacher/usage_max 0.8765 (0.7344) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.3874 (0.3066) nleep/row_max_mean 1527.2976 (1542.3445) nleep/row_max_std 67.5627 (57.1169) nleep/row_min_mean 1491.0671 (1504.1557) lr 1.1874e-03 eta 0:09:04
epoch [24/50] batch [100/173] time 0.099 (0.119) data 0.000 (0.003) loss 1.4934 (1.4866) teacher_loss 0.1347 (0.2927) loss_zs_kd 0.0136 (0.0162) loss_oracle 0.8744 (0.7854) kd_loss 0.9147 (0.7931) acc 93.7500 (88.8438) gate/entropy 1.0102 (1.0080) gate/usage_max 0.5335 (0.5370) gate/usage_min 0.2026 (0.2038) gate/usage_std 0.1437 (0.1458) teacher/entropy 0.0494 (0.0272) teacher/usage_max 0.5230 (0.7275) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2365 (0.3032) nleep/row_max_mean 1534.4229 (1542.2096) nleep/row_max_std 56.8612 (56.5160) nleep/row_min_mean 1500.6775 (1504.2332) lr 1.1874e-03 eta 0:09:03
epoch [24/50] batch [120/173] time 0.092 (0.119) data 0.000 (0.003) loss 1.4775 (1.4778) teacher_loss 0.2674 (0.2814) loss_zs_kd 0.0080 (0.0157) loss_oracle 0.7954 (0.7861) kd_loss 0.8083 (0.7956) acc 87.5000 (89.4010) gate/entropy 1.0107 (1.0084) gate/usage_max 0.5325 (0.5363) gate/usage_min 0.2020 (0.2035) gate/usage_std 0.1432 (0.1454) teacher/entropy 0.0230 (0.0268) teacher/usage_max 0.7104 (0.7246) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2917 (0.3015) nleep/row_max_mean 1537.3784 (1542.2931) nleep/row_max_std 68.6217 (56.5261) nleep/row_min_mean 1498.1984 (1504.5367) lr 1.1874e-03 eta 0:09:00
epoch [24/50] batch [140/173] time 0.171 (0.119) data 0.000 (0.002) loss 1.4486 (1.4780) teacher_loss 0.2315 (0.2798) loss_zs_kd 0.0199 (0.0157) loss_oracle 0.8216 (0.7884) kd_loss 0.7964 (0.7963) acc 90.6250 (89.4643) gate/entropy 1.0114 (1.0088) gate/usage_max 0.5313 (0.5357) gate/usage_min 0.2014 (0.2033) gate/usage_std 0.1425 (0.1450) teacher/entropy 0.0078 (0.0262) teacher/usage_max 0.7489 (0.7246) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.3112 (0.3015) nleep/row_max_mean 1541.8940 (1542.2305) nleep/row_max_std 62.4635 (56.1133) nleep/row_min_mean 1504.5894 (1504.6497) lr 1.1874e-03 eta 0:09:01
epoch [24/50] batch [160/173] time 0.123 (0.119) data 0.000 (0.002) loss 1.9083 (1.4763) teacher_loss 0.5925 (0.2791) loss_zs_kd 0.0323 (0.0162) loss_oracle 0.9205 (0.7859) kd_loss 0.8394 (0.7962) acc 78.1250 (89.4336) gate/entropy 1.0125 (1.0092) gate/usage_max 0.5294 (0.5350) gate/usage_min 0.2008 (0.2030) gate/usage_std 0.1415 (0.1446) teacher/entropy 0.0249 (0.0253) teacher/usage_max 0.6618 (0.7260) teacher/usage_min 0.0007 (0.0027) teacher/usage_std 0.2699 (0.3026) nleep/row_max_mean 1537.7678 (1541.7603) nleep/row_max_std 35.3189 (55.8638) nleep/row_min_mean 1504.2395 (1504.3050) lr 1.1874e-03 eta 0:08:55
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [25/50] batch [20/173] time 0.169 (0.180) data 0.000 (0.013) loss 1.4344 (1.5002) teacher_loss 0.2372 (0.3050) loss_zs_kd 0.0093 (0.0124) loss_oracle 0.7285 (0.7748) kd_loss 0.8283 (0.8016) acc 93.7500 (88.7500) gate/entropy 1.0135 (1.0132) gate/usage_max 0.5276 (0.5281) gate/usage_min 0.2000 (0.2003) gate/usage_std 0.1405 (0.1408) teacher/entropy 0.0513 (0.0252) teacher/usage_max 0.6484 (0.7171) teacher/usage_min 0.0272 (0.0014) teacher/usage_std 0.2537 (0.2980) nleep/row_max_mean 1530.1740 (1540.5849) nleep/row_max_std 52.8537 (55.5187) nleep/row_min_mean 1500.3777 (1503.1689) lr 1.1253e-03 eta 0:13:24
epoch [25/50] batch [40/173] time 0.153 (0.171) data 0.000 (0.007) loss 1.2832 (1.5099) teacher_loss 0.1412 (0.2890) loss_zs_kd 0.0086 (0.0142) loss_oracle 0.6802 (0.7955) kd_loss 0.7975 (0.8160) acc 93.7500 (89.1406) gate/entropy 1.0146 (1.0137) gate/usage_max 0.5256 (0.5273) gate/usage_min 0.1993 (0.2000) gate/usage_std 0.1394 (0.1404) teacher/entropy 0.0087 (0.0297) teacher/usage_max 0.7479 (0.6879) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3107 (0.2856) nleep/row_max_mean 1549.3518 (1542.5824) nleep/row_max_std 48.8504 (52.6897) nleep/row_min_mean 1509.7754 (1505.4029) lr 1.1253e-03 eta 0:12:41
epoch [25/50] batch [60/173] time 0.146 (0.165) data 0.000 (0.004) loss 1.7250 (1.5104) teacher_loss 0.6104 (0.2931) loss_zs_kd 0.0185 (0.0145) loss_oracle 0.6849 (0.7807) kd_loss 0.7629 (0.8196) acc 68.7500 (88.6979) gate/entropy 1.0156 (1.0141) gate/usage_max 0.5237 (0.5264) gate/usage_min 0.1986 (0.1996) gate/usage_std 0.1384 (0.1399) teacher/entropy 0.0029 (0.0291) teacher/usage_max 0.8120 (0.6835) teacher/usage_min 0.0003 (0.0025) teacher/usage_std 0.3470 (0.2841) nleep/row_max_mean 1531.1697 (1541.6712) nleep/row_max_std 52.7478 (51.5441) nleep/row_min_mean 1495.2495 (1504.6361) lr 1.1253e-03 eta 0:12:10
epoch [25/50] batch [80/173] time 0.164 (0.159) data 0.000 (0.003) loss 1.4212 (1.4955) teacher_loss 0.1578 (0.2916) loss_zs_kd 0.0167 (0.0151) loss_oracle 0.8193 (0.7657) kd_loss 0.8454 (0.8135) acc 93.7500 (88.5938) gate/entropy 1.0161 (1.0146) gate/usage_max 0.5225 (0.5256) gate/usage_min 0.1980 (0.1993) gate/usage_std 0.1378 (0.1394) teacher/entropy 0.0419 (0.0300) teacher/usage_max 0.6194 (0.6913) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.2551 (0.2873) nleep/row_max_mean 1552.6791 (1542.5218) nleep/row_max_std 50.2599 (50.8078) nleep/row_min_mean 1513.2173 (1505.1530) lr 1.1253e-03 eta 0:11:43
epoch [25/50] batch [100/173] time 0.102 (0.153) data 0.000 (0.003) loss 1.3387 (1.4872) teacher_loss 0.2353 (0.2881) loss_zs_kd 0.0147 (0.0151) loss_oracle 0.6668 (0.7583) kd_loss 0.7626 (0.8124) acc 93.7500 (88.9688) gate/entropy 1.0168 (1.0150) gate/usage_max 0.5211 (0.5248) gate/usage_min 0.1974 (0.1990) gate/usage_std 0.1371 (0.1390) teacher/entropy 0.0043 (0.0292) teacher/usage_max 0.8128 (0.6940) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.3475 (0.2882) nleep/row_max_mean 1550.1506 (1543.7871) nleep/row_max_std 45.7320 (49.8914) nleep/row_min_mean 1510.5710 (1505.8823) lr 1.1253e-03 eta 0:11:14
epoch [25/50] batch [120/173] time 0.105 (0.147) data 0.000 (0.002) loss 1.5276 (1.4784) teacher_loss 0.2970 (0.2848) loss_zs_kd 0.0225 (0.0147) loss_oracle 0.8022 (0.7564) kd_loss 0.8183 (0.8081) acc 87.5000 (89.0365) gate/entropy 1.0177 (1.0154) gate/usage_max 0.5193 (0.5240) gate/usage_min 0.1969 (0.1987) gate/usage_std 0.1362 (0.1386) teacher/entropy 0.0354 (0.0300) teacher/usage_max 0.6827 (0.6998) teacher/usage_min 0.0202 (0.0025) teacher/usage_std 0.2716 (0.2912) nleep/row_max_mean 1535.0251 (1544.0804) nleep/row_max_std 43.2563 (49.0797) nleep/row_min_mean 1496.8608 (1505.9569) lr 1.1253e-03 eta 0:10:42
epoch [25/50] batch [140/173] time 0.119 (0.144) data 0.000 (0.002) loss 1.4756 (1.4751) teacher_loss 0.2428 (0.2807) loss_zs_kd 0.0084 (0.0147) loss_oracle 0.7639 (0.7573) kd_loss 0.8466 (0.8084) acc 90.6250 (89.1964) gate/entropy 1.0182 (1.0157) gate/usage_max 0.5181 (0.5232) gate/usage_min 0.1961 (0.1984) gate/usage_std 0.1356 (0.1382) teacher/entropy 0.0275 (0.0301) teacher/usage_max 0.6347 (0.6989) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2601 (0.2907) nleep/row_max_mean 1567.8262 (1545.1049) nleep/row_max_std 41.8661 (48.5885) nleep/row_min_mean 1524.9167 (1506.9146) lr 1.1253e-03 eta 0:10:29
epoch [25/50] batch [160/173] time 0.080 (0.139) data 0.000 (0.002) loss 1.4453 (1.4714) teacher_loss 0.2506 (0.2794) loss_zs_kd 0.0228 (0.0150) loss_oracle 0.7335 (0.7586) kd_loss 0.8165 (0.8052) acc 90.6250 (89.3750) gate/entropy 1.0192 (1.0161) gate/usage_max 0.5160 (0.5225) gate/usage_min 0.1957 (0.1981) gate/usage_std 0.1346 (0.1378) teacher/entropy 0.0095 (0.0300) teacher/usage_max 0.7166 (0.7044) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2947 (0.2931) nleep/row_max_mean 1532.5304 (1545.4000) nleep/row_max_std 43.4705 (48.1965) nleep/row_min_mean 1495.2405 (1507.1111) lr 1.1253e-03 eta 0:10:04
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [26/50] batch [20/173] time 0.090 (0.132) data 0.000 (0.020) loss 1.4126 (1.4158) teacher_loss 0.2551 (0.2321) loss_zs_kd 0.0223 (0.0156) loss_oracle 0.7210 (0.7471) kd_loss 0.7858 (0.8024) acc 87.5000 (91.5625) gate/entropy 1.0199 (1.0197) gate/usage_max 0.5141 (0.5147) gate/usage_min 0.1947 (0.1950) gate/usage_std 0.1337 (0.1340) teacher/entropy 0.0036 (0.0236) teacher/usage_max 0.7807 (0.7175) teacher/usage_min 0.0001 (0.0006) teacher/usage_std 0.3287 (0.3002) nleep/row_max_mean 1551.3225 (1545.3966) nleep/row_max_std 52.6371 (48.9768) nleep/row_min_mean 1508.3542 (1506.0650) lr 1.0628e-03 eta 0:09:28
epoch [26/50] batch [40/173] time 0.116 (0.129) data 0.000 (0.010) loss 1.6564 (1.4242) teacher_loss 0.4063 (0.2524) loss_zs_kd 0.0147 (0.0144) loss_oracle 0.7753 (0.7260) kd_loss 0.8551 (0.8016) acc 81.2500 (90.0000) gate/entropy 1.0205 (1.0199) gate/usage_max 0.5127 (0.5141) gate/usage_min 0.1942 (0.1947) gate/usage_std 0.1331 (0.1337) teacher/entropy 0.0186 (0.0251) teacher/usage_max 0.6308 (0.7164) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2588 (0.2985) nleep/row_max_mean 1548.7693 (1547.0899) nleep/row_max_std 38.8492 (47.3807) nleep/row_min_mean 1509.3193 (1507.2818) lr 1.0628e-03 eta 0:09:11
epoch [26/50] batch [60/173] time 0.084 (0.126) data 0.000 (0.007) loss 1.4354 (1.4382) teacher_loss 0.3655 (0.2705) loss_zs_kd 0.0152 (0.0150) loss_oracle 0.6462 (0.7215) kd_loss 0.7392 (0.7994) acc 84.3750 (89.1667) gate/entropy 1.0209 (1.0202) gate/usage_max 0.5116 (0.5135) gate/usage_min 0.1938 (0.1945) gate/usage_std 0.1326 (0.1335) teacher/entropy 0.0381 (0.0244) teacher/usage_max 0.8049 (0.7221) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3428 (0.3013) nleep/row_max_mean 1543.0787 (1547.6552) nleep/row_max_std 50.2480 (46.4132) nleep/row_min_mean 1506.0333 (1507.9799) lr 1.0628e-03 eta 0:08:57
epoch [26/50] batch [80/173] time 0.166 (0.128) data 0.000 (0.005) loss 1.3586 (1.4406) teacher_loss 0.0938 (0.2732) loss_zs_kd 0.0115 (0.0152) loss_oracle 0.8325 (0.7224) kd_loss 0.8428 (0.7986) acc 100.0000 (89.0625) gate/entropy 1.0215 (1.0204) gate/usage_max 0.5102 (0.5129) gate/usage_min 0.1933 (0.1942) gate/usage_std 0.1320 (0.1332) teacher/entropy 0.0740 (0.0264) teacher/usage_max 0.5568 (0.7202) teacher/usage_min 0.0094 (0.0022) teacher/usage_std 0.2345 (0.3003) nleep/row_max_mean 1536.8665 (1547.9112) nleep/row_max_std 47.5194 (46.6317) nleep/row_min_mean 1502.6697 (1508.1928) lr 1.0628e-03 eta 0:09:03
epoch [26/50] batch [100/173] time 0.161 (0.136) data 0.000 (0.004) loss 1.4856 (1.4445) teacher_loss 0.3292 (0.2765) loss_zs_kd 0.0053 (0.0155) loss_oracle 0.7768 (0.7267) kd_loss 0.7654 (0.7969) acc 84.3750 (88.9688) gate/entropy 1.0217 (1.0206) gate/usage_max 0.5093 (0.5123) gate/usage_min 0.1928 (0.1940) gate/usage_std 0.1316 (0.1329) teacher/entropy 0.0606 (0.0267) teacher/usage_max 0.7168 (0.7231) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.2948 (0.3017) nleep/row_max_mean 1552.0691 (1547.9314) nleep/row_max_std 49.2666 (47.7123) nleep/row_min_mean 1508.2263 (1508.1582) lr 1.0628e-03 eta 0:09:32
epoch [26/50] batch [120/173] time 0.160 (0.139) data 0.000 (0.003) loss 1.4755 (1.4426) teacher_loss 0.3780 (0.2752) loss_zs_kd 0.0095 (0.0161) loss_oracle 0.7092 (0.7270) kd_loss 0.7381 (0.7959) acc 87.5000 (89.1406) gate/entropy 1.0223 (1.0208) gate/usage_max 0.5078 (0.5117) gate/usage_min 0.1922 (0.1937) gate/usage_std 0.1310 (0.1327) teacher/entropy 0.0509 (0.0277) teacher/usage_max 0.7881 (0.7233) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.3330 (0.3017) nleep/row_max_mean 1543.2126 (1547.6563) nleep/row_max_std 57.1664 (47.6234) nleep/row_min_mean 1502.8384 (1508.1081) lr 1.0628e-03 eta 0:09:44
epoch [26/50] batch [140/173] time 0.162 (0.143) data 0.000 (0.003) loss 1.3607 (1.4434) teacher_loss 0.1997 (0.2760) loss_zs_kd 0.0179 (0.0165) loss_oracle 0.7453 (0.7265) kd_loss 0.7794 (0.7960) acc 90.6250 (89.2857) gate/entropy 1.0228 (1.0211) gate/usage_max 0.5063 (0.5110) gate/usage_min 0.1917 (0.1935) gate/usage_std 0.1303 (0.1324) teacher/entropy 0.0414 (0.0279) teacher/usage_max 0.7280 (0.7230) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.3003 (0.3013) nleep/row_max_mean 1546.4053 (1547.6807) nleep/row_max_std 49.6161 (47.7696) nleep/row_min_mean 1505.8696 (1508.2591) lr 1.0628e-03 eta 0:09:57
epoch [26/50] batch [160/173] time 0.154 (0.145) data 0.000 (0.003) loss 1.3091 (1.4395) teacher_loss 0.1258 (0.2702) loss_zs_kd 0.0100 (0.0164) loss_oracle 0.7466 (0.7274) kd_loss 0.8050 (0.7973) acc 96.8750 (89.4531) gate/entropy 1.0234 (1.0213) gate/usage_max 0.5048 (0.5103) gate/usage_min 0.1911 (0.1932) gate/usage_std 0.1297 (0.1321) teacher/entropy 0.0198 (0.0274) teacher/usage_max 0.7205 (0.7213) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2966 (0.3007) nleep/row_max_mean 1530.4224 (1547.0308) nleep/row_max_std 48.1411 (47.8409) nleep/row_min_mean 1490.8187 (1507.8674) lr 1.0628e-03 eta 0:10:04
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,291
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,999
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [27/50] batch [20/173] time 0.062 (0.111) data 0.000 (0.014) loss 1.4148 (1.4492) teacher_loss 0.2209 (0.2810) loss_zs_kd 0.0171 (0.0156) loss_oracle 0.7383 (0.7195) kd_loss 0.8162 (0.8007) acc 93.7500 (89.5312) gate/entropy 1.0242 (1.0239) gate/usage_max 0.5022 (0.5030) gate/usage_min 0.1901 (0.1903) gate/usage_std 0.1287 (0.1290) teacher/entropy 0.0231 (0.0328) teacher/usage_max 0.6929 (0.7093) teacher/usage_min 0.0011 (0.0063) teacher/usage_std 0.2831 (0.2907) nleep/row_max_mean 1544.3203 (1542.4392) nleep/row_max_std 43.1824 (44.3302) nleep/row_min_mean 1504.9404 (1504.6548) lr 1.0000e-03 eta 0:07:37
epoch [27/50] batch [40/173] time 0.114 (0.105) data 0.000 (0.007) loss 1.3675 (1.4384) teacher_loss 0.1852 (0.2752) loss_zs_kd 0.0185 (0.0149) loss_oracle 0.7241 (0.7117) kd_loss 0.8109 (0.7999) acc 90.6250 (89.2969) gate/entropy 1.0246 (1.0241) gate/usage_max 0.5007 (0.5023) gate/usage_min 0.1895 (0.1900) gate/usage_std 0.1281 (0.1288) teacher/entropy 0.0442 (0.0292) teacher/usage_max 0.6585 (0.7158) teacher/usage_min 0.0001 (0.0036) teacher/usage_std 0.2688 (0.2962) nleep/row_max_mean 1538.0658 (1542.7855) nleep/row_max_std 47.1847 (46.3510) nleep/row_min_mean 1499.5852 (1504.5021) lr 1.0000e-03 eta 0:07:11
epoch [27/50] batch [60/173] time 0.154 (0.102) data 0.000 (0.005) loss 1.3789 (1.4367) teacher_loss 0.2035 (0.2626) loss_zs_kd 0.0208 (0.0161) loss_oracle 0.6497 (0.7187) kd_loss 0.8401 (0.8066) acc 93.7500 (89.5312) gate/entropy 1.0250 (1.0243) gate/usage_max 0.4987 (0.5014) gate/usage_min 0.1885 (0.1896) gate/usage_std 0.1275 (0.1285) teacher/entropy 0.0009 (0.0309) teacher/usage_max 0.6874 (0.6993) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.2810 (0.2888) nleep/row_max_mean 1547.6838 (1543.4950) nleep/row_max_std 57.6408 (47.9790) nleep/row_min_mean 1506.8337 (1505.3157) lr 1.0000e-03 eta 0:06:56
epoch [27/50] batch [80/173] time 0.154 (0.106) data 0.000 (0.004) loss 1.3923 (1.4227) teacher_loss 0.3277 (0.2593) loss_zs_kd 0.0158 (0.0168) loss_oracle 0.6182 (0.7037) kd_loss 0.7476 (0.8031) acc 90.6250 (89.8438) gate/entropy 1.0255 (1.0246) gate/usage_max 0.4970 (0.5005) gate/usage_min 0.1879 (0.1892) gate/usage_std 0.1269 (0.1281) teacher/entropy 0.0328 (0.0326) teacher/usage_max 0.8213 (0.7035) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3527 (0.2913) nleep/row_max_mean 1546.7870 (1543.3117) nleep/row_max_std 45.7816 (48.9090) nleep/row_min_mean 1511.6173 (1505.3632) lr 1.0000e-03 eta 0:07:12
epoch [27/50] batch [100/173] time 0.097 (0.105) data 0.000 (0.003) loss 1.3043 (1.4243) teacher_loss 0.2134 (0.2581) loss_zs_kd 0.0133 (0.0171) loss_oracle 0.6313 (0.7019) kd_loss 0.7686 (0.8066) acc 90.6250 (89.9688) gate/entropy 1.0259 (1.0248) gate/usage_max 0.4956 (0.4996) gate/usage_min 0.1873 (0.1889) gate/usage_std 0.1264 (0.1278) teacher/entropy 0.0363 (0.0324) teacher/usage_max 0.7696 (0.6965) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3225 (0.2885) nleep/row_max_mean 1542.4032 (1542.1929) nleep/row_max_std 58.6286 (49.6025) nleep/row_min_mean 1503.4299 (1504.5877) lr 1.0000e-03 eta 0:07:04
epoch [27/50] batch [120/173] time 0.085 (0.107) data 0.000 (0.003) loss 1.4248 (1.4215) teacher_loss 0.2228 (0.2547) loss_zs_kd 0.0115 (0.0169) loss_oracle 0.7204 (0.7005) kd_loss 0.8360 (0.8081) acc 93.7500 (90.0781) gate/entropy 1.0262 (1.0250) gate/usage_max 0.4938 (0.4988) gate/usage_min 0.1865 (0.1886) gate/usage_std 0.1258 (0.1275) teacher/entropy 0.0218 (0.0332) teacher/usage_max 0.6486 (0.6912) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2651 (0.2865) nleep/row_max_mean 1540.8997 (1540.8033) nleep/row_max_std 49.4691 (49.7936) nleep/row_min_mean 1503.1173 (1503.7173) lr 1.0000e-03 eta 0:07:12
epoch [27/50] batch [140/173] time 0.195 (0.110) data 0.000 (0.002) loss 1.4352 (1.4236) teacher_loss 0.4269 (0.2586) loss_zs_kd 0.0127 (0.0168) loss_oracle 0.5427 (0.6972) kd_loss 0.7306 (0.8080) acc 78.1250 (90.0223) gate/entropy 1.0265 (1.0252) gate/usage_max 0.4925 (0.4980) gate/usage_min 0.1860 (0.1883) gate/usage_std 0.1254 (0.1272) teacher/entropy 0.0046 (0.0334) teacher/usage_max 0.9367 (0.6910) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.4274 (0.2866) nleep/row_max_mean 1532.1267 (1539.8929) nleep/row_max_std 53.6556 (49.6461) nleep/row_min_mean 1494.5955 (1503.1964) lr 1.0000e-03 eta 0:07:22
epoch [27/50] batch [160/173] time 0.138 (0.111) data 0.000 (0.002) loss 1.6950 (1.4232) teacher_loss 0.4845 (0.2607) loss_zs_kd 0.0149 (0.0164) loss_oracle 0.7323 (0.6940) kd_loss 0.8369 (0.8073) acc 84.3750 (90.0781) gate/entropy 1.0267 (1.0254) gate/usage_max 0.4913 (0.4972) gate/usage_min 0.1854 (0.1879) gate/usage_std 0.1251 (0.1270) teacher/entropy 0.0204 (0.0340) teacher/usage_max 0.6492 (0.6912) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2653 (0.2867) nleep/row_max_mean 1548.1879 (1540.1749) nleep/row_max_std 40.8071 (49.5097) nleep/row_min_mean 1510.9541 (1503.6059) lr 1.0000e-03 eta 0:07:23
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [28/50] batch [20/173] time 0.149 (0.166) data 0.000 (0.016) loss 1.3912 (1.3948) teacher_loss 0.2055 (0.2363) loss_zs_kd 0.0164 (0.0146) loss_oracle 0.7197 (0.6850) kd_loss 0.8177 (0.8087) acc 90.6250 (91.8750) gate/entropy 1.0272 (1.0271) gate/usage_max 0.4889 (0.4895) gate/usage_min 0.1846 (0.1849) gate/usage_std 0.1243 (0.1245) teacher/entropy 0.0489 (0.0353) teacher/usage_max 0.6269 (0.6872) teacher/usage_min 0.0016 (0.0025) teacher/usage_std 0.2567 (0.2858) nleep/row_max_mean 1548.1035 (1536.1440) nleep/row_max_std 53.0699 (48.0767) nleep/row_min_mean 1512.6887 (1500.8615) lr 9.3721e-04 eta 0:10:56
epoch [28/50] batch [40/173] time 0.146 (0.157) data 0.000 (0.008) loss 1.2974 (1.3915) teacher_loss 0.1281 (0.2425) loss_zs_kd 0.0162 (0.0151) loss_oracle 0.6480 (0.6620) kd_loss 0.8372 (0.8104) acc 96.8750 (91.1719) gate/entropy 1.0274 (1.0272) gate/usage_max 0.4876 (0.4889) gate/usage_min 0.1841 (0.1846) gate/usage_std 0.1240 (0.1243) teacher/entropy 0.0044 (0.0341) teacher/usage_max 0.6867 (0.6885) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.2807 (0.2854) nleep/row_max_mean 1537.2307 (1537.6354) nleep/row_max_std 64.3391 (50.7534) nleep/row_min_mean 1502.7762 (1502.7283) lr 9.3721e-04 eta 0:10:17
epoch [28/50] batch [60/173] time 0.150 (0.151) data 0.001 (0.006) loss 1.4705 (1.3936) teacher_loss 0.3554 (0.2462) loss_zs_kd 0.0111 (0.0155) loss_oracle 0.6468 (0.6559) kd_loss 0.7862 (0.8117) acc 81.2500 (90.5729) gate/entropy 1.0275 (1.0273) gate/usage_max 0.4866 (0.4883) gate/usage_min 0.1836 (0.1844) gate/usage_std 0.1237 (0.1242) teacher/entropy 0.0535 (0.0331) teacher/usage_max 0.7606 (0.6920) teacher/usage_min 0.0453 (0.0080) teacher/usage_std 0.3082 (0.2855) nleep/row_max_mean 1548.2620 (1538.3720) nleep/row_max_std 57.4226 (51.4939) nleep/row_min_mean 1508.6936 (1503.0945) lr 9.3721e-04 eta 0:09:51
epoch [28/50] batch [80/173] time 0.165 (0.151) data 0.000 (0.004) loss 1.5048 (1.3940) teacher_loss 0.3046 (0.2447) loss_zs_kd 0.0324 (0.0161) loss_oracle 0.7277 (0.6553) kd_loss 0.8201 (0.8136) acc 84.3750 (90.6641) gate/entropy 1.0277 (1.0274) gate/usage_max 0.4856 (0.4878) gate/usage_min 0.1832 (0.1842) gate/usage_std 0.1234 (0.1240) teacher/entropy 0.0329 (0.0328) teacher/usage_max 0.6579 (0.6888) teacher/usage_min 0.0000 (0.0087) teacher/usage_std 0.2687 (0.2833) nleep/row_max_mean 1538.1233 (1539.1677) nleep/row_max_std 56.9858 (52.0236) nleep/row_min_mean 1500.4336 (1503.8853) lr 9.3721e-04 eta 0:09:47
epoch [28/50] batch [100/173] time 0.147 (0.153) data 0.000 (0.003) loss 1.4045 (1.3963) teacher_loss 0.3159 (0.2481) loss_zs_kd 0.0330 (0.0167) loss_oracle 0.5994 (0.6550) kd_loss 0.7724 (0.8124) acc 87.5000 (90.4062) gate/entropy 1.0277 (1.0275) gate/usage_max 0.4851 (0.4873) gate/usage_min 0.1829 (0.1839) gate/usage_std 0.1234 (0.1239) teacher/entropy 0.0064 (0.0320) teacher/usage_max 0.9049 (0.6945) teacher/usage_min 0.0325 (0.0089) teacher/usage_std 0.4043 (0.2860) nleep/row_max_mean 1546.4817 (1540.4656) nleep/row_max_std 61.9835 (51.9263) nleep/row_min_mean 1508.1362 (1504.8293) lr 9.3721e-04 eta 0:09:53
epoch [28/50] batch [120/173] time 0.097 (0.152) data 0.000 (0.003) loss 1.3782 (1.3933) teacher_loss 0.2223 (0.2487) loss_zs_kd 0.0172 (0.0177) loss_oracle 0.6723 (0.6522) kd_loss 0.8111 (0.8097) acc 93.7500 (90.4427) gate/entropy 1.0278 (1.0275) gate/usage_max 0.4846 (0.4869) gate/usage_min 0.1827 (0.1838) gate/usage_std 0.1232 (0.1238) teacher/entropy 0.0589 (0.0341) teacher/usage_max 0.6318 (0.6963) teacher/usage_min 0.0121 (0.0087) teacher/usage_std 0.2535 (0.2868) nleep/row_max_mean 1556.0671 (1541.2761) nleep/row_max_std 50.3990 (51.5839) nleep/row_min_mean 1523.4014 (1505.8051) lr 9.3721e-04 eta 0:09:45
epoch [28/50] batch [140/173] time 0.173 (0.145) data 0.000 (0.002) loss 1.1086 (1.3834) teacher_loss 0.1117 (0.2433) loss_zs_kd 0.0068 (0.0172) loss_oracle 0.4437 (0.6445) kd_loss 0.7717 (0.8093) acc 93.7500 (90.6473) gate/entropy 1.0280 (1.0276) gate/usage_max 0.4839 (0.4865) gate/usage_min 0.1826 (0.1836) gate/usage_std 0.1230 (0.1237) teacher/entropy 0.0822 (0.0352) teacher/usage_max 0.7038 (0.6954) teacher/usage_min 0.0300 (0.0094) teacher/usage_std 0.2792 (0.2861) nleep/row_max_mean 1540.3029 (1540.8471) nleep/row_max_std 54.2340 (51.7802) nleep/row_min_mean 1507.9341 (1505.6540) lr 9.3721e-04 eta 0:09:16
epoch [28/50] batch [160/173] time 0.080 (0.140) data 0.000 (0.002) loss 1.5426 (1.3891) teacher_loss 0.4263 (0.2500) loss_zs_kd 0.0237 (0.0172) loss_oracle 0.6388 (0.6428) kd_loss 0.7850 (0.8091) acc 78.1250 (90.3906) gate/entropy 1.0279 (1.0276) gate/usage_max 0.4834 (0.4861) gate/usage_min 0.1823 (0.1835) gate/usage_std 0.1229 (0.1236) teacher/entropy 0.0429 (0.0360) teacher/usage_max 0.7246 (0.6932) teacher/usage_min 0.0000 (0.0091) teacher/usage_std 0.2986 (0.2851) nleep/row_max_mean 1537.1431 (1540.7477) nleep/row_max_std 53.4447 (51.4136) nleep/row_min_mean 1505.9641 (1505.8647) lr 9.3721e-04 eta 0:08:54
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [29/50] batch [20/173] time 0.084 (0.144) data 0.000 (0.018) loss 1.3678 (1.4083) teacher_loss 0.1907 (0.2731) loss_zs_kd 0.0101 (0.0188) loss_oracle 0.6326 (0.6299) kd_loss 0.8558 (0.8109) acc 93.7500 (88.5938) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4833 (0.4831) gate/usage_min 0.1823 (0.1822) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0044 (0.0237) teacher/usage_max 0.6882 (0.7246) teacher/usage_min 0.0312 (0.0105) teacher/usage_std 0.2708 (0.2987) nleep/row_max_mean 1525.4790 (1532.6463) nleep/row_max_std 46.1357 (50.1916) nleep/row_min_mean 1484.4283 (1498.4143) lr 8.7467e-04 eta 0:09:05
epoch [29/50] batch [40/173] time 0.083 (0.130) data 0.000 (0.009) loss 1.4005 (1.4130) teacher_loss 0.1700 (0.2738) loss_zs_kd 0.0286 (0.0215) loss_oracle 0.7091 (0.6397) kd_loss 0.8617 (0.8087) acc 93.7500 (88.9062) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4829 (0.4831) gate/usage_min 0.1820 (0.1822) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0374 (0.0335) teacher/usage_max 0.5589 (0.7100) teacher/usage_min 0.0172 (0.0143) teacher/usage_std 0.2303 (0.2904) nleep/row_max_mean 1547.0405 (1533.7884) nleep/row_max_std 45.8501 (47.7424) nleep/row_min_mean 1514.9614 (1500.6742) lr 8.7467e-04 eta 0:08:11
epoch [29/50] batch [60/173] time 0.192 (0.126) data 0.001 (0.006) loss 1.4716 (1.4018) teacher_loss 0.3914 (0.2663) loss_zs_kd 0.0325 (0.0206) loss_oracle 0.5832 (0.6358) kd_loss 0.7723 (0.8073) acc 84.3750 (89.1667) gate/entropy 1.0279 (1.0280) gate/usage_max 0.4828 (0.4830) gate/usage_min 0.1819 (0.1821) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0143 (0.0309) teacher/usage_max 0.8408 (0.7200) teacher/usage_min 0.0013 (0.0136) teacher/usage_std 0.3645 (0.2956) nleep/row_max_mean 1527.0049 (1533.9371) nleep/row_max_std 49.8477 (48.6445) nleep/row_min_mean 1496.5050 (1500.7515) lr 8.7467e-04 eta 0:07:52
epoch [29/50] batch [80/173] time 0.154 (0.125) data 0.000 (0.005) loss 1.3859 (1.3976) teacher_loss 0.3121 (0.2710) loss_zs_kd 0.0226 (0.0195) loss_oracle 0.5874 (0.6279) kd_loss 0.7688 (0.8029) acc 84.3750 (89.2578) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4829 (0.4830) gate/usage_min 0.1820 (0.1821) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0538 (0.0325) teacher/usage_max 0.7400 (0.7255) teacher/usage_min 0.0001 (0.0124) teacher/usage_std 0.3065 (0.2989) nleep/row_max_mean 1536.4315 (1533.6269) nleep/row_max_std 48.5916 (49.2442) nleep/row_min_mean 1508.5480 (1500.9705) lr 8.7467e-04 eta 0:07:45
epoch [29/50] batch [100/173] time 0.162 (0.129) data 0.000 (0.004) loss 1.3039 (1.4004) teacher_loss 0.1848 (0.2780) loss_zs_kd 0.0123 (0.0195) loss_oracle 0.5707 (0.6254) kd_loss 0.8275 (0.8000) acc 93.7500 (89.1875) gate/entropy 1.0279 (1.0280) gate/usage_max 0.4831 (0.4830) gate/usage_min 0.1820 (0.1821) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0241 (0.0330) teacher/usage_max 0.7140 (0.7311) teacher/usage_min 0.0326 (0.0118) teacher/usage_std 0.2839 (0.3024) nleep/row_max_mean 1528.7130 (1533.4349) nleep/row_max_std 48.2852 (49.3296) nleep/row_min_mean 1500.0707 (1500.8412) lr 8.7467e-04 eta 0:07:56
epoch [29/50] batch [120/173] time 0.168 (0.133) data 0.000 (0.003) loss 1.5076 (1.3947) teacher_loss 0.3073 (0.2736) loss_zs_kd 0.0350 (0.0199) loss_oracle 0.6792 (0.6240) kd_loss 0.8432 (0.7992) acc 87.5000 (89.4271) gate/entropy 1.0279 (1.0280) gate/usage_max 0.4834 (0.4830) gate/usage_min 0.1823 (0.1821) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0053 (0.0335) teacher/usage_max 0.7195 (0.7341) teacher/usage_min 0.0306 (0.0131) teacher/usage_std 0.2874 (0.3035) nleep/row_max_mean 1521.0114 (1532.7498) nleep/row_max_std 53.0812 (49.4708) nleep/row_min_mean 1485.8783 (1500.2860) lr 8.7467e-04 eta 0:08:10
epoch [29/50] batch [140/173] time 0.164 (0.137) data 0.000 (0.003) loss 1.5699 (1.3908) teacher_loss 0.4259 (0.2670) loss_zs_kd 0.0602 (0.0198) loss_oracle 0.6215 (0.6260) kd_loss 0.8032 (0.8009) acc 81.2500 (89.6875) gate/entropy 1.0278 (1.0280) gate/usage_max 0.4832 (0.4831) gate/usage_min 0.1819 (0.1821) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0192 (0.0331) teacher/usage_max 0.7459 (0.7308) teacher/usage_min 0.0039 (0.0133) teacher/usage_std 0.3086 (0.3017) nleep/row_max_mean 1536.2825 (1533.0906) nleep/row_max_std 45.1141 (49.1061) nleep/row_min_mean 1506.3743 (1500.6132) lr 8.7467e-04 eta 0:08:23
epoch [29/50] batch [160/173] time 0.152 (0.140) data 0.000 (0.002) loss 1.3623 (1.3927) teacher_loss 0.1430 (0.2650) loss_zs_kd 0.0152 (0.0202) loss_oracle 0.7462 (0.6295) kd_loss 0.8385 (0.8028) acc 93.7500 (89.7461) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4830 (0.4831) gate/usage_min 0.1821 (0.1821) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0417 (0.0327) teacher/usage_max 0.6084 (0.7282) teacher/usage_min 0.0152 (0.0141) teacher/usage_std 0.2441 (0.3003) nleep/row_max_mean 1527.7981 (1532.7491) nleep/row_max_std 40.9530 (49.0613) nleep/row_min_mean 1497.9375 (1500.3066) lr 8.7467e-04 eta 0:08:28
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [30/50] batch [20/173] time 0.090 (0.137) data 0.000 (0.013) loss 1.2136 (1.3645) teacher_loss 0.0631 (0.2399) loss_zs_kd 0.0225 (0.0214) loss_oracle 0.6360 (0.6294) kd_loss 0.8213 (0.7993) acc 100.0000 (91.2500) gate/entropy 1.0279 (1.0279) gate/usage_max 0.4823 (0.4825) gate/usage_min 0.1815 (0.1817) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0095 (0.0306) teacher/usage_max 0.7195 (0.7396) teacher/usage_min 0.0000 (0.0114) teacher/usage_std 0.2961 (0.3061) nleep/row_max_mean 1545.7727 (1538.3905) nleep/row_max_std 48.9817 (50.1388) nleep/row_min_mean 1513.5701 (1503.5993) lr 8.1262e-04 eta 0:08:14
epoch [30/50] batch [40/173] time 0.084 (0.124) data 0.000 (0.007) loss 1.3382 (1.3688) teacher_loss 0.2068 (0.2330) loss_zs_kd 0.0266 (0.0220) loss_oracle 0.6065 (0.6341) kd_loss 0.8149 (0.8077) acc 90.6250 (91.1719) gate/entropy 1.0281 (1.0280) gate/usage_max 0.4822 (0.4824) gate/usage_min 0.1818 (0.1817) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0284 (0.0333) teacher/usage_max 0.7248 (0.7167) teacher/usage_min 0.0246 (0.0162) teacher/usage_std 0.2918 (0.2941) nleep/row_max_mean 1534.8867 (1538.8952) nleep/row_max_std 55.0849 (50.3500) nleep/row_min_mean 1497.7505 (1503.9268) lr 8.1262e-04 eta 0:07:25
epoch [30/50] batch [60/173] time 0.089 (0.123) data 0.001 (0.005) loss 1.3813 (1.3723) teacher_loss 0.1728 (0.2307) loss_zs_kd 0.0221 (0.0222) loss_oracle 0.6445 (0.6353) kd_loss 0.8752 (0.8129) acc 90.6250 (91.2500) gate/entropy 1.0281 (1.0280) gate/usage_max 0.4813 (0.4822) gate/usage_min 0.1812 (0.1816) gate/usage_std 0.1225 (0.1227) teacher/entropy 0.0294 (0.0311) teacher/usage_max 0.5669 (0.7071) teacher/usage_min 0.0323 (0.0152) teacher/usage_std 0.2234 (0.2889) nleep/row_max_mean 1540.3966 (1541.4280) nleep/row_max_std 46.5377 (49.8674) nleep/row_min_mean 1510.5520 (1506.1669) lr 8.1262e-04 eta 0:07:18
epoch [30/50] batch [80/173] time 0.183 (0.123) data 0.000 (0.004) loss 1.5493 (1.3810) teacher_loss 0.4125 (0.2439) loss_zs_kd 0.0273 (0.0212) loss_oracle 0.6486 (0.6297) kd_loss 0.7989 (0.8116) acc 78.1250 (90.7812) gate/entropy 1.0281 (1.0280) gate/usage_max 0.4807 (0.4819) gate/usage_min 0.1809 (0.1815) gate/usage_std 0.1225 (0.1227) teacher/entropy 0.0322 (0.0310) teacher/usage_max 0.7178 (0.7123) teacher/usage_min 0.0000 (0.0157) teacher/usage_std 0.2952 (0.2915) nleep/row_max_mean 1548.0447 (1542.8711) nleep/row_max_std 47.4282 (50.2878) nleep/row_min_mean 1515.5067 (1507.5606) lr 8.1262e-04 eta 0:07:15
epoch [30/50] batch [100/173] time 0.084 (0.120) data 0.000 (0.003) loss 1.4309 (1.3866) teacher_loss 0.3118 (0.2459) loss_zs_kd 0.0199 (0.0225) loss_oracle 0.6433 (0.6321) kd_loss 0.7875 (0.8134) acc 87.5000 (90.4375) gate/entropy 1.0281 (1.0280) gate/usage_max 0.4803 (0.4816) gate/usage_min 0.1807 (0.1813) gate/usage_std 0.1224 (0.1226) teacher/entropy 0.0291 (0.0298) teacher/usage_max 0.7929 (0.7098) teacher/usage_min 0.0184 (0.0152) teacher/usage_std 0.3323 (0.2905) nleep/row_max_mean 1546.7240 (1542.3854) nleep/row_max_std 41.0820 (50.0881) nleep/row_min_mean 1511.2729 (1507.2227) lr 8.1262e-04 eta 0:07:02
epoch [30/50] batch [120/173] time 0.195 (0.118) data 0.000 (0.002) loss 1.4761 (1.3953) teacher_loss 0.3423 (0.2527) loss_zs_kd 0.0254 (0.0227) loss_oracle 0.6315 (0.6339) kd_loss 0.8054 (0.8143) acc 84.3750 (90.2604) gate/entropy 1.0283 (1.0281) gate/usage_max 0.4799 (0.4814) gate/usage_min 0.1807 (0.1812) gate/usage_std 0.1222 (0.1226) teacher/entropy 0.0507 (0.0295) teacher/usage_max 0.7255 (0.7076) teacher/usage_min 0.0431 (0.0147) teacher/usage_std 0.2878 (0.2898) nleep/row_max_mean 1536.8934 (1540.5823) nleep/row_max_std 53.3651 (50.6196) nleep/row_min_mean 1502.5425 (1505.6857) lr 8.1262e-04 eta 0:06:55
epoch [30/50] batch [140/173] time 0.072 (0.117) data 0.000 (0.002) loss 1.3916 (1.3936) teacher_loss 0.2897 (0.2499) loss_zs_kd 0.0181 (0.0233) loss_oracle 0.6573 (0.6340) kd_loss 0.7641 (0.8150) acc 84.3750 (90.3571) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4792 (0.4811) gate/usage_min 0.1803 (0.1811) gate/usage_std 0.1221 (0.1225) teacher/entropy 0.0733 (0.0296) teacher/usage_max 0.7010 (0.7057) teacher/usage_min 0.0001 (0.0150) teacher/usage_std 0.2872 (0.2889) nleep/row_max_mean 1551.1581 (1539.9529) nleep/row_max_std 44.8752 (50.8227) nleep/row_min_mean 1514.1387 (1505.1768) lr 8.1262e-04 eta 0:06:47
epoch [30/50] batch [160/173] time 0.072 (0.116) data 0.000 (0.002) loss 1.3718 (1.3966) teacher_loss 0.3086 (0.2532) loss_zs_kd 0.0106 (0.0235) loss_oracle 0.5252 (0.6348) kd_loss 0.7952 (0.8143) acc 87.5000 (90.3516) gate/entropy 1.0282 (1.0281) gate/usage_max 0.4789 (0.4808) gate/usage_min 0.1801 (0.1810) gate/usage_std 0.1221 (0.1225) teacher/entropy 0.0042 (0.0295) teacher/usage_max 0.8741 (0.7076) teacher/usage_min 0.0321 (0.0145) teacher/usage_std 0.3832 (0.2898) nleep/row_max_mean 1559.3717 (1539.7143) nleep/row_max_std 53.6234 (51.0651) nleep/row_min_mean 1517.1411 (1504.8396) lr 8.1262e-04 eta 0:06:44
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,298
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [31/50] batch [20/173] time 0.148 (0.159) data 0.000 (0.013) loss 1.5338 (1.3812) teacher_loss 0.4368 (0.2449) loss_zs_kd 0.0165 (0.0177) loss_oracle 0.5570 (0.6098) kd_loss 0.8102 (0.8225) acc 84.3750 (90.4688) gate/entropy 1.0283 (1.0283) gate/usage_max 0.4785 (0.4787) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0100 (0.0265) teacher/usage_max 0.7530 (0.6842) teacher/usage_min 0.0000 (0.0092) teacher/usage_std 0.3134 (0.2799) nleep/row_max_mean 1533.9727 (1538.3503) nleep/row_max_std 55.2400 (51.6602) nleep/row_min_mean 1501.7004 (1504.7532) lr 7.5131e-04 eta 0:09:07
epoch [31/50] batch [40/173] time 0.161 (0.152) data 0.000 (0.006) loss 1.6158 (1.3896) teacher_loss 0.4823 (0.2624) loss_zs_kd 0.0425 (0.0208) loss_oracle 0.6042 (0.5995) kd_loss 0.8102 (0.8170) acc 87.5000 (89.8438) gate/entropy 1.0282 (1.0283) gate/usage_max 0.4778 (0.4784) gate/usage_min 0.1796 (0.1800) gate/usage_std 0.1219 (0.1220) teacher/entropy 0.0638 (0.0300) teacher/usage_max 0.6544 (0.6948) teacher/usage_min 0.0313 (0.0114) teacher/usage_std 0.2547 (0.2842) nleep/row_max_mean 1548.0945 (1539.6551) nleep/row_max_std 43.8470 (51.4004) nleep/row_min_mean 1513.5641 (1506.0974) lr 7.5131e-04 eta 0:08:39
epoch [31/50] batch [60/173] time 0.144 (0.152) data 0.001 (0.004) loss 1.5150 (1.3852) teacher_loss 0.2996 (0.2528) loss_zs_kd 0.0273 (0.0207) loss_oracle 0.6785 (0.6026) kd_loss 0.8625 (0.8207) acc 87.5000 (90.3125) gate/entropy 1.0283 (1.0283) gate/usage_max 0.4775 (0.4782) gate/usage_min 0.1794 (0.1799) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0003 (0.0289) teacher/usage_max 0.6250 (0.6893) teacher/usage_min 0.0000 (0.0125) teacher/usage_std 0.2568 (0.2819) nleep/row_max_mean 1561.1595 (1539.5988) nleep/row_max_std 45.1406 (52.3222) nleep/row_min_mean 1525.8877 (1506.2052) lr 7.5131e-04 eta 0:08:36
epoch [31/50] batch [80/173] time 0.162 (0.153) data 0.000 (0.003) loss 1.3176 (1.3818) teacher_loss 0.1640 (0.2454) loss_zs_kd 0.0489 (0.0216) loss_oracle 0.6299 (0.6041) kd_loss 0.8141 (0.8235) acc 93.7500 (90.7031) gate/entropy 1.0284 (1.0283) gate/usage_max 0.4772 (0.4780) gate/usage_min 0.1796 (0.1798) gate/usage_std 0.1217 (0.1219) teacher/entropy 0.0230 (0.0276) teacher/usage_max 0.7025 (0.6859) teacher/usage_min 0.0000 (0.0132) teacher/usage_std 0.2879 (0.2806) nleep/row_max_mean 1524.9004 (1539.7016) nleep/row_max_std 55.1312 (52.1740) nleep/row_min_mean 1491.0739 (1506.3121) lr 7.5131e-04 eta 0:08:37
epoch [31/50] batch [100/173] time 0.166 (0.154) data 0.000 (0.003) loss 1.4880 (1.3809) teacher_loss 0.2466 (0.2375) loss_zs_kd 0.0188 (0.0212) loss_oracle 0.7041 (0.6134) kd_loss 0.8799 (0.8260) acc 93.7500 (91.0938) gate/entropy 1.0284 (1.0283) gate/usage_max 0.4763 (0.4777) gate/usage_min 0.1791 (0.1797) gate/usage_std 0.1216 (0.1218) teacher/entropy 0.0291 (0.0291) teacher/usage_max 0.5388 (0.6748) teacher/usage_min 0.0289 (0.0135) teacher/usage_std 0.2196 (0.2759) nleep/row_max_mean 1538.6011 (1540.2936) nleep/row_max_std 49.5139 (51.8300) nleep/row_min_mean 1503.9487 (1506.8918) lr 7.5131e-04 eta 0:08:36
epoch [31/50] batch [120/173] time 0.139 (0.154) data 0.000 (0.002) loss 1.4383 (1.3788) teacher_loss 0.2748 (0.2305) loss_zs_kd 0.0077 (0.0206) loss_oracle 0.6249 (0.6207) kd_loss 0.8472 (0.8276) acc 90.6250 (91.1719) gate/entropy 1.0285 (1.0284) gate/usage_max 0.4752 (0.4774) gate/usage_min 0.1787 (0.1796) gate/usage_std 0.1214 (0.1218) teacher/entropy 0.0243 (0.0293) teacher/usage_max 0.6546 (0.6709) teacher/usage_min 0.0286 (0.0141) teacher/usage_std 0.2558 (0.2740) nleep/row_max_mean 1537.7302 (1539.5055) nleep/row_max_std 49.3849 (51.8052) nleep/row_min_mean 1508.3688 (1506.1075) lr 7.5131e-04 eta 0:08:32
epoch [31/50] batch [140/173] time 0.182 (0.149) data 0.001 (0.002) loss 1.5756 (1.3814) teacher_loss 0.4277 (0.2313) loss_zs_kd 0.0370 (0.0209) loss_oracle 0.6112 (0.6229) kd_loss 0.8238 (0.8282) acc 84.3750 (91.1384) gate/entropy 1.0285 (1.0284) gate/usage_max 0.4743 (0.4770) gate/usage_min 0.1782 (0.1794) gate/usage_std 0.1213 (0.1217) teacher/entropy 0.0400 (0.0297) teacher/usage_max 0.6462 (0.6679) teacher/usage_min 0.0118 (0.0142) teacher/usage_std 0.2591 (0.2724) nleep/row_max_mean 1540.8921 (1539.4785) nleep/row_max_std 58.3514 (51.7837) nleep/row_min_mean 1509.3501 (1506.1245) lr 7.5131e-04 eta 0:08:13
epoch [31/50] batch [160/173] time 0.171 (0.145) data 0.000 (0.002) loss 1.2899 (1.3840) teacher_loss 0.1715 (0.2308) loss_zs_kd 0.0243 (0.0211) loss_oracle 0.6024 (0.6272) kd_loss 0.8051 (0.8291) acc 93.7500 (91.3477) gate/entropy 1.0285 (1.0284) gate/usage_max 0.4734 (0.4766) gate/usage_min 0.1779 (0.1793) gate/usage_std 0.1211 (0.1216) teacher/entropy 0.0326 (0.0300) teacher/usage_max 0.7028 (0.6653) teacher/usage_min 0.0000 (0.0147) teacher/usage_std 0.2880 (0.2708) nleep/row_max_mean 1535.0093 (1539.0693) nleep/row_max_std 60.2605 (52.3567) nleep/row_min_mean 1502.9856 (1505.6919) lr 7.5131e-04 eta 0:07:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [32/50] batch [20/173] time 0.069 (0.109) data 0.000 (0.015) loss 1.3181 (1.4050) teacher_loss 0.1887 (0.2514) loss_zs_kd 0.0284 (0.0266) loss_oracle 0.6332 (0.6253) kd_loss 0.7986 (0.8277) acc 90.6250 (90.4688) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4722 (0.4725) gate/usage_min 0.1774 (0.1775) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0894 (0.0313) teacher/usage_max 0.5847 (0.6813) teacher/usage_min 0.0215 (0.0206) teacher/usage_std 0.2339 (0.2782) nleep/row_max_mean 1548.3186 (1541.2798) nleep/row_max_std 42.2620 (52.9090) nleep/row_min_mean 1520.2570 (1508.3103) lr 6.9098e-04 eta 0:05:57
epoch [32/50] batch [40/173] time 0.127 (0.113) data 0.000 (0.007) loss 1.3849 (1.3966) teacher_loss 0.1982 (0.2390) loss_zs_kd 0.0354 (0.0291) loss_oracle 0.6355 (0.6277) kd_loss 0.8513 (0.8291) acc 90.6250 (90.9375) gate/entropy 1.0287 (1.0286) gate/usage_max 0.4720 (0.4723) gate/usage_min 0.1776 (0.1775) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0264 (0.0313) teacher/usage_max 0.6422 (0.6780) teacher/usage_min 0.0308 (0.0213) teacher/usage_std 0.2497 (0.2741) nleep/row_max_mean 1525.5247 (1539.6696) nleep/row_max_std 54.0065 (54.0210) nleep/row_min_mean 1492.3560 (1506.8103) lr 6.9098e-04 eta 0:06:06
epoch [32/50] batch [60/173] time 0.165 (0.116) data 0.001 (0.005) loss 1.4868 (1.4024) teacher_loss 0.4066 (0.2491) loss_zs_kd 0.0261 (0.0292) loss_oracle 0.5668 (0.6216) kd_loss 0.7837 (0.8279) acc 81.2500 (90.4688) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4713 (0.4721) gate/usage_min 0.1770 (0.1774) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0449 (0.0307) teacher/usage_max 0.7607 (0.6804) teacher/usage_min 0.0098 (0.0195) teacher/usage_std 0.3152 (0.2765) nleep/row_max_mean 1546.8961 (1538.4894) nleep/row_max_std 42.7568 (52.8082) nleep/row_min_mean 1511.3535 (1505.3207) lr 6.9098e-04 eta 0:06:14
epoch [32/50] batch [80/173] time 0.073 (0.116) data 0.000 (0.004) loss 1.4373 (1.3959) teacher_loss 0.1693 (0.2382) loss_zs_kd 0.0183 (0.0286) loss_oracle 0.7461 (0.6284) kd_loss 0.8858 (0.8292) acc 90.6250 (91.1328) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4706 (0.4718) gate/usage_min 0.1767 (0.1773) gate/usage_std 0.1208 (0.1209) teacher/entropy 0.0026 (0.0294) teacher/usage_max 0.5314 (0.6760) teacher/usage_min 0.0001 (0.0172) teacher/usage_std 0.2371 (0.2760) nleep/row_max_mean 1560.8870 (1538.2397) nleep/row_max_std 43.8507 (52.5353) nleep/row_min_mean 1526.6719 (1504.9126) lr 6.9098e-04 eta 0:06:10
epoch [32/50] batch [100/173] time 0.150 (0.118) data 0.000 (0.003) loss 1.2458 (1.3932) teacher_loss 0.0860 (0.2402) loss_zs_kd 0.0136 (0.0285) loss_oracle 0.6148 (0.6196) kd_loss 0.8456 (0.8289) acc 100.0000 (91.0938) gate/entropy 1.0287 (1.0286) gate/usage_max 0.4708 (0.4716) gate/usage_min 0.1770 (0.1772) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0232 (0.0292) teacher/usage_max 0.6394 (0.6800) teacher/usage_min 0.0171 (0.0179) teacher/usage_std 0.2541 (0.2775) nleep/row_max_mean 1523.4576 (1537.5461) nleep/row_max_std 47.6465 (51.9819) nleep/row_min_mean 1491.2297 (1504.2496) lr 6.9098e-04 eta 0:06:15
epoch [32/50] batch [120/173] time 0.151 (0.124) data 0.000 (0.003) loss 1.0580 (1.3921) teacher_loss 0.0332 (0.2432) loss_zs_kd 0.0128 (0.0282) loss_oracle 0.5506 (0.6165) kd_loss 0.7430 (0.8266) acc 100.0000 (91.1458) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4703 (0.4714) gate/usage_min 0.1767 (0.1771) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0772 (0.0307) teacher/usage_max 0.7744 (0.6812) teacher/usage_min 0.0025 (0.0173) teacher/usage_std 0.3246 (0.2778) nleep/row_max_mean 1545.1984 (1536.4004) nleep/row_max_std 51.2635 (51.6000) nleep/row_min_mean 1514.5027 (1503.4180) lr 6.9098e-04 eta 0:06:33
epoch [32/50] batch [140/173] time 0.156 (0.129) data 0.000 (0.002) loss 1.3896 (1.3857) teacher_loss 0.1832 (0.2381) loss_zs_kd 0.0296 (0.0274) loss_oracle 0.6685 (0.6162) kd_loss 0.8574 (0.8258) acc 93.7500 (91.1384) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4701 (0.4713) gate/usage_min 0.1765 (0.1771) gate/usage_std 0.1207 (0.1208) teacher/entropy 0.0133 (0.0305) teacher/usage_max 0.5939 (0.6833) teacher/usage_min 0.0005 (0.0166) teacher/usage_std 0.2476 (0.2787) nleep/row_max_mean 1536.3956 (1535.9705) nleep/row_max_std 47.8423 (51.6711) nleep/row_min_mean 1503.9196 (1503.1445) lr 6.9098e-04 eta 0:06:46
epoch [32/50] batch [160/173] time 0.190 (0.134) data 0.000 (0.002) loss 1.4213 (1.3867) teacher_loss 0.2825 (0.2367) loss_zs_kd 0.0230 (0.0273) loss_oracle 0.6351 (0.6176) kd_loss 0.8097 (0.8275) acc 90.6250 (91.2109) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4699 (0.4711) gate/usage_min 0.1765 (0.1770) gate/usage_std 0.1206 (0.1208) teacher/entropy 0.0226 (0.0305) teacher/usage_max 0.7269 (0.6797) teacher/usage_min 0.0000 (0.0177) teacher/usage_std 0.2998 (0.2769) nleep/row_max_mean 1534.3433 (1536.2689) nleep/row_max_std 53.4075 (51.5194) nleep/row_min_mean 1505.1309 (1503.6947) lr 6.9098e-04 eta 0:06:58
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [33/50] batch [20/173] time 0.157 (0.169) data 0.000 (0.014) loss 1.4344 (1.4187) teacher_loss 0.2401 (0.2675) loss_zs_kd 0.0382 (0.0244) loss_oracle 0.6417 (0.6138) kd_loss 0.8543 (0.8322) acc 87.5000 (89.8438) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4698 (0.4699) gate/usage_min 0.1763 (0.1764) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0287 (0.0327) teacher/usage_max 0.6853 (0.6867) teacher/usage_min 0.0559 (0.0289) teacher/usage_std 0.2623 (0.2789) nleep/row_max_mean 1540.5647 (1541.7708) nleep/row_max_std 54.6353 (51.2245) nleep/row_min_mean 1510.4929 (1510.4897) lr 6.3188e-04 eta 0:08:44
epoch [33/50] batch [40/173] time 0.075 (0.125) data 0.000 (0.007) loss 1.2573 (1.4106) teacher_loss 0.1277 (0.2594) loss_zs_kd 0.0284 (0.0271) loss_oracle 0.5672 (0.6144) kd_loss 0.8318 (0.8304) acc 93.7500 (90.3125) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4698 (0.4699) gate/usage_min 0.1764 (0.1765) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0798 (0.0341) teacher/usage_max 0.6337 (0.6833) teacher/usage_min 0.0757 (0.0274) teacher/usage_std 0.2298 (0.2772) nleep/row_max_mean 1546.7365 (1541.0111) nleep/row_max_std 53.6291 (51.1508) nleep/row_min_mean 1514.9341 (1509.9766) lr 6.3188e-04 eta 0:06:25
epoch [33/50] batch [60/173] time 0.083 (0.119) data 0.001 (0.005) loss 1.4559 (1.4034) teacher_loss 0.2658 (0.2536) loss_zs_kd 0.0315 (0.0272) loss_oracle 0.6474 (0.6146) kd_loss 0.8506 (0.8289) acc 90.6250 (90.6250) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4698 (0.4699) gate/usage_min 0.1764 (0.1764) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0305 (0.0349) teacher/usage_max 0.6329 (0.6862) teacher/usage_min 0.0315 (0.0280) teacher/usage_std 0.2455 (0.2774) nleep/row_max_mean 1529.5056 (1540.2392) nleep/row_max_std 54.6892 (51.7721) nleep/row_min_mean 1500.6940 (1509.3226) lr 6.3188e-04 eta 0:06:04
epoch [33/50] batch [80/173] time 0.179 (0.120) data 0.000 (0.004) loss 1.3987 (1.4097) teacher_loss 0.2134 (0.2580) loss_zs_kd 0.0176 (0.0273) loss_oracle 0.6732 (0.6170) kd_loss 0.8400 (0.8296) acc 93.7500 (90.4297) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4694 (0.4698) gate/usage_min 0.1762 (0.1764) gate/usage_std 0.1206 (0.1207) teacher/entropy 0.0308 (0.0322) teacher/usage_max 0.5930 (0.6874) teacher/usage_min 0.0009 (0.0256) teacher/usage_std 0.2472 (0.2782) nleep/row_max_mean 1548.0955 (1539.9359) nleep/row_max_std 51.5201 (51.8508) nleep/row_min_mean 1521.6746 (1509.1334) lr 6.3188e-04 eta 0:06:04
epoch [33/50] batch [100/173] time 0.175 (0.119) data 0.000 (0.003) loss 1.3256 (1.4022) teacher_loss 0.1874 (0.2544) loss_zs_kd 0.0360 (0.0263) loss_oracle 0.5783 (0.6153) kd_loss 0.8311 (0.8270) acc 96.8750 (90.6562) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4694 (0.4698) gate/usage_min 0.1762 (0.1764) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0073 (0.0342) teacher/usage_max 0.7815 (0.6898) teacher/usage_min 0.0304 (0.0258) teacher/usage_std 0.3234 (0.2788) nleep/row_max_mean 1539.3969 (1539.0530) nleep/row_max_std 44.5178 (50.0565) nleep/row_min_mean 1508.0288 (1508.5900) lr 6.3188e-04 eta 0:05:59
epoch [33/50] batch [120/173] time 0.098 (0.117) data 0.000 (0.002) loss 1.7465 (1.3991) teacher_loss 0.6050 (0.2528) loss_zs_kd 0.0374 (0.0260) loss_oracle 0.5306 (0.6132) kd_loss 0.8576 (0.8267) acc 81.2500 (90.7031) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4695 (0.4697) gate/usage_min 0.1763 (0.1764) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0810 (0.0356) teacher/usage_max 0.6747 (0.6907) teacher/usage_min 0.1302 (0.0277) teacher/usage_std 0.2428 (0.2786) nleep/row_max_mean 1528.9777 (1538.9277) nleep/row_max_std 51.7903 (49.2350) nleep/row_min_mean 1502.0898 (1508.6689) lr 6.3188e-04 eta 0:05:48
epoch [33/50] batch [140/173] time 0.145 (0.117) data 0.000 (0.002) loss 1.3128 (1.3966) teacher_loss 0.1547 (0.2502) loss_zs_kd 0.0268 (0.0263) loss_oracle 0.6730 (0.6144) kd_loss 0.8082 (0.8261) acc 93.7500 (90.8929) gate/entropy 1.0286 (1.0286) gate/usage_max 0.4693 (0.4697) gate/usage_min 0.1762 (0.1763) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0308 (0.0381) teacher/usage_max 0.7771 (0.6895) teacher/usage_min 0.0290 (0.0300) teacher/usage_std 0.3209 (0.2770) nleep/row_max_mean 1535.4390 (1538.4706) nleep/row_max_std 58.5557 (48.9063) nleep/row_min_mean 1507.3141 (1508.4397) lr 6.3188e-04 eta 0:05:48
epoch [33/50] batch [160/173] time 0.077 (0.115) data 0.000 (0.002) loss 1.3479 (1.3967) teacher_loss 0.2528 (0.2484) loss_zs_kd 0.0444 (0.0264) loss_oracle 0.5776 (0.6178) kd_loss 0.7841 (0.8262) acc 87.5000 (90.9375) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4691 (0.4696) gate/usage_min 0.1760 (0.1763) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0532 (0.0393) teacher/usage_max 0.7503 (0.6859) teacher/usage_min 0.0162 (0.0304) teacher/usage_std 0.3079 (0.2751) nleep/row_max_mean 1538.3081 (1538.2755) nleep/row_max_std 52.6335 (49.3553) nleep/row_min_mean 1511.6915 (1508.3496) lr 6.3188e-04 eta 0:05:40
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,000
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [34/50] batch [20/173] time 0.137 (0.152) data 0.000 (0.013) loss 1.2683 (1.3864) teacher_loss 0.0794 (0.2501) loss_zs_kd 0.0285 (0.0237) loss_oracle 0.5970 (0.6149) kd_loss 0.8762 (0.8170) acc 100.0000 (90.6250) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4687 (0.4688) gate/usage_min 0.1759 (0.1760) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0460 (0.0403) teacher/usage_max 0.5591 (0.6871) teacher/usage_min 0.0601 (0.0191) teacher/usage_std 0.2065 (0.2792) nleep/row_max_mean 1537.7701 (1537.1685) nleep/row_max_std 48.1643 (52.9057) nleep/row_min_mean 1506.1582 (1506.2690) lr 5.7422e-04 eta 0:07:23
epoch [34/50] batch [40/173] time 0.163 (0.147) data 0.000 (0.007) loss 1.3991 (1.3849) teacher_loss 0.3032 (0.2416) loss_zs_kd 0.0457 (0.0241) loss_oracle 0.5759 (0.6137) kd_loss 0.7852 (0.8245) acc 84.3750 (90.6250) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4684 (0.4687) gate/usage_min 0.1756 (0.1759) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0237 (0.0378) teacher/usage_max 0.8149 (0.6738) teacher/usage_min 0.0002 (0.0209) teacher/usage_std 0.3488 (0.2733) nleep/row_max_mean 1547.5759 (1536.6125) nleep/row_max_std 48.5537 (53.2607) nleep/row_min_mean 1511.0496 (1505.6560) lr 5.7422e-04 eta 0:07:07
epoch [34/50] batch [60/173] time 0.157 (0.143) data 0.001 (0.005) loss 1.1734 (1.3864) teacher_loss 0.1380 (0.2395) loss_zs_kd 0.0080 (0.0229) loss_oracle 0.5224 (0.6097) kd_loss 0.7702 (0.8305) acc 93.7500 (90.5208) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4683 (0.4686) gate/usage_min 0.1757 (0.1759) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0953 (0.0374) teacher/usage_max 0.7121 (0.6701) teacher/usage_min 0.0396 (0.0273) teacher/usage_std 0.2810 (0.2683) nleep/row_max_mean 1547.1021 (1538.0226) nleep/row_max_std 64.3714 (54.2722) nleep/row_min_mean 1515.5417 (1506.8566) lr 5.7422e-04 eta 0:06:50
epoch [34/50] batch [80/173] time 0.133 (0.141) data 0.000 (0.003) loss 1.3566 (1.3849) teacher_loss 0.1709 (0.2349) loss_zs_kd 0.0269 (0.0232) loss_oracle 0.6625 (0.6126) kd_loss 0.8411 (0.8321) acc 93.7500 (90.8203) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4682 (0.4685) gate/usage_min 0.1757 (0.1758) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0331 (0.0384) teacher/usage_max 0.5865 (0.6682) teacher/usage_min 0.0040 (0.0302) teacher/usage_std 0.2439 (0.2661) nleep/row_max_mean 1537.8530 (1538.9337) nleep/row_max_std 51.3429 (55.3369) nleep/row_min_mean 1504.3003 (1507.6356) lr 5.7422e-04 eta 0:06:44
epoch [34/50] batch [100/173] time 0.135 (0.141) data 0.000 (0.003) loss 1.4897 (1.3781) teacher_loss 0.3413 (0.2327) loss_zs_kd 0.0243 (0.0227) loss_oracle 0.6676 (0.6142) kd_loss 0.8024 (0.8270) acc 81.2500 (90.9688) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4679 (0.4684) gate/usage_min 0.1754 (0.1758) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0399 (0.0420) teacher/usage_max 0.6949 (0.6715) teacher/usage_min 0.0000 (0.0292) teacher/usage_std 0.2844 (0.2679) nleep/row_max_mean 1552.7822 (1539.1580) nleep/row_max_std 58.3680 (56.3749) nleep/row_min_mean 1512.9565 (1507.5851) lr 5.7422e-04 eta 0:06:40
epoch [34/50] batch [120/173] time 0.152 (0.141) data 0.000 (0.002) loss 1.2735 (1.3733) teacher_loss 0.1553 (0.2314) loss_zs_kd 0.0250 (0.0230) loss_oracle 0.5729 (0.6123) kd_loss 0.8192 (0.8243) acc 90.6250 (91.0156) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4680 (0.4684) gate/usage_min 0.1756 (0.1758) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0873 (0.0432) teacher/usage_max 0.6008 (0.6766) teacher/usage_min 0.0554 (0.0290) teacher/usage_std 0.2228 (0.2701) nleep/row_max_mean 1527.5300 (1539.7373) nleep/row_max_std 71.1803 (56.3655) nleep/row_min_mean 1497.9966 (1507.8872) lr 5.7422e-04 eta 0:06:36
epoch [34/50] batch [140/173] time 0.153 (0.142) data 0.000 (0.002) loss 1.2908 (1.3735) teacher_loss 0.1657 (0.2320) loss_zs_kd 0.0244 (0.0231) loss_oracle 0.6710 (0.6131) kd_loss 0.7774 (0.8233) acc 90.6250 (90.9152) gate/entropy 1.0286 (1.0285) gate/usage_max 0.4681 (0.4683) gate/usage_min 0.1758 (0.1757) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0885 (0.0439) teacher/usage_max 0.6241 (0.6764) teacher/usage_min 0.0078 (0.0286) teacher/usage_std 0.2528 (0.2701) nleep/row_max_mean 1526.3115 (1539.5877) nleep/row_max_std 62.4269 (57.0692) nleep/row_min_mean 1497.7896 (1507.8161) lr 5.7422e-04 eta 0:06:37
epoch [34/50] batch [160/173] time 0.092 (0.142) data 0.000 (0.002) loss 1.2817 (1.3682) teacher_loss 0.1849 (0.2279) loss_zs_kd 0.0329 (0.0226) loss_oracle 0.6154 (0.6121) kd_loss 0.7726 (0.8229) acc 90.6250 (91.1914) gate/entropy 1.0286 (1.0285) gate/usage_max 0.4680 (0.4683) gate/usage_min 0.1757 (0.1757) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0823 (0.0445) teacher/usage_max 0.6513 (0.6769) teacher/usage_min 0.0006 (0.0289) teacher/usage_std 0.2658 (0.2700) nleep/row_max_mean 1536.5663 (1539.9950) nleep/row_max_std 56.3641 (57.2663) nleep/row_min_mean 1500.5542 (1508.0309) lr 5.7422e-04 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,999
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [35/50] batch [20/173] time 0.197 (0.128) data 0.000 (0.012) loss 1.3550 (1.3549) teacher_loss 0.2917 (0.2368) loss_zs_kd 0.0339 (0.0257) loss_oracle 0.5372 (0.5947) kd_loss 0.7777 (0.8079) acc 84.3750 (91.0938) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4681 (0.4679) gate/usage_min 0.1757 (0.1756) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0729 (0.0535) teacher/usage_max 0.7627 (0.7165) teacher/usage_min 0.0387 (0.0354) teacher/usage_std 0.3106 (0.2878) nleep/row_max_mean 1536.5714 (1540.4529) nleep/row_max_std 53.8134 (57.7913) nleep/row_min_mean 1509.5344 (1508.4198) lr 5.1825e-04 eta 0:05:52
epoch [35/50] batch [40/173] time 0.090 (0.123) data 0.000 (0.006) loss 1.3481 (1.3431) teacher_loss 0.3058 (0.2389) loss_zs_kd 0.0287 (0.0252) loss_oracle 0.5055 (0.5849) kd_loss 0.7752 (0.7991) acc 93.7500 (91.2500) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4682 (0.4680) gate/usage_min 0.1756 (0.1756) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0201 (0.0564) teacher/usage_max 0.8692 (0.7326) teacher/usage_min 0.0014 (0.0335) teacher/usage_std 0.3825 (0.2976) nleep/row_max_mean 1542.2349 (1541.7349) nleep/row_max_std 60.3110 (56.5956) nleep/row_min_mean 1511.4819 (1510.5577) lr 5.1825e-04 eta 0:05:34
epoch [35/50] batch [60/173] time 0.162 (0.121) data 0.001 (0.004) loss 1.2499 (1.3403) teacher_loss 0.1509 (0.2380) loss_zs_kd 0.0148 (0.0227) loss_oracle 0.5525 (0.5814) kd_loss 0.8153 (0.8002) acc 96.8750 (91.4062) gate/entropy 1.0286 (1.0285) gate/usage_max 0.4687 (0.4681) gate/usage_min 0.1760 (0.1756) gate/usage_std 0.1205 (0.1205) teacher/entropy 0.0487 (0.0558) teacher/usage_max 0.7635 (0.7342) teacher/usage_min 0.0583 (0.0348) teacher/usage_std 0.3081 (0.2977) nleep/row_max_mean 1524.4259 (1540.7546) nleep/row_max_std 62.3297 (56.2820) nleep/row_min_mean 1496.1954 (1509.9996) lr 5.1825e-04 eta 0:05:26
epoch [35/50] batch [80/173] time 0.102 (0.116) data 0.000 (0.003) loss 1.4206 (1.3580) teacher_loss 0.2886 (0.2521) loss_zs_kd 0.0066 (0.0218) loss_oracle 0.6459 (0.5836) kd_loss 0.8057 (0.8032) acc 87.5000 (90.6641) gate/entropy 1.0284 (1.0285) gate/usage_max 0.4684 (0.4682) gate/usage_min 0.1755 (0.1756) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0714 (0.0532) teacher/usage_max 0.6576 (0.7291) teacher/usage_min 0.0351 (0.0335) teacher/usage_std 0.2548 (0.2954) nleep/row_max_mean 1559.1414 (1540.9257) nleep/row_max_std 42.0263 (55.7733) nleep/row_min_mean 1528.2301 (1510.2835) lr 5.1825e-04 eta 0:05:12
epoch [35/50] batch [100/173] time 0.175 (0.116) data 0.000 (0.003) loss 1.2775 (1.3672) teacher_loss 0.1004 (0.2549) loss_zs_kd 0.0294 (0.0218) loss_oracle 0.7010 (0.5901) kd_loss 0.8119 (0.8064) acc 100.0000 (90.3750) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4687 (0.4683) gate/usage_min 0.1758 (0.1757) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.1201 (0.0560) teacher/usage_max 0.5745 (0.7206) teacher/usage_min 0.0802 (0.0389) teacher/usage_std 0.2020 (0.2893) nleep/row_max_mean 1533.5457 (1541.6657) nleep/row_max_std 53.5100 (54.9264) nleep/row_min_mean 1506.0151 (1511.2314) lr 5.1825e-04 eta 0:05:10
epoch [35/50] batch [120/173] time 0.139 (0.115) data 0.000 (0.002) loss 1.3073 (1.3719) teacher_loss 0.2086 (0.2548) loss_zs_kd 0.0235 (0.0234) loss_oracle 0.5685 (0.5960) kd_loss 0.8027 (0.8074) acc 90.6250 (90.3385) gate/entropy 1.0286 (1.0285) gate/usage_max 0.4689 (0.4683) gate/usage_min 0.1760 (0.1757) gate/usage_std 0.1206 (0.1205) teacher/entropy 0.0466 (0.0570) teacher/usage_max 0.7638 (0.7167) teacher/usage_min 0.0376 (0.0401) teacher/usage_std 0.3114 (0.2872) nleep/row_max_mean 1531.9553 (1541.6362) nleep/row_max_std 54.0666 (54.3506) nleep/row_min_mean 1503.7336 (1511.4775) lr 5.1825e-04 eta 0:05:05
epoch [35/50] batch [140/173] time 0.161 (0.120) data 0.000 (0.002) loss 1.2970 (1.3753) teacher_loss 0.2162 (0.2566) loss_zs_kd 0.0263 (0.0241) loss_oracle 0.5298 (0.5998) kd_loss 0.8027 (0.8068) acc 93.7500 (90.2232) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4689 (0.4684) gate/usage_min 0.1760 (0.1757) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0503 (0.0583) teacher/usage_max 0.8329 (0.7160) teacher/usage_min 0.0700 (0.0409) teacher/usage_std 0.3534 (0.2869) nleep/row_max_mean 1539.4480 (1541.6574) nleep/row_max_std 56.4352 (53.4092) nleep/row_min_mean 1505.9956 (1511.4996) lr 5.1825e-04 eta 0:05:16
epoch [35/50] batch [160/173] time 0.136 (0.124) data 0.000 (0.002) loss 1.3131 (1.3720) teacher_loss 0.1214 (0.2514) loss_zs_kd 0.0143 (0.0238) loss_oracle 0.7112 (0.6008) kd_loss 0.8290 (0.8083) acc 96.8750 (90.5273) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4688 (0.4685) gate/usage_min 0.1759 (0.1757) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0403 (0.0590) teacher/usage_max 0.6708 (0.7094) teacher/usage_min 0.0302 (0.0416) teacher/usage_std 0.2626 (0.2833) nleep/row_max_mean 1545.2927 (1541.2503) nleep/row_max_std 46.6936 (52.8846) nleep/row_min_mean 1515.5513 (1511.2439) lr 5.1825e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [36/50] batch [20/173] time 0.144 (0.159) data 0.000 (0.015) loss 1.4172 (1.4064) teacher_loss 0.2759 (0.2783) loss_zs_kd 0.0289 (0.0258) loss_oracle 0.5922 (0.6034) kd_loss 0.8307 (0.8136) acc 84.3750 (89.3750) gate/entropy 1.0285 (1.0284) gate/usage_max 0.4690 (0.4688) gate/usage_min 0.1760 (0.1758) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0219 (0.0509) teacher/usage_max 0.7462 (0.7124) teacher/usage_min 0.0360 (0.0390) teacher/usage_std 0.3012 (0.2841) nleep/row_max_mean 1528.6438 (1535.3988) nleep/row_max_std 51.5367 (49.0025) nleep/row_min_mean 1497.8705 (1505.0121) lr 4.6417e-04 eta 0:06:50
epoch [36/50] batch [40/173] time 0.163 (0.160) data 0.000 (0.008) loss 1.4091 (1.3883) teacher_loss 0.2935 (0.2570) loss_zs_kd 0.0400 (0.0271) loss_oracle 0.5964 (0.5999) kd_loss 0.7974 (0.8178) acc 87.5000 (89.9219) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4689 (0.4688) gate/usage_min 0.1758 (0.1758) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0370 (0.0520) teacher/usage_max 0.7242 (0.7038) teacher/usage_min 0.0015 (0.0431) teacher/usage_std 0.2980 (0.2788) nleep/row_max_mean 1519.7374 (1534.1957) nleep/row_max_std 53.6232 (49.9392) nleep/row_min_mean 1492.7941 (1504.8575) lr 4.6417e-04 eta 0:06:48
epoch [36/50] batch [60/173] time 0.097 (0.149) data 0.001 (0.005) loss 1.3566 (1.3570) teacher_loss 0.3155 (0.2347) loss_zs_kd 0.0299 (0.0248) loss_oracle 0.5801 (0.5937) kd_loss 0.7361 (0.8129) acc 90.6250 (91.1979) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4690 (0.4689) gate/usage_min 0.1758 (0.1758) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0985 (0.0543) teacher/usage_max 0.7713 (0.7089) teacher/usage_min 0.0198 (0.0417) teacher/usage_std 0.3192 (0.2816) nleep/row_max_mean 1539.0642 (1533.1648) nleep/row_max_std 38.4610 (49.9229) nleep/row_min_mean 1510.0453 (1504.1740) lr 4.6417e-04 eta 0:06:17
epoch [36/50] batch [80/173] time 0.091 (0.139) data 0.001 (0.004) loss 1.2524 (1.3478) teacher_loss 0.1071 (0.2332) loss_zs_kd 0.0169 (0.0240) loss_oracle 0.6685 (0.5892) kd_loss 0.8026 (0.8080) acc 93.7500 (91.0156) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4692 (0.4689) gate/usage_min 0.1760 (0.1758) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0535 (0.0567) teacher/usage_max 0.6595 (0.7141) teacher/usage_min 0.0074 (0.0402) teacher/usage_std 0.2662 (0.2851) nleep/row_max_mean 1532.6838 (1532.0870) nleep/row_max_std 50.8159 (50.3775) nleep/row_min_mean 1506.8149 (1503.2643) lr 4.6417e-04 eta 0:05:49
epoch [36/50] batch [100/173] time 0.091 (0.132) data 0.000 (0.003) loss 1.5164 (1.3457) teacher_loss 0.3920 (0.2356) loss_zs_kd 0.0252 (0.0234) loss_oracle 0.5971 (0.5856) kd_loss 0.8133 (0.8056) acc 87.5000 (90.9375) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4694 (0.4690) gate/usage_min 0.1760 (0.1759) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0582 (0.0590) teacher/usage_max 0.7007 (0.7169) teacher/usage_min 0.0446 (0.0413) teacher/usage_std 0.2736 (0.2863) nleep/row_max_mean 1529.7021 (1532.2219) nleep/row_max_std 65.2908 (50.7084) nleep/row_min_mean 1500.8507 (1503.5220) lr 4.6417e-04 eta 0:05:30
epoch [36/50] batch [120/173] time 0.070 (0.130) data 0.000 (0.003) loss 1.3155 (1.3473) teacher_loss 0.2308 (0.2389) loss_zs_kd 0.0424 (0.0231) loss_oracle 0.5837 (0.5849) kd_loss 0.7717 (0.8044) acc 87.5000 (90.9896) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4697 (0.4691) gate/usage_min 0.1762 (0.1759) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0487 (0.0609) teacher/usage_max 0.7774 (0.7192) teacher/usage_min 0.0035 (0.0434) teacher/usage_std 0.3261 (0.2869) nleep/row_max_mean 1524.4370 (1531.7091) nleep/row_max_std 65.6184 (51.4388) nleep/row_min_mean 1493.8671 (1503.0661) lr 4.6417e-04 eta 0:05:22
epoch [36/50] batch [140/173] time 0.192 (0.128) data 0.000 (0.002) loss 1.4389 (1.3453) teacher_loss 0.3225 (0.2408) loss_zs_kd 0.0297 (0.0230) loss_oracle 0.5413 (0.5838) kd_loss 0.8309 (0.8012) acc 87.5000 (90.7812) gate/entropy 1.0283 (1.0284) gate/usage_max 0.4697 (0.4692) gate/usage_min 0.1760 (0.1759) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0191 (0.0632) teacher/usage_max 0.7484 (0.7222) teacher/usage_min 0.0338 (0.0433) teacher/usage_std 0.3030 (0.2887) nleep/row_max_mean 1534.1910 (1531.2361) nleep/row_max_std 48.8167 (51.5896) nleep/row_min_mean 1507.0931 (1502.7686) lr 4.6417e-04 eta 0:05:14
epoch [36/50] batch [160/173] time 0.083 (0.124) data 0.000 (0.002) loss 1.3307 (1.3477) teacher_loss 0.2807 (0.2427) loss_zs_kd 0.0226 (0.0228) loss_oracle 0.5024 (0.5837) kd_loss 0.7875 (0.8018) acc 90.6250 (90.6445) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4701 (0.4693) gate/usage_min 0.1763 (0.1760) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0602 (0.0635) teacher/usage_max 0.7940 (0.7232) teacher/usage_min 0.0504 (0.0450) teacher/usage_std 0.3285 (0.2889) nleep/row_max_mean 1531.8662 (1531.2749) nleep/row_max_std 56.2788 (51.7987) nleep/row_min_mean 1506.3564 (1502.8227) lr 4.6417e-04 eta 0:05:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [37/50] batch [20/173] time 0.074 (0.125) data 0.000 (0.012) loss 1.2416 (1.3689) teacher_loss 0.2384 (0.2841) loss_zs_kd 0.0211 (0.0274) loss_oracle 0.5550 (0.5700) kd_loss 0.7151 (0.7861) acc 93.7500 (88.5938) gate/entropy 1.0283 (1.0284) gate/usage_max 0.4707 (0.4705) gate/usage_min 0.1764 (0.1764) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.1160 (0.0775) teacher/usage_max 0.7655 (0.7428) teacher/usage_min 0.0144 (0.0519) teacher/usage_std 0.3169 (0.2982) nleep/row_max_mean 1550.3796 (1538.5573) nleep/row_max_std 48.6949 (50.9182) nleep/row_min_mean 1521.6646 (1510.1889) lr 4.1221e-04 eta 0:05:01
epoch [37/50] batch [40/173] time 0.145 (0.127) data 0.000 (0.006) loss 1.3014 (1.3612) teacher_loss 0.2188 (0.2689) loss_zs_kd 0.0168 (0.0246) loss_oracle 0.5478 (0.5645) kd_loss 0.8004 (0.7977) acc 93.7500 (90.0000) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4712 (0.4707) gate/usage_min 0.1768 (0.1765) gate/usage_std 0.1209 (0.1209) teacher/entropy 0.0400 (0.0682) teacher/usage_max 0.7774 (0.7380) teacher/usage_min 0.0347 (0.0536) teacher/usage_std 0.3202 (0.2949) nleep/row_max_mean 1529.8503 (1536.7981) nleep/row_max_std 50.0009 (51.7229) nleep/row_min_mean 1502.8999 (1507.9868) lr 4.1221e-04 eta 0:05:02
epoch [37/50] batch [60/173] time 0.165 (0.137) data 0.001 (0.004) loss 1.2337 (1.3645) teacher_loss 0.1499 (0.2780) loss_zs_kd 0.0337 (0.0246) loss_oracle 0.5224 (0.5652) kd_loss 0.8058 (0.7916) acc 93.7500 (89.8438) gate/entropy 1.0284 (1.0284) gate/usage_max 0.4715 (0.4709) gate/usage_min 0.1769 (0.1765) gate/usage_std 0.1210 (0.1209) teacher/entropy 0.1049 (0.0738) teacher/usage_max 0.7312 (0.7456) teacher/usage_min 0.1166 (0.0560) teacher/usage_std 0.2817 (0.2993) nleep/row_max_mean 1525.5869 (1536.0803) nleep/row_max_std 56.9709 (51.4552) nleep/row_min_mean 1502.1794 (1507.4355) lr 4.1221e-04 eta 0:05:23
epoch [37/50] batch [80/173] time 0.161 (0.144) data 0.000 (0.003) loss 1.2322 (1.3549) teacher_loss 0.1776 (0.2700) loss_zs_kd 0.0192 (0.0233) loss_oracle 0.5416 (0.5685) kd_loss 0.7742 (0.7890) acc 90.6250 (90.2344) gate/entropy 1.0283 (1.0283) gate/usage_max 0.4717 (0.4710) gate/usage_min 0.1768 (0.1766) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0293 (0.0763) teacher/usage_max 0.8228 (0.7421) teacher/usage_min 0.0002 (0.0548) teacher/usage_std 0.3536 (0.2970) nleep/row_max_mean 1548.7498 (1537.0649) nleep/row_max_std 48.9100 (51.3794) nleep/row_min_mean 1519.3320 (1508.3505) lr 4.1221e-04 eta 0:05:36
epoch [37/50] batch [100/173] time 0.144 (0.145) data 0.000 (0.003) loss 1.4065 (1.3505) teacher_loss 0.3694 (0.2703) loss_zs_kd 0.0203 (0.0225) loss_oracle 0.5515 (0.5702) kd_loss 0.7512 (0.7839) acc 84.3750 (90.1562) gate/entropy 1.0283 (1.0283) gate/usage_max 0.4720 (0.4712) gate/usage_min 0.1769 (0.1766) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.1199 (0.0808) teacher/usage_max 0.7074 (0.7408) teacher/usage_min 0.0495 (0.0535) teacher/usage_std 0.2761 (0.2966) nleep/row_max_mean 1540.3293 (1536.2836) nleep/row_max_std 55.4076 (51.7891) nleep/row_min_mean 1513.8208 (1507.7872) lr 4.1221e-04 eta 0:05:35
epoch [37/50] batch [120/173] time 0.157 (0.147) data 0.000 (0.002) loss 1.2575 (1.3558) teacher_loss 0.1773 (0.2725) loss_zs_kd 0.0093 (0.0223) loss_oracle 0.6071 (0.5730) kd_loss 0.7720 (0.7857) acc 93.7500 (89.9219) gate/entropy 1.0284 (1.0283) gate/usage_max 0.4725 (0.4713) gate/usage_min 0.1773 (0.1767) gate/usage_std 0.1211 (0.1210) teacher/entropy 0.0625 (0.0822) teacher/usage_max 0.7737 (0.7373) teacher/usage_min 0.0254 (0.0566) teacher/usage_std 0.3195 (0.2940) nleep/row_max_mean 1522.4915 (1535.7434) nleep/row_max_std 65.3754 (52.0723) nleep/row_min_mean 1492.4194 (1507.3000) lr 4.1221e-04 eta 0:05:37
epoch [37/50] batch [140/173] time 0.162 (0.149) data 0.000 (0.002) loss 1.2137 (1.3564) teacher_loss 0.1403 (0.2739) loss_zs_kd 0.0381 (0.0224) loss_oracle 0.5686 (0.5736) kd_loss 0.7700 (0.7846) acc 96.8750 (90.0223) gate/entropy 1.0283 (1.0283) gate/usage_max 0.4726 (0.4715) gate/usage_min 0.1771 (0.1768) gate/usage_std 0.1212 (0.1210) teacher/entropy 0.0928 (0.0820) teacher/usage_max 0.7073 (0.7408) teacher/usage_min 0.0385 (0.0564) teacher/usage_std 0.2787 (0.2961) nleep/row_max_mean 1531.9342 (1535.7264) nleep/row_max_std 53.4938 (52.2673) nleep/row_min_mean 1504.1892 (1507.0800) lr 4.1221e-04 eta 0:05:38
epoch [37/50] batch [160/173] time 0.146 (0.149) data 0.000 (0.002) loss 1.4229 (1.3532) teacher_loss 0.2473 (0.2707) loss_zs_kd 0.0155 (0.0222) loss_oracle 0.6104 (0.5762) kd_loss 0.8627 (0.7833) acc 90.6250 (90.0000) gate/entropy 1.0282 (1.0283) gate/usage_max 0.4730 (0.4717) gate/usage_min 0.1773 (0.1768) gate/usage_std 0.1213 (0.1211) teacher/entropy 0.0304 (0.0820) teacher/usage_max 0.7213 (0.7426) teacher/usage_min 0.0898 (0.0557) teacher/usage_std 0.2773 (0.2972) nleep/row_max_mean 1550.1360 (1535.5685) nleep/row_max_std 51.0135 (52.2037) nleep/row_min_mean 1518.8387 (1506.7637) lr 4.1221e-04 eta 0:05:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,999
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [38/50] batch [20/173] time 0.070 (0.123) data 0.001 (0.014) loss 1.4122 (1.3425) teacher_loss 0.3405 (0.2522) loss_zs_kd 0.0310 (0.0230) loss_oracle 0.5657 (0.5852) kd_loss 0.7734 (0.7862) acc 84.3750 (89.6875) gate/entropy 1.0282 (1.0283) gate/usage_max 0.4732 (0.4732) gate/usage_min 0.1774 (0.1774) gate/usage_std 0.1213 (0.1213) teacher/entropy 0.0793 (0.0910) teacher/usage_max 0.7976 (0.7301) teacher/usage_min 0.0639 (0.0696) teacher/usage_std 0.3297 (0.2876) nleep/row_max_mean 1534.3927 (1531.6464) nleep/row_max_std 48.4133 (53.6577) nleep/row_min_mean 1508.1106 (1502.7232) lr 3.6258e-04 eta 0:04:33
epoch [38/50] batch [40/173] time 0.162 (0.111) data 0.000 (0.007) loss 1.4004 (1.3679) teacher_loss 0.2699 (0.2773) loss_zs_kd 0.0237 (0.0237) loss_oracle 0.6364 (0.5802) kd_loss 0.8004 (0.7886) acc 87.5000 (89.4531) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4732 (0.4732) gate/usage_min 0.1773 (0.1774) gate/usage_std 0.1213 (0.1213) teacher/entropy 0.0485 (0.0797) teacher/usage_max 0.7387 (0.7324) teacher/usage_min 0.0318 (0.0576) teacher/usage_std 0.2978 (0.2912) nleep/row_max_mean 1543.2427 (1534.6334) nleep/row_max_std 50.4300 (51.7557) nleep/row_min_mean 1514.3696 (1505.6547) lr 3.6258e-04 eta 0:04:04
epoch [38/50] batch [60/173] time 0.113 (0.104) data 0.000 (0.005) loss 1.4231 (1.3397) teacher_loss 0.4202 (0.2581) loss_zs_kd 0.0238 (0.0229) loss_oracle 0.5296 (0.5763) kd_loss 0.7262 (0.7820) acc 81.2500 (90.1042) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4732 (0.4733) gate/usage_min 0.1772 (0.1774) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0858 (0.0857) teacher/usage_max 0.8725 (0.7357) teacher/usage_min 0.0374 (0.0578) teacher/usage_std 0.3818 (0.2940) nleep/row_max_mean 1557.2070 (1532.8836) nleep/row_max_std 40.5568 (51.5388) nleep/row_min_mean 1526.8685 (1504.2194) lr 3.6258e-04 eta 0:03:48
epoch [38/50] batch [80/173] time 0.111 (0.105) data 0.000 (0.004) loss 1.3008 (1.3498) teacher_loss 0.3368 (0.2714) loss_zs_kd 0.0153 (0.0228) loss_oracle 0.4790 (0.5761) kd_loss 0.7169 (0.7789) acc 87.5000 (89.6875) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4735 (0.4734) gate/usage_min 0.1773 (0.1775) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.1473 (0.0828) teacher/usage_max 0.7710 (0.7457) teacher/usage_min 0.0690 (0.0536) teacher/usage_std 0.3117 (0.3006) nleep/row_max_mean 1532.4790 (1533.4019) nleep/row_max_std 47.4887 (50.5096) nleep/row_min_mean 1509.2729 (1504.4541) lr 3.6258e-04 eta 0:03:48
epoch [38/50] batch [100/173] time 0.166 (0.106) data 0.000 (0.003) loss 1.5222 (1.3505) teacher_loss 0.4388 (0.2729) loss_zs_kd 0.0178 (0.0225) loss_oracle 0.6094 (0.5754) kd_loss 0.7698 (0.7787) acc 87.5000 (89.7812) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4740 (0.4735) gate/usage_min 0.1777 (0.1775) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0677 (0.0805) teacher/usage_max 0.8569 (0.7525) teacher/usage_min 0.0698 (0.0525) teacher/usage_std 0.3702 (0.3046) nleep/row_max_mean 1529.9022 (1533.1185) nleep/row_max_std 54.6475 (50.8413) nleep/row_min_mean 1500.6064 (1504.0144) lr 3.6258e-04 eta 0:03:47
epoch [38/50] batch [120/173] time 0.127 (0.108) data 0.000 (0.002) loss 1.2197 (1.3521) teacher_loss 0.1166 (0.2717) loss_zs_kd 0.0127 (0.0228) loss_oracle 0.5599 (0.5747) kd_loss 0.8168 (0.7817) acc 96.8750 (89.8698) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4744 (0.4736) gate/usage_min 0.1778 (0.1775) gate/usage_std 0.1215 (0.1214) teacher/entropy 0.0112 (0.0796) teacher/usage_max 0.8728 (0.7540) teacher/usage_min 0.0633 (0.0562) teacher/usage_std 0.3815 (0.3048) nleep/row_max_mean 1545.9325 (1533.3475) nleep/row_max_std 58.1630 (50.8241) nleep/row_min_mean 1511.5940 (1504.4176) lr 3.6258e-04 eta 0:03:50
epoch [38/50] batch [140/173] time 0.104 (0.108) data 0.000 (0.002) loss 1.2337 (1.3535) teacher_loss 0.1719 (0.2702) loss_zs_kd 0.0136 (0.0227) loss_oracle 0.4625 (0.5721) kd_loss 0.8237 (0.7859) acc 93.7500 (90.1562) gate/entropy 1.0282 (1.0282) gate/usage_max 0.4749 (0.4738) gate/usage_min 0.1781 (0.1776) gate/usage_std 0.1216 (0.1214) teacher/entropy 0.0433 (0.0793) teacher/usage_max 0.8097 (0.7527) teacher/usage_min 0.0941 (0.0602) teacher/usage_std 0.3369 (0.3034) nleep/row_max_mean 1543.9160 (1533.2499) nleep/row_max_std 55.0723 (51.0858) nleep/row_min_mean 1512.8953 (1504.6065) lr 3.6258e-04 eta 0:03:47
epoch [38/50] batch [160/173] time 0.152 (0.111) data 0.000 (0.002) loss 1.4062 (1.3563) teacher_loss 0.2920 (0.2696) loss_zs_kd 0.0156 (0.0228) loss_oracle 0.5763 (0.5717) kd_loss 0.8183 (0.7894) acc 93.7500 (90.2344) gate/entropy 1.0281 (1.0282) gate/usage_max 0.4749 (0.4739) gate/usage_min 0.1779 (0.1776) gate/usage_std 0.1216 (0.1214) teacher/entropy 0.1098 (0.0778) teacher/usage_max 0.6654 (0.7517) teacher/usage_min 0.1180 (0.0631) teacher/usage_std 0.2383 (0.3023) nleep/row_max_mean 1548.5225 (1533.2521) nleep/row_max_std 51.0053 (51.7737) nleep/row_min_mean 1523.7153 (1504.6622) lr 3.6258e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,999
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [39/50] batch [20/173] time 0.142 (0.166) data 0.000 (0.014) loss 1.4270 (1.3516) teacher_loss 0.3720 (0.2318) loss_zs_kd 0.0199 (0.0214) loss_oracle 0.4891 (0.5721) kd_loss 0.8005 (0.8230) acc 84.3750 (92.3438) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4756 (0.4754) gate/usage_min 0.1782 (0.1782) gate/usage_std 0.1218 (0.1217) teacher/entropy 0.0607 (0.0760) teacher/usage_max 0.8012 (0.7408) teacher/usage_min 0.0837 (0.0961) teacher/usage_std 0.3311 (0.2905) nleep/row_max_mean 1548.4807 (1533.1895) nleep/row_max_std 50.8392 (51.6827) nleep/row_min_mean 1516.7640 (1506.3683) lr 3.1545e-04 eta 0:05:40
epoch [39/50] batch [40/173] time 0.152 (0.158) data 0.000 (0.007) loss 1.3276 (1.3654) teacher_loss 0.2304 (0.2351) loss_zs_kd 0.0314 (0.0224) loss_oracle 0.5465 (0.5641) kd_loss 0.8083 (0.8371) acc 93.7500 (91.7969) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4762 (0.4756) gate/usage_min 0.1786 (0.1783) gate/usage_std 0.1218 (0.1217) teacher/entropy 0.0253 (0.0759) teacher/usage_max 0.8218 (0.7218) teacher/usage_min 0.0532 (0.1028) teacher/usage_std 0.3466 (0.2777) nleep/row_max_mean 1529.8728 (1530.6736) nleep/row_max_std 57.0147 (51.7959) nleep/row_min_mean 1497.7515 (1504.7770) lr 3.1545e-04 eta 0:05:20
epoch [39/50] batch [60/173] time 0.154 (0.155) data 0.000 (0.005) loss 1.3503 (1.3712) teacher_loss 0.1566 (0.2412) loss_zs_kd 0.0107 (0.0221) loss_oracle 0.6598 (0.5692) kd_loss 0.8585 (0.8344) acc 93.7500 (91.7708) gate/entropy 1.0281 (1.0281) gate/usage_max 0.4765 (0.4758) gate/usage_min 0.1787 (0.1784) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.1038 (0.0746) teacher/usage_max 0.6927 (0.7289) teacher/usage_min 0.1219 (0.1006) teacher/usage_std 0.2554 (0.2823) nleep/row_max_mean 1518.6786 (1530.9744) nleep/row_max_std 45.7691 (51.6067) nleep/row_min_mean 1493.0298 (1504.8350) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [80/173] time 0.155 (0.153) data 0.000 (0.004) loss 1.4570 (1.3778) teacher_loss 0.3090 (0.2448) loss_zs_kd 0.0155 (0.0221) loss_oracle 0.5677 (0.5708) kd_loss 0.8564 (0.8366) acc 84.3750 (91.4844) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4767 (0.4759) gate/usage_min 0.1787 (0.1784) gate/usage_std 0.1219 (0.1218) teacher/entropy 0.0593 (0.0732) teacher/usage_max 0.7408 (0.7252) teacher/usage_min 0.1212 (0.1008) teacher/usage_std 0.2882 (0.2799) nleep/row_max_mean 1507.0300 (1530.6007) nleep/row_max_std 57.8214 (52.1014) nleep/row_min_mean 1483.6541 (1504.5850) lr 3.1545e-04 eta 0:05:05
epoch [39/50] batch [100/173] time 0.082 (0.141) data 0.000 (0.003) loss 1.4575 (1.3814) teacher_loss 0.4188 (0.2415) loss_zs_kd 0.0354 (0.0218) loss_oracle 0.4669 (0.5708) kd_loss 0.7875 (0.8436) acc 87.5000 (91.6562) gate/entropy 1.0280 (1.0281) gate/usage_max 0.4769 (0.4761) gate/usage_min 0.1787 (0.1784) gate/usage_std 0.1220 (0.1218) teacher/entropy 0.0567 (0.0705) teacher/usage_max 0.8645 (0.7194) teacher/usage_min 0.0446 (0.1025) teacher/usage_std 0.3761 (0.2760) nleep/row_max_mean 1530.8071 (1530.9952) nleep/row_max_std 62.4966 (52.6288) nleep/row_min_mean 1503.2188 (1505.1019) lr 3.1545e-04 eta 0:04:38
epoch [39/50] batch [120/173] time 0.087 (0.135) data 0.000 (0.002) loss 1.4637 (1.3816) teacher_loss 0.2937 (0.2393) loss_zs_kd 0.0273 (0.0222) loss_oracle 0.5060 (0.5715) kd_loss 0.9034 (0.8455) acc 87.5000 (91.7448) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4772 (0.4763) gate/usage_min 0.1789 (0.1785) gate/usage_std 0.1220 (0.1218) teacher/entropy 0.0105 (0.0692) teacher/usage_max 0.7807 (0.7194) teacher/usage_min 0.0634 (0.1036) teacher/usage_std 0.3186 (0.2758) nleep/row_max_mean 1532.7617 (1530.9030) nleep/row_max_std 57.6186 (53.6960) nleep/row_min_mean 1506.1841 (1504.8624) lr 3.1545e-04 eta 0:04:23
epoch [39/50] batch [140/173] time 0.183 (0.130) data 0.000 (0.002) loss 1.2631 (1.3847) teacher_loss 0.2025 (0.2443) loss_zs_kd 0.0191 (0.0224) loss_oracle 0.5135 (0.5721) kd_loss 0.7943 (0.8432) acc 96.8750 (91.5179) gate/entropy 1.0280 (1.0280) gate/usage_max 0.4777 (0.4764) gate/usage_min 0.1791 (0.1786) gate/usage_std 0.1221 (0.1219) teacher/entropy 0.0287 (0.0673) teacher/usage_max 0.8524 (0.7242) teacher/usage_min 0.0545 (0.1021) teacher/usage_std 0.3674 (0.2791) nleep/row_max_mean 1534.6475 (1531.3153) nleep/row_max_std 60.9476 (54.2827) nleep/row_min_mean 1503.6948 (1505.1014) lr 3.1545e-04 eta 0:04:12
epoch [39/50] batch [160/173] time 0.064 (0.127) data 0.000 (0.002) loss 1.4449 (1.3854) teacher_loss 0.2552 (0.2429) loss_zs_kd 0.0217 (0.0225) loss_oracle 0.5216 (0.5723) kd_loss 0.9180 (0.8451) acc 90.6250 (91.4453) gate/entropy 1.0279 (1.0280) gate/usage_max 0.4778 (0.4766) gate/usage_min 0.1790 (0.1786) gate/usage_std 0.1222 (0.1219) teacher/entropy 0.0055 (0.0660) teacher/usage_max 0.6877 (0.7246) teacher/usage_min 0.1254 (0.1025) teacher/usage_std 0.2518 (0.2792) nleep/row_max_mean 1544.6692 (1531.7509) nleep/row_max_std 58.2125 (54.3915) nleep/row_min_mean 1515.1321 (1505.3866) lr 3.1545e-04 eta 0:04:03
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,291
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,993
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.1%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [40/50] batch [20/173] time 0.129 (0.124) data 0.000 (0.014) loss 1.3017 (1.4098) teacher_loss 0.1412 (0.2096) loss_zs_kd 0.0141 (0.0231) loss_oracle 0.6378 (0.6085) kd_loss 0.8346 (0.8845) acc 96.8750 (92.3438) gate/entropy 1.0279 (1.0279) gate/usage_max 0.4782 (0.4781) gate/usage_min 0.1793 (0.1792) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0686 (0.0613) teacher/usage_max 0.6744 (0.6770) teacher/usage_min 0.0882 (0.1154) teacher/usage_std 0.2487 (0.2486) nleep/row_max_mean 1534.5502 (1530.4540) nleep/row_max_std 54.6377 (49.2026) nleep/row_min_mean 1506.5850 (1504.7739) lr 2.7103e-04 eta 0:03:53
epoch [40/50] batch [40/173] time 0.163 (0.122) data 0.000 (0.007) loss 1.4299 (1.4130) teacher_loss 0.2851 (0.2133) loss_zs_kd 0.0338 (0.0234) loss_oracle 0.5522 (0.6102) kd_loss 0.8518 (0.8828) acc 93.7500 (91.9531) gate/entropy 1.0278 (1.0279) gate/usage_max 0.4783 (0.4782) gate/usage_min 0.1792 (0.1792) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0608 (0.0536) teacher/usage_max 0.7866 (0.6855) teacher/usage_min 0.0536 (0.1151) teacher/usage_std 0.3234 (0.2538) nleep/row_max_mean 1530.1472 (1532.5796) nleep/row_max_std 49.3435 (48.2107) nleep/row_min_mean 1503.3131 (1506.1465) lr 2.7103e-04 eta 0:03:46
epoch [40/50] batch [60/173] time 0.166 (0.124) data 0.000 (0.005) loss 1.2200 (1.4120) teacher_loss 0.1580 (0.2228) loss_zs_kd 0.0211 (0.0239) loss_oracle 0.5025 (0.6017) kd_loss 0.8002 (0.8764) acc 93.7500 (92.0833) gate/entropy 1.0278 (1.0279) gate/usage_max 0.4784 (0.4782) gate/usage_min 0.1793 (0.1793) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0489 (0.0539) teacher/usage_max 0.8254 (0.6910) teacher/usage_min 0.0829 (0.1159) teacher/usage_std 0.3480 (0.2570) nleep/row_max_mean 1540.2856 (1533.0494) nleep/row_max_std 42.2593 (48.6580) nleep/row_min_mean 1512.1924 (1506.8522) lr 2.7103e-04 eta 0:03:48
epoch [40/50] batch [80/173] time 0.155 (0.131) data 0.000 (0.004) loss 1.4748 (1.4143) teacher_loss 0.2975 (0.2273) loss_zs_kd 0.0253 (0.0234) loss_oracle 0.5491 (0.6004) kd_loss 0.8900 (0.8751) acc 84.3750 (91.4453) gate/entropy 1.0278 (1.0279) gate/usage_max 0.4784 (0.4783) gate/usage_min 0.1792 (0.1793) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0339 (0.0557) teacher/usage_max 0.7087 (0.6901) teacher/usage_min 0.1382 (0.1168) teacher/usage_std 0.2655 (0.2560) nleep/row_max_mean 1529.8909 (1533.2209) nleep/row_max_std 48.2976 (48.4124) nleep/row_min_mean 1507.6482 (1507.1859) lr 2.7103e-04 eta 0:03:58
epoch [40/50] batch [100/173] time 0.165 (0.137) data 0.000 (0.003) loss 1.4154 (1.4126) teacher_loss 0.3690 (0.2265) loss_zs_kd 0.0156 (0.0245) loss_oracle 0.4916 (0.5992) kd_loss 0.7928 (0.8742) acc 87.5000 (91.5000) gate/entropy 1.0277 (1.0279) gate/usage_max 0.4787 (0.4784) gate/usage_min 0.1793 (0.1793) gate/usage_std 0.1224 (0.1223) teacher/entropy 0.0463 (0.0564) teacher/usage_max 0.7838 (0.6896) teacher/usage_min 0.0464 (0.1170) teacher/usage_std 0.3225 (0.2556) nleep/row_max_mean 1539.9886 (1532.3162) nleep/row_max_std 50.2035 (49.0439) nleep/row_min_mean 1512.1011 (1506.2114) lr 2.7103e-04 eta 0:04:06
epoch [40/50] batch [120/173] time 0.167 (0.141) data 0.000 (0.002) loss 1.2624 (1.4148) teacher_loss 0.1961 (0.2351) loss_zs_kd 0.0118 (0.0243) loss_oracle 0.5093 (0.5964) kd_loss 0.8058 (0.8693) acc 96.8750 (90.9635) gate/entropy 1.0279 (1.0279) gate/usage_max 0.4789 (0.4784) gate/usage_min 0.1796 (0.1793) gate/usage_std 0.1223 (0.1223) teacher/entropy 0.0277 (0.0564) teacher/usage_max 0.8326 (0.6964) teacher/usage_min 0.0637 (0.1146) teacher/usage_std 0.3534 (0.2603) nleep/row_max_mean 1531.1433 (1532.1578) nleep/row_max_std 44.5244 (49.1704) nleep/row_min_mean 1504.3395 (1506.0423) lr 2.7103e-04 eta 0:04:11
epoch [40/50] batch [140/173] time 0.158 (0.143) data 0.000 (0.002) loss 1.5674 (1.4140) teacher_loss 0.3416 (0.2332) loss_zs_kd 0.0367 (0.0244) loss_oracle 0.5780 (0.5946) kd_loss 0.9184 (0.8713) acc 87.5000 (90.9821) gate/entropy 1.0277 (1.0279) gate/usage_max 0.4789 (0.4785) gate/usage_min 0.1794 (0.1794) gate/usage_std 0.1224 (0.1223) teacher/entropy 0.0130 (0.0550) teacher/usage_max 0.7202 (0.6980) teacher/usage_min 0.1237 (0.1154) teacher/usage_std 0.2739 (0.2611) nleep/row_max_mean 1543.6359 (1532.1641) nleep/row_max_std 41.2575 (49.1567) nleep/row_min_mean 1514.7140 (1506.0725) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [160/173] time 0.163 (0.146) data 0.000 (0.002) loss 1.7055 (1.4205) teacher_loss 0.3976 (0.2321) loss_zs_kd 0.0472 (0.0248) loss_oracle 0.6287 (0.5958) kd_loss 0.9700 (0.8781) acc 78.1250 (91.0156) gate/entropy 1.0277 (1.0278) gate/usage_max 0.4792 (0.4786) gate/usage_min 0.1794 (0.1794) gate/usage_std 0.1225 (0.1223) teacher/entropy 0.0321 (0.0523) teacher/usage_max 0.6554 (0.6947) teacher/usage_min 0.1117 (0.1169) teacher/usage_std 0.2331 (0.2587) nleep/row_max_mean 1536.6740 (1531.8689) nleep/row_max_std 38.7093 (48.9249) nleep/row_min_mean 1509.5813 (1505.8390) lr 2.7103e-04 eta 0:04:13
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [41/50] batch [20/173] time 0.068 (0.128) data 0.000 (0.014) loss 1.3237 (1.4037) teacher_loss 0.2513 (0.2247) loss_zs_kd 0.0233 (0.0229) loss_oracle 0.5921 (0.5790) kd_loss 0.7647 (0.8780) acc 87.5000 (91.4062) gate/entropy 1.0277 (1.0278) gate/usage_max 0.4795 (0.4796) gate/usage_min 0.1796 (0.1798) gate/usage_std 0.1226 (0.1225) teacher/entropy 0.0890 (0.0612) teacher/usage_max 0.7694 (0.7069) teacher/usage_min 0.0626 (0.0989) teacher/usage_std 0.3113 (0.2683) nleep/row_max_mean 1534.7079 (1524.2375) nleep/row_max_std 41.4980 (46.1691) nleep/row_min_mean 1510.7920 (1500.6722) lr 2.2949e-04 eta 0:03:38
epoch [41/50] batch [40/173] time 0.066 (0.120) data 0.000 (0.007) loss 1.6868 (1.4319) teacher_loss 0.4371 (0.2434) loss_zs_kd 0.0450 (0.0277) loss_oracle 0.6806 (0.5884) kd_loss 0.8869 (0.8804) acc 87.5000 (91.1719) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4797 (0.4797) gate/usage_min 0.1797 (0.1798) gate/usage_std 0.1226 (0.1225) teacher/entropy 0.0269 (0.0515) teacher/usage_max 0.6567 (0.7148) teacher/usage_min 0.0971 (0.1038) teacher/usage_std 0.2366 (0.2726) nleep/row_max_mean 1534.4045 (1525.6653) nleep/row_max_std 35.0330 (44.7496) nleep/row_min_mean 1509.9304 (1500.9180) lr 2.2949e-04 eta 0:03:22
epoch [41/50] batch [60/173] time 0.151 (0.117) data 0.000 (0.005) loss 1.4751 (1.4377) teacher_loss 0.2416 (0.2429) loss_zs_kd 0.0282 (0.0266) loss_oracle 0.5850 (0.5951) kd_loss 0.9269 (0.8839) acc 87.5000 (90.9375) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4799 (0.4797) gate/usage_min 0.1797 (0.1798) gate/usage_std 0.1226 (0.1226) teacher/entropy 0.0135 (0.0522) teacher/usage_max 0.6898 (0.6993) teacher/usage_min 0.1541 (0.1145) teacher/usage_std 0.2520 (0.2613) nleep/row_max_mean 1543.8260 (1528.4108) nleep/row_max_std 46.2033 (44.0062) nleep/row_min_mean 1517.9730 (1503.3689) lr 2.2949e-04 eta 0:03:15
epoch [41/50] batch [80/173] time 0.073 (0.111) data 0.000 (0.004) loss 1.4342 (1.4340) teacher_loss 0.1853 (0.2346) loss_zs_kd 0.0165 (0.0264) loss_oracle 0.5161 (0.6022) kd_loss 0.9826 (0.8851) acc 90.6250 (90.9766) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4802 (0.4798) gate/usage_min 0.1801 (0.1798) gate/usage_std 0.1226 (0.1226) teacher/entropy 0.0154 (0.0508) teacher/usage_max 0.6879 (0.6938) teacher/usage_min 0.0663 (0.1148) teacher/usage_std 0.2612 (0.2583) nleep/row_max_mean 1527.4447 (1528.8654) nleep/row_max_std 39.5856 (44.2851) nleep/row_min_mean 1499.2618 (1503.6217) lr 2.2949e-04 eta 0:03:03
epoch [41/50] batch [100/173] time 0.084 (0.110) data 0.000 (0.003) loss 1.4978 (1.4297) teacher_loss 0.3323 (0.2298) loss_zs_kd 0.0343 (0.0264) loss_oracle 0.5738 (0.6022) kd_loss 0.8614 (0.8857) acc 87.5000 (91.2188) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4802 (0.4799) gate/usage_min 0.1801 (0.1799) gate/usage_std 0.1226 (0.1226) teacher/entropy 0.0833 (0.0510) teacher/usage_max 0.7307 (0.6944) teacher/usage_min 0.0835 (0.1154) teacher/usage_std 0.2841 (0.2586) nleep/row_max_mean 1507.1396 (1529.1559) nleep/row_max_std 56.1658 (44.5951) nleep/row_min_mean 1484.3578 (1503.8198) lr 2.2949e-04 eta 0:02:59
epoch [41/50] batch [120/173] time 0.080 (0.111) data 0.000 (0.003) loss 1.5258 (1.4364) teacher_loss 0.3025 (0.2280) loss_zs_kd 0.0377 (0.0265) loss_oracle 0.6324 (0.6051) kd_loss 0.8883 (0.8926) acc 90.6250 (91.2240) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4803 (0.4799) gate/usage_min 0.1800 (0.1799) gate/usage_std 0.1227 (0.1226) teacher/entropy 0.0277 (0.0501) teacher/usage_max 0.6512 (0.6887) teacher/usage_min 0.0982 (0.1171) teacher/usage_std 0.2332 (0.2548) nleep/row_max_mean 1531.9446 (1528.6721) nleep/row_max_std 47.4991 (45.2073) nleep/row_min_mean 1507.6268 (1503.3569) lr 2.2949e-04 eta 0:02:59
epoch [41/50] batch [140/173] time 0.090 (0.113) data 0.000 (0.002) loss 1.4442 (1.4359) teacher_loss 0.1584 (0.2249) loss_zs_kd 0.0253 (0.0262) loss_oracle 0.6457 (0.6082) kd_loss 0.9503 (0.8937) acc 93.7500 (91.3170) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4801 (0.4800) gate/usage_min 0.1798 (0.1799) gate/usage_std 0.1227 (0.1226) teacher/entropy 0.0441 (0.0508) teacher/usage_max 0.5628 (0.6862) teacher/usage_min 0.1726 (0.1165) teacher/usage_std 0.1665 (0.2533) nleep/row_max_mean 1540.9030 (1529.0150) nleep/row_max_std 40.1878 (45.5228) nleep/row_min_mean 1517.1926 (1503.8282) lr 2.2949e-04 eta 0:02:58
epoch [41/50] batch [160/173] time 0.075 (0.112) data 0.000 (0.002) loss 1.5287 (1.4366) teacher_loss 0.3108 (0.2246) loss_zs_kd 0.0158 (0.0262) loss_oracle 0.5665 (0.6093) kd_loss 0.9267 (0.8942) acc 81.2500 (91.3672) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4804 (0.4800) gate/usage_min 0.1801 (0.1799) gate/usage_std 0.1227 (0.1226) teacher/entropy 0.0323 (0.0502) teacher/usage_max 0.6866 (0.6850) teacher/usage_min 0.1288 (0.1170) teacher/usage_std 0.2508 (0.2525) nleep/row_max_mean 1527.8335 (1529.4299) nleep/row_max_std 52.0901 (46.0347) nleep/row_min_mean 1504.3586 (1504.2836) lr 2.2949e-04 eta 0:02:55
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,292
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,999
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.5%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [42/50] batch [20/173] time 0.160 (0.162) data 0.000 (0.014) loss 1.1965 (1.4139) teacher_loss 0.0994 (0.1900) loss_zs_kd 0.0147 (0.0215) loss_oracle 0.6300 (0.6491) kd_loss 0.7748 (0.8886) acc 96.8750 (92.8125) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4805 (0.4803) gate/usage_min 0.1802 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.1079 (0.0575) teacher/usage_max 0.7757 (0.6694) teacher/usage_min 0.1108 (0.1385) teacher/usage_std 0.3128 (0.2407) nleep/row_max_mean 1516.9641 (1532.3263) nleep/row_max_std 46.0258 (49.1835) nleep/row_min_mean 1495.2217 (1507.0659) lr 1.9098e-04 eta 0:04:09
epoch [42/50] batch [40/173] time 0.153 (0.155) data 0.000 (0.007) loss 1.5616 (1.4114) teacher_loss 0.1881 (0.1840) loss_zs_kd 0.0148 (0.0211) loss_oracle 0.6848 (0.6333) kd_loss 1.0237 (0.9003) acc 96.8750 (92.6562) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4804 (0.4803) gate/usage_min 0.1801 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0668 (0.0488) teacher/usage_max 0.5578 (0.6782) teacher/usage_min 0.1209 (0.1244) teacher/usage_std 0.1786 (0.2477) nleep/row_max_mean 1524.5264 (1532.3263) nleep/row_max_std 45.7986 (47.4556) nleep/row_min_mean 1502.6759 (1507.0642) lr 1.9098e-04 eta 0:03:54
epoch [42/50] batch [60/173] time 0.138 (0.155) data 0.000 (0.005) loss 1.4605 (1.4146) teacher_loss 0.2735 (0.1925) loss_zs_kd 0.0127 (0.0215) loss_oracle 0.5786 (0.6310) kd_loss 0.8914 (0.8959) acc 93.7500 (92.3958) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4804 (0.4804) gate/usage_min 0.1800 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0517 (0.0484) teacher/usage_max 0.6718 (0.6758) teacher/usage_min 0.1517 (0.1244) teacher/usage_std 0.2396 (0.2463) nleep/row_max_mean 1537.7955 (1532.8291) nleep/row_max_std 46.3366 (47.2164) nleep/row_min_mean 1512.9377 (1507.5273) lr 1.9098e-04 eta 0:03:51
epoch [42/50] batch [80/173] time 0.153 (0.156) data 0.000 (0.004) loss 1.4014 (1.4135) teacher_loss 0.1754 (0.1875) loss_zs_kd 0.0127 (0.0210) loss_oracle 0.6453 (0.6319) kd_loss 0.8970 (0.8995) acc 93.7500 (92.6953) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4805 (0.4804) gate/usage_min 0.1802 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0150 (0.0479) teacher/usage_max 0.6542 (0.6709) teacher/usage_min 0.0943 (0.1270) teacher/usage_std 0.2358 (0.2425) nleep/row_max_mean 1528.9204 (1534.4204) nleep/row_max_std 52.9011 (47.6279) nleep/row_min_mean 1502.6085 (1508.8284) lr 1.9098e-04 eta 0:03:50
epoch [42/50] batch [100/173] time 0.162 (0.157) data 0.000 (0.003) loss 1.4711 (1.4229) teacher_loss 0.2506 (0.1991) loss_zs_kd 0.0267 (0.0219) loss_oracle 0.7540 (0.6334) kd_loss 0.8301 (0.8961) acc 90.6250 (92.1562) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4805 (0.4804) gate/usage_min 0.1802 (0.1801) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.1255 (0.0492) teacher/usage_max 0.6048 (0.6728) teacher/usage_min 0.1360 (0.1270) teacher/usage_std 0.1984 (0.2436) nleep/row_max_mean 1531.6814 (1535.7166) nleep/row_max_std 47.3851 (48.0344) nleep/row_min_mean 1509.1995 (1509.9039) lr 1.9098e-04 eta 0:03:49
epoch [42/50] batch [120/173] time 0.096 (0.146) data 0.000 (0.002) loss 1.5741 (1.4315) teacher_loss 0.2834 (0.2038) loss_zs_kd 0.0311 (0.0229) loss_oracle 0.7107 (0.6336) kd_loss 0.9198 (0.8995) acc 84.3750 (91.9271) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4804 (0.4804) gate/usage_min 0.1800 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0708 (0.0480) teacher/usage_max 0.5108 (0.6696) teacher/usage_min 0.1398 (0.1275) teacher/usage_std 0.1519 (0.2417) nleep/row_max_mean 1546.9316 (1537.0261) nleep/row_max_std 36.5871 (47.8573) nleep/row_min_mean 1523.9626 (1511.0740) lr 1.9098e-04 eta 0:03:30
epoch [42/50] batch [140/173] time 0.090 (0.143) data 0.000 (0.002) loss 1.4227 (1.4409) teacher_loss 0.1461 (0.2092) loss_zs_kd 0.0153 (0.0234) loss_oracle 0.7257 (0.6367) kd_loss 0.9061 (0.9016) acc 93.7500 (91.8304) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4802 (0.4804) gate/usage_min 0.1799 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0297 (0.0483) teacher/usage_max 0.6512 (0.6649) teacher/usage_min 0.1287 (0.1300) teacher/usage_std 0.2279 (0.2383) nleep/row_max_mean 1540.3707 (1537.7358) nleep/row_max_std 45.0192 (48.0705) nleep/row_min_mean 1516.2036 (1511.6351) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [160/173] time 0.079 (0.139) data 0.000 (0.002) loss 1.3735 (1.4442) teacher_loss 0.2487 (0.2130) loss_zs_kd 0.0417 (0.0239) loss_oracle 0.6168 (0.6358) kd_loss 0.7955 (0.9014) acc 90.6250 (91.6016) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4803 (0.4804) gate/usage_min 0.1799 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0996 (0.0492) teacher/usage_max 0.7377 (0.6635) teacher/usage_min 0.1121 (0.1304) teacher/usage_std 0.2864 (0.2373) nleep/row_max_mean 1538.2126 (1538.5190) nleep/row_max_std 56.8540 (48.4305) nleep/row_min_mean 1516.5535 (1512.4065) lr 1.9098e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.4%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [43/50] batch [20/173] time 0.096 (0.131) data 0.000 (0.017) loss 1.3791 (1.4773) teacher_loss 0.1941 (0.2199) loss_zs_kd 0.0147 (0.0264) loss_oracle 0.5699 (0.6332) kd_loss 0.8927 (0.9276) acc 90.6250 (91.7188) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4803 (0.4804) gate/usage_min 0.1800 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0492 (0.0504) teacher/usage_max 0.7087 (0.6388) teacher/usage_min 0.1212 (0.1457) teacher/usage_std 0.2662 (0.2191) nleep/row_max_mean 1540.7861 (1536.0542) nleep/row_max_std 56.4675 (54.2689) nleep/row_min_mean 1515.4336 (1510.7901) lr 1.5567e-04 eta 0:02:58
epoch [43/50] batch [40/173] time 0.107 (0.124) data 0.000 (0.009) loss 1.4937 (1.4649) teacher_loss 0.1417 (0.2094) loss_zs_kd 0.0228 (0.0256) loss_oracle 0.7239 (0.6346) kd_loss 0.9786 (0.9254) acc 93.7500 (92.2656) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4803 (0.4803) gate/usage_min 0.1799 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0732 (0.0497) teacher/usage_max 0.5577 (0.6434) teacher/usage_min 0.1823 (0.1393) teacher/usage_std 0.1618 (0.2229) nleep/row_max_mean 1536.7349 (1533.1538) nleep/row_max_std 50.2663 (52.9691) nleep/row_min_mean 1512.9331 (1508.4531) lr 1.5567e-04 eta 0:02:47
epoch [43/50] batch [60/173] time 0.085 (0.118) data 0.000 (0.006) loss 1.8722 (1.4529) teacher_loss 0.5379 (0.2002) loss_zs_kd 0.0580 (0.0250) loss_oracle 0.6210 (0.6315) kd_loss 0.9947 (0.9244) acc 81.2500 (92.5521) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4804 (0.4803) gate/usage_min 0.1800 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0960 (0.0516) teacher/usage_max 0.5832 (0.6474) teacher/usage_min 0.0817 (0.1364) teacher/usage_std 0.2047 (0.2260) nleep/row_max_mean 1506.7174 (1529.4605) nleep/row_max_std 51.6484 (53.5216) nleep/row_min_mean 1484.7361 (1505.0028) lr 1.5567e-04 eta 0:02:36
epoch [43/50] batch [80/173] time 0.173 (0.122) data 0.000 (0.004) loss 1.3965 (1.4612) teacher_loss 0.1502 (0.2050) loss_zs_kd 0.0425 (0.0254) loss_oracle 0.6829 (0.6396) kd_loss 0.8836 (0.9236) acc 96.8750 (92.5781) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4804 (0.4803) gate/usage_min 0.1801 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.1255 (0.0546) teacher/usage_max 0.5812 (0.6403) teacher/usage_min 0.2062 (0.1389) teacher/usage_std 0.1753 (0.2212) nleep/row_max_mean 1522.4816 (1528.8759) nleep/row_max_std 48.4336 (52.8959) nleep/row_min_mean 1499.1956 (1504.5542) lr 1.5567e-04 eta 0:02:38
epoch [43/50] batch [100/173] time 0.159 (0.130) data 0.000 (0.004) loss 1.4668 (1.4617) teacher_loss 0.1571 (0.2060) loss_zs_kd 0.0593 (0.0264) loss_oracle 0.5803 (0.6362) kd_loss 0.9899 (0.9244) acc 100.0000 (92.4375) gate/entropy 1.0276 (1.0277) gate/usage_max 0.4803 (0.4804) gate/usage_min 0.1799 (0.1800) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.1154 (0.0546) teacher/usage_max 0.5214 (0.6414) teacher/usage_min 0.1538 (0.1367) teacher/usage_std 0.1502 (0.2222) nleep/row_max_mean 1538.2786 (1528.5659) nleep/row_max_std 51.9693 (52.3455) nleep/row_min_mean 1512.3492 (1504.3275) lr 1.5567e-04 eta 0:02:46
epoch [43/50] batch [120/173] time 0.183 (0.135) data 0.000 (0.003) loss 1.3643 (1.4659) teacher_loss 0.1244 (0.2092) loss_zs_kd 0.0183 (0.0262) loss_oracle 0.7045 (0.6336) kd_loss 0.8785 (0.9269) acc 93.7500 (92.2917) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4805 (0.4804) gate/usage_min 0.1801 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0506 (0.0545) teacher/usage_max 0.6220 (0.6408) teacher/usage_min 0.1028 (0.1344) teacher/usage_std 0.2159 (0.2227) nleep/row_max_mean 1535.0422 (1528.5352) nleep/row_max_std 48.9051 (52.0817) nleep/row_min_mean 1506.3108 (1504.3583) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [140/173] time 0.149 (0.139) data 0.000 (0.003) loss 1.6198 (1.4643) teacher_loss 0.2689 (0.2075) loss_zs_kd 0.0348 (0.0254) loss_oracle 0.6644 (0.6336) kd_loss 1.0013 (0.9273) acc 90.6250 (92.2545) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4803 (0.4804) gate/usage_min 0.1798 (0.1800) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.0259 (0.0544) teacher/usage_max 0.6230 (0.6412) teacher/usage_min 0.1208 (0.1340) teacher/usage_std 0.2121 (0.2229) nleep/row_max_mean 1552.6484 (1529.3812) nleep/row_max_std 43.8239 (52.0628) nleep/row_min_mean 1526.2661 (1505.1531) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [160/173] time 0.161 (0.142) data 0.000 (0.002) loss 1.4796 (1.4640) teacher_loss 0.1355 (0.2077) loss_zs_kd 0.0203 (0.0254) loss_oracle 0.6693 (0.6337) kd_loss 0.9993 (0.9267) acc 96.8750 (92.1680) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4804 (0.4804) gate/usage_min 0.1800 (0.1800) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0804 (0.0556) teacher/usage_max 0.5356 (0.6401) teacher/usage_min 0.1720 (0.1350) teacher/usage_std 0.1512 (0.2220) nleep/row_max_mean 1553.4774 (1530.2465) nleep/row_max_std 46.9064 (51.7606) nleep/row_min_mean 1527.4473 (1506.0375) lr 1.5567e-04 eta 0:02:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [44/50] batch [20/173] time 0.209 (0.131) data 0.000 (0.014) loss 1.5483 (1.4992) teacher_loss 0.1922 (0.2120) loss_zs_kd 0.0253 (0.0232) loss_oracle 0.5943 (0.6391) kd_loss 1.0463 (0.9560) acc 93.7500 (92.1875) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4805 (0.4805) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0420 (0.0643) teacher/usage_max 0.5556 (0.6079) teacher/usage_min 0.1270 (0.1327) teacher/usage_std 0.1754 (0.2038) nleep/row_max_mean 1529.1780 (1535.1969) nleep/row_max_std 52.7264 (51.2860) nleep/row_min_mean 1504.8082 (1511.0462) lr 1.2369e-04 eta 0:02:36
epoch [44/50] batch [40/173] time 0.128 (0.125) data 0.000 (0.007) loss 1.6826 (1.5241) teacher_loss 0.3297 (0.2320) loss_zs_kd 0.0253 (0.0249) loss_oracle 0.7043 (0.6360) kd_loss 0.9880 (0.9617) acc 87.5000 (90.7031) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4805 (0.4805) gate/usage_min 0.1800 (0.1801) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.0755 (0.0696) teacher/usage_max 0.5210 (0.5954) teacher/usage_min 0.2196 (0.1399) teacher/usage_std 0.1337 (0.1958) nleep/row_max_mean 1545.6097 (1536.0083) nleep/row_max_std 44.2408 (50.1500) nleep/row_min_mean 1520.6897 (1512.1958) lr 1.2369e-04 eta 0:02:26
epoch [44/50] batch [60/173] time 0.201 (0.124) data 0.000 (0.005) loss 1.4427 (1.5117) teacher_loss 0.1529 (0.2178) loss_zs_kd 0.0216 (0.0233) loss_oracle 0.6948 (0.6322) kd_loss 0.9316 (0.9661) acc 93.7500 (91.2500) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4806 (0.4805) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.1287 (0.0733) teacher/usage_max 0.5281 (0.5901) teacher/usage_min 0.2119 (0.1394) teacher/usage_std 0.1391 (0.1931) nleep/row_max_mean 1544.3483 (1535.3401) nleep/row_max_std 39.2714 (50.2688) nleep/row_min_mean 1521.6195 (1511.5323) lr 1.2369e-04 eta 0:02:22
epoch [44/50] batch [80/173] time 0.082 (0.120) data 0.000 (0.004) loss 1.5243 (1.5112) teacher_loss 0.2330 (0.2094) loss_zs_kd 0.0290 (0.0235) loss_oracle 0.6145 (0.6319) kd_loss 0.9695 (0.9740) acc 90.6250 (91.6406) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4806) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.0863 (0.0719) teacher/usage_max 0.5620 (0.5861) teacher/usage_min 0.1674 (0.1389) teacher/usage_std 0.1671 (0.1918) nleep/row_max_mean 1537.8829 (1535.4836) nleep/row_max_std 47.3245 (50.1671) nleep/row_min_mean 1515.1562 (1511.6581) lr 1.2369e-04 eta 0:02:15
epoch [44/50] batch [100/173] time 0.063 (0.116) data 0.000 (0.003) loss 1.6000 (1.5234) teacher_loss 0.2070 (0.2073) loss_zs_kd 0.0166 (0.0245) loss_oracle 0.6458 (0.6372) kd_loss 1.0618 (0.9852) acc 90.6250 (91.6875) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4808 (0.4806) gate/usage_min 0.1803 (0.1801) gate/usage_std 0.1227 (0.1227) teacher/entropy 0.0556 (0.0718) teacher/usage_max 0.5510 (0.5753) teacher/usage_min 0.0874 (0.1397) teacher/usage_std 0.1903 (0.1861) nleep/row_max_mean 1522.5481 (1535.9449) nleep/row_max_std 62.7564 (49.6466) nleep/row_min_mean 1497.4735 (1511.9801) lr 1.2369e-04 eta 0:02:08
epoch [44/50] batch [120/173] time 0.127 (0.116) data 0.000 (0.003) loss 1.6950 (1.5285) teacher_loss 0.2111 (0.2051) loss_zs_kd 0.0352 (0.0253) loss_oracle 0.7393 (0.6419) kd_loss 1.0966 (0.9897) acc 90.6250 (91.7708) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4805 (0.4806) gate/usage_min 0.1799 (0.1801) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.0424 (0.0712) teacher/usage_max 0.4339 (0.5681) teacher/usage_min 0.2361 (0.1438) teacher/usage_std 0.0808 (0.1811) nleep/row_max_mean 1541.8774 (1535.8437) nleep/row_max_std 47.7225 (49.4430) nleep/row_min_mean 1515.4675 (1511.8282) lr 1.2369e-04 eta 0:02:06
epoch [44/50] batch [140/173] time 0.155 (0.116) data 0.000 (0.002) loss 1.6303 (1.5281) teacher_loss 0.1369 (0.2060) loss_zs_kd 0.0249 (0.0262) loss_oracle 0.7105 (0.6424) kd_loss 1.1257 (0.9879) acc 93.7500 (91.7411) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4807 (0.4806) gate/usage_min 0.1803 (0.1801) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0663 (0.0709) teacher/usage_max 0.4353 (0.5716) teacher/usage_min 0.1496 (0.1416) teacher/usage_std 0.1302 (0.1838) nleep/row_max_mean 1527.1802 (1536.1697) nleep/row_max_std 52.2198 (49.7056) nleep/row_min_mean 1503.6896 (1512.0358) lr 1.2369e-04 eta 0:02:04
epoch [44/50] batch [160/173] time 0.070 (0.116) data 0.000 (0.002) loss 1.6402 (1.5232) teacher_loss 0.3719 (0.2057) loss_zs_kd 0.0283 (0.0259) loss_oracle 0.6180 (0.6414) kd_loss 0.9452 (0.9838) acc 90.6250 (91.7578) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4806) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.1138 (0.0714) teacher/usage_max 0.6074 (0.5750) teacher/usage_min 0.0927 (0.1424) teacher/usage_std 0.2114 (0.1852) nleep/row_max_mean 1547.8555 (1536.9559) nleep/row_max_std 53.3444 (50.0488) nleep/row_min_mean 1521.4614 (1512.7506) lr 1.2369e-04 eta 0:02:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,993
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.1%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [45/50] batch [20/173] time 0.161 (0.165) data 0.000 (0.014) loss 1.4215 (1.5778) teacher_loss 0.2134 (0.2033) loss_zs_kd 0.0467 (0.0290) loss_oracle 0.6599 (0.6659) kd_loss 0.8548 (1.0271) acc 87.5000 (92.1875) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0437 (0.0519) teacher/usage_max 0.7891 (0.5443) teacher/usage_min 0.0645 (0.1609) teacher/usage_std 0.3240 (0.1649) nleep/row_max_mean 1545.2617 (1537.2389) nleep/row_max_std 50.7567 (52.9008) nleep/row_min_mean 1518.2482 (1512.1555) lr 9.5173e-05 eta 0:02:48
epoch [45/50] batch [40/173] time 0.162 (0.162) data 0.000 (0.007) loss 1.5919 (1.5626) teacher_loss 0.3974 (0.2245) loss_zs_kd 0.0247 (0.0281) loss_oracle 0.5138 (0.6513) kd_loss 0.9253 (0.9984) acc 84.3750 (91.2500) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0246 (0.0575) teacher/usage_max 0.7571 (0.5703) teacher/usage_min 0.0327 (0.1505) teacher/usage_std 0.3083 (0.1808) nleep/row_max_mean 1540.0861 (1537.5541) nleep/row_max_std 65.6478 (55.3687) nleep/row_min_mean 1512.0782 (1512.2148) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [60/173] time 0.170 (0.162) data 0.000 (0.005) loss 1.5993 (1.5582) teacher_loss 0.1554 (0.2298) loss_zs_kd 0.0319 (0.0290) loss_oracle 0.6195 (0.6385) kd_loss 1.1182 (0.9946) acc 96.8750 (90.3646) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4806 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0067 (0.0569) teacher/usage_max 0.4993 (0.5702) teacher/usage_min 0.1568 (0.1500) teacher/usage_std 0.1400 (0.1802) nleep/row_max_mean 1534.0686 (1538.6173) nleep/row_max_std 46.7229 (54.8443) nleep/row_min_mean 1509.3340 (1513.3847) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [80/173] time 0.125 (0.162) data 0.001 (0.004) loss 1.5395 (1.5531) teacher_loss 0.1868 (0.2227) loss_zs_kd 0.0179 (0.0282) loss_oracle 0.6191 (0.6427) kd_loss 1.0342 (0.9949) acc 87.5000 (90.7812) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4811 (0.4808) gate/usage_min 0.1805 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0516 (0.0589) teacher/usage_max 0.5607 (0.5652) teacher/usage_min 0.1207 (0.1553) teacher/usage_std 0.1799 (0.1756) nleep/row_max_mean 1520.1671 (1537.9645) nleep/row_max_std 62.2441 (55.2214) nleep/row_min_mean 1492.9650 (1512.9178) lr 9.5173e-05 eta 0:02:34
epoch [45/50] batch [100/173] time 0.122 (0.159) data 0.000 (0.003) loss 1.6342 (1.5526) teacher_loss 0.2942 (0.2136) loss_zs_kd 0.0343 (0.0275) loss_oracle 0.5814 (0.6439) kd_loss 1.0322 (1.0033) acc 87.5000 (91.0938) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0245 (0.0577) teacher/usage_max 0.5480 (0.5573) teacher/usage_min 0.1875 (0.1576) teacher/usage_std 0.1550 (0.1708) nleep/row_max_mean 1533.9414 (1536.9259) nleep/row_max_std 50.7515 (54.5672) nleep/row_min_mean 1506.0753 (1511.9207) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [120/173] time 0.096 (0.152) data 0.000 (0.003) loss 1.5789 (1.5574) teacher_loss 0.2303 (0.2187) loss_zs_kd 0.0153 (0.0278) loss_oracle 0.6319 (0.6429) kd_loss 1.0250 (1.0033) acc 87.5000 (90.9635) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0754 (0.0573) teacher/usage_max 0.5511 (0.5582) teacher/usage_min 0.1142 (0.1563) teacher/usage_std 0.1784 (0.1715) nleep/row_max_mean 1523.5986 (1537.0359) nleep/row_max_std 57.8200 (54.3028) nleep/row_min_mean 1499.5779 (1511.9711) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [140/173] time 0.094 (0.147) data 0.000 (0.002) loss 1.4946 (1.5537) teacher_loss 0.0669 (0.2132) loss_zs_kd 0.0219 (0.0277) loss_oracle 0.6923 (0.6443) kd_loss 1.0706 (1.0045) acc 96.8750 (91.2946) gate/entropy 1.0278 (1.0276) gate/usage_max 0.4811 (0.4808) gate/usage_min 0.1806 (0.1802) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0519 (0.0584) teacher/usage_max 0.5339 (0.5561) teacher/usage_min 0.1043 (0.1562) teacher/usage_std 0.1766 (0.1707) nleep/row_max_mean 1505.4269 (1535.9086) nleep/row_max_std 63.4479 (54.5936) nleep/row_min_mean 1479.6473 (1510.9242) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [160/173] time 0.070 (0.143) data 0.000 (0.002) loss 1.4657 (1.5514) teacher_loss 0.1505 (0.2105) loss_zs_kd 0.0350 (0.0273) loss_oracle 0.5794 (0.6471) kd_loss 1.0080 (1.0037) acc 93.7500 (91.4648) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0356 (0.0573) teacher/usage_max 0.6263 (0.5564) teacher/usage_min 0.0876 (0.1563) teacher/usage_std 0.2225 (0.1709) nleep/row_max_mean 1521.4220 (1534.9407) nleep/row_max_std 51.5102 (54.4379) nleep/row_min_mean 1495.4517 (1509.8780) lr 9.5173e-05 eta 0:02:05
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [46/50] batch [20/173] time 0.085 (0.132) data 0.000 (0.015) loss 1.5628 (1.5579) teacher_loss 0.1905 (0.2312) loss_zs_kd 0.0168 (0.0285) loss_oracle 0.6998 (0.6577) kd_loss 1.0140 (0.9836) acc 93.7500 (92.3438) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0670 (0.0675) teacher/usage_max 0.5080 (0.5612) teacher/usage_min 0.2120 (0.1686) teacher/usage_std 0.1266 (0.1683) nleep/row_max_mean 1543.4091 (1528.6687) nleep/row_max_std 49.8029 (50.2098) nleep/row_min_mean 1519.6006 (1503.4324) lr 7.0224e-05 eta 0:01:51
epoch [46/50] batch [40/173] time 0.178 (0.129) data 0.000 (0.008) loss 1.4680 (1.5599) teacher_loss 0.2807 (0.2083) loss_zs_kd 0.0271 (0.0275) loss_oracle 0.5660 (0.6624) kd_loss 0.8908 (1.0065) acc 87.5000 (92.9688) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0511 (0.0551) teacher/usage_max 0.7172 (0.5547) teacher/usage_min 0.1065 (0.1664) teacher/usage_std 0.2729 (0.1661) nleep/row_max_mean 1521.8962 (1527.4741) nleep/row_max_std 55.9382 (52.7282) nleep/row_min_mean 1497.2327 (1502.4862) lr 7.0224e-05 eta 0:01:46
epoch [46/50] batch [60/173] time 0.181 (0.126) data 0.000 (0.005) loss 1.4785 (1.5314) teacher_loss 0.1238 (0.2007) loss_zs_kd 0.0210 (0.0281) loss_oracle 0.6625 (0.6519) kd_loss 1.0129 (0.9908) acc 93.7500 (93.0729) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0215 (0.0536) teacher/usage_max 0.6250 (0.5777) teacher/usage_min 0.1043 (0.1572) teacher/usage_std 0.2171 (0.1812) nleep/row_max_mean 1541.0486 (1530.0263) nleep/row_max_std 59.9931 (53.2576) nleep/row_min_mean 1514.5293 (1504.4278) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [80/173] time 0.148 (0.123) data 0.000 (0.004) loss 1.5677 (1.5490) teacher_loss 0.0827 (0.2052) loss_zs_kd 0.0098 (0.0275) loss_oracle 0.7312 (0.6550) kd_loss 1.1145 (1.0025) acc 96.8750 (92.6562) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0584 (0.0526) teacher/usage_max 0.4079 (0.5669) teacher/usage_min 0.2220 (0.1525) teacher/usage_std 0.0802 (0.1776) nleep/row_max_mean 1514.2783 (1529.8872) nleep/row_max_std 55.9454 (52.4128) nleep/row_min_mean 1491.4568 (1504.4212) lr 7.0224e-05 eta 0:01:36
epoch [46/50] batch [100/173] time 0.163 (0.129) data 0.000 (0.003) loss 1.5051 (1.5440) teacher_loss 0.1941 (0.2013) loss_zs_kd 0.0292 (0.0276) loss_oracle 0.6287 (0.6562) kd_loss 0.9821 (1.0008) acc 96.8750 (92.8125) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4810 (0.4808) gate/usage_min 0.1805 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0582 (0.0515) teacher/usage_max 0.5813 (0.5662) teacher/usage_min 0.1609 (0.1564) teacher/usage_std 0.1797 (0.1762) nleep/row_max_mean 1506.3262 (1528.7105) nleep/row_max_std 60.0090 (52.5027) nleep/row_min_mean 1483.7725 (1503.4086) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [120/173] time 0.166 (0.132) data 0.000 (0.003) loss 1.5463 (1.5474) teacher_loss 0.1729 (0.2058) loss_zs_kd 0.0209 (0.0274) loss_oracle 0.6581 (0.6539) kd_loss 1.0340 (1.0010) acc 90.6250 (92.6823) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1804 (0.1802) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0659 (0.0503) teacher/usage_max 0.4951 (0.5664) teacher/usage_min 0.2011 (0.1583) teacher/usage_std 0.1218 (0.1760) nleep/row_max_mean 1509.9370 (1528.5803) nleep/row_max_std 55.5081 (52.6287) nleep/row_min_mean 1486.8879 (1503.3375) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [140/173] time 0.160 (0.135) data 0.000 (0.002) loss 1.4483 (1.5400) teacher_loss 0.0474 (0.1999) loss_zs_kd 0.0238 (0.0271) loss_oracle 0.6432 (0.6540) kd_loss 1.0673 (0.9996) acc 100.0000 (92.7455) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1804 (0.1802) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0464 (0.0508) teacher/usage_max 0.5468 (0.5663) teacher/usage_min 0.0989 (0.1602) teacher/usage_std 0.1835 (0.1755) nleep/row_max_mean 1511.4614 (1528.5478) nleep/row_max_std 59.6672 (52.1937) nleep/row_min_mean 1487.5869 (1503.4521) lr 7.0224e-05 eta 0:01:37
epoch [46/50] batch [160/173] time 0.125 (0.135) data 0.000 (0.002) loss 1.7794 (1.5415) teacher_loss 0.4787 (0.2026) loss_zs_kd 0.0446 (0.0269) loss_oracle 0.6508 (0.6552) kd_loss 0.9530 (0.9978) acc 84.3750 (92.6562) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0852 (0.0513) teacher/usage_max 0.5674 (0.5662) teacher/usage_min 0.1870 (0.1614) teacher/usage_std 0.1672 (0.1749) nleep/row_max_mean 1532.3715 (1529.1648) nleep/row_max_std 41.1901 (51.7367) nleep/row_min_mean 1508.4475 (1504.1008) lr 7.0224e-05 eta 0:01:35
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,296
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [47/50] batch [20/173] time 0.068 (0.161) data 0.000 (0.016) loss 1.4331 (1.5188) teacher_loss 0.1475 (0.1709) loss_zs_kd 0.0217 (0.0265) loss_oracle 0.5666 (0.6486) kd_loss 0.9914 (1.0104) acc 93.7500 (95.0000) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0291 (0.0512) teacher/usage_max 0.5685 (0.5478) teacher/usage_min 0.2130 (0.1654) teacher/usage_std 0.1663 (0.1650) nleep/row_max_mean 1532.9763 (1529.3767) nleep/row_max_std 51.4212 (53.7758) nleep/row_min_mean 1508.9912 (1504.4807) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [40/173] time 0.141 (0.126) data 0.000 (0.008) loss 1.4791 (1.5342) teacher_loss 0.3261 (0.1973) loss_zs_kd 0.0436 (0.0272) loss_oracle 0.5420 (0.6490) kd_loss 0.8601 (0.9988) acc 87.5000 (93.1250) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.1417 (0.0552) teacher/usage_max 0.6550 (0.5507) teacher/usage_min 0.1091 (0.1640) teacher/usage_std 0.2333 (0.1663) nleep/row_max_mean 1539.7650 (1529.5705) nleep/row_max_std 47.1779 (52.4978) nleep/row_min_mean 1514.8357 (1504.4607) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [60/173] time 0.084 (0.124) data 0.001 (0.005) loss 1.4949 (1.5178) teacher_loss 0.1911 (0.1935) loss_zs_kd 0.0420 (0.0269) loss_oracle 0.5435 (0.6467) kd_loss 1.0110 (0.9875) acc 96.8750 (92.8125) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0195 (0.0561) teacher/usage_max 0.5937 (0.5684) teacher/usage_min 0.1589 (0.1572) teacher/usage_std 0.1876 (0.1775) nleep/row_max_mean 1528.1348 (1527.8566) nleep/row_max_std 50.5724 (51.7674) nleep/row_min_mean 1501.5424 (1502.6757) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [80/173] time 0.098 (0.123) data 0.000 (0.004) loss 1.7763 (1.5186) teacher_loss 0.2501 (0.1932) loss_zs_kd 0.0221 (0.0264) loss_oracle 0.7248 (0.6484) kd_loss 1.1527 (0.9880) acc 90.6250 (92.8516) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0162 (0.0558) teacher/usage_max 0.3743 (0.5685) teacher/usage_min 0.2795 (0.1587) teacher/usage_std 0.0397 (0.1772) nleep/row_max_mean 1533.3182 (1527.6301) nleep/row_max_std 41.9637 (50.7082) nleep/row_min_mean 1510.4514 (1502.5807) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [100/173] time 0.075 (0.122) data 0.000 (0.003) loss 1.8008 (1.5189) teacher_loss 0.3814 (0.1965) loss_zs_kd 0.0226 (0.0267) loss_oracle 0.6273 (0.6495) kd_loss 1.0945 (0.9843) acc 81.2500 (92.6250) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4806 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0217 (0.0570) teacher/usage_max 0.4685 (0.5714) teacher/usage_min 0.2179 (0.1592) teacher/usage_std 0.1033 (0.1785) nleep/row_max_mean 1530.1206 (1527.7476) nleep/row_max_std 43.4652 (49.9069) nleep/row_min_mean 1507.7878 (1502.7607) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [120/173] time 0.102 (0.119) data 0.000 (0.003) loss 1.7355 (1.5287) teacher_loss 0.2956 (0.1999) loss_zs_kd 0.0251 (0.0267) loss_oracle 0.7228 (0.6529) kd_loss 1.0659 (0.9891) acc 81.2500 (92.3698) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0482 (0.0564) teacher/usage_max 0.4377 (0.5661) teacher/usage_min 0.2681 (0.1627) teacher/usage_std 0.0746 (0.1746) nleep/row_max_mean 1537.2299 (1528.1286) nleep/row_max_std 42.4609 (49.0728) nleep/row_min_mean 1510.6177 (1503.1391) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [140/173] time 0.185 (0.119) data 0.000 (0.002) loss 1.4990 (1.5282) teacher_loss 0.1150 (0.1973) loss_zs_kd 0.0358 (0.0266) loss_oracle 0.6083 (0.6525) kd_loss 1.0619 (0.9914) acc 96.8750 (92.5223) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0185 (0.0543) teacher/usage_max 0.5635 (0.5687) teacher/usage_min 0.1264 (0.1592) teacher/usage_std 0.1792 (0.1766) nleep/row_max_mean 1542.9204 (1529.1918) nleep/row_max_std 39.0938 (48.9537) nleep/row_min_mean 1514.7207 (1503.9456) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [160/173] time 0.073 (0.119) data 0.000 (0.002) loss 1.4071 (1.5290) teacher_loss 0.0890 (0.1973) loss_zs_kd 0.0176 (0.0266) loss_oracle 0.5994 (0.6521) kd_loss 1.0097 (0.9924) acc 100.0000 (92.5977) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0112 (0.0526) teacher/usage_max 0.6259 (0.5702) teacher/usage_min 0.1243 (0.1586) teacher/usage_std 0.2131 (0.1778) nleep/row_max_mean 1547.2737 (1530.4858) nleep/row_max_std 47.3437 (48.9810) nleep/row_min_mean 1520.6777 (1504.9937) lr 4.8943e-05 eta 0:01:03
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,996
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.3%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [48/50] batch [20/173] time 0.157 (0.180) data 0.000 (0.013) loss 1.5673 (1.5891) teacher_loss 0.1704 (0.2717) loss_zs_kd 0.0238 (0.0299) loss_oracle 0.7191 (0.6418) kd_loss 1.0255 (0.9816) acc 93.7500 (89.0625) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4807) gate/usage_min 0.1801 (0.1801) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0753 (0.0495) teacher/usage_max 0.4940 (0.5787) teacher/usage_min 0.2030 (0.1591) teacher/usage_std 0.1207 (0.1803) nleep/row_max_mean 1552.1287 (1544.7085) nleep/row_max_std 41.7149 (46.5041) nleep/row_min_mean 1522.7375 (1517.9308) lr 3.1417e-05 eta 0:01:29
epoch [48/50] batch [40/173] time 0.158 (0.173) data 0.000 (0.007) loss 1.7162 (1.5632) teacher_loss 0.2325 (0.2395) loss_zs_kd 0.0415 (0.0283) loss_oracle 0.6445 (0.6448) kd_loss 1.1407 (0.9871) acc 90.6250 (90.5469) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0449 (0.0489) teacher/usage_max 0.4565 (0.5766) teacher/usage_min 0.1252 (0.1608) teacher/usage_std 0.1480 (0.1812) nleep/row_max_mean 1524.8639 (1541.9118) nleep/row_max_std 43.9751 (46.8326) nleep/row_min_mean 1502.1074 (1515.3039) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [60/173] time 0.158 (0.170) data 0.000 (0.005) loss 1.6037 (1.5446) teacher_loss 0.3049 (0.2202) loss_zs_kd 0.0491 (0.0286) loss_oracle 0.5858 (0.6404) kd_loss 0.9813 (0.9899) acc 87.5000 (91.4583) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4807 (0.4807) gate/usage_min 0.1800 (0.1801) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0762 (0.0484) teacher/usage_max 0.5937 (0.5766) teacher/usage_min 0.1161 (0.1587) teacher/usage_std 0.1973 (0.1818) nleep/row_max_mean 1547.0284 (1542.4273) nleep/row_max_std 46.4619 (46.5339) nleep/row_min_mean 1517.8196 (1515.7697) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [80/173] time 0.167 (0.168) data 0.000 (0.003) loss 1.5443 (1.5521) teacher_loss 0.3158 (0.2225) loss_zs_kd 0.0268 (0.0290) loss_oracle 0.5519 (0.6371) kd_loss 0.9392 (0.9965) acc 90.6250 (91.3281) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4807) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0435 (0.0483) teacher/usage_max 0.6639 (0.5724) teacher/usage_min 0.1250 (0.1553) teacher/usage_std 0.2364 (0.1808) nleep/row_max_mean 1544.3749 (1541.2237) nleep/row_max_std 51.7389 (47.1986) nleep/row_min_mean 1514.9109 (1514.7607) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [100/173] time 0.149 (0.167) data 0.000 (0.003) loss 1.5600 (1.5528) teacher_loss 0.1853 (0.2175) loss_zs_kd 0.0365 (0.0280) loss_oracle 0.6327 (0.6403) kd_loss 1.0401 (1.0012) acc 87.5000 (91.4688) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4807) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0623 (0.0481) teacher/usage_max 0.5165 (0.5688) teacher/usage_min 0.1643 (0.1545) teacher/usage_std 0.1441 (0.1787) nleep/row_max_mean 1530.2190 (1541.6980) nleep/row_max_std 52.3609 (47.3889) nleep/row_min_mean 1506.4041 (1515.2651) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [120/173] time 0.079 (0.164) data 0.000 (0.002) loss 1.3710 (1.5464) teacher_loss 0.1851 (0.2117) loss_zs_kd 0.0366 (0.0281) loss_oracle 0.5739 (0.6385) kd_loss 0.8807 (1.0014) acc 90.6250 (91.8750) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0410 (0.0477) teacher/usage_max 0.7068 (0.5697) teacher/usage_min 0.1386 (0.1550) teacher/usage_std 0.2641 (0.1791) nleep/row_max_mean 1540.9950 (1541.5668) nleep/row_max_std 55.8195 (47.8206) nleep/row_min_mean 1507.8441 (1515.0247) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [140/173] time 0.101 (0.154) data 0.000 (0.002) loss 1.5277 (1.5501) teacher_loss 0.1980 (0.2129) loss_zs_kd 0.0251 (0.0282) loss_oracle 0.5755 (0.6365) kd_loss 1.0293 (1.0049) acc 93.7500 (91.8304) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4807) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0517 (0.0468) teacher/usage_max 0.5385 (0.5658) teacher/usage_min 0.1637 (0.1570) teacher/usage_std 0.1550 (0.1764) nleep/row_max_mean 1545.8545 (1542.1443) nleep/row_max_std 59.1535 (48.3138) nleep/row_min_mean 1518.4104 (1515.5026) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [160/173] time 0.068 (0.149) data 0.000 (0.002) loss 1.4868 (1.5471) teacher_loss 0.1587 (0.2112) loss_zs_kd 0.0256 (0.0278) loss_oracle 0.6620 (0.6363) kd_loss 0.9843 (1.0039) acc 93.7500 (91.8750) gate/entropy 1.0277 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0223 (0.0471) teacher/usage_max 0.6576 (0.5678) teacher/usage_min 0.0967 (0.1558) teacher/usage_std 0.2373 (0.1778) nleep/row_max_mean 1528.7583 (1541.5466) nleep/row_max_std 65.3869 (48.8088) nleep/row_min_mean 1500.4424 (1514.8649) lr 3.1417e-05 eta 0:00:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [49/50] batch [20/173] time 0.189 (0.126) data 0.000 (0.014) loss 1.5462 (1.5451) teacher_loss 0.2847 (0.1995) loss_zs_kd 0.0325 (0.0249) loss_oracle 0.5934 (0.6643) kd_loss 0.9486 (1.0010) acc 87.5000 (92.9688) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0957 (0.0510) teacher/usage_max 0.6106 (0.5583) teacher/usage_min 0.1103 (0.1722) teacher/usage_std 0.2078 (0.1680) nleep/row_max_mean 1546.6492 (1537.1952) nleep/row_max_std 48.9612 (55.8237) nleep/row_min_mean 1521.0278 (1510.7485) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [40/173] time 0.155 (0.119) data 0.000 (0.007) loss 1.6243 (1.5530) teacher_loss 0.2377 (0.2025) loss_zs_kd 0.0316 (0.0269) loss_oracle 0.5741 (0.6579) kd_loss 1.0838 (1.0081) acc 87.5000 (92.7344) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0368 (0.0483) teacher/usage_max 0.5612 (0.5586) teacher/usage_min 0.0663 (0.1667) teacher/usage_std 0.2039 (0.1703) nleep/row_max_mean 1548.4789 (1538.8629) nleep/row_max_std 55.1948 (55.0572) nleep/row_min_mean 1520.6155 (1511.8407) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [60/173] time 0.084 (0.125) data 0.000 (0.005) loss 1.3324 (1.5618) teacher_loss 0.0859 (0.2168) loss_zs_kd 0.0272 (0.0273) loss_oracle 0.6161 (0.6539) kd_loss 0.9249 (1.0044) acc 100.0000 (92.3438) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0818 (0.0535) teacher/usage_max 0.6172 (0.5595) teacher/usage_min 0.1595 (0.1631) teacher/usage_std 0.2024 (0.1715) nleep/row_max_mean 1533.8873 (1538.7957) nleep/row_max_std 58.5648 (54.4452) nleep/row_min_mean 1506.6044 (1511.9743) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [80/173] time 0.163 (0.123) data 0.000 (0.004) loss 1.6804 (1.5590) teacher_loss 0.2278 (0.2148) loss_zs_kd 0.0268 (0.0270) loss_oracle 0.7593 (0.6546) kd_loss 1.0595 (1.0034) acc 90.6250 (92.3047) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0438 (0.0532) teacher/usage_max 0.4675 (0.5566) teacher/usage_min 0.2391 (0.1688) teacher/usage_std 0.0974 (0.1681) nleep/row_max_mean 1551.4305 (1539.8298) nleep/row_max_std 46.1034 (55.0563) nleep/row_min_mean 1523.3257 (1512.9919) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [100/173] time 0.163 (0.131) data 0.000 (0.003) loss 1.5698 (1.5605) teacher_loss 0.1620 (0.2187) loss_zs_kd 0.0111 (0.0276) loss_oracle 0.7113 (0.6526) kd_loss 1.0465 (1.0017) acc 93.7500 (92.2500) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0185 (0.0523) teacher/usage_max 0.4991 (0.5595) teacher/usage_min 0.2501 (0.1674) teacher/usage_std 0.1172 (0.1698) nleep/row_max_mean 1547.4839 (1540.1495) nleep/row_max_std 59.9890 (55.6704) nleep/row_min_mean 1523.2550 (1513.2641) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [120/173] time 0.134 (0.135) data 0.000 (0.003) loss 1.4037 (1.5499) teacher_loss 0.1281 (0.2141) loss_zs_kd 0.0254 (0.0272) loss_oracle 0.5940 (0.6516) kd_loss 0.9659 (0.9964) acc 96.8750 (92.4219) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0507 (0.0513) teacher/usage_max 0.6281 (0.5654) teacher/usage_min 0.1267 (0.1661) teacher/usage_std 0.2140 (0.1732) nleep/row_max_mean 1547.5334 (1539.9789) nleep/row_max_std 50.2006 (55.7680) nleep/row_min_mean 1521.3196 (1513.0146) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [140/173] time 0.160 (0.137) data 0.000 (0.002) loss 1.6301 (1.5484) teacher_loss 0.3234 (0.2130) loss_zs_kd 0.0370 (0.0269) loss_oracle 0.5648 (0.6495) kd_loss 1.0058 (0.9973) acc 90.6250 (92.3884) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4806 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0147 (0.0504) teacher/usage_max 0.6254 (0.5668) teacher/usage_min 0.1262 (0.1636) teacher/usage_std 0.2124 (0.1744) nleep/row_max_mean 1542.6482 (1540.1426) nleep/row_max_std 58.7612 (55.6395) nleep/row_min_mean 1516.0637 (1513.2187) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [160/173] time 0.163 (0.140) data 0.000 (0.002) loss 1.3476 (1.5441) teacher_loss 0.1350 (0.2094) loss_zs_kd 0.0282 (0.0266) loss_oracle 0.6394 (0.6472) kd_loss 0.8787 (0.9978) acc 100.0000 (92.4609) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0239 (0.0501) teacher/usage_max 0.7824 (0.5680) teacher/usage_min 0.0679 (0.1615) teacher/usage_std 0.3193 (0.1757) nleep/row_max_mean 1543.8770 (1539.0420) nleep/row_max_std 55.7651 (55.8478) nleep/row_min_mean 1510.2090 (1512.1485) lr 1.7713e-05 eta 0:00:26
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
epoch [50/50] batch [20/173] time 0.079 (0.133) data 0.000 (0.013) loss 1.6436 (1.5236) teacher_loss 0.2995 (0.2072) loss_zs_kd 0.0454 (0.0261) loss_oracle 0.6378 (0.6484) kd_loss 1.0025 (0.9791) acc 84.3750 (92.3438) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0394 (0.0462) teacher/usage_max 0.5642 (0.5950) teacher/usage_min 0.1852 (0.1598) teacher/usage_std 0.1654 (0.1920) nleep/row_max_mean 1535.3052 (1537.0739) nleep/row_max_std 47.7511 (54.1316) nleep/row_min_mean 1508.5253 (1510.6685) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [40/173] time 0.065 (0.114) data 0.000 (0.007) loss 1.5782 (1.5389) teacher_loss 0.2577 (0.2129) loss_zs_kd 0.0298 (0.0266) loss_oracle 0.7070 (0.6506) kd_loss 0.9521 (0.9873) acc 90.6250 (91.9531) gate/entropy 1.0275 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1799 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0214 (0.0473) teacher/usage_max 0.6506 (0.5885) teacher/usage_min 0.1614 (0.1546) teacher/usage_std 0.2246 (0.1892) nleep/row_max_mean 1555.1567 (1537.2934) nleep/row_max_std 50.2235 (54.9570) nleep/row_min_mean 1524.9246 (1510.8538) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [60/173] time 0.086 (0.107) data 0.000 (0.005) loss 1.6620 (1.5329) teacher_loss 0.2437 (0.2099) loss_zs_kd 0.0305 (0.0258) loss_oracle 0.6759 (0.6479) kd_loss 1.0651 (0.9860) acc 90.6250 (92.0833) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4806 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0809 (0.0467) teacher/usage_max 0.4260 (0.5903) teacher/usage_min 0.2362 (0.1522) teacher/usage_std 0.0775 (0.1899) nleep/row_max_mean 1539.8054 (1537.4979) nleep/row_max_std 45.6417 (55.2786) nleep/row_min_mean 1517.2338 (1510.8833) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [80/173] time 0.173 (0.107) data 0.000 (0.004) loss 1.6796 (1.5267) teacher_loss 0.3211 (0.2035) loss_zs_kd 0.0368 (0.0264) loss_oracle 0.6830 (0.6412) kd_loss 0.9985 (0.9894) acc 87.5000 (92.4609) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4808 (0.4808) gate/usage_min 0.1802 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0665 (0.0484) teacher/usage_max 0.5782 (0.5851) teacher/usage_min 0.1277 (0.1521) teacher/usage_std 0.1860 (0.1872) nleep/row_max_mean 1542.9554 (1537.4818) nleep/row_max_std 44.9823 (55.1889) nleep/row_min_mean 1516.3184 (1510.9799) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [100/173] time 0.179 (0.106) data 0.001 (0.003) loss 1.5101 (1.5297) teacher_loss 0.3333 (0.2071) loss_zs_kd 0.0349 (0.0265) loss_oracle 0.6410 (0.6426) kd_loss 0.8390 (0.9881) acc 87.5000 (92.3125) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4807 (0.4808) gate/usage_min 0.1801 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.1107 (0.0495) teacher/usage_max 0.6103 (0.5817) teacher/usage_min 0.1298 (0.1553) teacher/usage_std 0.2029 (0.1842) nleep/row_max_mean 1544.9111 (1537.5813) nleep/row_max_std 50.9267 (55.6912) nleep/row_min_mean 1518.4392 (1510.8728) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/173] time 0.086 (0.105) data 0.000 (0.002) loss 1.5078 (1.5293) teacher_loss 0.1271 (0.2052) loss_zs_kd 0.0170 (0.0261) loss_oracle 0.6634 (0.6378) kd_loss 1.0405 (0.9921) acc 90.6250 (92.4479) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4805 (0.4808) gate/usage_min 0.1800 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0499 (0.0498) teacher/usage_max 0.4811 (0.5785) teacher/usage_min 0.2393 (0.1537) teacher/usage_std 0.1058 (0.1831) nleep/row_max_mean 1543.6390 (1537.4002) nleep/row_max_std 48.4478 (55.5822) nleep/row_min_mean 1518.0281 (1510.6828) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/173] time 0.141 (0.106) data 0.000 (0.002) loss 1.4873 (1.5342) teacher_loss 0.0571 (0.2029) loss_zs_kd 0.0161 (0.0262) loss_oracle 0.6184 (0.6429) kd_loss 1.1130 (0.9968) acc 100.0000 (92.6116) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0089 (0.0493) teacher/usage_max 0.5003 (0.5725) teacher/usage_min 0.1580 (0.1560) teacher/usage_std 0.1399 (0.1794) nleep/row_max_mean 1540.4741 (1537.1359) nleep/row_max_std 40.3779 (54.9322) nleep/row_min_mean 1512.1442 (1510.4893) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/173] time 0.186 (0.106) data 0.000 (0.002) loss 1.3552 (1.5344) teacher_loss 0.1359 (0.2059) loss_zs_kd 0.0296 (0.0263) loss_oracle 0.6002 (0.6431) kd_loss 0.9045 (0.9938) acc 96.8750 (92.4805) gate/entropy 1.0276 (1.0276) gate/usage_max 0.4809 (0.4808) gate/usage_min 0.1803 (0.1802) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0672 (0.0500) teacher/usage_max 0.6627 (0.5740) teacher/usage_min 0.1444 (0.1555) teacher/usage_std 0.2337 (0.1804) nleep/row_max_mean 1540.1128 (1537.5326) nleep/row_max_std 59.3655 (54.4255) nleep/row_min_mean 1512.0173 (1510.8296) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,995
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 97.2%
******* Domain a best val acc:      96.6%, epoch: 18 *******
******* Domain a best val test acc: 97.9%, epoch: 18 *******
******* Domain a best test acc:     98.0%, epoch: 19 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:11

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_38', 'location_43', 'location_46']
Target     ['location_100']
# classes  10
# train_x  13,713
# val      5,876
# test     4,741
---------  ---------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/428] time 0.084 (0.137) data 0.000 (0.039) loss 2.6000 (2.6310) teacher_loss 2.5102 (2.4721) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0326 (0.0121) kd_loss 0.1470 (0.3057) acc 31.2500 (23.5938) lr 1.0000e-05 eta 0:48:50
epoch [1/50] batch [40/428] time 0.128 (0.113) data 0.000 (0.020) loss 2.6281 (2.5330) teacher_loss 2.4991 (2.3985) loss_zs_kd 0.0021 (0.0005) loss_oracle 0.1503 (0.0628) kd_loss 0.1076 (0.2063) acc 18.7500 (25.8594) lr 1.0000e-05 eta 0:40:13
epoch [1/50] batch [60/428] time 0.081 (0.106) data 0.000 (0.013) loss 2.7617 (2.5140) teacher_loss 2.5558 (2.3745) loss_zs_kd 0.0053 (0.0016) loss_oracle 0.3114 (0.1202) kd_loss 0.1003 (0.1588) acc 28.1250 (26.3542) lr 1.0000e-05 eta 0:37:40
epoch [1/50] batch [80/428] time 0.090 (0.099) data 0.000 (0.010) loss 2.4875 (2.5116) teacher_loss 2.2730 (2.3510) loss_zs_kd 0.0088 (0.0033) loss_oracle 0.3094 (0.1780) kd_loss 0.1197 (0.1433) acc 31.2500 (26.7578) lr 1.0000e-05 eta 0:35:16
epoch [1/50] batch [100/428] time 0.098 (0.097) data 0.000 (0.008) loss 2.5900 (2.5055) teacher_loss 2.3432 (2.3271) loss_zs_kd 0.0150 (0.0056) loss_oracle 0.4085 (0.2260) kd_loss 0.0851 (0.1308) acc 28.1250 (27.2500) lr 1.0000e-05 eta 0:34:23
epoch [1/50] batch [120/428] time 0.076 (0.095) data 0.000 (0.007) loss 2.5574 (2.5034) teacher_loss 2.2565 (2.3033) loss_zs_kd 0.0299 (0.0084) loss_oracle 0.5187 (0.2780) kd_loss 0.0830 (0.1221) acc 37.5000 (27.9948) lr 1.0000e-05 eta 0:33:34
epoch [1/50] batch [140/428] time 0.077 (0.093) data 0.000 (0.006) loss 2.5260 (2.5160) teacher_loss 2.1862 (2.2985) loss_zs_kd 0.0465 (0.0122) loss_oracle 0.5404 (0.3169) kd_loss 0.1390 (0.1181) acc 21.8750 (28.1027) lr 1.0000e-05 eta 0:32:48
epoch [1/50] batch [160/428] time 0.085 (0.091) data 0.000 (0.005) loss 2.6998 (2.5141) teacher_loss 2.0752 (2.2667) loss_zs_kd 0.1753 (0.0226) loss_oracle 0.8752 (0.3658) kd_loss 0.3740 (0.1289) acc 37.5000 (28.5547) lr 1.0000e-05 eta 0:32:21
epoch [1/50] batch [180/428] time 0.082 (0.090) data 0.000 (0.005) loss 3.3610 (2.5467) teacher_loss 2.3510 (2.2283) loss_zs_kd 0.4888 (0.0662) loss_oracle 1.0350 (0.4385) kd_loss 0.9850 (0.1983) acc 28.1250 (29.3924) lr 1.0000e-05 eta 0:31:59
epoch [1/50] batch [200/428] time 0.091 (0.090) data 0.000 (0.004) loss 3.0180 (2.5950) teacher_loss 1.9245 (2.2015) loss_zs_kd 0.6081 (0.1137) loss_oracle 1.0954 (0.5032) kd_loss 1.0917 (0.2838) acc 46.8750 (30.0625) lr 1.0000e-05 eta 0:31:41
epoch [1/50] batch [220/428] time 0.085 (0.089) data 0.000 (0.004) loss 3.4931 (2.6385) teacher_loss 2.4193 (2.1823) loss_zs_kd 0.5114 (0.1563) loss_oracle 1.0702 (0.5567) kd_loss 1.0775 (0.3556) acc 34.3750 (30.6818) lr 1.0000e-05 eta 0:31:25
epoch [1/50] batch [240/428] time 0.085 (0.088) data 0.000 (0.004) loss 2.9902 (2.6687) teacher_loss 1.9078 (2.1609) loss_zs_kd 0.6757 (0.1978) loss_oracle 1.0947 (0.6009) kd_loss 1.0702 (0.4147) acc 31.2500 (31.1198) lr 1.0000e-05 eta 0:31:04
epoch [1/50] batch [260/428] time 0.086 (0.088) data 0.000 (0.003) loss 3.3143 (2.6864) teacher_loss 2.2313 (2.1347) loss_zs_kd 0.7514 (0.2359) loss_oracle 1.0948 (0.6384) kd_loss 1.0711 (0.4650) acc 37.5000 (31.7428) lr 1.0000e-05 eta 0:30:51
epoch [1/50] batch [280/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.6150 (2.6963) teacher_loss 1.5277 (2.1069) loss_zs_kd 0.8705 (0.2738) loss_oracle 1.0951 (0.6702) kd_loss 1.0796 (0.5085) acc 50.0000 (32.3438) lr 1.0000e-05 eta 0:30:44
epoch [1/50] batch [300/428] time 0.086 (0.087) data 0.000 (0.003) loss 3.1212 (2.7041) teacher_loss 2.0334 (2.0820) loss_zs_kd 0.9027 (0.3116) loss_oracle 1.0946 (0.6981) kd_loss 1.0810 (0.5462) acc 31.2500 (32.9375) lr 1.0000e-05 eta 0:30:37
epoch [1/50] batch [320/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.7594 (2.7098) teacher_loss 1.6811 (2.0592) loss_zs_kd 0.8821 (0.3469) loss_oracle 1.0942 (0.7225) kd_loss 1.0623 (0.5787) acc 37.5000 (33.3398) lr 1.0000e-05 eta 0:30:36
epoch [1/50] batch [340/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.9411 (2.7180) teacher_loss 1.8543 (2.0419) loss_zs_kd 1.0581 (0.3830) loss_oracle 1.0945 (0.7444) kd_loss 1.0792 (0.6079) acc 40.6250 (33.7408) lr 1.0000e-05 eta 0:30:31
epoch [1/50] batch [360/428] time 0.088 (0.087) data 0.000 (0.002) loss 2.6292 (2.7218) teacher_loss 1.5392 (2.0229) loss_zs_kd 1.0947 (0.4167) loss_oracle 1.0941 (0.7636) kd_loss 1.0858 (0.6342) acc 56.2500 (34.2448) lr 1.0000e-05 eta 0:30:23
epoch [1/50] batch [380/428] time 0.078 (0.086) data 0.000 (0.002) loss 3.0216 (2.7276) teacher_loss 1.9349 (2.0083) loss_zs_kd 1.0465 (0.4498) loss_oracle 1.0939 (0.7810) kd_loss 1.0795 (0.6578) acc 31.2500 (34.5230) lr 1.0000e-05 eta 0:30:12
epoch [1/50] batch [400/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.7118 (2.7299) teacher_loss 1.6193 (1.9923) loss_zs_kd 1.1991 (0.4819) loss_oracle 1.0941 (0.7964) kd_loss 1.0908 (0.6787) acc 53.1250 (34.9141) lr 1.0000e-05 eta 0:30:02
epoch [1/50] batch [420/428] time 0.083 (0.086) data 0.000 (0.002) loss 3.0291 (2.7278) teacher_loss 1.9489 (1.9735) loss_zs_kd 1.1081 (0.5092) loss_oracle 1.0890 (0.8104) kd_loss 1.0716 (0.6981) acc 31.2500 (35.4315) lr 1.0000e-05 eta 0:29:55
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,266
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 22.1%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,946
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 26.8%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      38.6%, epoch: 1 *******
******* Domain 1 best val test acc: 41.0%, epoch: 1 *******
******* Domain 1 best test acc:     41.0%, epoch: 1 *******
epoch [2/50] batch [20/428] time 0.096 (0.118) data 0.000 (0.028) loss 2.7352 (2.7647) teacher_loss 1.6794 (1.7064) loss_zs_kd 1.3940 (0.8725) loss_oracle 1.0384 (1.0355) kd_loss 1.0730 (1.0811) acc 34.3750 (41.8750) lr 2.0000e-03 eta 0:41:07
epoch [2/50] batch [40/428] time 0.078 (0.101) data 0.000 (0.014) loss 2.8024 (2.7206) teacher_loss 1.7544 (1.6614) loss_zs_kd 1.1780 (1.0575) loss_oracle 1.0434 (1.0451) kd_loss 1.0527 (1.0733) acc 46.8750 (42.9688) lr 2.0000e-03 eta 0:35:16
epoch [2/50] batch [60/428] time 0.081 (0.094) data 0.000 (0.010) loss 2.5664 (2.6716) teacher_loss 1.5534 (1.6251) loss_zs_kd 0.9400 (0.9925) loss_oracle 0.9862 (1.0288) kd_loss 1.0400 (1.0642) acc 53.1250 (44.3750) lr 2.0000e-03 eta 0:32:35
epoch [2/50] batch [80/428] time 0.082 (0.090) data 0.000 (0.007) loss 2.5092 (2.6117) teacher_loss 1.4833 (1.5708) loss_zs_kd 0.9929 (1.0159) loss_oracle 1.0335 (1.0272) kd_loss 1.0183 (1.0547) acc 46.8750 (46.2891) lr 2.0000e-03 eta 0:31:16
epoch [2/50] batch [100/428] time 0.087 (0.088) data 0.000 (0.006) loss 2.3074 (2.5673) teacher_loss 1.3056 (1.5321) loss_zs_kd 1.6502 (1.0926) loss_oracle 1.0140 (1.0244) kd_loss 0.9896 (1.0459) acc 56.2500 (47.4062) lr 2.0000e-03 eta 0:30:37
epoch [2/50] batch [120/428] time 0.082 (0.088) data 0.001 (0.005) loss 2.8637 (2.5443) teacher_loss 1.8716 (1.5151) loss_zs_kd 1.9257 (1.1788) loss_oracle 0.9926 (1.0204) kd_loss 0.9916 (1.0379) acc 34.3750 (48.1771) lr 2.0000e-03 eta 0:30:28
epoch [2/50] batch [140/428] time 0.081 (0.087) data 0.000 (0.004) loss 2.2187 (2.5121) teacher_loss 1.2465 (1.4896) loss_zs_kd 1.6750 (1.2569) loss_oracle 0.9728 (1.0149) kd_loss 0.9717 (1.0299) acc 65.6250 (49.0625) lr 2.0000e-03 eta 0:30:12
epoch [2/50] batch [160/428] time 0.085 (0.087) data 0.000 (0.004) loss 2.3456 (2.4843) teacher_loss 1.3900 (1.4691) loss_zs_kd 1.7884 (1.3138) loss_oracle 0.9557 (1.0086) kd_loss 0.9557 (1.0217) acc 46.8750 (49.5508) lr 2.0000e-03 eta 0:30:04
epoch [2/50] batch [180/428] time 0.133 (0.087) data 0.000 (0.003) loss 2.0860 (2.4603) teacher_loss 1.1475 (1.4526) loss_zs_kd 1.6210 (1.3493) loss_oracle 0.9385 (1.0020) kd_loss 0.9385 (1.0134) acc 56.2500 (50.0174) lr 2.0000e-03 eta 0:30:18
epoch [2/50] batch [200/428] time 0.082 (0.088) data 0.000 (0.003) loss 2.1861 (2.4430) teacher_loss 1.2648 (1.4431) loss_zs_kd 1.5419 (1.3825) loss_oracle 0.9213 (0.9949) kd_loss 0.9213 (1.0050) acc 50.0000 (50.1562) lr 2.0000e-03 eta 0:30:26
epoch [2/50] batch [220/428] time 0.083 (0.088) data 0.000 (0.003) loss 2.0544 (2.4140) teacher_loss 1.1500 (1.4220) loss_zs_kd 1.7712 (1.4105) loss_oracle 0.9044 (0.9875) kd_loss 0.9044 (0.9966) acc 62.5000 (50.7812) lr 2.0000e-03 eta 0:30:20
epoch [2/50] batch [240/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.0808 (2.3923) teacher_loss 1.1931 (1.4083) loss_zs_kd 1.5078 (1.4278) loss_oracle 0.8877 (0.9799) kd_loss 0.8877 (0.9882) acc 59.3750 (51.1328) lr 2.0000e-03 eta 0:30:12
epoch [2/50] batch [260/428] time 0.084 (0.087) data 0.000 (0.002) loss 1.7952 (2.3681) teacher_loss 0.9168 (1.3904) loss_zs_kd 1.5941 (1.4214) loss_oracle 0.8733 (0.9757) kd_loss 0.8837 (0.9798) acc 65.6250 (51.6346) lr 2.0000e-03 eta 0:30:09
epoch [2/50] batch [280/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.8454 (2.3438) teacher_loss 0.9627 (1.3730) loss_zs_kd 1.8962 (1.4937) loss_oracle 0.8603 (0.9684) kd_loss 0.9051 (0.9731) acc 65.6250 (52.1875) lr 2.0000e-03 eta 0:30:02
epoch [2/50] batch [300/428] time 0.091 (0.087) data 0.000 (0.002) loss 2.0506 (2.3185) teacher_loss 1.1820 (1.3543) loss_zs_kd 3.1415 (1.6174) loss_oracle 0.8585 (0.9614) kd_loss 0.8788 (0.9668) acc 65.6250 (52.8750) lr 2.0000e-03 eta 0:29:49
epoch [2/50] batch [320/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.0657 (2.2995) teacher_loss 1.2464 (1.3431) loss_zs_kd 3.1251 (1.6954) loss_oracle 0.8320 (0.9538) kd_loss 0.8067 (0.9590) acc 62.5000 (53.1934) lr 2.0000e-03 eta 0:29:40
epoch [2/50] batch [340/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.9061 (2.2819) teacher_loss 1.0884 (1.3332) loss_zs_kd 3.1982 (1.7833) loss_oracle 0.8177 (0.9462) kd_loss 0.8176 (0.9511) acc 62.5000 (53.5018) lr 2.0000e-03 eta 0:29:32
epoch [2/50] batch [360/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.5626 (2.2624) teacher_loss 0.7485 (1.3214) loss_zs_kd 3.5400 (1.8731) loss_oracle 0.8165 (0.9387) kd_loss 0.8117 (0.9432) acc 71.8750 (53.8194) lr 2.0000e-03 eta 0:29:27
epoch [2/50] batch [380/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.6655 (2.2464) teacher_loss 0.8737 (1.3130) loss_zs_kd 3.9102 (1.9683) loss_oracle 0.7888 (0.9314) kd_loss 0.7947 (0.9355) acc 71.8750 (54.0132) lr 2.0000e-03 eta 0:29:22
epoch [2/50] batch [400/428] time 0.083 (0.085) data 0.000 (0.002) loss 1.8324 (2.2315) teacher_loss 1.0211 (1.3045) loss_zs_kd 3.9212 (2.0663) loss_oracle 0.7784 (0.9247) kd_loss 0.8443 (0.9293) acc 65.6250 (54.3281) lr 2.0000e-03 eta 0:29:18
epoch [2/50] batch [420/428] time 0.073 (0.085) data 0.000 (0.002) loss 1.6840 (2.2104) teacher_loss 0.8696 (1.2895) loss_zs_kd 3.9969 (2.1567) loss_oracle 0.7961 (0.9181) kd_loss 0.8328 (0.9238) acc 75.0000 (54.7396) lr 2.0000e-03 eta 0:29:13
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,500
* accuracy: 42.5%
* error: 57.5%
* macro_f1: 29.0%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,980
* accuracy: 41.8%
* error: 58.2%
* macro_f1: 26.8%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      42.5%, epoch: 2 *******
******* Domain 1 best val test acc: 41.8%, epoch: 2 *******
******* Domain 1 best test acc:     41.8%, epoch: 2 *******
epoch [3/50] batch [20/428] time 0.083 (0.112) data 0.000 (0.025) loss 1.6129 (1.8152) teacher_loss 0.7792 (1.0189) loss_zs_kd 4.1361 (4.1315) loss_oracle 0.7733 (0.7743) kd_loss 0.8940 (0.8184) acc 68.7500 (62.6562) lr 1.9980e-03 eta 0:38:16
epoch [3/50] batch [40/428] time 0.088 (0.099) data 0.000 (0.013) loss 1.6401 (1.8139) teacher_loss 0.8719 (1.0249) loss_zs_kd 4.2978 (4.1153) loss_oracle 0.7405 (0.7701) kd_loss 0.7959 (0.8079) acc 65.6250 (62.8906) lr 1.9980e-03 eta 0:33:41
epoch [3/50] batch [60/428] time 0.089 (0.094) data 0.000 (0.008) loss 1.7984 (1.7815) teacher_loss 1.0388 (0.9915) loss_zs_kd 4.1519 (4.1609) loss_oracle 0.7310 (0.7703) kd_loss 0.7881 (0.8096) acc 59.3750 (64.1146) lr 1.9980e-03 eta 0:31:55
epoch [3/50] batch [80/428] time 0.072 (0.090) data 0.000 (0.006) loss 1.5129 (1.7693) teacher_loss 0.7010 (0.9800) loss_zs_kd 4.3291 (4.2017) loss_oracle 0.7646 (0.7703) kd_loss 0.8593 (0.8084) acc 68.7500 (64.1797) lr 1.9980e-03 eta 0:30:47
epoch [3/50] batch [100/428] time 0.080 (0.089) data 0.000 (0.005) loss 2.0251 (1.7762) teacher_loss 1.2308 (0.9891) loss_zs_kd 4.8319 (4.2755) loss_oracle 0.7942 (0.7689) kd_loss 0.7942 (0.8053) acc 62.5000 (63.8750) lr 1.9980e-03 eta 0:30:18
epoch [3/50] batch [120/428] time 0.089 (0.088) data 0.000 (0.004) loss 1.9190 (1.7670) teacher_loss 1.0802 (0.9818) loss_zs_kd 5.0590 (4.3816) loss_oracle 0.8284 (0.7672) kd_loss 0.8492 (0.8031) acc 56.2500 (63.8542) lr 1.9980e-03 eta 0:30:04
epoch [3/50] batch [140/428] time 0.077 (0.088) data 0.000 (0.004) loss 1.6753 (1.7605) teacher_loss 0.9579 (0.9783) loss_zs_kd 5.2284 (4.4685) loss_oracle 0.7162 (0.7648) kd_loss 0.7185 (0.7995) acc 59.3750 (63.7054) lr 1.9980e-03 eta 0:29:50
epoch [3/50] batch [160/428] time 0.084 (0.087) data 0.000 (0.003) loss 1.8357 (1.7565) teacher_loss 1.1155 (0.9772) loss_zs_kd 5.2445 (4.5833) loss_oracle 0.7138 (0.7624) kd_loss 0.7265 (0.7962) acc 59.3750 (63.5547) lr 1.9980e-03 eta 0:29:30
epoch [3/50] batch [180/428] time 0.080 (0.086) data 0.000 (0.003) loss 1.6033 (1.7461) teacher_loss 0.7884 (0.9678) loss_zs_kd 5.5088 (4.6954) loss_oracle 0.8154 (0.7614) kd_loss 0.8143 (0.7952) acc 68.7500 (63.9410) lr 1.9980e-03 eta 0:29:20
epoch [3/50] batch [200/428] time 0.079 (0.085) data 0.000 (0.003) loss 1.6517 (1.7495) teacher_loss 0.8989 (0.9735) loss_zs_kd 5.9196 (4.8098) loss_oracle 0.7457 (0.7600) kd_loss 0.7601 (0.7920) acc 65.6250 (63.6406) lr 1.9980e-03 eta 0:28:58
epoch [3/50] batch [220/428] time 0.088 (0.085) data 0.000 (0.003) loss 1.5574 (1.7413) teacher_loss 0.8171 (0.9685) loss_zs_kd 5.8487 (4.9070) loss_oracle 0.7208 (0.7569) kd_loss 0.7597 (0.7886) acc 75.0000 (63.9915) lr 1.9980e-03 eta 0:28:46
epoch [3/50] batch [240/428] time 0.088 (0.085) data 0.000 (0.002) loss 1.3620 (1.7288) teacher_loss 0.6494 (0.9601) loss_zs_kd 6.4451 (5.0042) loss_oracle 0.7014 (0.7537) kd_loss 0.7239 (0.7838) acc 81.2500 (64.3880) lr 1.9980e-03 eta 0:28:44
epoch [3/50] batch [260/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.9495 (1.7199) teacher_loss 1.1948 (0.9536) loss_zs_kd 6.3794 (5.1141) loss_oracle 0.7546 (0.7513) kd_loss 0.7546 (0.7813) acc 56.2500 (64.6635) lr 1.9980e-03 eta 0:28:41
epoch [3/50] batch [280/428] time 0.079 (0.085) data 0.000 (0.002) loss 1.5677 (1.7176) teacher_loss 0.8789 (0.9537) loss_zs_kd 7.0283 (5.2090) loss_oracle 0.6802 (0.7488) kd_loss 0.6974 (0.7790) acc 65.6250 (64.6317) lr 1.9980e-03 eta 0:28:39
epoch [3/50] batch [300/428] time 0.127 (0.086) data 0.001 (0.002) loss 1.6550 (1.7139) teacher_loss 0.9436 (0.9530) loss_zs_kd 6.3807 (5.2933) loss_oracle 0.6759 (0.7455) kd_loss 0.7469 (0.7763) acc 65.6250 (64.7604) lr 1.9980e-03 eta 0:28:58
epoch [3/50] batch [320/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.5871 (1.7028) teacher_loss 0.8726 (0.9431) loss_zs_kd 6.5639 (5.3675) loss_oracle 0.7099 (0.7442) kd_loss 0.7192 (0.7752) acc 68.7500 (65.0879) lr 1.9980e-03 eta 0:28:56
epoch [3/50] batch [340/428] time 0.079 (0.086) data 0.000 (0.002) loss 1.6794 (1.6975) teacher_loss 0.9760 (0.9389) loss_zs_kd 6.5848 (5.4388) loss_oracle 0.6906 (0.7430) kd_loss 0.7162 (0.7742) acc 68.7500 (65.2298) lr 1.9980e-03 eta 0:28:51
epoch [3/50] batch [360/428] time 0.079 (0.085) data 0.000 (0.002) loss 1.4797 (1.6908) teacher_loss 0.7566 (0.9333) loss_zs_kd 6.5574 (5.5028) loss_oracle 0.6885 (0.7421) kd_loss 0.7577 (0.7730) acc 65.6250 (65.4514) lr 1.9980e-03 eta 0:28:44
epoch [3/50] batch [380/428] time 0.080 (0.085) data 0.000 (0.002) loss 1.7772 (1.6876) teacher_loss 0.9923 (0.9317) loss_zs_kd 6.6385 (5.5658) loss_oracle 0.7600 (0.7404) kd_loss 0.8098 (0.7714) acc 71.8750 (65.5099) lr 1.9980e-03 eta 0:28:37
epoch [3/50] batch [400/428] time 0.080 (0.085) data 0.000 (0.002) loss 1.4971 (1.6853) teacher_loss 0.7151 (0.9298) loss_zs_kd 7.1561 (5.6218) loss_oracle 0.7570 (0.7398) kd_loss 0.8070 (0.7711) acc 78.1250 (65.5625) lr 1.9980e-03 eta 0:28:34
epoch [3/50] batch [420/428] time 0.072 (0.085) data 0.000 (0.001) loss 1.4437 (1.6765) teacher_loss 0.7013 (0.9222) loss_zs_kd 6.8464 (5.6731) loss_oracle 0.7046 (0.7384) kd_loss 0.7802 (0.7703) acc 68.7500 (65.8185) lr 1.9980e-03 eta 0:28:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,789
* accuracy: 47.5%
* error: 52.5%
* macro_f1: 32.1%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,922
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 29.8%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      47.5%, epoch: 3 *******
******* Domain 1 best val test acc: 61.6%, epoch: 3 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [4/50] batch [20/428] time 0.058 (0.100) data 0.000 (0.028) loss 1.4693 (1.5668) teacher_loss 0.6525 (0.8338) loss_zs_kd 6.6608 (6.7646) loss_oracle 0.8029 (0.7199) kd_loss 0.8307 (0.7462) acc 75.0000 (67.8125) lr 1.9921e-03 eta 0:33:35
epoch [4/50] batch [40/428] time 0.076 (0.097) data 0.000 (0.014) loss 1.5250 (1.6091) teacher_loss 0.7083 (0.8791) loss_zs_kd 6.5597 (6.7582) loss_oracle 0.8033 (0.7171) kd_loss 0.8301 (0.7429) acc 78.1250 (66.8750) lr 1.9921e-03 eta 0:32:31
epoch [4/50] batch [60/428] time 0.083 (0.091) data 0.000 (0.009) loss 1.6741 (1.6100) teacher_loss 0.9761 (0.8850) loss_zs_kd 6.8295 (6.7567) loss_oracle 0.6978 (0.7109) kd_loss 0.6982 (0.7390) acc 59.3750 (66.6667) lr 1.9921e-03 eta 0:30:23
epoch [4/50] batch [80/428] time 0.066 (0.089) data 0.000 (0.007) loss 1.6787 (1.6084) teacher_loss 0.9816 (0.8810) loss_zs_kd 6.9887 (6.7739) loss_oracle 0.6971 (0.7149) kd_loss 0.6971 (0.7399) acc 56.2500 (66.9141) lr 1.9921e-03 eta 0:29:41
epoch [4/50] batch [100/428] time 0.064 (0.086) data 0.000 (0.006) loss 1.5137 (1.6065) teacher_loss 0.8207 (0.8814) loss_zs_kd 7.3787 (6.8105) loss_oracle 0.6930 (0.7125) kd_loss 0.6930 (0.7377) acc 68.7500 (66.8750) lr 1.9921e-03 eta 0:28:47
epoch [4/50] batch [120/428] time 0.073 (0.085) data 0.000 (0.005) loss 1.6605 (1.5902) teacher_loss 0.9761 (0.8650) loss_zs_kd 6.9986 (6.8285) loss_oracle 0.6504 (0.7109) kd_loss 0.7186 (0.7395) acc 62.5000 (67.8906) lr 1.9921e-03 eta 0:28:11
epoch [4/50] batch [140/428] time 0.074 (0.083) data 0.000 (0.004) loss 1.6669 (1.5857) teacher_loss 1.0434 (0.8606) loss_zs_kd 7.1659 (6.8573) loss_oracle 0.6098 (0.7115) kd_loss 0.6372 (0.7389) acc 65.6250 (68.1920) lr 1.9921e-03 eta 0:27:30
epoch [4/50] batch [160/428] time 0.079 (0.082) data 0.000 (0.004) loss 1.6740 (1.5880) teacher_loss 0.9859 (0.8625) loss_zs_kd 7.1902 (6.8691) loss_oracle 0.6875 (0.7111) kd_loss 0.6888 (0.7399) acc 56.2500 (67.8516) lr 1.9921e-03 eta 0:27:07
epoch [4/50] batch [180/428] time 0.079 (0.081) data 0.000 (0.003) loss 1.6747 (1.5880) teacher_loss 0.9248 (0.8640) loss_zs_kd 6.9345 (6.8825) loss_oracle 0.7313 (0.7095) kd_loss 0.7686 (0.7385) acc 62.5000 (67.6910) lr 1.9921e-03 eta 0:26:57
epoch [4/50] batch [200/428] time 0.072 (0.081) data 0.000 (0.003) loss 1.5135 (1.5842) teacher_loss 0.8542 (0.8627) loss_zs_kd 6.7101 (6.9017) loss_oracle 0.6593 (0.7069) kd_loss 0.6593 (0.7361) acc 62.5000 (67.7344) lr 1.9921e-03 eta 0:26:58
epoch [4/50] batch [220/428] time 0.084 (0.081) data 0.000 (0.003) loss 1.5958 (1.5885) teacher_loss 0.8425 (0.8665) loss_zs_kd 7.0987 (6.9204) loss_oracle 0.7390 (0.7073) kd_loss 0.7675 (0.7368) acc 65.6250 (67.3722) lr 1.9921e-03 eta 0:26:58
epoch [4/50] batch [240/428] time 0.079 (0.081) data 0.000 (0.003) loss 1.4167 (1.5840) teacher_loss 0.7783 (0.8622) loss_zs_kd 7.3786 (6.9288) loss_oracle 0.6213 (0.7076) kd_loss 0.6556 (0.7360) acc 68.7500 (67.5260) lr 1.9921e-03 eta 0:26:54
epoch [4/50] batch [260/428] time 0.078 (0.080) data 0.000 (0.002) loss 1.7041 (1.5823) teacher_loss 1.0365 (0.8619) loss_zs_kd 7.0868 (6.9468) loss_oracle 0.6531 (0.7063) kd_loss 0.6821 (0.7343) acc 59.3750 (67.4760) lr 1.9921e-03 eta 0:26:37
epoch [4/50] batch [280/428] time 0.079 (0.080) data 0.000 (0.002) loss 1.6133 (1.5759) teacher_loss 0.9460 (0.8565) loss_zs_kd 7.2490 (6.9605) loss_oracle 0.6530 (0.7053) kd_loss 0.6814 (0.7334) acc 68.7500 (67.7344) lr 1.9921e-03 eta 0:26:24
epoch [4/50] batch [300/428] time 0.071 (0.080) data 0.000 (0.002) loss 1.4026 (1.5752) teacher_loss 0.6392 (0.8548) loss_zs_kd 6.9892 (6.9777) loss_oracle 0.7635 (0.7058) kd_loss 0.7635 (0.7348) acc 78.1250 (67.8438) lr 1.9921e-03 eta 0:26:26
epoch [4/50] batch [320/428] time 0.083 (0.080) data 0.000 (0.002) loss 1.6988 (1.5729) teacher_loss 1.0488 (0.8533) loss_zs_kd 7.3540 (6.9949) loss_oracle 0.6500 (0.7050) kd_loss 0.6500 (0.7342) acc 68.7500 (67.9492) lr 1.9921e-03 eta 0:26:26
epoch [4/50] batch [340/428] time 0.088 (0.080) data 0.000 (0.002) loss 1.4208 (1.5691) teacher_loss 0.5595 (0.8484) loss_zs_kd 7.3259 (7.0096) loss_oracle 0.8473 (0.7063) kd_loss 0.8752 (0.7351) acc 78.1250 (68.1158) lr 1.9921e-03 eta 0:26:25
epoch [4/50] batch [360/428] time 0.079 (0.080) data 0.000 (0.002) loss 1.7069 (1.5689) teacher_loss 1.0780 (0.8481) loss_zs_kd 7.0979 (7.0204) loss_oracle 0.6094 (0.7068) kd_loss 0.6485 (0.7348) acc 53.1250 (68.0122) lr 1.9921e-03 eta 0:26:25
epoch [4/50] batch [380/428] time 0.084 (0.080) data 0.000 (0.002) loss 1.4755 (1.5666) teacher_loss 0.7758 (0.8466) loss_zs_kd 7.3717 (7.0325) loss_oracle 0.6663 (0.7060) kd_loss 0.7332 (0.7339) acc 84.3750 (68.1661) lr 1.9921e-03 eta 0:26:24
epoch [4/50] batch [400/428] time 0.072 (0.080) data 0.000 (0.002) loss 1.7353 (1.5669) teacher_loss 1.0491 (0.8477) loss_zs_kd 7.2751 (7.0401) loss_oracle 0.6698 (0.7052) kd_loss 0.7027 (0.7333) acc 59.3750 (68.1797) lr 1.9921e-03 eta 0:26:18
epoch [4/50] batch [420/428] time 0.081 (0.080) data 0.000 (0.002) loss 1.3928 (1.5663) teacher_loss 0.7187 (0.8479) loss_zs_kd 6.9417 (7.0463) loss_oracle 0.6459 (0.7042) kd_loss 0.7024 (0.7327) acc 68.7500 (68.1473) lr 1.9921e-03 eta 0:26:16
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,006
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 36.2%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,871
* accuracy: 60.6%
* error: 39.4%
* macro_f1: 31.1%
******* Domain 1 best val acc:      51.2%, epoch: 4 *******
******* Domain 1 best val test acc: 60.6%, epoch: 4 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [5/50] batch [20/428] time 0.081 (0.112) data 0.000 (0.024) loss 1.1396 (1.4673) teacher_loss 0.4093 (0.7573) loss_zs_kd 6.9505 (7.1758) loss_oracle 0.7303 (0.6971) kd_loss 0.7302 (0.7229) acc 90.6250 (71.0938) lr 1.9823e-03 eta 0:36:46
epoch [5/50] batch [40/428] time 0.080 (0.097) data 0.000 (0.012) loss 1.6793 (1.4944) teacher_loss 0.9459 (0.7907) loss_zs_kd 7.3474 (7.1951) loss_oracle 0.7102 (0.6905) kd_loss 0.7566 (0.7168) acc 59.3750 (69.6094) lr 1.9823e-03 eta 0:31:48
epoch [5/50] batch [60/428] time 0.077 (0.091) data 0.000 (0.008) loss 1.4653 (1.4797) teacher_loss 0.7651 (0.7756) loss_zs_kd 7.1992 (7.2194) loss_oracle 0.7002 (0.6892) kd_loss 0.7002 (0.7188) acc 71.8750 (70.6771) lr 1.9823e-03 eta 0:29:43
epoch [5/50] batch [80/428] time 0.091 (0.089) data 0.000 (0.006) loss 1.6175 (1.5184) teacher_loss 0.8454 (0.8157) loss_zs_kd 7.3970 (7.2266) loss_oracle 0.7579 (0.6879) kd_loss 0.7863 (0.7175) acc 62.5000 (69.1797) lr 1.9823e-03 eta 0:29:09
epoch [5/50] batch [100/428] time 0.083 (0.089) data 0.000 (0.005) loss 1.3219 (1.5400) teacher_loss 0.6950 (0.8385) loss_zs_kd 7.1674 (7.2267) loss_oracle 0.6122 (0.6864) kd_loss 0.6416 (0.7165) acc 78.1250 (68.7188) lr 1.9823e-03 eta 0:29:04
epoch [5/50] batch [120/428] time 0.092 (0.089) data 0.000 (0.004) loss 1.7224 (1.5397) teacher_loss 0.9837 (0.8367) loss_zs_kd 7.1885 (7.2222) loss_oracle 0.7228 (0.6870) kd_loss 0.7546 (0.7189) acc 59.3750 (68.9062) lr 1.9823e-03 eta 0:28:55
epoch [5/50] batch [140/428] time 0.076 (0.088) data 0.000 (0.004) loss 1.5366 (1.5447) teacher_loss 0.9257 (0.8472) loss_zs_kd 7.1030 (7.2166) loss_oracle 0.6110 (0.6820) kd_loss 0.6110 (0.7132) acc 62.5000 (68.3705) lr 1.9823e-03 eta 0:28:40
epoch [5/50] batch [160/428] time 0.085 (0.088) data 0.000 (0.003) loss 1.7100 (1.5526) teacher_loss 1.0131 (0.8545) loss_zs_kd 6.9262 (7.2071) loss_oracle 0.6969 (0.6809) kd_loss 0.6969 (0.7155) acc 65.6250 (68.1641) lr 1.9823e-03 eta 0:28:35
epoch [5/50] batch [180/428] time 0.074 (0.089) data 0.000 (0.003) loss 1.4334 (1.5502) teacher_loss 0.7392 (0.8509) loss_zs_kd 7.4067 (7.2099) loss_oracle 0.6646 (0.6816) kd_loss 0.7239 (0.7169) acc 71.8750 (68.3507) lr 1.9823e-03 eta 0:28:56
epoch [5/50] batch [200/428] time 0.086 (0.088) data 0.000 (0.003) loss 1.4638 (1.5474) teacher_loss 0.8409 (0.8495) loss_zs_kd 7.1990 (7.2119) loss_oracle 0.6085 (0.6802) kd_loss 0.6372 (0.7156) acc 78.1250 (68.3125) lr 1.9823e-03 eta 0:28:36
epoch [5/50] batch [220/428] time 0.091 (0.087) data 0.001 (0.002) loss 1.5701 (1.5481) teacher_loss 0.7736 (0.8511) loss_zs_kd 7.4513 (7.2230) loss_oracle 0.7821 (0.6797) kd_loss 0.8109 (0.7143) acc 71.8750 (68.0824) lr 1.9823e-03 eta 0:28:22
epoch [5/50] batch [240/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.8199 (1.5451) teacher_loss 1.0090 (0.8465) loss_zs_kd 7.1785 (7.2371) loss_oracle 0.8110 (0.6814) kd_loss 0.8110 (0.7158) acc 62.5000 (68.1120) lr 1.9823e-03 eta 0:28:14
epoch [5/50] batch [260/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.7398 (1.5460) teacher_loss 0.9724 (0.8456) loss_zs_kd 7.1218 (7.2409) loss_oracle 0.7525 (0.6833) kd_loss 0.7822 (0.7175) acc 65.6250 (68.2212) lr 1.9823e-03 eta 0:28:05
epoch [5/50] batch [280/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.2373 (1.5433) teacher_loss 0.5729 (0.8427) loss_zs_kd 7.2549 (7.2411) loss_oracle 0.6350 (0.6838) kd_loss 0.6938 (0.7173) acc 81.2500 (68.2478) lr 1.9823e-03 eta 0:28:00
epoch [5/50] batch [300/428] time 0.092 (0.086) data 0.001 (0.002) loss 1.7178 (1.5421) teacher_loss 1.0385 (0.8415) loss_zs_kd 7.2353 (7.2428) loss_oracle 0.6648 (0.6840) kd_loss 0.6939 (0.7171) acc 62.5000 (68.3021) lr 1.9823e-03 eta 0:27:55
epoch [5/50] batch [320/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.7224 (1.5415) teacher_loss 0.9269 (0.8408) loss_zs_kd 7.3293 (7.2448) loss_oracle 0.7806 (0.6839) kd_loss 0.8102 (0.7175) acc 62.5000 (68.2910) lr 1.9823e-03 eta 0:27:44
epoch [5/50] batch [340/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.4421 (1.5407) teacher_loss 0.8084 (0.8401) loss_zs_kd 7.0988 (7.2438) loss_oracle 0.6045 (0.6837) kd_loss 0.6628 (0.7175) acc 68.7500 (68.3456) lr 1.9823e-03 eta 0:27:39
epoch [5/50] batch [360/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.1274 (1.5376) teacher_loss 0.4935 (0.8372) loss_zs_kd 7.3588 (7.2498) loss_oracle 0.6339 (0.6836) kd_loss 0.6339 (0.7172) acc 84.3750 (68.3854) lr 1.9823e-03 eta 0:27:32
epoch [5/50] batch [380/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.6828 (1.5352) teacher_loss 0.9779 (0.8335) loss_zs_kd 7.8090 (7.2549) loss_oracle 0.6883 (0.6852) kd_loss 0.7214 (0.7183) acc 65.6250 (68.5362) lr 1.9823e-03 eta 0:27:29
epoch [5/50] batch [400/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.5291 (1.5357) teacher_loss 0.8863 (0.8340) loss_zs_kd 6.9189 (7.2558) loss_oracle 0.6238 (0.6855) kd_loss 0.6618 (0.7179) acc 62.5000 (68.5938) lr 1.9823e-03 eta 0:27:26
epoch [5/50] batch [420/428] time 0.075 (0.085) data 0.000 (0.001) loss 1.4493 (1.5339) teacher_loss 0.7875 (0.8332) loss_zs_kd 7.1173 (7.2558) loss_oracle 0.6619 (0.6847) kd_loss 0.6619 (0.7168) acc 68.7500 (68.5714) lr 1.9823e-03 eta 0:27:22
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,050
* accuracy: 51.9%
* error: 48.1%
* macro_f1: 35.4%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,717
* accuracy: 57.3%
* error: 42.7%
* macro_f1: 27.3%
******* Domain 1 best val acc:      51.9%, epoch: 5 *******
******* Domain 1 best val test acc: 57.3%, epoch: 5 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [6/50] batch [20/428] time 0.089 (0.112) data 0.000 (0.032) loss 1.6577 (1.4872) teacher_loss 0.8089 (0.7778) loss_zs_kd 7.2258 (7.2549) loss_oracle 0.8289 (0.6996) kd_loss 0.8686 (0.7191) acc 75.0000 (70.1562) lr 1.9686e-03 eta 0:35:54
epoch [6/50] batch [40/428] time 0.078 (0.097) data 0.000 (0.016) loss 1.3629 (1.5027) teacher_loss 0.5841 (0.8033) loss_zs_kd 7.5276 (7.2916) loss_oracle 0.7780 (0.6910) kd_loss 0.7796 (0.7079) acc 78.1250 (69.4531) lr 1.9686e-03 eta 0:31:12
epoch [6/50] batch [60/428] time 0.083 (0.090) data 0.000 (0.011) loss 1.5282 (1.5314) teacher_loss 0.8813 (0.8321) loss_zs_kd 7.3207 (7.3076) loss_oracle 0.5744 (0.6896) kd_loss 0.7195 (0.7089) acc 68.7500 (67.9167) lr 1.9686e-03 eta 0:28:43
epoch [6/50] batch [80/428] time 0.072 (0.087) data 0.000 (0.008) loss 1.4253 (1.5404) teacher_loss 0.7290 (0.8427) loss_zs_kd 7.2837 (7.3036) loss_oracle 0.6730 (0.6861) kd_loss 0.7194 (0.7094) acc 71.8750 (68.0078) lr 1.9686e-03 eta 0:27:49
epoch [6/50] batch [100/428] time 0.065 (0.085) data 0.000 (0.007) loss 1.3698 (1.5373) teacher_loss 0.6805 (0.8391) loss_zs_kd 7.1891 (7.3045) loss_oracle 0.6894 (0.6864) kd_loss 0.6894 (0.7099) acc 75.0000 (68.2812) lr 1.9686e-03 eta 0:27:03
epoch [6/50] batch [120/428] time 0.069 (0.082) data 0.000 (0.006) loss 1.6056 (1.5271) teacher_loss 0.9456 (0.8291) loss_zs_kd 7.1698 (7.3070) loss_oracle 0.6599 (0.6863) kd_loss 0.6599 (0.7097) acc 65.6250 (68.8542) lr 1.9686e-03 eta 0:26:17
epoch [6/50] batch [140/428] time 0.119 (0.087) data 0.000 (0.005) loss 1.5279 (1.5223) teacher_loss 0.7791 (0.8229) loss_zs_kd 7.3478 (7.3218) loss_oracle 0.7483 (0.6874) kd_loss 0.7494 (0.7113) acc 71.8750 (69.1741) lr 1.9686e-03 eta 0:27:34
epoch [6/50] batch [160/428] time 0.153 (0.093) data 0.000 (0.004) loss 1.6987 (1.5280) teacher_loss 0.8616 (0.8278) loss_zs_kd 7.3350 (7.3177) loss_oracle 0.8074 (0.6884) kd_loss 0.8668 (0.7120) acc 68.7500 (69.1211) lr 1.9686e-03 eta 0:29:29
epoch [6/50] batch [180/428] time 0.136 (0.097) data 0.000 (0.004) loss 1.2661 (1.5321) teacher_loss 0.6222 (0.8331) loss_zs_kd 4.7147 (7.0850) loss_oracle 0.6288 (0.6866) kd_loss 0.6589 (0.7115) acc 81.2500 (68.9410) lr 1.9686e-03 eta 0:30:57
epoch [6/50] batch [200/428] time 0.136 (0.101) data 0.000 (0.003) loss 1.3638 (1.5298) teacher_loss 0.6483 (0.8311) loss_zs_kd 4.9235 (6.8531) loss_oracle 0.7135 (0.6857) kd_loss 0.7175 (0.7117) acc 81.2500 (69.0156) lr 1.9686e-03 eta 0:32:09
epoch [6/50] batch [220/428] time 0.137 (0.104) data 0.000 (0.003) loss 1.7410 (1.5276) teacher_loss 1.0729 (0.8311) loss_zs_kd 5.3065 (6.7239) loss_oracle 0.6264 (0.6825) kd_loss 0.7100 (0.7104) acc 65.6250 (69.0057) lr 1.9686e-03 eta 0:33:08
epoch [6/50] batch [240/428] time 0.143 (0.107) data 0.000 (0.003) loss 1.4372 (1.5251) teacher_loss 0.7670 (0.8309) loss_zs_kd 5.4200 (6.6035) loss_oracle 0.6525 (0.6795) kd_loss 0.6879 (0.7090) acc 75.0000 (69.0885) lr 1.9686e-03 eta 0:33:58
epoch [6/50] batch [260/428] time 0.148 (0.109) data 0.000 (0.003) loss 1.7136 (1.5330) teacher_loss 1.0711 (0.8415) loss_zs_kd 4.8635 (6.4849) loss_oracle 0.6277 (0.6766) kd_loss 0.6574 (0.7065) acc 53.1250 (68.7500) lr 1.9686e-03 eta 0:34:37
epoch [6/50] batch [280/428] time 0.142 (0.111) data 0.000 (0.003) loss 1.4450 (1.5378) teacher_loss 0.7823 (0.8490) loss_zs_kd 4.5420 (6.3600) loss_oracle 0.6384 (0.6736) kd_loss 0.6871 (0.7041) acc 65.6250 (68.3594) lr 1.9686e-03 eta 0:35:11
epoch [6/50] batch [300/428] time 0.140 (0.113) data 0.000 (0.002) loss 1.7656 (1.5398) teacher_loss 1.0462 (0.8525) loss_zs_kd 4.2035 (6.2282) loss_oracle 0.6919 (0.6720) kd_loss 0.7469 (0.7027) acc 68.7500 (68.2812) lr 1.9686e-03 eta 0:35:41
epoch [6/50] batch [320/428] time 0.111 (0.114) data 0.000 (0.002) loss 1.9185 (1.5446) teacher_loss 1.3279 (0.8589) loss_zs_kd 4.7584 (6.1283) loss_oracle 0.5975 (0.6702) kd_loss 0.5837 (0.7012) acc 50.0000 (68.1055) lr 1.9686e-03 eta 0:36:05
epoch [6/50] batch [340/428] time 0.136 (0.115) data 0.000 (0.002) loss 1.5226 (1.5423) teacher_loss 0.9257 (0.8576) loss_zs_kd 5.2010 (6.0552) loss_oracle 0.5671 (0.6691) kd_loss 0.6267 (0.7004) acc 59.3750 (68.2629) lr 1.9686e-03 eta 0:36:20
epoch [6/50] batch [360/428] time 0.150 (0.117) data 0.000 (0.002) loss 1.4070 (1.5449) teacher_loss 0.7953 (0.8614) loss_zs_kd 5.3322 (6.0119) loss_oracle 0.5969 (0.6679) kd_loss 0.6266 (0.6991) acc 75.0000 (68.1684) lr 1.9686e-03 eta 0:36:42
epoch [6/50] batch [380/428] time 0.074 (0.117) data 0.000 (0.002) loss 1.7355 (1.5456) teacher_loss 1.1091 (0.8628) loss_zs_kd 5.4540 (5.9844) loss_oracle 0.5964 (0.6671) kd_loss 0.6562 (0.6986) acc 59.3750 (68.1414) lr 1.9686e-03 eta 0:36:43
epoch [6/50] batch [400/428] time 0.164 (0.118) data 0.000 (0.002) loss 1.3655 (1.5395) teacher_loss 0.7589 (0.8578) loss_zs_kd 5.8336 (5.9672) loss_oracle 0.5869 (0.6659) kd_loss 0.6262 (0.6975) acc 68.7500 (68.3594) lr 1.9686e-03 eta 0:37:06
epoch [6/50] batch [420/428] time 0.131 (0.117) data 0.000 (0.002) loss 1.4688 (1.5407) teacher_loss 0.7978 (0.8592) loss_zs_kd 6.0089 (5.9534) loss_oracle 0.6558 (0.6660) kd_loss 0.6862 (0.6971) acc 68.7500 (68.2887) lr 1.9686e-03 eta 0:36:51
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,011
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 34.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,660
* accuracy: 56.1%
* error: 43.9%
* macro_f1: 31.1%
******* Domain 1 best val acc:      51.9%, epoch: 5 *******
******* Domain 1 best val test acc: 57.3%, epoch: 5 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [7/50] batch [20/428] time 0.136 (0.158) data 0.000 (0.026) loss 1.7080 (1.5389) teacher_loss 1.0574 (0.8765) loss_zs_kd 5.6013 (5.7857) loss_oracle 0.6453 (0.6482) kd_loss 0.6560 (0.6764) acc 68.7500 (67.3438) lr 1.9511e-03 eta 0:49:31
epoch [7/50] batch [40/428] time 0.111 (0.147) data 0.000 (0.013) loss 1.4144 (1.5727) teacher_loss 0.7438 (0.9160) loss_zs_kd 5.8480 (5.7372) loss_oracle 0.6556 (0.6415) kd_loss 0.6856 (0.6718) acc 68.7500 (66.2500) lr 1.9511e-03 eta 0:46:09
epoch [7/50] batch [60/428] time 0.133 (0.143) data 0.000 (0.009) loss 1.6539 (1.5786) teacher_loss 0.9419 (0.9268) loss_zs_kd 5.5027 (5.7194) loss_oracle 0.7082 (0.6366) kd_loss 0.7156 (0.6669) acc 62.5000 (65.7292) lr 1.9511e-03 eta 0:44:47
epoch [7/50] batch [80/428] time 0.136 (0.141) data 0.000 (0.007) loss 1.6595 (1.5719) teacher_loss 0.9893 (0.9181) loss_zs_kd 5.6522 (5.7186) loss_oracle 0.6552 (0.6369) kd_loss 0.6852 (0.6707) acc 65.6250 (66.3672) lr 1.9511e-03 eta 0:44:04
epoch [7/50] batch [100/428] time 0.132 (0.140) data 0.000 (0.005) loss 1.3013 (1.5555) teacher_loss 0.6163 (0.8986) loss_zs_kd 5.7557 (5.7288) loss_oracle 0.6850 (0.6387) kd_loss 0.6850 (0.6751) acc 87.5000 (67.1562) lr 1.9511e-03 eta 0:43:39
epoch [7/50] batch [120/428] time 0.131 (0.139) data 0.000 (0.004) loss 1.5605 (1.5441) teacher_loss 0.8055 (0.8869) loss_zs_kd 5.7934 (5.7384) loss_oracle 0.7347 (0.6399) kd_loss 0.7755 (0.6746) acc 65.6250 (67.5260) lr 1.9511e-03 eta 0:43:19
epoch [7/50] batch [140/428] time 0.073 (0.136) data 0.000 (0.004) loss 1.9531 (1.5570) teacher_loss 1.2232 (0.8991) loss_zs_kd 5.5751 (5.7451) loss_oracle 0.6850 (0.6403) kd_loss 0.7748 (0.6754) acc 62.5000 (67.1875) lr 1.9511e-03 eta 0:42:24
epoch [7/50] batch [160/428] time 0.153 (0.140) data 0.000 (0.003) loss 1.2582 (1.5521) teacher_loss 0.5596 (0.8927) loss_zs_kd 5.7609 (5.7543) loss_oracle 0.6525 (0.6417) kd_loss 0.7448 (0.6771) acc 81.2500 (67.5000) lr 1.9511e-03 eta 0:43:30
epoch [7/50] batch [180/428] time 0.178 (0.136) data 0.000 (0.003) loss 1.5115 (1.5590) teacher_loss 0.9043 (0.8990) loss_zs_kd 5.9221 (5.7561) loss_oracle 0.5906 (0.6421) kd_loss 0.6239 (0.6779) acc 68.7500 (67.2743) lr 1.9511e-03 eta 0:42:22
epoch [7/50] batch [200/428] time 0.069 (0.139) data 0.000 (0.003) loss 1.3316 (1.5609) teacher_loss 0.6325 (0.8996) loss_zs_kd 6.0458 (5.7647) loss_oracle 0.6840 (0.6443) kd_loss 0.7143 (0.6783) acc 71.8750 (67.3281) lr 1.9511e-03 eta 0:43:05
epoch [7/50] batch [220/428] time 0.137 (0.136) data 0.000 (0.003) loss 1.7008 (1.5655) teacher_loss 1.0466 (0.9047) loss_zs_kd 5.8631 (5.7874) loss_oracle 0.6540 (0.6446) kd_loss 0.6543 (0.6771) acc 56.2500 (66.9744) lr 1.9511e-03 eta 0:42:12
epoch [7/50] batch [240/428] time 0.137 (0.136) data 0.000 (0.002) loss 1.7385 (1.5649) teacher_loss 1.1143 (0.9038) loss_zs_kd 5.9526 (5.8040) loss_oracle 0.6241 (0.6448) kd_loss 0.6241 (0.6774) acc 59.3750 (67.1224) lr 1.9511e-03 eta 0:42:11
epoch [7/50] batch [260/428] time 0.138 (0.136) data 0.000 (0.002) loss 1.5122 (1.5666) teacher_loss 0.8283 (0.9052) loss_zs_kd 5.9947 (5.8233) loss_oracle 0.6839 (0.6458) kd_loss 0.6839 (0.6771) acc 65.6250 (67.0553) lr 1.9511e-03 eta 0:42:12
epoch [7/50] batch [280/428] time 0.133 (0.137) data 0.000 (0.002) loss 1.5365 (1.5646) teacher_loss 0.7923 (0.9011) loss_zs_kd 6.1390 (5.8429) loss_oracle 0.7140 (0.6480) kd_loss 0.7744 (0.6790) acc 71.8750 (67.0424) lr 1.9511e-03 eta 0:42:13
epoch [7/50] batch [300/428] time 0.135 (0.137) data 0.000 (0.002) loss 1.4407 (1.5635) teacher_loss 0.7872 (0.9000) loss_zs_kd 5.8328 (5.8527) loss_oracle 0.6535 (0.6483) kd_loss 0.6535 (0.6787) acc 78.1250 (67.1250) lr 1.9511e-03 eta 0:42:13
epoch [7/50] batch [320/428] time 0.134 (0.136) data 0.000 (0.002) loss 1.6251 (1.5595) teacher_loss 1.0363 (0.8967) loss_zs_kd 6.2762 (5.8720) loss_oracle 0.5585 (0.6473) kd_loss 0.6191 (0.6781) acc 62.5000 (67.2266) lr 1.9511e-03 eta 0:42:00
epoch [7/50] batch [340/428] time 0.143 (0.136) data 0.000 (0.002) loss 1.3576 (1.5607) teacher_loss 0.6490 (0.8980) loss_zs_kd 5.5185 (5.8660) loss_oracle 0.6731 (0.6476) kd_loss 0.7443 (0.6779) acc 78.1250 (67.0496) lr 1.9511e-03 eta 0:41:55
epoch [7/50] batch [360/428] time 0.133 (0.136) data 0.000 (0.002) loss 1.4545 (1.5616) teacher_loss 0.7892 (0.8998) loss_zs_kd 5.6570 (5.8522) loss_oracle 0.6471 (0.6470) kd_loss 0.6835 (0.6766) acc 75.0000 (67.0312) lr 1.9511e-03 eta 0:41:51
epoch [7/50] batch [380/428] time 0.132 (0.136) data 0.000 (0.002) loss 1.4117 (1.5575) teacher_loss 0.8042 (0.8950) loss_zs_kd 5.6051 (5.8376) loss_oracle 0.5925 (0.6477) kd_loss 0.6227 (0.6772) acc 68.7500 (67.2368) lr 1.9511e-03 eta 0:41:46
epoch [7/50] batch [400/428] time 0.133 (0.136) data 0.000 (0.001) loss 1.9490 (1.5538) teacher_loss 1.2632 (0.8913) loss_zs_kd 5.8957 (5.8319) loss_oracle 0.6583 (0.6477) kd_loss 0.7134 (0.6773) acc 56.2500 (67.3984) lr 1.9511e-03 eta 0:41:42
epoch [7/50] batch [420/428] time 0.130 (0.135) data 0.000 (0.001) loss 1.3821 (1.5525) teacher_loss 0.7640 (0.8901) loss_zs_kd 5.5871 (5.8232) loss_oracle 0.5829 (0.6476) kd_loss 0.6531 (0.6772) acc 68.7500 (67.4479) lr 1.9511e-03 eta 0:41:32
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,187
* accuracy: 54.2%
* error: 45.8%
* macro_f1: 40.9%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,737
* accuracy: 57.7%
* error: 42.3%
* macro_f1: 35.1%
******* Domain 1 best val acc:      54.2%, epoch: 7 *******
******* Domain 1 best val test acc: 57.7%, epoch: 7 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [8/50] batch [20/428] time 0.130 (0.161) data 0.000 (0.027) loss 1.5507 (1.5072) teacher_loss 0.9892 (0.8535) loss_zs_kd 5.5414 (5.6463) loss_oracle 0.5617 (0.6380) kd_loss 0.5614 (0.6693) acc 62.5000 (70.0000) lr 1.9298e-03 eta 0:49:28
epoch [8/50] batch [40/428] time 0.138 (0.148) data 0.000 (0.014) loss 1.5317 (1.5458) teacher_loss 0.8385 (0.9004) loss_zs_kd 5.6738 (5.6087) loss_oracle 0.6728 (0.6315) kd_loss 0.7136 (0.6593) acc 68.7500 (68.2031) lr 1.9298e-03 eta 0:45:17
epoch [8/50] batch [60/428] time 0.131 (0.144) data 0.000 (0.009) loss 1.3979 (1.5567) teacher_loss 0.7471 (0.9054) loss_zs_kd 5.6183 (5.5617) loss_oracle 0.6497 (0.6377) kd_loss 0.6519 (0.6649) acc 68.7500 (67.5521) lr 1.9298e-03 eta 0:43:54
epoch [8/50] batch [80/428] time 0.133 (0.141) data 0.000 (0.007) loss 1.8223 (1.5651) teacher_loss 1.1439 (0.9122) loss_zs_kd 5.3965 (5.5381) loss_oracle 0.6748 (0.6411) kd_loss 0.6821 (0.6647) acc 62.5000 (67.5781) lr 1.9298e-03 eta 0:43:11
epoch [8/50] batch [100/428] time 0.146 (0.140) data 0.000 (0.006) loss 1.5090 (1.5807) teacher_loss 0.7655 (0.9240) loss_zs_kd 5.5795 (5.5283) loss_oracle 0.7435 (0.6447) kd_loss 0.7434 (0.6686) acc 75.0000 (67.0938) lr 1.9298e-03 eta 0:42:48
epoch [8/50] batch [120/428] time 0.140 (0.139) data 0.000 (0.005) loss 1.3564 (1.5709) teacher_loss 0.6431 (0.9122) loss_zs_kd 5.1978 (5.5076) loss_oracle 0.7133 (0.6476) kd_loss 0.7133 (0.6698) acc 78.1250 (67.5521) lr 1.9298e-03 eta 0:42:13
epoch [8/50] batch [140/428] time 0.134 (0.138) data 0.000 (0.004) loss 1.6764 (1.5705) teacher_loss 0.9329 (0.9097) loss_zs_kd 5.5887 (5.4952) loss_oracle 0.7436 (0.6483) kd_loss 0.7436 (0.6734) acc 62.5000 (67.6786) lr 1.9298e-03 eta 0:42:04
epoch [8/50] batch [160/428] time 0.134 (0.138) data 0.000 (0.004) loss 1.6305 (1.5687) teacher_loss 0.9667 (0.9076) loss_zs_kd 5.2951 (5.4841) loss_oracle 0.6451 (0.6474) kd_loss 0.6824 (0.6747) acc 68.7500 (67.6953) lr 1.9298e-03 eta 0:41:52
epoch [8/50] batch [180/428] time 0.136 (0.137) data 0.000 (0.003) loss 1.7093 (1.5658) teacher_loss 1.0456 (0.9035) loss_zs_kd 5.5802 (5.4821) loss_oracle 0.6456 (0.6488) kd_loss 0.6818 (0.6759) acc 62.5000 (67.6910) lr 1.9298e-03 eta 0:41:45
epoch [8/50] batch [200/428] time 0.131 (0.137) data 0.000 (0.003) loss 1.5629 (1.5604) teacher_loss 0.8320 (0.8980) loss_zs_kd 5.5292 (5.4800) loss_oracle 0.7188 (0.6487) kd_loss 0.7432 (0.6760) acc 71.8750 (67.6406) lr 1.9298e-03 eta 0:41:35
epoch [8/50] batch [220/428] time 0.173 (0.136) data 0.000 (0.003) loss 1.8289 (1.5602) teacher_loss 1.1773 (0.8982) loss_zs_kd 5.4182 (5.4753) loss_oracle 0.6211 (0.6479) kd_loss 0.6820 (0.6761) acc 62.5000 (67.6705) lr 1.9298e-03 eta 0:41:10
epoch [8/50] batch [240/428] time 0.069 (0.136) data 0.000 (0.002) loss 1.3942 (1.5577) teacher_loss 0.7499 (0.8969) loss_zs_kd 5.3980 (5.4669) loss_oracle 0.6518 (0.6469) kd_loss 0.6367 (0.6747) acc 71.8750 (67.6953) lr 1.9298e-03 eta 0:41:17
epoch [8/50] batch [260/428] time 0.181 (0.137) data 0.000 (0.002) loss 1.3039 (1.5522) teacher_loss 0.5760 (0.8898) loss_zs_kd 4.6036 (5.4230) loss_oracle 0.7126 (0.6487) kd_loss 0.7433 (0.6761) acc 71.8750 (67.9087) lr 1.9298e-03 eta 0:41:27
epoch [8/50] batch [280/428] time 0.096 (0.136) data 0.000 (0.002) loss 1.3992 (1.5503) teacher_loss 0.7176 (0.8887) loss_zs_kd 4.6840 (5.3679) loss_oracle 0.6816 (0.6483) kd_loss 0.6816 (0.6749) acc 75.0000 (67.8906) lr 1.9298e-03 eta 0:41:05
epoch [8/50] batch [300/428] time 0.135 (0.136) data 0.000 (0.002) loss 1.7677 (1.5540) teacher_loss 1.1469 (0.8921) loss_zs_kd 4.0403 (5.2801) loss_oracle 0.6211 (0.6492) kd_loss 0.6204 (0.6746) acc 59.3750 (67.9062) lr 1.9298e-03 eta 0:41:04
epoch [8/50] batch [320/428] time 0.138 (0.136) data 0.000 (0.002) loss 1.3339 (1.5516) teacher_loss 0.6018 (0.8878) loss_zs_kd 2.6182 (5.1731) loss_oracle 0.7009 (0.6511) kd_loss 0.7633 (0.6766) acc 78.1250 (68.0762) lr 1.9298e-03 eta 0:41:00
epoch [8/50] batch [340/428] time 0.134 (0.136) data 0.000 (0.002) loss 1.6652 (1.5588) teacher_loss 0.7990 (0.8883) loss_zs_kd 2.7666 (5.0242) loss_oracle 0.6794 (0.6550) kd_loss 1.0528 (0.6860) acc 78.1250 (68.2629) lr 1.9298e-03 eta 0:40:54
epoch [8/50] batch [360/428] time 0.134 (0.136) data 0.000 (0.002) loss 2.4880 (1.5984) teacher_loss 1.4501 (0.9110) loss_zs_kd 2.3042 (4.8772) loss_oracle 0.6688 (0.6588) kd_loss 1.4070 (0.7159) acc 43.7500 (67.4219) lr 1.9298e-03 eta 0:40:49
epoch [8/50] batch [380/428] time 0.129 (0.136) data 0.000 (0.002) loss 2.5068 (1.6442) teacher_loss 1.3909 (0.9366) loss_zs_kd 2.3824 (4.7429) loss_oracle 0.7552 (0.6614) kd_loss 1.4767 (0.7538) acc 56.2500 (66.5296) lr 1.9298e-03 eta 0:40:46
epoch [8/50] batch [400/428] time 0.139 (0.136) data 0.000 (0.002) loss 1.8710 (1.6809) teacher_loss 0.8202 (0.9543) loss_zs_kd 2.4516 (4.6269) loss_oracle 0.8147 (0.6683) kd_loss 1.2871 (0.7849) acc 78.1250 (65.9219) lr 1.9298e-03 eta 0:40:45
epoch [8/50] batch [420/428] time 0.136 (0.136) data 0.000 (0.002) loss 2.4508 (1.7109) teacher_loss 1.3071 (0.9667) loss_zs_kd 1.6753 (4.5154) loss_oracle 0.9401 (0.6785) kd_loss 1.3473 (0.8099) acc 56.2500 (65.3943) lr 1.9298e-03 eta 0:40:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,982
* accuracy: 50.7%
* error: 49.3%
* macro_f1: 32.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,783
* accuracy: 37.6%
* error: 62.4%
* macro_f1: 27.0%
******* Domain 1 best val acc:      54.2%, epoch: 7 *******
******* Domain 1 best val test acc: 57.7%, epoch: 7 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [9/50] batch [20/428] time 0.063 (0.177) data 0.000 (0.025) loss 1.6586 (2.2103) teacher_loss 0.8858 (1.1477) loss_zs_kd 1.7802 (1.6097) loss_oracle 0.6491 (0.8950) kd_loss 0.8965 (1.2301) acc 75.0000 (57.9688) lr 1.9048e-03 eta 0:53:04
epoch [9/50] batch [40/428] time 0.080 (0.143) data 0.000 (0.013) loss 2.5135 (2.2220) teacher_loss 1.3307 (1.1518) loss_zs_kd 1.6887 (1.6076) loss_oracle 1.0550 (0.9018) kd_loss 1.3106 (1.2387) acc 50.0000 (57.2656) lr 1.9048e-03 eta 0:42:52
epoch [9/50] batch [60/428] time 0.123 (0.135) data 0.001 (0.009) loss 2.0192 (2.1838) teacher_loss 0.9355 (1.1180) loss_zs_kd 1.8742 (1.6938) loss_oracle 0.9894 (0.9093) kd_loss 1.1780 (1.2223) acc 62.5000 (58.5938) lr 1.9048e-03 eta 0:40:22
epoch [9/50] batch [80/428] time 0.141 (0.133) data 0.000 (0.006) loss 2.0384 (2.1269) teacher_loss 1.0315 (1.0701) loss_zs_kd 2.0011 (1.7724) loss_oracle 0.8944 (0.9132) kd_loss 1.1195 (1.2005) acc 53.1250 (60.5078) lr 1.9048e-03 eta 0:39:34
epoch [9/50] batch [100/428] time 0.135 (0.133) data 0.000 (0.005) loss 2.2996 (2.1289) teacher_loss 1.1157 (1.0611) loss_zs_kd 2.0716 (1.8367) loss_oracle 1.0931 (0.9347) kd_loss 1.2746 (1.2008) acc 62.5000 (60.7188) lr 1.9048e-03 eta 0:39:37
epoch [9/50] batch [120/428] time 0.135 (0.133) data 0.000 (0.004) loss 2.2969 (2.1457) teacher_loss 1.1780 (1.0600) loss_zs_kd 2.2069 (1.8978) loss_oracle 0.9658 (0.9543) kd_loss 1.2722 (1.2171) acc 53.1250 (60.7812) lr 1.9048e-03 eta 0:39:40
epoch [9/50] batch [140/428] time 0.115 (0.133) data 0.000 (0.004) loss 2.4176 (2.1578) teacher_loss 1.2061 (1.0565) loss_zs_kd 2.1984 (1.9637) loss_oracle 1.1440 (0.9721) kd_loss 1.2791 (1.2305) acc 53.1250 (61.1384) lr 1.9048e-03 eta 0:39:35
epoch [9/50] batch [160/428] time 0.135 (0.133) data 0.000 (0.003) loss 2.4796 (2.1862) teacher_loss 1.0829 (1.0614) loss_zs_kd 2.6128 (2.0294) loss_oracle 1.3729 (0.9980) kd_loss 1.4205 (1.2516) acc 53.1250 (60.6836) lr 1.9048e-03 eta 0:39:29
epoch [9/50] batch [180/428] time 0.137 (0.133) data 0.000 (0.003) loss 2.6880 (2.2226) teacher_loss 1.3970 (1.0767) loss_zs_kd 2.5755 (2.0764) loss_oracle 1.2114 (1.0214) kd_loss 1.3707 (1.2703) acc 53.1250 (59.8958) lr 1.9048e-03 eta 0:39:29
epoch [9/50] batch [200/428] time 0.138 (0.133) data 0.000 (0.003) loss 2.3362 (2.2441) teacher_loss 1.0689 (1.0832) loss_zs_kd 2.4621 (2.1224) loss_oracle 1.1939 (1.0392) kd_loss 1.3407 (1.2827) acc 65.6250 (59.5938) lr 1.9048e-03 eta 0:39:27
epoch [9/50] batch [220/428] time 0.142 (0.133) data 0.000 (0.003) loss 2.0908 (2.2591) teacher_loss 0.8774 (1.0827) loss_zs_kd 2.6083 (2.1505) loss_oracle 1.0907 (1.0588) kd_loss 1.3360 (1.2939) acc 71.8750 (59.6449) lr 1.9048e-03 eta 0:39:27
epoch [9/50] batch [240/428] time 0.135 (0.133) data 0.000 (0.002) loss 2.1487 (2.2694) teacher_loss 0.7876 (1.0792) loss_zs_kd 2.5332 (2.1865) loss_oracle 1.3038 (1.0773) kd_loss 1.4184 (1.3031) acc 71.8750 (59.7786) lr 1.9048e-03 eta 0:39:27
epoch [9/50] batch [260/428] time 0.133 (0.134) data 0.000 (0.002) loss 2.7398 (2.2920) teacher_loss 1.2756 (1.0896) loss_zs_kd 2.7297 (2.2167) loss_oracle 1.4189 (1.0942) kd_loss 1.5096 (1.3105) acc 50.0000 (59.2668) lr 1.9048e-03 eta 0:39:29
epoch [9/50] batch [280/428] time 0.091 (0.134) data 0.000 (0.002) loss 2.4547 (2.3082) teacher_loss 1.0531 (1.0908) loss_zs_kd 2.6981 (2.2496) loss_oracle 1.3376 (1.1143) kd_loss 1.4658 (1.3206) acc 53.1250 (59.4643) lr 1.9048e-03 eta 0:39:24
epoch [9/50] batch [300/428] time 0.193 (0.134) data 0.000 (0.002) loss 2.5087 (2.3211) teacher_loss 1.0685 (1.0904) loss_zs_kd 2.9827 (2.2913) loss_oracle 1.4144 (1.1326) kd_loss 1.4658 (1.3288) acc 68.7500 (59.6771) lr 1.9048e-03 eta 0:39:36
epoch [9/50] batch [320/428] time 0.207 (0.136) data 0.000 (0.002) loss 2.5288 (2.3246) teacher_loss 1.1229 (1.0829) loss_zs_kd 2.7845 (2.3236) loss_oracle 1.4009 (1.1486) kd_loss 1.4110 (1.3349) acc 56.2500 (60.0391) lr 1.9048e-03 eta 0:39:53
epoch [9/50] batch [340/428] time 0.133 (0.136) data 0.000 (0.002) loss 2.4916 (2.3350) teacher_loss 1.1345 (1.0844) loss_zs_kd 2.7439 (2.3513) loss_oracle 1.3503 (1.1629) kd_loss 1.3639 (1.3385) acc 59.3750 (60.0919) lr 1.9048e-03 eta 0:40:06
epoch [9/50] batch [360/428] time 0.135 (0.136) data 0.000 (0.002) loss 2.4888 (2.3407) teacher_loss 1.0491 (1.0814) loss_zs_kd 3.0331 (2.3810) loss_oracle 1.4411 (1.1766) kd_loss 1.4384 (1.3420) acc 56.2500 (60.2257) lr 1.9048e-03 eta 0:40:03
epoch [9/50] batch [380/428] time 0.134 (0.136) data 0.000 (0.002) loss 2.5075 (2.3498) teacher_loss 1.1004 (1.0832) loss_zs_kd 2.8890 (2.4112) loss_oracle 1.4095 (1.1884) kd_loss 1.4047 (1.3449) acc 62.5000 (60.2632) lr 1.9048e-03 eta 0:39:49
epoch [9/50] batch [400/428] time 0.133 (0.136) data 0.000 (0.002) loss 2.7670 (2.3560) teacher_loss 1.3864 (1.0840) loss_zs_kd 2.7367 (2.4323) loss_oracle 1.3747 (1.1972) kd_loss 1.3864 (1.3467) acc 50.0000 (60.3203) lr 1.9048e-03 eta 0:39:45
epoch [9/50] batch [420/428] time 0.135 (0.136) data 0.000 (0.001) loss 1.9755 (2.3580) teacher_loss 0.6178 (1.0810) loss_zs_kd 3.0926 (2.4544) loss_oracle 1.3521 (1.2059) kd_loss 1.3633 (1.3481) acc 75.0000 (60.5432) lr 1.9048e-03 eta 0:39:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 1,336
* accuracy: 22.7%
* error: 77.3%
* macro_f1: 12.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 596
* accuracy: 12.6%
* error: 87.4%
* macro_f1: 12.0%
******* Domain 1 best val acc:      54.2%, epoch: 7 *******
******* Domain 1 best val test acc: 57.7%, epoch: 7 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [10/50] batch [20/428] time 0.073 (0.132) data 0.000 (0.025) loss 2.3701 (2.2969) teacher_loss 1.0284 (0.9661) loss_zs_kd 3.0173 (2.7579) loss_oracle 1.3540 (1.3582) kd_loss 1.3293 (1.3033) acc 56.2500 (64.5312) lr 1.8763e-03 eta 0:38:37
epoch [10/50] batch [40/428] time 0.182 (0.153) data 0.000 (0.013) loss 1.9012 (2.2945) teacher_loss 0.6585 (0.9747) loss_zs_kd 3.0039 (2.7897) loss_oracle 1.2380 (1.3360) kd_loss 1.2476 (1.3036) acc 81.2500 (64.2969) lr 1.8763e-03 eta 0:44:38
epoch [10/50] batch [60/428] time 0.190 (0.145) data 0.001 (0.009) loss 2.4906 (2.2930) teacher_loss 1.1062 (0.9710) loss_zs_kd 2.7194 (2.7760) loss_oracle 1.3628 (1.3321) kd_loss 1.4060 (1.3119) acc 56.2500 (64.3229) lr 1.8763e-03 eta 0:42:11
epoch [10/50] batch [80/428] time 0.094 (0.144) data 0.000 (0.006) loss 2.3082 (2.2948) teacher_loss 1.0825 (0.9755) loss_zs_kd 2.7139 (2.7807) loss_oracle 1.2224 (1.3263) kd_loss 1.2290 (1.3122) acc 62.5000 (64.7656) lr 1.8763e-03 eta 0:41:48
epoch [10/50] batch [100/428] time 0.152 (0.142) data 0.000 (0.005) loss 2.0207 (2.2801) teacher_loss 0.7397 (0.9670) loss_zs_kd 3.0929 (2.7842) loss_oracle 1.2709 (1.3201) kd_loss 1.2913 (1.3061) acc 75.0000 (64.7500) lr 1.8763e-03 eta 0:41:17
epoch [10/50] batch [120/428] time 0.122 (0.141) data 0.000 (0.004) loss 2.4863 (2.2782) teacher_loss 1.1178 (0.9690) loss_zs_kd 2.7454 (2.8086) loss_oracle 1.3686 (1.3174) kd_loss 1.3685 (1.3010) acc 65.6250 (64.8177) lr 1.8763e-03 eta 0:41:05
epoch [10/50] batch [140/428] time 0.127 (0.141) data 0.000 (0.004) loss 2.1511 (2.2690) teacher_loss 0.9343 (0.9663) loss_zs_kd 3.1874 (2.8210) loss_oracle 1.2197 (1.3109) kd_loss 1.2139 (1.2945) acc 56.2500 (64.9554) lr 1.8763e-03 eta 0:40:55
epoch [10/50] batch [160/428] time 0.138 (0.141) data 0.000 (0.003) loss 2.2355 (2.2545) teacher_loss 0.9965 (0.9634) loss_zs_kd 2.6366 (2.8403) loss_oracle 1.2415 (1.2989) kd_loss 1.2364 (1.2833) acc 62.5000 (65.1953) lr 1.8763e-03 eta 0:40:44
epoch [10/50] batch [180/428] time 0.137 (0.139) data 0.000 (0.003) loss 2.0985 (2.2477) teacher_loss 0.9664 (0.9696) loss_zs_kd 2.7616 (2.8602) loss_oracle 1.1508 (1.2849) kd_loss 1.1135 (1.2712) acc 71.8750 (65.1215) lr 1.8763e-03 eta 0:40:14
epoch [10/50] batch [200/428] time 0.118 (0.139) data 0.000 (0.003) loss 2.3371 (2.2433) teacher_loss 1.2254 (0.9791) loss_zs_kd 2.6563 (2.8464) loss_oracle 1.1178 (1.2704) kd_loss 1.1056 (1.2580) acc 62.5000 (64.8750) lr 1.8763e-03 eta 0:40:07
epoch [10/50] batch [220/428] time 0.134 (0.138) data 0.000 (0.003) loss 2.0915 (2.2348) teacher_loss 1.0850 (0.9886) loss_zs_kd 2.6172 (2.8335) loss_oracle 1.0050 (1.2523) kd_loss 1.0080 (1.2401) acc 59.3750 (64.4460) lr 1.8763e-03 eta 0:39:53
epoch [10/50] batch [240/428] time 0.081 (0.137) data 0.000 (0.002) loss 2.2837 (2.2226) teacher_loss 1.2682 (0.9946) loss_zs_kd 2.7539 (2.8214) loss_oracle 1.0075 (1.2340) kd_loss 1.0236 (1.2219) acc 50.0000 (64.3359) lr 1.8763e-03 eta 0:39:29
epoch [10/50] batch [260/428] time 0.131 (0.136) data 0.000 (0.002) loss 1.9685 (2.2054) teacher_loss 1.0123 (0.9961) loss_zs_kd 2.8484 (2.8141) loss_oracle 0.9755 (1.2158) kd_loss 0.9369 (1.2029) acc 65.6250 (64.2308) lr 1.8763e-03 eta 0:39:19
epoch [10/50] batch [280/428] time 0.134 (0.136) data 0.000 (0.002) loss 1.6180 (2.1829) teacher_loss 0.7079 (0.9934) loss_zs_kd 2.6071 (2.8009) loss_oracle 0.8968 (1.1956) kd_loss 0.9236 (1.1836) acc 78.1250 (64.2411) lr 1.8763e-03 eta 0:39:07
epoch [10/50] batch [300/428] time 0.131 (0.136) data 0.000 (0.002) loss 1.5750 (2.1606) teacher_loss 0.6388 (0.9896) loss_zs_kd 2.5541 (2.7861) loss_oracle 0.9298 (1.1773) kd_loss 0.9428 (1.1649) acc 78.1250 (64.3542) lr 1.8763e-03 eta 0:39:04
epoch [10/50] batch [320/428] time 0.133 (0.136) data 0.000 (0.002) loss 1.4502 (2.1411) teacher_loss 0.5624 (0.9866) loss_zs_kd 2.4454 (2.7673) loss_oracle 0.8984 (1.1603) kd_loss 0.8772 (1.1485) acc 81.2500 (64.4824) lr 1.8763e-03 eta 0:39:01
epoch [10/50] batch [340/428] time 0.080 (0.135) data 0.000 (0.002) loss 2.3615 (2.1262) teacher_loss 1.4962 (0.9879) loss_zs_kd 2.5666 (2.7619) loss_oracle 0.8808 (1.1445) kd_loss 0.8498 (1.1320) acc 59.3750 (64.4577) lr 1.8763e-03 eta 0:38:39
epoch [10/50] batch [360/428] time 0.183 (0.136) data 0.000 (0.002) loss 1.5542 (2.1066) teacher_loss 0.6957 (0.9834) loss_zs_kd 2.4373 (2.7563) loss_oracle 0.8656 (1.1302) kd_loss 0.8515 (1.1163) acc 75.0000 (64.7569) lr 1.8763e-03 eta 0:39:02
epoch [10/50] batch [380/428] time 0.178 (0.135) data 0.000 (0.002) loss 1.6859 (2.0894) teacher_loss 0.8553 (0.9809) loss_zs_kd 2.1750 (2.7346) loss_oracle 0.8632 (1.1162) kd_loss 0.7980 (1.1008) acc 81.2500 (64.9918) lr 1.8763e-03 eta 0:38:33
epoch [10/50] batch [400/428] time 0.062 (0.136) data 0.000 (0.002) loss 1.8247 (2.0714) teacher_loss 1.0443 (0.9795) loss_zs_kd 2.0757 (2.7041) loss_oracle 0.8170 (1.1014) kd_loss 0.7438 (1.0824) acc 59.3750 (64.9062) lr 1.8763e-03 eta 0:38:56
epoch [10/50] batch [420/428] time 0.137 (0.136) data 0.000 (0.001) loss 1.9296 (2.0628) teacher_loss 1.1192 (0.9849) loss_zs_kd 2.2512 (2.6763) loss_oracle 0.8285 (1.0882) kd_loss 0.7923 (1.0676) acc 50.0000 (64.7396) lr 1.8763e-03 eta 0:38:43
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,820
* accuracy: 48.0%
* error: 52.0%
* macro_f1: 33.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,833
* accuracy: 38.7%
* error: 61.3%
* macro_f1: 25.2%
******* Domain 1 best val acc:      54.2%, epoch: 7 *******
******* Domain 1 best val test acc: 57.7%, epoch: 7 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [11/50] batch [20/428] time 0.137 (0.171) data 0.000 (0.034) loss 1.7491 (1.8588) teacher_loss 0.9255 (1.0429) loss_zs_kd 3.1665 (2.9896) loss_oracle 0.8394 (0.8234) kd_loss 0.8077 (0.8083) acc 62.5000 (62.8125) lr 1.8443e-03 eta 0:48:49
epoch [11/50] batch [40/428] time 0.137 (0.154) data 0.000 (0.017) loss 2.0061 (1.8388) teacher_loss 1.2116 (1.0210) loss_zs_kd 3.0642 (3.0564) loss_oracle 0.8250 (0.8272) kd_loss 0.7639 (0.8085) acc 56.2500 (63.6719) lr 1.8443e-03 eta 0:43:50
epoch [11/50] batch [60/428] time 0.125 (0.147) data 0.000 (0.012) loss 1.8477 (1.8604) teacher_loss 1.0357 (1.0431) loss_zs_kd 3.3953 (3.0826) loss_oracle 0.8358 (0.8261) kd_loss 0.7883 (0.8084) acc 59.3750 (62.9688) lr 1.8443e-03 eta 0:41:41
epoch [11/50] batch [80/428] time 0.142 (0.144) data 0.000 (0.009) loss 2.0137 (1.8683) teacher_loss 1.2182 (1.0522) loss_zs_kd 2.7594 (3.0878) loss_oracle 0.8100 (0.8244) kd_loss 0.7811 (0.8079) acc 56.2500 (62.2266) lr 1.8443e-03 eta 0:40:55
epoch [11/50] batch [100/428] time 0.191 (0.144) data 0.000 (0.007) loss 1.7511 (1.8865) teacher_loss 0.9406 (1.0716) loss_zs_kd 3.4578 (3.0991) loss_oracle 0.8094 (0.8212) kd_loss 0.8116 (0.8086) acc 59.3750 (60.9062) lr 1.8443e-03 eta 0:40:44
epoch [11/50] batch [120/428] time 0.183 (0.144) data 0.000 (0.006) loss 2.1174 (1.8908) teacher_loss 1.3111 (1.0775) loss_zs_kd 3.1118 (3.0996) loss_oracle 0.8063 (0.8190) kd_loss 0.8063 (0.8076) acc 43.7500 (60.9635) lr 1.8443e-03 eta 0:40:51
epoch [11/50] batch [140/428] time 0.052 (0.148) data 0.000 (0.005) loss 2.0740 (1.8933) teacher_loss 1.2808 (1.0820) loss_zs_kd 2.9442 (3.0975) loss_oracle 0.8070 (0.8165) kd_loss 0.7794 (0.8060) acc 56.2500 (60.8259) lr 1.8443e-03 eta 0:41:46
epoch [11/50] batch [160/428] time 0.137 (0.144) data 0.000 (0.005) loss 2.1880 (1.8938) teacher_loss 1.3985 (1.0850) loss_zs_kd 3.1342 (3.1176) loss_oracle 0.7895 (0.8137) kd_loss 0.7895 (0.8038) acc 46.8750 (60.8789) lr 1.8443e-03 eta 0:40:40
epoch [11/50] batch [180/428] time 0.136 (0.144) data 0.000 (0.004) loss 2.0448 (1.8984) teacher_loss 1.2609 (1.0925) loss_zs_kd 2.9801 (3.1149) loss_oracle 0.7873 (0.8107) kd_loss 0.7804 (0.8010) acc 43.7500 (60.5556) lr 1.8443e-03 eta 0:40:33
epoch [11/50] batch [200/428] time 0.137 (0.142) data 0.000 (0.004) loss 1.9498 (1.9013) teacher_loss 1.1762 (1.0989) loss_zs_kd 3.1714 (3.1103) loss_oracle 0.7781 (0.8068) kd_loss 0.7691 (0.7980) acc 46.8750 (60.2656) lr 1.8443e-03 eta 0:40:05
epoch [11/50] batch [220/428] time 0.135 (0.142) data 0.000 (0.003) loss 1.9428 (1.9003) teacher_loss 1.1816 (1.1016) loss_zs_kd 2.8856 (3.1116) loss_oracle 0.7660 (0.8029) kd_loss 0.7563 (0.7945) acc 56.2500 (60.0426) lr 1.8443e-03 eta 0:39:52
epoch [11/50] batch [240/428] time 0.139 (0.141) data 0.000 (0.003) loss 1.9108 (1.8923) teacher_loss 1.1620 (1.0976) loss_zs_kd 3.4984 (3.1122) loss_oracle 0.7537 (0.7986) kd_loss 0.7440 (0.7907) acc 65.6250 (60.1693) lr 1.8443e-03 eta 0:39:40
epoch [11/50] batch [260/428] time 0.139 (0.141) data 0.000 (0.003) loss 1.8962 (1.8951) teacher_loss 1.1663 (1.1050) loss_zs_kd 3.1768 (3.1149) loss_oracle 0.7299 (0.7938) kd_loss 0.7299 (0.7863) acc 65.6250 (59.9038) lr 1.8443e-03 eta 0:39:29
epoch [11/50] batch [280/428] time 0.134 (0.140) data 0.000 (0.003) loss 1.7682 (1.8883) teacher_loss 1.0485 (1.1031) loss_zs_kd 3.6686 (3.1191) loss_oracle 0.7279 (0.7893) kd_loss 0.7116 (0.7811) acc 65.6250 (59.9219) lr 1.8443e-03 eta 0:39:20
epoch [11/50] batch [300/428] time 0.136 (0.140) data 0.000 (0.003) loss 1.9997 (1.8843) teacher_loss 1.2994 (1.1043) loss_zs_kd 3.0780 (3.1245) loss_oracle 0.7176 (0.7841) kd_loss 0.6830 (0.7758) acc 50.0000 (59.9896) lr 1.8443e-03 eta 0:39:11
epoch [11/50] batch [320/428] time 0.136 (0.140) data 0.000 (0.002) loss 1.7858 (1.8806) teacher_loss 1.0981 (1.1059) loss_zs_kd 3.3771 (3.1249) loss_oracle 0.7027 (0.7790) kd_loss 0.6728 (0.7704) acc 56.2500 (59.8828) lr 1.8443e-03 eta 0:39:04
epoch [11/50] batch [340/428] time 0.107 (0.139) data 0.000 (0.002) loss 1.8234 (1.8689) teacher_loss 1.1466 (1.0995) loss_zs_kd 2.9749 (3.1232) loss_oracle 0.6792 (0.7739) kd_loss 0.6742 (0.7649) acc 56.2500 (60.1379) lr 1.8443e-03 eta 0:38:49
epoch [11/50] batch [360/428] time 0.119 (0.138) data 0.000 (0.002) loss 1.6290 (1.8629) teacher_loss 0.9617 (1.0989) loss_zs_kd 3.1382 (3.1305) loss_oracle 0.6805 (0.7686) kd_loss 0.6542 (0.7594) acc 62.5000 (60.1562) lr 1.8443e-03 eta 0:38:24
epoch [11/50] batch [380/428] time 0.115 (0.136) data 0.000 (0.002) loss 1.8866 (1.8577) teacher_loss 1.2369 (1.0992) loss_zs_kd 2.9997 (3.1305) loss_oracle 0.6586 (0.7636) kd_loss 0.6409 (0.7536) acc 56.2500 (60.0082) lr 1.8443e-03 eta 0:37:54
epoch [11/50] batch [400/428] time 0.132 (0.136) data 0.000 (0.002) loss 1.7342 (1.8546) teacher_loss 1.0901 (1.1015) loss_zs_kd 3.1946 (3.1313) loss_oracle 0.6603 (0.7585) kd_loss 0.6278 (0.7478) acc 53.1250 (60.0781) lr 1.8443e-03 eta 0:37:47
epoch [11/50] batch [420/428] time 0.180 (0.135) data 0.000 (0.002) loss 1.8210 (1.8469) teacher_loss 1.1772 (1.0992) loss_zs_kd 3.4132 (3.1377) loss_oracle 0.6549 (0.7532) kd_loss 0.6327 (0.7422) acc 56.2500 (60.1935) lr 1.8443e-03 eta 0:37:30
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 1,986
* accuracy: 33.8%
* error: 66.2%
* macro_f1: 24.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,403
* accuracy: 29.6%
* error: 70.4%
* macro_f1: 21.7%
******* Domain 1 best val acc:      54.2%, epoch: 7 *******
******* Domain 1 best val test acc: 57.7%, epoch: 7 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [12/50] batch [20/428] time 0.135 (0.159) data 0.000 (0.025) loss 1.6896 (1.6952) teacher_loss 1.0612 (1.0626) loss_zs_kd 2.8174 (3.1030) loss_oracle 0.6330 (0.6423) kd_loss 0.6238 (0.6228) acc 53.1250 (63.5938) lr 1.8090e-03 eta 0:44:16
epoch [12/50] batch [40/428] time 0.131 (0.144) data 0.000 (0.013) loss 1.7631 (1.6928) teacher_loss 1.1363 (1.0622) loss_zs_kd 3.3984 (3.0628) loss_oracle 0.6404 (0.6403) kd_loss 0.6130 (0.6208) acc 46.8750 (62.9688) lr 1.8090e-03 eta 0:39:53
epoch [12/50] batch [60/428] time 0.132 (0.136) data 0.000 (0.009) loss 1.6758 (1.7068) teacher_loss 1.0405 (1.0786) loss_zs_kd 2.6869 (3.0206) loss_oracle 0.6688 (0.6385) kd_loss 0.6019 (0.6179) acc 62.5000 (61.9271) lr 1.8090e-03 eta 0:37:36
epoch [12/50] batch [80/428] time 0.132 (0.135) data 0.000 (0.007) loss 1.5967 (1.7076) teacher_loss 0.9785 (1.0824) loss_zs_kd 2.8764 (2.9836) loss_oracle 0.6433 (0.6353) kd_loss 0.5930 (0.6151) acc 68.7500 (61.6797) lr 1.8090e-03 eta 0:37:26
epoch [12/50] batch [100/428] time 0.136 (0.134) data 0.000 (0.005) loss 2.0521 (1.7167) teacher_loss 1.4141 (1.0937) loss_zs_kd 3.0296 (2.9298) loss_oracle 0.6741 (0.6337) kd_loss 0.6019 (0.6123) acc 59.3750 (61.3438) lr 1.8090e-03 eta 0:37:04
epoch [12/50] batch [120/428] time 0.097 (0.133) data 0.000 (0.004) loss 1.6861 (1.7194) teacher_loss 1.0871 (1.0973) loss_zs_kd 2.2972 (2.9093) loss_oracle 0.5998 (0.6341) kd_loss 0.5983 (0.6101) acc 62.5000 (61.3802) lr 1.8090e-03 eta 0:36:37
epoch [12/50] batch [140/428] time 0.118 (0.128) data 0.000 (0.004) loss 1.6209 (1.7139) teacher_loss 1.0132 (1.0929) loss_zs_kd 2.5419 (2.8740) loss_oracle 0.6257 (0.6344) kd_loss 0.5895 (0.6076) acc 59.3750 (61.3393) lr 1.8090e-03 eta 0:35:12
epoch [12/50] batch [160/428] time 0.134 (0.125) data 0.000 (0.003) loss 1.5979 (1.7186) teacher_loss 0.9603 (1.0984) loss_zs_kd 3.0898 (2.8425) loss_oracle 0.6576 (0.6353) kd_loss 0.6175 (0.6052) acc 62.5000 (60.8203) lr 1.8090e-03 eta 0:34:25
epoch [12/50] batch [180/428] time 0.217 (0.126) data 0.000 (0.003) loss 1.4821 (1.7099) teacher_loss 0.8929 (1.0918) loss_zs_kd 2.7529 (2.8309) loss_oracle 0.5867 (0.6330) kd_loss 0.5915 (0.6033) acc 65.6250 (61.3368) lr 1.8090e-03 eta 0:34:33
epoch [12/50] batch [200/428] time 0.163 (0.127) data 0.000 (0.003) loss 1.6849 (1.7053) teacher_loss 1.0758 (1.0885) loss_zs_kd 2.5812 (2.8267) loss_oracle 0.6303 (0.6321) kd_loss 0.5880 (0.6015) acc 59.3750 (61.4062) lr 1.8090e-03 eta 0:34:47
epoch [12/50] batch [220/428] time 0.070 (0.130) data 0.000 (0.003) loss 1.6417 (1.7047) teacher_loss 1.0341 (1.0886) loss_zs_kd 2.5007 (2.8218) loss_oracle 0.6267 (0.6326) kd_loss 0.5887 (0.5997) acc 56.2500 (61.2926) lr 1.8090e-03 eta 0:35:40
epoch [12/50] batch [240/428] time 0.074 (0.125) data 0.000 (0.002) loss 1.8005 (1.7073) teacher_loss 1.2153 (1.0921) loss_zs_kd 2.3241 (2.8083) loss_oracle 0.5855 (0.6324) kd_loss 0.5848 (0.5982) acc 46.8750 (61.1719) lr 1.8090e-03 eta 0:34:23
epoch [12/50] batch [260/428] time 0.076 (0.122) data 0.000 (0.002) loss 1.3845 (1.7041) teacher_loss 0.8031 (1.0900) loss_zs_kd 2.4815 (2.7939) loss_oracle 0.5787 (0.6312) kd_loss 0.5842 (0.5971) acc 65.6250 (61.1659) lr 1.8090e-03 eta 0:33:23
epoch [12/50] batch [280/428] time 0.079 (0.119) data 0.000 (0.002) loss 1.5330 (1.7031) teacher_loss 0.9163 (1.0895) loss_zs_kd 2.7253 (2.7802) loss_oracle 0.6646 (0.6314) kd_loss 0.5689 (0.5958) acc 65.6250 (61.1384) lr 1.8090e-03 eta 0:32:27
epoch [12/50] batch [300/428] time 0.057 (0.116) data 0.000 (0.002) loss 1.5614 (1.7021) teacher_loss 0.9722 (1.0896) loss_zs_kd 2.7198 (2.7760) loss_oracle 0.6085 (0.6303) kd_loss 0.5699 (0.5945) acc 62.5000 (61.1146) lr 1.8090e-03 eta 0:31:34
epoch [12/50] batch [320/428] time 0.076 (0.113) data 0.000 (0.002) loss 1.5680 (1.7012) teacher_loss 0.9977 (1.0895) loss_zs_kd 2.5314 (2.7713) loss_oracle 0.5661 (0.6300) kd_loss 0.5744 (0.5933) acc 50.0000 (61.0938) lr 1.8090e-03 eta 0:30:51
epoch [12/50] batch [340/428] time 0.092 (0.111) data 0.000 (0.002) loss 2.1902 (1.7011) teacher_loss 1.6082 (1.0902) loss_zs_kd 2.6379 (2.7612) loss_oracle 0.5914 (0.6295) kd_loss 0.5726 (0.5923) acc 46.8750 (61.1489) lr 1.8090e-03 eta 0:30:20
epoch [12/50] batch [360/428] time 0.077 (0.110) data 0.000 (0.002) loss 1.3702 (1.6959) teacher_loss 0.7939 (1.0863) loss_zs_kd 2.5528 (2.7537) loss_oracle 0.5753 (0.6279) kd_loss 0.5773 (0.5914) acc 68.7500 (61.2500) lr 1.8090e-03 eta 0:29:48
epoch [12/50] batch [380/428] time 0.073 (0.108) data 0.000 (0.002) loss 1.9996 (1.6933) teacher_loss 1.4192 (1.0846) loss_zs_kd 2.4452 (2.7473) loss_oracle 0.5906 (0.6271) kd_loss 0.5702 (0.5903) acc 50.0000 (61.3322) lr 1.8090e-03 eta 0:29:18
epoch [12/50] batch [400/428] time 0.075 (0.106) data 0.000 (0.002) loss 1.4170 (1.6906) teacher_loss 0.8322 (1.0826) loss_zs_kd 2.5183 (2.7413) loss_oracle 0.5947 (0.6265) kd_loss 0.5748 (0.5893) acc 71.8750 (61.3125) lr 1.8090e-03 eta 0:28:50
epoch [12/50] batch [420/428] time 0.070 (0.105) data 0.000 (0.001) loss 1.8507 (1.6923) teacher_loss 1.2244 (1.0850) loss_zs_kd 2.3891 (2.7330) loss_oracle 0.6834 (0.6264) kd_loss 0.5692 (0.5884) acc 53.1250 (61.2128) lr 1.8090e-03 eta 0:28:26
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,239
* accuracy: 55.1%
* error: 44.9%
* macro_f1: 41.1%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,861
* accuracy: 39.3%
* error: 60.7%
* macro_f1: 26.7%
******* Domain 1 best val acc:      55.1%, epoch: 12 *******
******* Domain 1 best val test acc: 39.3%, epoch: 12 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [13/50] batch [20/428] time 0.084 (0.153) data 0.000 (0.027) loss 1.6148 (1.6912) teacher_loss 1.0207 (1.0971) loss_zs_kd 2.5292 (2.6717) loss_oracle 0.5977 (0.6184) kd_loss 0.5905 (0.5697) acc 65.6250 (58.4375) lr 1.7705e-03 eta 0:41:22
epoch [13/50] batch [40/428] time 0.134 (0.145) data 0.000 (0.014) loss 1.7626 (1.6871) teacher_loss 1.1922 (1.0995) loss_zs_kd 2.7205 (2.6480) loss_oracle 0.5686 (0.6077) kd_loss 0.5723 (0.5676) acc 56.2500 (60.1562) lr 1.7705e-03 eta 0:39:05
epoch [13/50] batch [60/428] time 0.137 (0.142) data 0.000 (0.009) loss 1.6193 (1.6485) teacher_loss 1.0338 (1.0630) loss_zs_kd 2.4295 (2.5903) loss_oracle 0.6270 (0.6049) kd_loss 0.5441 (0.5663) acc 56.2500 (61.2500) lr 1.7705e-03 eta 0:38:25
epoch [13/50] batch [80/428] time 0.139 (0.141) data 0.000 (0.007) loss 1.6030 (1.6654) teacher_loss 1.0235 (1.0808) loss_zs_kd 2.6039 (2.5844) loss_oracle 0.5911 (0.6027) kd_loss 0.5679 (0.5664) acc 68.7500 (60.1172) lr 1.7705e-03 eta 0:37:59
epoch [13/50] batch [100/428] time 0.138 (0.140) data 0.000 (0.006) loss 1.6468 (1.6569) teacher_loss 1.0746 (1.0730) loss_zs_kd 2.5282 (2.5801) loss_oracle 0.5874 (0.6012) kd_loss 0.5570 (0.5664) acc 50.0000 (60.0625) lr 1.7705e-03 eta 0:37:43
epoch [13/50] batch [120/428] time 0.138 (0.139) data 0.000 (0.005) loss 1.5231 (1.6617) teacher_loss 0.8978 (1.0772) loss_zs_kd 2.3523 (2.5723) loss_oracle 0.6434 (0.6017) kd_loss 0.6073 (0.5673) acc 68.7500 (60.0521) lr 1.7705e-03 eta 0:37:18
epoch [13/50] batch [140/428] time 0.135 (0.139) data 0.000 (0.004) loss 1.4713 (1.6522) teacher_loss 0.8672 (1.0675) loss_zs_kd 2.2475 (2.5690) loss_oracle 0.6382 (0.6030) kd_loss 0.5700 (0.5664) acc 65.6250 (60.5580) lr 1.7705e-03 eta 0:37:26
epoch [13/50] batch [160/428] time 0.134 (0.139) data 0.000 (0.004) loss 1.7864 (1.6610) teacher_loss 1.1810 (1.0764) loss_zs_kd 2.3767 (2.5683) loss_oracle 0.6074 (0.6031) kd_loss 0.6033 (0.5660) acc 59.3750 (60.4102) lr 1.7705e-03 eta 0:37:16
epoch [13/50] batch [180/428] time 0.194 (0.134) data 0.000 (0.003) loss 1.4394 (1.6455) teacher_loss 0.8504 (1.0622) loss_zs_kd 2.5967 (2.5848) loss_oracle 0.6260 (0.6009) kd_loss 0.5520 (0.5659) acc 71.8750 (60.9549) lr 1.7705e-03 eta 0:35:54
epoch [13/50] batch [200/428] time 0.077 (0.137) data 0.001 (0.003) loss 1.6090 (1.6406) teacher_loss 1.0426 (1.0581) loss_zs_kd 2.7695 (2.5911) loss_oracle 0.5671 (0.5992) kd_loss 0.5657 (0.5657) acc 59.3750 (61.1250) lr 1.7705e-03 eta 0:36:34
epoch [13/50] batch [220/428] time 0.176 (0.138) data 0.000 (0.003) loss 1.6527 (1.6373) teacher_loss 1.0863 (1.0560) loss_zs_kd 2.4839 (2.6001) loss_oracle 0.5670 (0.5970) kd_loss 0.5659 (0.5656) acc 65.6250 (60.8949) lr 1.7705e-03 eta 0:36:55
epoch [13/50] batch [240/428] time 0.130 (0.138) data 0.000 (0.003) loss 1.7103 (1.6337) teacher_loss 1.1388 (1.0530) loss_zs_kd 2.6485 (2.6076) loss_oracle 0.5817 (0.5958) kd_loss 0.5613 (0.5655) acc 62.5000 (60.9896) lr 1.7705e-03 eta 0:36:45
epoch [13/50] batch [260/428] time 0.136 (0.138) data 0.000 (0.002) loss 1.7124 (1.6363) teacher_loss 1.1051 (1.0562) loss_zs_kd 2.6245 (2.6142) loss_oracle 0.6250 (0.5951) kd_loss 0.5896 (0.5653) acc 62.5000 (60.9375) lr 1.7705e-03 eta 0:36:41
epoch [13/50] batch [280/428] time 0.121 (0.137) data 0.000 (0.002) loss 1.5821 (1.6353) teacher_loss 1.0222 (1.0555) loss_zs_kd 2.4566 (2.6181) loss_oracle 0.5558 (0.5946) kd_loss 0.5640 (0.5650) acc 59.3750 (60.9710) lr 1.7705e-03 eta 0:36:32
epoch [13/50] batch [300/428] time 0.137 (0.137) data 0.000 (0.002) loss 1.5666 (1.6382) teacher_loss 0.9916 (1.0585) loss_zs_kd 2.7919 (2.6204) loss_oracle 0.5945 (0.5947) kd_loss 0.5555 (0.5647) acc 59.3750 (60.9375) lr 1.7705e-03 eta 0:36:28
epoch [13/50] batch [320/428] time 0.139 (0.137) data 0.000 (0.002) loss 1.6687 (1.6349) teacher_loss 1.0661 (1.0555) loss_zs_kd 2.5527 (2.6291) loss_oracle 0.6210 (0.5938) kd_loss 0.5844 (0.5649) acc 59.3750 (61.1328) lr 1.7705e-03 eta 0:36:24
epoch [13/50] batch [340/428] time 0.135 (0.137) data 0.000 (0.002) loss 1.5054 (1.6369) teacher_loss 0.9424 (1.0575) loss_zs_kd 2.6564 (2.6312) loss_oracle 0.5647 (0.5936) kd_loss 0.5614 (0.5653) acc 68.7500 (61.1489) lr 1.7705e-03 eta 0:36:20
epoch [13/50] batch [360/428] time 0.135 (0.137) data 0.000 (0.002) loss 1.6826 (1.6356) teacher_loss 1.1191 (1.0561) loss_zs_kd 2.3999 (2.6301) loss_oracle 0.5641 (0.5935) kd_loss 0.5629 (0.5656) acc 59.3750 (61.2587) lr 1.7705e-03 eta 0:36:15
epoch [13/50] batch [380/428] time 0.148 (0.137) data 0.000 (0.002) loss 1.7270 (1.6360) teacher_loss 1.1132 (1.0568) loss_zs_kd 2.6564 (2.6303) loss_oracle 0.6073 (0.5928) kd_loss 0.6204 (0.5655) acc 59.3750 (61.2829) lr 1.7705e-03 eta 0:36:12
epoch [13/50] batch [400/428] time 0.144 (0.136) data 0.000 (0.002) loss 1.7741 (1.6333) teacher_loss 1.2150 (1.0541) loss_zs_kd 2.5104 (2.6312) loss_oracle 0.5639 (0.5928) kd_loss 0.5545 (0.5657) acc 59.3750 (61.2734) lr 1.7705e-03 eta 0:36:00
epoch [13/50] batch [420/428] time 0.142 (0.136) data 0.000 (0.002) loss 1.7378 (1.6338) teacher_loss 1.1729 (1.0547) loss_zs_kd 2.5300 (2.6314) loss_oracle 0.5853 (0.5924) kd_loss 0.5445 (0.5656) acc 59.3750 (61.2723) lr 1.7705e-03 eta 0:35:57
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,482
* accuracy: 59.3%
* error: 40.7%
* macro_f1: 41.9%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,961
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 26.3%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [14/50] batch [20/428] time 0.132 (0.172) data 0.000 (0.033) loss 1.8247 (1.6780) teacher_loss 1.2279 (1.0954) loss_zs_kd 2.5452 (2.6012) loss_oracle 0.6119 (0.6019) kd_loss 0.5815 (0.5633) acc 53.1250 (60.0000) lr 1.7290e-03 eta 0:45:20
epoch [14/50] batch [40/428] time 0.134 (0.153) data 0.000 (0.017) loss 1.8223 (1.6292) teacher_loss 1.2600 (1.0452) loss_zs_kd 2.7921 (2.5865) loss_oracle 0.5646 (0.6044) kd_loss 0.5599 (0.5637) acc 62.5000 (62.6562) lr 1.7290e-03 eta 0:40:19
epoch [14/50] batch [60/428] time 0.138 (0.147) data 0.000 (0.011) loss 1.2320 (1.6074) teacher_loss 0.6341 (1.0218) loss_zs_kd 2.6139 (2.5863) loss_oracle 0.6222 (0.6074) kd_loss 0.5737 (0.5636) acc 78.1250 (63.2812) lr 1.7290e-03 eta 0:38:43
epoch [14/50] batch [80/428] time 0.131 (0.144) data 0.000 (0.008) loss 1.2698 (1.6070) teacher_loss 0.6732 (1.0228) loss_zs_kd 2.4370 (2.5989) loss_oracle 0.6182 (0.6042) kd_loss 0.5751 (0.5644) acc 81.2500 (63.5938) lr 1.7290e-03 eta 0:37:56
epoch [14/50] batch [100/428] time 0.129 (0.143) data 0.000 (0.007) loss 1.8953 (1.6038) teacher_loss 1.3455 (1.0206) loss_zs_kd 2.6546 (2.6112) loss_oracle 0.5517 (0.6016) kd_loss 0.5480 (0.5648) acc 50.0000 (63.2188) lr 1.7290e-03 eta 0:37:23
epoch [14/50] batch [120/428] time 0.134 (0.141) data 0.000 (0.006) loss 1.4641 (1.6002) teacher_loss 0.8856 (1.0174) loss_zs_kd 2.8037 (2.6380) loss_oracle 0.6216 (0.6002) kd_loss 0.5354 (0.5653) acc 75.0000 (63.5938) lr 1.7290e-03 eta 0:36:58
epoch [14/50] batch [140/428] time 0.139 (0.140) data 0.000 (0.005) loss 1.5726 (1.5971) teacher_loss 0.9719 (1.0153) loss_zs_kd 2.8405 (2.6431) loss_oracle 0.6212 (0.5987) kd_loss 0.5802 (0.5648) acc 65.6250 (63.2589) lr 1.7290e-03 eta 0:36:44
epoch [14/50] batch [160/428] time 0.133 (0.140) data 0.000 (0.004) loss 1.5009 (1.5895) teacher_loss 0.9224 (1.0093) loss_zs_kd 3.0259 (2.6696) loss_oracle 0.6085 (0.5966) kd_loss 0.5485 (0.5640) acc 65.6250 (63.5156) lr 1.7290e-03 eta 0:36:31
epoch [14/50] batch [180/428] time 0.132 (0.139) data 0.000 (0.004) loss 1.6416 (1.5994) teacher_loss 1.0936 (1.0186) loss_zs_kd 2.5886 (2.6754) loss_oracle 0.5543 (0.5972) kd_loss 0.5417 (0.5644) acc 62.5000 (63.4028) lr 1.7290e-03 eta 0:36:23
epoch [14/50] batch [200/428] time 0.133 (0.139) data 0.000 (0.004) loss 1.7629 (1.5996) teacher_loss 1.1236 (1.0188) loss_zs_kd 2.8035 (2.6890) loss_oracle 0.6524 (0.5971) kd_loss 0.6264 (0.5646) acc 53.1250 (63.5000) lr 1.7290e-03 eta 0:36:14
epoch [14/50] batch [220/428] time 0.133 (0.138) data 0.000 (0.003) loss 1.5663 (1.6084) teacher_loss 1.0216 (1.0274) loss_zs_kd 2.8464 (2.6912) loss_oracle 0.5508 (0.5976) kd_loss 0.5386 (0.5643) acc 65.6250 (63.1250) lr 1.7290e-03 eta 0:35:59
epoch [14/50] batch [240/428] time 0.097 (0.138) data 0.000 (0.003) loss 1.4338 (1.6037) teacher_loss 0.8658 (1.0226) loss_zs_kd 2.5516 (2.6979) loss_oracle 0.5593 (0.5974) kd_loss 0.5768 (0.5648) acc 75.0000 (63.2943) lr 1.7290e-03 eta 0:35:51
epoch [14/50] batch [260/428] time 0.188 (0.139) data 0.000 (0.003) loss 1.4276 (1.6043) teacher_loss 0.8586 (1.0212) loss_zs_kd 2.2837 (2.6840) loss_oracle 0.6268 (0.5997) kd_loss 0.5113 (0.5666) acc 71.8750 (63.2452) lr 1.7290e-03 eta 0:36:03
epoch [14/50] batch [280/428] time 0.186 (0.139) data 0.000 (0.003) loss 1.6277 (1.6006) teacher_loss 0.9325 (1.0148) loss_zs_kd 2.4896 (2.6750) loss_oracle 0.7096 (0.6009) kd_loss 0.6808 (0.5707) acc 65.6250 (63.6049) lr 1.7290e-03 eta 0:36:02
epoch [14/50] batch [300/428] time 0.154 (0.141) data 0.001 (0.002) loss 1.6872 (1.6005) teacher_loss 1.0416 (1.0097) loss_zs_kd 2.4811 (2.6723) loss_oracle 0.6848 (0.6054) kd_loss 0.6064 (0.5763) acc 53.1250 (63.7812) lr 1.7290e-03 eta 0:36:29
epoch [14/50] batch [320/428] time 0.134 (0.140) data 0.000 (0.002) loss 1.5075 (1.6029) teacher_loss 0.7739 (1.0062) loss_zs_kd 2.1827 (2.6565) loss_oracle 0.6874 (0.6094) kd_loss 0.7799 (0.5839) acc 90.6250 (63.9941) lr 1.7290e-03 eta 0:36:17
epoch [14/50] batch [340/428] time 0.136 (0.140) data 0.000 (0.002) loss 1.5100 (1.6064) teacher_loss 0.8257 (0.9997) loss_zs_kd 2.3846 (2.6446) loss_oracle 0.6630 (0.6164) kd_loss 0.7056 (0.5969) acc 68.7500 (64.3934) lr 1.7290e-03 eta 0:36:11
epoch [14/50] batch [360/428] time 0.138 (0.140) data 0.000 (0.002) loss 1.8775 (1.6231) teacher_loss 0.8951 (0.9974) loss_zs_kd 2.2282 (2.6227) loss_oracle 0.7672 (0.6253) kd_loss 1.1977 (0.6261) acc 62.5000 (64.2969) lr 1.7290e-03 eta 0:36:05
epoch [14/50] batch [380/428] time 0.137 (0.140) data 0.000 (0.002) loss 2.2852 (1.6400) teacher_loss 1.1811 (0.9926) loss_zs_kd 2.4933 (2.6158) loss_oracle 0.9531 (0.6376) kd_loss 1.2550 (0.6572) acc 50.0000 (64.4655) lr 1.7290e-03 eta 0:35:59
epoch [14/50] batch [400/428] time 0.136 (0.140) data 0.000 (0.002) loss 2.0885 (1.6573) teacher_loss 1.0276 (0.9908) loss_zs_kd 2.5287 (2.6105) loss_oracle 1.0188 (0.6520) kd_loss 1.1031 (0.6810) acc 59.3750 (64.5078) lr 1.7290e-03 eta 0:35:54
epoch [14/50] batch [420/428] time 0.133 (0.139) data 0.000 (0.002) loss 1.9005 (1.6706) teacher_loss 0.9129 (0.9875) loss_zs_kd 3.0740 (2.6113) loss_oracle 0.9803 (0.6665) kd_loss 0.9949 (0.6998) acc 53.1250 (64.5536) lr 1.7290e-03 eta 0:35:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,168
* accuracy: 53.9%
* error: 46.1%
* macro_f1: 31.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,734
* accuracy: 36.6%
* error: 63.4%
* macro_f1: 24.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [15/50] batch [20/428] time 0.073 (0.193) data 0.000 (0.027) loss 1.7604 (1.8645) teacher_loss 0.7350 (0.8312) loss_zs_kd 2.5409 (2.5980) loss_oracle 1.0116 (0.9801) kd_loss 1.0392 (1.0864) acc 71.8750 (69.2188) lr 1.6845e-03 eta 0:49:28
epoch [15/50] batch [40/428] time 0.137 (0.153) data 0.000 (0.013) loss 1.8914 (1.8784) teacher_loss 0.9293 (0.8434) loss_zs_kd 2.6710 (2.6040) loss_oracle 0.9049 (0.9950) kd_loss 1.0193 (1.0749) acc 59.3750 (68.2031) lr 1.6845e-03 eta 0:39:08
epoch [15/50] batch [60/428] time 0.134 (0.147) data 0.000 (0.009) loss 2.3388 (1.9004) teacher_loss 1.1004 (0.8621) loss_zs_kd 2.8538 (2.6333) loss_oracle 1.2485 (1.0101) kd_loss 1.2285 (1.0666) acc 43.7500 (67.1354) lr 1.6845e-03 eta 0:37:43
epoch [15/50] batch [80/428] time 0.136 (0.145) data 0.000 (0.007) loss 2.1893 (1.9294) teacher_loss 0.9981 (0.8723) loss_zs_kd 2.8196 (2.6561) loss_oracle 1.1888 (1.0231) kd_loss 1.1937 (1.0912) acc 68.7500 (67.2656) lr 1.6845e-03 eta 0:36:55
epoch [15/50] batch [100/428] time 0.137 (0.143) data 0.000 (0.006) loss 2.3295 (1.9454) teacher_loss 1.1217 (0.8867) loss_zs_kd 2.8309 (2.6984) loss_oracle 1.1994 (1.0223) kd_loss 1.2161 (1.0953) acc 62.5000 (66.9688) lr 1.6845e-03 eta 0:36:24
epoch [15/50] batch [120/428] time 0.111 (0.141) data 0.000 (0.005) loss 2.0886 (1.9475) teacher_loss 0.9613 (0.8880) loss_zs_kd 2.5942 (2.7175) loss_oracle 1.0925 (1.0251) kd_loss 1.1620 (1.0939) acc 68.7500 (67.1875) lr 1.6845e-03 eta 0:35:57
epoch [15/50] batch [140/428] time 0.132 (0.139) data 0.000 (0.004) loss 1.9491 (1.9503) teacher_loss 0.9023 (0.8886) loss_zs_kd 2.9955 (2.7147) loss_oracle 0.9975 (1.0308) kd_loss 1.0961 (1.0924) acc 65.6250 (67.0312) lr 1.6845e-03 eta 0:35:22
epoch [15/50] batch [160/428] time 0.136 (0.139) data 0.000 (0.004) loss 1.6048 (1.9497) teacher_loss 0.6461 (0.8870) loss_zs_kd 2.8951 (2.7261) loss_oracle 0.9486 (1.0341) kd_loss 0.9687 (1.0913) acc 75.0000 (67.0508) lr 1.6845e-03 eta 0:35:12
epoch [15/50] batch [180/428] time 0.134 (0.137) data 0.000 (0.003) loss 2.1859 (1.9537) teacher_loss 0.9729 (0.8869) loss_zs_kd 2.9491 (2.7420) loss_oracle 1.1658 (1.0397) kd_loss 1.2603 (1.0940) acc 62.5000 (67.2222) lr 1.6845e-03 eta 0:34:45
epoch [15/50] batch [200/428] time 0.138 (0.136) data 0.000 (0.003) loss 1.5905 (1.9546) teacher_loss 0.5906 (0.8858) loss_zs_kd 2.9575 (2.7577) loss_oracle 0.9966 (1.0444) kd_loss 1.0032 (1.0932) acc 78.1250 (67.3125) lr 1.6845e-03 eta 0:34:31
epoch [15/50] batch [220/428] time 0.132 (0.136) data 0.000 (0.003) loss 1.8622 (1.9453) teacher_loss 0.8869 (0.8811) loss_zs_kd 2.6541 (2.7691) loss_oracle 1.0062 (1.0425) kd_loss 0.9445 (1.0857) acc 78.1250 (67.6562) lr 1.6845e-03 eta 0:34:27
epoch [15/50] batch [240/428] time 0.133 (0.136) data 0.000 (0.002) loss 2.0262 (1.9320) teacher_loss 0.8666 (0.8716) loss_zs_kd 2.8947 (2.7725) loss_oracle 1.1484 (1.0409) kd_loss 1.1708 (1.0798) acc 62.5000 (67.8255) lr 1.6845e-03 eta 0:34:18
epoch [15/50] batch [260/428] time 0.138 (0.135) data 0.000 (0.002) loss 1.9117 (1.9255) teacher_loss 0.8465 (0.8656) loss_zs_kd 2.8026 (2.7695) loss_oracle 1.0277 (1.0408) kd_loss 1.1029 (1.0791) acc 62.5000 (67.8846) lr 1.6845e-03 eta 0:34:07
epoch [15/50] batch [280/428] time 0.101 (0.135) data 0.000 (0.002) loss 1.8666 (1.9122) teacher_loss 0.9572 (0.8573) loss_zs_kd 2.8579 (2.7701) loss_oracle 0.8973 (1.0372) kd_loss 0.9214 (1.0726) acc 56.2500 (68.1027) lr 1.6845e-03 eta 0:34:02
epoch [15/50] batch [300/428] time 0.161 (0.135) data 0.000 (0.002) loss 2.0219 (1.9040) teacher_loss 1.0671 (0.8537) loss_zs_kd 2.4813 (2.7711) loss_oracle 0.9571 (1.0341) kd_loss 0.9524 (1.0666) acc 59.3750 (68.2812) lr 1.6845e-03 eta 0:34:01
epoch [15/50] batch [320/428] time 0.218 (0.133) data 0.000 (0.002) loss 1.9330 (1.8990) teacher_loss 1.0045 (0.8507) loss_zs_kd 2.8393 (2.7672) loss_oracle 0.9677 (1.0325) kd_loss 0.8893 (1.0642) acc 59.3750 (68.2715) lr 1.6845e-03 eta 0:33:31
epoch [15/50] batch [340/428] time 0.187 (0.135) data 0.000 (0.002) loss 2.0479 (1.8977) teacher_loss 1.0245 (0.8525) loss_zs_kd 2.5641 (2.7611) loss_oracle 1.0144 (1.0298) kd_loss 1.0326 (1.0606) acc 53.1250 (68.1893) lr 1.6845e-03 eta 0:34:01
epoch [15/50] batch [360/428] time 0.136 (0.134) data 0.000 (0.002) loss 1.9036 (1.8943) teacher_loss 0.9248 (0.8519) loss_zs_kd 2.6632 (2.7560) loss_oracle 1.0021 (1.0273) kd_loss 0.9554 (1.0576) acc 65.6250 (68.2031) lr 1.6845e-03 eta 0:33:41
epoch [15/50] batch [380/428] time 0.131 (0.134) data 0.000 (0.002) loss 2.2069 (1.8942) teacher_loss 1.0872 (0.8516) loss_zs_kd 2.7203 (2.7573) loss_oracle 1.1035 (1.0270) kd_loss 1.1358 (1.0582) acc 59.3750 (68.3059) lr 1.6845e-03 eta 0:33:39
epoch [15/50] batch [400/428] time 0.133 (0.134) data 0.000 (0.002) loss 1.9082 (1.8934) teacher_loss 0.7987 (0.8505) loss_zs_kd 2.6712 (2.7526) loss_oracle 1.0493 (1.0262) kd_loss 1.1696 (1.0595) acc 65.6250 (68.3750) lr 1.6845e-03 eta 0:33:37
epoch [15/50] batch [420/428] time 0.134 (0.134) data 0.000 (0.001) loss 1.9942 (1.8936) teacher_loss 0.8789 (0.8507) loss_zs_kd 2.6664 (2.7476) loss_oracle 1.0955 (1.0255) kd_loss 1.1351 (1.0603) acc 62.5000 (68.3333) lr 1.6845e-03 eta 0:33:34
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,263
* accuracy: 55.5%
* error: 44.5%
* macro_f1: 33.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,858
* accuracy: 39.2%
* error: 60.8%
* macro_f1: 26.2%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [16/50] batch [20/428] time 0.133 (0.159) data 0.000 (0.025) loss 2.0545 (1.8413) teacher_loss 0.9785 (0.8251) loss_zs_kd 2.9635 (2.7248) loss_oracle 1.0936 (1.0089) kd_loss 1.0583 (1.0235) acc 59.3750 (68.9062) lr 1.6374e-03 eta 0:39:31
epoch [16/50] batch [40/428] time 0.187 (0.149) data 0.000 (0.012) loss 1.8573 (1.8660) teacher_loss 0.8351 (0.8345) loss_zs_kd 2.7939 (2.6948) loss_oracle 1.0126 (1.0124) kd_loss 1.0317 (1.0507) acc 56.2500 (69.2188) lr 1.6374e-03 eta 0:37:09
epoch [16/50] batch [60/428] time 0.181 (0.148) data 0.000 (0.008) loss 2.1059 (1.8860) teacher_loss 1.0017 (0.8436) loss_zs_kd 2.7082 (2.6781) loss_oracle 1.0700 (1.0195) kd_loss 1.1385 (1.0654) acc 62.5000 (69.1667) lr 1.6374e-03 eta 0:36:49
epoch [16/50] batch [80/428] time 0.164 (0.155) data 0.000 (0.006) loss 1.8871 (1.8993) teacher_loss 0.7447 (0.8452) loss_zs_kd 2.7690 (2.7206) loss_oracle 1.1577 (1.0333) kd_loss 1.1271 (1.0749) acc 71.8750 (69.0625) lr 1.6374e-03 eta 0:38:24
epoch [16/50] batch [100/428] time 0.136 (0.147) data 0.000 (0.005) loss 2.1078 (1.9148) teacher_loss 0.9591 (0.8503) loss_zs_kd 2.9033 (2.7379) loss_oracle 1.1315 (1.0424) kd_loss 1.1657 (1.0866) acc 75.0000 (69.1562) lr 1.6374e-03 eta 0:36:31
epoch [16/50] batch [120/428] time 0.137 (0.145) data 0.000 (0.004) loss 2.1603 (1.9282) teacher_loss 0.8974 (0.8547) loss_zs_kd 2.9122 (2.7662) loss_oracle 1.2596 (1.0480) kd_loss 1.2660 (1.0990) acc 65.6250 (68.9323) lr 1.6374e-03 eta 0:36:01
epoch [16/50] batch [140/428] time 0.132 (0.143) data 0.000 (0.004) loss 1.6639 (1.9274) teacher_loss 0.6214 (0.8445) loss_zs_kd 3.0027 (2.7834) loss_oracle 0.9381 (1.0573) kd_loss 1.1469 (1.1083) acc 75.0000 (69.4420) lr 1.6374e-03 eta 0:35:25
epoch [16/50] batch [160/428] time 0.131 (0.142) data 0.000 (0.003) loss 2.0466 (1.9317) teacher_loss 0.9044 (0.8431) loss_zs_kd 2.9594 (2.8085) loss_oracle 1.0902 (1.0635) kd_loss 1.1942 (1.1136) acc 65.6250 (69.6875) lr 1.6374e-03 eta 0:35:01
epoch [16/50] batch [180/428] time 0.135 (0.141) data 0.000 (0.003) loss 1.7168 (1.9347) teacher_loss 0.6621 (0.8446) loss_zs_kd 2.9595 (2.8329) loss_oracle 1.0148 (1.0660) kd_loss 1.0948 (1.1143) acc 81.2500 (69.7396) lr 1.6374e-03 eta 0:34:47
epoch [16/50] batch [200/428] time 0.129 (0.141) data 0.000 (0.003) loss 1.6569 (1.9383) teacher_loss 0.5982 (0.8497) loss_zs_kd 3.1476 (2.8409) loss_oracle 1.0430 (1.0653) kd_loss 1.0744 (1.1120) acc 81.2500 (69.7656) lr 1.6374e-03 eta 0:34:36
epoch [16/50] batch [220/428] time 0.133 (0.140) data 0.000 (0.002) loss 1.6375 (1.9341) teacher_loss 0.6648 (0.8512) loss_zs_kd 2.7668 (2.8448) loss_oracle 0.9118 (1.0598) kd_loss 1.0336 (1.1060) acc 71.8750 (69.7869) lr 1.6374e-03 eta 0:34:25
epoch [16/50] batch [240/428] time 0.138 (0.138) data 0.000 (0.002) loss 1.7068 (1.9251) teacher_loss 0.7151 (0.8493) loss_zs_kd 2.5556 (2.8378) loss_oracle 0.9391 (1.0516) kd_loss 1.0443 (1.1000) acc 71.8750 (69.8698) lr 1.6374e-03 eta 0:33:59
epoch [16/50] batch [260/428] time 0.136 (0.138) data 0.000 (0.002) loss 1.9614 (1.9189) teacher_loss 0.9357 (0.8479) loss_zs_kd 2.8430 (2.8373) loss_oracle 0.9886 (1.0466) kd_loss 1.0627 (1.0954) acc 71.8750 (69.8918) lr 1.6374e-03 eta 0:33:50
epoch [16/50] batch [280/428] time 0.135 (0.137) data 0.000 (0.002) loss 2.1700 (1.9165) teacher_loss 1.1736 (0.8499) loss_zs_kd 2.9008 (2.8380) loss_oracle 0.9903 (1.0434) kd_loss 1.0024 (1.0898) acc 53.1250 (69.7433) lr 1.6374e-03 eta 0:33:39
epoch [16/50] batch [300/428] time 0.133 (0.137) data 0.000 (0.002) loss 1.8722 (1.9087) teacher_loss 0.9085 (0.8488) loss_zs_kd 2.7541 (2.8397) loss_oracle 0.9558 (1.0376) kd_loss 0.9715 (1.0822) acc 59.3750 (69.8021) lr 1.6374e-03 eta 0:33:34
epoch [16/50] batch [320/428] time 0.136 (0.137) data 0.000 (0.002) loss 1.9274 (1.9052) teacher_loss 0.9711 (0.8504) loss_zs_kd 2.7204 (2.8394) loss_oracle 0.9658 (1.0340) kd_loss 0.9467 (1.0755) acc 68.7500 (69.6875) lr 1.6374e-03 eta 0:33:30
epoch [16/50] batch [340/428] time 0.084 (0.137) data 0.000 (0.002) loss 1.7704 (1.8947) teacher_loss 0.8268 (0.8473) loss_zs_kd 2.7905 (2.8381) loss_oracle 0.8903 (1.0278) kd_loss 0.9969 (1.0670) acc 65.6250 (69.7610) lr 1.6374e-03 eta 0:33:19
epoch [16/50] batch [360/428] time 0.142 (0.139) data 0.000 (0.002) loss 1.9278 (1.8879) teacher_loss 0.9939 (0.8471) loss_zs_kd 2.7547 (2.8267) loss_oracle 0.9404 (1.0226) kd_loss 0.9274 (1.0590) acc 62.5000 (69.7309) lr 1.6374e-03 eta 0:33:48
epoch [16/50] batch [380/428] time 0.191 (0.138) data 0.000 (0.002) loss 1.6927 (1.8798) teacher_loss 0.7442 (0.8452) loss_zs_kd 2.8945 (2.8246) loss_oracle 0.9600 (1.0177) kd_loss 0.9369 (1.0515) acc 75.0000 (69.7615) lr 1.6374e-03 eta 0:33:29
epoch [16/50] batch [400/428] time 0.111 (0.139) data 0.000 (0.001) loss 1.6438 (1.8714) teacher_loss 0.7217 (0.8432) loss_zs_kd 2.7415 (2.8241) loss_oracle 0.9286 (1.0125) kd_loss 0.9155 (1.0440) acc 68.7500 (69.7969) lr 1.6374e-03 eta 0:33:46
epoch [16/50] batch [420/428] time 0.136 (0.139) data 0.000 (0.001) loss 1.6213 (1.8651) teacher_loss 0.7416 (0.8439) loss_zs_kd 2.7412 (2.8209) loss_oracle 0.9089 (1.0070) kd_loss 0.8506 (1.0355) acc 71.8750 (69.7321) lr 1.6374e-03 eta 0:33:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,289
* accuracy: 56.0%
* error: 44.0%
* macro_f1: 34.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,077
* accuracy: 43.8%
* error: 56.2%
* macro_f1: 27.1%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [17/50] batch [20/428] time 0.136 (0.163) data 0.000 (0.031) loss 1.5372 (1.6882) teacher_loss 0.6676 (0.8096) loss_zs_kd 2.6771 (2.6526) loss_oracle 0.8914 (0.8932) kd_loss 0.8477 (0.8639) acc 78.1250 (71.8750) lr 1.5878e-03 eta 0:39:33
epoch [17/50] batch [40/428] time 0.133 (0.150) data 0.000 (0.016) loss 1.6726 (1.6802) teacher_loss 0.7897 (0.8044) loss_zs_kd 2.6923 (2.6537) loss_oracle 0.9033 (0.8903) kd_loss 0.8625 (0.8612) acc 65.6250 (71.3281) lr 1.5878e-03 eta 0:36:11
epoch [17/50] batch [60/428] time 0.137 (0.145) data 0.000 (0.011) loss 1.6307 (1.6793) teacher_loss 0.7621 (0.8024) loss_zs_kd 2.9274 (2.6975) loss_oracle 0.8900 (0.8904) kd_loss 0.8473 (0.8634) acc 78.1250 (71.7708) lr 1.5878e-03 eta 0:35:04
epoch [17/50] batch [80/428] time 0.095 (0.139) data 0.000 (0.008) loss 1.7583 (1.6761) teacher_loss 0.8697 (0.7991) loss_zs_kd 2.8211 (2.7556) loss_oracle 0.8986 (0.8888) kd_loss 0.8786 (0.8651) acc 65.6250 (72.1484) lr 1.5878e-03 eta 0:33:27
epoch [17/50] batch [100/428] time 0.130 (0.145) data 0.000 (0.006) loss 1.3804 (1.6639) teacher_loss 0.5298 (0.7889) loss_zs_kd 2.8776 (2.7899) loss_oracle 0.8703 (0.8870) kd_loss 0.8309 (0.8629) acc 78.1250 (72.5000) lr 1.5878e-03 eta 0:34:51
epoch [17/50] batch [120/428] time 0.178 (0.144) data 0.000 (0.005) loss 1.7057 (1.6653) teacher_loss 0.8369 (0.7925) loss_zs_kd 3.1204 (2.8085) loss_oracle 0.8749 (0.8851) kd_loss 0.8628 (0.8605) acc 65.6250 (72.5000) lr 1.5878e-03 eta 0:34:43
epoch [17/50] batch [140/428] time 0.130 (0.143) data 0.000 (0.005) loss 1.4760 (1.6529) teacher_loss 0.6424 (0.7825) loss_zs_kd 2.9426 (2.7950) loss_oracle 0.8578 (0.8829) kd_loss 0.8095 (0.8579) acc 78.1250 (72.9241) lr 1.5878e-03 eta 0:34:18
epoch [17/50] batch [160/428] time 0.139 (0.142) data 0.000 (0.004) loss 1.8452 (1.6539) teacher_loss 0.9737 (0.7855) loss_zs_kd 2.8201 (2.7805) loss_oracle 0.8691 (0.8809) kd_loss 0.8737 (0.8560) acc 68.7500 (72.6953) lr 1.5878e-03 eta 0:34:04
epoch [17/50] batch [180/428] time 0.133 (0.141) data 0.000 (0.004) loss 1.7191 (1.6557) teacher_loss 0.8732 (0.7899) loss_zs_kd 2.4801 (2.7830) loss_oracle 0.8518 (0.8790) kd_loss 0.8398 (0.8526) acc 71.8750 (72.6736) lr 1.5878e-03 eta 0:33:50
epoch [17/50] batch [200/428] time 0.136 (0.141) data 0.000 (0.003) loss 1.3816 (1.6551) teacher_loss 0.5298 (0.7912) loss_zs_kd 2.5520 (2.7782) loss_oracle 0.8597 (0.8774) kd_loss 0.8440 (0.8505) acc 84.3750 (72.5625) lr 1.5878e-03 eta 0:33:41
epoch [17/50] batch [220/428] time 0.146 (0.140) data 0.000 (0.003) loss 1.6182 (1.6514) teacher_loss 0.7682 (0.7885) loss_zs_kd 2.8612 (2.7779) loss_oracle 0.8548 (0.8762) kd_loss 0.8453 (0.8496) acc 71.8750 (72.6278) lr 1.5878e-03 eta 0:33:32
epoch [17/50] batch [240/428] time 0.133 (0.140) data 0.000 (0.003) loss 1.6369 (1.6581) teacher_loss 0.7743 (0.7957) loss_zs_kd 2.9541 (2.7733) loss_oracle 0.8745 (0.8757) kd_loss 0.8506 (0.8492) acc 71.8750 (72.3177) lr 1.5878e-03 eta 0:33:23
epoch [17/50] batch [260/428] time 0.137 (0.140) data 0.000 (0.003) loss 1.7946 (1.6602) teacher_loss 0.9495 (0.7981) loss_zs_kd 2.9884 (2.7829) loss_oracle 0.8773 (0.8756) kd_loss 0.8130 (0.8484) acc 78.1250 (72.3317) lr 1.5878e-03 eta 0:33:15
epoch [17/50] batch [280/428] time 0.127 (0.139) data 0.000 (0.002) loss 1.7739 (1.6575) teacher_loss 0.9056 (0.7967) loss_zs_kd 3.2288 (2.8014) loss_oracle 0.8701 (0.8747) kd_loss 0.8665 (0.8469) acc 65.6250 (72.4107) lr 1.5878e-03 eta 0:33:09
epoch [17/50] batch [300/428] time 0.143 (0.139) data 0.000 (0.002) loss 1.4633 (1.6535) teacher_loss 0.6000 (0.7931) loss_zs_kd 3.3481 (2.8152) loss_oracle 0.8717 (0.8742) kd_loss 0.8548 (0.8466) acc 84.3750 (72.5417) lr 1.5878e-03 eta 0:33:03
epoch [17/50] batch [320/428] time 0.152 (0.139) data 0.000 (0.002) loss 1.8970 (1.6484) teacher_loss 1.0784 (0.7885) loss_zs_kd 3.1644 (2.8285) loss_oracle 0.8439 (0.8736) kd_loss 0.7932 (0.8463) acc 62.5000 (72.6953) lr 1.5878e-03 eta 0:32:58
epoch [17/50] batch [340/428] time 0.087 (0.138) data 0.000 (0.002) loss 1.4852 (1.6486) teacher_loss 0.6610 (0.7894) loss_zs_kd 2.7504 (2.8350) loss_oracle 0.8620 (0.8730) kd_loss 0.7864 (0.8454) acc 75.0000 (72.6011) lr 1.5878e-03 eta 0:32:46
epoch [17/50] batch [360/428] time 0.139 (0.138) data 0.000 (0.002) loss 1.6335 (1.6505) teacher_loss 0.8047 (0.7924) loss_zs_kd 2.7064 (2.8276) loss_oracle 0.8690 (0.8722) kd_loss 0.7886 (0.8439) acc 71.8750 (72.5347) lr 1.5878e-03 eta 0:32:41
epoch [17/50] batch [380/428] time 0.134 (0.138) data 0.000 (0.002) loss 1.4915 (1.6490) teacher_loss 0.6590 (0.7918) loss_zs_kd 2.6198 (2.8210) loss_oracle 0.8702 (0.8716) kd_loss 0.7948 (0.8429) acc 75.0000 (72.4753) lr 1.5878e-03 eta 0:32:36
epoch [17/50] batch [400/428] time 0.181 (0.138) data 0.000 (0.002) loss 1.6405 (1.6498) teacher_loss 0.8283 (0.7932) loss_zs_kd 3.2428 (2.8185) loss_oracle 0.8168 (0.8710) kd_loss 0.8076 (0.8421) acc 71.8750 (72.4062) lr 1.5878e-03 eta 0:32:29
epoch [17/50] batch [420/428] time 0.152 (0.138) data 0.000 (0.002) loss 1.5772 (1.6508) teacher_loss 0.7251 (0.7952) loss_zs_kd 2.7265 (2.8208) loss_oracle 0.8755 (0.8701) kd_loss 0.8288 (0.8413) acc 78.1250 (72.3661) lr 1.5878e-03 eta 0:32:26
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,601
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 27.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,953
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 25.5%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [18/50] batch [20/428] time 0.073 (0.132) data 0.000 (0.027) loss 1.7130 (1.5309) teacher_loss 0.9059 (0.6871) loss_zs_kd 2.8326 (3.0139) loss_oracle 0.8280 (0.8567) kd_loss 0.7861 (0.8309) acc 68.7500 (76.4062) lr 1.5358e-03 eta 0:31:04
epoch [18/50] batch [40/428] time 0.074 (0.103) data 0.000 (0.013) loss 1.6116 (1.5949) teacher_loss 0.7552 (0.7501) loss_zs_kd 3.0406 (3.0153) loss_oracle 0.8761 (0.8603) kd_loss 0.8368 (0.8294) acc 65.6250 (73.6719) lr 1.5358e-03 eta 0:24:17
epoch [18/50] batch [60/428] time 0.091 (0.095) data 0.001 (0.009) loss 1.6347 (1.5868) teacher_loss 0.7922 (0.7460) loss_zs_kd 2.9555 (2.9843) loss_oracle 0.8444 (0.8583) kd_loss 0.8408 (0.8232) acc 68.7500 (74.3229) lr 1.5358e-03 eta 0:22:15
epoch [18/50] batch [80/428] time 0.083 (0.092) data 0.000 (0.007) loss 1.7655 (1.6011) teacher_loss 0.9379 (0.7654) loss_zs_kd 2.8604 (2.9409) loss_oracle 0.8325 (0.8560) kd_loss 0.8228 (0.8155) acc 62.5000 (73.7500) lr 1.5358e-03 eta 0:21:31
epoch [18/50] batch [100/428] time 0.084 (0.089) data 0.000 (0.006) loss 1.2003 (1.6025) teacher_loss 0.3720 (0.7684) loss_zs_kd 3.1133 (2.9440) loss_oracle 0.8571 (0.8558) kd_loss 0.7997 (0.8124) acc 90.6250 (73.5000) lr 1.5358e-03 eta 0:20:51
epoch [18/50] batch [120/428] time 0.074 (0.088) data 0.000 (0.005) loss 1.6460 (1.6127) teacher_loss 0.7862 (0.7786) loss_zs_kd 2.9898 (2.9559) loss_oracle 0.8523 (0.8564) kd_loss 0.8674 (0.8118) acc 59.3750 (73.0990) lr 1.5358e-03 eta 0:20:26
epoch [18/50] batch [140/428] time 0.075 (0.086) data 0.000 (0.004) loss 1.5664 (1.6169) teacher_loss 0.7233 (0.7833) loss_zs_kd 3.1907 (2.9801) loss_oracle 0.8660 (0.8557) kd_loss 0.8201 (0.8115) acc 78.1250 (72.7679) lr 1.5358e-03 eta 0:20:09
epoch [18/50] batch [160/428] time 0.085 (0.086) data 0.000 (0.004) loss 1.5278 (1.6139) teacher_loss 0.6743 (0.7800) loss_zs_kd 3.1628 (2.9969) loss_oracle 0.8713 (0.8558) kd_loss 0.8357 (0.8121) acc 75.0000 (72.8711) lr 1.5358e-03 eta 0:20:06
epoch [18/50] batch [180/428] time 0.089 (0.086) data 0.000 (0.003) loss 1.6679 (1.6164) teacher_loss 0.8289 (0.7809) loss_zs_kd 3.0759 (3.0234) loss_oracle 0.8712 (0.8566) kd_loss 0.8067 (0.8144) acc 75.0000 (72.6910) lr 1.5358e-03 eta 0:20:01
epoch [18/50] batch [200/428] time 0.092 (0.086) data 0.000 (0.003) loss 1.3647 (1.6132) teacher_loss 0.5041 (0.7766) loss_zs_kd 2.8164 (3.0273) loss_oracle 0.8688 (0.8569) kd_loss 0.8522 (0.8164) acc 84.3750 (73.0312) lr 1.5358e-03 eta 0:19:55
epoch [18/50] batch [220/428] time 0.090 (0.086) data 0.000 (0.003) loss 1.5106 (1.6178) teacher_loss 0.6557 (0.7801) loss_zs_kd 3.1109 (3.0127) loss_oracle 0.8658 (0.8570) kd_loss 0.8440 (0.8183) acc 71.8750 (72.8267) lr 1.5358e-03 eta 0:19:54
epoch [18/50] batch [240/428] time 0.077 (0.086) data 0.000 (0.002) loss 1.7406 (1.6233) teacher_loss 0.9085 (0.7861) loss_zs_kd 2.7492 (3.0173) loss_oracle 0.8683 (0.8562) kd_loss 0.7958 (0.8182) acc 71.8750 (72.6953) lr 1.5358e-03 eta 0:19:48
epoch [18/50] batch [260/428] time 0.085 (0.085) data 0.000 (0.002) loss 1.6796 (1.6223) teacher_loss 0.8499 (0.7851) loss_zs_kd 3.0495 (3.0189) loss_oracle 0.8489 (0.8561) kd_loss 0.8106 (0.8183) acc 75.0000 (72.4760) lr 1.5358e-03 eta 0:19:44
epoch [18/50] batch [280/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.2675 (1.6168) teacher_loss 0.4262 (0.7803) loss_zs_kd 2.8551 (3.0140) loss_oracle 0.8663 (0.8560) kd_loss 0.8161 (0.8170) acc 87.5000 (72.7232) lr 1.5358e-03 eta 0:19:36
epoch [18/50] batch [300/428] time 0.075 (0.085) data 0.000 (0.002) loss 1.5044 (1.6159) teacher_loss 0.6690 (0.7799) loss_zs_kd 3.2932 (3.0149) loss_oracle 0.8674 (0.8556) kd_loss 0.8035 (0.8164) acc 81.2500 (72.8125) lr 1.5358e-03 eta 0:19:29
epoch [18/50] batch [320/428] time 0.072 (0.084) data 0.000 (0.002) loss 1.6147 (1.6135) teacher_loss 0.8191 (0.7779) loss_zs_kd 3.0993 (3.0221) loss_oracle 0.8629 (0.8555) kd_loss 0.7283 (0.8158) acc 78.1250 (72.9297) lr 1.5358e-03 eta 0:19:21
epoch [18/50] batch [340/428] time 0.081 (0.084) data 0.000 (0.002) loss 1.6486 (1.6118) teacher_loss 0.8045 (0.7763) loss_zs_kd 2.9834 (3.0197) loss_oracle 0.8452 (0.8553) kd_loss 0.8429 (0.8156) acc 75.0000 (73.0055) lr 1.5358e-03 eta 0:19:17
epoch [18/50] batch [360/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.6064 (1.6111) teacher_loss 0.7637 (0.7758) loss_zs_kd 2.6992 (3.0121) loss_oracle 0.8372 (0.8551) kd_loss 0.8483 (0.8155) acc 65.6250 (73.1250) lr 1.5358e-03 eta 0:19:15
epoch [18/50] batch [380/428] time 0.081 (0.084) data 0.000 (0.002) loss 1.7775 (1.6112) teacher_loss 0.9297 (0.7761) loss_zs_kd 3.1592 (3.0036) loss_oracle 0.8610 (0.8551) kd_loss 0.8347 (0.8149) acc 68.7500 (73.2812) lr 1.5358e-03 eta 0:19:13
epoch [18/50] batch [400/428] time 0.080 (0.084) data 0.000 (0.002) loss 1.5503 (1.6104) teacher_loss 0.6692 (0.7748) loss_zs_kd 2.5109 (3.0233) loss_oracle 0.8987 (0.8558) kd_loss 0.8635 (0.8154) acc 81.2500 (73.3984) lr 1.5358e-03 eta 0:19:10
epoch [18/50] batch [420/428] time 0.069 (0.084) data 0.000 (0.002) loss 1.6370 (1.6094) teacher_loss 0.7811 (0.7735) loss_zs_kd 2.7639 (3.0091) loss_oracle 0.8435 (0.8561) kd_loss 0.8684 (0.8159) acc 71.8750 (73.4970) lr 1.5358e-03 eta 0:19:17
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,702
* accuracy: 46.0%
* error: 54.0%
* macro_f1: 26.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,032
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 24.8%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     61.6%, epoch: 3 *******
epoch [19/50] batch [20/428] time 0.065 (0.093) data 0.000 (0.024) loss 1.4712 (1.6214) teacher_loss 0.6226 (0.7769) loss_zs_kd 2.9798 (2.8564) loss_oracle 0.8474 (0.8559) kd_loss 0.8497 (0.8332) acc 84.3750 (73.7500) lr 1.4818e-03 eta 0:21:14
epoch [19/50] batch [40/428] time 0.062 (0.079) data 0.000 (0.012) loss 1.4734 (1.6152) teacher_loss 0.6097 (0.7738) loss_zs_kd 2.4030 (2.7073) loss_oracle 0.8643 (0.8557) kd_loss 0.8632 (0.8272) acc 78.1250 (73.6719) lr 1.4818e-03 eta 0:18:02
epoch [19/50] batch [60/428] time 0.075 (0.077) data 0.000 (0.008) loss 1.5712 (1.6103) teacher_loss 0.7239 (0.7707) loss_zs_kd 2.4507 (2.6457) loss_oracle 0.8673 (0.8555) kd_loss 0.8273 (0.8236) acc 75.0000 (74.1146) lr 1.4818e-03 eta 0:17:24
epoch [19/50] batch [80/428] time 0.071 (0.076) data 0.000 (0.006) loss 1.4927 (1.5907) teacher_loss 0.6516 (0.7512) loss_zs_kd 2.4849 (2.5834) loss_oracle 0.8421 (0.8558) kd_loss 0.8401 (0.8231) acc 81.2500 (74.8047) lr 1.4818e-03 eta 0:17:19
epoch [19/50] batch [100/428] time 0.081 (0.076) data 0.000 (0.005) loss 1.5352 (1.5903) teacher_loss 0.6791 (0.7517) loss_zs_kd 2.4481 (2.5597) loss_oracle 0.8667 (0.8562) kd_loss 0.8455 (0.8209) acc 75.0000 (74.6250) lr 1.4818e-03 eta 0:17:11
epoch [19/50] batch [120/428] time 0.085 (0.076) data 0.000 (0.004) loss 1.4715 (1.5820) teacher_loss 0.6242 (0.7440) loss_zs_kd 2.8954 (2.5608) loss_oracle 0.8596 (0.8561) kd_loss 0.8349 (0.8199) acc 75.0000 (75.1823) lr 1.4818e-03 eta 0:17:05
epoch [19/50] batch [140/428] time 0.083 (0.076) data 0.000 (0.004) loss 1.3905 (1.5808) teacher_loss 0.5259 (0.7433) loss_zs_kd 2.6156 (2.5758) loss_oracle 0.9060 (0.8574) kd_loss 0.8230 (0.8177) acc 90.6250 (75.2232) lr 1.4818e-03 eta 0:17:12
epoch [19/50] batch [160/428] time 0.091 (0.077) data 0.000 (0.003) loss 1.9581 (1.5907) teacher_loss 1.0288 (0.7468) loss_zs_kd 2.5797 (2.5517) loss_oracle 0.8682 (0.8653) kd_loss 0.9906 (0.8226) acc 71.8750 (74.9805) lr 1.4818e-03 eta 0:17:23
epoch [19/50] batch [180/428] time 0.096 (0.080) data 0.000 (0.003) loss 2.1942 (1.6572) teacher_loss 1.1156 (0.7878) loss_zs_kd 2.2104 (2.5247) loss_oracle 0.8268 (0.8745) kd_loss 1.3303 (0.8644) acc 68.7500 (73.4896) lr 1.4818e-03 eta 0:18:00
epoch [19/50] batch [200/428] time 0.078 (0.080) data 0.000 (0.003) loss 2.0410 (1.7098) teacher_loss 0.9619 (0.8207) loss_zs_kd 2.2747 (2.4965) loss_oracle 0.8453 (0.8722) kd_loss 1.3130 (0.9060) acc 65.6250 (72.3125) lr 1.4818e-03 eta 0:18:05
epoch [19/50] batch [220/428] time 0.076 (0.080) data 0.000 (0.002) loss 1.7933 (1.7311) teacher_loss 0.7957 (0.8317) loss_zs_kd 2.5356 (2.4814) loss_oracle 0.9064 (0.8718) kd_loss 1.0889 (0.9270) acc 71.8750 (72.1165) lr 1.4818e-03 eta 0:18:01
epoch [19/50] batch [240/428] time 0.081 (0.080) data 0.000 (0.002) loss 1.5771 (1.7227) teacher_loss 0.6572 (0.8216) loss_zs_kd 2.3621 (2.4655) loss_oracle 0.8656 (0.8728) kd_loss 0.9743 (0.9293) acc 78.1250 (72.3438) lr 1.4818e-03 eta 0:18:01
epoch [19/50] batch [260/428] time 0.071 (0.080) data 0.000 (0.002) loss 1.5155 (1.7116) teacher_loss 0.6757 (0.8132) loss_zs_kd 2.1768 (2.4545) loss_oracle 0.8630 (0.8715) kd_loss 0.8166 (0.9253) acc 75.0000 (72.6202) lr 1.4818e-03 eta 0:18:01
epoch [19/50] batch [280/428] time 0.082 (0.080) data 0.000 (0.002) loss 1.5928 (1.7029) teacher_loss 0.7114 (0.8067) loss_zs_kd 2.2880 (2.4351) loss_oracle 0.8541 (0.8706) kd_loss 0.9088 (0.9219) acc 71.8750 (72.9018) lr 1.4818e-03 eta 0:17:59
epoch [19/50] batch [300/428] time 0.084 (0.081) data 0.000 (0.002) loss 1.3934 (1.6983) teacher_loss 0.5546 (0.8050) loss_zs_kd 2.3555 (2.4314) loss_oracle 0.8587 (0.8700) kd_loss 0.8189 (0.9166) acc 84.3750 (72.9062) lr 1.4818e-03 eta 0:17:58
epoch [19/50] batch [320/428] time 0.080 (0.081) data 0.000 (0.002) loss 1.5785 (1.6926) teacher_loss 0.7015 (0.8009) loss_zs_kd 2.5632 (2.4306) loss_oracle 0.8609 (0.8700) kd_loss 0.8931 (0.9135) acc 71.8750 (73.1934) lr 1.4818e-03 eta 0:18:01
epoch [19/50] batch [340/428] time 0.082 (0.081) data 0.000 (0.002) loss 1.9303 (1.6894) teacher_loss 0.9766 (0.7984) loss_zs_kd 2.4344 (2.4338) loss_oracle 0.9086 (0.8700) kd_loss 0.9988 (0.9120) acc 62.5000 (73.1893) lr 1.4818e-03 eta 0:17:58
epoch [19/50] batch [360/428] time 0.085 (0.081) data 0.000 (0.002) loss 1.5928 (1.6858) teacher_loss 0.6797 (0.7944) loss_zs_kd 2.5169 (2.4369) loss_oracle 0.9116 (0.8710) kd_loss 0.9147 (0.9117) acc 75.0000 (73.2205) lr 1.4818e-03 eta 0:17:57
epoch [19/50] batch [380/428] time 0.088 (0.081) data 0.000 (0.002) loss 1.7013 (1.6807) teacher_loss 0.7144 (0.7879) loss_zs_kd 2.4416 (2.4408) loss_oracle 1.0024 (0.8739) kd_loss 0.9714 (0.9117) acc 78.1250 (73.4868) lr 1.4818e-03 eta 0:17:57
epoch [19/50] batch [400/428] time 0.091 (0.081) data 0.000 (0.001) loss 1.6331 (1.6774) teacher_loss 0.5773 (0.7805) loss_zs_kd 2.9279 (2.4491) loss_oracle 1.0783 (0.8797) kd_loss 1.0332 (0.9141) acc 84.3750 (73.6406) lr 1.4818e-03 eta 0:17:54
epoch [19/50] batch [420/428] time 0.069 (0.081) data 0.000 (0.001) loss 1.7427 (1.6754) teacher_loss 0.7216 (0.7755) loss_zs_kd 2.5515 (2.4600) loss_oracle 1.0326 (0.8835) kd_loss 1.0098 (0.9161) acc 78.1250 (73.7798) lr 1.4818e-03 eta 0:17:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,181
* accuracy: 54.1%
* error: 45.9%
* macro_f1: 38.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,944
* accuracy: 62.1%
* error: 37.9%
* macro_f1: 30.5%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [20/50] batch [20/428] time 0.082 (0.153) data 0.000 (0.033) loss 1.6522 (1.5997) teacher_loss 0.6773 (0.6040) loss_zs_kd 2.8305 (2.7493) loss_oracle 0.9895 (1.0019) kd_loss 0.9602 (0.9894) acc 71.8750 (79.0625) lr 1.4258e-03 eta 0:33:47
epoch [20/50] batch [40/428] time 0.137 (0.134) data 0.000 (0.017) loss 1.5002 (1.5872) teacher_loss 0.5410 (0.6054) loss_zs_kd 2.7243 (2.7783) loss_oracle 0.9467 (0.9988) kd_loss 0.9717 (0.9649) acc 81.2500 (78.8281) lr 1.4258e-03 eta 0:29:35
epoch [20/50] batch [60/428] time 0.131 (0.131) data 0.000 (0.011) loss 1.4595 (1.5775) teacher_loss 0.5617 (0.6070) loss_zs_kd 2.6161 (2.7673) loss_oracle 0.8874 (0.9894) kd_loss 0.9083 (0.9518) acc 78.1250 (79.2708) lr 1.4258e-03 eta 0:28:45
epoch [20/50] batch [80/428] time 0.137 (0.129) data 0.000 (0.008) loss 1.8091 (1.5924) teacher_loss 0.9000 (0.6338) loss_zs_kd 2.5287 (2.6981) loss_oracle 1.0091 (0.9835) kd_loss 0.8090 (0.9337) acc 62.5000 (78.4766) lr 1.4258e-03 eta 0:28:16
epoch [20/50] batch [100/428] time 0.116 (0.126) data 0.000 (0.007) loss 1.6861 (1.6020) teacher_loss 0.6368 (0.6454) loss_zs_kd 2.6659 (2.6823) loss_oracle 1.0755 (0.9856) kd_loss 1.0230 (0.9275) acc 87.5000 (77.6250) lr 1.4258e-03 eta 0:27:43
epoch [20/50] batch [120/428] time 0.116 (0.124) data 0.000 (0.006) loss 1.5057 (1.6040) teacher_loss 0.4239 (0.6420) loss_zs_kd 2.5270 (2.6672) loss_oracle 1.1231 (0.9915) kd_loss 1.0406 (0.9326) acc 90.6250 (77.7344) lr 1.4258e-03 eta 0:27:11
epoch [20/50] batch [140/428] time 0.138 (0.125) data 0.000 (0.005) loss 1.6177 (1.6191) teacher_loss 0.6437 (0.6531) loss_zs_kd 2.8526 (2.6787) loss_oracle 0.9892 (0.9951) kd_loss 0.9588 (0.9368) acc 75.0000 (77.0982) lr 1.4258e-03 eta 0:27:26
epoch [20/50] batch [160/428] time 0.074 (0.123) data 0.000 (0.004) loss 1.7004 (1.6195) teacher_loss 0.7521 (0.6542) loss_zs_kd 2.5513 (2.6689) loss_oracle 0.9818 (0.9929) kd_loss 0.9149 (0.9376) acc 81.2500 (76.7188) lr 1.4258e-03 eta 0:26:48
epoch [20/50] batch [180/428] time 0.187 (0.127) data 0.000 (0.004) loss 1.9508 (1.6299) teacher_loss 0.9501 (0.6653) loss_zs_kd 2.3834 (2.6596) loss_oracle 1.0359 (0.9944) kd_loss 0.9654 (0.9348) acc 62.5000 (76.3368) lr 1.4258e-03 eta 0:27:40
epoch [20/50] batch [200/428] time 0.193 (0.125) data 0.000 (0.004) loss 1.8211 (1.6335) teacher_loss 0.8489 (0.6704) loss_zs_kd 1.9728 (2.6479) loss_oracle 1.0407 (0.9952) kd_loss 0.9036 (0.9310) acc 68.7500 (76.3125) lr 1.4258e-03 eta 0:27:19
epoch [20/50] batch [220/428] time 0.120 (0.128) data 0.000 (0.003) loss 1.6233 (1.6336) teacher_loss 0.6971 (0.6716) loss_zs_kd 3.1872 (2.6541) loss_oracle 0.9889 (0.9942) kd_loss 0.8636 (0.9299) acc 78.1250 (76.2500) lr 1.4258e-03 eta 0:27:54
epoch [20/50] batch [240/428] time 0.107 (0.125) data 0.000 (0.003) loss 1.9015 (1.6374) teacher_loss 0.8355 (0.6750) loss_zs_kd 2.7609 (2.6577) loss_oracle 1.1170 (0.9949) kd_loss 1.0150 (0.9297) acc 65.6250 (76.1458) lr 1.4258e-03 eta 0:27:14
epoch [20/50] batch [260/428] time 0.138 (0.126) data 0.000 (0.003) loss 1.7823 (1.6386) teacher_loss 0.8837 (0.6771) loss_zs_kd 2.8027 (2.6795) loss_oracle 0.9296 (0.9948) kd_loss 0.8675 (0.9281) acc 62.5000 (76.0697) lr 1.4258e-03 eta 0:27:13
epoch [20/50] batch [280/428] time 0.139 (0.126) data 0.000 (0.003) loss 1.7903 (1.6415) teacher_loss 0.7901 (0.6786) loss_zs_kd 2.7999 (2.6931) loss_oracle 1.0429 (0.9979) kd_loss 0.9576 (0.9279) acc 65.6250 (75.9710) lr 1.4258e-03 eta 0:27:13
epoch [20/50] batch [300/428] time 0.139 (0.126) data 0.000 (0.002) loss 1.6976 (1.6420) teacher_loss 0.7175 (0.6781) loss_zs_kd 3.1748 (2.7027) loss_oracle 1.0200 (0.9985) kd_loss 0.9401 (0.9294) acc 68.7500 (75.9792) lr 1.4258e-03 eta 0:27:19
epoch [20/50] batch [320/428] time 0.152 (0.127) data 0.000 (0.002) loss 1.5720 (1.6430) teacher_loss 0.4939 (0.6781) loss_zs_kd 2.7722 (2.7130) loss_oracle 1.1164 (0.9986) kd_loss 1.0398 (0.9311) acc 78.1250 (75.9766) lr 1.4258e-03 eta 0:27:28
epoch [20/50] batch [340/428] time 0.134 (0.128) data 0.000 (0.002) loss 1.7013 (1.6455) teacher_loss 0.6679 (0.6795) loss_zs_kd 2.6408 (2.7294) loss_oracle 0.9920 (0.9993) kd_loss 1.0747 (0.9326) acc 81.2500 (76.0386) lr 1.4258e-03 eta 0:27:29
epoch [20/50] batch [360/428] time 0.137 (0.128) data 0.000 (0.002) loss 1.6752 (1.6449) teacher_loss 0.6486 (0.6790) loss_zs_kd 2.9854 (2.7454) loss_oracle 1.0573 (0.9987) kd_loss 0.9959 (0.9330) acc 68.7500 (76.0851) lr 1.4258e-03 eta 0:27:34
epoch [20/50] batch [380/428] time 0.139 (0.129) data 0.000 (0.002) loss 1.6253 (1.6497) teacher_loss 0.7008 (0.6818) loss_zs_kd 2.9877 (2.7594) loss_oracle 0.9270 (1.0009) kd_loss 0.9221 (0.9348) acc 71.8750 (75.9293) lr 1.4258e-03 eta 0:27:38
epoch [20/50] batch [400/428] time 0.136 (0.129) data 0.000 (0.002) loss 1.7402 (1.6536) teacher_loss 0.6018 (0.6840) loss_zs_kd 2.6788 (2.7715) loss_oracle 1.2070 (1.0031) kd_loss 1.0697 (0.9360) acc 81.2500 (75.8984) lr 1.4258e-03 eta 0:27:41
epoch [20/50] batch [420/428] time 0.137 (0.129) data 0.000 (0.002) loss 1.6266 (1.6566) teacher_loss 0.7509 (0.6865) loss_zs_kd 2.9856 (2.7849) loss_oracle 0.8776 (1.0040) kd_loss 0.8738 (0.9362) acc 68.7500 (75.7812) lr 1.4258e-03 eta 0:27:43
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,716
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 25.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,039
* accuracy: 43.0%
* error: 57.0%
* macro_f1: 24.0%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [21/50] batch [20/428] time 0.112 (0.157) data 0.000 (0.031) loss 1.9976 (1.7500) teacher_loss 1.0066 (0.7912) loss_zs_kd 3.4687 (3.1482) loss_oracle 1.0708 (1.0107) kd_loss 0.9112 (0.9069) acc 75.0000 (73.9062) lr 1.3681e-03 eta 0:33:29
epoch [21/50] batch [40/428] time 0.131 (0.144) data 0.000 (0.016) loss 1.3429 (1.6858) teacher_loss 0.4305 (0.7318) loss_zs_kd 3.6017 (3.2675) loss_oracle 0.9483 (0.9950) kd_loss 0.8766 (0.9129) acc 93.7500 (76.0156) lr 1.3681e-03 eta 0:30:48
epoch [21/50] batch [60/428] time 0.151 (0.143) data 0.000 (0.011) loss 1.6387 (1.6759) teacher_loss 0.7126 (0.7199) loss_zs_kd 3.1987 (3.2683) loss_oracle 0.9558 (0.9904) kd_loss 0.8962 (0.9216) acc 75.0000 (75.5729) lr 1.3681e-03 eta 0:30:24
epoch [21/50] batch [80/428] time 0.147 (0.140) data 0.001 (0.008) loss 1.4860 (1.6681) teacher_loss 0.5362 (0.7209) loss_zs_kd 3.3958 (3.2634) loss_oracle 0.9861 (0.9839) kd_loss 0.9133 (0.9105) acc 81.2500 (75.4297) lr 1.3681e-03 eta 0:29:40
epoch [21/50] batch [100/428] time 0.143 (0.139) data 0.000 (0.006) loss 1.7053 (1.6698) teacher_loss 0.7587 (0.7182) loss_zs_kd 3.4008 (3.2780) loss_oracle 0.9898 (0.9888) kd_loss 0.9035 (0.9145) acc 68.7500 (75.2500) lr 1.3681e-03 eta 0:29:27
epoch [21/50] batch [120/428] time 0.130 (0.137) data 0.001 (0.005) loss 1.7070 (1.6922) teacher_loss 0.7738 (0.7334) loss_zs_kd 3.5852 (3.2692) loss_oracle 0.9776 (0.9976) kd_loss 0.8889 (0.9200) acc 62.5000 (74.7656) lr 1.3681e-03 eta 0:29:07
epoch [21/50] batch [140/428] time 0.131 (0.138) data 0.000 (0.005) loss 1.5209 (1.6910) teacher_loss 0.5904 (0.7295) loss_zs_kd 3.2098 (3.2410) loss_oracle 0.9200 (0.9989) kd_loss 0.9410 (0.9241) acc 75.0000 (74.6429) lr 1.3681e-03 eta 0:29:11
epoch [21/50] batch [160/428] time 0.136 (0.138) data 0.000 (0.004) loss 1.4337 (1.6903) teacher_loss 0.4398 (0.7278) loss_zs_kd 3.3571 (3.2295) loss_oracle 1.0440 (0.9988) kd_loss 0.9437 (0.9263) acc 87.5000 (74.7266) lr 1.3681e-03 eta 0:29:14
epoch [21/50] batch [180/428] time 0.149 (0.138) data 0.000 (0.004) loss 1.5526 (1.6893) teacher_loss 0.4435 (0.7195) loss_zs_kd 3.4651 (3.2510) loss_oracle 1.1404 (1.0063) kd_loss 1.0779 (0.9332) acc 84.3750 (75.0000) lr 1.3681e-03 eta 0:29:09
epoch [21/50] batch [200/428] time 0.140 (0.137) data 0.000 (0.003) loss 1.5051 (1.6871) teacher_loss 0.5140 (0.7133) loss_zs_kd 3.0700 (3.2402) loss_oracle 1.0382 (1.0106) kd_loss 0.9440 (0.9371) acc 87.5000 (75.2344) lr 1.3681e-03 eta 0:28:54
epoch [21/50] batch [220/428] time 0.149 (0.137) data 0.000 (0.003) loss 1.7858 (1.6837) teacher_loss 0.7201 (0.7122) loss_zs_kd 2.7969 (3.2288) loss_oracle 1.0722 (1.0059) kd_loss 1.0590 (0.9371) acc 78.1250 (75.2131) lr 1.3681e-03 eta 0:28:53
epoch [21/50] batch [240/428] time 0.138 (0.137) data 0.000 (0.003) loss 1.6965 (1.6876) teacher_loss 0.7523 (0.7168) loss_zs_kd 2.9494 (3.2339) loss_oracle 0.9532 (1.0039) kd_loss 0.9352 (0.9376) acc 75.0000 (75.0260) lr 1.3681e-03 eta 0:28:50
epoch [21/50] batch [260/428] time 0.082 (0.136) data 0.000 (0.003) loss 1.5006 (1.6788) teacher_loss 0.5886 (0.7081) loss_zs_kd 3.1812 (3.2299) loss_oracle 0.9192 (1.0029) kd_loss 0.9050 (0.9385) acc 71.8750 (75.2764) lr 1.3681e-03 eta 0:28:35
epoch [21/50] batch [280/428] time 0.067 (0.139) data 0.000 (0.003) loss 1.8912 (1.6834) teacher_loss 0.8579 (0.7130) loss_zs_kd 3.2916 (3.2234) loss_oracle 1.0661 (1.0021) kd_loss 1.0006 (0.9387) acc 75.0000 (75.0558) lr 1.3681e-03 eta 0:29:04
epoch [21/50] batch [300/428] time 0.193 (0.140) data 0.000 (0.002) loss 1.6177 (1.6818) teacher_loss 0.7419 (0.7100) loss_zs_kd 2.9019 (3.2105) loss_oracle 0.8957 (1.0025) kd_loss 0.8558 (0.9409) acc 78.1250 (75.1042) lr 1.3681e-03 eta 0:29:12
epoch [21/50] batch [320/428] time 0.137 (0.140) data 0.000 (0.002) loss 1.6935 (1.6816) teacher_loss 0.6142 (0.7087) loss_zs_kd 3.1938 (3.2047) loss_oracle 1.0834 (1.0030) kd_loss 1.0752 (0.9428) acc 71.8750 (75.0293) lr 1.3681e-03 eta 0:29:10
epoch [21/50] batch [340/428] time 0.136 (0.140) data 0.000 (0.002) loss 1.5376 (1.6843) teacher_loss 0.5588 (0.7106) loss_zs_kd 3.2868 (3.2012) loss_oracle 0.9836 (1.0033) kd_loss 0.9740 (0.9440) acc 78.1250 (75.0368) lr 1.3681e-03 eta 0:29:05
epoch [21/50] batch [360/428] time 0.141 (0.139) data 0.000 (0.002) loss 1.8600 (1.6882) teacher_loss 0.8367 (0.7127) loss_zs_kd 2.7608 (3.1875) loss_oracle 1.1065 (1.0054) kd_loss 0.9401 (0.9455) acc 65.6250 (74.9132) lr 1.3681e-03 eta 0:29:00
epoch [21/50] batch [380/428] time 0.135 (0.139) data 0.000 (0.002) loss 1.5794 (1.6928) teacher_loss 0.5860 (0.7169) loss_zs_kd 3.1717 (3.1801) loss_oracle 1.0140 (1.0067) kd_loss 0.9728 (0.9452) acc 84.3750 (74.7862) lr 1.3681e-03 eta 0:28:55
epoch [21/50] batch [400/428] time 0.139 (0.139) data 0.000 (0.002) loss 1.9626 (1.6955) teacher_loss 0.9501 (0.7199) loss_zs_kd 2.7562 (3.1718) loss_oracle 1.1344 (1.0070) kd_loss 0.8906 (0.9441) acc 71.8750 (74.6875) lr 1.3681e-03 eta 0:28:51
epoch [21/50] batch [420/428] time 0.114 (0.138) data 0.000 (0.002) loss 1.9099 (1.6958) teacher_loss 0.9813 (0.7205) loss_zs_kd 2.8708 (3.1568) loss_oracle 0.9453 (1.0072) kd_loss 0.9118 (0.9434) acc 65.6250 (74.5982) lr 1.3681e-03 eta 0:28:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,716
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 26.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,418
* accuracy: 29.9%
* error: 70.1%
* macro_f1: 21.2%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [22/50] batch [20/428] time 0.072 (0.187) data 0.001 (0.038) loss 1.7507 (1.7326) teacher_loss 0.6910 (0.7760) loss_zs_kd 3.3511 (3.1053) loss_oracle 1.1131 (1.0068) kd_loss 1.0063 (0.9064) acc 75.0000 (73.4375) lr 1.3090e-03 eta 0:38:33
epoch [22/50] batch [40/428] time 0.179 (0.176) data 0.000 (0.019) loss 1.5344 (1.7161) teacher_loss 0.6406 (0.7560) loss_zs_kd 3.9305 (3.3101) loss_oracle 0.9438 (1.0063) kd_loss 0.8437 (0.9139) acc 68.7500 (73.4375) lr 1.3090e-03 eta 0:36:16
epoch [22/50] batch [60/428] time 0.140 (0.163) data 0.001 (0.013) loss 1.6879 (1.7296) teacher_loss 0.7642 (0.7669) loss_zs_kd 3.4325 (3.3306) loss_oracle 1.0049 (1.0060) kd_loss 0.8426 (0.9194) acc 81.2500 (73.2812) lr 1.3090e-03 eta 0:33:32
epoch [22/50] batch [80/428] time 0.139 (0.157) data 0.000 (0.010) loss 1.7375 (1.7251) teacher_loss 0.8510 (0.7652) loss_zs_kd 3.7262 (3.3454) loss_oracle 0.9141 (1.0032) kd_loss 0.8589 (0.9166) acc 65.6250 (73.2812) lr 1.3090e-03 eta 0:32:13
epoch [22/50] batch [100/428] time 0.120 (0.153) data 0.000 (0.008) loss 1.3933 (1.7110) teacher_loss 0.4617 (0.7519) loss_zs_kd 3.7000 (3.3354) loss_oracle 0.9582 (1.0032) kd_loss 0.9051 (0.9148) acc 81.2500 (73.8438) lr 1.3090e-03 eta 0:31:28
epoch [22/50] batch [120/428] time 0.139 (0.149) data 0.000 (0.007) loss 1.5392 (1.7249) teacher_loss 0.5812 (0.7676) loss_zs_kd 2.8869 (3.3178) loss_oracle 1.0170 (1.0020) kd_loss 0.8990 (0.9125) acc 84.3750 (73.5938) lr 1.3090e-03 eta 0:30:33
epoch [22/50] batch [140/428] time 0.137 (0.147) data 0.000 (0.006) loss 1.6159 (1.7147) teacher_loss 0.5543 (0.7577) loss_zs_kd 3.2692 (3.3059) loss_oracle 1.0801 (1.0006) kd_loss 1.0431 (0.9134) acc 90.6250 (74.0179) lr 1.3090e-03 eta 0:30:09
epoch [22/50] batch [160/428] time 0.127 (0.145) data 0.000 (0.005) loss 1.4292 (1.7070) teacher_loss 0.4808 (0.7512) loss_zs_kd 3.4126 (3.3202) loss_oracle 0.9726 (0.9987) kd_loss 0.9242 (0.9130) acc 87.5000 (74.1992) lr 1.3090e-03 eta 0:29:35
epoch [22/50] batch [180/428] time 0.112 (0.143) data 0.000 (0.004) loss 1.8206 (1.7003) teacher_loss 0.8338 (0.7443) loss_zs_kd 3.7828 (3.3409) loss_oracle 1.0150 (0.9991) kd_loss 0.9586 (0.9128) acc 71.8750 (74.4965) lr 1.3090e-03 eta 0:29:07
epoch [22/50] batch [200/428] time 0.137 (0.141) data 0.000 (0.004) loss 1.6162 (1.6958) teacher_loss 0.6411 (0.7392) loss_zs_kd 3.9106 (3.3637) loss_oracle 1.0522 (1.0020) kd_loss 0.8980 (0.9113) acc 71.8750 (74.6875) lr 1.3090e-03 eta 0:28:38
epoch [22/50] batch [220/428] time 0.137 (0.139) data 0.000 (0.004) loss 1.6462 (1.6904) teacher_loss 0.6492 (0.7282) loss_zs_kd 3.2518 (3.3858) loss_oracle 1.0556 (1.0089) kd_loss 0.9384 (0.9155) acc 78.1250 (74.9574) lr 1.3090e-03 eta 0:28:20
epoch [22/50] batch [240/428] time 0.139 (0.139) data 0.000 (0.003) loss 1.7154 (1.6860) teacher_loss 0.7154 (0.7205) loss_zs_kd 3.6483 (3.4054) loss_oracle 1.1107 (1.0136) kd_loss 0.8894 (0.9174) acc 65.6250 (75.1042) lr 1.3090e-03 eta 0:28:10
epoch [22/50] batch [260/428] time 0.136 (0.138) data 0.000 (0.003) loss 1.5772 (1.6791) teacher_loss 0.5769 (0.7103) loss_zs_kd 3.6858 (3.4189) loss_oracle 0.9842 (1.0163) kd_loss 1.0164 (0.9213) acc 75.0000 (75.3245) lr 1.3090e-03 eta 0:27:56
epoch [22/50] batch [280/428] time 0.149 (0.138) data 0.000 (0.003) loss 1.5684 (1.6721) teacher_loss 0.5292 (0.7011) loss_zs_kd 4.1557 (3.4533) loss_oracle 1.0760 (1.0181) kd_loss 1.0023 (0.9240) acc 75.0000 (75.5804) lr 1.3090e-03 eta 0:27:53
epoch [22/50] batch [300/428] time 0.130 (0.137) data 0.000 (0.003) loss 1.4639 (1.6615) teacher_loss 0.4383 (0.6906) loss_zs_kd 4.3464 (3.4904) loss_oracle 1.0697 (1.0168) kd_loss 0.9816 (0.9250) acc 84.3750 (75.8958) lr 1.3090e-03 eta 0:27:43
epoch [22/50] batch [320/428] time 0.070 (0.136) data 0.000 (0.003) loss 1.4992 (1.6510) teacher_loss 0.4416 (0.6788) loss_zs_kd 4.1698 (3.5416) loss_oracle 1.1433 (1.0177) kd_loss 0.9720 (0.9268) acc 84.3750 (76.2988) lr 1.3090e-03 eta 0:27:19
epoch [22/50] batch [340/428] time 0.156 (0.137) data 0.000 (0.002) loss 1.5860 (1.6432) teacher_loss 0.6082 (0.6702) loss_zs_kd 4.3519 (3.5902) loss_oracle 1.0190 (1.0181) kd_loss 0.9368 (0.9279) acc 84.3750 (76.5349) lr 1.3090e-03 eta 0:27:31
epoch [22/50] batch [360/428] time 0.197 (0.136) data 0.000 (0.002) loss 1.4533 (1.6379) teacher_loss 0.5692 (0.6640) loss_zs_kd 3.8322 (3.6168) loss_oracle 0.9185 (1.0186) kd_loss 0.8497 (0.9294) acc 75.0000 (76.6406) lr 1.3090e-03 eta 0:27:20
epoch [22/50] batch [380/428] time 0.068 (0.138) data 0.000 (0.002) loss 1.4723 (1.6322) teacher_loss 0.4328 (0.6568) loss_zs_kd 4.4337 (3.6520) loss_oracle 1.1015 (1.0200) kd_loss 0.9774 (0.9309) acc 87.5000 (76.7928) lr 1.3090e-03 eta 0:27:34
epoch [22/50] batch [400/428] time 0.136 (0.136) data 0.000 (0.002) loss 1.5466 (1.6294) teacher_loss 0.5997 (0.6529) loss_zs_kd 4.5813 (3.6833) loss_oracle 0.9823 (1.0205) kd_loss 0.9115 (0.9325) acc 71.8750 (76.8984) lr 1.3090e-03 eta 0:27:14
epoch [22/50] batch [420/428] time 0.089 (0.136) data 0.000 (0.002) loss 1.5590 (1.6254) teacher_loss 0.5475 (0.6472) loss_zs_kd 4.5614 (3.7141) loss_oracle 1.0414 (1.0225) kd_loss 0.9817 (0.9339) acc 81.2500 (77.1131) lr 1.3090e-03 eta 0:27:06
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,171
* accuracy: 54.0%
* error: 46.0%
* macro_f1: 33.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,919
* accuracy: 40.5%
* error: 59.5%
* macro_f1: 24.1%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [23/50] batch [20/428] time 0.138 (0.163) data 0.000 (0.026) loss 1.4338 (1.5497) teacher_loss 0.5194 (0.5821) loss_zs_kd 4.6631 (4.2765) loss_oracle 0.9478 (1.0056) kd_loss 0.8811 (0.9296) acc 78.1250 (79.8438) lr 1.2487e-03 eta 0:32:34
epoch [23/50] batch [40/428] time 0.147 (0.151) data 0.000 (0.013) loss 1.5179 (1.5312) teacher_loss 0.5601 (0.5498) loss_zs_kd 3.6140 (4.1650) loss_oracle 1.0303 (1.0186) kd_loss 0.8855 (0.9441) acc 81.2500 (80.3906) lr 1.2487e-03 eta 0:30:00
epoch [23/50] batch [60/428] time 0.150 (0.145) data 0.001 (0.009) loss 1.5734 (1.5351) teacher_loss 0.5390 (0.5535) loss_zs_kd 4.0701 (4.1509) loss_oracle 1.0872 (1.0248) kd_loss 0.9817 (0.9386) acc 78.1250 (80.6771) lr 1.2487e-03 eta 0:28:49
epoch [23/50] batch [80/428] time 0.102 (0.143) data 0.000 (0.007) loss 1.7794 (1.5505) teacher_loss 0.7412 (0.5639) loss_zs_kd 4.0854 (4.1807) loss_oracle 1.1410 (1.0332) kd_loss 0.9354 (0.9400) acc 68.7500 (79.8828) lr 1.2487e-03 eta 0:28:22
epoch [23/50] batch [100/428] time 0.171 (0.144) data 0.000 (0.005) loss 1.5383 (1.5579) teacher_loss 0.5738 (0.5718) loss_zs_kd 4.1149 (4.1978) loss_oracle 1.0167 (1.0363) kd_loss 0.9123 (0.9358) acc 84.3750 (79.8125) lr 1.2487e-03 eta 0:28:28
epoch [23/50] batch [120/428] time 0.174 (0.142) data 0.000 (0.005) loss 1.7303 (1.5591) teacher_loss 0.7220 (0.5759) loss_zs_kd 3.9938 (4.1914) loss_oracle 1.0800 (1.0328) kd_loss 0.9364 (0.9334) acc 71.8750 (79.1146) lr 1.2487e-03 eta 0:28:06
epoch [23/50] batch [140/428] time 0.071 (0.145) data 0.000 (0.004) loss 1.8318 (1.5647) teacher_loss 0.9192 (0.5814) loss_zs_kd 4.2743 (4.1905) loss_oracle 0.9475 (1.0336) kd_loss 0.8777 (0.9330) acc 62.5000 (79.0625) lr 1.2487e-03 eta 0:28:42
epoch [23/50] batch [160/428] time 0.137 (0.142) data 0.000 (0.004) loss 1.5330 (1.5677) teacher_loss 0.6000 (0.5853) loss_zs_kd 4.3280 (4.2069) loss_oracle 0.9872 (1.0340) kd_loss 0.8788 (0.9308) acc 78.1250 (78.7695) lr 1.2487e-03 eta 0:28:04
epoch [23/50] batch [180/428] time 0.151 (0.142) data 0.000 (0.003) loss 1.3070 (1.5644) teacher_loss 0.4489 (0.5817) loss_zs_kd 4.7746 (4.2282) loss_oracle 0.8533 (1.0343) kd_loss 0.8629 (0.9310) acc 84.3750 (78.8542) lr 1.2487e-03 eta 0:27:54
epoch [23/50] batch [200/428] time 0.136 (0.141) data 0.000 (0.003) loss 1.4580 (1.5615) teacher_loss 0.5362 (0.5812) loss_zs_kd 4.0262 (4.2422) loss_oracle 0.9869 (1.0313) kd_loss 0.8567 (0.9293) acc 75.0000 (78.5938) lr 1.2487e-03 eta 0:27:42
epoch [23/50] batch [220/428] time 0.137 (0.140) data 0.000 (0.003) loss 1.5571 (1.5657) teacher_loss 0.5985 (0.5851) loss_zs_kd 4.2154 (4.2286) loss_oracle 1.0119 (1.0322) kd_loss 0.9053 (0.9290) acc 78.1250 (78.4233) lr 1.2487e-03 eta 0:27:29
epoch [23/50] batch [240/428] time 0.127 (0.139) data 0.000 (0.002) loss 1.7293 (1.5615) teacher_loss 0.7616 (0.5815) loss_zs_kd 4.2824 (4.2286) loss_oracle 1.0413 (1.0319) kd_loss 0.8941 (0.9283) acc 71.8750 (78.4635) lr 1.2487e-03 eta 0:27:14
epoch [23/50] batch [260/428] time 0.150 (0.139) data 0.000 (0.002) loss 1.7243 (1.5622) teacher_loss 0.6865 (0.5822) loss_zs_kd 4.0303 (4.2334) loss_oracle 1.0763 (1.0322) kd_loss 0.9994 (0.9278) acc 68.7500 (78.2812) lr 1.2487e-03 eta 0:27:05
epoch [23/50] batch [280/428] time 0.133 (0.138) data 0.000 (0.002) loss 1.3951 (1.5617) teacher_loss 0.3223 (0.5819) loss_zs_kd 3.3769 (4.2179) loss_oracle 1.1725 (1.0323) kd_loss 0.9731 (0.9273) acc 90.6250 (78.3036) lr 1.2487e-03 eta 0:26:55
epoch [23/50] batch [300/428] time 0.132 (0.137) data 0.000 (0.002) loss 1.3979 (1.5598) teacher_loss 0.4728 (0.5820) loss_zs_kd 4.0661 (4.2012) loss_oracle 0.9561 (1.0295) kd_loss 0.8941 (0.9261) acc 84.3750 (78.2188) lr 1.2487e-03 eta 0:26:45
epoch [23/50] batch [320/428] time 0.088 (0.137) data 0.000 (0.002) loss 1.4267 (1.5616) teacher_loss 0.4323 (0.5855) loss_zs_kd 4.2670 (4.1905) loss_oracle 1.0887 (1.0285) kd_loss 0.9000 (0.9235) acc 87.5000 (78.0762) lr 1.2487e-03 eta 0:26:33
epoch [23/50] batch [340/428] time 0.149 (0.136) data 0.000 (0.002) loss 1.6842 (1.5622) teacher_loss 0.7327 (0.5859) loss_zs_kd 3.5957 (4.1703) loss_oracle 1.0373 (1.0301) kd_loss 0.8656 (0.9223) acc 75.0000 (77.9412) lr 1.2487e-03 eta 0:26:26
epoch [23/50] batch [360/428] time 0.137 (0.136) data 0.000 (0.002) loss 1.8822 (1.5623) teacher_loss 0.8379 (0.5859) loss_zs_kd 4.0496 (4.1565) loss_oracle 1.1034 (1.0315) kd_loss 0.9853 (0.9213) acc 68.7500 (78.0208) lr 1.2487e-03 eta 0:26:24
epoch [23/50] batch [380/428] time 0.137 (0.136) data 0.000 (0.002) loss 1.3582 (1.5586) teacher_loss 0.4103 (0.5835) loss_zs_kd 3.9476 (4.1436) loss_oracle 0.9564 (1.0300) kd_loss 0.9393 (0.9203) acc 84.3750 (78.1332) lr 1.2487e-03 eta 0:26:22
epoch [23/50] batch [400/428] time 0.139 (0.136) data 0.000 (0.002) loss 1.4778 (1.5582) teacher_loss 0.5049 (0.5833) loss_zs_kd 4.1908 (4.1461) loss_oracle 1.0168 (1.0297) kd_loss 0.9289 (0.9201) acc 87.5000 (78.1484) lr 1.2487e-03 eta 0:26:17
epoch [23/50] batch [420/428] time 0.180 (0.136) data 0.000 (0.001) loss 1.4677 (1.5582) teacher_loss 0.5288 (0.5837) loss_zs_kd 3.7524 (4.1425) loss_oracle 0.9634 (1.0286) kd_loss 0.9144 (0.9204) acc 84.3750 (78.1399) lr 1.2487e-03 eta 0:26:14
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,406
* accuracy: 40.9%
* error: 59.1%
* macro_f1: 25.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,904
* accuracy: 40.2%
* error: 59.8%
* macro_f1: 24.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [24/50] batch [20/428] time 0.089 (0.115) data 0.000 (0.026) loss 1.3666 (1.5666) teacher_loss 0.4117 (0.6015) loss_zs_kd 4.5179 (3.9012) loss_oracle 1.0111 (1.0040) kd_loss 0.8987 (0.9262) acc 84.3750 (76.5625) lr 1.1874e-03 eta 0:22:11
epoch [24/50] batch [40/428] time 0.091 (0.100) data 0.000 (0.013) loss 1.5994 (1.5310) teacher_loss 0.5921 (0.5674) loss_zs_kd 3.8616 (3.9715) loss_oracle 1.0401 (1.0040) kd_loss 0.9743 (0.9231) acc 78.1250 (78.1250) lr 1.1874e-03 eta 0:19:13
epoch [24/50] batch [60/428] time 0.086 (0.095) data 0.000 (0.009) loss 1.7707 (1.5232) teacher_loss 0.7834 (0.5599) loss_zs_kd 4.4367 (4.0879) loss_oracle 1.0492 (1.0037) kd_loss 0.9254 (0.9229) acc 62.5000 (78.2292) lr 1.1874e-03 eta 0:18:12
epoch [24/50] batch [80/428] time 0.088 (0.093) data 0.000 (0.007) loss 1.6878 (1.5157) teacher_loss 0.7821 (0.5527) loss_zs_kd 4.4142 (4.2251) loss_oracle 0.9210 (1.0015) kd_loss 0.8903 (0.9246) acc 62.5000 (78.8281) lr 1.1874e-03 eta 0:17:42
epoch [24/50] batch [100/428] time 0.073 (0.090) data 0.000 (0.006) loss 1.3197 (1.5148) teacher_loss 0.2876 (0.5479) loss_zs_kd 4.7060 (4.3219) loss_oracle 1.0475 (1.0047) kd_loss 1.0165 (0.9290) acc 90.6250 (78.8750) lr 1.1874e-03 eta 0:17:11
epoch [24/50] batch [120/428] time 0.077 (0.088) data 0.000 (0.005) loss 1.4446 (1.5185) teacher_loss 0.4722 (0.5492) loss_zs_kd 4.3726 (4.3608) loss_oracle 1.0088 (1.0088) kd_loss 0.9361 (0.9300) acc 84.3750 (78.4115) lr 1.1874e-03 eta 0:16:43
epoch [24/50] batch [140/428] time 0.077 (0.087) data 0.000 (0.004) loss 1.6799 (1.5209) teacher_loss 0.7187 (0.5524) loss_zs_kd 4.5622 (4.4141) loss_oracle 0.9876 (1.0074) kd_loss 0.9348 (0.9295) acc 68.7500 (78.3482) lr 1.1874e-03 eta 0:16:28
epoch [24/50] batch [160/428] time 0.077 (0.085) data 0.000 (0.004) loss 1.4035 (1.5206) teacher_loss 0.4226 (0.5524) loss_zs_kd 5.3053 (4.4694) loss_oracle 1.0491 (1.0071) kd_loss 0.9126 (0.9294) acc 78.1250 (78.3984) lr 1.1874e-03 eta 0:16:11
epoch [24/50] batch [180/428] time 0.139 (0.089) data 0.000 (0.003) loss 1.5930 (1.5235) teacher_loss 0.6074 (0.5559) loss_zs_kd 5.1119 (4.5247) loss_oracle 1.0334 (1.0072) kd_loss 0.9378 (0.9279) acc 81.2500 (78.2292) lr 1.1874e-03 eta 0:16:50
epoch [24/50] batch [200/428] time 0.142 (0.094) data 0.000 (0.003) loss 1.4761 (1.5269) teacher_loss 0.5125 (0.5587) loss_zs_kd 4.8468 (4.5428) loss_oracle 1.0091 (1.0087) kd_loss 0.9181 (0.9277) acc 81.2500 (78.0469) lr 1.1874e-03 eta 0:17:47
epoch [24/50] batch [220/428] time 0.135 (0.097) data 0.000 (0.003) loss 1.7850 (1.5329) teacher_loss 0.7845 (0.5645) loss_zs_kd 4.4006 (4.5737) loss_oracle 1.0476 (1.0083) kd_loss 0.9534 (0.9286) acc 62.5000 (77.7557) lr 1.1874e-03 eta 0:18:22
epoch [24/50] batch [240/428] time 0.131 (0.101) data 0.000 (0.002) loss 1.7201 (1.5397) teacher_loss 0.7723 (0.5707) loss_zs_kd 5.0153 (4.5949) loss_oracle 1.0183 (1.0095) kd_loss 0.8774 (0.9284) acc 78.1250 (77.5521) lr 1.1874e-03 eta 0:19:01
epoch [24/50] batch [260/428] time 0.139 (0.104) data 0.000 (0.002) loss 1.6024 (1.5381) teacher_loss 0.6684 (0.5694) loss_zs_kd 4.7995 (4.6085) loss_oracle 0.9430 (1.0092) kd_loss 0.9250 (0.9282) acc 71.8750 (77.5361) lr 1.1874e-03 eta 0:19:34
epoch [24/50] batch [280/428] time 0.121 (0.106) data 0.000 (0.002) loss 1.5487 (1.5400) teacher_loss 0.5314 (0.5705) loss_zs_kd 4.8441 (4.6117) loss_oracle 1.0498 (1.0097) kd_loss 0.9849 (0.9293) acc 75.0000 (77.6562) lr 1.1874e-03 eta 0:19:50
epoch [24/50] batch [300/428] time 0.137 (0.108) data 0.000 (0.002) loss 1.4275 (1.5389) teacher_loss 0.4992 (0.5696) loss_zs_kd 4.5514 (4.6048) loss_oracle 0.9520 (1.0093) kd_loss 0.9044 (0.9295) acc 81.2500 (77.6771) lr 1.1874e-03 eta 0:20:14
epoch [24/50] batch [320/428] time 0.132 (0.110) data 0.000 (0.002) loss 1.3409 (1.5392) teacher_loss 0.4067 (0.5697) loss_zs_kd 4.7682 (4.6007) loss_oracle 0.9564 (1.0091) kd_loss 0.9119 (0.9299) acc 87.5000 (77.8320) lr 1.1874e-03 eta 0:20:34
epoch [24/50] batch [340/428] time 0.152 (0.111) data 0.000 (0.002) loss 1.2584 (1.5372) teacher_loss 0.3216 (0.5673) loss_zs_kd 4.3509 (4.5984) loss_oracle 0.9802 (1.0092) kd_loss 0.8933 (0.9305) acc 93.7500 (77.9412) lr 1.1874e-03 eta 0:20:50
epoch [24/50] batch [360/428] time 0.137 (0.113) data 0.000 (0.002) loss 1.3500 (1.5390) teacher_loss 0.4347 (0.5690) loss_zs_kd 4.6000 (4.5900) loss_oracle 0.9739 (1.0091) kd_loss 0.8569 (0.9309) acc 84.3750 (77.9514) lr 1.1874e-03 eta 0:21:06
epoch [24/50] batch [380/428] time 0.131 (0.114) data 0.000 (0.002) loss 1.4953 (1.5359) teacher_loss 0.4845 (0.5669) loss_zs_kd 4.9967 (4.5911) loss_oracle 1.0399 (1.0077) kd_loss 0.9817 (0.9303) acc 75.0000 (78.0428) lr 1.1874e-03 eta 0:21:14
epoch [24/50] batch [400/428] time 0.122 (0.115) data 0.000 (0.002) loss 1.5022 (1.5358) teacher_loss 0.5776 (0.5679) loss_zs_kd 4.3544 (4.5871) loss_oracle 0.9819 (1.0070) kd_loss 0.8672 (0.9288) acc 71.8750 (77.9766) lr 1.1874e-03 eta 0:21:27
epoch [24/50] batch [420/428] time 0.104 (0.116) data 0.000 (0.002) loss 1.4613 (1.5351) teacher_loss 0.4701 (0.5670) loss_zs_kd 4.0654 (4.5666) loss_oracle 1.0168 (1.0071) kd_loss 0.9656 (0.9291) acc 81.2500 (78.0878) lr 1.1874e-03 eta 0:21:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,111
* accuracy: 52.9%
* error: 47.1%
* macro_f1: 33.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,994
* accuracy: 42.1%
* error: 57.9%
* macro_f1: 25.9%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [25/50] batch [20/428] time 0.080 (0.138) data 0.000 (0.026) loss 1.6585 (1.5697) teacher_loss 0.7156 (0.5829) loss_zs_kd 4.6297 (4.2048) loss_oracle 0.9850 (1.0285) kd_loss 0.9008 (0.9452) acc 75.0000 (77.9688) lr 1.1253e-03 eta 0:25:29
epoch [25/50] batch [40/428] time 0.105 (0.126) data 0.000 (0.013) loss 1.4814 (1.5420) teacher_loss 0.4726 (0.5603) loss_zs_kd 4.7558 (4.3344) loss_oracle 1.0399 (1.0237) kd_loss 0.9778 (0.9398) acc 84.3750 (79.2969) lr 1.1253e-03 eta 0:23:18
epoch [25/50] batch [60/428] time 0.143 (0.124) data 0.000 (0.009) loss 1.5939 (1.5518) teacher_loss 0.5946 (0.5747) loss_zs_kd 3.5936 (4.3503) loss_oracle 1.0477 (1.0165) kd_loss 0.9507 (0.9377) acc 68.7500 (78.5938) lr 1.1253e-03 eta 0:22:52
epoch [25/50] batch [80/428] time 0.091 (0.122) data 0.000 (0.007) loss 1.5694 (1.5477) teacher_loss 0.6365 (0.5737) loss_zs_kd 4.4347 (4.3761) loss_oracle 0.9768 (1.0137) kd_loss 0.8890 (0.9343) acc 78.1250 (78.3594) lr 1.1253e-03 eta 0:22:24
epoch [25/50] batch [100/428] time 0.136 (0.119) data 0.000 (0.006) loss 1.7798 (1.5544) teacher_loss 0.7063 (0.5728) loss_zs_kd 4.1002 (4.3728) loss_oracle 1.0708 (1.0214) kd_loss 1.0762 (0.9419) acc 75.0000 (78.2812) lr 1.1253e-03 eta 0:21:56
epoch [25/50] batch [120/428] time 0.111 (0.119) data 0.000 (0.005) loss 1.5182 (1.5454) teacher_loss 0.4632 (0.5663) loss_zs_kd 4.0919 (4.3289) loss_oracle 1.0479 (1.0162) kd_loss 1.0621 (0.9420) acc 75.0000 (78.2292) lr 1.1253e-03 eta 0:21:45
epoch [25/50] batch [140/428] time 0.094 (0.117) data 0.000 (0.004) loss 1.6787 (1.5427) teacher_loss 0.7137 (0.5621) loss_zs_kd 4.4054 (4.2886) loss_oracle 0.9465 (1.0156) kd_loss 0.9834 (0.9454) acc 68.7500 (78.5491) lr 1.1253e-03 eta 0:21:28
epoch [25/50] batch [160/428] time 0.107 (0.117) data 0.000 (0.004) loss 1.5235 (1.5349) teacher_loss 0.5177 (0.5553) loss_zs_kd 4.3391 (4.2999) loss_oracle 1.0075 (1.0135) kd_loss 1.0041 (0.9457) acc 78.1250 (78.8867) lr 1.1253e-03 eta 0:21:19
epoch [25/50] batch [180/428] time 0.089 (0.116) data 0.000 (0.003) loss 1.4969 (1.5314) teacher_loss 0.5733 (0.5532) loss_zs_kd 4.2376 (4.2996) loss_oracle 0.9257 (1.0112) kd_loss 0.9214 (0.9452) acc 71.8750 (79.0104) lr 1.1253e-03 eta 0:21:08
epoch [25/50] batch [200/428] time 0.080 (0.116) data 0.000 (0.003) loss 1.9113 (1.5351) teacher_loss 0.9758 (0.5576) loss_zs_kd 4.5435 (4.3043) loss_oracle 0.9410 (1.0100) kd_loss 0.9299 (0.9449) acc 65.6250 (78.7500) lr 1.1253e-03 eta 0:21:06
epoch [25/50] batch [220/428] time 0.097 (0.116) data 0.000 (0.003) loss 1.2286 (1.5324) teacher_loss 0.2897 (0.5558) loss_zs_kd 4.5515 (4.3110) loss_oracle 0.9549 (1.0088) kd_loss 0.9230 (0.9442) acc 90.6250 (78.8636) lr 1.1253e-03 eta 0:21:05
epoch [25/50] batch [240/428] time 0.081 (0.116) data 0.000 (0.002) loss 1.3279 (1.5294) teacher_loss 0.3755 (0.5531) loss_zs_kd 4.0466 (4.3146) loss_oracle 0.9591 (1.0075) kd_loss 0.9456 (0.9450) acc 81.2500 (78.9844) lr 1.1253e-03 eta 0:21:02
epoch [25/50] batch [260/428] time 0.092 (0.116) data 0.000 (0.002) loss 1.4369 (1.5262) teacher_loss 0.5054 (0.5506) loss_zs_kd 4.4383 (4.3313) loss_oracle 0.9564 (1.0056) kd_loss 0.9065 (0.9456) acc 87.5000 (79.1827) lr 1.1253e-03 eta 0:21:02
epoch [25/50] batch [280/428] time 0.114 (0.120) data 0.000 (0.002) loss 1.6104 (1.5265) teacher_loss 0.5273 (0.5512) loss_zs_kd 4.4101 (4.3554) loss_oracle 1.1363 (1.0047) kd_loss 1.0299 (0.9459) acc 78.1250 (79.1853) lr 1.1253e-03 eta 0:21:41
epoch [25/50] batch [300/428] time 0.202 (0.119) data 0.000 (0.002) loss 1.3881 (1.5238) teacher_loss 0.4144 (0.5499) loss_zs_kd 4.7097 (4.3754) loss_oracle 1.0183 (1.0029) kd_loss 0.9291 (0.9450) acc 90.6250 (79.2708) lr 1.1253e-03 eta 0:21:26
epoch [25/50] batch [320/428] time 0.066 (0.122) data 0.000 (0.002) loss 1.5288 (1.5236) teacher_loss 0.5751 (0.5509) loss_zs_kd 4.2658 (4.3922) loss_oracle 0.9564 (1.0008) kd_loss 0.9511 (0.9444) acc 75.0000 (79.1992) lr 1.1253e-03 eta 0:21:56
epoch [25/50] batch [340/428] time 0.117 (0.120) data 0.000 (0.002) loss 1.2793 (1.5217) teacher_loss 0.3274 (0.5497) loss_zs_kd 4.4606 (4.3942) loss_oracle 0.9483 (0.9996) kd_loss 0.9555 (0.9442) acc 81.2500 (79.3015) lr 1.1253e-03 eta 0:21:39
epoch [25/50] batch [360/428] time 0.110 (0.121) data 0.000 (0.002) loss 1.3723 (1.5215) teacher_loss 0.4114 (0.5506) loss_zs_kd 4.2940 (4.3945) loss_oracle 0.9564 (0.9980) kd_loss 0.9655 (0.9439) acc 87.5000 (79.2188) lr 1.1253e-03 eta 0:21:39
epoch [25/50] batch [380/428] time 0.137 (0.120) data 0.000 (0.002) loss 1.6846 (1.5231) teacher_loss 0.7430 (0.5516) loss_zs_kd 4.3852 (4.3992) loss_oracle 0.9555 (0.9982) kd_loss 0.9277 (0.9448) acc 75.0000 (79.2763) lr 1.1253e-03 eta 0:21:33
epoch [25/50] batch [400/428] time 0.118 (0.120) data 0.000 (0.002) loss 1.3772 (1.5208) teacher_loss 0.3799 (0.5499) loss_zs_kd 4.4370 (4.4021) loss_oracle 1.0178 (0.9972) kd_loss 0.9768 (0.9446) acc 90.6250 (79.3203) lr 1.1253e-03 eta 0:21:32
epoch [25/50] batch [420/428] time 0.070 (0.120) data 0.000 (0.002) loss 1.2876 (1.5179) teacher_loss 0.4100 (0.5483) loss_zs_kd 4.4508 (4.3946) loss_oracle 0.8934 (0.9956) kd_loss 0.8618 (0.9437) acc 81.2500 (79.3899) lr 1.1253e-03 eta 0:21:26
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,984
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 32.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,909
* accuracy: 40.3%
* error: 59.7%
* macro_f1: 24.9%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [26/50] batch [20/428] time 0.139 (0.158) data 0.000 (0.033) loss 1.5230 (1.5203) teacher_loss 0.6202 (0.5679) loss_zs_kd 4.7090 (4.5308) loss_oracle 0.9253 (0.9728) kd_loss 0.8803 (0.9320) acc 65.6250 (77.1875) lr 1.0628e-03 eta 0:28:05
epoch [26/50] batch [40/428] time 0.170 (0.142) data 0.000 (0.016) loss 1.3557 (1.5154) teacher_loss 0.3888 (0.5587) loss_zs_kd 4.7016 (4.5276) loss_oracle 0.9873 (0.9738) kd_loss 0.9465 (0.9397) acc 84.3750 (77.8125) lr 1.0628e-03 eta 0:25:09
epoch [26/50] batch [60/428] time 0.190 (0.139) data 0.001 (0.011) loss 1.5974 (1.5221) teacher_loss 0.6407 (0.5656) loss_zs_kd 4.6792 (4.5810) loss_oracle 0.9568 (0.9758) kd_loss 0.9568 (0.9372) acc 78.1250 (77.2917) lr 1.0628e-03 eta 0:24:43
epoch [26/50] batch [80/428] time 0.173 (0.147) data 0.000 (0.008) loss 1.4718 (1.5223) teacher_loss 0.4864 (0.5662) loss_zs_kd 5.0751 (4.6399) loss_oracle 0.9877 (0.9743) kd_loss 0.9831 (0.9380) acc 78.1250 (77.2266) lr 1.0628e-03 eta 0:26:04
epoch [26/50] batch [100/428] time 0.116 (0.140) data 0.000 (0.007) loss 1.2531 (1.5121) teacher_loss 0.3457 (0.5552) loss_zs_kd 4.6671 (4.6773) loss_oracle 0.9206 (0.9763) kd_loss 0.8943 (0.9374) acc 90.6250 (77.7812) lr 1.0628e-03 eta 0:24:41
epoch [26/50] batch [120/428] time 0.125 (0.136) data 0.000 (0.006) loss 1.5646 (1.5058) teacher_loss 0.6423 (0.5526) loss_zs_kd 4.6959 (4.7016) loss_oracle 0.9321 (0.9720) kd_loss 0.9126 (0.9345) acc 84.3750 (77.9948) lr 1.0628e-03 eta 0:23:56
epoch [26/50] batch [140/428] time 0.130 (0.135) data 0.000 (0.005) loss 1.5515 (1.4990) teacher_loss 0.5583 (0.5476) loss_zs_kd 4.5848 (4.6799) loss_oracle 1.0182 (0.9699) kd_loss 0.9681 (0.9329) acc 84.3750 (78.4598) lr 1.0628e-03 eta 0:23:44
epoch [26/50] batch [160/428] time 0.130 (0.134) data 0.000 (0.004) loss 1.3170 (1.4949) teacher_loss 0.4147 (0.5429) loss_zs_kd 4.4289 (4.6079) loss_oracle 0.9189 (0.9704) kd_loss 0.8857 (0.9335) acc 84.3750 (78.8281) lr 1.0628e-03 eta 0:23:31
epoch [26/50] batch [180/428] time 0.140 (0.134) data 0.000 (0.004) loss 1.6384 (1.4962) teacher_loss 0.6952 (0.5410) loss_zs_kd 3.9326 (4.5715) loss_oracle 0.9490 (0.9732) kd_loss 0.9374 (0.9373) acc 68.7500 (79.0278) lr 1.0628e-03 eta 0:23:30
epoch [26/50] batch [200/428] time 0.136 (0.133) data 0.000 (0.003) loss 1.6255 (1.5043) teacher_loss 0.5915 (0.5473) loss_zs_kd 4.6867 (4.5691) loss_oracle 1.0496 (0.9749) kd_loss 1.0184 (0.9392) acc 71.8750 (78.8906) lr 1.0628e-03 eta 0:23:17
epoch [26/50] batch [220/428] time 0.135 (0.133) data 0.000 (0.003) loss 1.5053 (1.5124) teacher_loss 0.5869 (0.5534) loss_zs_kd 4.9423 (4.5760) loss_oracle 0.9754 (0.9779) kd_loss 0.8614 (0.9401) acc 78.1250 (78.7500) lr 1.0628e-03 eta 0:23:17
epoch [26/50] batch [240/428] time 0.141 (0.134) data 0.000 (0.003) loss 1.4871 (1.5090) teacher_loss 0.5293 (0.5497) loss_zs_kd 4.8990 (4.5810) loss_oracle 0.9949 (0.9778) kd_loss 0.9207 (0.9408) acc 84.3750 (78.8932) lr 1.0628e-03 eta 0:23:17
epoch [26/50] batch [260/428] time 0.135 (0.134) data 0.000 (0.003) loss 1.7487 (1.5050) teacher_loss 0.8139 (0.5457) loss_zs_kd 4.4087 (4.5950) loss_oracle 0.9468 (0.9773) kd_loss 0.9228 (0.9412) acc 81.2500 (79.1226) lr 1.0628e-03 eta 0:23:16
epoch [26/50] batch [280/428] time 0.135 (0.134) data 0.000 (0.003) loss 1.4254 (1.5051) teacher_loss 0.5037 (0.5454) loss_zs_kd 4.9174 (4.6051) loss_oracle 0.9183 (0.9774) kd_loss 0.9251 (0.9418) acc 84.3750 (79.1518) lr 1.0628e-03 eta 0:23:11
epoch [26/50] batch [300/428] time 0.114 (0.134) data 0.000 (0.002) loss 1.3477 (1.5026) teacher_loss 0.4442 (0.5432) loss_zs_kd 4.9729 (4.6213) loss_oracle 0.9145 (0.9773) kd_loss 0.8924 (0.9415) acc 78.1250 (79.2396) lr 1.0628e-03 eta 0:23:10
epoch [26/50] batch [320/428] time 0.079 (0.132) data 0.000 (0.002) loss 1.2332 (1.4996) teacher_loss 0.2807 (0.5400) loss_zs_kd 5.2386 (4.6394) loss_oracle 0.9801 (0.9771) kd_loss 0.9248 (0.9421) acc 90.6250 (79.3750) lr 1.0628e-03 eta 0:22:54
epoch [26/50] batch [340/428] time 0.138 (0.133) data 0.000 (0.002) loss 1.5725 (1.5016) teacher_loss 0.5906 (0.5413) loss_zs_kd 5.5182 (4.6590) loss_oracle 0.9873 (0.9782) kd_loss 0.9764 (0.9423) acc 71.8750 (79.4118) lr 1.0628e-03 eta 0:22:53
epoch [26/50] batch [360/428] time 0.063 (0.131) data 0.000 (0.002) loss 1.5818 (1.5012) teacher_loss 0.6201 (0.5407) loss_zs_kd 4.9730 (4.6870) loss_oracle 0.9779 (0.9780) kd_loss 0.9455 (0.9429) acc 81.2500 (79.4184) lr 1.0628e-03 eta 0:22:35
epoch [26/50] batch [380/428] time 0.193 (0.133) data 0.000 (0.002) loss 1.4195 (1.5018) teacher_loss 0.4680 (0.5402) loss_zs_kd 5.4770 (4.7161) loss_oracle 0.9852 (0.9793) kd_loss 0.9177 (0.9438) acc 84.3750 (79.4984) lr 1.0628e-03 eta 0:22:52
epoch [26/50] batch [400/428] time 0.181 (0.132) data 0.000 (0.002) loss 1.3937 (1.5008) teacher_loss 0.4450 (0.5388) loss_zs_kd 5.4720 (4.7375) loss_oracle 0.9411 (0.9795) kd_loss 0.9562 (0.9445) acc 81.2500 (79.5312) lr 1.0628e-03 eta 0:22:43
epoch [26/50] batch [420/428] time 0.069 (0.134) data 0.000 (0.002) loss 1.3044 (1.4991) teacher_loss 0.4105 (0.5373) loss_zs_kd 5.2014 (4.7505) loss_oracle 0.8943 (0.9790) kd_loss 0.8935 (0.9445) acc 84.3750 (79.5908) lr 1.0628e-03 eta 0:22:53
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,319
* accuracy: 56.5%
* error: 43.5%
* macro_f1: 36.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,905
* accuracy: 40.2%
* error: 59.8%
* macro_f1: 26.4%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [27/50] batch [20/428] time 0.105 (0.151) data 0.000 (0.026) loss 1.3844 (1.5125) teacher_loss 0.3851 (0.5534) loss_zs_kd 5.3967 (5.0777) loss_oracle 1.0249 (0.9789) kd_loss 0.9737 (0.9395) acc 90.6250 (79.6875) lr 1.0000e-03 eta 0:25:48
epoch [27/50] batch [40/428] time 0.129 (0.142) data 0.000 (0.013) loss 1.7546 (1.5259) teacher_loss 0.7171 (0.5589) loss_zs_kd 4.4496 (5.0020) loss_oracle 1.0491 (0.9891) kd_loss 1.0260 (0.9449) acc 78.1250 (79.4531) lr 1.0000e-03 eta 0:24:10
epoch [27/50] batch [60/428] time 0.097 (0.135) data 0.000 (0.009) loss 1.4530 (1.5159) teacher_loss 0.5631 (0.5504) loss_zs_kd 4.6693 (4.9497) loss_oracle 0.8942 (0.9883) kd_loss 0.8856 (0.9429) acc 84.3750 (79.8438) lr 1.0000e-03 eta 0:22:56
epoch [27/50] batch [80/428] time 0.135 (0.132) data 0.000 (0.007) loss 1.5596 (1.5119) teacher_loss 0.6371 (0.5476) loss_zs_kd 4.4445 (4.8893) loss_oracle 0.9426 (0.9880) kd_loss 0.9024 (0.9405) acc 81.2500 (80.2734) lr 1.0000e-03 eta 0:22:21
epoch [27/50] batch [100/428] time 0.134 (0.130) data 0.000 (0.005) loss 1.3704 (1.5028) teacher_loss 0.4053 (0.5384) loss_zs_kd 5.0645 (4.8514) loss_oracle 0.9832 (0.9876) kd_loss 0.9472 (0.9411) acc 84.3750 (80.5312) lr 1.0000e-03 eta 0:22:00
epoch [27/50] batch [120/428] time 0.087 (0.130) data 0.001 (0.004) loss 1.6047 (1.4979) teacher_loss 0.6537 (0.5354) loss_zs_kd 4.7213 (4.8214) loss_oracle 0.9565 (0.9849) kd_loss 0.9456 (0.9400) acc 71.8750 (80.3906) lr 1.0000e-03 eta 0:21:59
epoch [27/50] batch [140/428] time 0.187 (0.133) data 0.000 (0.004) loss 1.5131 (1.4934) teacher_loss 0.5270 (0.5316) loss_zs_kd 4.6292 (4.8135) loss_oracle 1.0179 (0.9834) kd_loss 0.9543 (0.9402) acc 78.1250 (80.6920) lr 1.0000e-03 eta 0:22:27
epoch [27/50] batch [160/428] time 0.170 (0.134) data 0.000 (0.003) loss 1.4511 (1.4945) teacher_loss 0.3726 (0.5308) loss_zs_kd 4.4575 (4.7989) loss_oracle 1.1114 (0.9850) kd_loss 1.0455 (0.9425) acc 93.7500 (80.7617) lr 1.0000e-03 eta 0:22:37
epoch [27/50] batch [180/428] time 0.105 (0.136) data 0.000 (0.003) loss 1.4267 (1.4922) teacher_loss 0.3771 (0.5278) loss_zs_kd 4.7125 (4.7861) loss_oracle 1.0801 (0.9844) kd_loss 1.0191 (0.9444) acc 87.5000 (80.6597) lr 1.0000e-03 eta 0:22:54
epoch [27/50] batch [200/428] time 0.106 (0.132) data 0.000 (0.003) loss 1.3556 (1.4933) teacher_loss 0.4375 (0.5292) loss_zs_kd 4.5695 (4.7718) loss_oracle 0.9232 (0.9835) kd_loss 0.9131 (0.9445) acc 81.2500 (80.3750) lr 1.0000e-03 eta 0:22:07
epoch [27/50] batch [220/428] time 0.100 (0.128) data 0.000 (0.003) loss 1.3982 (1.4941) teacher_loss 0.3953 (0.5295) loss_zs_kd 4.7866 (4.7686) loss_oracle 1.0186 (0.9838) kd_loss 0.9873 (0.9455) acc 84.3750 (80.2699) lr 1.0000e-03 eta 0:21:30
epoch [27/50] batch [240/428] time 0.114 (0.125) data 0.000 (0.002) loss 1.4772 (1.4936) teacher_loss 0.5367 (0.5284) loss_zs_kd 4.7810 (4.7686) loss_oracle 0.9563 (0.9846) kd_loss 0.9245 (0.9459) acc 75.0000 (80.3776) lr 1.0000e-03 eta 0:20:57
epoch [27/50] batch [260/428] time 0.071 (0.123) data 0.000 (0.002) loss 1.4575 (1.4930) teacher_loss 0.5227 (0.5283) loss_zs_kd 4.9122 (4.7656) loss_oracle 0.9443 (0.9833) kd_loss 0.9254 (0.9460) acc 84.3750 (80.3245) lr 1.0000e-03 eta 0:20:31
epoch [27/50] batch [280/428] time 0.133 (0.121) data 0.000 (0.002) loss 1.6758 (1.4943) teacher_loss 0.7058 (0.5289) loss_zs_kd 4.6052 (4.7684) loss_oracle 0.9860 (0.9837) kd_loss 0.9539 (0.9471) acc 75.0000 (80.3013) lr 1.0000e-03 eta 0:20:12
epoch [27/50] batch [300/428] time 0.135 (0.122) data 0.000 (0.002) loss 1.4772 (1.4948) teacher_loss 0.4817 (0.5300) loss_zs_kd 5.1294 (4.7894) loss_oracle 1.0168 (0.9828) kd_loss 0.9743 (0.9468) acc 78.1250 (80.2188) lr 1.0000e-03 eta 0:20:20
epoch [27/50] batch [320/428] time 0.100 (0.122) data 0.000 (0.002) loss 1.5276 (1.4951) teacher_loss 0.4165 (0.5301) loss_zs_kd 5.4278 (4.8099) loss_oracle 1.1115 (0.9829) kd_loss 1.1107 (0.9472) acc 87.5000 (80.2344) lr 1.0000e-03 eta 0:20:17
epoch [27/50] batch [340/428] time 0.131 (0.123) data 0.000 (0.002) loss 1.4457 (1.4973) teacher_loss 0.4899 (0.5335) loss_zs_kd 5.3321 (4.8290) loss_oracle 0.9557 (0.9818) kd_loss 0.9558 (0.9458) acc 87.5000 (80.1379) lr 1.0000e-03 eta 0:20:20
epoch [27/50] batch [360/428] time 0.152 (0.123) data 0.000 (0.002) loss 1.3374 (1.4964) teacher_loss 0.4179 (0.5330) loss_zs_kd 5.0124 (4.8279) loss_oracle 0.9138 (0.9811) kd_loss 0.9252 (0.9457) acc 78.1250 (80.1823) lr 1.0000e-03 eta 0:20:23
epoch [27/50] batch [380/428] time 0.136 (0.124) data 0.000 (0.002) loss 1.3806 (1.4962) teacher_loss 0.4610 (0.5320) loss_zs_kd 5.1073 (4.8249) loss_oracle 0.9250 (0.9814) kd_loss 0.9143 (0.9470) acc 84.3750 (80.1562) lr 1.0000e-03 eta 0:20:24
epoch [27/50] batch [400/428] time 0.136 (0.124) data 0.000 (0.002) loss 1.6526 (1.4961) teacher_loss 0.6207 (0.5314) loss_zs_kd 4.8349 (4.8281) loss_oracle 1.0142 (0.9815) kd_loss 1.0496 (0.9479) acc 81.2500 (80.1797) lr 1.0000e-03 eta 0:20:24
epoch [27/50] batch [420/428] time 0.119 (0.123) data 0.000 (0.001) loss 1.5998 (1.4948) teacher_loss 0.6304 (0.5308) loss_zs_kd 4.7279 (4.8308) loss_oracle 0.9824 (0.9807) kd_loss 0.9565 (0.9473) acc 71.8750 (80.1935) lr 1.0000e-03 eta 0:20:16
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,223
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 37.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,942
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 25.2%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [28/50] batch [20/428] time 0.134 (0.155) data 0.000 (0.024) loss 1.7675 (1.4760) teacher_loss 0.8291 (0.5080) loss_zs_kd 4.6367 (4.9689) loss_oracle 0.9553 (0.9806) kd_loss 0.9214 (0.9554) acc 71.8750 (81.0938) lr 9.3721e-04 eta 0:25:20
epoch [28/50] batch [40/428] time 0.136 (0.143) data 0.000 (0.012) loss 1.6528 (1.5097) teacher_loss 0.7678 (0.5464) loss_zs_kd 4.9594 (4.8939) loss_oracle 0.9162 (0.9747) kd_loss 0.8540 (0.9519) acc 65.6250 (79.4531) lr 9.3721e-04 eta 0:23:20
epoch [28/50] batch [60/428] time 0.132 (0.137) data 0.000 (0.008) loss 1.4190 (1.5100) teacher_loss 0.4188 (0.5455) loss_zs_kd 4.8233 (4.8261) loss_oracle 1.0181 (0.9748) kd_loss 0.9822 (0.9541) acc 87.5000 (79.8958) lr 9.3721e-04 eta 0:22:24
epoch [28/50] batch [80/428] time 0.135 (0.136) data 0.000 (0.006) loss 1.5024 (1.5012) teacher_loss 0.5638 (0.5338) loss_zs_kd 4.8062 (4.7881) loss_oracle 0.9732 (0.9779) kd_loss 0.9040 (0.9569) acc 84.3750 (80.1172) lr 9.3721e-04 eta 0:22:11
epoch [28/50] batch [100/428] time 0.126 (0.133) data 0.000 (0.005) loss 1.5261 (1.5002) teacher_loss 0.5389 (0.5340) loss_zs_kd 4.5679 (4.7977) loss_oracle 0.9871 (0.9778) kd_loss 0.9873 (0.9547) acc 75.0000 (80.4375) lr 9.3721e-04 eta 0:21:34
epoch [28/50] batch [120/428] time 0.107 (0.129) data 0.000 (0.004) loss 1.7862 (1.5000) teacher_loss 0.8672 (0.5373) loss_zs_kd 4.5454 (4.7682) loss_oracle 0.9195 (0.9731) kd_loss 0.9183 (0.9523) acc 71.8750 (79.9219) lr 9.3721e-04 eta 0:20:57
epoch [28/50] batch [140/428] time 0.116 (0.128) data 0.000 (0.004) loss 1.4762 (1.4951) teacher_loss 0.4616 (0.5335) loss_zs_kd 4.8467 (4.7541) loss_oracle 1.0110 (0.9709) kd_loss 1.0182 (0.9523) acc 78.1250 (79.9554) lr 9.3721e-04 eta 0:20:37
epoch [28/50] batch [160/428] time 0.137 (0.126) data 0.000 (0.003) loss 1.4550 (1.5010) teacher_loss 0.5062 (0.5410) loss_zs_kd 4.3382 (4.7324) loss_oracle 0.9567 (0.9689) kd_loss 0.9408 (0.9511) acc 87.5000 (79.6094) lr 9.3721e-04 eta 0:20:23
epoch [28/50] batch [180/428] time 0.119 (0.126) data 0.000 (0.003) loss 1.5249 (1.4944) teacher_loss 0.5857 (0.5374) loss_zs_kd 4.7556 (4.7169) loss_oracle 0.9487 (0.9660) kd_loss 0.9297 (0.9480) acc 71.8750 (79.7049) lr 9.3721e-04 eta 0:20:16
epoch [28/50] batch [200/428] time 0.140 (0.127) data 0.000 (0.003) loss 1.4498 (1.4924) teacher_loss 0.5501 (0.5361) loss_zs_kd 4.7673 (4.7223) loss_oracle 0.8894 (0.9652) kd_loss 0.9098 (0.9476) acc 84.3750 (79.7344) lr 9.3721e-04 eta 0:20:20
epoch [28/50] batch [220/428] time 0.136 (0.127) data 0.000 (0.002) loss 1.6752 (1.4981) teacher_loss 0.7550 (0.5412) loss_zs_kd 4.8766 (4.7173) loss_oracle 0.9221 (0.9661) kd_loss 0.9184 (0.9478) acc 71.8750 (79.5881) lr 9.3721e-04 eta 0:20:20
epoch [28/50] batch [240/428] time 0.129 (0.127) data 0.000 (0.002) loss 1.3857 (1.4915) teacher_loss 0.4699 (0.5354) loss_zs_kd 5.0183 (4.7398) loss_oracle 0.9557 (0.9654) kd_loss 0.8759 (0.9467) acc 84.3750 (79.8177) lr 9.3721e-04 eta 0:20:18
epoch [28/50] batch [260/428] time 0.135 (0.127) data 0.000 (0.002) loss 1.5031 (1.4838) teacher_loss 0.6097 (0.5292) loss_zs_kd 4.8562 (4.7666) loss_oracle 0.8946 (0.9645) kd_loss 0.8922 (0.9447) acc 78.1250 (79.9880) lr 9.3721e-04 eta 0:20:15
epoch [28/50] batch [280/428] time 0.156 (0.126) data 0.000 (0.002) loss 1.7261 (1.4806) teacher_loss 0.7053 (0.5251) loss_zs_kd 4.6022 (4.7829) loss_oracle 1.0788 (0.9660) kd_loss 0.9627 (0.9449) acc 71.8750 (80.1897) lr 9.3721e-04 eta 0:20:06
epoch [28/50] batch [300/428] time 0.067 (0.128) data 0.000 (0.002) loss 1.3966 (1.4784) teacher_loss 0.4937 (0.5249) loss_zs_kd 4.9087 (4.8005) loss_oracle 0.9251 (0.9639) kd_loss 0.8807 (0.9431) acc 84.3750 (80.2500) lr 9.3721e-04 eta 0:20:20
epoch [28/50] batch [320/428] time 0.152 (0.128) data 0.000 (0.002) loss 1.4953 (1.4801) teacher_loss 0.5395 (0.5263) loss_zs_kd 4.7522 (4.8001) loss_oracle 0.9808 (0.9644) kd_loss 0.9307 (0.9433) acc 84.3750 (80.2734) lr 9.3721e-04 eta 0:20:17
epoch [28/50] batch [340/428] time 0.088 (0.129) data 0.000 (0.002) loss 1.5707 (1.4829) teacher_loss 0.6347 (0.5287) loss_zs_kd 4.9104 (4.7934) loss_oracle 0.9562 (0.9653) kd_loss 0.9157 (0.9431) acc 71.8750 (80.1746) lr 9.3721e-04 eta 0:20:23
epoch [28/50] batch [360/428] time 0.150 (0.129) data 0.000 (0.002) loss 1.2064 (1.4820) teacher_loss 0.3154 (0.5286) loss_zs_kd 4.3597 (4.7820) loss_oracle 0.8941 (0.9644) kd_loss 0.8879 (0.9425) acc 87.5000 (80.1823) lr 9.3721e-04 eta 0:20:19
epoch [28/50] batch [380/428] time 0.135 (0.129) data 0.000 (0.001) loss 1.4011 (1.4824) teacher_loss 0.3708 (0.5288) loss_zs_kd 4.4691 (4.7620) loss_oracle 1.0317 (0.9646) kd_loss 1.0290 (0.9427) acc 84.3750 (80.1562) lr 9.3721e-04 eta 0:20:17
epoch [28/50] batch [400/428] time 0.138 (0.129) data 0.000 (0.001) loss 1.9415 (1.4844) teacher_loss 0.9307 (0.5317) loss_zs_kd 4.2607 (4.7469) loss_oracle 1.0027 (0.9635) kd_loss 1.0188 (0.9418) acc 71.8750 (80.0938) lr 9.3721e-04 eta 0:20:18
epoch [28/50] batch [420/428] time 0.131 (0.129) data 0.000 (0.001) loss 1.3585 (1.4849) teacher_loss 0.4919 (0.5328) loss_zs_kd 4.1122 (4.7265) loss_oracle 0.8650 (0.9631) kd_loss 0.8682 (0.9412) acc 84.3750 (80.0372) lr 9.3721e-04 eta 0:20:18
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,805
* accuracy: 47.7%
* error: 52.3%
* macro_f1: 34.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,303
* accuracy: 48.6%
* error: 51.4%
* macro_f1: 23.3%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [29/50] batch [20/428] time 0.151 (0.177) data 0.000 (0.038) loss 1.4473 (1.4737) teacher_loss 0.5209 (0.5365) loss_zs_kd 3.9852 (3.9817) loss_oracle 0.9560 (0.9484) kd_loss 0.8969 (0.9259) acc 81.2500 (79.2188) lr 8.7467e-04 eta 0:27:45
epoch [29/50] batch [40/428] time 0.185 (0.162) data 0.000 (0.019) loss 1.3902 (1.4858) teacher_loss 0.4071 (0.5436) loss_zs_kd 3.3714 (3.9012) loss_oracle 0.9852 (0.9530) kd_loss 0.9809 (0.9316) acc 78.1250 (78.6719) lr 8.7467e-04 eta 0:25:16
epoch [29/50] batch [60/428] time 0.200 (0.158) data 0.001 (0.013) loss 1.5475 (1.5043) teacher_loss 0.6238 (0.5744) loss_zs_kd 3.0730 (3.7625) loss_oracle 0.9755 (0.9469) kd_loss 0.8720 (0.9130) acc 81.2500 (78.5417) lr 8.7467e-04 eta 0:24:42
epoch [29/50] batch [80/428] time 0.079 (0.165) data 0.000 (0.010) loss 1.5654 (1.5498) teacher_loss 0.6737 (0.6287) loss_zs_kd 3.3971 (3.6188) loss_oracle 0.9029 (0.9461) kd_loss 0.8805 (0.8961) acc 75.0000 (76.9922) lr 8.7467e-04 eta 0:25:37
epoch [29/50] batch [100/428] time 0.142 (0.157) data 0.000 (0.008) loss 1.7300 (1.5907) teacher_loss 0.8284 (0.6765) loss_zs_kd 3.2074 (3.5563) loss_oracle 0.9798 (0.9449) kd_loss 0.8234 (0.8835) acc 65.6250 (75.9062) lr 8.7467e-04 eta 0:24:18
epoch [29/50] batch [120/428] time 0.143 (0.153) data 0.000 (0.007) loss 1.7688 (1.6305) teacher_loss 0.9162 (0.7220) loss_zs_kd 3.8570 (3.5497) loss_oracle 0.8531 (0.9403) kd_loss 0.8521 (0.8767) acc 62.5000 (74.1927) lr 8.7467e-04 eta 0:23:46
epoch [29/50] batch [140/428] time 0.138 (0.151) data 0.000 (0.006) loss 1.6095 (1.6542) teacher_loss 0.6963 (0.7461) loss_zs_kd 3.6295 (3.5649) loss_oracle 0.9469 (0.9419) kd_loss 0.8794 (0.8743) acc 78.1250 (73.4152) lr 8.7467e-04 eta 0:23:20
epoch [29/50] batch [160/428] time 0.136 (0.149) data 0.000 (0.005) loss 1.7910 (1.6743) teacher_loss 0.9507 (0.7675) loss_zs_kd 4.0866 (3.5976) loss_oracle 0.8255 (0.9412) kd_loss 0.8551 (0.8723) acc 68.7500 (72.8516) lr 8.7467e-04 eta 0:23:00
epoch [29/50] batch [180/428] time 0.133 (0.148) data 0.000 (0.005) loss 1.3716 (1.6843) teacher_loss 0.4874 (0.7783) loss_zs_kd 4.2614 (3.6259) loss_oracle 0.9112 (0.9416) kd_loss 0.8573 (0.8705) acc 84.3750 (72.5000) lr 8.7467e-04 eta 0:22:45
epoch [29/50] batch [200/428] time 0.136 (0.147) data 0.000 (0.004) loss 1.7208 (1.6936) teacher_loss 0.8313 (0.7884) loss_zs_kd 3.9528 (3.6521) loss_oracle 0.9208 (0.9415) kd_loss 0.8582 (0.8688) acc 75.0000 (72.0625) lr 8.7467e-04 eta 0:22:31
epoch [29/50] batch [220/428] time 0.138 (0.146) data 0.000 (0.004) loss 1.7993 (1.7009) teacher_loss 0.8816 (0.7960) loss_zs_kd 4.2773 (3.6722) loss_oracle 0.9499 (0.9421) kd_loss 0.8856 (0.8677) acc 59.3750 (71.6477) lr 8.7467e-04 eta 0:22:19
epoch [29/50] batch [240/428] time 0.134 (0.145) data 0.000 (0.003) loss 1.8475 (1.7040) teacher_loss 0.9611 (0.8002) loss_zs_kd 4.2309 (3.6941) loss_oracle 0.9142 (0.9410) kd_loss 0.8586 (0.8667) acc 62.5000 (71.3151) lr 8.7467e-04 eta 0:22:10
epoch [29/50] batch [260/428] time 0.139 (0.144) data 0.000 (0.003) loss 1.7800 (1.7087) teacher_loss 0.8256 (0.8053) loss_zs_kd 3.9563 (3.7145) loss_oracle 0.9957 (0.9406) kd_loss 0.9131 (0.8663) acc 68.7500 (71.1178) lr 8.7467e-04 eta 0:22:01
epoch [29/50] batch [280/428] time 0.131 (0.144) data 0.000 (0.003) loss 2.0024 (1.7158) teacher_loss 1.1269 (0.8124) loss_zs_kd 3.9736 (3.7303) loss_oracle 0.9037 (0.9410) kd_loss 0.8472 (0.8657) acc 68.7500 (70.9598) lr 8.7467e-04 eta 0:21:55
epoch [29/50] batch [300/428] time 0.138 (0.143) data 0.000 (0.003) loss 1.7408 (1.7172) teacher_loss 0.8677 (0.8152) loss_zs_kd 4.3175 (3.7484) loss_oracle 0.9134 (0.9393) kd_loss 0.8327 (0.8648) acc 65.6250 (70.9167) lr 8.7467e-04 eta 0:21:47
epoch [29/50] batch [320/428] time 0.137 (0.143) data 0.000 (0.003) loss 1.7832 (1.7219) teacher_loss 0.9056 (0.8207) loss_zs_kd 4.0345 (3.7617) loss_oracle 0.8972 (0.9381) kd_loss 0.8581 (0.8643) acc 78.1250 (70.7910) lr 8.7467e-04 eta 0:21:41
epoch [29/50] batch [340/428] time 0.193 (0.142) data 0.000 (0.003) loss 1.6367 (1.7239) teacher_loss 0.7307 (0.8232) loss_zs_kd 4.4973 (3.7744) loss_oracle 0.9296 (0.9373) kd_loss 0.8825 (0.8640) acc 78.1250 (70.7445) lr 8.7467e-04 eta 0:21:26
epoch [29/50] batch [360/428] time 0.069 (0.143) data 0.000 (0.002) loss 1.6600 (1.7262) teacher_loss 0.7668 (0.8265) loss_zs_kd 3.9123 (3.7903) loss_oracle 0.9289 (0.9360) kd_loss 0.8575 (0.8635) acc 75.0000 (70.6424) lr 8.7467e-04 eta 0:21:33
epoch [29/50] batch [380/428] time 0.195 (0.144) data 0.000 (0.002) loss 1.9681 (1.7276) teacher_loss 1.1068 (0.8286) loss_zs_kd 3.9175 (3.8033) loss_oracle 0.8642 (0.9349) kd_loss 0.8584 (0.8631) acc 62.5000 (70.5839) lr 8.7467e-04 eta 0:21:43
epoch [29/50] batch [400/428] time 0.092 (0.142) data 0.000 (0.002) loss 1.5737 (1.7292) teacher_loss 0.6960 (0.8306) loss_zs_kd 4.2972 (3.8181) loss_oracle 0.8936 (0.9343) kd_loss 0.8620 (0.8628) acc 81.2500 (70.5547) lr 8.7467e-04 eta 0:21:22
epoch [29/50] batch [420/428] time 0.113 (0.141) data 0.000 (0.002) loss 1.4902 (1.7298) teacher_loss 0.5971 (0.8313) loss_zs_kd 4.3022 (3.8317) loss_oracle 0.9245 (0.9345) kd_loss 0.8617 (0.8624) acc 78.1250 (70.5134) lr 8.7467e-04 eta 0:21:05
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,075
* accuracy: 35.3%
* error: 64.7%
* macro_f1: 30.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,442
* accuracy: 30.4%
* error: 69.6%
* macro_f1: 16.5%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [30/50] batch [20/428] time 0.142 (0.167) data 0.000 (0.026) loss 1.6067 (1.7320) teacher_loss 0.7059 (0.8414) loss_zs_kd 3.9461 (4.1678) loss_oracle 0.9098 (0.9115) kd_loss 0.8917 (0.8697) acc 71.8750 (69.5312) lr 8.1262e-04 eta 0:24:55
epoch [30/50] batch [40/428] time 0.137 (0.152) data 0.000 (0.013) loss 1.8447 (1.7526) teacher_loss 0.9812 (0.8610) loss_zs_kd 4.2577 (4.1376) loss_oracle 0.8650 (0.9184) kd_loss 0.8619 (0.8648) acc 68.7500 (69.6094) lr 8.1262e-04 eta 0:22:40
epoch [30/50] batch [60/428] time 0.132 (0.147) data 0.000 (0.009) loss 1.8382 (1.7519) teacher_loss 0.9302 (0.8611) loss_zs_kd 4.1034 (4.1081) loss_oracle 0.9546 (0.9196) kd_loss 0.8614 (0.8620) acc 56.2500 (69.3750) lr 8.1262e-04 eta 0:21:52
epoch [30/50] batch [80/428] time 0.134 (0.144) data 0.000 (0.007) loss 1.4341 (1.7484) teacher_loss 0.5690 (0.8604) loss_zs_kd 4.5901 (4.1318) loss_oracle 0.8683 (0.9158) kd_loss 0.8619 (0.8601) acc 78.1250 (69.4531) lr 8.1262e-04 eta 0:21:24
epoch [30/50] batch [100/428] time 0.086 (0.142) data 0.000 (0.005) loss 1.4640 (1.7600) teacher_loss 0.5820 (0.8718) loss_zs_kd 4.6787 (4.1492) loss_oracle 0.9045 (0.9174) kd_loss 0.8594 (0.8590) acc 75.0000 (68.5625) lr 8.1262e-04 eta 0:20:58
epoch [30/50] batch [120/428] time 0.189 (0.144) data 0.000 (0.005) loss 1.4214 (1.7625) teacher_loss 0.5213 (0.8725) loss_zs_kd 4.2745 (4.1377) loss_oracle 0.9461 (0.9198) kd_loss 0.8540 (0.8604) acc 87.5000 (68.4635) lr 8.1262e-04 eta 0:21:16
epoch [30/50] batch [140/428] time 0.195 (0.142) data 0.000 (0.004) loss 1.6662 (1.7536) teacher_loss 0.7596 (0.8644) loss_zs_kd 3.9215 (4.1354) loss_oracle 0.9844 (0.9192) kd_loss 0.8289 (0.8592) acc 75.0000 (68.9286) lr 8.1262e-04 eta 0:20:55
epoch [30/50] batch [160/428] time 0.070 (0.145) data 0.000 (0.003) loss 1.9025 (1.7520) teacher_loss 1.0068 (0.8630) loss_zs_kd 3.7473 (4.1166) loss_oracle 0.9154 (0.9188) kd_loss 0.8760 (0.8592) acc 62.5000 (68.9062) lr 8.1262e-04 eta 0:21:20
epoch [30/50] batch [180/428] time 0.137 (0.142) data 0.000 (0.003) loss 1.6512 (1.7492) teacher_loss 0.7869 (0.8596) loss_zs_kd 3.5516 (4.0893) loss_oracle 0.8671 (0.9193) kd_loss 0.8615 (0.8597) acc 68.7500 (69.0451) lr 8.1262e-04 eta 0:20:50
epoch [30/50] batch [200/428] time 0.156 (0.142) data 0.000 (0.003) loss 1.9409 (1.7484) teacher_loss 1.1011 (0.8602) loss_zs_kd 3.4777 (4.0347) loss_oracle 0.8493 (0.9166) kd_loss 0.8304 (0.8598) acc 56.2500 (68.9531) lr 8.1262e-04 eta 0:20:47
epoch [30/50] batch [220/428] time 0.138 (0.141) data 0.000 (0.003) loss 1.5586 (1.7417) teacher_loss 0.6892 (0.8546) loss_zs_kd 3.5834 (3.9705) loss_oracle 0.8801 (0.9144) kd_loss 0.8586 (0.8596) acc 75.0000 (69.1193) lr 8.1262e-04 eta 0:20:34
epoch [30/50] batch [240/428] time 0.137 (0.141) data 0.000 (0.002) loss 1.6759 (1.7424) teacher_loss 0.8272 (0.8575) loss_zs_kd 3.7047 (3.9234) loss_oracle 0.8434 (0.9104) kd_loss 0.8540 (0.8595) acc 71.8750 (69.0365) lr 8.1262e-04 eta 0:20:29
epoch [30/50] batch [260/428] time 0.138 (0.140) data 0.000 (0.002) loss 1.4899 (1.7327) teacher_loss 0.6423 (0.8495) loss_zs_kd 3.6017 (3.9050) loss_oracle 0.8664 (0.9071) kd_loss 0.8289 (0.8593) acc 71.8750 (69.3269) lr 8.1262e-04 eta 0:20:22
epoch [30/50] batch [280/428] time 0.135 (0.139) data 0.000 (0.002) loss 1.6309 (1.7254) teacher_loss 0.7068 (0.8428) loss_zs_kd 3.8946 (3.9012) loss_oracle 0.9592 (0.9046) kd_loss 0.8890 (0.8605) acc 71.8750 (69.4866) lr 8.1262e-04 eta 0:20:14
epoch [30/50] batch [300/428] time 0.136 (0.139) data 0.000 (0.002) loss 1.5544 (1.7218) teacher_loss 0.7237 (0.8401) loss_zs_kd 3.8205 (3.9156) loss_oracle 0.8220 (0.9019) kd_loss 0.8394 (0.8615) acc 71.8750 (69.6667) lr 8.1262e-04 eta 0:20:07
epoch [30/50] batch [320/428] time 0.136 (0.139) data 0.000 (0.002) loss 1.5778 (1.7229) teacher_loss 0.6833 (0.8409) loss_zs_kd 4.3965 (3.9290) loss_oracle 0.8876 (0.9008) kd_loss 0.9015 (0.8631) acc 84.3750 (69.8145) lr 8.1262e-04 eta 0:20:01
epoch [30/50] batch [340/428] time 0.142 (0.139) data 0.000 (0.002) loss 1.6251 (1.7186) teacher_loss 0.7557 (0.8359) loss_zs_kd 4.2297 (3.9419) loss_oracle 0.8999 (0.9007) kd_loss 0.8389 (0.8647) acc 78.1250 (70.0551) lr 8.1262e-04 eta 0:19:58
epoch [30/50] batch [360/428] time 0.141 (0.138) data 0.000 (0.002) loss 1.6043 (1.7196) teacher_loss 0.7621 (0.8367) loss_zs_kd 3.9042 (3.9563) loss_oracle 0.8306 (0.8995) kd_loss 0.8537 (0.8663) acc 75.0000 (70.0955) lr 8.1262e-04 eta 0:19:54
epoch [30/50] batch [380/428] time 0.134 (0.138) data 0.000 (0.002) loss 1.6168 (1.7163) teacher_loss 0.6971 (0.8325) loss_zs_kd 4.6244 (3.9751) loss_oracle 0.9205 (0.8995) kd_loss 0.9189 (0.8680) acc 75.0000 (70.3043) lr 8.1262e-04 eta 0:19:51
epoch [30/50] batch [400/428] time 0.137 (0.138) data 0.000 (0.002) loss 1.5660 (1.7129) teacher_loss 0.6489 (0.8285) loss_zs_kd 4.3379 (3.9916) loss_oracle 0.8843 (0.8988) kd_loss 0.9498 (0.8699) acc 68.7500 (70.3594) lr 8.1262e-04 eta 0:19:45
epoch [30/50] batch [420/428] time 0.093 (0.138) data 0.000 (0.001) loss 1.7873 (1.7118) teacher_loss 0.8753 (0.8266) loss_zs_kd 3.9144 (4.0122) loss_oracle 0.9092 (0.8985) kd_loss 0.9147 (0.8719) acc 68.7500 (70.4018) lr 8.1262e-04 eta 0:19:40
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,764
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 38.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,137
* accuracy: 45.1%
* error: 54.9%
* macro_f1: 23.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [31/50] batch [20/428] time 0.142 (0.155) data 0.000 (0.028) loss 1.6987 (1.6567) teacher_loss 0.7367 (0.7412) loss_zs_kd 4.7090 (4.4587) loss_oracle 0.9146 (0.8917) kd_loss 1.0095 (0.9393) acc 78.1250 (73.7500) lr 7.5131e-04 eta 0:21:59
epoch [31/50] batch [40/428] time 0.149 (0.147) data 0.000 (0.014) loss 1.6290 (1.6440) teacher_loss 0.6404 (0.7124) loss_zs_kd 3.8951 (4.4223) loss_oracle 0.9226 (0.9050) kd_loss 1.0546 (0.9583) acc 78.1250 (75.2344) lr 7.5131e-04 eta 0:20:56
epoch [31/50] batch [60/428] time 0.132 (0.145) data 0.000 (0.010) loss 1.4909 (1.6371) teacher_loss 0.5162 (0.6960) loss_zs_kd 4.4037 (4.4048) loss_oracle 0.9299 (0.9077) kd_loss 1.0195 (0.9743) acc 81.2500 (75.2083) lr 7.5131e-04 eta 0:20:32
epoch [31/50] batch [80/428] time 0.138 (0.144) data 0.000 (0.007) loss 1.5549 (1.6549) teacher_loss 0.5893 (0.7110) loss_zs_kd 4.2353 (4.3937) loss_oracle 0.9535 (0.9084) kd_loss 0.9777 (0.9795) acc 78.1250 (74.4141) lr 7.5131e-04 eta 0:20:20
epoch [31/50] batch [100/428] time 0.136 (0.141) data 0.000 (0.006) loss 1.7178 (1.6575) teacher_loss 0.7581 (0.7102) loss_zs_kd 4.4814 (4.4028) loss_oracle 0.9029 (0.9073) kd_loss 1.0166 (0.9873) acc 71.8750 (74.0625) lr 7.5131e-04 eta 0:19:50
epoch [31/50] batch [120/428] time 0.126 (0.137) data 0.000 (0.005) loss 1.3835 (1.6448) teacher_loss 0.4070 (0.6954) loss_zs_kd 4.5180 (4.4061) loss_oracle 0.8803 (0.9064) kd_loss 1.0728 (0.9924) acc 81.2500 (74.6354) lr 7.5131e-04 eta 0:19:15
epoch [31/50] batch [140/428] time 0.084 (0.134) data 0.000 (0.004) loss 1.6233 (1.6428) teacher_loss 0.7086 (0.6920) loss_zs_kd 4.1300 (4.4282) loss_oracle 0.8388 (0.9071) kd_loss 0.9907 (0.9946) acc 71.8750 (74.6875) lr 7.5131e-04 eta 0:18:44
epoch [31/50] batch [160/428] time 0.137 (0.133) data 0.000 (0.004) loss 1.5429 (1.6364) teacher_loss 0.6334 (0.6815) loss_zs_kd 4.5831 (4.4352) loss_oracle 0.8794 (0.9095) kd_loss 0.9396 (1.0003) acc 84.3750 (75.1758) lr 7.5131e-04 eta 0:18:35
epoch [31/50] batch [180/428] time 0.134 (0.131) data 0.000 (0.003) loss 1.5878 (1.6333) teacher_loss 0.6210 (0.6783) loss_zs_kd 4.6623 (4.4426) loss_oracle 0.9369 (0.9099) kd_loss 0.9966 (1.0001) acc 75.0000 (75.2778) lr 7.5131e-04 eta 0:18:17
epoch [31/50] batch [200/428] time 0.191 (0.130) data 0.000 (0.003) loss 1.7800 (1.6384) teacher_loss 0.7779 (0.6819) loss_zs_kd 4.3674 (4.4424) loss_oracle 0.9686 (0.9111) kd_loss 1.0357 (1.0020) acc 65.6250 (75.1562) lr 7.5131e-04 eta 0:18:08
epoch [31/50] batch [220/428] time 0.075 (0.132) data 0.000 (0.003) loss 1.8180 (1.6329) teacher_loss 0.9131 (0.6760) loss_zs_kd 4.5647 (4.4462) loss_oracle 0.8847 (0.9117) kd_loss 0.9251 (1.0020) acc 65.6250 (75.5114) lr 7.5131e-04 eta 0:18:23
epoch [31/50] batch [240/428] time 0.190 (0.136) data 0.000 (0.003) loss 1.5869 (1.6325) teacher_loss 0.6636 (0.6725) loss_zs_kd 4.5110 (4.4463) loss_oracle 0.8578 (0.9137) kd_loss 0.9889 (1.0063) acc 75.0000 (75.4688) lr 7.5131e-04 eta 0:18:49
epoch [31/50] batch [260/428] time 0.127 (0.135) data 0.000 (0.002) loss 1.6944 (1.6348) teacher_loss 0.7686 (0.6738) loss_zs_kd 4.1704 (4.4482) loss_oracle 0.8886 (0.9146) kd_loss 0.9629 (1.0074) acc 71.8750 (75.5889) lr 7.5131e-04 eta 0:18:39
epoch [31/50] batch [280/428] time 0.129 (0.134) data 0.000 (0.002) loss 1.7485 (1.6364) teacher_loss 0.7212 (0.6736) loss_zs_kd 4.5293 (4.4474) loss_oracle 0.9927 (0.9167) kd_loss 1.0617 (1.0090) acc 68.7500 (75.3795) lr 7.5131e-04 eta 0:18:27
epoch [31/50] batch [300/428] time 0.131 (0.134) data 0.000 (0.002) loss 1.5180 (1.6332) teacher_loss 0.5522 (0.6676) loss_zs_kd 4.4682 (4.4560) loss_oracle 0.9152 (0.9180) kd_loss 1.0165 (1.0133) acc 78.1250 (75.5729) lr 7.5131e-04 eta 0:18:22
epoch [31/50] batch [320/428] time 0.147 (0.134) data 0.000 (0.002) loss 1.6202 (1.6318) teacher_loss 0.6726 (0.6653) loss_zs_kd 4.7096 (4.4581) loss_oracle 0.8909 (0.9181) kd_loss 1.0042 (1.0150) acc 71.8750 (75.6641) lr 7.5131e-04 eta 0:18:22
epoch [31/50] batch [340/428] time 0.138 (0.134) data 0.000 (0.002) loss 1.5606 (1.6319) teacher_loss 0.6555 (0.6642) loss_zs_kd 4.8293 (4.4581) loss_oracle 0.8583 (0.9188) kd_loss 0.9518 (1.0166) acc 78.1250 (75.7077) lr 7.5131e-04 eta 0:18:19
epoch [31/50] batch [360/428] time 0.100 (0.133) data 0.000 (0.002) loss 1.7585 (1.6325) teacher_loss 0.7734 (0.6652) loss_zs_kd 4.1693 (4.4608) loss_oracle 0.9130 (0.9182) kd_loss 1.0572 (1.0165) acc 68.7500 (75.6337) lr 7.5131e-04 eta 0:18:13
epoch [31/50] batch [380/428] time 0.123 (0.133) data 0.000 (0.002) loss 1.7040 (1.6322) teacher_loss 0.7388 (0.6646) loss_zs_kd 5.1591 (4.4709) loss_oracle 0.9337 (0.9191) kd_loss 0.9968 (1.0161) acc 68.7500 (75.5921) lr 7.5131e-04 eta 0:18:06
epoch [31/50] batch [400/428] time 0.135 (0.132) data 0.000 (0.002) loss 1.3943 (1.6284) teacher_loss 0.5303 (0.6601) loss_zs_kd 4.6575 (4.4756) loss_oracle 0.8353 (0.9195) kd_loss 0.8926 (1.0170) acc 75.0000 (75.6953) lr 7.5131e-04 eta 0:17:59
epoch [31/50] batch [420/428] time 0.116 (0.132) data 0.000 (0.002) loss 2.0337 (1.6284) teacher_loss 1.1007 (0.6604) loss_zs_kd 4.8829 (4.4795) loss_oracle 0.8648 (0.9191) kd_loss 1.0011 (1.0169) acc 50.0000 (75.6324) lr 7.5131e-04 eta 0:17:50
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,989
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 38.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,395
* accuracy: 50.5%
* error: 49.5%
* macro_f1: 26.7%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [32/50] batch [20/428] time 0.085 (0.174) data 0.000 (0.031) loss 1.4531 (1.5924) teacher_loss 0.3760 (0.6257) loss_zs_kd 4.3164 (4.6627) loss_oracle 1.0475 (0.9144) kd_loss 1.1068 (1.0190) acc 90.6250 (76.5625) lr 6.9098e-04 eta 0:23:32
epoch [32/50] batch [40/428] time 0.145 (0.146) data 0.000 (0.016) loss 1.6690 (1.6051) teacher_loss 0.7700 (0.6310) loss_zs_kd 4.5892 (4.6558) loss_oracle 0.8579 (0.9279) kd_loss 0.9401 (1.0202) acc 75.0000 (76.6406) lr 6.9098e-04 eta 0:19:38
epoch [32/50] batch [60/428] time 0.079 (0.130) data 0.001 (0.011) loss 1.5304 (1.6039) teacher_loss 0.5912 (0.6279) loss_zs_kd 4.6096 (4.6885) loss_oracle 0.8628 (0.9299) kd_loss 1.0157 (1.0220) acc 75.0000 (76.8229) lr 6.9098e-04 eta 0:17:31
epoch [32/50] batch [80/428] time 0.070 (0.124) data 0.000 (0.008) loss 1.4804 (1.6038) teacher_loss 0.5850 (0.6330) loss_zs_kd 4.7600 (4.6902) loss_oracle 0.8178 (0.9267) kd_loss 0.9730 (1.0149) acc 71.8750 (76.7578) lr 6.9098e-04 eta 0:16:39
epoch [32/50] batch [100/428] time 0.079 (0.115) data 0.000 (0.007) loss 1.6336 (1.6194) teacher_loss 0.7277 (0.6503) loss_zs_kd 4.5867 (4.6906) loss_oracle 0.8355 (0.9255) kd_loss 0.9763 (1.0126) acc 75.0000 (76.2812) lr 6.9098e-04 eta 0:15:19
epoch [32/50] batch [120/428] time 0.083 (0.109) data 0.000 (0.005) loss 1.8695 (1.6218) teacher_loss 0.9406 (0.6498) loss_zs_kd 4.2437 (4.6732) loss_oracle 0.9064 (0.9280) kd_loss 0.9514 (1.0161) acc 68.7500 (75.9375) lr 6.9098e-04 eta 0:14:34
epoch [32/50] batch [140/428] time 0.084 (0.106) data 0.000 (0.005) loss 1.4903 (1.6202) teacher_loss 0.5182 (0.6450) loss_zs_kd 4.7753 (4.6762) loss_oracle 0.8880 (0.9292) kd_loss 1.0561 (1.0212) acc 81.2500 (76.1830) lr 6.9098e-04 eta 0:14:03
epoch [32/50] batch [160/428] time 0.086 (0.103) data 0.000 (0.004) loss 1.5627 (1.6302) teacher_loss 0.4551 (0.6506) loss_zs_kd 4.3710 (4.6678) loss_oracle 1.0393 (0.9324) kd_loss 1.1760 (1.0267) acc 78.1250 (75.9180) lr 6.9098e-04 eta 0:13:39
epoch [32/50] batch [180/428] time 0.089 (0.101) data 0.000 (0.004) loss 1.6369 (1.6318) teacher_loss 0.6230 (0.6500) loss_zs_kd 4.8557 (4.6728) loss_oracle 0.9163 (0.9342) kd_loss 1.1116 (1.0294) acc 75.0000 (75.9722) lr 6.9098e-04 eta 0:13:21
epoch [32/50] batch [200/428] time 0.083 (0.099) data 0.000 (0.003) loss 1.6158 (1.6351) teacher_loss 0.5571 (0.6497) loss_zs_kd 4.6323 (4.6656) loss_oracle 0.9909 (0.9371) kd_loss 1.1265 (1.0336) acc 75.0000 (76.0312) lr 6.9098e-04 eta 0:13:07
epoch [32/50] batch [220/428] time 0.080 (0.098) data 0.000 (0.003) loss 1.7804 (1.6355) teacher_loss 0.8338 (0.6509) loss_zs_kd 4.5313 (4.6568) loss_oracle 0.8476 (0.9348) kd_loss 1.0456 (1.0344) acc 65.6250 (75.9517) lr 6.9098e-04 eta 0:12:54
epoch [32/50] batch [240/428] time 0.093 (0.096) data 0.001 (0.003) loss 1.7122 (1.6290) teacher_loss 0.7713 (0.6439) loss_zs_kd 4.4576 (4.6515) loss_oracle 0.9237 (0.9360) kd_loss 0.9581 (1.0342) acc 68.7500 (76.3542) lr 6.9098e-04 eta 0:12:41
epoch [32/50] batch [260/428] time 0.079 (0.095) data 0.000 (0.003) loss 1.6254 (1.6305) teacher_loss 0.5704 (0.6445) loss_zs_kd 4.7182 (4.6518) loss_oracle 0.9592 (0.9362) kd_loss 1.1510 (1.0358) acc 75.0000 (76.2139) lr 6.9098e-04 eta 0:12:29
epoch [32/50] batch [280/428] time 0.077 (0.094) data 0.000 (0.003) loss 2.2372 (1.6351) teacher_loss 1.2996 (0.6482) loss_zs_kd 4.4068 (4.6458) loss_oracle 0.8834 (0.9363) kd_loss 0.9919 (1.0374) acc 53.1250 (76.0938) lr 6.9098e-04 eta 0:12:17
epoch [32/50] batch [300/428] time 0.072 (0.093) data 0.000 (0.002) loss 1.6182 (1.6362) teacher_loss 0.6159 (0.6474) loss_zs_kd 4.1879 (4.6331) loss_oracle 0.8720 (0.9379) kd_loss 1.1326 (1.0398) acc 68.7500 (76.1354) lr 6.9098e-04 eta 0:12:07
epoch [32/50] batch [320/428] time 0.085 (0.092) data 0.000 (0.002) loss 1.8324 (1.6367) teacher_loss 0.8898 (0.6479) loss_zs_kd 4.1308 (4.6230) loss_oracle 0.8907 (0.9380) kd_loss 0.9944 (1.0397) acc 62.5000 (76.0449) lr 6.9098e-04 eta 0:11:59
epoch [32/50] batch [340/428] time 0.084 (0.092) data 0.000 (0.002) loss 1.4902 (1.6348) teacher_loss 0.5180 (0.6461) loss_zs_kd 4.4736 (4.6257) loss_oracle 0.9188 (0.9371) kd_loss 1.0256 (1.0403) acc 81.2500 (75.9926) lr 6.9098e-04 eta 0:11:53
epoch [32/50] batch [360/428] time 0.082 (0.091) data 0.001 (0.002) loss 1.7617 (1.6346) teacher_loss 0.7425 (0.6446) loss_zs_kd 4.4848 (4.6248) loss_oracle 0.9566 (0.9375) kd_loss 1.0818 (1.0425) acc 71.8750 (75.9635) lr 6.9098e-04 eta 0:11:47
epoch [32/50] batch [380/428] time 0.080 (0.091) data 0.000 (0.002) loss 1.8458 (1.6360) teacher_loss 0.9362 (0.6453) loss_zs_kd 3.8775 (4.6282) loss_oracle 0.8812 (0.9371) kd_loss 0.9380 (1.0442) acc 65.6250 (75.7648) lr 6.9098e-04 eta 0:11:43
epoch [32/50] batch [400/428] time 0.072 (0.090) data 0.000 (0.002) loss 1.7113 (1.6358) teacher_loss 0.7429 (0.6441) loss_zs_kd 4.6258 (4.6280) loss_oracle 0.9341 (0.9371) kd_loss 1.0027 (1.0463) acc 71.8750 (75.8203) lr 6.9098e-04 eta 0:11:37
epoch [32/50] batch [420/428] time 0.067 (0.090) data 0.000 (0.002) loss 1.7824 (1.6386) teacher_loss 0.7940 (0.6450) loss_zs_kd 4.2792 (4.6245) loss_oracle 0.9323 (0.9380) kd_loss 1.0445 (1.0494) acc 75.0000 (75.7440) lr 6.9098e-04 eta 0:11:32
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,870
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 38.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,184
* accuracy: 46.1%
* error: 53.9%
* macro_f1: 23.4%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [33/50] batch [20/428] time 0.071 (0.119) data 0.000 (0.027) loss 1.7221 (1.6356) teacher_loss 0.7784 (0.6213) loss_zs_kd 4.2903 (4.5391) loss_oracle 0.9055 (0.9511) kd_loss 0.9819 (1.0776) acc 62.5000 (75.6250) lr 6.3188e-04 eta 0:15:13
epoch [33/50] batch [40/428] time 0.081 (0.101) data 0.000 (0.014) loss 1.6684 (1.6440) teacher_loss 0.6151 (0.6300) loss_zs_kd 4.4994 (4.5529) loss_oracle 1.0090 (0.9475) kd_loss 1.0974 (1.0805) acc 71.8750 (75.6250) lr 6.3188e-04 eta 0:12:53
epoch [33/50] batch [60/428] time 0.080 (0.095) data 0.000 (0.009) loss 1.7635 (1.6335) teacher_loss 0.7948 (0.6232) loss_zs_kd 4.4738 (4.5770) loss_oracle 0.9402 (0.9421) kd_loss 0.9971 (1.0786) acc 68.7500 (76.3542) lr 6.3188e-04 eta 0:12:07
epoch [33/50] batch [80/428] time 0.082 (0.092) data 0.000 (0.007) loss 1.5455 (1.6341) teacher_loss 0.4790 (0.6241) loss_zs_kd 3.9414 (4.5705) loss_oracle 0.9460 (0.9418) kd_loss 1.1868 (1.0782) acc 81.2500 (76.2500) lr 6.3188e-04 eta 0:11:39
epoch [33/50] batch [100/428] time 0.075 (0.090) data 0.000 (0.006) loss 1.9049 (1.6396) teacher_loss 0.9131 (0.6290) loss_zs_kd 4.5863 (4.5810) loss_oracle 0.9144 (0.9427) kd_loss 1.0692 (1.0784) acc 56.2500 (76.0312) lr 6.3188e-04 eta 0:11:24
epoch [33/50] batch [120/428] time 0.091 (0.089) data 0.000 (0.005) loss 1.6186 (1.6485) teacher_loss 0.6311 (0.6373) loss_zs_kd 4.2638 (4.5644) loss_oracle 0.9365 (0.9444) kd_loss 1.0386 (1.0781) acc 84.3750 (75.8333) lr 6.3188e-04 eta 0:11:11
epoch [33/50] batch [140/428] time 0.080 (0.088) data 0.000 (0.004) loss 1.6038 (1.6435) teacher_loss 0.5664 (0.6344) loss_zs_kd 4.3296 (4.5367) loss_oracle 0.9598 (0.9445) kd_loss 1.1151 (1.0738) acc 84.3750 (75.9598) lr 6.3188e-04 eta 0:11:07
epoch [33/50] batch [160/428] time 0.085 (0.088) data 0.000 (0.004) loss 1.5379 (1.6406) teacher_loss 0.4695 (0.6310) loss_zs_kd 4.5358 (4.5227) loss_oracle 0.9861 (0.9457) kd_loss 1.1507 (1.0735) acc 78.1250 (76.2305) lr 6.3188e-04 eta 0:11:03
epoch [33/50] batch [180/428] time 0.078 (0.087) data 0.000 (0.003) loss 1.8012 (1.6494) teacher_loss 0.8114 (0.6398) loss_zs_kd 4.5428 (4.5158) loss_oracle 0.9183 (0.9452) kd_loss 1.0611 (1.0741) acc 65.6250 (75.8333) lr 6.3188e-04 eta 0:10:57
epoch [33/50] batch [200/428] time 0.088 (0.087) data 0.000 (0.003) loss 1.6139 (1.6445) teacher_loss 0.6489 (0.6325) loss_zs_kd 4.1801 (4.4998) loss_oracle 0.9449 (0.9472) kd_loss 0.9850 (1.0768) acc 84.3750 (76.1562) lr 6.3188e-04 eta 0:10:55
epoch [33/50] batch [220/428] time 0.084 (0.089) data 0.000 (0.003) loss 1.8457 (1.6466) teacher_loss 0.8321 (0.6326) loss_zs_kd 3.7959 (4.4852) loss_oracle 0.9602 (0.9492) kd_loss 1.0670 (1.0788) acc 65.6250 (76.2642) lr 6.3188e-04 eta 0:11:05
epoch [33/50] batch [240/428] time 0.082 (0.088) data 0.000 (0.003) loss 1.7188 (1.6459) teacher_loss 0.6180 (0.6308) loss_zs_kd 4.4158 (4.4596) loss_oracle 1.0097 (0.9496) kd_loss 1.1918 (1.0806) acc 75.0000 (76.5104) lr 6.3188e-04 eta 0:11:00
epoch [33/50] batch [260/428] time 0.082 (0.088) data 0.000 (0.002) loss 1.4931 (1.6432) teacher_loss 0.5338 (0.6301) loss_zs_kd 4.0850 (4.4410) loss_oracle 0.8697 (0.9480) kd_loss 1.0488 (1.0783) acc 81.2500 (76.6106) lr 6.3188e-04 eta 0:10:57
epoch [33/50] batch [280/428] time 0.073 (0.088) data 0.000 (0.002) loss 1.5378 (1.6415) teacher_loss 0.4690 (0.6292) loss_zs_kd 4.3396 (4.4283) loss_oracle 1.0133 (0.9475) kd_loss 1.1242 (1.0770) acc 84.3750 (76.6295) lr 6.3188e-04 eta 0:10:52
epoch [33/50] batch [300/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.6258 (1.6392) teacher_loss 0.7272 (0.6263) loss_zs_kd 4.8890 (4.4223) loss_oracle 0.8890 (0.9485) kd_loss 0.9082 (1.0774) acc 78.1250 (76.8854) lr 6.3188e-04 eta 0:10:46
epoch [33/50] batch [320/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.6681 (1.6390) teacher_loss 0.6453 (0.6253) loss_zs_kd 4.4790 (4.4305) loss_oracle 0.9350 (0.9491) kd_loss 1.1106 (1.0784) acc 71.8750 (76.8750) lr 6.3188e-04 eta 0:10:42
epoch [33/50] batch [340/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.7543 (1.6414) teacher_loss 0.7061 (0.6282) loss_zs_kd 4.0643 (4.4253) loss_oracle 0.9513 (0.9484) kd_loss 1.1451 (1.0781) acc 65.6250 (76.6544) lr 6.3188e-04 eta 0:10:40
epoch [33/50] batch [360/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.5540 (1.6412) teacher_loss 0.5936 (0.6275) loss_zs_kd 4.3205 (4.4172) loss_oracle 0.8878 (0.9496) kd_loss 1.0330 (1.0778) acc 75.0000 (76.7448) lr 6.3188e-04 eta 0:10:37
epoch [33/50] batch [380/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.6493 (1.6404) teacher_loss 0.7345 (0.6275) loss_zs_kd 4.6293 (4.4129) loss_oracle 0.8657 (0.9496) kd_loss 0.9638 (1.0762) acc 75.0000 (76.8257) lr 6.3188e-04 eta 0:10:34
epoch [33/50] batch [400/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.8226 (1.6405) teacher_loss 0.8164 (0.6275) loss_zs_kd 4.5231 (4.4080) loss_oracle 0.9631 (0.9508) kd_loss 1.0491 (1.0752) acc 68.7500 (76.9375) lr 6.3188e-04 eta 0:10:33
epoch [33/50] batch [420/428] time 0.074 (0.086) data 0.000 (0.002) loss 1.5486 (1.6379) teacher_loss 0.5664 (0.6265) loss_zs_kd 4.7525 (4.4074) loss_oracle 0.9233 (0.9499) kd_loss 1.0411 (1.0730) acc 68.7500 (76.9940) lr 6.3188e-04 eta 0:10:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,103
* accuracy: 52.8%
* error: 47.2%
* macro_f1: 40.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,001
* accuracy: 42.2%
* error: 57.8%
* macro_f1: 24.1%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [34/50] batch [20/428] time 0.082 (0.112) data 0.000 (0.031) loss 1.5603 (1.5834) teacher_loss 0.4169 (0.5881) loss_zs_kd 4.4600 (4.2588) loss_oracle 1.0450 (0.9386) kd_loss 1.2418 (1.0520) acc 90.6250 (78.7500) lr 5.7422e-04 eta 0:13:34
epoch [34/50] batch [40/428] time 0.069 (0.095) data 0.000 (0.016) loss 1.6153 (1.6092) teacher_loss 0.5250 (0.6073) loss_zs_kd 4.7531 (4.3400) loss_oracle 1.0486 (0.9450) kd_loss 1.1319 (1.0589) acc 87.5000 (76.8750) lr 5.7422e-04 eta 0:11:24
epoch [34/50] batch [60/428] time 0.059 (0.085) data 0.001 (0.010) loss 1.5111 (1.6084) teacher_loss 0.5316 (0.5960) loss_zs_kd 4.7269 (4.3908) loss_oracle 0.9448 (0.9572) kd_loss 1.0142 (1.0677) acc 75.0000 (77.0833) lr 5.7422e-04 eta 0:10:12
epoch [34/50] batch [80/428] time 0.064 (0.080) data 0.000 (0.008) loss 1.5971 (1.6059) teacher_loss 0.5269 (0.5919) loss_zs_kd 4.7172 (4.4114) loss_oracle 0.9825 (0.9573) kd_loss 1.1579 (1.0706) acc 81.2500 (77.5391) lr 5.7422e-04 eta 0:09:33
epoch [34/50] batch [100/428] time 0.085 (0.078) data 0.000 (0.006) loss 1.5092 (1.6050) teacher_loss 0.4570 (0.5878) loss_zs_kd 4.7900 (4.4050) loss_oracle 0.9802 (0.9579) kd_loss 1.1242 (1.0764) acc 71.8750 (77.5938) lr 5.7422e-04 eta 0:09:16
epoch [34/50] batch [120/428] time 0.081 (0.077) data 0.000 (0.005) loss 1.8485 (1.6147) teacher_loss 0.7884 (0.5962) loss_zs_kd 4.4040 (4.4020) loss_oracle 1.0027 (0.9597) kd_loss 1.1176 (1.0772) acc 65.6250 (77.1354) lr 5.7422e-04 eta 0:09:07
epoch [34/50] batch [140/428] time 0.062 (0.075) data 0.000 (0.005) loss 1.5225 (1.6195) teacher_loss 0.4140 (0.5986) loss_zs_kd 4.2042 (4.3877) loss_oracle 1.0769 (0.9593) kd_loss 1.1400 (1.0825) acc 81.2500 (77.1429) lr 5.7422e-04 eta 0:08:53
epoch [34/50] batch [160/428] time 0.067 (0.073) data 0.000 (0.004) loss 1.5990 (1.6185) teacher_loss 0.6071 (0.5958) loss_zs_kd 4.4209 (4.3812) loss_oracle 0.9125 (0.9591) kd_loss 1.0712 (1.0863) acc 78.1250 (77.1680) lr 5.7422e-04 eta 0:08:41
epoch [34/50] batch [180/428] time 0.062 (0.072) data 0.000 (0.004) loss 1.5451 (1.6274) teacher_loss 0.4041 (0.6036) loss_zs_kd 4.3186 (4.3730) loss_oracle 1.0334 (0.9602) kd_loss 1.2485 (1.0875) acc 81.2500 (76.7361) lr 5.7422e-04 eta 0:08:32
epoch [34/50] batch [200/428] time 0.071 (0.071) data 0.000 (0.003) loss 1.8018 (1.6253) teacher_loss 0.7934 (0.6002) loss_zs_kd 3.9332 (4.3450) loss_oracle 0.9460 (0.9608) kd_loss 1.0707 (1.0894) acc 75.0000 (76.8750) lr 5.7422e-04 eta 0:08:25
epoch [34/50] batch [220/428] time 0.068 (0.072) data 0.000 (0.003) loss 1.6292 (1.6229) teacher_loss 0.5969 (0.5992) loss_zs_kd 4.3310 (4.3215) loss_oracle 0.9345 (0.9584) kd_loss 1.1302 (1.0890) acc 75.0000 (76.8466) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [240/428] time 0.082 (0.073) data 0.001 (0.003) loss 1.5597 (1.6211) teacher_loss 0.6069 (0.5975) loss_zs_kd 3.8524 (4.2827) loss_oracle 0.8734 (0.9560) kd_loss 1.0323 (1.0912) acc 78.1250 (76.9141) lr 5.7422e-04 eta 0:08:31
epoch [34/50] batch [260/428] time 0.079 (0.073) data 0.000 (0.003) loss 1.5137 (1.6203) teacher_loss 0.4073 (0.5946) loss_zs_kd 3.8695 (4.2707) loss_oracle 1.0095 (0.9567) kd_loss 1.2032 (1.0948) acc 90.6250 (77.1875) lr 5.7422e-04 eta 0:08:31
epoch [34/50] batch [280/428] time 0.095 (0.073) data 0.001 (0.002) loss 1.7320 (1.6240) teacher_loss 0.6844 (0.5970) loss_zs_kd 3.4509 (4.2507) loss_oracle 1.0071 (0.9574) kd_loss 1.0882 (1.0964) acc 71.8750 (77.0089) lr 5.7422e-04 eta 0:08:31
epoch [34/50] batch [300/428] time 0.075 (0.073) data 0.000 (0.002) loss 1.6190 (1.6218) teacher_loss 0.5920 (0.5936) loss_zs_kd 3.6763 (4.2351) loss_oracle 0.9401 (0.9573) kd_loss 1.1141 (1.0991) acc 75.0000 (77.1667) lr 5.7422e-04 eta 0:08:32
epoch [34/50] batch [320/428] time 0.079 (0.074) data 0.000 (0.002) loss 1.5214 (1.6211) teacher_loss 0.4705 (0.5911) loss_zs_kd 4.1054 (4.2182) loss_oracle 0.9707 (0.9592) kd_loss 1.1312 (1.1009) acc 78.1250 (77.2266) lr 5.7422e-04 eta 0:08:33
epoch [34/50] batch [340/428] time 0.069 (0.074) data 0.000 (0.002) loss 1.6342 (1.6200) teacher_loss 0.5114 (0.5875) loss_zs_kd 3.8580 (4.2070) loss_oracle 0.9884 (0.9599) kd_loss 1.2572 (1.1051) acc 81.2500 (77.4173) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [360/428] time 0.073 (0.074) data 0.000 (0.002) loss 1.6089 (1.6194) teacher_loss 0.5389 (0.5863) loss_zs_kd 3.6788 (4.1878) loss_oracle 0.9360 (0.9592) kd_loss 1.2040 (1.1071) acc 78.1250 (77.3524) lr 5.7422e-04 eta 0:08:31
epoch [34/50] batch [380/428] time 0.086 (0.075) data 0.000 (0.002) loss 1.5194 (1.6181) teacher_loss 0.4629 (0.5837) loss_zs_kd 4.4215 (4.1783) loss_oracle 0.9526 (0.9593) kd_loss 1.1604 (1.1095) acc 87.5000 (77.5000) lr 5.7422e-04 eta 0:08:33
epoch [34/50] batch [400/428] time 0.076 (0.076) data 0.000 (0.002) loss 1.5283 (1.6187) teacher_loss 0.4706 (0.5816) loss_zs_kd 4.3078 (4.1723) loss_oracle 0.9319 (0.9604) kd_loss 1.1835 (1.1138) acc 81.2500 (77.5938) lr 5.7422e-04 eta 0:08:40
epoch [34/50] batch [420/428] time 0.076 (0.076) data 0.000 (0.002) loss 1.4225 (1.6185) teacher_loss 0.3060 (0.5793) loss_zs_kd 3.8144 (4.1759) loss_oracle 1.0027 (0.9618) kd_loss 1.2303 (1.1166) acc 90.6250 (77.7307) lr 5.7422e-04 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,038
* accuracy: 51.7%
* error: 48.3%
* macro_f1: 39.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,350
* accuracy: 49.6%
* error: 50.4%
* macro_f1: 22.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [35/50] batch [20/428] time 0.085 (0.105) data 0.000 (0.024) loss 1.5724 (1.6478) teacher_loss 0.5008 (0.5741) loss_zs_kd 3.5279 (4.0695) loss_oracle 0.9376 (0.9789) kd_loss 1.2056 (1.1684) acc 84.3750 (77.1875) lr 5.1825e-04 eta 0:11:53
epoch [35/50] batch [40/428] time 0.083 (0.093) data 0.000 (0.012) loss 1.4779 (1.6540) teacher_loss 0.3739 (0.5757) loss_zs_kd 4.0038 (3.9871) loss_oracle 0.9930 (0.9954) kd_loss 1.2152 (1.1612) acc 84.3750 (77.6562) lr 5.1825e-04 eta 0:10:30
epoch [35/50] batch [60/428] time 0.085 (0.089) data 0.001 (0.008) loss 1.7453 (1.6346) teacher_loss 0.6026 (0.5552) loss_zs_kd 4.3260 (4.0389) loss_oracle 1.0507 (1.0001) kd_loss 1.2347 (1.1588) acc 68.7500 (79.1146) lr 5.1825e-04 eta 0:10:07
epoch [35/50] batch [80/428] time 0.079 (0.088) data 0.000 (0.006) loss 1.6245 (1.6312) teacher_loss 0.6626 (0.5514) loss_zs_kd 4.2398 (4.0476) loss_oracle 0.9525 (0.9985) kd_loss 0.9713 (1.1611) acc 78.1250 (79.0625) lr 5.1825e-04 eta 0:09:58
epoch [35/50] batch [100/428] time 0.086 (0.088) data 0.000 (0.005) loss 1.6230 (1.6273) teacher_loss 0.5995 (0.5540) loss_zs_kd 3.8458 (4.0317) loss_oracle 0.8891 (0.9961) kd_loss 1.1580 (1.1505) acc 65.6250 (78.9375) lr 5.1825e-04 eta 0:09:55
epoch [35/50] batch [120/428] time 0.168 (0.089) data 0.000 (0.004) loss 1.7204 (1.6201) teacher_loss 0.7702 (0.5479) loss_zs_kd 3.9280 (4.0128) loss_oracle 0.8745 (0.9943) kd_loss 1.0259 (1.1500) acc 59.3750 (79.2448) lr 5.1825e-04 eta 0:09:56
epoch [35/50] batch [140/428] time 0.083 (0.090) data 0.000 (0.004) loss 1.4754 (1.6215) teacher_loss 0.4130 (0.5514) loss_zs_kd 3.2055 (3.9465) loss_oracle 1.0054 (0.9894) kd_loss 1.1193 (1.1508) acc 81.2500 (78.8839) lr 5.1825e-04 eta 0:10:05
epoch [35/50] batch [160/428] time 0.080 (0.090) data 0.000 (0.003) loss 1.4790 (1.6223) teacher_loss 0.4145 (0.5533) loss_zs_kd 3.3190 (3.8975) loss_oracle 0.9012 (0.9848) kd_loss 1.2279 (1.1534) acc 87.5000 (78.8672) lr 5.1825e-04 eta 0:09:59
epoch [35/50] batch [180/428] time 0.098 (0.089) data 0.000 (0.003) loss 1.5722 (1.6212) teacher_loss 0.5310 (0.5542) loss_zs_kd 3.7977 (3.8719) loss_oracle 0.9675 (0.9816) kd_loss 1.1147 (1.1523) acc 75.0000 (78.7500) lr 5.1825e-04 eta 0:09:54
epoch [35/50] batch [200/428] time 0.084 (0.089) data 0.000 (0.003) loss 1.5700 (1.6197) teacher_loss 0.4893 (0.5537) loss_zs_kd 3.6688 (3.8632) loss_oracle 0.9527 (0.9802) kd_loss 1.2086 (1.1518) acc 78.1250 (78.6094) lr 5.1825e-04 eta 0:09:50
epoch [35/50] batch [220/428] time 0.075 (0.089) data 0.000 (0.002) loss 1.4545 (1.6221) teacher_loss 0.3483 (0.5568) loss_zs_kd 4.0457 (3.8656) loss_oracle 0.9677 (0.9809) kd_loss 1.2446 (1.1497) acc 81.2500 (78.4801) lr 5.1825e-04 eta 0:09:46
epoch [35/50] batch [240/428] time 0.088 (0.088) data 0.000 (0.002) loss 1.7233 (1.6236) teacher_loss 0.6574 (0.5571) loss_zs_kd 4.2941 (3.8706) loss_oracle 1.0172 (0.9836) kd_loss 1.1146 (1.1496) acc 71.8750 (78.3464) lr 5.1825e-04 eta 0:09:43
epoch [35/50] batch [260/428] time 0.083 (0.088) data 0.000 (0.002) loss 1.5662 (1.6270) teacher_loss 0.3655 (0.5573) loss_zs_kd 3.8421 (3.8646) loss_oracle 1.0470 (0.9867) kd_loss 1.3544 (1.1527) acc 87.5000 (78.2212) lr 5.1825e-04 eta 0:09:39
epoch [35/50] batch [280/428] time 0.085 (0.088) data 0.000 (0.002) loss 1.5070 (1.6259) teacher_loss 0.4131 (0.5561) loss_zs_kd 4.4462 (3.8730) loss_oracle 1.0250 (0.9868) kd_loss 1.1627 (1.1528) acc 93.7500 (78.3705) lr 5.1825e-04 eta 0:09:36
epoch [35/50] batch [300/428] time 0.080 (0.087) data 0.000 (0.002) loss 1.5288 (1.6270) teacher_loss 0.4292 (0.5574) loss_zs_kd 3.9259 (3.8750) loss_oracle 0.9815 (0.9858) kd_loss 1.2176 (1.1534) acc 84.3750 (78.1146) lr 5.1825e-04 eta 0:09:32
epoch [35/50] batch [320/428] time 0.075 (0.087) data 0.000 (0.002) loss 1.8833 (1.6276) teacher_loss 0.8998 (0.5591) loss_zs_kd 4.0261 (3.8869) loss_oracle 0.9378 (0.9853) kd_loss 1.0292 (1.1517) acc 65.6250 (78.0371) lr 5.1825e-04 eta 0:09:29
epoch [35/50] batch [340/428] time 0.077 (0.087) data 0.000 (0.002) loss 1.7427 (1.6293) teacher_loss 0.6766 (0.5583) loss_zs_kd 4.4826 (3.8856) loss_oracle 1.0269 (0.9881) kd_loss 1.1053 (1.1539) acc 71.8750 (78.0790) lr 5.1825e-04 eta 0:09:25
epoch [35/50] batch [360/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.7160 (1.6327) teacher_loss 0.6308 (0.5605) loss_zs_kd 4.2424 (3.8941) loss_oracle 1.0051 (0.9902) kd_loss 1.1652 (1.1542) acc 62.5000 (77.9167) lr 5.1825e-04 eta 0:09:24
epoch [35/50] batch [380/428] time 0.077 (0.087) data 0.000 (0.002) loss 1.5589 (1.6343) teacher_loss 0.4165 (0.5599) loss_zs_kd 3.9710 (3.8994) loss_oracle 1.0560 (0.9938) kd_loss 1.2289 (1.1550) acc 84.3750 (77.8536) lr 5.1825e-04 eta 0:09:22
epoch [35/50] batch [400/428] time 0.077 (0.087) data 0.000 (0.001) loss 1.6435 (1.6372) teacher_loss 0.5328 (0.5603) loss_zs_kd 3.9647 (3.9019) loss_oracle 1.0852 (0.9974) kd_loss 1.1362 (1.1565) acc 81.2500 (77.7812) lr 5.1825e-04 eta 0:09:20
epoch [35/50] batch [420/428] time 0.081 (0.087) data 0.000 (0.001) loss 1.7240 (1.6388) teacher_loss 0.5365 (0.5605) loss_zs_kd 4.0319 (3.9067) loss_oracle 1.1242 (0.9998) kd_loss 1.2510 (1.1568) acc 75.0000 (77.6190) lr 5.1825e-04 eta 0:09:17
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,984
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 37.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,676
* accuracy: 56.4%
* error: 43.6%
* macro_f1: 22.7%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [36/50] batch [20/428] time 0.077 (0.116) data 0.000 (0.038) loss 1.7003 (1.6750) teacher_loss 0.5344 (0.5709) loss_zs_kd 3.7284 (4.0724) loss_oracle 1.0712 (1.0371) kd_loss 1.2606 (1.1711) acc 78.1250 (77.6562) lr 4.6417e-04 eta 0:12:22
epoch [36/50] batch [40/428] time 0.080 (0.100) data 0.000 (0.019) loss 1.5292 (1.6633) teacher_loss 0.3385 (0.5689) loss_zs_kd 4.0285 (4.0708) loss_oracle 1.0738 (1.0270) kd_loss 1.3075 (1.1618) acc 87.5000 (76.8750) lr 4.6417e-04 eta 0:10:37
epoch [36/50] batch [60/428] time 0.072 (0.093) data 0.000 (0.013) loss 1.8106 (1.6447) teacher_loss 0.7247 (0.5442) loss_zs_kd 3.9417 (4.0856) loss_oracle 1.0589 (1.0379) kd_loss 1.1130 (1.1632) acc 75.0000 (78.1771) lr 4.6417e-04 eta 0:09:49
epoch [36/50] batch [80/428] time 0.084 (0.090) data 0.000 (0.010) loss 1.6773 (1.6402) teacher_loss 0.6038 (0.5375) loss_zs_kd 4.6160 (4.1110) loss_oracle 0.9890 (1.0406) kd_loss 1.1580 (1.1648) acc 75.0000 (78.4766) lr 4.6417e-04 eta 0:09:29
epoch [36/50] batch [100/428] time 0.088 (0.089) data 0.000 (0.008) loss 1.6493 (1.6412) teacher_loss 0.4515 (0.5388) loss_zs_kd 4.5585 (4.1271) loss_oracle 1.1340 (1.0428) kd_loss 1.2614 (1.1620) acc 87.5000 (78.4688) lr 4.6417e-04 eta 0:09:23
epoch [36/50] batch [120/428] time 0.086 (0.089) data 0.000 (0.007) loss 1.6674 (1.6418) teacher_loss 0.6957 (0.5382) loss_zs_kd 4.4303 (4.1367) loss_oracle 0.9620 (1.0414) kd_loss 0.9814 (1.1658) acc 62.5000 (78.3333) lr 4.6417e-04 eta 0:09:18
epoch [36/50] batch [140/428] time 0.086 (0.088) data 0.000 (0.006) loss 1.7722 (1.6407) teacher_loss 0.7946 (0.5387) loss_zs_kd 4.4795 (4.1362) loss_oracle 0.9288 (1.0386) kd_loss 1.0264 (1.1654) acc 59.3750 (78.1473) lr 4.6417e-04 eta 0:09:13
epoch [36/50] batch [160/428] time 0.076 (0.087) data 0.000 (0.005) loss 1.5575 (1.6353) teacher_loss 0.3606 (0.5337) loss_zs_kd 4.6503 (4.1392) loss_oracle 1.0665 (1.0362) kd_loss 1.3273 (1.1669) acc 87.5000 (78.4766) lr 4.6417e-04 eta 0:09:06
epoch [36/50] batch [180/428] time 0.085 (0.087) data 0.000 (0.004) loss 1.4998 (1.6369) teacher_loss 0.2802 (0.5380) loss_zs_kd 3.7896 (4.1313) loss_oracle 1.0786 (1.0297) kd_loss 1.3607 (1.1683) acc 90.6250 (78.2986) lr 4.6417e-04 eta 0:09:03
epoch [36/50] batch [200/428] time 0.105 (0.087) data 0.001 (0.004) loss 1.4493 (1.6288) teacher_loss 0.4112 (0.5350) loss_zs_kd 4.0265 (4.1278) loss_oracle 0.9299 (1.0219) kd_loss 1.1463 (1.1658) acc 90.6250 (78.5625) lr 4.6417e-04 eta 0:09:02
epoch [36/50] batch [220/428] time 0.076 (0.087) data 0.000 (0.004) loss 1.6604 (1.6260) teacher_loss 0.6535 (0.5365) loss_zs_kd 3.9359 (4.1103) loss_oracle 0.9117 (1.0149) kd_loss 1.1020 (1.1641) acc 65.6250 (78.4517) lr 4.6417e-04 eta 0:09:00
epoch [36/50] batch [240/428] time 0.079 (0.088) data 0.000 (0.003) loss 1.5716 (1.6262) teacher_loss 0.4562 (0.5384) loss_zs_kd 4.0694 (4.1112) loss_oracle 1.0057 (1.0113) kd_loss 1.2250 (1.1641) acc 87.5000 (78.4375) lr 4.6417e-04 eta 0:09:04
epoch [36/50] batch [260/428] time 0.090 (0.088) data 0.000 (0.003) loss 1.6075 (1.6280) teacher_loss 0.4867 (0.5427) loss_zs_kd 4.2499 (4.1110) loss_oracle 1.0053 (1.0075) kd_loss 1.2364 (1.1631) acc 78.1250 (78.3293) lr 4.6417e-04 eta 0:09:02
epoch [36/50] batch [280/428] time 0.077 (0.088) data 0.000 (0.003) loss 1.7237 (1.6254) teacher_loss 0.6553 (0.5426) loss_zs_kd 4.0179 (4.0992) loss_oracle 1.0013 (1.0030) kd_loss 1.1356 (1.1625) acc 75.0000 (78.2366) lr 4.6417e-04 eta 0:08:59
epoch [36/50] batch [300/428] time 0.100 (0.088) data 0.000 (0.003) loss 1.6085 (1.6262) teacher_loss 0.5636 (0.5440) loss_zs_kd 4.0953 (4.1040) loss_oracle 0.9711 (1.0013) kd_loss 1.1189 (1.1632) acc 75.0000 (78.2083) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [320/428] time 0.076 (0.087) data 0.000 (0.003) loss 1.3866 (1.6268) teacher_loss 0.3731 (0.5452) loss_zs_kd 4.6002 (4.1109) loss_oracle 0.9590 (1.0004) kd_loss 1.0681 (1.1628) acc 87.5000 (78.0176) lr 4.6417e-04 eta 0:08:52
epoch [36/50] batch [340/428] time 0.081 (0.087) data 0.000 (0.003) loss 1.5407 (1.6293) teacher_loss 0.5241 (0.5485) loss_zs_kd 4.5727 (4.1225) loss_oracle 0.9298 (0.9999) kd_loss 1.1033 (1.1618) acc 78.1250 (77.7298) lr 4.6417e-04 eta 0:08:49
epoch [36/50] batch [360/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.5710 (1.6308) teacher_loss 0.6385 (0.5509) loss_zs_kd 3.9191 (4.1266) loss_oracle 0.8597 (0.9974) kd_loss 1.0052 (1.1625) acc 78.1250 (77.6302) lr 4.6417e-04 eta 0:08:46
epoch [36/50] batch [380/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.6896 (1.6305) teacher_loss 0.6554 (0.5530) loss_zs_kd 3.9423 (4.1207) loss_oracle 0.9300 (0.9939) kd_loss 1.1384 (1.1612) acc 68.7500 (77.4013) lr 4.6417e-04 eta 0:08:43
epoch [36/50] batch [400/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.5950 (1.6289) teacher_loss 0.5423 (0.5529) loss_zs_kd 4.1369 (4.1178) loss_oracle 0.9049 (0.9909) kd_loss 1.2004 (1.1611) acc 75.0000 (77.3750) lr 4.6417e-04 eta 0:08:41
epoch [36/50] batch [420/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.5429 (1.6292) teacher_loss 0.5543 (0.5548) loss_zs_kd 4.5164 (4.1176) loss_oracle 0.9167 (0.9885) kd_loss 1.0603 (1.1604) acc 84.3750 (77.2842) lr 4.6417e-04 eta 0:08:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,237
* accuracy: 55.1%
* error: 44.9%
* macro_f1: 37.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,315
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 20.9%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [37/50] batch [20/428] time 0.072 (0.113) data 0.000 (0.031) loss 1.4433 (1.6010) teacher_loss 0.3205 (0.5435) loss_zs_kd 4.2519 (4.1202) loss_oracle 1.0118 (0.9627) kd_loss 1.2338 (1.1524) acc 87.5000 (78.4375) lr 4.1221e-04 eta 0:11:16
epoch [37/50] batch [40/428] time 0.068 (0.092) data 0.000 (0.016) loss 1.7168 (1.6230) teacher_loss 0.6905 (0.5668) loss_zs_kd 4.2443 (4.1316) loss_oracle 0.9431 (0.9606) kd_loss 1.1094 (1.1517) acc 68.7500 (76.3281) lr 4.1221e-04 eta 0:09:07
epoch [37/50] batch [60/428] time 0.076 (0.087) data 0.000 (0.011) loss 1.5889 (1.6327) teacher_loss 0.6158 (0.5795) loss_zs_kd 4.8878 (4.1601) loss_oracle 0.9010 (0.9559) kd_loss 1.0454 (1.1506) acc 68.7500 (75.9375) lr 4.1221e-04 eta 0:08:33
epoch [37/50] batch [80/428] time 0.083 (0.086) data 0.000 (0.008) loss 1.8201 (1.6306) teacher_loss 0.8195 (0.5818) loss_zs_kd 5.1198 (4.2109) loss_oracle 0.9150 (0.9521) kd_loss 1.0860 (1.1455) acc 78.1250 (76.0156) lr 4.1221e-04 eta 0:08:28
epoch [37/50] batch [100/428] time 0.078 (0.086) data 0.000 (0.006) loss 1.6534 (1.6345) teacher_loss 0.7340 (0.5835) loss_zs_kd 4.3030 (4.2259) loss_oracle 0.8586 (0.9511) kd_loss 0.9802 (1.1509) acc 71.8750 (76.1875) lr 4.1221e-04 eta 0:08:25
epoch [37/50] batch [120/428] time 0.082 (0.086) data 0.000 (0.005) loss 1.7632 (1.6279) teacher_loss 0.7407 (0.5822) loss_zs_kd 4.5245 (4.2119) loss_oracle 0.8816 (0.9423) kd_loss 1.1634 (1.1492) acc 68.7500 (76.1979) lr 4.1221e-04 eta 0:08:22
epoch [37/50] batch [140/428] time 0.081 (0.085) data 0.000 (0.005) loss 1.5408 (1.6245) teacher_loss 0.4305 (0.5776) loss_zs_kd 4.2586 (4.2161) loss_oracle 0.9853 (0.9399) kd_loss 1.2354 (1.1540) acc 81.2500 (76.2946) lr 4.1221e-04 eta 0:08:19
epoch [37/50] batch [160/428] time 0.088 (0.085) data 0.000 (0.004) loss 1.5852 (1.6190) teacher_loss 0.6335 (0.5715) loss_zs_kd 4.0414 (4.2197) loss_oracle 0.8341 (0.9392) kd_loss 1.0693 (1.1556) acc 71.8750 (76.5039) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [180/428] time 0.084 (0.085) data 0.000 (0.004) loss 1.7774 (1.6153) teacher_loss 0.7238 (0.5661) loss_zs_kd 4.8511 (4.2254) loss_oracle 0.9668 (0.9398) kd_loss 1.1404 (1.1588) acc 65.6250 (76.7014) lr 4.1221e-04 eta 0:08:14
epoch [37/50] batch [200/428] time 0.078 (0.085) data 0.000 (0.003) loss 1.3835 (1.6131) teacher_loss 0.3108 (0.5638) loss_zs_kd 4.3766 (4.2400) loss_oracle 0.9217 (0.9420) kd_loss 1.2237 (1.1565) acc 93.7500 (76.9688) lr 4.1221e-04 eta 0:08:12
epoch [37/50] batch [220/428] time 0.086 (0.085) data 0.000 (0.003) loss 1.6134 (1.6156) teacher_loss 0.5945 (0.5638) loss_zs_kd 4.8392 (4.2475) loss_oracle 0.8993 (0.9440) kd_loss 1.1385 (1.1595) acc 68.7500 (77.0170) lr 4.1221e-04 eta 0:08:10
epoch [37/50] batch [240/428] time 0.079 (0.085) data 0.000 (0.003) loss 1.4996 (1.6117) teacher_loss 0.5187 (0.5598) loss_zs_kd 4.4965 (4.2515) loss_oracle 0.8883 (0.9459) kd_loss 1.0735 (1.1579) acc 81.2500 (77.1484) lr 4.1221e-04 eta 0:08:08
epoch [37/50] batch [260/428] time 0.088 (0.085) data 0.000 (0.003) loss 1.6880 (1.6114) teacher_loss 0.6334 (0.5575) loss_zs_kd 4.1781 (4.2529) loss_oracle 0.9152 (0.9476) kd_loss 1.1940 (1.1601) acc 75.0000 (77.2236) lr 4.1221e-04 eta 0:08:05
epoch [37/50] batch [280/428] time 0.081 (0.084) data 0.000 (0.003) loss 1.4336 (1.6102) teacher_loss 0.4404 (0.5556) loss_zs_kd 4.5957 (4.2582) loss_oracle 0.7942 (0.9483) kd_loss 1.1922 (1.1610) acc 84.3750 (77.2879) lr 4.1221e-04 eta 0:08:02
epoch [37/50] batch [300/428] time 0.071 (0.084) data 0.000 (0.002) loss 1.6864 (1.6118) teacher_loss 0.5744 (0.5554) loss_zs_kd 4.5063 (4.2669) loss_oracle 0.9653 (0.9509) kd_loss 1.2587 (1.1618) acc 84.3750 (77.3333) lr 4.1221e-04 eta 0:07:59
epoch [37/50] batch [320/428] time 0.075 (0.084) data 0.000 (0.002) loss 1.5974 (1.6092) teacher_loss 0.5066 (0.5524) loss_zs_kd 4.7314 (4.2809) loss_oracle 1.0250 (0.9517) kd_loss 1.1567 (1.1618) acc 78.1250 (77.5879) lr 4.1221e-04 eta 0:07:56
epoch [37/50] batch [340/428] time 0.083 (0.084) data 0.000 (0.002) loss 1.5437 (1.6101) teacher_loss 0.2294 (0.5528) loss_zs_kd 4.6233 (4.2907) loss_oracle 1.1535 (0.9535) kd_loss 1.4751 (1.1611) acc 90.6250 (77.5092) lr 4.1221e-04 eta 0:07:53
epoch [37/50] batch [360/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.5697 (1.6099) teacher_loss 0.5318 (0.5517) loss_zs_kd 4.6057 (4.3044) loss_oracle 0.9355 (0.9548) kd_loss 1.1403 (1.1614) acc 75.0000 (77.5347) lr 4.1221e-04 eta 0:07:51
epoch [37/50] batch [380/428] time 0.136 (0.085) data 0.000 (0.002) loss 1.6412 (1.6116) teacher_loss 0.6936 (0.5543) loss_zs_kd 4.2420 (4.3143) loss_oracle 0.8642 (0.9552) kd_loss 1.0309 (1.1592) acc 68.7500 (77.3109) lr 4.1221e-04 eta 0:07:54
epoch [37/50] batch [400/428] time 0.069 (0.084) data 0.000 (0.002) loss 1.5824 (1.6086) teacher_loss 0.4973 (0.5509) loss_zs_kd 4.4244 (4.3183) loss_oracle 0.9680 (0.9558) kd_loss 1.2022 (1.1595) acc 71.8750 (77.4375) lr 4.1221e-04 eta 0:07:51
epoch [37/50] batch [420/428] time 0.067 (0.084) data 0.000 (0.002) loss 1.6135 (1.6087) teacher_loss 0.5419 (0.5499) loss_zs_kd 4.9037 (4.3257) loss_oracle 0.9510 (0.9564) kd_loss 1.1922 (1.1611) acc 81.2500 (77.4702) lr 4.1221e-04 eta 0:07:45
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,280
* accuracy: 55.8%
* error: 44.2%
* macro_f1: 37.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,117
* accuracy: 44.7%
* error: 55.3%
* macro_f1: 20.9%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [38/50] batch [20/428] time 0.075 (0.115) data 0.000 (0.031) loss 1.4294 (1.5712) teacher_loss 0.4542 (0.5285) loss_zs_kd 3.9475 (4.4587) loss_oracle 0.8841 (0.9464) kd_loss 1.0663 (1.1391) acc 84.3750 (78.5938) lr 3.6258e-04 eta 0:10:39
epoch [38/50] batch [40/428] time 0.081 (0.099) data 0.000 (0.016) loss 1.6836 (1.5690) teacher_loss 0.6214 (0.5295) loss_zs_kd 4.7073 (4.4996) loss_oracle 1.0016 (0.9488) kd_loss 1.1227 (1.1301) acc 78.1250 (78.7500) lr 3.6258e-04 eta 0:09:06
epoch [38/50] batch [60/428] time 0.076 (0.093) data 0.001 (0.010) loss 1.6694 (1.5767) teacher_loss 0.6724 (0.5244) loss_zs_kd 4.4873 (4.4854) loss_oracle 0.9171 (0.9588) kd_loss 1.0767 (1.1459) acc 71.8750 (79.0625) lr 3.6258e-04 eta 0:08:31
epoch [38/50] batch [80/428] time 0.089 (0.091) data 0.000 (0.008) loss 1.8269 (1.5871) teacher_loss 0.8196 (0.5381) loss_zs_kd 4.1535 (4.4623) loss_oracle 0.9347 (0.9549) kd_loss 1.0798 (1.1433) acc 59.3750 (78.8281) lr 3.6258e-04 eta 0:08:17
epoch [38/50] batch [100/428] time 0.080 (0.089) data 0.000 (0.006) loss 1.4132 (1.5942) teacher_loss 0.3442 (0.5454) loss_zs_kd 4.2357 (4.4187) loss_oracle 0.9081 (0.9532) kd_loss 1.2299 (1.1446) acc 87.5000 (77.9062) lr 3.6258e-04 eta 0:08:08
epoch [38/50] batch [120/428] time 0.085 (0.088) data 0.000 (0.005) loss 1.5503 (1.5931) teacher_loss 0.4053 (0.5426) loss_zs_kd 4.3236 (4.4092) loss_oracle 1.0642 (0.9552) kd_loss 1.2259 (1.1459) acc 84.3750 (78.0729) lr 3.6258e-04 eta 0:07:59
epoch [38/50] batch [140/428] time 0.085 (0.090) data 0.000 (0.005) loss 1.4993 (1.5928) teacher_loss 0.4213 (0.5414) loss_zs_kd 4.5090 (4.4131) loss_oracle 0.9715 (0.9554) kd_loss 1.1846 (1.1475) acc 84.3750 (78.3259) lr 3.6258e-04 eta 0:08:09
epoch [38/50] batch [160/428] time 0.083 (0.089) data 0.000 (0.004) loss 1.6103 (1.5959) teacher_loss 0.5212 (0.5424) loss_zs_kd 4.6277 (4.4046) loss_oracle 0.9941 (0.9566) kd_loss 1.1841 (1.1503) acc 87.5000 (78.3984) lr 3.6258e-04 eta 0:08:01
epoch [38/50] batch [180/428] time 0.081 (0.088) data 0.000 (0.004) loss 1.7925 (1.5943) teacher_loss 0.6762 (0.5417) loss_zs_kd 4.1755 (4.3891) loss_oracle 1.0355 (0.9571) kd_loss 1.1972 (1.1480) acc 71.8750 (78.5938) lr 3.6258e-04 eta 0:07:55
epoch [38/50] batch [200/428] time 0.086 (0.087) data 0.000 (0.003) loss 1.7370 (1.6014) teacher_loss 0.5017 (0.5475) loss_zs_kd 4.1625 (4.3818) loss_oracle 1.1220 (0.9612) kd_loss 1.3485 (1.1466) acc 87.5000 (78.4531) lr 3.6258e-04 eta 0:07:49
epoch [38/50] batch [220/428] time 0.091 (0.087) data 0.000 (0.003) loss 1.5930 (1.6027) teacher_loss 0.5327 (0.5454) loss_zs_kd 4.7536 (4.3869) loss_oracle 0.9804 (0.9658) kd_loss 1.1401 (1.1487) acc 78.1250 (78.5653) lr 3.6258e-04 eta 0:07:45
epoch [38/50] batch [240/428] time 0.081 (0.087) data 0.000 (0.003) loss 1.6606 (1.6033) teacher_loss 0.6394 (0.5447) loss_zs_kd 4.4018 (4.4007) loss_oracle 0.9550 (0.9679) kd_loss 1.0873 (1.1493) acc 78.1250 (78.5417) lr 3.6258e-04 eta 0:07:41
epoch [38/50] batch [260/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.6024 (1.6036) teacher_loss 0.5048 (0.5434) loss_zs_kd 4.9452 (4.4094) loss_oracle 0.9730 (0.9694) kd_loss 1.2222 (1.1510) acc 84.3750 (78.5577) lr 3.6258e-04 eta 0:07:39
epoch [38/50] batch [280/428] time 0.081 (0.086) data 0.000 (0.003) loss 1.6531 (1.6052) teacher_loss 0.5810 (0.5449) loss_zs_kd 4.7604 (4.4166) loss_oracle 0.9922 (0.9694) kd_loss 1.1520 (1.1512) acc 78.1250 (78.5268) lr 3.6258e-04 eta 0:07:36
epoch [38/50] batch [300/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.5341 (1.6062) teacher_loss 0.3428 (0.5461) loss_zs_kd 4.2346 (4.4212) loss_oracle 1.0431 (0.9692) kd_loss 1.3395 (1.1509) acc 84.3750 (78.3958) lr 3.6258e-04 eta 0:07:34
epoch [38/50] batch [320/428] time 0.096 (0.086) data 0.000 (0.002) loss 1.6962 (1.6032) teacher_loss 0.5683 (0.5430) loss_zs_kd 4.9381 (4.4342) loss_oracle 1.0523 (0.9700) kd_loss 1.2034 (1.1504) acc 78.1250 (78.6621) lr 3.6258e-04 eta 0:07:33
epoch [38/50] batch [340/428] time 0.087 (0.087) data 0.000 (0.002) loss 1.7378 (1.6055) teacher_loss 0.6161 (0.5457) loss_zs_kd 4.5096 (4.4421) loss_oracle 1.0690 (0.9703) kd_loss 1.1745 (1.1492) acc 75.0000 (78.6581) lr 3.6258e-04 eta 0:07:32
epoch [38/50] batch [360/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.6776 (1.6080) teacher_loss 0.5869 (0.5486) loss_zs_kd 4.5980 (4.4491) loss_oracle 0.9664 (0.9702) kd_loss 1.2152 (1.1484) acc 87.5000 (78.5851) lr 3.6258e-04 eta 0:07:29
epoch [38/50] batch [380/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.8148 (1.6092) teacher_loss 0.7726 (0.5505) loss_zs_kd 4.4017 (4.4512) loss_oracle 0.9745 (0.9698) kd_loss 1.1099 (1.1474) acc 65.6250 (78.5197) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [400/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.5605 (1.6126) teacher_loss 0.4284 (0.5530) loss_zs_kd 4.7582 (4.4590) loss_oracle 1.0022 (0.9715) kd_loss 1.2620 (1.1475) acc 81.2500 (78.4141) lr 3.6258e-04 eta 0:07:26
epoch [38/50] batch [420/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.5316 (1.6123) teacher_loss 0.4192 (0.5510) loss_zs_kd 4.3541 (4.4623) loss_oracle 0.9600 (0.9728) kd_loss 1.2647 (1.1497) acc 90.6250 (78.5268) lr 3.6258e-04 eta 0:07:23
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,298
* accuracy: 56.1%
* error: 43.9%
* macro_f1: 37.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,942
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 20.1%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [39/50] batch [20/428] time 0.087 (0.118) data 0.000 (0.033) loss 1.5654 (1.5860) teacher_loss 0.4474 (0.5050) loss_zs_kd 4.6091 (4.6009) loss_oracle 1.0200 (0.9873) kd_loss 1.2159 (1.1747) acc 81.2500 (79.0625) lr 3.1545e-04 eta 0:10:02
epoch [39/50] batch [40/428] time 0.081 (0.101) data 0.000 (0.017) loss 1.7412 (1.6282) teacher_loss 0.5107 (0.5552) loss_zs_kd 4.6647 (4.5633) loss_oracle 1.0778 (0.9842) kd_loss 1.3831 (1.1616) acc 75.0000 (78.2031) lr 3.1545e-04 eta 0:08:34
epoch [39/50] batch [60/428] time 0.085 (0.094) data 0.001 (0.011) loss 1.5311 (1.6205) teacher_loss 0.5447 (0.5473) loss_zs_kd 4.2215 (4.5333) loss_oracle 0.9322 (0.9837) kd_loss 1.0406 (1.1628) acc 81.2500 (77.9688) lr 3.1545e-04 eta 0:07:59
epoch [39/50] batch [80/428] time 0.084 (0.091) data 0.000 (0.009) loss 1.6889 (1.6330) teacher_loss 0.7088 (0.5570) loss_zs_kd 4.8361 (4.5377) loss_oracle 0.9190 (0.9879) kd_loss 1.0411 (1.1641) acc 75.0000 (77.6953) lr 3.1545e-04 eta 0:07:41
epoch [39/50] batch [100/428] time 0.085 (0.089) data 0.000 (0.007) loss 1.4860 (1.6333) teacher_loss 0.4029 (0.5567) loss_zs_kd 4.2334 (4.5279) loss_oracle 1.0080 (0.9900) kd_loss 1.1583 (1.1632) acc 87.5000 (78.0312) lr 3.1545e-04 eta 0:07:30
epoch [39/50] batch [120/428] time 0.082 (0.089) data 0.000 (0.006) loss 1.7379 (1.6341) teacher_loss 0.7105 (0.5590) loss_zs_kd 4.4524 (4.5117) loss_oracle 0.9759 (0.9887) kd_loss 1.0791 (1.1616) acc 71.8750 (77.7604) lr 3.1545e-04 eta 0:07:25
epoch [39/50] batch [140/428] time 0.078 (0.087) data 0.000 (0.005) loss 1.7240 (1.6274) teacher_loss 0.6908 (0.5563) loss_zs_kd 4.3006 (4.4939) loss_oracle 0.9290 (0.9839) kd_loss 1.1376 (1.1584) acc 71.8750 (77.8125) lr 3.1545e-04 eta 0:07:16
epoch [39/50] batch [160/428] time 0.082 (0.087) data 0.000 (0.004) loss 1.5221 (1.6205) teacher_loss 0.5980 (0.5532) loss_zs_kd 4.3681 (4.4865) loss_oracle 0.8826 (0.9800) kd_loss 0.9657 (1.1546) acc 81.2500 (78.3203) lr 3.1545e-04 eta 0:07:10
epoch [39/50] batch [180/428] time 0.083 (0.086) data 0.000 (0.004) loss 1.5708 (1.6145) teacher_loss 0.4927 (0.5499) loss_zs_kd 3.9323 (4.4524) loss_oracle 0.9156 (0.9758) kd_loss 1.2405 (1.1534) acc 78.1250 (78.6458) lr 3.1545e-04 eta 0:07:05
epoch [39/50] batch [200/428] time 0.077 (0.085) data 0.000 (0.004) loss 1.6934 (1.6100) teacher_loss 0.6299 (0.5476) loss_zs_kd 4.3583 (4.4273) loss_oracle 0.9824 (0.9721) kd_loss 1.1446 (1.1529) acc 81.2500 (79.0000) lr 3.1545e-04 eta 0:07:00
epoch [39/50] batch [220/428] time 0.085 (0.085) data 0.000 (0.003) loss 1.5528 (1.6113) teacher_loss 0.4476 (0.5507) loss_zs_kd 4.1087 (4.3890) loss_oracle 0.9697 (0.9694) kd_loss 1.2407 (1.1519) acc 78.1250 (78.9062) lr 3.1545e-04 eta 0:06:58
epoch [39/50] batch [240/428] time 0.089 (0.085) data 0.000 (0.003) loss 1.8767 (1.6112) teacher_loss 0.8553 (0.5517) loss_zs_kd 3.9721 (4.3579) loss_oracle 0.9849 (0.9674) kd_loss 1.0581 (1.1515) acc 71.8750 (79.0495) lr 3.1545e-04 eta 0:06:57
epoch [39/50] batch [260/428] time 0.075 (0.087) data 0.000 (0.003) loss 1.7433 (1.6093) teacher_loss 0.6758 (0.5525) loss_zs_kd 4.0981 (4.3359) loss_oracle 0.9158 (0.9646) kd_loss 1.2193 (1.1490) acc 75.0000 (79.0264) lr 3.1545e-04 eta 0:07:02
epoch [39/50] batch [280/428] time 0.084 (0.086) data 0.000 (0.003) loss 1.5959 (1.6063) teacher_loss 0.5329 (0.5521) loss_zs_kd 4.3295 (4.3223) loss_oracle 0.9517 (0.9632) kd_loss 1.1744 (1.1453) acc 81.2500 (79.1183) lr 3.1545e-04 eta 0:06:59
epoch [39/50] batch [300/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.7274 (1.6095) teacher_loss 0.6730 (0.5594) loss_zs_kd 4.1323 (4.3060) loss_oracle 0.9856 (0.9597) kd_loss 1.1233 (1.1406) acc 68.7500 (78.8854) lr 3.1545e-04 eta 0:06:56
epoch [39/50] batch [320/428] time 0.077 (0.086) data 0.000 (0.002) loss 1.5624 (1.6088) teacher_loss 0.5789 (0.5615) loss_zs_kd 3.3841 (4.2911) loss_oracle 0.8680 (0.9571) kd_loss 1.0990 (1.1374) acc 81.2500 (78.8184) lr 3.1545e-04 eta 0:06:53
epoch [39/50] batch [340/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.6765 (1.6098) teacher_loss 0.6649 (0.5659) loss_zs_kd 4.7666 (4.2863) loss_oracle 0.9309 (0.9538) kd_loss 1.0923 (1.1339) acc 71.8750 (78.5662) lr 3.1545e-04 eta 0:06:50
epoch [39/50] batch [360/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.5984 (1.6053) teacher_loss 0.6904 (0.5662) loss_zs_kd 4.0258 (4.2819) loss_oracle 0.8892 (0.9499) kd_loss 0.9269 (1.1284) acc 78.1250 (78.5069) lr 3.1545e-04 eta 0:06:48
epoch [39/50] batch [380/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.5391 (1.6040) teacher_loss 0.5544 (0.5684) loss_zs_kd 4.5230 (4.2698) loss_oracle 0.8974 (0.9464) kd_loss 1.0720 (1.1247) acc 81.2500 (78.4293) lr 3.1545e-04 eta 0:06:46
epoch [39/50] batch [400/428] time 0.087 (0.085) data 0.000 (0.002) loss 1.6292 (1.6049) teacher_loss 0.5500 (0.5721) loss_zs_kd 4.3261 (4.2732) loss_oracle 1.0042 (0.9440) kd_loss 1.1542 (1.1215) acc 75.0000 (78.2578) lr 3.1545e-04 eta 0:06:44
epoch [39/50] batch [420/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.8123 (1.6067) teacher_loss 0.9135 (0.5774) loss_zs_kd 4.4450 (4.2701) loss_oracle 0.8368 (0.9420) kd_loss 0.9608 (1.1165) acc 59.3750 (77.9390) lr 3.1545e-04 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,319
* accuracy: 56.5%
* error: 43.5%
* macro_f1: 37.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,413
* accuracy: 29.8%
* error: 70.2%
* macro_f1: 15.2%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [40/50] batch [20/428] time 0.082 (0.135) data 0.000 (0.033) loss 1.6512 (1.5341) teacher_loss 0.7140 (0.5591) loss_zs_kd 4.0584 (4.3355) loss_oracle 0.8916 (0.9125) kd_loss 0.9827 (1.0376) acc 75.0000 (80.6250) lr 2.7103e-04 eta 0:10:33
epoch [40/50] batch [40/428] time 0.077 (0.107) data 0.000 (0.017) loss 1.7342 (1.5245) teacher_loss 0.7617 (0.5486) loss_zs_kd 4.0163 (4.3849) loss_oracle 0.9203 (0.9151) kd_loss 1.0247 (1.0366) acc 68.7500 (80.7031) lr 2.7103e-04 eta 0:08:17
epoch [40/50] batch [60/428] time 0.082 (0.097) data 0.001 (0.011) loss 1.6034 (1.5394) teacher_loss 0.6633 (0.5730) loss_zs_kd 3.8603 (4.3624) loss_oracle 0.9523 (0.9114) kd_loss 0.9279 (1.0215) acc 75.0000 (78.8542) lr 2.7103e-04 eta 0:07:31
epoch [40/50] batch [80/428] time 0.088 (0.095) data 0.000 (0.009) loss 1.5278 (1.5377) teacher_loss 0.6363 (0.5785) loss_zs_kd 5.2285 (4.3850) loss_oracle 0.8148 (0.9055) kd_loss 0.9683 (1.0128) acc 71.8750 (79.1016) lr 2.7103e-04 eta 0:07:17
epoch [40/50] batch [100/428] time 0.083 (0.092) data 0.000 (0.007) loss 1.5232 (1.5344) teacher_loss 0.5576 (0.5759) loss_zs_kd 4.3711 (4.3702) loss_oracle 0.8941 (0.9061) kd_loss 1.0371 (1.0109) acc 78.1250 (79.0000) lr 2.7103e-04 eta 0:07:04
epoch [40/50] batch [120/428] time 0.083 (0.090) data 0.000 (0.006) loss 1.4530 (1.5333) teacher_loss 0.5328 (0.5735) loss_zs_kd 4.4726 (4.3677) loss_oracle 0.8449 (0.9056) kd_loss 0.9953 (1.0139) acc 75.0000 (78.8281) lr 2.7103e-04 eta 0:06:54
epoch [40/50] batch [140/428] time 0.081 (0.089) data 0.000 (0.005) loss 1.5528 (1.5330) teacher_loss 0.6187 (0.5721) loss_zs_kd 4.5534 (4.3717) loss_oracle 0.8154 (0.9037) kd_loss 1.0527 (1.0181) acc 78.1250 (78.9286) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [160/428] time 0.085 (0.089) data 0.000 (0.004) loss 1.7907 (1.5419) teacher_loss 0.8956 (0.5808) loss_zs_kd 4.7036 (4.3822) loss_oracle 0.8403 (0.9020) kd_loss 0.9501 (1.0202) acc 71.8750 (78.7891) lr 2.7103e-04 eta 0:06:43
epoch [40/50] batch [180/428] time 0.082 (0.088) data 0.000 (0.004) loss 1.6153 (1.5444) teacher_loss 0.5732 (0.5779) loss_zs_kd 4.3297 (4.4037) loss_oracle 0.8946 (0.9055) kd_loss 1.1897 (1.0275) acc 78.1250 (78.7500) lr 2.7103e-04 eta 0:06:39
epoch [40/50] batch [200/428] time 0.079 (0.087) data 0.000 (0.004) loss 1.6491 (1.5470) teacher_loss 0.7339 (0.5792) loss_zs_kd 4.5655 (4.4087) loss_oracle 0.8482 (0.9054) kd_loss 0.9822 (1.0303) acc 68.7500 (78.7031) lr 2.7103e-04 eta 0:06:33
epoch [40/50] batch [220/428] time 0.079 (0.086) data 0.000 (0.003) loss 1.5226 (1.5480) teacher_loss 0.5063 (0.5789) loss_zs_kd 4.6532 (4.4240) loss_oracle 0.9468 (0.9061) kd_loss 1.0859 (1.0322) acc 93.7500 (78.6222) lr 2.7103e-04 eta 0:06:28
epoch [40/50] batch [240/428] time 0.081 (0.086) data 0.000 (0.003) loss 1.5732 (1.5471) teacher_loss 0.6075 (0.5772) loss_zs_kd 4.1181 (4.4337) loss_oracle 0.8539 (0.9058) kd_loss 1.0774 (1.0340) acc 75.0000 (78.6328) lr 2.7103e-04 eta 0:06:23
epoch [40/50] batch [260/428] time 0.076 (0.086) data 0.000 (0.003) loss 1.6113 (1.5495) teacher_loss 0.5987 (0.5780) loss_zs_kd 3.9044 (4.4520) loss_oracle 0.9137 (0.9065) kd_loss 1.1116 (1.0366) acc 78.1250 (78.6899) lr 2.7103e-04 eta 0:06:20
epoch [40/50] batch [280/428] time 0.084 (0.085) data 0.000 (0.003) loss 1.3824 (1.5513) teacher_loss 0.4623 (0.5786) loss_zs_kd 4.4340 (4.4597) loss_oracle 0.9008 (0.9065) kd_loss 0.9393 (1.0389) acc 81.2500 (78.5826) lr 2.7103e-04 eta 0:06:18
epoch [40/50] batch [300/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.8395 (1.5557) teacher_loss 0.8956 (0.5819) loss_zs_kd 4.0877 (4.4652) loss_oracle 0.8811 (0.9067) kd_loss 1.0068 (1.0410) acc 59.3750 (78.3646) lr 2.7103e-04 eta 0:06:15
epoch [40/50] batch [320/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.5601 (1.5544) teacher_loss 0.5825 (0.5793) loss_zs_kd 4.6705 (4.4727) loss_oracle 0.8823 (0.9060) kd_loss 1.0730 (1.0443) acc 81.2500 (78.4570) lr 2.7103e-04 eta 0:06:13
epoch [40/50] batch [340/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.5027 (1.5562) teacher_loss 0.4810 (0.5795) loss_zs_kd 4.7586 (4.4751) loss_oracle 0.9535 (0.9071) kd_loss 1.0898 (1.0463) acc 81.2500 (78.4651) lr 2.7103e-04 eta 0:06:10
epoch [40/50] batch [360/428] time 0.077 (0.084) data 0.000 (0.002) loss 1.5875 (1.5542) teacher_loss 0.6106 (0.5758) loss_zs_kd 4.7816 (4.4832) loss_oracle 0.8741 (0.9080) kd_loss 1.0797 (1.0486) acc 78.1250 (78.5677) lr 2.7103e-04 eta 0:06:07
epoch [40/50] batch [380/428] time 0.077 (0.084) data 0.000 (0.002) loss 1.6178 (1.5530) teacher_loss 0.6189 (0.5739) loss_zs_kd 4.7112 (4.4880) loss_oracle 0.9722 (0.9085) kd_loss 1.0256 (1.0498) acc 71.8750 (78.5691) lr 2.7103e-04 eta 0:06:03
epoch [40/50] batch [400/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.5271 (1.5537) teacher_loss 0.5449 (0.5730) loss_zs_kd 4.7055 (4.4912) loss_oracle 0.8733 (0.9095) kd_loss 1.0910 (1.0517) acc 78.1250 (78.5000) lr 2.7103e-04 eta 0:06:01
epoch [40/50] batch [420/428] time 0.066 (0.085) data 0.000 (0.002) loss 1.7871 (1.5538) teacher_loss 0.7842 (0.5719) loss_zs_kd 4.1572 (4.4972) loss_oracle 0.9238 (0.9096) kd_loss 1.0819 (1.0542) acc 65.6250 (78.5863) lr 2.7103e-04 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,352
* accuracy: 57.0%
* error: 43.0%
* macro_f1: 37.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,434
* accuracy: 30.2%
* error: 69.8%
* macro_f1: 15.3%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [41/50] batch [20/428] time 0.086 (0.124) data 0.000 (0.036) loss 1.4883 (1.5492) teacher_loss 0.4387 (0.5259) loss_zs_kd 4.6095 (4.6003) loss_oracle 0.9078 (0.9490) kd_loss 1.1915 (1.0975) acc 78.1250 (80.9375) lr 2.2949e-04 eta 0:08:49
epoch [41/50] batch [40/428] time 0.089 (0.104) data 0.000 (0.018) loss 1.5381 (1.5534) teacher_loss 0.5245 (0.5322) loss_zs_kd 5.2039 (4.6237) loss_oracle 0.9226 (0.9398) kd_loss 1.1046 (1.1027) acc 78.1250 (80.0000) lr 2.2949e-04 eta 0:07:20
epoch [41/50] batch [60/428] time 0.065 (0.095) data 0.000 (0.012) loss 1.3790 (1.5626) teacher_loss 0.3292 (0.5482) loss_zs_kd 4.5689 (4.6473) loss_oracle 0.9528 (0.9352) kd_loss 1.1469 (1.0937) acc 90.6250 (79.3229) lr 2.2949e-04 eta 0:06:41
epoch [41/50] batch [80/428] time 0.072 (0.091) data 0.000 (0.009) loss 1.7048 (1.5631) teacher_loss 0.6738 (0.5494) loss_zs_kd 4.9588 (4.6671) loss_oracle 0.9103 (0.9341) kd_loss 1.1517 (1.0933) acc 71.8750 (79.6094) lr 2.2949e-04 eta 0:06:20
epoch [41/50] batch [100/428] time 0.060 (0.086) data 0.000 (0.007) loss 1.5866 (1.5614) teacher_loss 0.5991 (0.5517) loss_zs_kd 4.5278 (4.6597) loss_oracle 0.8876 (0.9306) kd_loss 1.0873 (1.0888) acc 71.8750 (79.4688) lr 2.2949e-04 eta 0:05:59
epoch [41/50] batch [120/428] time 0.086 (0.084) data 0.000 (0.006) loss 1.3876 (1.5654) teacher_loss 0.3971 (0.5584) loss_zs_kd 4.5516 (4.6345) loss_oracle 0.8706 (0.9281) kd_loss 1.1104 (1.0859) acc 90.6250 (79.2448) lr 2.2949e-04 eta 0:05:50
epoch [41/50] batch [140/428] time 0.083 (0.084) data 0.000 (0.005) loss 1.6536 (1.5635) teacher_loss 0.7108 (0.5603) loss_zs_kd 5.1981 (4.6433) loss_oracle 0.8464 (0.9231) kd_loss 1.0392 (1.0834) acc 71.8750 (78.9062) lr 2.2949e-04 eta 0:05:49
epoch [41/50] batch [160/428] time 0.135 (0.087) data 0.001 (0.005) loss 1.6489 (1.5688) teacher_loss 0.6047 (0.5618) loss_zs_kd 4.8388 (4.6388) loss_oracle 0.9660 (0.9259) kd_loss 1.1226 (1.0880) acc 68.7500 (78.9453) lr 2.2949e-04 eta 0:05:58
epoch [41/50] batch [180/428] time 0.089 (0.086) data 0.000 (0.004) loss 1.4413 (1.5640) teacher_loss 0.4731 (0.5562) loss_zs_kd 4.4887 (4.6364) loss_oracle 0.9080 (0.9252) kd_loss 1.0284 (1.0904) acc 81.2500 (79.1840) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [200/428] time 0.085 (0.086) data 0.000 (0.004) loss 1.4439 (1.5630) teacher_loss 0.4387 (0.5548) loss_zs_kd 4.7530 (4.6249) loss_oracle 0.9114 (0.9244) kd_loss 1.0991 (1.0920) acc 84.3750 (79.3594) lr 2.2949e-04 eta 0:05:49
epoch [41/50] batch [220/428] time 0.080 (0.085) data 0.000 (0.004) loss 1.7702 (1.5662) teacher_loss 0.7653 (0.5580) loss_zs_kd 4.8535 (4.6277) loss_oracle 0.9409 (0.9258) kd_loss 1.0687 (1.0907) acc 71.8750 (79.3466) lr 2.2949e-04 eta 0:05:46
epoch [41/50] batch [240/428] time 0.085 (0.085) data 0.000 (0.003) loss 1.4337 (1.5655) teacher_loss 0.2834 (0.5561) loss_zs_kd 4.7585 (4.6292) loss_oracle 1.0165 (0.9266) kd_loss 1.2840 (1.0922) acc 87.5000 (79.3099) lr 2.2949e-04 eta 0:05:44
epoch [41/50] batch [260/428] time 0.077 (0.085) data 0.000 (0.003) loss 1.5817 (1.5641) teacher_loss 0.5307 (0.5548) loss_zs_kd 4.6784 (4.6320) loss_oracle 0.9410 (0.9265) kd_loss 1.1610 (1.0922) acc 84.3750 (79.3990) lr 2.2949e-04 eta 0:05:43
epoch [41/50] batch [280/428] time 0.077 (0.085) data 0.000 (0.003) loss 1.6389 (1.5645) teacher_loss 0.6419 (0.5552) loss_zs_kd 4.3267 (4.6171) loss_oracle 0.9029 (0.9261) kd_loss 1.0911 (1.0926) acc 71.8750 (79.4978) lr 2.2949e-04 eta 0:05:40
epoch [41/50] batch [300/428] time 0.076 (0.085) data 0.000 (0.003) loss 1.8041 (1.5628) teacher_loss 0.8129 (0.5548) loss_zs_kd 4.4382 (4.6139) loss_oracle 0.8962 (0.9239) kd_loss 1.0861 (1.0922) acc 59.3750 (79.4271) lr 2.2949e-04 eta 0:05:36
epoch [41/50] batch [320/428] time 0.083 (0.084) data 0.000 (0.003) loss 1.5293 (1.5628) teacher_loss 0.5514 (0.5530) loss_zs_kd 4.5631 (4.6074) loss_oracle 0.9104 (0.9261) kd_loss 1.0454 (1.0934) acc 84.3750 (79.5801) lr 2.2949e-04 eta 0:05:33
epoch [41/50] batch [340/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.6401 (1.5626) teacher_loss 0.5891 (0.5531) loss_zs_kd 4.5410 (4.6078) loss_oracle 0.9101 (0.9249) kd_loss 1.1918 (1.0943) acc 75.0000 (79.5772) lr 2.2949e-04 eta 0:05:32
epoch [41/50] batch [360/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.4402 (1.5600) teacher_loss 0.3831 (0.5509) loss_zs_kd 3.8960 (4.5970) loss_oracle 0.9696 (0.9236) kd_loss 1.1447 (1.0946) acc 90.6250 (79.6615) lr 2.2949e-04 eta 0:05:29
epoch [41/50] batch [380/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.5069 (1.5590) teacher_loss 0.5218 (0.5486) loss_zs_kd 4.0947 (4.5962) loss_oracle 0.8800 (0.9235) kd_loss 1.0901 (1.0972) acc 71.8750 (79.7451) lr 2.2949e-04 eta 0:05:27
epoch [41/50] batch [400/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.4928 (1.5597) teacher_loss 0.4680 (0.5498) loss_zs_kd 4.8350 (4.5913) loss_oracle 0.9040 (0.9226) kd_loss 1.1454 (1.0973) acc 81.2500 (79.7266) lr 2.2949e-04 eta 0:05:26
epoch [41/50] batch [420/428] time 0.080 (0.084) data 0.000 (0.002) loss 1.4714 (1.5623) teacher_loss 0.4290 (0.5523) loss_zs_kd 5.0320 (4.5973) loss_oracle 0.9192 (0.9224) kd_loss 1.1654 (1.0976) acc 81.2500 (79.6057) lr 2.2949e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,365
* accuracy: 57.3%
* error: 42.7%
* macro_f1: 37.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,472
* accuracy: 31.0%
* error: 69.0%
* macro_f1: 15.5%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [42/50] batch [20/428] time 0.072 (0.118) data 0.000 (0.031) loss 1.5484 (1.5349) teacher_loss 0.5174 (0.5085) loss_zs_kd 3.7364 (4.6352) loss_oracle 0.9164 (0.9238) kd_loss 1.1456 (1.1290) acc 84.3750 (80.7812) lr 1.9098e-04 eta 0:07:31
epoch [42/50] batch [40/428] time 0.083 (0.099) data 0.000 (0.016) loss 1.5942 (1.5613) teacher_loss 0.5690 (0.5353) loss_zs_kd 4.8373 (4.5509) loss_oracle 0.9244 (0.9238) kd_loss 1.1259 (1.1282) acc 81.2500 (80.0781) lr 1.9098e-04 eta 0:06:15
epoch [42/50] batch [60/428] time 0.090 (0.094) data 0.000 (0.011) loss 1.6873 (1.5631) teacher_loss 0.7824 (0.5332) loss_zs_kd 4.2260 (4.5693) loss_oracle 0.8796 (0.9319) kd_loss 0.9303 (1.1280) acc 65.6250 (79.8438) lr 1.9098e-04 eta 0:05:56
epoch [42/50] batch [80/428] time 0.074 (0.091) data 0.000 (0.008) loss 1.3736 (1.5701) teacher_loss 0.3611 (0.5371) loss_zs_kd 4.7642 (4.5764) loss_oracle 0.8944 (0.9336) kd_loss 1.1307 (1.1324) acc 87.5000 (79.9219) lr 1.9098e-04 eta 0:05:41
epoch [42/50] batch [100/428] time 0.092 (0.089) data 0.000 (0.007) loss 1.4663 (1.5723) teacher_loss 0.4908 (0.5388) loss_zs_kd 4.5797 (4.5794) loss_oracle 0.9231 (0.9352) kd_loss 1.0279 (1.1317) acc 81.2500 (79.8125) lr 1.9098e-04 eta 0:05:33
epoch [42/50] batch [120/428] time 0.086 (0.088) data 0.000 (0.006) loss 1.5859 (1.5737) teacher_loss 0.5822 (0.5425) loss_zs_kd 3.8463 (4.5755) loss_oracle 0.9472 (0.9333) kd_loss 1.0601 (1.1290) acc 84.3750 (79.7396) lr 1.9098e-04 eta 0:05:28
epoch [42/50] batch [140/428] time 0.082 (0.088) data 0.000 (0.005) loss 1.7041 (1.5762) teacher_loss 0.6719 (0.5435) loss_zs_kd 4.6216 (4.5767) loss_oracle 0.9786 (0.9351) kd_loss 1.0858 (1.1302) acc 71.8750 (79.7991) lr 1.9098e-04 eta 0:05:26
epoch [42/50] batch [160/428] time 0.089 (0.087) data 0.000 (0.004) loss 1.5630 (1.5762) teacher_loss 0.5713 (0.5445) loss_zs_kd 4.3159 (4.5784) loss_oracle 0.9342 (0.9360) kd_loss 1.0491 (1.1274) acc 75.0000 (79.6680) lr 1.9098e-04 eta 0:05:22
epoch [42/50] batch [180/428] time 0.084 (0.087) data 0.001 (0.004) loss 1.5636 (1.5734) teacher_loss 0.5268 (0.5447) loss_zs_kd 4.5024 (4.5723) loss_oracle 0.9174 (0.9352) kd_loss 1.1562 (1.1221) acc 71.8750 (79.5833) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [200/428] time 0.075 (0.087) data 0.000 (0.003) loss 1.4450 (1.5681) teacher_loss 0.4032 (0.5401) loss_zs_kd 3.7485 (4.5640) loss_oracle 1.0009 (0.9321) kd_loss 1.0826 (1.1237) acc 84.3750 (79.7969) lr 1.9098e-04 eta 0:05:16
epoch [42/50] batch [220/428] time 0.088 (0.086) data 0.000 (0.003) loss 1.5739 (1.5722) teacher_loss 0.4413 (0.5449) loss_zs_kd 4.1766 (4.5595) loss_oracle 0.9980 (0.9313) kd_loss 1.2672 (1.1233) acc 81.2500 (79.6733) lr 1.9098e-04 eta 0:05:13
epoch [42/50] batch [240/428] time 0.082 (0.086) data 0.000 (0.003) loss 1.5392 (1.5727) teacher_loss 0.5271 (0.5472) loss_zs_kd 4.1505 (4.5520) loss_oracle 0.9647 (0.9303) kd_loss 1.0594 (1.1208) acc 78.1250 (79.4531) lr 1.9098e-04 eta 0:05:11
epoch [42/50] batch [260/428] time 0.089 (0.086) data 0.001 (0.003) loss 1.3908 (1.5698) teacher_loss 0.3877 (0.5447) loss_zs_kd 3.9059 (4.5386) loss_oracle 0.8653 (0.9278) kd_loss 1.1410 (1.1224) acc 84.3750 (79.4351) lr 1.9098e-04 eta 0:05:10
epoch [42/50] batch [280/428] time 0.080 (0.086) data 0.000 (0.003) loss 1.6733 (1.5708) teacher_loss 0.6223 (0.5467) loss_zs_kd 4.5497 (4.5269) loss_oracle 0.9418 (0.9266) kd_loss 1.1601 (1.1215) acc 65.6250 (79.1071) lr 1.9098e-04 eta 0:05:07
epoch [42/50] batch [300/428] time 0.142 (0.087) data 0.001 (0.002) loss 1.5589 (1.5714) teacher_loss 0.6040 (0.5480) loss_zs_kd 3.7490 (4.5134) loss_oracle 0.8543 (0.9254) kd_loss 1.0554 (1.1215) acc 75.0000 (79.0208) lr 1.9098e-04 eta 0:05:08
epoch [42/50] batch [320/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.6386 (1.5742) teacher_loss 0.6093 (0.5498) loss_zs_kd 4.3184 (4.4942) loss_oracle 0.9435 (0.9248) kd_loss 1.1152 (1.1240) acc 81.2500 (78.8672) lr 1.9098e-04 eta 0:05:07
epoch [42/50] batch [340/428] time 0.077 (0.087) data 0.000 (0.002) loss 1.5439 (1.5780) teacher_loss 0.4975 (0.5544) loss_zs_kd 4.1388 (4.4699) loss_oracle 0.9217 (0.9242) kd_loss 1.1712 (1.1230) acc 78.1250 (78.6673) lr 1.9098e-04 eta 0:05:04
epoch [42/50] batch [360/428] time 0.088 (0.086) data 0.000 (0.002) loss 1.5641 (1.5779) teacher_loss 0.5541 (0.5550) loss_zs_kd 3.7691 (4.4427) loss_oracle 0.8930 (0.9231) kd_loss 1.1270 (1.1226) acc 75.0000 (78.7413) lr 1.9098e-04 eta 0:05:01
epoch [42/50] batch [380/428] time 0.087 (0.086) data 0.000 (0.002) loss 1.5676 (1.5778) teacher_loss 0.5335 (0.5538) loss_zs_kd 3.7627 (4.4049) loss_oracle 0.9318 (0.9229) kd_loss 1.1362 (1.1250) acc 68.7500 (78.7911) lr 1.9098e-04 eta 0:04:58
epoch [42/50] batch [400/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.5030 (1.5761) teacher_loss 0.5058 (0.5528) loss_zs_kd 3.7355 (4.3714) loss_oracle 0.8580 (0.9223) kd_loss 1.1365 (1.1243) acc 78.1250 (78.8906) lr 1.9098e-04 eta 0:04:56
epoch [42/50] batch [420/428] time 0.077 (0.085) data 0.000 (0.002) loss 1.5837 (1.5773) teacher_loss 0.6505 (0.5540) loss_zs_kd 3.3118 (4.3365) loss_oracle 0.9325 (0.9238) kd_loss 0.9338 (1.1229) acc 71.8750 (78.8244) lr 1.9098e-04 eta 0:04:53
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,220
* accuracy: 54.8%
* error: 45.2%
* macro_f1: 36.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,297
* accuracy: 48.4%
* error: 51.6%
* macro_f1: 21.4%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [43/50] batch [20/428] time 0.083 (0.113) data 0.000 (0.030) loss 1.5770 (1.6264) teacher_loss 0.4610 (0.5755) loss_zs_kd 3.7402 (3.6207) loss_oracle 1.1104 (0.9927) kd_loss 1.1215 (1.1092) acc 75.0000 (76.7188) lr 1.5567e-04 eta 0:06:23
epoch [43/50] batch [40/428] time 0.071 (0.107) data 0.000 (0.015) loss 1.8455 (1.6024) teacher_loss 0.7691 (0.5619) loss_zs_kd 3.7936 (3.6079) loss_oracle 1.0048 (0.9730) kd_loss 1.1479 (1.1080) acc 75.0000 (77.4219) lr 1.5567e-04 eta 0:06:01
epoch [43/50] batch [60/428] time 0.076 (0.096) data 0.001 (0.010) loss 1.5309 (1.5840) teacher_loss 0.5638 (0.5445) loss_zs_kd 3.3961 (3.6068) loss_oracle 0.8880 (0.9714) kd_loss 1.0462 (1.1077) acc 81.2500 (78.1771) lr 1.5567e-04 eta 0:05:22
epoch [43/50] batch [80/428] time 0.074 (0.092) data 0.000 (0.008) loss 1.7867 (1.5862) teacher_loss 0.7531 (0.5586) loss_zs_kd 3.7511 (3.6112) loss_oracle 0.9813 (0.9601) kd_loss 1.0858 (1.0950) acc 75.0000 (77.5391) lr 1.5567e-04 eta 0:05:08
epoch [43/50] batch [100/428] time 0.073 (0.090) data 0.000 (0.006) loss 1.4894 (1.5818) teacher_loss 0.5808 (0.5576) loss_zs_kd 3.6216 (3.5990) loss_oracle 0.8448 (0.9556) kd_loss 0.9724 (1.0928) acc 78.1250 (77.8750) lr 1.5567e-04 eta 0:04:58
epoch [43/50] batch [120/428] time 0.082 (0.089) data 0.000 (0.005) loss 1.5464 (1.5811) teacher_loss 0.5313 (0.5619) loss_zs_kd 3.2708 (3.5943) loss_oracle 0.9654 (0.9504) kd_loss 1.0647 (1.0879) acc 78.1250 (77.8385) lr 1.5567e-04 eta 0:04:53
epoch [43/50] batch [140/428] time 0.083 (0.088) data 0.000 (0.005) loss 1.6062 (1.5796) teacher_loss 0.6023 (0.5602) loss_zs_kd 3.6232 (3.5849) loss_oracle 0.9838 (0.9496) kd_loss 1.0242 (1.0892) acc 75.0000 (78.0580) lr 1.5567e-04 eta 0:04:48
epoch [43/50] batch [160/428] time 0.090 (0.088) data 0.000 (0.004) loss 1.5520 (1.5773) teacher_loss 0.6252 (0.5599) loss_zs_kd 3.6960 (3.5901) loss_oracle 0.8746 (0.9460) kd_loss 0.9789 (1.0888) acc 78.1250 (78.3398) lr 1.5567e-04 eta 0:04:46
epoch [43/50] batch [180/428] time 0.083 (0.087) data 0.000 (0.004) loss 1.4052 (1.5798) teacher_loss 0.3896 (0.5626) loss_zs_kd 3.3983 (3.5787) loss_oracle 0.9383 (0.9466) kd_loss 1.0928 (1.0878) acc 81.2500 (78.0556) lr 1.5567e-04 eta 0:04:43
epoch [43/50] batch [200/428] time 0.088 (0.087) data 0.000 (0.003) loss 1.6378 (1.5774) teacher_loss 0.6847 (0.5622) loss_zs_kd 3.6849 (3.5886) loss_oracle 0.9108 (0.9441) kd_loss 0.9954 (1.0864) acc 84.3750 (77.9688) lr 1.5567e-04 eta 0:04:41
epoch [43/50] batch [220/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.6441 (1.5797) teacher_loss 0.5374 (0.5634) loss_zs_kd 3.5932 (3.5896) loss_oracle 1.0119 (0.9440) kd_loss 1.2014 (1.0887) acc 81.2500 (78.1676) lr 1.5567e-04 eta 0:04:38
epoch [43/50] batch [240/428] time 0.097 (0.087) data 0.001 (0.003) loss 1.3858 (1.5759) teacher_loss 0.4483 (0.5608) loss_zs_kd 3.5772 (3.5857) loss_oracle 0.8499 (0.9421) kd_loss 1.0250 (1.0881) acc 84.3750 (78.3073) lr 1.5567e-04 eta 0:04:35
epoch [43/50] batch [260/428] time 0.077 (0.086) data 0.000 (0.003) loss 1.5766 (1.5787) teacher_loss 0.6250 (0.5646) loss_zs_kd 3.3135 (3.5832) loss_oracle 0.9097 (0.9404) kd_loss 0.9936 (1.0878) acc 75.0000 (78.3053) lr 1.5567e-04 eta 0:04:33
epoch [43/50] batch [280/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.6249 (1.5803) teacher_loss 0.5238 (0.5676) loss_zs_kd 3.3134 (3.5848) loss_oracle 1.0140 (0.9382) kd_loss 1.1881 (1.0871) acc 81.2500 (78.1808) lr 1.5567e-04 eta 0:04:30
epoch [43/50] batch [300/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.5598 (1.5846) teacher_loss 0.6056 (0.5705) loss_zs_kd 3.5493 (3.5843) loss_oracle 0.8942 (0.9399) kd_loss 1.0141 (1.0883) acc 75.0000 (78.1562) lr 1.5567e-04 eta 0:04:28
epoch [43/50] batch [320/428] time 0.077 (0.086) data 0.000 (0.002) loss 1.7291 (1.5867) teacher_loss 0.7683 (0.5722) loss_zs_kd 3.5280 (3.5967) loss_oracle 0.9151 (0.9409) kd_loss 1.0064 (1.0880) acc 71.8750 (78.1543) lr 1.5567e-04 eta 0:04:26
epoch [43/50] batch [340/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.4438 (1.5857) teacher_loss 0.4302 (0.5733) loss_zs_kd 3.7667 (3.6030) loss_oracle 0.9521 (0.9390) kd_loss 1.0752 (1.0858) acc 84.3750 (78.1985) lr 1.5567e-04 eta 0:04:23
epoch [43/50] batch [360/428] time 0.086 (0.085) data 0.000 (0.002) loss 1.5564 (1.5870) teacher_loss 0.4946 (0.5758) loss_zs_kd 3.4768 (3.6117) loss_oracle 0.9839 (0.9389) kd_loss 1.1397 (1.0834) acc 84.3750 (78.1944) lr 1.5567e-04 eta 0:04:21
epoch [43/50] batch [380/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.7626 (1.5911) teacher_loss 0.7245 (0.5818) loss_zs_kd 3.8229 (3.6191) loss_oracle 0.9499 (0.9382) kd_loss 1.1261 (1.0805) acc 75.0000 (77.9523) lr 1.5567e-04 eta 0:04:20
epoch [43/50] batch [400/428] time 0.075 (0.085) data 0.000 (0.002) loss 1.3645 (1.5923) teacher_loss 0.4263 (0.5849) loss_zs_kd 3.8590 (3.6304) loss_oracle 0.8969 (0.9369) kd_loss 0.9794 (1.0779) acc 90.6250 (77.8828) lr 1.5567e-04 eta 0:04:18
epoch [43/50] batch [420/428] time 0.076 (0.085) data 0.000 (0.002) loss 1.5523 (1.5919) teacher_loss 0.6404 (0.5869) loss_zs_kd 3.7476 (3.6339) loss_oracle 0.8846 (0.9357) kd_loss 0.9392 (1.0743) acc 78.1250 (77.9167) lr 1.5567e-04 eta 0:04:15
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,433
* accuracy: 58.4%
* error: 41.6%
* macro_f1: 40.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,770
* accuracy: 37.3%
* error: 62.7%
* macro_f1: 22.5%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [44/50] batch [20/428] time 0.083 (0.114) data 0.000 (0.031) loss 1.8924 (1.6332) teacher_loss 0.9268 (0.6709) loss_zs_kd 3.6787 (3.6547) loss_oracle 0.9203 (0.9037) kd_loss 1.0110 (1.0211) acc 62.5000 (75.0000) lr 1.2369e-04 eta 0:05:40
epoch [44/50] batch [40/428] time 0.085 (0.099) data 0.000 (0.016) loss 1.4772 (1.5969) teacher_loss 0.5335 (0.6231) loss_zs_kd 4.0315 (3.6746) loss_oracle 0.8631 (0.9099) kd_loss 1.0244 (1.0376) acc 87.5000 (77.5000) lr 1.2369e-04 eta 0:04:53
epoch [44/50] batch [60/428] time 0.093 (0.094) data 0.001 (0.011) loss 1.5933 (1.5944) teacher_loss 0.6290 (0.6162) loss_zs_kd 3.3752 (3.7076) loss_oracle 0.8935 (0.9143) kd_loss 1.0351 (1.0421) acc 75.0000 (77.5521) lr 1.2369e-04 eta 0:04:36
epoch [44/50] batch [80/428] time 0.088 (0.092) data 0.000 (0.008) loss 1.6726 (1.5932) teacher_loss 0.6257 (0.6099) loss_zs_kd 3.8379 (3.7217) loss_oracle 0.9849 (0.9170) kd_loss 1.1088 (1.0496) acc 78.1250 (77.6953) lr 1.2369e-04 eta 0:04:28
epoch [44/50] batch [100/428] time 0.087 (0.090) data 0.000 (0.006) loss 1.4100 (1.5918) teacher_loss 0.4524 (0.6048) loss_zs_kd 3.9022 (3.7280) loss_oracle 0.9256 (0.9219) kd_loss 0.9896 (1.0523) acc 84.3750 (77.8125) lr 1.2369e-04 eta 0:04:22
epoch [44/50] batch [120/428] time 0.082 (0.089) data 0.000 (0.005) loss 1.7003 (1.6023) teacher_loss 0.6026 (0.6136) loss_zs_kd 3.2643 (3.7199) loss_oracle 1.0508 (0.9226) kd_loss 1.1446 (1.0548) acc 81.2500 (77.4219) lr 1.2369e-04 eta 0:04:16
epoch [44/50] batch [140/428] time 0.100 (0.088) data 0.000 (0.005) loss 1.5480 (1.6036) teacher_loss 0.6007 (0.6149) loss_zs_kd 3.3053 (3.7195) loss_oracle 0.9201 (0.9221) kd_loss 0.9745 (1.0553) acc 78.1250 (77.5893) lr 1.2369e-04 eta 0:04:12
epoch [44/50] batch [160/428] time 0.090 (0.088) data 0.000 (0.004) loss 1.5737 (1.5980) teacher_loss 0.5894 (0.6060) loss_zs_kd 3.7843 (3.7286) loss_oracle 0.9264 (0.9242) kd_loss 1.0422 (1.0598) acc 78.1250 (77.8125) lr 1.2369e-04 eta 0:04:09
epoch [44/50] batch [180/428] time 0.071 (0.089) data 0.000 (0.004) loss 1.6658 (1.5996) teacher_loss 0.6706 (0.6062) loss_zs_kd 3.6163 (3.7337) loss_oracle 0.8801 (0.9244) kd_loss 1.1102 (1.0624) acc 68.7500 (77.7604) lr 1.2369e-04 eta 0:04:10
epoch [44/50] batch [200/428] time 0.077 (0.090) data 0.000 (0.003) loss 1.8953 (1.5982) teacher_loss 0.9456 (0.6065) loss_zs_kd 3.8251 (3.7404) loss_oracle 0.8906 (0.9220) kd_loss 1.0088 (1.0613) acc 75.0000 (77.7344) lr 1.2369e-04 eta 0:04:11
epoch [44/50] batch [220/428] time 0.088 (0.090) data 0.000 (0.003) loss 1.5041 (1.5962) teacher_loss 0.6044 (0.6033) loss_zs_kd 3.5341 (3.7429) loss_oracle 0.8657 (0.9225) kd_loss 0.9337 (1.0633) acc 81.2500 (77.7415) lr 1.2369e-04 eta 0:04:08
epoch [44/50] batch [240/428] time 0.089 (0.089) data 0.000 (0.003) loss 1.7483 (1.5970) teacher_loss 0.7508 (0.6033) loss_zs_kd 4.1037 (3.7485) loss_oracle 0.9490 (0.9229) kd_loss 1.0461 (1.0645) acc 68.7500 (77.6172) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [260/428] time 0.086 (0.089) data 0.000 (0.003) loss 1.4807 (1.5952) teacher_loss 0.4912 (0.6015) loss_zs_kd 3.2557 (3.7415) loss_oracle 0.9582 (0.9232) kd_loss 1.0208 (1.0641) acc 78.1250 (77.5841) lr 1.2369e-04 eta 0:04:03
epoch [44/50] batch [280/428] time 0.075 (0.088) data 0.000 (0.003) loss 1.5268 (1.5983) teacher_loss 0.5153 (0.6030) loss_zs_kd 3.6143 (3.7420) loss_oracle 0.9274 (0.9248) kd_loss 1.0956 (1.0657) acc 81.2500 (77.4554) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [300/428] time 0.082 (0.088) data 0.000 (0.002) loss 1.7380 (1.5982) teacher_loss 0.8398 (0.6026) loss_zs_kd 3.3484 (3.7323) loss_oracle 0.8968 (0.9255) kd_loss 0.8996 (1.0658) acc 62.5000 (77.5104) lr 1.2369e-04 eta 0:03:57
epoch [44/50] batch [320/428] time 0.084 (0.088) data 0.000 (0.002) loss 1.7434 (1.5997) teacher_loss 0.7894 (0.6023) loss_zs_kd 3.5718 (3.7283) loss_oracle 0.9096 (0.9268) kd_loss 0.9984 (1.0680) acc 81.2500 (77.6172) lr 1.2369e-04 eta 0:03:55
epoch [44/50] batch [340/428] time 0.082 (0.088) data 0.000 (0.002) loss 1.6447 (1.5999) teacher_loss 0.5722 (0.6012) loss_zs_kd 4.0468 (3.7312) loss_oracle 0.9386 (0.9275) kd_loss 1.2064 (1.0700) acc 78.1250 (77.7206) lr 1.2369e-04 eta 0:03:52
epoch [44/50] batch [360/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.7045 (1.6033) teacher_loss 0.6786 (0.6036) loss_zs_kd 4.0203 (3.7286) loss_oracle 0.9273 (0.9285) kd_loss 1.1245 (1.0709) acc 78.1250 (77.6302) lr 1.2369e-04 eta 0:03:50
epoch [44/50] batch [380/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.3234 (1.6031) teacher_loss 0.3159 (0.6030) loss_zs_kd 3.9295 (3.7325) loss_oracle 0.9365 (0.9280) kd_loss 1.0785 (1.0723) acc 93.7500 (77.7632) lr 1.2369e-04 eta 0:03:48
epoch [44/50] batch [400/428] time 0.092 (0.087) data 0.000 (0.002) loss 1.7062 (1.6001) teacher_loss 0.7183 (0.5989) loss_zs_kd 3.9149 (3.7355) loss_oracle 0.9276 (0.9282) kd_loss 1.0482 (1.0742) acc 68.7500 (77.9141) lr 1.2369e-04 eta 0:03:45
epoch [44/50] batch [420/428] time 0.074 (0.087) data 0.000 (0.002) loss 1.5795 (1.6004) teacher_loss 0.5679 (0.5978) loss_zs_kd 3.7482 (3.7397) loss_oracle 0.8870 (0.9287) kd_loss 1.1362 (1.0764) acc 81.2500 (77.9688) lr 1.2369e-04 eta 0:03:43
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,197
* accuracy: 54.4%
* error: 45.6%
* macro_f1: 35.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,712
* accuracy: 36.1%
* error: 63.9%
* macro_f1: 19.8%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [45/50] batch [20/428] time 0.064 (0.092) data 0.000 (0.025) loss 1.4495 (1.5589) teacher_loss 0.5333 (0.5554) loss_zs_kd 4.0363 (3.8570) loss_oracle 0.8963 (0.9302) kd_loss 0.9363 (1.0769) acc 78.1250 (77.1875) lr 9.5173e-05 eta 0:03:55
epoch [45/50] batch [40/428] time 0.075 (0.083) data 0.000 (0.013) loss 1.3155 (1.5682) teacher_loss 0.3660 (0.5556) loss_zs_kd 3.6290 (3.8279) loss_oracle 0.9548 (0.9373) kd_loss 0.9443 (1.0881) acc 84.3750 (77.6562) lr 9.5173e-05 eta 0:03:31
epoch [45/50] batch [60/428] time 0.077 (0.082) data 0.000 (0.009) loss 1.6595 (1.5890) teacher_loss 0.7038 (0.5697) loss_zs_kd 3.7859 (3.8119) loss_oracle 0.9275 (0.9475) kd_loss 0.9839 (1.0910) acc 81.2500 (77.7604) lr 9.5173e-05 eta 0:03:25
epoch [45/50] batch [80/428] time 0.085 (0.082) data 0.000 (0.007) loss 1.5413 (1.5888) teacher_loss 0.4831 (0.5727) loss_zs_kd 3.6888 (3.7931) loss_oracle 0.9742 (0.9448) kd_loss 1.1423 (1.0874) acc 84.3750 (78.2031) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [100/428] time 0.078 (0.082) data 0.000 (0.005) loss 1.7502 (1.5860) teacher_loss 0.7538 (0.5695) loss_zs_kd 3.6521 (3.8040) loss_oracle 1.0056 (0.9455) kd_loss 0.9871 (1.0874) acc 78.1250 (78.7188) lr 9.5173e-05 eta 0:03:22
epoch [45/50] batch [120/428] time 0.076 (0.081) data 0.001 (0.005) loss 1.6450 (1.5882) teacher_loss 0.5883 (0.5731) loss_zs_kd 3.8384 (3.8026) loss_oracle 0.9498 (0.9432) kd_loss 1.1636 (1.0871) acc 78.1250 (78.6979) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [140/428] time 0.079 (0.082) data 0.001 (0.004) loss 1.5409 (1.5947) teacher_loss 0.4933 (0.5772) loss_zs_kd 4.1034 (3.8261) loss_oracle 1.0199 (0.9425) kd_loss 1.0754 (1.0926) acc 87.5000 (78.6161) lr 9.5173e-05 eta 0:03:18
epoch [45/50] batch [160/428] time 0.085 (0.082) data 0.001 (0.003) loss 1.4422 (1.5969) teacher_loss 0.5271 (0.5833) loss_zs_kd 3.8935 (3.8174) loss_oracle 0.8654 (0.9400) kd_loss 0.9648 (1.0872) acc 87.5000 (78.3008) lr 9.5173e-05 eta 0:03:17
epoch [45/50] batch [180/428] time 0.079 (0.082) data 0.000 (0.003) loss 1.5103 (1.5991) teacher_loss 0.5898 (0.5857) loss_zs_kd 3.6015 (3.8114) loss_oracle 0.8830 (0.9407) kd_loss 0.9580 (1.0862) acc 78.1250 (78.2639) lr 9.5173e-05 eta 0:03:15
epoch [45/50] batch [200/428] time 0.091 (0.082) data 0.000 (0.003) loss 1.5489 (1.5962) teacher_loss 0.4702 (0.5795) loss_zs_kd 4.0489 (3.8248) loss_oracle 0.9786 (0.9428) kd_loss 1.1787 (1.0906) acc 84.3750 (78.5000) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [220/428] time 0.086 (0.082) data 0.000 (0.003) loss 1.5094 (1.5950) teacher_loss 0.4542 (0.5765) loss_zs_kd 4.0482 (3.8334) loss_oracle 0.9147 (0.9432) kd_loss 1.1958 (1.0937) acc 78.1250 (78.5227) lr 9.5173e-05 eta 0:03:12
epoch [45/50] batch [240/428] time 0.086 (0.083) data 0.000 (0.002) loss 1.3581 (1.5943) teacher_loss 0.3880 (0.5756) loss_zs_kd 4.0086 (3.8325) loss_oracle 0.8824 (0.9431) kd_loss 1.0578 (1.0944) acc 90.6250 (78.5677) lr 9.5173e-05 eta 0:03:12
epoch [45/50] batch [260/428] time 0.085 (0.083) data 0.000 (0.002) loss 1.5120 (1.5945) teacher_loss 0.5816 (0.5756) loss_zs_kd 3.7158 (3.8330) loss_oracle 0.8742 (0.9432) kd_loss 0.9867 (1.0945) acc 84.3750 (78.5938) lr 9.5173e-05 eta 0:03:11
epoch [45/50] batch [280/428] time 0.081 (0.083) data 0.000 (0.002) loss 1.6116 (1.5926) teacher_loss 0.4834 (0.5731) loss_zs_kd 4.1211 (3.8396) loss_oracle 1.0517 (0.9438) kd_loss 1.2048 (1.0953) acc 78.1250 (78.7835) lr 9.5173e-05 eta 0:03:10
epoch [45/50] batch [300/428] time 0.083 (0.083) data 0.000 (0.002) loss 1.6331 (1.5914) teacher_loss 0.6108 (0.5712) loss_zs_kd 4.0359 (3.8459) loss_oracle 0.9531 (0.9439) kd_loss 1.0916 (1.0965) acc 75.0000 (78.7708) lr 9.5173e-05 eta 0:03:08
epoch [45/50] batch [320/428] time 0.069 (0.084) data 0.000 (0.002) loss 1.7591 (1.5915) teacher_loss 0.6894 (0.5699) loss_zs_kd 3.5875 (3.8500) loss_oracle 1.0499 (0.9449) kd_loss 1.0895 (1.0984) acc 81.2500 (78.8574) lr 9.5173e-05 eta 0:03:09
epoch [45/50] batch [340/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.5852 (1.5929) teacher_loss 0.5525 (0.5702) loss_zs_kd 3.7585 (3.8569) loss_oracle 0.9275 (0.9454) kd_loss 1.1379 (1.0998) acc 71.8750 (78.7684) lr 9.5173e-05 eta 0:03:07
epoch [45/50] batch [360/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.5198 (1.5931) teacher_loss 0.5796 (0.5704) loss_zs_kd 3.5100 (3.8567) loss_oracle 0.9308 (0.9459) kd_loss 0.9495 (1.0995) acc 71.8750 (78.7326) lr 9.5173e-05 eta 0:03:05
epoch [45/50] batch [380/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.6572 (1.5936) teacher_loss 0.6837 (0.5697) loss_zs_kd 3.8803 (3.8597) loss_oracle 0.8821 (0.9468) kd_loss 1.0650 (1.1011) acc 75.0000 (78.6924) lr 9.5173e-05 eta 0:03:04
epoch [45/50] batch [400/428] time 0.083 (0.084) data 0.000 (0.002) loss 1.8698 (1.5931) teacher_loss 0.7303 (0.5689) loss_zs_kd 4.0409 (3.8616) loss_oracle 1.0680 (0.9465) kd_loss 1.2111 (1.1020) acc 68.7500 (78.7109) lr 9.5173e-05 eta 0:03:02
epoch [45/50] batch [420/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.5752 (1.5951) teacher_loss 0.5927 (0.5710) loss_zs_kd 3.7190 (3.8642) loss_oracle 0.9251 (0.9465) kd_loss 1.0400 (1.1016) acc 81.2500 (78.6161) lr 9.5173e-05 eta 0:03:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,154
* accuracy: 53.7%
* error: 46.3%
* macro_f1: 34.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,662
* accuracy: 35.1%
* error: 64.9%
* macro_f1: 19.9%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [46/50] batch [20/428] time 0.077 (0.123) data 0.000 (0.035) loss 1.6178 (1.6194) teacher_loss 0.5221 (0.5885) loss_zs_kd 3.9506 (3.8789) loss_oracle 1.0417 (0.9538) kd_loss 1.1496 (1.1081) acc 78.1250 (78.7500) lr 7.0224e-05 eta 0:04:21
epoch [46/50] batch [40/428] time 0.086 (0.102) data 0.000 (0.018) loss 1.6193 (1.6028) teacher_loss 0.6895 (0.5735) loss_zs_kd 3.8130 (3.9103) loss_oracle 0.9262 (0.9535) kd_loss 0.9333 (1.1051) acc 68.7500 (79.6875) lr 7.0224e-05 eta 0:03:34
epoch [46/50] batch [60/428] time 0.077 (0.100) data 0.000 (0.012) loss 1.5020 (1.5880) teacher_loss 0.5356 (0.5531) loss_zs_kd 4.5777 (3.9081) loss_oracle 0.9208 (0.9572) kd_loss 1.0121 (1.1127) acc 84.3750 (80.0521) lr 7.0224e-05 eta 0:03:28
epoch [46/50] batch [80/428] time 0.082 (0.096) data 0.000 (0.009) loss 1.5002 (1.5995) teacher_loss 0.4861 (0.5623) loss_zs_kd 3.8201 (3.9076) loss_oracle 0.9535 (0.9579) kd_loss 1.0747 (1.1164) acc 81.2500 (79.1016) lr 7.0224e-05 eta 0:03:18
epoch [46/50] batch [100/428] time 0.079 (0.094) data 0.000 (0.007) loss 1.5315 (1.6041) teacher_loss 0.4769 (0.5627) loss_zs_kd 3.9809 (3.9134) loss_oracle 1.0073 (0.9626) kd_loss 1.1019 (1.1204) acc 87.5000 (79.2188) lr 7.0224e-05 eta 0:03:11
epoch [46/50] batch [120/428] time 0.079 (0.092) data 0.000 (0.006) loss 1.7438 (1.6063) teacher_loss 0.7234 (0.5629) loss_zs_kd 3.7795 (3.9100) loss_oracle 0.9560 (0.9619) kd_loss 1.0848 (1.1248) acc 65.6250 (78.8802) lr 7.0224e-05 eta 0:03:05
epoch [46/50] batch [140/428] time 0.079 (0.090) data 0.000 (0.005) loss 1.5798 (1.6104) teacher_loss 0.5168 (0.5669) loss_zs_kd 3.4916 (3.9135) loss_oracle 0.9707 (0.9617) kd_loss 1.1553 (1.1252) acc 65.6250 (78.5714) lr 7.0224e-05 eta 0:03:00
epoch [46/50] batch [160/428] time 0.096 (0.090) data 0.000 (0.005) loss 1.5021 (1.6131) teacher_loss 0.4781 (0.5695) loss_zs_kd 3.8194 (3.9032) loss_oracle 0.9488 (0.9611) kd_loss 1.0992 (1.1259) acc 78.1250 (78.4570) lr 7.0224e-05 eta 0:02:57
epoch [46/50] batch [180/428] time 0.082 (0.089) data 0.000 (0.004) loss 1.6415 (1.6128) teacher_loss 0.7355 (0.5720) loss_zs_kd 3.6983 (3.8869) loss_oracle 0.8568 (0.9608) kd_loss 0.9551 (1.1208) acc 68.7500 (78.2465) lr 7.0224e-05 eta 0:02:54
epoch [46/50] batch [200/428] time 0.081 (0.089) data 0.000 (0.004) loss 1.4833 (1.6169) teacher_loss 0.3278 (0.5754) loss_zs_kd 3.7697 (3.8941) loss_oracle 0.9898 (0.9629) kd_loss 1.3212 (1.1201) acc 93.7500 (78.2500) lr 7.0224e-05 eta 0:02:51
epoch [46/50] batch [220/428] time 0.081 (0.088) data 0.000 (0.003) loss 1.6853 (1.6191) teacher_loss 0.6831 (0.5783) loss_zs_kd 3.6956 (3.8861) loss_oracle 0.9686 (0.9618) kd_loss 1.0358 (1.1196) acc 75.0000 (78.3381) lr 7.0224e-05 eta 0:02:49
epoch [46/50] batch [240/428] time 0.085 (0.088) data 0.000 (0.003) loss 2.0091 (1.6197) teacher_loss 0.9847 (0.5792) loss_zs_kd 3.5514 (3.8791) loss_oracle 0.9574 (0.9617) kd_loss 1.0916 (1.1192) acc 75.0000 (78.3333) lr 7.0224e-05 eta 0:02:46
epoch [46/50] batch [260/428] time 0.084 (0.088) data 0.000 (0.003) loss 1.5518 (1.6205) teacher_loss 0.5479 (0.5768) loss_zs_kd 3.6460 (3.8732) loss_oracle 0.9057 (0.9640) kd_loss 1.1023 (1.1234) acc 81.2500 (78.3774) lr 7.0224e-05 eta 0:02:44
epoch [46/50] batch [280/428] time 0.083 (0.087) data 0.000 (0.003) loss 1.5496 (1.6158) teacher_loss 0.5222 (0.5712) loss_zs_kd 3.8148 (3.8674) loss_oracle 0.9209 (0.9652) kd_loss 1.1339 (1.1240) acc 81.2500 (78.7388) lr 7.0224e-05 eta 0:02:42
epoch [46/50] batch [300/428] time 0.086 (0.087) data 0.000 (0.003) loss 1.3741 (1.6119) teacher_loss 0.3548 (0.5659) loss_zs_kd 3.6836 (3.8652) loss_oracle 0.9390 (0.9653) kd_loss 1.0995 (1.1268) acc 90.6250 (78.9271) lr 7.0224e-05 eta 0:02:40
epoch [46/50] batch [320/428] time 0.070 (0.087) data 0.000 (0.003) loss 1.7152 (1.6117) teacher_loss 0.7191 (0.5636) loss_zs_kd 3.4019 (3.8673) loss_oracle 0.9578 (0.9672) kd_loss 1.0343 (1.1289) acc 75.0000 (79.0527) lr 7.0224e-05 eta 0:02:37
epoch [46/50] batch [340/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.7201 (1.6130) teacher_loss 0.7131 (0.5646) loss_zs_kd 3.7172 (3.8710) loss_oracle 0.9499 (0.9670) kd_loss 1.0642 (1.1298) acc 75.0000 (79.0625) lr 7.0224e-05 eta 0:02:35
epoch [46/50] batch [360/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.4093 (1.6117) teacher_loss 0.2987 (0.5632) loss_zs_kd 3.8079 (3.8713) loss_oracle 1.0062 (0.9670) kd_loss 1.2151 (1.1301) acc 90.6250 (79.0625) lr 7.0224e-05 eta 0:02:33
epoch [46/50] batch [380/428] time 0.077 (0.086) data 0.000 (0.002) loss 1.7553 (1.6107) teacher_loss 0.6470 (0.5609) loss_zs_kd 3.5868 (3.8731) loss_oracle 1.0301 (0.9675) kd_loss 1.1864 (1.1320) acc 78.1250 (79.1941) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [400/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.5560 (1.6096) teacher_loss 0.5420 (0.5586) loss_zs_kd 3.8858 (3.8772) loss_oracle 0.8934 (0.9686) kd_loss 1.1345 (1.1334) acc 81.2500 (79.2344) lr 7.0224e-05 eta 0:02:30
epoch [46/50] batch [420/428] time 0.079 (0.086) data 0.000 (0.002) loss 1.4675 (1.6072) teacher_loss 0.3214 (0.5549) loss_zs_kd 3.6645 (3.8752) loss_oracle 0.9644 (0.9696) kd_loss 1.3277 (1.1350) acc 90.6250 (79.4345) lr 7.0224e-05 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,110
* accuracy: 52.9%
* error: 47.1%
* macro_f1: 34.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,657
* accuracy: 35.0%
* error: 65.0%
* macro_f1: 19.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [47/50] batch [20/428] time 0.085 (0.124) data 0.000 (0.032) loss 1.8384 (1.6533) teacher_loss 0.7686 (0.5787) loss_zs_kd 3.8177 (3.8461) loss_oracle 1.0082 (0.9796) kd_loss 1.1313 (1.1696) acc 65.6250 (77.9688) lr 4.8943e-05 eta 0:03:29
epoch [47/50] batch [40/428] time 0.085 (0.104) data 0.000 (0.016) loss 1.6713 (1.6501) teacher_loss 0.6768 (0.5723) loss_zs_kd 4.2042 (3.9126) loss_oracle 0.8801 (0.9863) kd_loss 1.1090 (1.1693) acc 75.0000 (78.0469) lr 4.8943e-05 eta 0:02:53
epoch [47/50] batch [60/428] time 0.080 (0.097) data 0.000 (0.011) loss 1.4209 (1.6469) teacher_loss 0.4050 (0.5715) loss_zs_kd 3.5708 (3.8620) loss_oracle 0.9090 (0.9855) kd_loss 1.1230 (1.1652) acc 78.1250 (78.1771) lr 4.8943e-05 eta 0:02:41
epoch [47/50] batch [80/428] time 0.086 (0.094) data 0.001 (0.008) loss 1.8213 (1.6494) teacher_loss 0.8070 (0.5779) loss_zs_kd 3.6624 (3.8759) loss_oracle 0.9586 (0.9843) kd_loss 1.0700 (1.1588) acc 65.6250 (77.8516) lr 4.8943e-05 eta 0:02:33
epoch [47/50] batch [100/428] time 0.090 (0.093) data 0.000 (0.007) loss 1.6041 (1.6353) teacher_loss 0.4442 (0.5682) loss_zs_kd 3.8274 (3.8741) loss_oracle 1.0376 (0.9814) kd_loss 1.2823 (1.1527) acc 78.1250 (78.1875) lr 4.8943e-05 eta 0:02:29
epoch [47/50] batch [120/428] time 0.088 (0.091) data 0.000 (0.006) loss 1.5935 (1.6365) teacher_loss 0.4276 (0.5643) loss_zs_kd 4.0406 (3.8849) loss_oracle 1.0430 (0.9874) kd_loss 1.2888 (1.1569) acc 84.3750 (78.5156) lr 4.8943e-05 eta 0:02:25
epoch [47/50] batch [140/428] time 0.088 (0.090) data 0.000 (0.005) loss 1.6114 (1.6260) teacher_loss 0.5394 (0.5567) loss_zs_kd 3.7470 (3.8829) loss_oracle 1.0178 (0.9852) kd_loss 1.1263 (1.1535) acc 78.1250 (78.7946) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [160/428] time 0.163 (0.091) data 0.001 (0.004) loss 1.3541 (1.6239) teacher_loss 0.2929 (0.5551) loss_zs_kd 3.9100 (3.8781) loss_oracle 0.9294 (0.9843) kd_loss 1.1930 (1.1533) acc 96.8750 (78.9453) lr 4.8943e-05 eta 0:02:20
epoch [47/50] batch [180/428] time 0.087 (0.091) data 0.000 (0.004) loss 1.5115 (1.6180) teacher_loss 0.5150 (0.5503) loss_zs_kd 3.8407 (3.8728) loss_oracle 0.9289 (0.9834) kd_loss 1.0640 (1.1521) acc 78.1250 (79.3403) lr 4.8943e-05 eta 0:02:19
epoch [47/50] batch [200/428] time 0.085 (0.090) data 0.000 (0.003) loss 1.6310 (1.6183) teacher_loss 0.6256 (0.5491) loss_zs_kd 3.7496 (3.8678) loss_oracle 0.9457 (0.9842) kd_loss 1.0650 (1.1543) acc 71.8750 (79.2812) lr 4.8943e-05 eta 0:02:16
epoch [47/50] batch [220/428] time 0.085 (0.090) data 0.000 (0.003) loss 1.3785 (1.6181) teacher_loss 0.2919 (0.5474) loss_zs_kd 4.1008 (3.8735) loss_oracle 1.0290 (0.9861) kd_loss 1.1441 (1.1554) acc 90.6250 (79.4034) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [240/428] time 0.081 (0.089) data 0.000 (0.003) loss 1.6164 (1.6168) teacher_loss 0.5533 (0.5462) loss_zs_kd 4.3152 (3.8750) loss_oracle 0.9665 (0.9866) kd_loss 1.1597 (1.1547) acc 81.2500 (79.5182) lr 4.8943e-05 eta 0:02:11
epoch [47/50] batch [260/428] time 0.086 (0.089) data 0.000 (0.003) loss 1.6553 (1.6150) teacher_loss 0.6672 (0.5453) loss_zs_kd 4.0399 (3.8786) loss_oracle 0.9041 (0.9865) kd_loss 1.0721 (1.1529) acc 71.8750 (79.5433) lr 4.8943e-05 eta 0:02:09
epoch [47/50] batch [280/428] time 0.086 (0.089) data 0.000 (0.003) loss 1.4633 (1.6124) teacher_loss 0.4786 (0.5435) loss_zs_kd 4.1599 (3.8907) loss_oracle 0.9258 (0.9857) kd_loss 1.0435 (1.1520) acc 87.5000 (79.6540) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [300/428] time 0.080 (0.088) data 0.000 (0.002) loss 1.8866 (1.6118) teacher_loss 0.8053 (0.5421) loss_zs_kd 4.2911 (3.8888) loss_oracle 1.0133 (0.9852) kd_loss 1.1492 (1.1542) acc 75.0000 (79.8021) lr 4.8943e-05 eta 0:02:04
epoch [47/50] batch [320/428] time 0.084 (0.088) data 0.000 (0.002) loss 1.4545 (1.6095) teacher_loss 0.3287 (0.5399) loss_zs_kd 3.8299 (3.8946) loss_oracle 0.9584 (0.9855) kd_loss 1.2932 (1.1537) acc 90.6250 (79.9316) lr 4.8943e-05 eta 0:02:02
epoch [47/50] batch [340/428] time 0.082 (0.088) data 0.000 (0.002) loss 1.7643 (1.6097) teacher_loss 0.7324 (0.5412) loss_zs_kd 4.5208 (3.9011) loss_oracle 0.9008 (0.9852) kd_loss 1.1629 (1.1518) acc 84.3750 (79.9724) lr 4.8943e-05 eta 0:02:00
epoch [47/50] batch [360/428] time 0.091 (0.088) data 0.000 (0.002) loss 1.5431 (1.6092) teacher_loss 0.5030 (0.5417) loss_zs_kd 3.6739 (3.8978) loss_oracle 0.9863 (0.9845) kd_loss 1.0940 (1.1505) acc 78.1250 (79.9306) lr 4.8943e-05 eta 0:01:58
epoch [47/50] batch [380/428] time 0.082 (0.088) data 0.000 (0.002) loss 1.4039 (1.6067) teacher_loss 0.3568 (0.5390) loss_zs_kd 4.4852 (3.8971) loss_oracle 0.9822 (0.9844) kd_loss 1.1119 (1.1509) acc 87.5000 (80.0329) lr 4.8943e-05 eta 0:01:56
epoch [47/50] batch [400/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.3566 (1.6073) teacher_loss 0.2592 (0.5382) loss_zs_kd 4.0524 (3.8959) loss_oracle 0.9939 (0.9857) kd_loss 1.2009 (1.1524) acc 90.6250 (80.0781) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [420/428] time 0.076 (0.087) data 0.000 (0.002) loss 1.7309 (1.6088) teacher_loss 0.7459 (0.5407) loss_zs_kd 3.9716 (3.8948) loss_oracle 0.9212 (0.9849) kd_loss 1.0489 (1.1514) acc 71.8750 (79.8958) lr 4.8943e-05 eta 0:01:52
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,089
* accuracy: 52.6%
* error: 47.4%
* macro_f1: 33.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,662
* accuracy: 35.1%
* error: 64.9%
* macro_f1: 19.4%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [48/50] batch [20/428] time 0.084 (0.118) data 0.000 (0.032) loss 1.4642 (1.5345) teacher_loss 0.3463 (0.4813) loss_zs_kd 3.8527 (3.8785) loss_oracle 0.9818 (0.9727) kd_loss 1.2538 (1.1339) acc 87.5000 (82.8125) lr 3.1417e-05 eta 0:02:29
epoch [48/50] batch [40/428] time 0.081 (0.102) data 0.000 (0.016) loss 1.6802 (1.5744) teacher_loss 0.6058 (0.5183) loss_zs_kd 3.7056 (3.9105) loss_oracle 0.9669 (0.9788) kd_loss 1.1818 (1.1335) acc 78.1250 (81.3281) lr 3.1417e-05 eta 0:02:06
epoch [48/50] batch [60/428] time 0.091 (0.096) data 0.001 (0.011) loss 1.7919 (1.5890) teacher_loss 0.7241 (0.5221) loss_zs_kd 3.7736 (3.9094) loss_oracle 0.9852 (0.9883) kd_loss 1.1503 (1.1456) acc 71.8750 (80.7812) lr 3.1417e-05 eta 0:01:57
epoch [48/50] batch [80/428] time 0.081 (0.093) data 0.000 (0.008) loss 1.5971 (1.5995) teacher_loss 0.5489 (0.5321) loss_zs_kd 3.5402 (3.8991) loss_oracle 0.9895 (0.9883) kd_loss 1.1069 (1.1466) acc 78.1250 (80.0781) lr 3.1417e-05 eta 0:01:52
epoch [48/50] batch [100/428] time 0.096 (0.092) data 0.001 (0.007) loss 1.5765 (1.6080) teacher_loss 0.5791 (0.5416) loss_zs_kd 4.0441 (3.8956) loss_oracle 0.9408 (0.9889) kd_loss 1.0538 (1.1439) acc 84.3750 (79.8438) lr 3.1417e-05 eta 0:01:48
epoch [48/50] batch [120/428] time 0.077 (0.091) data 0.000 (0.006) loss 1.3845 (1.6075) teacher_loss 0.2522 (0.5393) loss_zs_kd 4.1335 (3.8934) loss_oracle 1.0200 (0.9902) kd_loss 1.2446 (1.1462) acc 90.6250 (79.6875) lr 3.1417e-05 eta 0:01:45
epoch [48/50] batch [140/428] time 0.087 (0.090) data 0.001 (0.005) loss 1.6504 (1.6137) teacher_loss 0.6680 (0.5452) loss_zs_kd 3.9571 (3.8954) loss_oracle 0.8826 (0.9902) kd_loss 1.0822 (1.1468) acc 81.2500 (79.5536) lr 3.1417e-05 eta 0:01:43
epoch [48/50] batch [160/428] time 0.084 (0.090) data 0.000 (0.004) loss 1.6543 (1.6141) teacher_loss 0.5667 (0.5480) loss_zs_kd 4.1319 (3.9001) loss_oracle 1.0315 (0.9865) kd_loss 1.1438 (1.1457) acc 75.0000 (79.2578) lr 3.1417e-05 eta 0:01:40
epoch [48/50] batch [180/428] time 0.092 (0.089) data 0.000 (0.004) loss 1.4428 (1.6121) teacher_loss 0.3702 (0.5462) loss_zs_kd 4.0651 (3.9082) loss_oracle 0.9723 (0.9865) kd_loss 1.1729 (1.1452) acc 93.7500 (79.4792) lr 3.1417e-05 eta 0:01:38
epoch [48/50] batch [200/428] time 0.084 (0.089) data 0.000 (0.003) loss 1.6169 (1.6124) teacher_loss 0.4364 (0.5482) loss_zs_kd 4.1479 (3.9166) loss_oracle 1.0876 (0.9838) kd_loss 1.2734 (1.1445) acc 81.2500 (79.3125) lr 3.1417e-05 eta 0:01:36
epoch [48/50] batch [220/428] time 0.083 (0.088) data 0.000 (0.003) loss 1.4135 (1.6116) teacher_loss 0.3906 (0.5476) loss_zs_kd 3.7855 (3.9106) loss_oracle 0.9216 (0.9847) kd_loss 1.1241 (1.1433) acc 93.7500 (79.4886) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [240/428] time 0.080 (0.088) data 0.000 (0.003) loss 1.5761 (1.6147) teacher_loss 0.5605 (0.5497) loss_zs_kd 4.1239 (3.9133) loss_oracle 0.9620 (0.9862) kd_loss 1.0692 (1.1438) acc 78.1250 (79.3880) lr 3.1417e-05 eta 0:01:32
epoch [48/50] batch [260/428] time 0.093 (0.088) data 0.000 (0.003) loss 1.7935 (1.6160) teacher_loss 0.7455 (0.5504) loss_zs_kd 3.6504 (3.9117) loss_oracle 0.9833 (0.9859) kd_loss 1.1126 (1.1451) acc 75.0000 (79.3149) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [280/428] time 0.080 (0.089) data 0.000 (0.003) loss 1.7493 (1.6205) teacher_loss 0.6798 (0.5540) loss_zs_kd 4.2030 (3.9136) loss_oracle 0.9380 (0.9864) kd_loss 1.2010 (1.1467) acc 78.1250 (79.2634) lr 3.1417e-05 eta 0:01:28
epoch [48/50] batch [300/428] time 0.085 (0.088) data 0.000 (0.002) loss 1.5618 (1.6197) teacher_loss 0.3560 (0.5500) loss_zs_kd 3.8543 (3.9169) loss_oracle 1.1436 (0.9890) kd_loss 1.2680 (1.1503) acc 84.3750 (79.4479) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [320/428] time 0.081 (0.088) data 0.000 (0.002) loss 1.5531 (1.6165) teacher_loss 0.4460 (0.5453) loss_zs_kd 4.3278 (3.9228) loss_oracle 1.0440 (0.9902) kd_loss 1.1702 (1.1521) acc 81.2500 (79.6289) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [340/428] time 0.099 (0.087) data 0.000 (0.002) loss 1.6227 (1.6154) teacher_loss 0.4982 (0.5436) loss_zs_kd 3.8761 (3.9206) loss_oracle 1.0252 (0.9906) kd_loss 1.2239 (1.1529) acc 81.2500 (79.6324) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [360/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.5393 (1.6141) teacher_loss 0.3979 (0.5413) loss_zs_kd 3.5436 (3.9253) loss_oracle 1.0681 (0.9915) kd_loss 1.2147 (1.1542) acc 87.5000 (79.7743) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [380/428] time 0.077 (0.087) data 0.000 (0.002) loss 1.7656 (1.6136) teacher_loss 0.6955 (0.5398) loss_zs_kd 3.9022 (3.9253) loss_oracle 1.0103 (0.9922) kd_loss 1.1299 (1.1555) acc 78.1250 (79.7862) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [400/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.4698 (1.6131) teacher_loss 0.3227 (0.5396) loss_zs_kd 3.7015 (3.9227) loss_oracle 1.0807 (0.9921) kd_loss 1.2136 (1.1549) acc 84.3750 (79.6875) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [420/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.6582 (1.6147) teacher_loss 0.6500 (0.5401) loss_zs_kd 4.1079 (3.9234) loss_oracle 0.9809 (0.9936) kd_loss 1.0356 (1.1557) acc 75.0000 (79.6503) lr 3.1417e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,082
* accuracy: 52.5%
* error: 47.5%
* macro_f1: 33.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,647
* accuracy: 34.7%
* error: 65.3%
* macro_f1: 19.3%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [49/50] batch [20/428] time 0.072 (0.128) data 0.000 (0.025) loss 1.4889 (1.6228) teacher_loss 0.3229 (0.5470) loss_zs_kd 3.7354 (3.9496) loss_oracle 1.0427 (1.0041) kd_loss 1.2893 (1.1474) acc 93.7500 (79.6875) lr 1.7713e-05 eta 0:01:46
epoch [49/50] batch [40/428] time 0.085 (0.105) data 0.000 (0.012) loss 1.4322 (1.6259) teacher_loss 0.3542 (0.5552) loss_zs_kd 3.9641 (3.9820) loss_oracle 1.0129 (0.9962) kd_loss 1.1431 (1.1452) acc 87.5000 (78.7500) lr 1.7713e-05 eta 0:01:26
epoch [49/50] batch [60/428] time 0.080 (0.098) data 0.000 (0.008) loss 1.5092 (1.6326) teacher_loss 0.3512 (0.5703) loss_zs_kd 3.6238 (3.9749) loss_oracle 1.0536 (0.9879) kd_loss 1.2625 (1.1368) acc 90.6250 (78.6979) lr 1.7713e-05 eta 0:01:18
epoch [49/50] batch [80/428] time 0.090 (0.096) data 0.000 (0.006) loss 1.5917 (1.6413) teacher_loss 0.4921 (0.5714) loss_zs_kd 3.8464 (3.9480) loss_oracle 0.9587 (0.9936) kd_loss 1.2404 (1.1463) acc 81.2500 (78.6719) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [100/428] time 0.076 (0.094) data 0.000 (0.005) loss 1.4272 (1.6428) teacher_loss 0.4202 (0.5706) loss_zs_kd 4.0988 (3.9584) loss_oracle 0.9578 (0.9971) kd_loss 1.0562 (1.1473) acc 87.5000 (78.5625) lr 1.7713e-05 eta 0:01:10
epoch [49/50] batch [120/428] time 0.083 (0.092) data 0.000 (0.004) loss 1.4985 (1.6425) teacher_loss 0.4058 (0.5677) loss_zs_kd 4.3092 (3.9472) loss_oracle 1.0446 (0.9994) kd_loss 1.1409 (1.1501) acc 93.7500 (78.8021) lr 1.7713e-05 eta 0:01:07
epoch [49/50] batch [140/428] time 0.065 (0.091) data 0.000 (0.004) loss 1.7821 (1.6469) teacher_loss 0.7518 (0.5748) loss_zs_kd 4.0708 (3.9368) loss_oracle 0.9702 (0.9976) kd_loss 1.0904 (1.1466) acc 75.0000 (78.5045) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [160/428] time 0.080 (0.088) data 0.000 (0.003) loss 1.8662 (1.6404) teacher_loss 0.6740 (0.5663) loss_zs_kd 4.1272 (3.9359) loss_oracle 1.1362 (0.9978) kd_loss 1.2483 (1.1505) acc 81.2500 (78.9062) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [180/428] time 0.077 (0.088) data 0.000 (0.003) loss 1.4968 (1.6358) teacher_loss 0.3476 (0.5624) loss_zs_kd 3.8811 (3.9339) loss_oracle 1.0491 (0.9963) kd_loss 1.2494 (1.1505) acc 87.5000 (78.9410) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [200/428] time 0.106 (0.088) data 0.000 (0.003) loss 1.4773 (1.6321) teacher_loss 0.4214 (0.5572) loss_zs_kd 3.7576 (3.9385) loss_oracle 0.9316 (0.9957) kd_loss 1.1803 (1.1541) acc 87.5000 (79.0938) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [220/428] time 0.090 (0.088) data 0.000 (0.003) loss 1.4742 (1.6258) teacher_loss 0.3756 (0.5497) loss_zs_kd 3.7585 (3.9328) loss_oracle 0.9028 (0.9954) kd_loss 1.2943 (1.1569) acc 87.5000 (79.3892) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [240/428] time 0.096 (0.088) data 0.000 (0.002) loss 1.4949 (1.6274) teacher_loss 0.4305 (0.5502) loss_zs_kd 3.7314 (3.9282) loss_oracle 0.9418 (0.9968) kd_loss 1.1870 (1.1576) acc 84.3750 (79.2708) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [260/428] time 0.083 (0.088) data 0.000 (0.002) loss 1.4973 (1.6256) teacher_loss 0.4759 (0.5482) loss_zs_kd 4.0578 (3.9234) loss_oracle 0.9886 (0.9973) kd_loss 1.0542 (1.1574) acc 84.3750 (79.2788) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [280/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.4537 (1.6239) teacher_loss 0.3442 (0.5484) loss_zs_kd 3.9906 (3.9271) loss_oracle 1.0075 (0.9956) kd_loss 1.2115 (1.1554) acc 87.5000 (79.2746) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [300/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.4282 (1.6207) teacher_loss 0.3677 (0.5456) loss_zs_kd 4.1624 (3.9297) loss_oracle 1.0050 (0.9947) kd_loss 1.1160 (1.1555) acc 90.6250 (79.4583) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [320/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.6256 (1.6203) teacher_loss 0.6144 (0.5445) loss_zs_kd 3.5329 (3.9279) loss_oracle 0.9142 (0.9953) kd_loss 1.1082 (1.1563) acc 75.0000 (79.4238) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [340/428] time 0.078 (0.087) data 0.000 (0.002) loss 1.5302 (1.6199) teacher_loss 0.3189 (0.5441) loss_zs_kd 4.3712 (3.9327) loss_oracle 1.1012 (0.9950) kd_loss 1.3213 (1.1567) acc 87.5000 (79.4026) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [360/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.4450 (1.6183) teacher_loss 0.4390 (0.5431) loss_zs_kd 3.5692 (3.9290) loss_oracle 0.9225 (0.9937) kd_loss 1.0896 (1.1567) acc 81.2500 (79.4705) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [380/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.3658 (1.6216) teacher_loss 0.2180 (0.5453) loss_zs_kd 3.9477 (3.9308) loss_oracle 1.0110 (0.9951) kd_loss 1.2845 (1.1575) acc 87.5000 (79.4079) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [400/428] time 0.144 (0.087) data 0.000 (0.002) loss 1.6075 (1.6186) teacher_loss 0.6340 (0.5413) loss_zs_kd 3.6080 (3.9370) loss_oracle 0.8729 (0.9952) kd_loss 1.0742 (1.1595) acc 75.0000 (79.5312) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [420/428] time 0.078 (0.087) data 0.000 (0.001) loss 1.6507 (1.6200) teacher_loss 0.6489 (0.5437) loss_zs_kd 3.8172 (3.9383) loss_oracle 0.9406 (0.9941) kd_loss 1.0631 (1.1584) acc 84.3750 (79.4643) lr 1.7713e-05 eta 0:00:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,088
* accuracy: 52.6%
* error: 47.4%
* macro_f1: 34.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,657
* accuracy: 35.0%
* error: 65.0%
* macro_f1: 19.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
epoch [50/50] batch [20/428] time 0.079 (0.114) data 0.000 (0.025) loss 1.6378 (1.5895) teacher_loss 0.5588 (0.5234) loss_zs_kd 3.7696 (3.8918) loss_oracle 0.9922 (0.9814) kd_loss 1.1658 (1.1507) acc 81.2500 (80.6250) lr 7.8853e-06 eta 0:00:46
epoch [50/50] batch [40/428] time 0.084 (0.097) data 0.000 (0.012) loss 1.7117 (1.6027) teacher_loss 0.7139 (0.5346) loss_zs_kd 4.2535 (3.9379) loss_oracle 0.9243 (0.9874) kd_loss 1.0712 (1.1488) acc 75.0000 (81.0938) lr 7.8853e-06 eta 0:00:37
epoch [50/50] batch [60/428] time 0.081 (0.092) data 0.001 (0.008) loss 1.6007 (1.6147) teacher_loss 0.4467 (0.5352) loss_zs_kd 3.9991 (3.9378) loss_oracle 1.0842 (1.0010) kd_loss 1.2236 (1.1579) acc 84.3750 (80.3646) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [80/428] time 0.085 (0.090) data 0.000 (0.006) loss 1.7773 (1.6245) teacher_loss 0.6449 (0.5467) loss_zs_kd 3.9826 (3.9337) loss_oracle 1.0509 (0.9966) kd_loss 1.2138 (1.1592) acc 78.1250 (79.8828) lr 7.8853e-06 eta 0:00:31
epoch [50/50] batch [100/428] time 0.086 (0.087) data 0.000 (0.005) loss 1.6902 (1.6228) teacher_loss 0.6226 (0.5451) loss_zs_kd 3.9224 (3.9361) loss_oracle 0.9854 (0.9936) kd_loss 1.1497 (1.1619) acc 65.6250 (79.8750) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [120/428] time 0.082 (0.087) data 0.000 (0.004) loss 1.5661 (1.6181) teacher_loss 0.4884 (0.5399) loss_zs_kd 4.3175 (3.9293) loss_oracle 1.0022 (0.9933) kd_loss 1.1531 (1.1632) acc 78.1250 (79.8698) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [140/428] time 0.068 (0.088) data 0.000 (0.004) loss 1.5552 (1.6236) teacher_loss 0.5501 (0.5426) loss_zs_kd 4.1268 (3.9315) loss_oracle 0.9875 (0.9961) kd_loss 1.0227 (1.1657) acc 78.1250 (79.7098) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [160/428] time 0.083 (0.086) data 0.000 (0.003) loss 1.5420 (1.6269) teacher_loss 0.4903 (0.5511) loss_zs_kd 3.8919 (3.9263) loss_oracle 1.0312 (0.9932) kd_loss 1.0721 (1.1585) acc 81.2500 (79.2969) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [180/428] time 0.081 (0.086) data 0.000 (0.003) loss 1.7571 (1.6282) teacher_loss 0.5118 (0.5523) loss_zs_kd 3.4859 (3.9290) loss_oracle 1.0725 (0.9932) kd_loss 1.4181 (1.1586) acc 78.1250 (79.1840) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [200/428] time 0.089 (0.086) data 0.000 (0.003) loss 1.7317 (1.6289) teacher_loss 0.7191 (0.5507) loss_zs_kd 3.9601 (3.9221) loss_oracle 0.9490 (0.9950) kd_loss 1.0761 (1.1614) acc 68.7500 (79.1719) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [220/428] time 0.077 (0.086) data 0.000 (0.003) loss 1.7963 (1.6287) teacher_loss 0.6606 (0.5496) loss_zs_kd 3.6396 (3.9194) loss_oracle 1.0530 (0.9971) kd_loss 1.2183 (1.1612) acc 78.1250 (79.2898) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [240/428] time 0.090 (0.086) data 0.000 (0.002) loss 1.5852 (1.6242) teacher_loss 0.5179 (0.5453) loss_zs_kd 3.8394 (3.9235) loss_oracle 0.9316 (0.9961) kd_loss 1.2032 (1.1616) acc 75.0000 (79.4531) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [260/428] time 0.090 (0.086) data 0.000 (0.002) loss 1.6092 (1.6281) teacher_loss 0.5022 (0.5502) loss_zs_kd 4.2570 (3.9160) loss_oracle 1.0087 (0.9959) kd_loss 1.2053 (1.1599) acc 78.1250 (79.2548) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [280/428] time 0.086 (0.086) data 0.000 (0.002) loss 1.4432 (1.6236) teacher_loss 0.4136 (0.5463) loss_zs_kd 4.6754 (3.9187) loss_oracle 1.0102 (0.9960) kd_loss 1.0489 (1.1584) acc 84.3750 (79.3080) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [300/428] time 0.078 (0.086) data 0.000 (0.002) loss 1.6289 (1.6225) teacher_loss 0.5102 (0.5439) loss_zs_kd 3.4668 (3.9166) loss_oracle 1.0426 (0.9962) kd_loss 1.1949 (1.1610) acc 71.8750 (79.3646) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [320/428] time 0.077 (0.085) data 0.000 (0.002) loss 1.7371 (1.6212) teacher_loss 0.5967 (0.5411) loss_zs_kd 3.9896 (3.9212) loss_oracle 1.0396 (0.9980) kd_loss 1.2411 (1.1623) acc 78.1250 (79.5410) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [340/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.7911 (1.6231) teacher_loss 0.8530 (0.5446) loss_zs_kd 3.8009 (3.9235) loss_oracle 0.9210 (0.9974) kd_loss 0.9553 (1.1596) acc 68.7500 (79.4485) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [360/428] time 0.096 (0.085) data 0.001 (0.002) loss 1.5373 (1.6243) teacher_loss 0.4826 (0.5455) loss_zs_kd 3.9528 (3.9250) loss_oracle 0.9584 (0.9977) kd_loss 1.1511 (1.1599) acc 78.1250 (79.3750) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [380/428] time 0.086 (0.085) data 0.000 (0.002) loss 1.5554 (1.6242) teacher_loss 0.5900 (0.5460) loss_zs_kd 3.8550 (3.9275) loss_oracle 0.9304 (0.9967) kd_loss 1.0004 (1.1597) acc 81.2500 (79.3503) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [400/428] time 0.085 (0.085) data 0.000 (0.002) loss 1.6329 (1.6191) teacher_loss 0.5886 (0.5419) loss_zs_kd 4.1143 (3.9252) loss_oracle 0.9544 (0.9956) kd_loss 1.1342 (1.1587) acc 75.0000 (79.5078) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [420/428] time 0.076 (0.085) data 0.000 (0.001) loss 1.5046 (1.6183) teacher_loss 0.4770 (0.5415) loss_zs_kd 3.7166 (3.9250) loss_oracle 0.9789 (0.9954) kd_loss 1.0763 (1.1580) acc 81.2500 (79.5387) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,104
* accuracy: 52.8%
* error: 47.2%
* macro_f1: 34.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,665
* accuracy: 35.1%
* error: 64.9%
* macro_f1: 19.6%
******* Domain 1 best val acc:      59.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.4%, epoch: 13 *******
******* Domain 1 best test acc:     62.1%, epoch: 19 *******
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:54:00

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_38', 'location_43', 'location_46']
Target     ['location_100']
# classes  10
# train_x  13,713
# val      5,876
# test     4,741
---------  ---------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/428] time 0.153 (0.178) data 0.000 (0.037) loss 2.9869 (2.9383) teacher_loss 2.5110 (2.4742) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0083 (0.0047) kd_loss 0.9434 (0.9234) acc 31.2500 (23.5938) lr 1.0000e-05 eta 1:03:20
epoch [1/50] batch [40/428] time 0.083 (0.138) data 0.000 (0.019) loss 2.9884 (2.8645) teacher_loss 2.4987 (2.4004) loss_zs_kd 0.0017 (0.0004) loss_oracle 0.0061 (0.0066) kd_loss 0.9733 (0.9215) acc 18.7500 (25.7812) lr 1.0000e-05 eta 0:49:10
epoch [1/50] batch [60/428] time 0.078 (0.124) data 0.000 (0.013) loss 3.0250 (2.8424) teacher_loss 2.5710 (2.3780) loss_zs_kd 0.0044 (0.0013) loss_oracle 0.0125 (0.0091) kd_loss 0.8955 (0.9197) acc 28.1250 (26.3021) lr 1.0000e-05 eta 0:44:00
epoch [1/50] batch [80/428] time 0.080 (0.117) data 0.000 (0.010) loss 2.7458 (2.8201) teacher_loss 2.2729 (2.3551) loss_zs_kd 0.0079 (0.0028) loss_oracle 0.0382 (0.0115) kd_loss 0.9075 (0.9184) acc 31.2500 (26.6406) lr 1.0000e-05 eta 0:41:38
epoch [1/50] batch [100/428] time 0.080 (0.116) data 0.000 (0.008) loss 2.8618 (2.8071) teacher_loss 2.3492 (2.3319) loss_zs_kd 0.0135 (0.0049) loss_oracle 0.1099 (0.0270) kd_loss 0.9154 (0.9233) acc 28.1250 (27.0312) lr 1.0000e-05 eta 0:41:14
epoch [1/50] batch [120/428] time 0.082 (0.116) data 0.000 (0.006) loss 2.8359 (2.7989) teacher_loss 2.2643 (2.3087) loss_zs_kd 0.0291 (0.0076) loss_oracle 0.2898 (0.0584) kd_loss 0.8534 (0.9219) acc 37.5000 (27.6823) lr 1.0000e-05 eta 0:41:01
epoch [1/50] batch [140/428] time 0.100 (0.113) data 0.000 (0.006) loss 2.9122 (2.8196) teacher_loss 2.2071 (2.3049) loss_zs_kd 0.0460 (0.0114) loss_oracle 0.4274 (0.1047) kd_loss 0.9827 (0.9246) acc 21.8750 (27.8125) lr 1.0000e-05 eta 0:39:57
epoch [1/50] batch [160/428] time 0.098 (0.112) data 0.000 (0.005) loss 2.9523 (2.8214) teacher_loss 2.0185 (2.2749) loss_zs_kd 0.1480 (0.0211) loss_oracle 0.8700 (0.1661) kd_loss 0.9976 (0.9269) acc 37.5000 (28.3984) lr 1.0000e-05 eta 0:39:37
epoch [1/50] batch [180/428] time 0.114 (0.111) data 0.000 (0.004) loss 3.1833 (2.8283) teacher_loss 2.3319 (2.2424) loss_zs_kd 0.1935 (0.0463) loss_oracle 0.7864 (0.2395) kd_loss 0.9162 (0.9322) acc 28.1250 (29.2188) lr 1.0000e-05 eta 0:39:04
epoch [1/50] batch [200/428] time 0.110 (0.110) data 0.000 (0.004) loss 2.9888 (2.8458) teacher_loss 1.9698 (2.2185) loss_zs_kd 0.3494 (0.0721) loss_oracle 1.0129 (0.3138) kd_loss 1.0251 (0.9407) acc 43.7500 (29.7344) lr 1.0000e-05 eta 0:38:50
epoch [1/50] batch [220/428] time 0.088 (0.109) data 0.000 (0.004) loss 3.2416 (2.8538) teacher_loss 2.3816 (2.1980) loss_zs_kd 0.2364 (0.0928) loss_oracle 0.7043 (0.3647) kd_loss 1.0157 (0.9470) acc 31.2500 (30.3835) lr 1.0000e-05 eta 0:38:32
epoch [1/50] batch [240/428] time 0.093 (0.108) data 0.000 (0.003) loss 2.9157 (2.8574) teacher_loss 1.9445 (2.1775) loss_zs_kd 0.3025 (0.1136) loss_oracle 0.9015 (0.4070) kd_loss 1.0410 (0.9527) acc 37.5000 (30.9115) lr 1.0000e-05 eta 0:37:59
epoch [1/50] batch [260/428] time 0.088 (0.106) data 0.000 (0.003) loss 3.4263 (2.8583) teacher_loss 2.4204 (2.1573) loss_zs_kd 0.2817 (0.1322) loss_oracle 0.9849 (0.4455) kd_loss 1.0268 (0.9566) acc 34.3750 (31.3822) lr 1.0000e-05 eta 0:37:23
epoch [1/50] batch [280/428] time 0.088 (0.105) data 0.000 (0.003) loss 2.6386 (2.8531) teacher_loss 1.6045 (2.1343) loss_zs_kd 0.4544 (0.1502) loss_oracle 1.0048 (0.4771) kd_loss 1.0636 (0.9604) acc 50.0000 (31.9531) lr 1.0000e-05 eta 0:36:53
epoch [1/50] batch [300/428] time 0.092 (0.104) data 0.000 (0.003) loss 3.2132 (2.8529) teacher_loss 2.1609 (2.1144) loss_zs_kd 0.4689 (0.1671) loss_oracle 1.0490 (0.5125) kd_loss 1.0555 (0.9645) acc 25.0000 (32.4583) lr 1.0000e-05 eta 0:36:28
epoch [1/50] batch [320/428] time 0.093 (0.103) data 0.000 (0.003) loss 2.8826 (2.8524) teacher_loss 1.7951 (2.0954) loss_zs_kd 0.4809 (0.1842) loss_oracle 1.1029 (0.5456) kd_loss 1.0721 (0.9683) acc 37.5000 (32.8711) lr 1.0000e-05 eta 0:36:11
epoch [1/50] batch [340/428] time 0.093 (0.102) data 0.000 (0.002) loss 2.9997 (2.8513) teacher_loss 1.9447 (2.0790) loss_zs_kd 0.3666 (0.1991) loss_oracle 1.0440 (0.5736) kd_loss 1.0659 (0.9709) acc 40.6250 (33.2537) lr 1.0000e-05 eta 0:35:53
epoch [1/50] batch [360/428] time 0.089 (0.101) data 0.000 (0.002) loss 2.6519 (2.8491) teacher_loss 1.5967 (2.0622) loss_zs_kd 0.4916 (0.2137) loss_oracle 1.0435 (0.5991) kd_loss 1.0668 (0.9746) acc 50.0000 (33.6111) lr 1.0000e-05 eta 0:35:32
epoch [1/50] batch [380/428] time 0.084 (0.101) data 0.000 (0.002) loss 3.2004 (2.8518) teacher_loss 2.1736 (2.0517) loss_zs_kd 0.5229 (0.2268) loss_oracle 1.0680 (0.6224) kd_loss 0.9856 (0.9778) acc 25.0000 (33.8322) lr 1.0000e-05 eta 0:35:19
epoch [1/50] batch [400/428] time 0.101 (0.100) data 0.000 (0.002) loss 2.7210 (2.8497) teacher_loss 1.6637 (2.0372) loss_zs_kd 0.6545 (0.2422) loss_oracle 1.0550 (0.6434) kd_loss 1.0595 (0.9815) acc 53.1250 (34.2109) lr 1.0000e-05 eta 0:35:08
epoch [1/50] batch [420/428] time 0.119 (0.100) data 0.000 (0.002) loss 3.0871 (2.8458) teacher_loss 2.0326 (2.0232) loss_zs_kd 0.4841 (0.2532) loss_oracle 1.0343 (0.6613) kd_loss 1.0746 (0.9841) acc 34.3750 (34.5833) lr 1.0000e-05 eta 0:35:02
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,424
* accuracy: 41.3%
* error: 58.7%
* macro_f1: 25.3%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,088
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 28.0%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      41.3%, epoch: 1 *******
******* Domain 1 best val test acc: 44.0%, epoch: 1 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [2/50] batch [20/428] time 0.075 (0.107) data 0.000 (0.027) loss 2.7670 (2.9057) teacher_loss 1.7492 (1.8821) loss_zs_kd 0.5494 (0.3989) loss_oracle 1.0671 (1.0199) kd_loss 0.9684 (1.0274) acc 46.8750 (38.1250) lr 2.0000e-03 eta 0:37:25
epoch [2/50] batch [40/428] time 0.166 (0.110) data 0.000 (0.013) loss 2.7917 (2.7846) teacher_loss 1.7473 (1.7676) loss_zs_kd 0.7010 (0.5088) loss_oracle 1.0246 (1.0105) kd_loss 1.0641 (1.0234) acc 40.6250 (40.0000) lr 2.0000e-03 eta 0:38:15
epoch [2/50] batch [60/428] time 0.169 (0.107) data 0.000 (0.009) loss 2.4971 (2.7022) teacher_loss 1.4667 (1.6797) loss_zs_kd 0.6525 (0.5371) loss_oracle 1.0232 (1.0125) kd_loss 1.0377 (1.0325) acc 62.5000 (42.7604) lr 2.0000e-03 eta 0:37:20
epoch [2/50] batch [80/428] time 0.056 (0.103) data 0.000 (0.007) loss 2.6785 (2.6339) teacher_loss 1.6500 (1.6088) loss_zs_kd 0.7908 (0.5848) loss_oracle 1.0414 (1.0214) kd_loss 1.0157 (1.0288) acc 50.0000 (45.2734) lr 2.0000e-03 eta 0:35:51
epoch [2/50] batch [100/428] time 0.094 (0.101) data 0.000 (0.006) loss 2.6082 (2.5839) teacher_loss 1.6000 (1.5593) loss_zs_kd 0.8812 (0.6933) loss_oracle 1.0393 (1.0225) kd_loss 0.9771 (1.0266) acc 43.7500 (47.1562) lr 2.0000e-03 eta 0:35:18
epoch [2/50] batch [120/428] time 0.100 (0.101) data 0.000 (0.005) loss 2.8422 (2.5717) teacher_loss 1.8337 (1.5493) loss_zs_kd 1.0772 (0.7200) loss_oracle 1.0420 (1.0211) kd_loss 0.9749 (1.0236) acc 31.2500 (47.3438) lr 2.0000e-03 eta 0:34:58
epoch [2/50] batch [140/428] time 0.096 (0.101) data 0.000 (0.004) loss 2.0558 (2.5307) teacher_loss 1.0795 (1.5094) loss_zs_kd 1.1108 (0.7896) loss_oracle 0.9959 (1.0208) kd_loss 0.9568 (1.0217) acc 65.6250 (48.3929) lr 2.0000e-03 eta 0:35:03
epoch [2/50] batch [160/428] time 0.101 (0.101) data 0.000 (0.004) loss 2.2487 (2.5021) teacher_loss 1.1966 (1.4811) loss_zs_kd 1.1619 (0.8488) loss_oracle 1.0455 (1.0199) kd_loss 1.0587 (1.0220) acc 62.5000 (49.3555) lr 2.0000e-03 eta 0:35:01
epoch [2/50] batch [180/428] time 0.104 (0.101) data 0.001 (0.003) loss 2.0622 (2.4757) teacher_loss 1.0058 (1.4532) loss_zs_kd 1.2846 (0.8987) loss_oracle 1.0784 (1.0216) kd_loss 1.0344 (1.0233) acc 65.6250 (50.2257) lr 2.0000e-03 eta 0:35:05
epoch [2/50] batch [200/428] time 0.100 (0.102) data 0.000 (0.003) loss 2.0620 (2.4514) teacher_loss 1.0430 (1.4280) loss_zs_kd 1.1492 (0.9202) loss_oracle 1.0388 (1.0236) kd_loss 0.9990 (1.0234) acc 62.5000 (51.2812) lr 2.0000e-03 eta 0:35:10
epoch [2/50] batch [220/428] time 0.094 (0.102) data 0.000 (0.003) loss 1.9598 (2.4174) teacher_loss 0.9579 (1.3935) loss_zs_kd 1.1876 (0.9688) loss_oracle 1.0223 (1.0247) kd_loss 0.9815 (1.0232) acc 68.7500 (52.5142) lr 2.0000e-03 eta 0:35:10
epoch [2/50] batch [240/428] time 0.103 (0.102) data 0.000 (0.002) loss 1.8937 (2.3892) teacher_loss 0.8396 (1.3646) loss_zs_kd 1.4118 (1.0027) loss_oracle 1.0926 (1.0257) kd_loss 1.0157 (1.0234) acc 75.0000 (53.6328) lr 2.0000e-03 eta 0:35:12
epoch [2/50] batch [260/428] time 0.099 (0.102) data 0.000 (0.002) loss 1.8805 (2.3685) teacher_loss 0.7876 (1.3431) loss_zs_kd 1.4413 (1.0484) loss_oracle 1.1025 (1.0266) kd_loss 1.0834 (1.0243) acc 78.1250 (54.3870) lr 2.0000e-03 eta 0:35:12
epoch [2/50] batch [280/428] time 0.115 (0.103) data 0.000 (0.002) loss 2.3966 (2.3592) teacher_loss 1.3439 (1.3328) loss_zs_kd 1.4231 (1.0780) loss_oracle 1.0879 (1.0288) kd_loss 1.0177 (1.0240) acc 65.6250 (54.7545) lr 2.0000e-03 eta 0:35:22
epoch [2/50] batch [300/428] time 0.107 (0.103) data 0.000 (0.002) loss 2.4157 (2.3500) teacher_loss 1.3822 (1.3232) loss_zs_kd 1.5624 (1.1023) loss_oracle 1.0408 (1.0300) kd_loss 1.0262 (1.0236) acc 50.0000 (55.0208) lr 2.0000e-03 eta 0:35:25
epoch [2/50] batch [320/428] time 0.106 (0.103) data 0.000 (0.002) loss 2.1622 (2.3373) teacher_loss 1.1220 (1.3098) loss_zs_kd 1.5474 (1.1296) loss_oracle 1.0695 (1.0306) kd_loss 1.0109 (1.0244) acc 53.1250 (55.3027) lr 2.0000e-03 eta 0:35:25
epoch [2/50] batch [340/428] time 0.103 (0.103) data 0.000 (0.002) loss 1.9625 (2.3230) teacher_loss 0.9029 (1.2946) loss_zs_kd 1.6182 (1.1590) loss_oracle 1.0714 (1.0320) kd_loss 1.0477 (1.0250) acc 62.5000 (55.6434) lr 2.0000e-03 eta 0:35:28
epoch [2/50] batch [360/428] time 0.093 (0.103) data 0.000 (0.002) loss 1.6394 (2.3096) teacher_loss 0.6420 (1.2800) loss_zs_kd 1.1204 (1.1731) loss_oracle 0.9983 (1.0336) kd_loss 0.9966 (1.0257) acc 84.3750 (56.0243) lr 2.0000e-03 eta 0:35:29
epoch [2/50] batch [380/428] time 0.108 (0.103) data 0.000 (0.002) loss 2.1071 (2.3036) teacher_loss 1.0978 (1.2739) loss_zs_kd 1.4343 (1.1806) loss_oracle 1.0126 (1.0337) kd_loss 1.0060 (1.0258) acc 62.5000 (56.0362) lr 2.0000e-03 eta 0:35:30
epoch [2/50] batch [400/428] time 0.091 (0.104) data 0.000 (0.002) loss 2.1351 (2.3032) teacher_loss 1.1400 (1.2741) loss_zs_kd 1.4026 (1.1865) loss_oracle 0.9999 (1.0334) kd_loss 0.9904 (1.0248) acc 68.7500 (55.9062) lr 2.0000e-03 eta 0:35:30
epoch [2/50] batch [420/428] time 0.099 (0.104) data 0.000 (0.002) loss 2.0248 (2.2975) teacher_loss 1.0158 (1.2687) loss_zs_kd 1.5931 (1.2106) loss_oracle 1.0061 (1.0339) kd_loss 1.0118 (1.0238) acc 65.6250 (56.1384) lr 2.0000e-03 eta 0:35:29
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,908
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 28.3%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,815
* accuracy: 38.3%
* error: 61.7%
* macro_f1: 25.4%
******* Domain 1 best val acc:      49.5%, epoch: 2 *******
******* Domain 1 best val test acc: 38.3%, epoch: 2 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [3/50] batch [20/428] time 0.079 (0.137) data 0.000 (0.031) loss 2.3425 (2.2997) teacher_loss 1.3029 (1.2796) loss_zs_kd 1.3845 (1.2911) loss_oracle 1.0499 (1.0333) kd_loss 1.0293 (1.0068) acc 59.3750 (53.9062) lr 1.9980e-03 eta 0:46:57
epoch [3/50] batch [40/428] time 0.079 (0.120) data 0.000 (0.016) loss 2.4102 (2.2894) teacher_loss 1.4032 (1.2801) loss_zs_kd 1.2356 (1.2386) loss_oracle 1.0290 (1.0223) kd_loss 0.9851 (0.9963) acc 46.8750 (53.5156) lr 1.9980e-03 eta 0:40:54
epoch [3/50] batch [60/428] time 0.072 (0.116) data 0.001 (0.011) loss 2.4177 (2.2670) teacher_loss 1.3886 (1.2590) loss_zs_kd 1.2782 (1.2724) loss_oracle 1.0422 (1.0224) kd_loss 1.0159 (0.9935) acc 50.0000 (55.2083) lr 1.9980e-03 eta 0:39:38
epoch [3/50] batch [80/428] time 0.071 (0.111) data 0.000 (0.008) loss 1.8529 (2.2483) teacher_loss 0.8765 (1.2385) loss_zs_kd 1.4709 (1.3141) loss_oracle 0.9829 (1.0263) kd_loss 0.9700 (0.9931) acc 71.8750 (55.8594) lr 1.9980e-03 eta 0:37:57
epoch [3/50] batch [100/428] time 0.115 (0.107) data 0.000 (0.006) loss 2.4881 (2.2399) teacher_loss 1.4567 (1.2272) loss_zs_kd 1.5049 (1.3135) loss_oracle 1.0310 (1.0290) kd_loss 1.0319 (0.9964) acc 53.1250 (56.6562) lr 1.9980e-03 eta 0:36:37
epoch [3/50] batch [120/428] time 0.095 (0.107) data 0.000 (0.005) loss 2.2908 (2.2173) teacher_loss 1.2310 (1.1965) loss_zs_kd 1.4634 (1.3383) loss_oracle 1.0896 (1.0369) kd_loss 1.0299 (1.0047) acc 65.6250 (57.8646) lr 1.9980e-03 eta 0:36:24
epoch [3/50] batch [140/428] time 0.096 (0.106) data 0.000 (0.005) loss 2.2530 (2.2041) teacher_loss 1.1970 (1.1793) loss_zs_kd 1.8327 (1.3678) loss_oracle 1.0894 (1.0414) kd_loss 1.0227 (1.0082) acc 50.0000 (58.4598) lr 1.9980e-03 eta 0:36:07
epoch [3/50] batch [160/428] time 0.109 (0.106) data 0.000 (0.004) loss 2.3334 (2.2030) teacher_loss 1.3560 (1.1805) loss_zs_kd 1.4275 (1.3991) loss_oracle 0.9851 (1.0382) kd_loss 0.9697 (1.0066) acc 53.1250 (58.5547) lr 1.9980e-03 eta 0:35:52
epoch [3/50] batch [180/428] time 0.089 (0.105) data 0.000 (0.004) loss 1.9139 (2.1865) teacher_loss 0.8516 (1.1648) loss_zs_kd 1.8655 (1.4177) loss_oracle 1.0462 (1.0376) kd_loss 1.0784 (1.0057) acc 75.0000 (59.0451) lr 1.9980e-03 eta 0:35:45
epoch [3/50] batch [200/428] time 0.105 (0.105) data 0.000 (0.003) loss 2.0297 (2.1775) teacher_loss 0.9515 (1.1505) loss_zs_kd 1.4573 (1.4517) loss_oracle 1.0857 (1.0441) kd_loss 1.0708 (1.0099) acc 62.5000 (59.7500) lr 1.9980e-03 eta 0:35:39
epoch [3/50] batch [220/428] time 0.107 (0.105) data 0.000 (0.003) loss 2.0911 (2.1686) teacher_loss 1.0409 (1.1393) loss_zs_kd 1.9169 (1.4720) loss_oracle 1.0659 (1.0473) kd_loss 1.0346 (1.0113) acc 62.5000 (60.0284) lr 1.9980e-03 eta 0:35:35
epoch [3/50] batch [240/428] time 0.090 (0.105) data 0.000 (0.003) loss 1.8725 (2.1597) teacher_loss 0.8096 (1.1281) loss_zs_kd 1.5080 (1.4729) loss_oracle 1.1054 (1.0500) kd_loss 1.0204 (1.0132) acc 78.1250 (60.4948) lr 1.9980e-03 eta 0:35:30
epoch [3/50] batch [260/428] time 0.099 (0.105) data 0.000 (0.003) loss 2.3383 (2.1540) teacher_loss 1.2669 (1.1205) loss_zs_kd 1.4644 (1.4806) loss_oracle 1.0878 (1.0528) kd_loss 1.0550 (1.0140) acc 56.2500 (60.8534) lr 1.9980e-03 eta 0:35:26
epoch [3/50] batch [280/428] time 0.110 (0.105) data 0.000 (0.002) loss 1.9843 (2.1534) teacher_loss 0.9154 (1.1176) loss_zs_kd 1.5858 (1.4796) loss_oracle 1.0995 (1.0548) kd_loss 1.0384 (1.0167) acc 62.5000 (61.0045) lr 1.9980e-03 eta 0:35:24
epoch [3/50] batch [300/428] time 0.109 (0.105) data 0.000 (0.002) loss 2.0103 (2.1468) teacher_loss 0.9261 (1.1087) loss_zs_kd 1.3242 (1.4735) loss_oracle 1.0802 (1.0564) kd_loss 1.0882 (1.0198) acc 71.8750 (61.4062) lr 1.9980e-03 eta 0:35:31
epoch [3/50] batch [320/428] time 0.109 (0.105) data 0.000 (0.002) loss 1.8142 (2.1324) teacher_loss 0.7386 (1.0931) loss_zs_kd 1.3901 (1.4715) loss_oracle 1.0832 (1.0571) kd_loss 1.0680 (1.0215) acc 75.0000 (62.0215) lr 1.9980e-03 eta 0:35:30
epoch [3/50] batch [340/428] time 0.113 (0.105) data 0.000 (0.002) loss 2.0137 (2.1251) teacher_loss 0.9183 (1.0830) loss_zs_kd 1.4483 (1.4828) loss_oracle 1.0924 (1.0600) kd_loss 1.0983 (1.0243) acc 71.8750 (62.5000) lr 1.9980e-03 eta 0:35:28
epoch [3/50] batch [360/428] time 0.110 (0.105) data 0.000 (0.002) loss 2.0308 (2.1167) teacher_loss 0.9410 (1.0720) loss_zs_kd 1.5502 (1.4899) loss_oracle 1.1211 (1.0628) kd_loss 1.0584 (1.0265) acc 71.8750 (62.8646) lr 1.9980e-03 eta 0:35:25
epoch [3/50] batch [380/428] time 0.107 (0.105) data 0.000 (0.002) loss 2.2462 (2.1143) teacher_loss 1.1988 (1.0680) loss_zs_kd 1.3388 (1.4901) loss_oracle 1.0819 (1.0646) kd_loss 1.0130 (1.0280) acc 56.2500 (62.9194) lr 1.9980e-03 eta 0:35:18
epoch [3/50] batch [400/428] time 0.105 (0.105) data 0.000 (0.002) loss 2.0919 (2.1099) teacher_loss 1.0040 (1.0628) loss_zs_kd 1.8720 (1.4890) loss_oracle 1.1258 (1.0658) kd_loss 1.0499 (1.0283) acc 68.7500 (63.1484) lr 1.9980e-03 eta 0:35:14
epoch [3/50] batch [420/428] time 0.097 (0.105) data 0.000 (0.002) loss 1.8410 (2.1028) teacher_loss 0.7950 (1.0547) loss_zs_kd 1.7298 (1.4947) loss_oracle 1.0639 (1.0669) kd_loss 1.0282 (1.0292) acc 75.0000 (63.4301) lr 1.9980e-03 eta 0:35:10
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,111
* accuracy: 52.9%
* error: 47.1%
* macro_f1: 34.9%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,155
* accuracy: 45.5%
* error: 54.5%
* macro_f1: 27.8%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      52.9%, epoch: 3 *******
******* Domain 1 best val test acc: 45.5%, epoch: 3 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [4/50] batch [20/428] time 0.097 (0.109) data 0.000 (0.026) loss 2.3080 (1.9893) teacher_loss 1.2132 (0.9277) loss_zs_kd 1.4183 (1.5193) loss_oracle 1.0977 (1.0771) kd_loss 1.0919 (1.0462) acc 50.0000 (67.0312) lr 1.9921e-03 eta 0:36:34
epoch [4/50] batch [40/428] time 0.087 (0.104) data 0.000 (0.013) loss 2.0515 (2.0157) teacher_loss 0.9570 (0.9488) loss_zs_kd 1.6202 (1.5075) loss_oracle 1.1060 (1.0868) kd_loss 1.0831 (1.0472) acc 75.0000 (67.5000) lr 1.9921e-03 eta 0:34:52
epoch [4/50] batch [60/428] time 0.093 (0.102) data 0.000 (0.009) loss 2.4094 (2.0315) teacher_loss 1.3549 (0.9644) loss_zs_kd 1.5328 (1.5229) loss_oracle 1.0683 (1.0873) kd_loss 1.0407 (1.0469) acc 56.2500 (66.4583) lr 1.9921e-03 eta 0:34:09
epoch [4/50] batch [80/428] time 0.085 (0.107) data 0.001 (0.007) loss 2.1989 (2.0383) teacher_loss 1.1535 (0.9735) loss_zs_kd 1.2122 (1.5073) loss_oracle 1.0697 (1.0851) kd_loss 1.0211 (1.0446) acc 65.6250 (66.0156) lr 1.9921e-03 eta 0:35:47
epoch [4/50] batch [100/428] time 0.078 (0.109) data 0.000 (0.005) loss 1.8723 (2.0511) teacher_loss 0.8273 (0.9861) loss_zs_kd 1.6184 (1.5068) loss_oracle 1.0937 (1.0860) kd_loss 0.9962 (1.0438) acc 71.8750 (65.5625) lr 1.9921e-03 eta 0:36:24
epoch [4/50] batch [120/428] time 0.111 (0.109) data 0.000 (0.005) loss 2.0822 (2.0497) teacher_loss 1.0868 (0.9873) loss_zs_kd 1.2467 (1.4783) loss_oracle 1.0267 (1.0839) kd_loss 0.9641 (1.0409) acc 46.8750 (65.6771) lr 1.9921e-03 eta 0:36:13
epoch [4/50] batch [140/428] time 0.108 (0.108) data 0.000 (0.004) loss 2.1429 (2.0629) teacher_loss 1.1014 (1.0039) loss_zs_kd 1.3958 (1.4432) loss_oracle 1.0701 (1.0801) kd_loss 1.0128 (1.0379) acc 62.5000 (65.4464) lr 1.9921e-03 eta 0:35:53
epoch [4/50] batch [160/428] time 0.102 (0.107) data 0.000 (0.003) loss 1.9885 (2.0799) teacher_loss 0.9121 (1.0227) loss_zs_kd 1.2211 (1.4338) loss_oracle 1.1075 (1.0774) kd_loss 1.0453 (1.0369) acc 68.7500 (64.4922) lr 1.9921e-03 eta 0:35:39
epoch [4/50] batch [180/428] time 0.108 (0.107) data 0.000 (0.003) loss 2.4696 (2.0878) teacher_loss 1.4401 (1.0310) loss_zs_kd 1.2070 (1.4110) loss_oracle 1.0019 (1.0766) kd_loss 1.0572 (1.0369) acc 43.7500 (63.9583) lr 1.9921e-03 eta 0:35:31
epoch [4/50] batch [200/428] time 0.096 (0.107) data 0.000 (0.003) loss 2.0086 (2.0854) teacher_loss 0.9785 (1.0290) loss_zs_kd 1.2054 (1.3922) loss_oracle 1.0531 (1.0757) kd_loss 1.0069 (1.0372) acc 65.6250 (64.0781) lr 1.9921e-03 eta 0:35:22
epoch [4/50] batch [220/428] time 0.115 (0.106) data 0.000 (0.003) loss 2.0118 (2.0931) teacher_loss 0.9867 (1.0368) loss_zs_kd 1.3765 (1.3913) loss_oracle 1.0566 (1.0753) kd_loss 0.9937 (1.0373) acc 62.5000 (63.8210) lr 1.9921e-03 eta 0:35:17
epoch [4/50] batch [240/428] time 0.100 (0.106) data 0.000 (0.002) loss 2.0015 (2.0835) teacher_loss 0.9535 (1.0276) loss_zs_kd 1.4408 (1.3901) loss_oracle 1.0682 (1.0738) kd_loss 1.0279 (1.0380) acc 68.7500 (64.1406) lr 1.9921e-03 eta 0:35:13
epoch [4/50] batch [260/428] time 0.106 (0.106) data 0.000 (0.002) loss 2.0594 (2.0799) teacher_loss 1.0075 (1.0241) loss_zs_kd 1.5990 (1.4047) loss_oracle 1.0442 (1.0726) kd_loss 1.0597 (1.0388) acc 56.2500 (64.1106) lr 1.9921e-03 eta 0:35:08
epoch [4/50] batch [280/428] time 0.110 (0.106) data 0.000 (0.002) loss 1.8855 (2.0736) teacher_loss 0.8530 (1.0183) loss_zs_kd 1.4689 (1.4067) loss_oracle 1.0251 (1.0719) kd_loss 1.0399 (1.0387) acc 75.0000 (64.4085) lr 1.9921e-03 eta 0:35:04
epoch [4/50] batch [300/428] time 0.107 (0.106) data 0.000 (0.002) loss 1.8247 (2.0702) teacher_loss 0.7758 (1.0154) loss_zs_kd 1.4929 (1.4093) loss_oracle 1.0651 (1.0707) kd_loss 1.0327 (1.0389) acc 78.1250 (64.6354) lr 1.9921e-03 eta 0:34:59
epoch [4/50] batch [320/428] time 0.103 (0.106) data 0.000 (0.002) loss 2.0964 (2.0628) teacher_loss 1.0455 (1.0078) loss_zs_kd 1.7886 (1.4198) loss_oracle 1.0548 (1.0701) kd_loss 1.0470 (1.0399) acc 62.5000 (64.9023) lr 1.9921e-03 eta 0:34:58
epoch [4/50] batch [340/428] time 0.106 (0.106) data 0.000 (0.002) loss 2.1188 (2.0539) teacher_loss 1.0782 (0.9994) loss_zs_kd 1.7989 (1.4365) loss_oracle 1.0698 (1.0693) kd_loss 1.0115 (1.0398) acc 62.5000 (65.2849) lr 1.9921e-03 eta 0:34:57
epoch [4/50] batch [360/428] time 0.110 (0.106) data 0.000 (0.002) loss 1.9599 (2.0499) teacher_loss 0.8927 (0.9952) loss_zs_kd 1.5969 (1.4538) loss_oracle 1.0458 (1.0685) kd_loss 1.0887 (1.0409) acc 65.6250 (65.3906) lr 1.9921e-03 eta 0:34:55
epoch [4/50] batch [380/428] time 0.095 (0.106) data 0.000 (0.002) loss 1.9860 (2.0427) teacher_loss 0.9208 (0.9883) loss_zs_kd 1.8745 (1.4639) loss_oracle 1.0577 (1.0677) kd_loss 1.0727 (1.0411) acc 68.7500 (65.5921) lr 1.9921e-03 eta 0:34:52
epoch [4/50] batch [400/428] time 0.118 (0.106) data 0.000 (0.002) loss 1.9650 (2.0392) teacher_loss 0.9394 (0.9848) loss_zs_kd 1.3673 (1.4725) loss_oracle 1.0519 (1.0671) kd_loss 0.9992 (1.0416) acc 78.1250 (65.7422) lr 1.9921e-03 eta 0:34:50
epoch [4/50] batch [420/428] time 0.106 (0.106) data 0.001 (0.001) loss 2.0012 (2.0375) teacher_loss 0.9527 (0.9831) loss_zs_kd 1.7759 (1.4859) loss_oracle 1.0471 (1.0665) kd_loss 1.0501 (1.0424) acc 65.6250 (65.8557) lr 1.9921e-03 eta 0:34:46
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,921
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 33.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,787
* accuracy: 37.7%
* error: 62.3%
* macro_f1: 25.2%
******* Domain 1 best val acc:      52.9%, epoch: 3 *******
******* Domain 1 best val test acc: 45.5%, epoch: 3 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [5/50] batch [20/428] time 0.084 (0.140) data 0.000 (0.032) loss 1.8421 (1.9336) teacher_loss 0.7910 (0.8822) loss_zs_kd 1.5559 (1.7891) loss_oracle 1.0608 (1.0586) kd_loss 1.0414 (1.0442) acc 78.1250 (69.0625) lr 1.9823e-03 eta 0:45:44
epoch [5/50] batch [40/428] time 0.174 (0.120) data 0.000 (0.016) loss 1.9119 (1.9353) teacher_loss 0.8620 (0.8841) loss_zs_kd 1.7097 (1.7842) loss_oracle 1.0840 (1.0566) kd_loss 1.0159 (1.0459) acc 65.6250 (69.5312) lr 1.9823e-03 eta 0:39:09
epoch [5/50] batch [60/428] time 0.114 (0.119) data 0.000 (0.011) loss 1.8341 (1.9089) teacher_loss 0.7648 (0.8567) loss_zs_kd 1.7552 (1.8389) loss_oracle 1.0717 (1.0569) kd_loss 1.0668 (1.0474) acc 71.8750 (70.7292) lr 1.9823e-03 eta 0:38:51
epoch [5/50] batch [80/428] time 0.148 (0.119) data 0.000 (0.008) loss 2.1138 (1.9400) teacher_loss 1.0782 (0.8866) loss_zs_kd 1.7745 (1.8262) loss_oracle 0.9993 (1.0551) kd_loss 1.0720 (1.0517) acc 59.3750 (69.5703) lr 1.9823e-03 eta 0:38:46
epoch [5/50] batch [100/428] time 0.073 (0.114) data 0.000 (0.007) loss 1.7964 (1.9575) teacher_loss 0.7525 (0.9040) loss_zs_kd 1.7224 (1.7904) loss_oracle 1.0686 (1.0561) kd_loss 1.0192 (1.0509) acc 68.7500 (69.1875) lr 1.9823e-03 eta 0:37:08
epoch [5/50] batch [120/428] time 0.106 (0.111) data 0.000 (0.006) loss 2.1750 (1.9601) teacher_loss 1.1002 (0.9076) loss_zs_kd 1.6525 (1.7616) loss_oracle 1.0522 (1.0535) kd_loss 1.0976 (1.0515) acc 56.2500 (69.1146) lr 1.9823e-03 eta 0:36:07
epoch [5/50] batch [140/428] time 0.103 (0.110) data 0.000 (0.005) loss 1.9141 (1.9665) teacher_loss 0.8480 (0.9151) loss_zs_kd 1.0609 (1.7072) loss_oracle 1.0283 (1.0512) kd_loss 1.1040 (1.0517) acc 68.7500 (68.8839) lr 1.9823e-03 eta 0:35:51
epoch [5/50] batch [160/428] time 0.108 (0.109) data 0.000 (0.004) loss 2.0818 (1.9778) teacher_loss 1.0516 (0.9264) loss_zs_kd 1.4668 (1.6950) loss_oracle 1.0313 (1.0506) kd_loss 1.0290 (1.0521) acc 62.5000 (68.4961) lr 1.9823e-03 eta 0:35:31
epoch [5/50] batch [180/428] time 0.096 (0.109) data 0.000 (0.004) loss 2.1056 (1.9793) teacher_loss 1.0679 (0.9282) loss_zs_kd 1.6700 (1.6787) loss_oracle 1.0273 (1.0500) kd_loss 1.0483 (1.0521) acc 62.5000 (68.6806) lr 1.9823e-03 eta 0:35:20
epoch [5/50] batch [200/428] time 0.099 (0.108) data 0.000 (0.003) loss 1.9600 (1.9808) teacher_loss 0.9124 (0.9316) loss_zs_kd 1.1381 (1.6590) loss_oracle 1.0604 (1.0481) kd_loss 1.0347 (1.0502) acc 75.0000 (68.6250) lr 1.9823e-03 eta 0:35:07
epoch [5/50] batch [220/428] time 0.099 (0.108) data 0.000 (0.003) loss 2.1278 (1.9968) teacher_loss 1.0740 (0.9477) loss_zs_kd 1.4346 (1.6272) loss_oracle 1.0263 (1.0464) kd_loss 1.0813 (1.0518) acc 62.5000 (67.9688) lr 1.9823e-03 eta 0:34:59
epoch [5/50] batch [240/428] time 0.101 (0.107) data 0.000 (0.003) loss 2.4388 (2.0144) teacher_loss 1.3915 (0.9660) loss_zs_kd 1.4084 (1.6100) loss_oracle 1.0178 (1.0447) kd_loss 1.0769 (1.0521) acc 53.1250 (67.0573) lr 1.9823e-03 eta 0:34:50
epoch [5/50] batch [260/428] time 0.086 (0.107) data 0.000 (0.003) loss 2.0988 (2.0263) teacher_loss 1.0573 (0.9779) loss_zs_kd 1.4846 (1.5940) loss_oracle 1.0265 (1.0435) kd_loss 1.0564 (1.0533) acc 62.5000 (66.5024) lr 1.9823e-03 eta 0:34:29
epoch [5/50] batch [280/428] time 0.097 (0.105) data 0.000 (0.003) loss 1.8693 (2.0216) teacher_loss 0.8205 (0.9741) loss_zs_kd 1.3559 (1.5851) loss_oracle 1.0442 (1.0434) kd_loss 1.0535 (1.0516) acc 71.8750 (66.6964) lr 1.9823e-03 eta 0:34:07
epoch [5/50] batch [300/428] time 0.100 (0.105) data 0.000 (0.002) loss 1.9656 (2.0159) teacher_loss 0.9378 (0.9692) loss_zs_kd 1.7305 (1.5869) loss_oracle 1.0224 (1.0428) kd_loss 1.0331 (1.0506) acc 65.6250 (66.9583) lr 1.9823e-03 eta 0:33:50
epoch [5/50] batch [320/428] time 0.093 (0.105) data 0.000 (0.002) loss 1.8954 (2.0099) teacher_loss 0.8917 (0.9636) loss_zs_kd 1.5146 (1.5905) loss_oracle 1.0051 (1.0425) kd_loss 1.0023 (1.0500) acc 59.3750 (67.2168) lr 1.9823e-03 eta 0:33:47
epoch [5/50] batch [340/428] time 0.094 (0.105) data 0.000 (0.002) loss 1.8432 (2.0111) teacher_loss 0.8077 (0.9654) loss_zs_kd 1.2090 (1.5755) loss_oracle 1.0375 (1.0426) kd_loss 1.0335 (1.0489) acc 75.0000 (67.2610) lr 1.9823e-03 eta 0:33:45
epoch [5/50] batch [360/428] time 0.109 (0.105) data 0.000 (0.002) loss 1.5805 (2.0070) teacher_loss 0.5950 (0.9617) loss_zs_kd 1.3783 (1.5712) loss_oracle 0.9964 (1.0421) kd_loss 0.9745 (1.0485) acc 81.2500 (67.3785) lr 1.9823e-03 eta 0:33:41
epoch [5/50] batch [380/428] time 0.094 (0.104) data 0.000 (0.002) loss 2.0498 (1.9990) teacher_loss 1.0307 (0.9547) loss_zs_kd 2.0108 (1.5789) loss_oracle 1.0000 (1.0414) kd_loss 1.0380 (1.0471) acc 75.0000 (67.7220) lr 1.9823e-03 eta 0:33:37
epoch [5/50] batch [400/428] time 0.090 (0.105) data 0.000 (0.002) loss 2.0286 (1.9988) teacher_loss 1.0141 (0.9547) loss_zs_kd 1.2937 (1.5831) loss_oracle 1.0323 (1.0409) kd_loss 0.9968 (1.0472) acc 62.5000 (67.7500) lr 1.9823e-03 eta 0:33:37
epoch [5/50] batch [420/428] time 0.097 (0.104) data 0.000 (0.002) loss 1.7656 (1.9921) teacher_loss 0.7228 (0.9482) loss_zs_kd 1.6868 (1.5872) loss_oracle 1.0594 (1.0405) kd_loss 1.0262 (1.0473) acc 71.8750 (67.9167) lr 1.9823e-03 eta 0:33:32
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,202
* accuracy: 54.5%
* error: 45.5%
* macro_f1: 39.2%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,798
* accuracy: 37.9%
* error: 62.1%
* macro_f1: 25.2%
******* Domain 1 best val acc:      54.5%, epoch: 5 *******
******* Domain 1 best val test acc: 37.9%, epoch: 5 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [6/50] batch [20/428] time 0.077 (0.116) data 0.000 (0.029) loss 2.3168 (1.9375) teacher_loss 1.2851 (0.9017) loss_zs_kd 1.7724 (1.6019) loss_oracle 1.0533 (1.0334) kd_loss 1.0102 (1.0382) acc 62.5000 (69.2188) lr 1.9686e-03 eta 0:37:11
epoch [6/50] batch [40/428] time 0.082 (0.106) data 0.000 (0.014) loss 1.7727 (1.9223) teacher_loss 0.7245 (0.8890) loss_zs_kd 1.7221 (1.6036) loss_oracle 1.0625 (1.0323) kd_loss 1.0339 (1.0344) acc 75.0000 (69.2969) lr 1.9686e-03 eta 0:33:56
epoch [6/50] batch [60/428] time 0.164 (0.106) data 0.000 (0.010) loss 1.8231 (1.9371) teacher_loss 0.8102 (0.9043) loss_zs_kd 1.7455 (1.6342) loss_oracle 0.9812 (1.0284) kd_loss 1.0446 (1.0371) acc 81.2500 (68.8542) lr 1.9686e-03 eta 0:34:04
epoch [6/50] batch [80/428] time 0.079 (0.105) data 0.000 (0.007) loss 1.8606 (1.9596) teacher_loss 0.8624 (0.9251) loss_zs_kd 1.7594 (1.6503) loss_oracle 0.9818 (1.0286) kd_loss 1.0147 (1.0404) acc 68.7500 (68.0859) lr 1.9686e-03 eta 0:33:25
epoch [6/50] batch [100/428] time 0.075 (0.106) data 0.001 (0.006) loss 1.8676 (1.9734) teacher_loss 0.7905 (0.9371) loss_zs_kd 2.0128 (1.6484) loss_oracle 1.0299 (1.0287) kd_loss 1.1244 (1.0439) acc 71.8750 (67.2812) lr 1.9686e-03 eta 0:33:41
epoch [6/50] batch [120/428] time 0.107 (0.105) data 0.000 (0.005) loss 2.1056 (1.9620) teacher_loss 1.0493 (0.9242) loss_zs_kd 1.8196 (1.6692) loss_oracle 1.0164 (1.0291) kd_loss 1.0961 (1.0464) acc 59.3750 (67.7083) lr 1.9686e-03 eta 0:33:33
epoch [6/50] batch [140/428] time 0.101 (0.105) data 0.000 (0.004) loss 1.8716 (1.9562) teacher_loss 0.8032 (0.9175) loss_zs_kd 1.5515 (1.6633) loss_oracle 1.0555 (1.0300) kd_loss 1.0813 (1.0473) acc 78.1250 (68.3705) lr 1.9686e-03 eta 0:33:34
epoch [6/50] batch [160/428] time 0.110 (0.106) data 0.000 (0.004) loss 2.3439 (1.9544) teacher_loss 1.3153 (0.9158) loss_zs_kd 1.7586 (1.6575) loss_oracle 1.0245 (1.0300) kd_loss 1.0328 (1.0473) acc 59.3750 (68.7500) lr 1.9686e-03 eta 0:33:35
epoch [6/50] batch [180/428] time 0.101 (0.106) data 0.000 (0.003) loss 2.1007 (1.9569) teacher_loss 1.0772 (0.9190) loss_zs_kd 1.5068 (1.6492) loss_oracle 0.9852 (1.0286) kd_loss 1.0618 (1.0473) acc 59.3750 (68.6806) lr 1.9686e-03 eta 0:33:33
epoch [6/50] batch [200/428] time 0.108 (0.105) data 0.000 (0.003) loss 1.7847 (1.9535) teacher_loss 0.7264 (0.9155) loss_zs_kd 1.8322 (1.6463) loss_oracle 1.0340 (1.0287) kd_loss 1.0827 (1.0472) acc 87.5000 (68.8594) lr 1.9686e-03 eta 0:33:28
epoch [6/50] batch [220/428] time 0.102 (0.105) data 0.000 (0.003) loss 2.2903 (1.9548) teacher_loss 1.2557 (0.9176) loss_zs_kd 1.2470 (1.6365) loss_oracle 1.0261 (1.0278) kd_loss 1.0429 (1.0464) acc 62.5000 (68.8352) lr 1.9686e-03 eta 0:33:25
epoch [6/50] batch [240/428] time 0.102 (0.105) data 0.000 (0.003) loss 1.8066 (1.9512) teacher_loss 0.7754 (0.9156) loss_zs_kd 1.6229 (1.6210) loss_oracle 1.0634 (1.0270) kd_loss 0.9989 (1.0441) acc 75.0000 (69.0365) lr 1.9686e-03 eta 0:33:23
epoch [6/50] batch [260/428] time 0.101 (0.105) data 0.000 (0.002) loss 2.0051 (1.9490) teacher_loss 0.9998 (0.9145) loss_zs_kd 1.5579 (1.6125) loss_oracle 0.9508 (1.0262) kd_loss 1.0598 (1.0429) acc 59.3750 (68.9784) lr 1.9686e-03 eta 0:33:21
epoch [6/50] batch [280/428] time 0.108 (0.105) data 0.000 (0.002) loss 1.9288 (1.9545) teacher_loss 0.9194 (0.9213) loss_zs_kd 1.6445 (1.6097) loss_oracle 1.0225 (1.0254) kd_loss 0.9963 (1.0411) acc 75.0000 (68.5603) lr 1.9686e-03 eta 0:33:18
epoch [6/50] batch [300/428] time 0.104 (0.105) data 0.000 (0.002) loss 1.9025 (1.9534) teacher_loss 0.8772 (0.9209) loss_zs_kd 1.6188 (1.6156) loss_oracle 1.0406 (1.0250) kd_loss 1.0100 (1.0399) acc 71.8750 (68.6042) lr 1.9686e-03 eta 0:33:14
epoch [6/50] batch [320/428] time 0.112 (0.105) data 0.000 (0.002) loss 2.1379 (1.9533) teacher_loss 1.1664 (0.9215) loss_zs_kd 1.7481 (1.6272) loss_oracle 0.9514 (1.0246) kd_loss 0.9918 (1.0389) acc 56.2500 (68.6133) lr 1.9686e-03 eta 0:33:11
epoch [6/50] batch [340/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.7566 (1.9510) teacher_loss 0.7022 (0.9196) loss_zs_kd 1.2725 (1.6134) loss_oracle 1.0519 (1.0235) kd_loss 1.0570 (1.0393) acc 75.0000 (68.7592) lr 1.9686e-03 eta 0:33:10
epoch [6/50] batch [360/428] time 0.102 (0.105) data 0.000 (0.002) loss 1.9720 (1.9531) teacher_loss 0.9145 (0.9208) loss_zs_kd 1.4940 (1.6050) loss_oracle 1.0386 (1.0232) kd_loss 1.0766 (1.0413) acc 71.8750 (68.7413) lr 1.9686e-03 eta 0:33:08
epoch [6/50] batch [380/428] time 0.096 (0.105) data 0.000 (0.002) loss 2.1883 (1.9530) teacher_loss 1.1517 (0.9205) loss_zs_kd 1.5647 (1.6019) loss_oracle 1.0142 (1.0233) kd_loss 1.0591 (1.0418) acc 62.5000 (68.7993) lr 1.9686e-03 eta 0:33:05
epoch [6/50] batch [400/428] time 0.107 (0.105) data 0.000 (0.002) loss 1.9150 (1.9492) teacher_loss 0.8601 (0.9168) loss_zs_kd 1.3025 (1.5973) loss_oracle 1.0445 (1.0226) kd_loss 1.0652 (1.0422) acc 75.0000 (68.9375) lr 1.9686e-03 eta 0:33:02
epoch [6/50] batch [420/428] time 0.114 (0.105) data 0.001 (0.002) loss 1.8814 (1.9457) teacher_loss 0.8025 (0.9129) loss_zs_kd 1.7110 (1.5971) loss_oracle 1.0620 (1.0233) kd_loss 1.0956 (1.0422) acc 68.7500 (69.1741) lr 1.9686e-03 eta 0:33:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,173
* accuracy: 54.0%
* error: 46.0%
* macro_f1: 42.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,990
* accuracy: 42.0%
* error: 58.0%
* macro_f1: 27.3%
******* Domain 1 best val acc:      54.5%, epoch: 5 *******
******* Domain 1 best val test acc: 37.9%, epoch: 5 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [7/50] batch [20/428] time 0.068 (0.135) data 0.001 (0.028) loss 2.0692 (1.7774) teacher_loss 1.0536 (0.7460) loss_zs_kd 1.7371 (1.8148) loss_oracle 1.0225 (1.0268) kd_loss 1.0088 (1.0359) acc 62.5000 (75.6250) lr 1.9511e-03 eta 0:42:12
epoch [7/50] batch [40/428] time 0.102 (0.108) data 0.000 (0.014) loss 1.6745 (1.8282) teacher_loss 0.6527 (0.7998) loss_zs_kd 1.6579 (1.7361) loss_oracle 1.0082 (1.0268) kd_loss 1.0355 (1.0299) acc 81.2500 (73.5938) lr 1.9511e-03 eta 0:33:52
epoch [7/50] batch [60/428] time 0.075 (0.101) data 0.001 (0.009) loss 2.0822 (1.8642) teacher_loss 1.0650 (0.8381) loss_zs_kd 1.4037 (1.6401) loss_oracle 1.0195 (1.0239) kd_loss 1.0148 (1.0284) acc 65.6250 (72.1354) lr 1.9511e-03 eta 0:31:42
epoch [7/50] batch [80/428] time 0.066 (0.102) data 0.000 (0.007) loss 1.8948 (1.8558) teacher_loss 0.9144 (0.8323) loss_zs_kd 1.6861 (1.6157) loss_oracle 0.9362 (1.0191) kd_loss 1.0245 (1.0279) acc 75.0000 (72.5000) lr 1.9511e-03 eta 0:31:50
epoch [7/50] batch [100/428] time 0.059 (0.103) data 0.000 (0.006) loss 1.5569 (1.8654) teacher_loss 0.5380 (0.8419) loss_zs_kd 1.5183 (1.6247) loss_oracle 1.0231 (1.0191) kd_loss 1.0148 (1.0279) acc 84.3750 (71.8438) lr 1.9511e-03 eta 0:32:05
epoch [7/50] batch [120/428] time 0.081 (0.100) data 0.000 (0.005) loss 2.0485 (1.8691) teacher_loss 1.0170 (0.8452) loss_zs_kd 1.6753 (1.5916) loss_oracle 1.0344 (1.0193) kd_loss 1.0286 (1.0285) acc 59.3750 (71.4583) lr 1.9511e-03 eta 0:31:14
epoch [7/50] batch [140/428] time 0.104 (0.101) data 0.000 (0.004) loss 2.6239 (1.8859) teacher_loss 1.5923 (0.8623) loss_zs_kd 1.5999 (1.5713) loss_oracle 1.0091 (1.0182) kd_loss 1.0541 (1.0290) acc 43.7500 (70.8929) lr 1.9511e-03 eta 0:31:25
epoch [7/50] batch [160/428] time 0.089 (0.101) data 0.000 (0.004) loss 1.6565 (1.8759) teacher_loss 0.6443 (0.8526) loss_zs_kd 1.9452 (1.5800) loss_oracle 0.9950 (1.0182) kd_loss 1.0293 (1.0283) acc 78.1250 (71.4453) lr 1.9511e-03 eta 0:31:30
epoch [7/50] batch [180/428] time 0.110 (0.102) data 0.000 (0.003) loss 1.9164 (1.8784) teacher_loss 0.8936 (0.8555) loss_zs_kd 1.6185 (1.5793) loss_oracle 1.0255 (1.0182) kd_loss 1.0201 (1.0277) acc 65.6250 (71.2674) lr 1.9511e-03 eta 0:31:37
epoch [7/50] batch [200/428] time 0.104 (0.102) data 0.000 (0.003) loss 1.7103 (1.8853) teacher_loss 0.7127 (0.8636) loss_zs_kd 1.8516 (1.5720) loss_oracle 0.9979 (1.0179) kd_loss 0.9973 (1.0254) acc 78.1250 (70.8594) lr 1.9511e-03 eta 0:31:40
epoch [7/50] batch [220/428] time 0.112 (0.102) data 0.000 (0.003) loss 2.0390 (1.8933) teacher_loss 0.9794 (0.8721) loss_zs_kd 1.7621 (1.5729) loss_oracle 1.0436 (1.0173) kd_loss 1.0755 (1.0250) acc 65.6250 (70.4972) lr 1.9511e-03 eta 0:31:43
epoch [7/50] batch [240/428] time 0.086 (0.102) data 0.000 (0.003) loss 2.0772 (1.8927) teacher_loss 1.0483 (0.8720) loss_zs_kd 1.6878 (1.5751) loss_oracle 0.9839 (1.0168) kd_loss 1.0739 (1.0247) acc 65.6250 (70.5469) lr 1.9511e-03 eta 0:31:42
epoch [7/50] batch [260/428] time 0.103 (0.103) data 0.000 (0.002) loss 1.7825 (1.8960) teacher_loss 0.7761 (0.8756) loss_zs_kd 1.6527 (1.5756) loss_oracle 0.9794 (1.0174) kd_loss 1.0333 (1.0235) acc 75.0000 (70.5529) lr 1.9511e-03 eta 0:31:48
epoch [7/50] batch [280/428] time 0.115 (0.103) data 0.000 (0.002) loss 2.0528 (1.8888) teacher_loss 1.0540 (0.8695) loss_zs_kd 2.0541 (1.5853) loss_oracle 1.0201 (1.0164) kd_loss 0.9774 (1.0222) acc 62.5000 (70.7254) lr 1.9511e-03 eta 0:31:50
epoch [7/50] batch [300/428] time 0.112 (0.103) data 0.000 (0.002) loss 1.6472 (1.8853) teacher_loss 0.6615 (0.8664) loss_zs_kd 1.5441 (1.5939) loss_oracle 0.9772 (1.0163) kd_loss 0.9943 (1.0215) acc 75.0000 (71.0000) lr 1.9511e-03 eta 0:31:52
epoch [7/50] batch [320/428] time 0.103 (0.104) data 0.000 (0.002) loss 1.7769 (1.8807) teacher_loss 0.7641 (0.8630) loss_zs_kd 1.5985 (1.6049) loss_oracle 1.0160 (1.0156) kd_loss 1.0095 (1.0199) acc 71.8750 (71.1523) lr 1.9511e-03 eta 0:31:56
epoch [7/50] batch [340/428] time 0.098 (0.104) data 0.000 (0.002) loss 2.0762 (1.8805) teacher_loss 1.0775 (0.8640) loss_zs_kd 1.6502 (1.6007) loss_oracle 0.9996 (1.0144) kd_loss 0.9979 (1.0186) acc 68.7500 (71.1305) lr 1.9511e-03 eta 0:31:57
epoch [7/50] batch [360/428] time 0.116 (0.104) data 0.000 (0.002) loss 1.8186 (1.8820) teacher_loss 0.7950 (0.8663) loss_zs_kd 1.4623 (1.6018) loss_oracle 1.0286 (1.0139) kd_loss 1.0185 (1.0175) acc 71.8750 (70.9115) lr 1.9511e-03 eta 0:31:57
epoch [7/50] batch [380/428] time 0.096 (0.104) data 0.000 (0.002) loss 1.6927 (1.8781) teacher_loss 0.7000 (0.8636) loss_zs_kd 1.4391 (1.6121) loss_oracle 1.0139 (1.0135) kd_loss 0.9715 (1.0155) acc 81.2500 (71.0526) lr 1.9511e-03 eta 0:31:56
epoch [7/50] batch [400/428] time 0.106 (0.104) data 0.000 (0.002) loss 2.3274 (1.8774) teacher_loss 1.2900 (0.8637) loss_zs_kd 1.6911 (1.6193) loss_oracle 1.0034 (1.0129) kd_loss 1.0714 (1.0145) acc 40.6250 (71.0469) lr 1.9511e-03 eta 0:31:56
epoch [7/50] batch [420/428] time 0.098 (0.104) data 0.000 (0.002) loss 1.8795 (1.8823) teacher_loss 0.7410 (0.8673) loss_zs_kd 1.4205 (1.6159) loss_oracle 1.0603 (1.0129) kd_loss 1.2169 (1.0171) acc 75.0000 (71.0417) lr 1.9511e-03 eta 0:31:53
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,393
* accuracy: 57.7%
* error: 42.3%
* macro_f1: 40.3%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,795
* accuracy: 37.9%
* error: 62.1%
* macro_f1: 25.9%
******* Domain 1 best val acc:      57.7%, epoch: 7 *******
******* Domain 1 best val test acc: 37.9%, epoch: 7 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [8/50] batch [20/428] time 0.080 (0.138) data 0.000 (0.028) loss 2.1008 (2.2241) teacher_loss 0.9482 (1.1079) loss_zs_kd 1.0144 (1.5016) loss_oracle 1.1210 (1.0405) kd_loss 1.1842 (1.1920) acc 65.6250 (61.4062) lr 1.9298e-03 eta 0:42:22
epoch [8/50] batch [40/428] time 0.139 (0.120) data 0.000 (0.014) loss 2.3221 (2.2214) teacher_loss 1.1905 (1.0970) loss_zs_kd 1.5552 (1.4414) loss_oracle 1.0585 (1.0594) kd_loss 1.2047 (1.1893) acc 50.0000 (62.2656) lr 1.9298e-03 eta 0:36:38
epoch [8/50] batch [60/428] time 0.079 (0.118) data 0.001 (0.010) loss 1.8906 (2.2094) teacher_loss 0.8000 (1.0869) loss_zs_kd 1.3469 (1.4248) loss_oracle 1.0737 (1.0584) kd_loss 1.1074 (1.1867) acc 68.7500 (62.2917) lr 1.9298e-03 eta 0:36:02
epoch [8/50] batch [80/428] time 0.082 (0.118) data 0.000 (0.007) loss 2.2888 (2.1782) teacher_loss 1.2094 (1.0696) loss_zs_kd 1.5936 (1.4397) loss_oracle 1.0315 (1.0547) kd_loss 1.1272 (1.1624) acc 59.3750 (62.8906) lr 1.9298e-03 eta 0:36:11
epoch [8/50] batch [100/428] time 0.080 (0.114) data 0.000 (0.006) loss 1.7921 (2.1448) teacher_loss 0.7221 (1.0457) loss_zs_kd 2.0492 (1.4931) loss_oracle 1.0614 (1.0537) kd_loss 1.0786 (1.1447) acc 71.8750 (63.5938) lr 1.9298e-03 eta 0:34:41
epoch [8/50] batch [120/428] time 0.100 (0.112) data 0.000 (0.005) loss 1.9591 (2.1083) teacher_loss 0.8997 (1.0182) loss_zs_kd 1.5090 (1.5306) loss_oracle 1.0626 (1.0513) kd_loss 1.0561 (1.1288) acc 65.6250 (64.7917) lr 1.9298e-03 eta 0:34:08
epoch [8/50] batch [140/428] time 0.100 (0.111) data 0.000 (0.004) loss 2.0705 (2.0883) teacher_loss 0.9852 (1.0050) loss_zs_kd 1.7182 (1.5480) loss_oracle 1.0556 (1.0501) kd_loss 1.1150 (1.1163) acc 59.3750 (65.0893) lr 1.9298e-03 eta 0:33:44
epoch [8/50] batch [160/428] time 0.105 (0.110) data 0.000 (0.004) loss 2.0187 (2.0659) teacher_loss 0.9428 (0.9881) loss_zs_kd 1.8004 (1.5684) loss_oracle 1.0576 (1.0486) kd_loss 1.0942 (1.1070) acc 62.5000 (65.6055) lr 1.9298e-03 eta 0:33:25
epoch [8/50] batch [180/428] time 0.103 (0.109) data 0.000 (0.003) loss 2.0382 (2.0462) teacher_loss 1.0201 (0.9729) loss_zs_kd 1.6092 (1.5838) loss_oracle 1.0131 (1.0479) kd_loss 1.0231 (1.0985) acc 65.6250 (66.1632) lr 1.9298e-03 eta 0:33:12
epoch [8/50] batch [200/428] time 0.107 (0.109) data 0.000 (0.003) loss 1.9177 (2.0286) teacher_loss 0.8801 (0.9596) loss_zs_kd 1.7020 (1.5904) loss_oracle 1.0261 (1.0465) kd_loss 1.0492 (1.0916) acc 65.6250 (66.6406) lr 1.9298e-03 eta 0:32:58
epoch [8/50] batch [220/428] time 0.108 (0.108) data 0.000 (0.003) loss 1.7209 (2.0072) teacher_loss 0.6972 (0.9410) loss_zs_kd 2.1336 (1.6126) loss_oracle 1.0082 (1.0459) kd_loss 1.0394 (1.0866) acc 78.1250 (67.3011) lr 1.9298e-03 eta 0:32:48
epoch [8/50] batch [240/428] time 0.103 (0.108) data 0.000 (0.003) loss 1.9547 (1.9883) teacher_loss 0.9491 (0.9250) loss_zs_kd 1.9168 (1.6325) loss_oracle 0.9867 (1.0441) kd_loss 1.0244 (1.0824) acc 71.8750 (68.0599) lr 1.9298e-03 eta 0:32:37
epoch [8/50] batch [260/428] time 0.098 (0.107) data 0.000 (0.002) loss 1.8263 (1.9744) teacher_loss 0.8157 (0.9140) loss_zs_kd 1.8100 (1.6454) loss_oracle 1.0351 (1.0437) kd_loss 0.9860 (1.0772) acc 68.7500 (68.5216) lr 1.9298e-03 eta 0:32:30
epoch [8/50] batch [280/428] time 0.103 (0.107) data 0.000 (0.002) loss 1.7696 (1.9632) teacher_loss 0.7363 (0.9059) loss_zs_kd 1.8147 (1.6555) loss_oracle 1.0073 (1.0419) kd_loss 1.0594 (1.0727) acc 78.1250 (68.8281) lr 1.9298e-03 eta 0:32:22
epoch [8/50] batch [300/428] time 0.112 (0.107) data 0.000 (0.002) loss 1.8727 (1.9532) teacher_loss 0.8830 (0.8985) loss_zs_kd 1.8778 (1.6688) loss_oracle 0.9713 (1.0397) kd_loss 1.0082 (1.0696) acc 65.6250 (68.9375) lr 1.9298e-03 eta 0:32:16
epoch [8/50] batch [320/428] time 0.102 (0.107) data 0.000 (0.002) loss 1.9878 (1.9412) teacher_loss 0.9475 (0.8895) loss_zs_kd 2.0497 (1.6809) loss_oracle 1.0272 (1.0373) kd_loss 1.0535 (1.0660) acc 65.6250 (69.2480) lr 1.9298e-03 eta 0:32:09
epoch [8/50] batch [340/428] time 0.100 (0.107) data 0.000 (0.002) loss 1.6450 (1.9333) teacher_loss 0.5980 (0.8832) loss_zs_kd 2.3891 (1.6951) loss_oracle 1.0391 (1.0359) kd_loss 1.0551 (1.0642) acc 81.2500 (69.5129) lr 1.9298e-03 eta 0:32:05
epoch [8/50] batch [360/428] time 0.106 (0.106) data 0.000 (0.002) loss 1.8551 (1.9277) teacher_loss 0.8718 (0.8799) loss_zs_kd 1.4937 (1.7017) loss_oracle 0.9850 (1.0341) kd_loss 0.9815 (1.0613) acc 65.6250 (69.6962) lr 1.9298e-03 eta 0:32:00
epoch [8/50] batch [380/428] time 0.090 (0.106) data 0.000 (0.002) loss 1.7124 (1.9210) teacher_loss 0.6504 (0.8749) loss_zs_kd 1.5229 (1.6966) loss_oracle 1.0221 (1.0324) kd_loss 1.1020 (1.0598) acc 75.0000 (69.8602) lr 1.9298e-03 eta 0:31:54
epoch [8/50] batch [400/428] time 0.096 (0.106) data 0.000 (0.002) loss 1.4616 (1.9124) teacher_loss 0.4288 (0.8675) loss_zs_kd 1.8660 (1.6995) loss_oracle 1.0151 (1.0311) kd_loss 1.0506 (1.0588) acc 84.3750 (70.0156) lr 1.9298e-03 eta 0:31:48
epoch [8/50] batch [420/428] time 0.099 (0.106) data 0.000 (0.002) loss 2.0166 (1.9075) teacher_loss 0.9470 (0.8633) loss_zs_kd 1.5247 (1.7072) loss_oracle 1.0347 (1.0301) kd_loss 1.1046 (1.0583) acc 65.6250 (70.0893) lr 1.9298e-03 eta 0:31:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,422
* accuracy: 58.2%
* error: 41.8%
* macro_f1: 44.7%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,821
* accuracy: 38.4%
* error: 61.6%
* macro_f1: 25.0%
******* Domain 1 best val acc:      58.2%, epoch: 8 *******
******* Domain 1 best val test acc: 38.4%, epoch: 8 *******
******* Domain 1 best test acc:     45.5%, epoch: 3 *******
epoch [9/50] batch [20/428] time 0.079 (0.119) data 0.000 (0.024) loss 1.5679 (1.8298) teacher_loss 0.5352 (0.7941) loss_zs_kd 1.7913 (1.7818) loss_oracle 1.0249 (1.0177) kd_loss 1.0404 (1.0535) acc 84.3750 (72.9688) lr 1.9048e-03 eta 0:35:40
epoch [9/50] batch [40/428] time 0.097 (0.111) data 0.000 (0.012) loss 2.0552 (1.8269) teacher_loss 1.0487 (0.7919) loss_zs_kd 1.6937 (1.7237) loss_oracle 1.0088 (1.0228) kd_loss 1.0042 (1.0473) acc 59.3750 (71.8750) lr 1.9048e-03 eta 0:33:18
epoch [9/50] batch [60/428] time 0.083 (0.114) data 0.001 (0.008) loss 1.6948 (1.8193) teacher_loss 0.6236 (0.7863) loss_zs_kd 1.5795 (1.7430) loss_oracle 1.0490 (1.0221) kd_loss 1.0934 (1.0438) acc 75.0000 (72.2396) lr 1.9048e-03 eta 0:34:03
epoch [9/50] batch [80/428] time 0.079 (0.114) data 0.000 (0.006) loss 2.0402 (1.8273) teacher_loss 0.9819 (0.7931) loss_zs_kd 1.8416 (1.7185) loss_oracle 1.0281 (1.0208) kd_loss 1.0884 (1.0476) acc 62.5000 (71.8359) lr 1.9048e-03 eta 0:34:06
epoch [9/50] batch [100/428] time 0.106 (0.113) data 0.000 (0.005) loss 1.8804 (1.8337) teacher_loss 0.8351 (0.7993) loss_zs_kd 1.6252 (1.7154) loss_oracle 1.0348 (1.0203) kd_loss 1.0558 (1.0485) acc 68.7500 (71.9062) lr 1.9048e-03 eta 0:33:31
epoch [9/50] batch [120/428] time 0.108 (0.111) data 0.000 (0.004) loss 2.1897 (1.8235) teacher_loss 1.1628 (0.7918) loss_zs_kd 1.8731 (1.7421) loss_oracle 1.0021 (1.0184) kd_loss 1.0518 (1.0449) acc 59.3750 (72.1615) lr 1.9048e-03 eta 0:33:05
epoch [9/50] batch [140/428] time 0.100 (0.110) data 0.000 (0.004) loss 1.9168 (1.8131) teacher_loss 0.9127 (0.7821) loss_zs_kd 1.7202 (1.7380) loss_oracle 1.0144 (1.0172) kd_loss 0.9939 (1.0448) acc 65.6250 (72.5893) lr 1.9048e-03 eta 0:32:50
epoch [9/50] batch [160/428] time 0.115 (0.110) data 0.000 (0.003) loss 2.0516 (1.8083) teacher_loss 1.0248 (0.7783) loss_zs_kd 1.7821 (1.7441) loss_oracle 1.0252 (1.0154) kd_loss 1.0284 (1.0446) acc 68.7500 (72.6953) lr 1.9048e-03 eta 0:32:34
epoch [9/50] batch [180/428] time 0.106 (0.109) data 0.000 (0.003) loss 1.7995 (1.8086) teacher_loss 0.7679 (0.7788) loss_zs_kd 2.2574 (1.7503) loss_oracle 0.9974 (1.0147) kd_loss 1.0657 (1.0448) acc 78.1250 (72.5174) lr 1.9048e-03 eta 0:32:20
epoch [9/50] batch [200/428] time 0.104 (0.108) data 0.000 (0.003) loss 1.6975 (1.8087) teacher_loss 0.6510 (0.7786) loss_zs_kd 1.5419 (1.7677) loss_oracle 0.9839 (1.0160) kd_loss 1.1090 (1.0442) acc 81.2500 (72.6875) lr 1.9048e-03 eta 0:32:06
epoch [9/50] batch [220/428] time 0.118 (0.108) data 0.000 (0.002) loss 1.7437 (1.8054) teacher_loss 0.7425 (0.7753) loss_zs_kd 2.2295 (1.7699) loss_oracle 1.0048 (1.0173) kd_loss 0.9976 (1.0429) acc 75.0000 (72.8835) lr 1.9048e-03 eta 0:31:57
epoch [9/50] batch [240/428] time 0.099 (0.108) data 0.000 (0.002) loss 1.9118 (1.8043) teacher_loss 0.8779 (0.7739) loss_zs_kd 2.2161 (1.7983) loss_oracle 1.0450 (1.0182) kd_loss 1.0229 (1.0426) acc 78.1250 (72.9557) lr 1.9048e-03 eta 0:31:49
epoch [9/50] batch [260/428] time 0.110 (0.108) data 0.000 (0.002) loss 1.9989 (1.8116) teacher_loss 0.9060 (0.7778) loss_zs_kd 2.2240 (1.8078) loss_oracle 1.0672 (1.0208) kd_loss 1.1185 (1.0468) acc 56.2500 (72.7163) lr 1.9048e-03 eta 0:31:45
epoch [9/50] batch [280/428] time 0.107 (0.107) data 0.000 (0.002) loss 1.7864 (1.8152) teacher_loss 0.7215 (0.7796) loss_zs_kd 1.9308 (1.8174) loss_oracle 1.0376 (1.0220) kd_loss 1.0924 (1.0492) acc 65.6250 (72.7009) lr 1.9048e-03 eta 0:31:37
epoch [9/50] batch [300/428] time 0.111 (0.107) data 0.000 (0.002) loss 1.8621 (1.8217) teacher_loss 0.8107 (0.7856) loss_zs_kd 2.0510 (1.8269) loss_oracle 0.9978 (1.0218) kd_loss 1.1050 (1.0505) acc 81.2500 (72.7188) lr 1.9048e-03 eta 0:31:30
epoch [9/50] batch [320/428] time 0.101 (0.107) data 0.000 (0.002) loss 2.1604 (1.8304) teacher_loss 1.0911 (0.7916) loss_zs_kd 1.5662 (1.8228) loss_oracle 1.0564 (1.0243) kd_loss 1.0821 (1.0534) acc 53.1250 (72.5195) lr 1.9048e-03 eta 0:31:25
epoch [9/50] batch [340/428] time 0.090 (0.107) data 0.000 (0.002) loss 2.0037 (1.8363) teacher_loss 0.9651 (0.7964) loss_zs_kd 1.4788 (1.8149) loss_oracle 1.0201 (1.0254) kd_loss 1.0571 (1.0543) acc 68.7500 (72.2794) lr 1.9048e-03 eta 0:31:22
epoch [9/50] batch [360/428] time 0.114 (0.107) data 0.001 (0.002) loss 1.8660 (1.8353) teacher_loss 0.8208 (0.7957) loss_zs_kd 1.9177 (1.8128) loss_oracle 0.9992 (1.0258) kd_loss 1.0911 (1.0533) acc 68.7500 (72.3611) lr 1.9048e-03 eta 0:31:23
epoch [9/50] batch [380/428] time 0.099 (0.107) data 0.000 (0.002) loss 2.0437 (1.8391) teacher_loss 1.0315 (0.7993) loss_zs_kd 1.7632 (1.8184) loss_oracle 1.0264 (1.0261) kd_loss 0.9980 (1.0535) acc 65.6250 (72.1053) lr 1.9048e-03 eta 0:31:20
epoch [9/50] batch [400/428] time 0.096 (0.107) data 0.000 (0.002) loss 2.2248 (1.8438) teacher_loss 1.1864 (0.8036) loss_zs_kd 1.5897 (1.8111) loss_oracle 0.9952 (1.0268) kd_loss 1.0816 (1.0536) acc 62.5000 (71.9375) lr 1.9048e-03 eta 0:31:17
epoch [9/50] batch [420/428] time 0.100 (0.107) data 0.000 (0.001) loss 1.5404 (1.8429) teacher_loss 0.4743 (0.8018) loss_zs_kd 1.6743 (1.8028) loss_oracle 1.0381 (1.0274) kd_loss 1.0940 (1.0548) acc 81.2500 (71.9792) lr 1.9048e-03 eta 0:31:12
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,410
* accuracy: 58.0%
* error: 42.0%
* macro_f1: 44.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,292
* accuracy: 48.3%
* error: 51.7%
* macro_f1: 28.9%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      58.2%, epoch: 8 *******
******* Domain 1 best val test acc: 38.4%, epoch: 8 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [10/50] batch [20/428] time 0.081 (0.121) data 0.000 (0.032) loss 1.8236 (1.8051) teacher_loss 0.7465 (0.7614) loss_zs_kd 1.7204 (1.6934) loss_oracle 1.0293 (1.0138) kd_loss 1.1250 (1.0736) acc 65.6250 (72.9688) lr 1.8763e-03 eta 0:35:25
epoch [10/50] batch [40/428] time 0.108 (0.114) data 0.000 (0.016) loss 1.6697 (1.8280) teacher_loss 0.6191 (0.7804) loss_zs_kd 1.9137 (1.7629) loss_oracle 1.0343 (1.0231) kd_loss 1.0671 (1.0722) acc 75.0000 (72.1094) lr 1.8763e-03 eta 0:33:08
epoch [10/50] batch [60/428] time 0.108 (0.114) data 0.001 (0.011) loss 1.9081 (1.8219) teacher_loss 0.8040 (0.7734) loss_zs_kd 1.5829 (1.7535) loss_oracle 1.0956 (1.0293) kd_loss 1.1127 (1.0677) acc 65.6250 (72.5521) lr 1.8763e-03 eta 0:33:05
epoch [10/50] batch [80/428] time 0.076 (0.115) data 0.000 (0.008) loss 1.8399 (1.8111) teacher_loss 0.7793 (0.7622) loss_zs_kd 1.8087 (1.7836) loss_oracle 1.0589 (1.0327) kd_loss 1.0623 (1.0650) acc 68.7500 (73.0859) lr 1.8763e-03 eta 0:33:22
epoch [10/50] batch [100/428] time 0.115 (0.112) data 0.000 (0.007) loss 1.6583 (1.8143) teacher_loss 0.6407 (0.7664) loss_zs_kd 1.8155 (1.8023) loss_oracle 0.9875 (1.0320) kd_loss 1.0477 (1.0638) acc 84.3750 (72.9062) lr 1.8763e-03 eta 0:32:40
epoch [10/50] batch [120/428] time 0.102 (0.111) data 0.000 (0.006) loss 1.7531 (1.8128) teacher_loss 0.7422 (0.7667) loss_zs_kd 2.1351 (1.8236) loss_oracle 0.9880 (1.0305) kd_loss 1.0337 (1.0617) acc 75.0000 (72.9427) lr 1.8763e-03 eta 0:32:17
epoch [10/50] batch [140/428] time 0.101 (0.110) data 0.001 (0.005) loss 1.7209 (1.8032) teacher_loss 0.7052 (0.7605) loss_zs_kd 1.9500 (1.8506) loss_oracle 0.9994 (1.0295) kd_loss 1.0320 (1.0558) acc 78.1250 (73.4152) lr 1.8763e-03 eta 0:31:58
epoch [10/50] batch [160/428] time 0.117 (0.110) data 0.000 (0.004) loss 1.8516 (1.8051) teacher_loss 0.8098 (0.7656) loss_zs_kd 1.5713 (1.8636) loss_oracle 1.0272 (1.0272) kd_loss 1.0565 (1.0518) acc 62.5000 (73.0859) lr 1.8763e-03 eta 0:31:45
epoch [10/50] batch [180/428] time 0.098 (0.109) data 0.000 (0.004) loss 1.7694 (1.8070) teacher_loss 0.8007 (0.7692) loss_zs_kd 1.8567 (1.8701) loss_oracle 0.9673 (1.0260) kd_loss 0.9702 (1.0494) acc 75.0000 (73.2292) lr 1.8763e-03 eta 0:31:30
epoch [10/50] batch [200/428] time 0.095 (0.108) data 0.000 (0.003) loss 1.7660 (1.8093) teacher_loss 0.7709 (0.7721) loss_zs_kd 1.8854 (1.8630) loss_oracle 1.0169 (1.0252) kd_loss 0.9734 (1.0490) acc 68.7500 (72.9688) lr 1.8763e-03 eta 0:31:18
epoch [10/50] batch [220/428] time 0.095 (0.108) data 0.000 (0.003) loss 1.7020 (1.8173) teacher_loss 0.6434 (0.7811) loss_zs_kd 1.8039 (1.8458) loss_oracle 1.0277 (1.0235) kd_loss 1.0895 (1.0490) acc 81.2500 (72.7557) lr 1.8763e-03 eta 0:31:09
epoch [10/50] batch [240/428] time 0.107 (0.108) data 0.000 (0.003) loss 2.1936 (1.8194) teacher_loss 1.1163 (0.7842) loss_zs_kd 1.7945 (1.8452) loss_oracle 1.0426 (1.0227) kd_loss 1.1119 (1.0476) acc 62.5000 (72.8125) lr 1.8763e-03 eta 0:31:02
epoch [10/50] batch [260/428] time 0.100 (0.107) data 0.000 (0.003) loss 1.7723 (1.8165) teacher_loss 0.7207 (0.7827) loss_zs_kd 2.1658 (1.8572) loss_oracle 1.0276 (1.0211) kd_loss 1.0755 (1.0466) acc 68.7500 (72.8606) lr 1.8763e-03 eta 0:30:56
epoch [10/50] batch [280/428] time 0.096 (0.107) data 0.000 (0.003) loss 2.0025 (1.8179) teacher_loss 0.9133 (0.7841) loss_zs_kd 1.7896 (1.8618) loss_oracle 1.0288 (1.0202) kd_loss 1.1498 (1.0474) acc 71.8750 (72.9018) lr 1.8763e-03 eta 0:30:48
epoch [10/50] batch [300/428] time 0.102 (0.107) data 0.000 (0.002) loss 1.5436 (1.8290) teacher_loss 0.4584 (0.7927) loss_zs_kd 1.6186 (1.8643) loss_oracle 1.0434 (1.0207) kd_loss 1.1270 (1.0517) acc 87.5000 (72.5312) lr 1.8763e-03 eta 0:30:42
epoch [10/50] batch [320/428] time 0.092 (0.107) data 0.000 (0.002) loss 1.6414 (1.8370) teacher_loss 0.5126 (0.7976) loss_zs_kd 1.7363 (1.8561) loss_oracle 1.0970 (1.0231) kd_loss 1.1607 (1.0557) acc 87.5000 (72.4219) lr 1.8763e-03 eta 0:30:37
epoch [10/50] batch [340/428] time 0.106 (0.107) data 0.000 (0.002) loss 2.4382 (1.8451) teacher_loss 1.4012 (0.8046) loss_zs_kd 1.5776 (1.8527) loss_oracle 1.0522 (1.0240) kd_loss 1.0218 (1.0571) acc 62.5000 (72.1599) lr 1.8763e-03 eta 0:30:33
epoch [10/50] batch [360/428] time 0.100 (0.106) data 0.000 (0.002) loss 1.8228 (1.8457) teacher_loss 0.7765 (0.8056) loss_zs_kd 1.7947 (1.8563) loss_oracle 1.0351 (1.0237) kd_loss 1.0577 (1.0566) acc 68.7500 (72.1788) lr 1.8763e-03 eta 0:30:29
epoch [10/50] batch [380/428] time 0.128 (0.107) data 0.000 (0.002) loss 1.9812 (1.8453) teacher_loss 0.9612 (0.8052) loss_zs_kd 1.7099 (1.8473) loss_oracle 0.9966 (1.0244) kd_loss 1.0433 (1.0558) acc 68.7500 (72.3273) lr 1.8763e-03 eta 0:30:29
epoch [10/50] batch [400/428] time 0.099 (0.107) data 0.000 (0.002) loss 1.6377 (1.8436) teacher_loss 0.6350 (0.8039) loss_zs_kd 1.8329 (1.8384) loss_oracle 0.9932 (1.0248) kd_loss 1.0122 (1.0547) acc 75.0000 (72.4766) lr 1.8763e-03 eta 0:30:30
epoch [10/50] batch [420/428] time 0.097 (0.107) data 0.000 (0.002) loss 1.5993 (1.8452) teacher_loss 0.5913 (0.8063) loss_zs_kd 1.7117 (1.8290) loss_oracle 1.0056 (1.0249) kd_loss 1.0104 (1.0529) acc 75.0000 (72.4033) lr 1.8763e-03 eta 0:30:25
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,270
* accuracy: 55.7%
* error: 44.3%
* macro_f1: 45.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,832
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 25.6%
******* Domain 1 best val acc:      58.2%, epoch: 8 *******
******* Domain 1 best val test acc: 38.4%, epoch: 8 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [11/50] batch [20/428] time 0.074 (0.126) data 0.000 (0.026) loss 1.7949 (1.8238) teacher_loss 0.7846 (0.7948) loss_zs_kd 1.8881 (1.7604) loss_oracle 1.0273 (1.0200) kd_loss 0.9935 (1.0379) acc 71.8750 (72.5000) lr 1.8443e-03 eta 0:36:00
epoch [11/50] batch [40/428] time 0.074 (0.111) data 0.000 (0.013) loss 1.8949 (1.7886) teacher_loss 0.8804 (0.7609) loss_zs_kd 1.9679 (1.7548) loss_oracle 0.9911 (1.0180) kd_loss 1.0380 (1.0373) acc 71.8750 (73.5938) lr 1.8443e-03 eta 0:31:31
epoch [11/50] batch [60/428] time 0.074 (0.110) data 0.001 (0.009) loss 1.9378 (1.7895) teacher_loss 0.8985 (0.7608) loss_zs_kd 2.1281 (1.8102) loss_oracle 0.9932 (1.0169) kd_loss 1.0854 (1.0403) acc 59.3750 (73.9062) lr 1.8443e-03 eta 0:31:24
epoch [11/50] batch [80/428] time 0.188 (0.110) data 0.000 (0.007) loss 1.8252 (1.7805) teacher_loss 0.8547 (0.7566) loss_zs_kd 1.4683 (1.7930) loss_oracle 0.9884 (1.0113) kd_loss 0.9527 (1.0366) acc 75.0000 (74.4141) lr 1.8443e-03 eta 0:31:21
epoch [11/50] batch [100/428] time 0.103 (0.109) data 0.001 (0.005) loss 1.6545 (1.7931) teacher_loss 0.6417 (0.7689) loss_zs_kd 1.7590 (1.7631) loss_oracle 0.9498 (1.0104) kd_loss 1.0759 (1.0379) acc 81.2500 (74.2500) lr 1.8443e-03 eta 0:30:58
epoch [11/50] batch [120/428] time 0.117 (0.108) data 0.000 (0.005) loss 1.7390 (1.7954) teacher_loss 0.7222 (0.7694) loss_zs_kd 1.8422 (1.7358) loss_oracle 0.9829 (1.0105) kd_loss 1.0506 (1.0414) acc 68.7500 (74.5052) lr 1.8443e-03 eta 0:30:36
epoch [11/50] batch [140/428] time 0.108 (0.108) data 0.000 (0.004) loss 2.1994 (1.8072) teacher_loss 1.2036 (0.7784) loss_zs_kd 1.8451 (1.7268) loss_oracle 0.9647 (1.0127) kd_loss 1.0269 (1.0451) acc 62.5000 (73.9509) lr 1.8443e-03 eta 0:30:27
epoch [11/50] batch [160/428] time 0.107 (0.107) data 0.000 (0.003) loss 2.3584 (1.8225) teacher_loss 1.2940 (0.7912) loss_zs_kd 1.6937 (1.7297) loss_oracle 1.0358 (1.0154) kd_loss 1.0930 (1.0474) acc 59.3750 (73.4961) lr 1.8443e-03 eta 0:30:20
epoch [11/50] batch [180/428] time 0.111 (0.107) data 0.000 (0.003) loss 2.0312 (1.8455) teacher_loss 0.9402 (0.8100) loss_zs_kd 1.6476 (1.7057) loss_oracle 1.0651 (1.0176) kd_loss 1.1170 (1.0535) acc 65.6250 (72.6389) lr 1.8443e-03 eta 0:30:14
epoch [11/50] batch [200/428] time 0.102 (0.107) data 0.000 (0.003) loss 2.1227 (1.8764) teacher_loss 1.0740 (0.8335) loss_zs_kd 1.3235 (1.6803) loss_oracle 1.0024 (1.0202) kd_loss 1.0950 (1.0656) acc 59.3750 (71.5469) lr 1.8443e-03 eta 0:30:07
epoch [11/50] batch [220/428] time 0.107 (0.107) data 0.000 (0.003) loss 1.9671 (1.8907) teacher_loss 0.9325 (0.8449) loss_zs_kd 1.3914 (1.6764) loss_oracle 0.9814 (1.0200) kd_loss 1.0877 (1.0717) acc 68.7500 (71.0369) lr 1.8443e-03 eta 0:30:01
epoch [11/50] batch [240/428] time 0.107 (0.106) data 0.000 (0.002) loss 2.2979 (1.8944) teacher_loss 1.2001 (0.8469) loss_zs_kd 2.2225 (1.6818) loss_oracle 1.0491 (1.0215) kd_loss 1.1463 (1.0734) acc 68.7500 (71.1328) lr 1.8443e-03 eta 0:29:57
epoch [11/50] batch [260/428] time 0.110 (0.106) data 0.000 (0.002) loss 1.8013 (1.9047) teacher_loss 0.7655 (0.8559) loss_zs_kd 1.7083 (1.6825) loss_oracle 1.0509 (1.0232) kd_loss 1.0207 (1.0745) acc 68.7500 (70.7212) lr 1.8443e-03 eta 0:29:53
epoch [11/50] batch [280/428] time 0.105 (0.106) data 0.000 (0.002) loss 2.0049 (1.8994) teacher_loss 0.9629 (0.8514) loss_zs_kd 1.9326 (1.6819) loss_oracle 1.0169 (1.0227) kd_loss 1.0672 (1.0732) acc 71.8750 (70.8482) lr 1.8443e-03 eta 0:29:51
epoch [11/50] batch [300/428] time 0.106 (0.106) data 0.000 (0.002) loss 2.0320 (1.8980) teacher_loss 0.9998 (0.8512) loss_zs_kd 1.9202 (1.6902) loss_oracle 1.0239 (1.0222) kd_loss 1.0406 (1.0714) acc 71.8750 (70.6042) lr 1.8443e-03 eta 0:29:49
epoch [11/50] batch [320/428] time 0.094 (0.106) data 0.000 (0.002) loss 1.8569 (1.9025) teacher_loss 0.8373 (0.8580) loss_zs_kd 2.0427 (1.7069) loss_oracle 1.0182 (1.0207) kd_loss 1.0211 (1.0683) acc 71.8750 (70.1660) lr 1.8443e-03 eta 0:29:46
epoch [11/50] batch [340/428] time 0.097 (0.106) data 0.000 (0.002) loss 2.0639 (1.9045) teacher_loss 1.0297 (0.8619) loss_zs_kd 1.5649 (1.7096) loss_oracle 0.9901 (1.0195) kd_loss 1.0784 (1.0656) acc 56.2500 (69.9908) lr 1.8443e-03 eta 0:29:43
epoch [11/50] batch [360/428] time 0.106 (0.106) data 0.000 (0.002) loss 1.9228 (1.9022) teacher_loss 0.8858 (0.8610) loss_zs_kd 1.7244 (1.7127) loss_oracle 0.9630 (1.0183) kd_loss 1.1109 (1.0640) acc 71.8750 (69.8698) lr 1.8443e-03 eta 0:29:40
epoch [11/50] batch [380/428] time 0.105 (0.106) data 0.000 (0.002) loss 2.0274 (1.9025) teacher_loss 0.9679 (0.8619) loss_zs_kd 1.6701 (1.7133) loss_oracle 1.0294 (1.0172) kd_loss 1.0896 (1.0640) acc 65.6250 (69.8520) lr 1.8443e-03 eta 0:29:36
epoch [11/50] batch [400/428] time 0.113 (0.106) data 0.000 (0.002) loss 1.9095 (1.9075) teacher_loss 0.8573 (0.8663) loss_zs_kd 1.7917 (1.7108) loss_oracle 1.0032 (1.0165) kd_loss 1.1012 (1.0658) acc 68.7500 (69.6719) lr 1.8443e-03 eta 0:29:34
epoch [11/50] batch [420/428] time 0.095 (0.106) data 0.000 (0.002) loss 1.8011 (1.9119) teacher_loss 0.7583 (0.8694) loss_zs_kd 1.7162 (1.7131) loss_oracle 0.9735 (1.0161) kd_loss 1.1121 (1.0690) acc 71.8750 (69.5536) lr 1.8443e-03 eta 0:29:32
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,620
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 47.9%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,988
* accuracy: 41.9%
* error: 58.1%
* macro_f1: 27.5%
******* Domain 1 best val acc:      61.6%, epoch: 11 *******
******* Domain 1 best val test acc: 41.9%, epoch: 11 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [12/50] batch [20/428] time 0.083 (0.119) data 0.000 (0.030) loss 1.9118 (1.9130) teacher_loss 0.9478 (0.8682) loss_zs_kd 1.6332 (1.6639) loss_oracle 0.9439 (1.0060) kd_loss 0.9840 (1.0836) acc 71.8750 (70.0000) lr 1.8090e-03 eta 0:33:09
epoch [12/50] batch [40/428] time 0.182 (0.116) data 0.000 (0.015) loss 1.9997 (1.8895) teacher_loss 0.9355 (0.8404) loss_zs_kd 2.1734 (1.6746) loss_oracle 1.0148 (1.0112) kd_loss 1.1135 (1.0870) acc 65.6250 (71.4062) lr 1.8090e-03 eta 0:32:11
epoch [12/50] batch [60/428] time 0.089 (0.116) data 0.001 (0.010) loss 1.9242 (1.8910) teacher_loss 0.8954 (0.8498) loss_zs_kd 1.6033 (1.6880) loss_oracle 0.9577 (1.0059) kd_loss 1.0997 (1.0765) acc 65.6250 (70.3125) lr 1.8090e-03 eta 0:32:17
epoch [12/50] batch [80/428] time 0.075 (0.116) data 0.000 (0.008) loss 1.6859 (1.8778) teacher_loss 0.6492 (0.8403) loss_zs_kd 1.7378 (1.6895) loss_oracle 1.0248 (1.0035) kd_loss 1.0487 (1.0715) acc 84.3750 (70.5469) lr 1.8090e-03 eta 0:31:59
epoch [12/50] batch [100/428] time 0.112 (0.111) data 0.000 (0.006) loss 2.2110 (1.8712) teacher_loss 1.1829 (0.8371) loss_zs_kd 2.0893 (1.7070) loss_oracle 1.0017 (1.0032) kd_loss 1.0545 (1.0651) acc 59.3750 (70.9062) lr 1.8090e-03 eta 0:30:48
epoch [12/50] batch [120/428] time 0.108 (0.110) data 0.000 (0.005) loss 1.8688 (1.8623) teacher_loss 0.8546 (0.8309) loss_zs_kd 1.7825 (1.7633) loss_oracle 1.0165 (1.0011) kd_loss 1.0119 (1.0617) acc 75.0000 (71.1719) lr 1.8090e-03 eta 0:30:25
epoch [12/50] batch [140/428] time 0.093 (0.109) data 0.000 (0.005) loss 1.8541 (1.8558) teacher_loss 0.8305 (0.8275) loss_zs_kd 1.5688 (1.7648) loss_oracle 0.9708 (0.9997) kd_loss 1.0764 (1.0569) acc 68.7500 (71.2500) lr 1.8090e-03 eta 0:30:08
epoch [12/50] batch [160/428] time 0.100 (0.109) data 0.000 (0.004) loss 1.7284 (1.8495) teacher_loss 0.7245 (0.8217) loss_zs_kd 1.9907 (1.7677) loss_oracle 0.9935 (1.0001) kd_loss 1.0142 (1.0555) acc 75.0000 (71.3867) lr 1.8090e-03 eta 0:29:56
epoch [12/50] batch [180/428] time 0.092 (0.108) data 0.000 (0.004) loss 1.8544 (1.8417) teacher_loss 0.8121 (0.8136) loss_zs_kd 1.5421 (1.7699) loss_oracle 1.0351 (1.0009) kd_loss 1.0496 (1.0552) acc 75.0000 (71.7361) lr 1.8090e-03 eta 0:29:47
epoch [12/50] batch [200/428] time 0.100 (0.108) data 0.000 (0.003) loss 1.6617 (1.8351) teacher_loss 0.6420 (0.8081) loss_zs_kd 1.8299 (1.7732) loss_oracle 1.0065 (1.0010) kd_loss 1.0329 (1.0530) acc 78.1250 (71.9688) lr 1.8090e-03 eta 0:29:40
epoch [12/50] batch [220/428] time 0.099 (0.108) data 0.000 (0.003) loss 1.8452 (1.8331) teacher_loss 0.7753 (0.8081) loss_zs_kd 1.3992 (1.7781) loss_oracle 1.0508 (1.0002) kd_loss 1.0889 (1.0498) acc 75.0000 (71.9886) lr 1.8090e-03 eta 0:29:35
epoch [12/50] batch [240/428] time 0.100 (0.108) data 0.000 (0.003) loss 1.9008 (1.8387) teacher_loss 0.8846 (0.8147) loss_zs_kd 1.5090 (1.7815) loss_oracle 0.9909 (1.0005) kd_loss 1.0415 (1.0476) acc 62.5000 (71.7057) lr 1.8090e-03 eta 0:29:29
epoch [12/50] batch [260/428] time 0.112 (0.107) data 0.000 (0.003) loss 1.7371 (1.8343) teacher_loss 0.7793 (0.8119) loss_zs_kd 1.4383 (1.7844) loss_oracle 0.9657 (0.9993) kd_loss 0.9500 (1.0454) acc 71.8750 (71.6587) lr 1.8090e-03 eta 0:29:24
epoch [12/50] batch [280/428] time 0.115 (0.107) data 0.000 (0.002) loss 1.6337 (1.8362) teacher_loss 0.6152 (0.8153) loss_zs_kd 1.9116 (1.7798) loss_oracle 1.0216 (0.9985) kd_loss 1.0155 (1.0435) acc 81.2500 (71.6518) lr 1.8090e-03 eta 0:29:19
epoch [12/50] batch [300/428] time 0.104 (0.107) data 0.000 (0.002) loss 1.9069 (1.8376) teacher_loss 0.8902 (0.8178) loss_zs_kd 1.9164 (1.7832) loss_oracle 1.0179 (0.9983) kd_loss 1.0155 (1.0413) acc 71.8750 (71.6250) lr 1.8090e-03 eta 0:29:19
epoch [12/50] batch [320/428] time 0.101 (0.107) data 0.000 (0.002) loss 1.7429 (1.8424) teacher_loss 0.7451 (0.8248) loss_zs_kd 1.7527 (1.7894) loss_oracle 0.9920 (0.9973) kd_loss 1.0036 (1.0380) acc 65.6250 (71.3477) lr 1.8090e-03 eta 0:29:13
epoch [12/50] batch [340/428] time 0.100 (0.107) data 0.000 (0.002) loss 2.1230 (1.8408) teacher_loss 1.1735 (0.8248) loss_zs_kd 1.6116 (1.7837) loss_oracle 0.9868 (0.9957) kd_loss 0.9121 (1.0362) acc 53.1250 (71.2960) lr 1.8090e-03 eta 0:29:10
epoch [12/50] batch [360/428] time 0.103 (0.107) data 0.000 (0.002) loss 1.5683 (1.8391) teacher_loss 0.5510 (0.8239) loss_zs_kd 1.6815 (1.7770) loss_oracle 1.0001 (0.9947) kd_loss 1.0345 (1.0357) acc 78.1250 (71.3889) lr 1.8090e-03 eta 0:29:06
epoch [12/50] batch [380/428] time 0.098 (0.107) data 0.000 (0.002) loss 1.8597 (1.8370) teacher_loss 0.8300 (0.8222) loss_zs_kd 1.1617 (1.7581) loss_oracle 0.9625 (0.9938) kd_loss 1.0968 (1.0357) acc 75.0000 (71.3898) lr 1.8090e-03 eta 0:29:03
epoch [12/50] batch [400/428] time 0.100 (0.107) data 0.000 (0.002) loss 1.8526 (1.8358) teacher_loss 0.8792 (0.8212) loss_zs_kd 1.7670 (1.7534) loss_oracle 0.9589 (0.9936) kd_loss 0.9879 (1.0355) acc 71.8750 (71.3750) lr 1.8090e-03 eta 0:29:00
epoch [12/50] batch [420/428] time 0.099 (0.107) data 0.000 (0.002) loss 1.9699 (1.8400) teacher_loss 0.9695 (0.8259) loss_zs_kd 1.6422 (1.7586) loss_oracle 1.0070 (0.9932) kd_loss 0.9939 (1.0350) acc 75.0000 (71.2277) lr 1.8090e-03 eta 0:28:54
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,430
* accuracy: 58.4%
* error: 41.6%
* macro_f1: 41.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,851
* accuracy: 39.0%
* error: 61.0%
* macro_f1: 24.9%
******* Domain 1 best val acc:      61.6%, epoch: 11 *******
******* Domain 1 best val test acc: 41.9%, epoch: 11 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [13/50] batch [20/428] time 0.086 (0.130) data 0.001 (0.027) loss 1.7353 (1.8909) teacher_loss 0.7113 (0.8960) loss_zs_kd 2.1843 (2.1275) loss_oracle 1.0098 (0.9770) kd_loss 1.0383 (1.0129) acc 75.0000 (67.1875) lr 1.7705e-03 eta 0:35:11
epoch [13/50] batch [40/428] time 0.163 (0.122) data 0.000 (0.014) loss 1.8882 (1.9002) teacher_loss 0.8769 (0.9106) loss_zs_kd 2.0383 (2.1077) loss_oracle 1.0113 (0.9704) kd_loss 1.0111 (1.0089) acc 71.8750 (69.1406) lr 1.7705e-03 eta 0:33:02
epoch [13/50] batch [60/428] time 0.149 (0.119) data 0.001 (0.009) loss 1.8343 (1.8637) teacher_loss 0.8397 (0.8717) loss_zs_kd 1.7948 (1.9825) loss_oracle 0.9618 (0.9726) kd_loss 1.0276 (1.0115) acc 68.7500 (69.7917) lr 1.7705e-03 eta 0:32:00
epoch [13/50] batch [80/428] time 0.076 (0.117) data 0.000 (0.007) loss 1.8336 (1.8725) teacher_loss 0.8860 (0.8831) loss_zs_kd 1.6996 (1.9403) loss_oracle 0.9897 (0.9707) kd_loss 0.9055 (1.0081) acc 75.0000 (68.9844) lr 1.7705e-03 eta 0:31:30
epoch [13/50] batch [100/428] time 0.111 (0.112) data 0.000 (0.006) loss 1.9301 (1.8660) teacher_loss 0.9450 (0.8773) loss_zs_kd 2.1189 (1.9405) loss_oracle 0.9878 (0.9708) kd_loss 0.9825 (1.0064) acc 59.3750 (69.1875) lr 1.7705e-03 eta 0:30:11
epoch [13/50] batch [120/428] time 0.104 (0.111) data 0.000 (0.005) loss 1.7444 (1.8803) teacher_loss 0.8077 (0.8958) loss_zs_kd 1.9793 (1.9594) loss_oracle 0.9477 (0.9691) kd_loss 0.9258 (0.9999) acc 75.0000 (68.6719) lr 1.7705e-03 eta 0:29:51
epoch [13/50] batch [140/428] time 0.100 (0.110) data 0.000 (0.004) loss 1.7584 (1.8783) teacher_loss 0.8043 (0.8984) loss_zs_kd 1.5986 (1.9652) loss_oracle 0.9452 (0.9654) kd_loss 0.9630 (0.9945) acc 78.1250 (68.4375) lr 1.7705e-03 eta 0:29:37
epoch [13/50] batch [160/428] time 0.102 (0.110) data 0.000 (0.004) loss 1.9100 (1.8872) teacher_loss 0.9527 (0.9114) loss_zs_kd 1.5563 (1.9401) loss_oracle 0.9261 (0.9629) kd_loss 0.9885 (0.9888) acc 65.6250 (68.1641) lr 1.7705e-03 eta 0:29:26
epoch [13/50] batch [180/428] time 0.110 (0.109) data 0.000 (0.003) loss 1.6592 (1.8740) teacher_loss 0.6959 (0.9017) loss_zs_kd 1.9346 (1.9302) loss_oracle 0.9432 (0.9584) kd_loss 0.9835 (0.9861) acc 81.2500 (68.5938) lr 1.7705e-03 eta 0:29:15
epoch [13/50] batch [200/428] time 0.106 (0.109) data 0.000 (0.003) loss 1.7072 (1.8670) teacher_loss 0.7764 (0.8945) loss_zs_kd 2.0149 (1.9125) loss_oracle 0.9028 (0.9568) kd_loss 0.9589 (0.9882) acc 75.0000 (68.7031) lr 1.7705e-03 eta 0:29:05
epoch [13/50] batch [220/428] time 0.102 (0.108) data 0.000 (0.003) loss 1.7427 (1.8626) teacher_loss 0.7891 (0.8910) loss_zs_kd 1.8851 (1.9055) loss_oracle 0.9703 (0.9553) kd_loss 0.9369 (0.9879) acc 71.8750 (68.5653) lr 1.7705e-03 eta 0:28:57
epoch [13/50] batch [240/428] time 0.096 (0.108) data 0.000 (0.003) loss 1.9087 (1.8587) teacher_loss 0.9648 (0.8887) loss_zs_kd 1.6955 (1.8944) loss_oracle 0.8876 (0.9530) kd_loss 1.0000 (0.9870) acc 68.7500 (68.5677) lr 1.7705e-03 eta 0:28:48
epoch [13/50] batch [260/428] time 0.101 (0.108) data 0.000 (0.002) loss 1.7248 (1.8576) teacher_loss 0.7494 (0.8891) loss_zs_kd 1.7872 (1.8892) loss_oracle 0.9091 (0.9509) kd_loss 1.0418 (0.9861) acc 81.2500 (68.6298) lr 1.7705e-03 eta 0:28:42
epoch [13/50] batch [280/428] time 0.107 (0.107) data 0.000 (0.002) loss 1.8548 (1.8583) teacher_loss 0.9435 (0.8917) loss_zs_kd 1.5728 (1.8801) loss_oracle 0.9067 (0.9487) kd_loss 0.9159 (0.9844) acc 59.3750 (68.2701) lr 1.7705e-03 eta 0:28:35
epoch [13/50] batch [300/428] time 0.094 (0.107) data 0.001 (0.002) loss 1.7802 (1.8606) teacher_loss 0.8193 (0.8944) loss_zs_kd 1.9055 (1.8734) loss_oracle 0.9504 (0.9476) kd_loss 0.9715 (0.9850) acc 68.7500 (68.0521) lr 1.7705e-03 eta 0:28:22
epoch [13/50] batch [320/428] time 0.085 (0.106) data 0.000 (0.002) loss 1.9520 (1.8573) teacher_loss 1.0009 (0.8920) loss_zs_kd 1.6780 (1.8690) loss_oracle 0.9329 (0.9455) kd_loss 0.9692 (0.9851) acc 65.6250 (68.1543) lr 1.7705e-03 eta 0:28:09
epoch [13/50] batch [340/428] time 0.101 (0.106) data 0.000 (0.002) loss 1.7262 (1.8601) teacher_loss 0.7563 (0.8950) loss_zs_kd 1.8960 (1.8680) loss_oracle 0.9090 (0.9441) kd_loss 1.0307 (0.9861) acc 78.1250 (67.9412) lr 1.7705e-03 eta 0:28:00
epoch [13/50] batch [360/428] time 0.104 (0.106) data 0.000 (0.002) loss 2.0636 (1.8573) teacher_loss 1.1097 (0.8925) loss_zs_kd 1.3690 (1.8631) loss_oracle 0.9246 (0.9429) kd_loss 0.9832 (0.9867) acc 56.2500 (67.9861) lr 1.7705e-03 eta 0:27:58
epoch [13/50] batch [380/428] time 0.104 (0.105) data 0.000 (0.002) loss 2.2068 (1.8609) teacher_loss 1.2752 (0.8963) loss_zs_kd 1.7016 (1.8557) loss_oracle 0.9195 (0.9416) kd_loss 0.9437 (0.9876) acc 43.7500 (67.8125) lr 1.7705e-03 eta 0:27:55
epoch [13/50] batch [400/428] time 0.105 (0.106) data 0.000 (0.002) loss 1.7790 (1.8568) teacher_loss 0.8014 (0.8932) loss_zs_kd 1.9292 (1.8520) loss_oracle 0.9348 (0.9400) kd_loss 1.0205 (0.9873) acc 65.6250 (67.8984) lr 1.7705e-03 eta 0:27:53
epoch [13/50] batch [420/428] time 0.096 (0.105) data 0.000 (0.002) loss 1.9797 (1.8558) teacher_loss 1.0383 (0.8924) loss_zs_kd 1.5726 (1.8515) loss_oracle 0.9127 (0.9386) kd_loss 0.9699 (0.9882) acc 59.3750 (67.9836) lr 1.7705e-03 eta 0:27:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,723
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 50.8%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,957
* accuracy: 41.3%
* error: 58.7%
* macro_f1: 29.0%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [14/50] batch [20/428] time 0.174 (0.126) data 0.000 (0.028) loss 2.0823 (1.8814) teacher_loss 1.1517 (0.9478) loss_zs_kd 2.0908 (1.9992) loss_oracle 0.9086 (0.9087) kd_loss 0.9526 (0.9585) acc 56.2500 (66.2500) lr 1.7290e-03 eta 0:33:17
epoch [14/50] batch [40/428] time 0.063 (0.112) data 0.000 (0.014) loss 2.0690 (1.8334) teacher_loss 1.1544 (0.8978) loss_zs_kd 2.0998 (2.0084) loss_oracle 0.8255 (0.9062) kd_loss 1.0037 (0.9649) acc 62.5000 (67.8125) lr 1.7290e-03 eta 0:29:34
epoch [14/50] batch [60/428] time 0.167 (0.108) data 0.001 (0.009) loss 1.4742 (1.8226) teacher_loss 0.5176 (0.8787) loss_zs_kd 1.6595 (1.8996) loss_oracle 0.9197 (0.9093) kd_loss 0.9935 (0.9785) acc 81.2500 (68.5417) lr 1.7290e-03 eta 0:28:22
epoch [14/50] batch [80/428] time 0.212 (0.108) data 0.000 (0.007) loss 1.5012 (1.8121) teacher_loss 0.5853 (0.8622) loss_zs_kd 1.4203 (1.8542) loss_oracle 0.8727 (0.9099) kd_loss 0.9590 (0.9898) acc 78.1250 (69.4922) lr 1.7290e-03 eta 0:28:20
epoch [14/50] batch [100/428] time 0.101 (0.107) data 0.000 (0.006) loss 2.0101 (1.8137) teacher_loss 1.0532 (0.8541) loss_zs_kd 1.6003 (1.8350) loss_oracle 0.9526 (0.9158) kd_loss 0.9613 (1.0034) acc 68.7500 (69.8750) lr 1.7290e-03 eta 0:27:56
epoch [14/50] batch [120/428] time 0.114 (0.106) data 0.000 (0.005) loss 1.7185 (1.8082) teacher_loss 0.7963 (0.8510) loss_zs_kd 1.9891 (1.8669) loss_oracle 0.9062 (0.9130) kd_loss 0.9383 (1.0015) acc 71.8750 (70.0260) lr 1.7290e-03 eta 0:27:48
epoch [14/50] batch [140/428] time 0.103 (0.106) data 0.000 (0.004) loss 1.7542 (1.8036) teacher_loss 0.7906 (0.8489) loss_zs_kd 1.9481 (1.8709) loss_oracle 0.9207 (0.9117) kd_loss 1.0066 (0.9978) acc 71.8750 (70.2232) lr 1.7290e-03 eta 0:27:40
epoch [14/50] batch [160/428] time 0.111 (0.106) data 0.000 (0.004) loss 1.8757 (1.8008) teacher_loss 0.9206 (0.8442) loss_zs_kd 1.9429 (1.8724) loss_oracle 0.9400 (0.9118) kd_loss 0.9702 (1.0015) acc 71.8750 (70.3320) lr 1.7290e-03 eta 0:27:38
epoch [14/50] batch [180/428] time 0.102 (0.106) data 0.000 (0.003) loss 1.7545 (1.8071) teacher_loss 0.8002 (0.8474) loss_zs_kd 1.7990 (1.8576) loss_oracle 0.8918 (0.9152) kd_loss 1.0167 (1.0041) acc 71.8750 (70.0000) lr 1.7290e-03 eta 0:27:34
epoch [14/50] batch [200/428] time 0.108 (0.106) data 0.000 (0.003) loss 1.6788 (1.8106) teacher_loss 0.6050 (0.8458) loss_zs_kd 1.8527 (1.8545) loss_oracle 1.0271 (0.9194) kd_loss 1.1206 (1.0102) acc 81.2500 (70.2344) lr 1.7290e-03 eta 0:27:30
epoch [14/50] batch [220/428] time 0.096 (0.106) data 0.000 (0.003) loss 1.7598 (1.8183) teacher_loss 0.8136 (0.8519) loss_zs_kd 1.6529 (1.8356) loss_oracle 0.8838 (0.9210) kd_loss 1.0085 (1.0120) acc 68.7500 (70.0000) lr 1.7290e-03 eta 0:27:29
epoch [14/50] batch [240/428] time 0.097 (0.105) data 0.000 (0.003) loss 1.6911 (1.8170) teacher_loss 0.7043 (0.8502) loss_zs_kd 1.4720 (1.8212) loss_oracle 0.9449 (0.9208) kd_loss 1.0287 (1.0130) acc 68.7500 (70.0521) lr 1.7290e-03 eta 0:27:24
epoch [14/50] batch [260/428] time 0.114 (0.106) data 0.000 (0.002) loss 1.7692 (1.8203) teacher_loss 0.8708 (0.8538) loss_zs_kd 1.4992 (1.8009) loss_oracle 0.8762 (0.9204) kd_loss 0.9206 (1.0127) acc 62.5000 (69.8317) lr 1.7290e-03 eta 0:27:23
epoch [14/50] batch [280/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.9377 (1.8177) teacher_loss 0.8410 (0.8490) loss_zs_kd 1.5543 (1.7964) loss_oracle 1.0450 (0.9225) kd_loss 1.1486 (1.0149) acc 65.6250 (69.9777) lr 1.7290e-03 eta 0:27:20
epoch [14/50] batch [300/428] time 0.111 (0.106) data 0.000 (0.002) loss 2.1933 (1.8252) teacher_loss 1.2866 (0.8526) loss_zs_kd 1.8419 (1.8016) loss_oracle 0.8875 (0.9252) kd_loss 0.9259 (1.0200) acc 53.1250 (69.8125) lr 1.7290e-03 eta 0:27:19
epoch [14/50] batch [320/428] time 0.115 (0.106) data 0.000 (0.002) loss 1.7742 (1.8306) teacher_loss 0.7889 (0.8546) loss_zs_kd 1.2144 (1.7873) loss_oracle 0.9419 (0.9285) kd_loss 1.0287 (1.0237) acc 71.8750 (69.7852) lr 1.7290e-03 eta 0:27:18
epoch [14/50] batch [340/428] time 0.099 (0.106) data 0.000 (0.002) loss 1.7851 (1.8264) teacher_loss 0.8031 (0.8493) loss_zs_kd 2.0867 (1.7938) loss_oracle 0.9326 (0.9290) kd_loss 1.0314 (1.0252) acc 68.7500 (70.0827) lr 1.7290e-03 eta 0:27:15
epoch [14/50] batch [360/428] time 0.093 (0.105) data 0.000 (0.002) loss 1.7386 (1.8255) teacher_loss 0.7905 (0.8478) loss_zs_kd 1.5918 (1.7971) loss_oracle 0.9377 (0.9294) kd_loss 0.9585 (1.0260) acc 81.2500 (70.2257) lr 1.7290e-03 eta 0:27:07
epoch [14/50] batch [380/428] time 0.122 (0.105) data 0.000 (0.002) loss 1.9527 (1.8213) teacher_loss 0.9511 (0.8439) loss_zs_kd 1.7325 (1.7969) loss_oracle 0.9545 (0.9290) kd_loss 1.0487 (1.0257) acc 65.6250 (70.3618) lr 1.7290e-03 eta 0:26:59
epoch [14/50] batch [400/428] time 0.106 (0.105) data 0.000 (0.002) loss 2.1080 (1.8215) teacher_loss 1.0863 (0.8436) loss_zs_kd 1.8188 (1.7954) loss_oracle 0.9845 (0.9297) kd_loss 1.0589 (1.0262) acc 65.6250 (70.4297) lr 1.7290e-03 eta 0:26:57
epoch [14/50] batch [420/428] time 0.100 (0.105) data 0.000 (0.002) loss 1.9024 (1.8188) teacher_loss 0.8985 (0.8405) loss_zs_kd 2.2258 (1.8009) loss_oracle 0.9273 (0.9298) kd_loss 1.0804 (1.0268) acc 62.5000 (70.4836) lr 1.7290e-03 eta 0:26:54
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,624
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 49.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,084
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 31.0%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [15/50] batch [20/428] time 0.214 (0.115) data 0.000 (0.030) loss 1.7634 (1.7600) teacher_loss 0.7248 (0.7237) loss_zs_kd 1.5436 (1.8500) loss_oracle 1.0046 (0.9664) kd_loss 1.0726 (1.1063) acc 75.0000 (74.0625) lr 1.6845e-03 eta 0:29:36
epoch [15/50] batch [40/428] time 0.163 (0.113) data 0.000 (0.015) loss 1.7999 (1.8052) teacher_loss 0.7932 (0.7707) loss_zs_kd 2.0407 (1.7320) loss_oracle 0.9129 (0.9668) kd_loss 1.1005 (1.1021) acc 71.8750 (72.5000) lr 1.6845e-03 eta 0:29:03
epoch [15/50] batch [60/428] time 0.079 (0.109) data 0.000 (0.010) loss 1.8055 (1.8252) teacher_loss 0.7832 (0.8016) loss_zs_kd 2.0693 (1.7288) loss_oracle 0.9413 (0.9560) kd_loss 1.1033 (1.0912) acc 65.6250 (71.5625) lr 1.6845e-03 eta 0:27:59
epoch [15/50] batch [80/428] time 0.083 (0.109) data 0.000 (0.008) loss 2.0736 (1.8193) teacher_loss 1.0505 (0.8010) loss_zs_kd 2.0156 (1.7311) loss_oracle 0.9506 (0.9529) kd_loss 1.0958 (1.0835) acc 68.7500 (72.0312) lr 1.6845e-03 eta 0:27:58
epoch [15/50] batch [100/428] time 0.106 (0.106) data 0.000 (0.006) loss 2.1086 (1.8219) teacher_loss 1.0575 (0.8087) loss_zs_kd 1.9965 (1.7625) loss_oracle 1.0358 (0.9494) kd_loss 1.0663 (1.0769) acc 68.7500 (71.6875) lr 1.6845e-03 eta 0:27:07
epoch [15/50] batch [120/428] time 0.117 (0.106) data 0.000 (0.005) loss 2.3480 (1.8301) teacher_loss 1.3994 (0.8193) loss_zs_kd 1.3394 (1.7596) loss_oracle 0.9500 (0.9476) kd_loss 0.9473 (1.0739) acc 59.3750 (71.1458) lr 1.6845e-03 eta 0:27:02
epoch [15/50] batch [140/428] time 0.116 (0.106) data 0.000 (0.005) loss 2.0354 (1.8360) teacher_loss 1.0351 (0.8265) loss_zs_kd 1.9959 (1.7448) loss_oracle 0.8736 (0.9451) kd_loss 1.1270 (1.0739) acc 62.5000 (71.0938) lr 1.6845e-03 eta 0:26:59
epoch [15/50] batch [160/428] time 0.118 (0.106) data 0.000 (0.004) loss 2.0091 (1.8405) teacher_loss 0.9720 (0.8334) loss_zs_kd 1.8023 (1.7438) loss_oracle 1.0031 (0.9413) kd_loss 1.0712 (1.0729) acc 56.2500 (70.5664) lr 1.6845e-03 eta 0:26:56
epoch [15/50] batch [180/428] time 0.103 (0.106) data 0.000 (0.004) loss 2.0884 (1.8494) teacher_loss 1.0495 (0.8419) loss_zs_kd 1.6799 (1.7294) loss_oracle 0.9289 (0.9391) kd_loss 1.1489 (1.0759) acc 62.5000 (70.1736) lr 1.6845e-03 eta 0:26:52
epoch [15/50] batch [200/428] time 0.105 (0.106) data 0.000 (0.003) loss 1.3856 (1.8462) teacher_loss 0.4455 (0.8417) loss_zs_kd 1.6953 (1.7217) loss_oracle 0.8682 (0.9370) kd_loss 1.0122 (1.0720) acc 93.7500 (70.3750) lr 1.6845e-03 eta 0:26:51
epoch [15/50] batch [220/428] time 0.112 (0.106) data 0.000 (0.003) loss 2.0486 (1.8422) teacher_loss 1.0293 (0.8397) loss_zs_kd 1.7317 (1.7354) loss_oracle 1.0163 (0.9364) kd_loss 1.0224 (1.0687) acc 68.7500 (70.5540) lr 1.6845e-03 eta 0:26:49
epoch [15/50] batch [240/428] time 0.113 (0.106) data 0.000 (0.003) loss 1.9348 (1.8388) teacher_loss 0.9216 (0.8374) loss_zs_kd 1.7827 (1.7449) loss_oracle 0.9220 (0.9358) kd_loss 1.1044 (1.0669) acc 68.7500 (70.4036) lr 1.6845e-03 eta 0:26:42
epoch [15/50] batch [260/428] time 0.095 (0.105) data 0.000 (0.003) loss 1.7274 (1.8372) teacher_loss 0.7050 (0.8349) loss_zs_kd 1.8751 (1.7403) loss_oracle 0.9594 (0.9362) kd_loss 1.0853 (1.0683) acc 68.7500 (70.4327) lr 1.6845e-03 eta 0:26:25
epoch [15/50] batch [280/428] time 0.092 (0.104) data 0.000 (0.002) loss 1.8188 (1.8320) teacher_loss 0.8198 (0.8294) loss_zs_kd 1.6396 (1.7376) loss_oracle 0.9921 (0.9364) kd_loss 1.0060 (1.0687) acc 75.0000 (70.5915) lr 1.6845e-03 eta 0:26:11
epoch [15/50] batch [300/428] time 0.082 (0.103) data 0.000 (0.002) loss 2.0964 (1.8288) teacher_loss 1.1101 (0.8269) loss_zs_kd 1.7130 (1.7464) loss_oracle 0.9310 (0.9369) kd_loss 1.0416 (1.0667) acc 59.3750 (70.6250) lr 1.6845e-03 eta 0:25:57
epoch [15/50] batch [320/428] time 0.093 (0.102) data 0.000 (0.002) loss 2.1770 (1.8284) teacher_loss 1.1701 (0.8272) loss_zs_kd 1.9656 (1.7512) loss_oracle 0.9791 (0.9382) kd_loss 1.0347 (1.0642) acc 62.5000 (70.4980) lr 1.6845e-03 eta 0:25:43
epoch [15/50] batch [340/428] time 0.102 (0.102) data 0.000 (0.002) loss 1.7468 (1.8307) teacher_loss 0.8144 (0.8310) loss_zs_kd 1.5348 (1.7567) loss_oracle 0.8912 (0.9381) kd_loss 0.9738 (1.0612) acc 71.8750 (70.4412) lr 1.6845e-03 eta 0:25:36
epoch [15/50] batch [360/428] time 0.120 (0.102) data 0.000 (0.002) loss 1.9867 (1.8260) teacher_loss 1.0880 (0.8287) loss_zs_kd 1.7632 (1.7621) loss_oracle 0.9473 (0.9366) kd_loss 0.8501 (1.0581) acc 65.6250 (70.5208) lr 1.6845e-03 eta 0:25:32
epoch [15/50] batch [380/428] time 0.071 (0.101) data 0.000 (0.002) loss 2.0987 (1.8242) teacher_loss 1.1500 (0.8298) loss_zs_kd 2.3791 (1.7828) loss_oracle 0.9069 (0.9351) kd_loss 0.9905 (1.0536) acc 56.2500 (70.4605) lr 1.6845e-03 eta 0:25:25
epoch [15/50] batch [400/428] time 0.103 (0.101) data 0.000 (0.002) loss 1.9676 (1.8242) teacher_loss 1.0344 (0.8319) loss_zs_kd 1.9108 (1.7927) loss_oracle 0.8994 (0.9341) kd_loss 0.9670 (1.0506) acc 65.6250 (70.3125) lr 1.6845e-03 eta 0:25:15
epoch [15/50] batch [420/428] time 0.087 (0.101) data 0.000 (0.002) loss 1.8885 (1.8262) teacher_loss 0.8751 (0.8339) loss_zs_kd 1.3005 (1.7847) loss_oracle 0.9440 (0.9337) kd_loss 1.0829 (1.0510) acc 65.6250 (70.2232) lr 1.6845e-03 eta 0:25:07
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,661
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 50.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,890
* accuracy: 39.9%
* error: 60.1%
* macro_f1: 27.7%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [16/50] batch [20/428] time 0.090 (0.130) data 0.000 (0.022) loss 2.2400 (1.8102) teacher_loss 1.1883 (0.7811) loss_zs_kd 2.2682 (1.7568) loss_oracle 0.8627 (0.9585) kd_loss 1.2407 (1.0998) acc 56.2500 (73.4375) lr 1.6374e-03 eta 0:32:21
epoch [16/50] batch [40/428] time 0.167 (0.117) data 0.000 (0.011) loss 1.7336 (1.8453) teacher_loss 0.7113 (0.8084) loss_zs_kd 1.7514 (1.8089) loss_oracle 0.9165 (0.9656) kd_loss 1.1281 (1.1083) acc 68.7500 (71.4062) lr 1.6374e-03 eta 0:29:13
epoch [16/50] batch [60/428] time 0.138 (0.117) data 0.000 (0.008) loss 2.2326 (1.8618) teacher_loss 1.1663 (0.8141) loss_zs_kd 1.6974 (1.7914) loss_oracle 1.0402 (0.9800) kd_loss 1.0923 (1.1154) acc 56.2500 (71.5104) lr 1.6374e-03 eta 0:29:03
epoch [16/50] batch [80/428] time 0.076 (0.118) data 0.000 (0.006) loss 1.5378 (1.8311) teacher_loss 0.4949 (0.7876) loss_zs_kd 1.7212 (1.8237) loss_oracle 0.9670 (0.9773) kd_loss 1.1188 (1.1098) acc 81.2500 (73.0078) lr 1.6374e-03 eta 0:29:25
epoch [16/50] batch [100/428] time 0.110 (0.115) data 0.000 (0.005) loss 1.9335 (1.8143) teacher_loss 0.9390 (0.7806) loss_zs_kd 2.3788 (1.8436) loss_oracle 0.9129 (0.9689) kd_loss 1.0761 (1.0985) acc 71.8750 (73.2812) lr 1.6374e-03 eta 0:28:25
epoch [16/50] batch [120/428] time 0.099 (0.113) data 0.000 (0.004) loss 1.6094 (1.8149) teacher_loss 0.5815 (0.7901) loss_zs_kd 1.7855 (1.8723) loss_oracle 0.9710 (0.9605) kd_loss 1.0848 (1.0892) acc 81.2500 (72.8125) lr 1.6374e-03 eta 0:28:01
epoch [16/50] batch [140/428] time 0.110 (0.112) data 0.000 (0.003) loss 1.6620 (1.8032) teacher_loss 0.6451 (0.7779) loss_zs_kd 1.8987 (1.8626) loss_oracle 0.9848 (0.9615) kd_loss 1.0491 (1.0889) acc 81.2500 (73.0134) lr 1.6374e-03 eta 0:27:41
epoch [16/50] batch [160/428] time 0.085 (0.111) data 0.000 (0.003) loss 1.9458 (1.8012) teacher_loss 0.9878 (0.7818) loss_zs_kd 1.9393 (1.8668) loss_oracle 0.9223 (0.9580) kd_loss 0.9937 (1.0808) acc 65.6250 (72.8711) lr 1.6374e-03 eta 0:27:23
epoch [16/50] batch [180/428] time 0.107 (0.110) data 0.000 (0.003) loss 1.4519 (1.8032) teacher_loss 0.4863 (0.7919) loss_zs_kd 1.7854 (1.8682) loss_oracle 0.9547 (0.9540) kd_loss 0.9764 (1.0686) acc 90.6250 (72.4132) lr 1.6374e-03 eta 0:27:10
epoch [16/50] batch [200/428] time 0.110 (0.110) data 0.000 (0.002) loss 1.6839 (1.8094) teacher_loss 0.6717 (0.8000) loss_zs_kd 1.9104 (1.8613) loss_oracle 0.9488 (0.9533) kd_loss 1.0754 (1.0653) acc 68.7500 (72.2188) lr 1.6374e-03 eta 0:27:05
epoch [16/50] batch [220/428] time 0.108 (0.109) data 0.000 (0.002) loss 1.6166 (1.8110) teacher_loss 0.6663 (0.8044) loss_zs_kd 1.7942 (1.8491) loss_oracle 0.9406 (0.9520) kd_loss 0.9601 (1.0612) acc 81.2500 (72.2159) lr 1.6374e-03 eta 0:26:54
epoch [16/50] batch [240/428] time 0.095 (0.109) data 0.000 (0.002) loss 1.7264 (1.8109) teacher_loss 0.7699 (0.8041) loss_zs_kd 1.6461 (1.8325) loss_oracle 0.9200 (0.9524) kd_loss 0.9929 (1.0612) acc 81.2500 (72.3047) lr 1.6374e-03 eta 0:26:46
epoch [16/50] batch [260/428] time 0.098 (0.109) data 0.000 (0.002) loss 2.1184 (1.8137) teacher_loss 1.0797 (0.8069) loss_zs_kd 1.5441 (1.8331) loss_oracle 0.9644 (0.9522) kd_loss 1.1130 (1.0615) acc 59.3750 (72.1875) lr 1.6374e-03 eta 0:26:38
epoch [16/50] batch [280/428] time 0.101 (0.108) data 0.000 (0.002) loss 2.0414 (1.8153) teacher_loss 1.0003 (0.8089) loss_zs_kd 1.6715 (1.8248) loss_oracle 0.9208 (0.9510) kd_loss 1.1614 (1.0616) acc 68.7500 (72.1540) lr 1.6374e-03 eta 0:26:31
epoch [16/50] batch [300/428] time 0.102 (0.108) data 0.000 (0.002) loss 1.9621 (1.8159) teacher_loss 0.9744 (0.8093) loss_zs_kd 1.7322 (1.8257) loss_oracle 0.9421 (0.9513) kd_loss 1.0331 (1.0619) acc 71.8750 (72.2083) lr 1.6374e-03 eta 0:26:24
epoch [16/50] batch [320/428] time 0.099 (0.108) data 0.000 (0.002) loss 1.9038 (1.8140) teacher_loss 0.9429 (0.8076) loss_zs_kd 1.9617 (1.8297) loss_oracle 0.9204 (0.9515) kd_loss 1.0014 (1.0612) acc 59.3750 (72.3145) lr 1.6374e-03 eta 0:26:19
epoch [16/50] batch [340/428] time 0.104 (0.108) data 0.000 (0.002) loss 1.8138 (1.8082) teacher_loss 0.8369 (0.8033) loss_zs_kd 1.8659 (1.8300) loss_oracle 0.9604 (0.9508) kd_loss 0.9932 (1.0590) acc 59.3750 (72.5184) lr 1.6374e-03 eta 0:26:14
epoch [16/50] batch [360/428] time 0.094 (0.107) data 0.000 (0.001) loss 1.9017 (1.8089) teacher_loss 0.8993 (0.8048) loss_zs_kd 1.7608 (1.8189) loss_oracle 0.9601 (0.9502) kd_loss 1.0446 (1.0579) acc 62.5000 (72.5434) lr 1.6374e-03 eta 0:26:08
epoch [16/50] batch [380/428] time 0.097 (0.107) data 0.000 (0.001) loss 1.6361 (1.8064) teacher_loss 0.5344 (0.8008) loss_zs_kd 1.9707 (1.8136) loss_oracle 1.0554 (0.9513) kd_loss 1.1480 (1.0599) acc 78.1250 (72.7138) lr 1.6374e-03 eta 0:26:04
epoch [16/50] batch [400/428] time 0.117 (0.107) data 0.000 (0.001) loss 1.7764 (1.8085) teacher_loss 0.6859 (0.8009) loss_zs_kd 1.9582 (1.8094) loss_oracle 1.0178 (0.9533) kd_loss 1.1633 (1.0618) acc 75.0000 (72.6328) lr 1.6374e-03 eta 0:26:03
epoch [16/50] batch [420/428] time 0.100 (0.107) data 0.000 (0.001) loss 1.5448 (1.8119) teacher_loss 0.5151 (0.8030) loss_zs_kd 1.9474 (1.8075) loss_oracle 0.9923 (0.9551) kd_loss 1.0671 (1.0627) acc 84.3750 (72.5595) lr 1.6374e-03 eta 0:25:57
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,685
* accuracy: 62.7%
* error: 37.3%
* macro_f1: 50.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,105
* accuracy: 44.4%
* error: 55.6%
* macro_f1: 32.4%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [17/50] batch [20/428] time 0.145 (0.124) data 0.000 (0.023) loss 1.6958 (1.7713) teacher_loss 0.6533 (0.7426) loss_zs_kd 1.6640 (1.6984) loss_oracle 0.9606 (0.9690) kd_loss 1.1246 (1.0883) acc 75.0000 (75.3125) lr 1.5878e-03 eta 0:29:58
epoch [17/50] batch [40/428] time 0.067 (0.117) data 0.000 (0.012) loss 1.8914 (1.7769) teacher_loss 0.8944 (0.7499) loss_zs_kd 1.7644 (1.7151) loss_oracle 0.9639 (0.9697) kd_loss 1.0303 (1.0843) acc 65.6250 (75.8594) lr 1.5878e-03 eta 0:28:13
epoch [17/50] batch [60/428] time 0.082 (0.116) data 0.000 (0.008) loss 1.5905 (1.7756) teacher_loss 0.5985 (0.7414) loss_zs_kd 1.5424 (1.7138) loss_oracle 0.9629 (0.9774) kd_loss 1.0211 (1.0909) acc 78.1250 (75.5729) lr 1.5878e-03 eta 0:27:58
epoch [17/50] batch [80/428] time 0.101 (0.110) data 0.000 (0.006) loss 1.7124 (1.7683) teacher_loss 0.7245 (0.7396) loss_zs_kd 1.7273 (1.7458) loss_oracle 0.9264 (0.9715) kd_loss 1.0496 (1.0859) acc 71.8750 (75.7812) lr 1.5878e-03 eta 0:26:30
epoch [17/50] batch [100/428] time 0.127 (0.109) data 0.000 (0.005) loss 1.5560 (1.7605) teacher_loss 0.5204 (0.7329) loss_zs_kd 1.8587 (1.7736) loss_oracle 1.0521 (0.9726) kd_loss 1.0192 (1.0827) acc 87.5000 (75.7812) lr 1.5878e-03 eta 0:26:18
epoch [17/50] batch [120/428] time 0.087 (0.107) data 0.000 (0.004) loss 2.0594 (1.7779) teacher_loss 1.0024 (0.7489) loss_zs_kd 1.8796 (1.7581) loss_oracle 1.0054 (0.9726) kd_loss 1.1085 (1.0854) acc 68.7500 (75.3906) lr 1.5878e-03 eta 0:25:49
epoch [17/50] batch [140/428] time 0.082 (0.105) data 0.000 (0.004) loss 1.4969 (1.7714) teacher_loss 0.4630 (0.7426) loss_zs_kd 1.9859 (1.7482) loss_oracle 0.9726 (0.9705) kd_loss 1.0952 (1.0869) acc 90.6250 (75.4911) lr 1.5878e-03 eta 0:25:11
epoch [17/50] batch [160/428] time 0.091 (0.103) data 0.000 (0.003) loss 1.8663 (1.7811) teacher_loss 0.8739 (0.7500) loss_zs_kd 1.8710 (1.7330) loss_oracle 0.9477 (0.9740) kd_loss 1.0371 (1.0883) acc 71.8750 (75.1562) lr 1.5878e-03 eta 0:24:40
epoch [17/50] batch [180/428] time 0.085 (0.102) data 0.000 (0.003) loss 1.8830 (1.7899) teacher_loss 0.7971 (0.7578) loss_zs_kd 1.5476 (1.7242) loss_oracle 1.0251 (0.9776) kd_loss 1.1466 (1.0868) acc 78.1250 (74.9479) lr 1.5878e-03 eta 0:24:22
epoch [17/50] batch [200/428] time 0.080 (0.100) data 0.000 (0.003) loss 1.4294 (1.7914) teacher_loss 0.3871 (0.7579) loss_zs_kd 1.6824 (1.7286) loss_oracle 0.9722 (0.9794) kd_loss 1.1123 (1.0878) acc 87.5000 (74.6094) lr 1.5878e-03 eta 0:24:02
epoch [17/50] batch [220/428] time 0.089 (0.099) data 0.000 (0.002) loss 1.9408 (1.7870) teacher_loss 0.9261 (0.7531) loss_zs_kd 2.2335 (1.7355) loss_oracle 1.0152 (0.9813) kd_loss 1.0142 (1.0866) acc 65.6250 (74.7017) lr 1.5878e-03 eta 0:23:43
epoch [17/50] batch [240/428] time 0.087 (0.098) data 0.000 (0.002) loss 1.8429 (1.7910) teacher_loss 0.7656 (0.7566) loss_zs_kd 1.8182 (1.7380) loss_oracle 0.9767 (0.9830) kd_loss 1.1777 (1.0857) acc 71.8750 (74.5182) lr 1.5878e-03 eta 0:23:28
epoch [17/50] batch [260/428] time 0.086 (0.098) data 0.000 (0.002) loss 1.9845 (1.8018) teacher_loss 0.9291 (0.7672) loss_zs_kd 1.9314 (1.7292) loss_oracle 1.0171 (0.9835) kd_loss 1.0937 (1.0857) acc 65.6250 (74.1587) lr 1.5878e-03 eta 0:23:14
epoch [17/50] batch [280/428] time 0.091 (0.097) data 0.000 (0.002) loss 1.7794 (1.8022) teacher_loss 0.7736 (0.7671) loss_zs_kd 2.1699 (1.7381) loss_oracle 0.9385 (0.9841) kd_loss 1.0730 (1.0861) acc 71.8750 (74.0737) lr 1.5878e-03 eta 0:23:03
epoch [17/50] batch [300/428] time 0.099 (0.097) data 0.000 (0.002) loss 1.6926 (1.8037) teacher_loss 0.6795 (0.7691) loss_zs_kd 2.2267 (1.7448) loss_oracle 0.9430 (0.9847) kd_loss 1.0832 (1.0845) acc 78.1250 (74.0521) lr 1.5878e-03 eta 0:23:02
epoch [17/50] batch [320/428] time 0.109 (0.097) data 0.000 (0.002) loss 1.9267 (1.8031) teacher_loss 0.9369 (0.7689) loss_zs_kd 2.0375 (1.7453) loss_oracle 0.9737 (0.9849) kd_loss 1.0060 (1.0835) acc 71.8750 (74.0137) lr 1.5878e-03 eta 0:23:02
epoch [17/50] batch [340/428] time 0.102 (0.097) data 0.000 (0.002) loss 1.8082 (1.8063) teacher_loss 0.7706 (0.7725) loss_zs_kd 1.7123 (1.7448) loss_oracle 1.0411 (0.9847) kd_loss 1.0341 (1.0829) acc 71.8750 (73.8787) lr 1.5878e-03 eta 0:23:00
epoch [17/50] batch [360/428] time 0.108 (0.097) data 0.000 (0.002) loss 1.7466 (1.8099) teacher_loss 0.7450 (0.7756) loss_zs_kd 1.5823 (1.7434) loss_oracle 0.9706 (0.9857) kd_loss 1.0326 (1.0830) acc 75.0000 (73.8021) lr 1.5878e-03 eta 0:23:02
epoch [17/50] batch [380/428] time 0.094 (0.098) data 0.000 (0.001) loss 1.6942 (1.8117) teacher_loss 0.6622 (0.7772) loss_zs_kd 1.6865 (1.7436) loss_oracle 0.9789 (0.9852) kd_loss 1.0850 (1.0838) acc 78.1250 (73.7664) lr 1.5878e-03 eta 0:23:07
epoch [17/50] batch [400/428] time 0.097 (0.098) data 0.000 (0.001) loss 1.9372 (1.8156) teacher_loss 0.9686 (0.7808) loss_zs_kd 2.0084 (1.7375) loss_oracle 0.9336 (0.9859) kd_loss 1.0035 (1.0837) acc 68.7500 (73.6875) lr 1.5878e-03 eta 0:23:10
epoch [17/50] batch [420/428] time 0.099 (0.099) data 0.000 (0.001) loss 1.6564 (1.8182) teacher_loss 0.6343 (0.7834) loss_zs_kd 1.7668 (1.7370) loss_oracle 0.9766 (0.9858) kd_loss 1.0677 (1.0837) acc 87.5000 (73.5193) lr 1.5878e-03 eta 0:23:12
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,673
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 50.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,855
* accuracy: 39.1%
* error: 60.9%
* macro_f1: 26.8%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     48.3%, epoch: 9 *******
epoch [18/50] batch [20/428] time 0.088 (0.143) data 0.000 (0.033) loss 1.7838 (1.7552) teacher_loss 0.7510 (0.7197) loss_zs_kd 1.5333 (1.8281) loss_oracle 0.9674 (0.9968) kd_loss 1.0983 (1.0742) acc 65.6250 (74.2188) lr 1.5358e-03 eta 0:33:40
epoch [18/50] batch [40/428] time 0.109 (0.125) data 0.000 (0.017) loss 1.6439 (1.7880) teacher_loss 0.5875 (0.7531) loss_zs_kd 1.6459 (1.8367) loss_oracle 1.0287 (0.9962) kd_loss 1.0842 (1.0737) acc 75.0000 (73.2031) lr 1.5358e-03 eta 0:29:20
epoch [18/50] batch [60/428] time 0.104 (0.118) data 0.001 (0.011) loss 2.0415 (1.7674) teacher_loss 1.0517 (0.7403) loss_zs_kd 2.1326 (1.8580) loss_oracle 0.8924 (0.9896) kd_loss 1.0871 (1.0646) acc 71.8750 (74.0104) lr 1.5358e-03 eta 0:27:35
epoch [18/50] batch [80/428] time 0.087 (0.114) data 0.000 (0.008) loss 2.2094 (1.8107) teacher_loss 1.1830 (0.7815) loss_zs_kd 1.5925 (1.8608) loss_oracle 0.9762 (0.9901) kd_loss 1.0767 (1.0685) acc 62.5000 (73.2812) lr 1.5358e-03 eta 0:26:35
epoch [18/50] batch [100/428] time 0.109 (0.112) data 0.000 (0.007) loss 1.4746 (1.8282) teacher_loss 0.4477 (0.7970) loss_zs_kd 1.7085 (1.8003) loss_oracle 1.0243 (0.9935) kd_loss 1.0296 (1.0689) acc 84.3750 (72.6250) lr 1.5358e-03 eta 0:26:06
epoch [18/50] batch [120/428] time 0.097 (0.110) data 0.000 (0.006) loss 1.7262 (1.8348) teacher_loss 0.7340 (0.8040) loss_zs_kd 1.5892 (1.7703) loss_oracle 0.9707 (0.9959) kd_loss 1.0136 (1.0656) acc 65.6250 (72.1094) lr 1.5358e-03 eta 0:25:44
epoch [18/50] batch [140/428] time 0.100 (0.109) data 0.000 (0.005) loss 1.7908 (1.8481) teacher_loss 0.7938 (0.8170) loss_zs_kd 1.4160 (1.7551) loss_oracle 0.9424 (0.9972) kd_loss 1.0515 (1.0650) acc 62.5000 (71.5402) lr 1.5358e-03 eta 0:25:30
epoch [18/50] batch [160/428] time 0.109 (0.109) data 0.000 (0.004) loss 1.7994 (1.8414) teacher_loss 0.7299 (0.8126) loss_zs_kd 1.6210 (1.7436) loss_oracle 0.9921 (0.9956) kd_loss 1.1469 (1.0619) acc 68.7500 (71.8359) lr 1.5358e-03 eta 0:25:18
epoch [18/50] batch [180/428] time 0.100 (0.108) data 0.000 (0.004) loss 2.0570 (1.8398) teacher_loss 1.0515 (0.8117) loss_zs_kd 1.6499 (1.7378) loss_oracle 0.9770 (0.9964) kd_loss 1.0340 (1.0598) acc 68.7500 (72.1701) lr 1.5358e-03 eta 0:25:08
epoch [18/50] batch [200/428] time 0.108 (0.108) data 0.000 (0.004) loss 1.6905 (1.8324) teacher_loss 0.6706 (0.8053) loss_zs_kd 1.5736 (1.7393) loss_oracle 0.9559 (0.9950) kd_loss 1.0838 (1.0590) acc 75.0000 (72.5781) lr 1.5358e-03 eta 0:24:58
epoch [18/50] batch [220/428] time 0.107 (0.107) data 0.000 (0.003) loss 1.9873 (1.8360) teacher_loss 0.9600 (0.8105) loss_zs_kd 1.7901 (1.7508) loss_oracle 0.9662 (0.9944) kd_loss 1.0884 (1.0565) acc 68.7500 (72.4432) lr 1.5358e-03 eta 0:24:52
epoch [18/50] batch [240/428] time 0.104 (0.107) data 0.000 (0.003) loss 1.6522 (1.8367) teacher_loss 0.6615 (0.8126) loss_zs_kd 1.4132 (1.7494) loss_oracle 0.9941 (0.9929) kd_loss 0.9873 (1.0554) acc 84.3750 (72.3047) lr 1.5358e-03 eta 0:24:46
epoch [18/50] batch [260/428] time 0.103 (0.107) data 0.000 (0.003) loss 1.9840 (1.8324) teacher_loss 0.9457 (0.8083) loss_zs_kd 2.1105 (1.7584) loss_oracle 0.9834 (0.9922) kd_loss 1.0932 (1.0561) acc 71.8750 (72.3678) lr 1.5358e-03 eta 0:24:40
epoch [18/50] batch [280/428] time 0.101 (0.107) data 0.000 (0.003) loss 1.5126 (1.8221) teacher_loss 0.4807 (0.7994) loss_zs_kd 2.0587 (1.7702) loss_oracle 1.0086 (0.9914) kd_loss 1.0551 (1.0540) acc 87.5000 (72.6786) lr 1.5358e-03 eta 0:24:34
epoch [18/50] batch [300/428] time 0.106 (0.106) data 0.000 (0.002) loss 1.5944 (1.8226) teacher_loss 0.5952 (0.8007) loss_zs_kd 2.2069 (1.7808) loss_oracle 0.9407 (0.9899) kd_loss 1.0578 (1.0540) acc 75.0000 (72.5208) lr 1.5358e-03 eta 0:24:30
epoch [18/50] batch [320/428] time 0.098 (0.106) data 0.000 (0.002) loss 1.6471 (1.8183) teacher_loss 0.6912 (0.7983) loss_zs_kd 1.9427 (1.8006) loss_oracle 0.9368 (0.9870) kd_loss 0.9748 (1.0530) acc 71.8750 (72.5879) lr 1.5358e-03 eta 0:24:26
epoch [18/50] batch [340/428] time 0.107 (0.106) data 0.000 (0.002) loss 1.7262 (1.8157) teacher_loss 0.7317 (0.7962) loss_zs_kd 1.6626 (1.8074) loss_oracle 0.9617 (0.9861) kd_loss 1.0274 (1.0530) acc 78.1250 (72.6195) lr 1.5358e-03 eta 0:24:23
epoch [18/50] batch [360/428] time 0.110 (0.106) data 0.000 (0.002) loss 1.8795 (1.8152) teacher_loss 0.8899 (0.7970) loss_zs_kd 1.4927 (1.8089) loss_oracle 0.9797 (0.9845) kd_loss 0.9995 (1.0519) acc 65.6250 (72.5694) lr 1.5358e-03 eta 0:24:20
epoch [18/50] batch [380/428] time 0.113 (0.106) data 0.000 (0.002) loss 2.2277 (1.8169) teacher_loss 1.1617 (0.7984) loss_zs_kd 1.8856 (1.8133) loss_oracle 1.0035 (0.9843) kd_loss 1.1285 (1.0526) acc 62.5000 (72.5905) lr 1.5358e-03 eta 0:24:16
epoch [18/50] batch [400/428] time 0.106 (0.106) data 0.000 (0.002) loss 1.9112 (1.8271) teacher_loss 0.7648 (0.8061) loss_zs_kd 1.4682 (1.8077) loss_oracle 1.0126 (0.9844) kd_loss 1.2803 (1.0576) acc 78.1250 (72.3125) lr 1.5358e-03 eta 0:24:13
epoch [18/50] batch [420/428] time 0.100 (0.106) data 0.000 (0.002) loss 2.1827 (1.8446) teacher_loss 1.0555 (0.8177) loss_zs_kd 1.4138 (1.7963) loss_oracle 1.0346 (0.9863) kd_loss 1.2198 (1.0676) acc 65.6250 (71.9196) lr 1.5358e-03 eta 0:24:09
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,465
* accuracy: 59.0%
* error: 41.0%
* macro_f1: 47.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,495
* accuracy: 52.6%
* error: 47.4%
* macro_f1: 33.5%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [19/50] batch [20/428] time 0.078 (0.147) data 0.000 (0.032) loss 1.8118 (2.1163) teacher_loss 0.6814 (0.9557) loss_zs_kd 1.6489 (1.4473) loss_oracle 1.0124 (1.0607) kd_loss 1.2484 (1.2603) acc 81.2500 (67.5000) lr 1.4818e-03 eta 0:33:29
epoch [19/50] batch [40/428] time 0.095 (0.119) data 0.000 (0.016) loss 2.1307 (2.1650) teacher_loss 0.9027 (1.0003) loss_zs_kd 1.1181 (1.4898) loss_oracle 1.1579 (1.0777) kd_loss 1.2981 (1.2518) acc 68.7500 (66.2500) lr 1.4818e-03 eta 0:27:04
epoch [19/50] batch [60/428] time 0.105 (0.114) data 0.000 (0.011) loss 2.0036 (2.1612) teacher_loss 0.8209 (1.0003) loss_zs_kd 1.4663 (1.4841) loss_oracle 1.1094 (1.0811) kd_loss 1.2560 (1.2406) acc 65.6250 (65.8854) lr 1.4818e-03 eta 0:25:51
epoch [19/50] batch [80/428] time 0.106 (0.111) data 0.000 (0.008) loss 2.0200 (2.1221) teacher_loss 0.8928 (0.9690) loss_zs_kd 1.5367 (1.5112) loss_oracle 1.0914 (1.0784) kd_loss 1.1631 (1.2276) acc 68.7500 (67.1484) lr 1.4818e-03 eta 0:25:11
epoch [19/50] batch [100/428] time 0.111 (0.110) data 0.000 (0.007) loss 2.1536 (2.1016) teacher_loss 1.0200 (0.9563) loss_zs_kd 1.7242 (1.5740) loss_oracle 1.0683 (1.0719) kd_loss 1.1989 (1.2186) acc 59.3750 (67.5312) lr 1.4818e-03 eta 0:24:52
epoch [19/50] batch [120/428] time 0.105 (0.109) data 0.000 (0.006) loss 1.9274 (2.0770) teacher_loss 0.7647 (0.9343) loss_zs_kd 2.0278 (1.6122) loss_oracle 1.1284 (1.0736) kd_loss 1.1970 (1.2117) acc 75.0000 (68.1771) lr 1.4818e-03 eta 0:24:42
epoch [19/50] batch [140/428] time 0.105 (0.109) data 0.000 (0.005) loss 1.6470 (2.0503) teacher_loss 0.5855 (0.9173) loss_zs_kd 1.7672 (1.6571) loss_oracle 1.0089 (1.0688) kd_loss 1.1141 (1.1972) acc 87.5000 (68.7054) lr 1.4818e-03 eta 0:24:33
epoch [19/50] batch [160/428] time 0.105 (0.108) data 0.000 (0.004) loss 2.2328 (2.0194) teacher_loss 1.1171 (0.8949) loss_zs_kd 1.9231 (1.6852) loss_oracle 1.0871 (1.0645) kd_loss 1.1442 (1.1844) acc 62.5000 (69.4922) lr 1.4818e-03 eta 0:24:23
epoch [19/50] batch [180/428] time 0.096 (0.108) data 0.000 (0.004) loss 1.7647 (1.9923) teacher_loss 0.8076 (0.8774) loss_zs_kd 1.9546 (1.7221) loss_oracle 0.9418 (1.0593) kd_loss 0.9724 (1.1704) acc 75.0000 (70.0694) lr 1.4818e-03 eta 0:24:24
epoch [19/50] batch [200/428] time 0.086 (0.107) data 0.000 (0.004) loss 1.6018 (1.9740) teacher_loss 0.5808 (0.8700) loss_zs_kd 2.2694 (1.7533) loss_oracle 0.9988 (1.0517) kd_loss 1.0432 (1.1563) acc 78.1250 (70.2500) lr 1.4818e-03 eta 0:24:01
epoch [19/50] batch [220/428] time 0.092 (0.105) data 0.000 (0.003) loss 1.7079 (1.9615) teacher_loss 0.7996 (0.8695) loss_zs_kd 1.9672 (1.7730) loss_oracle 0.9167 (1.0433) kd_loss 0.8999 (1.1406) acc 71.8750 (70.2557) lr 1.4818e-03 eta 0:23:41
epoch [19/50] batch [240/428] time 0.100 (0.105) data 0.000 (0.003) loss 1.8677 (1.9496) teacher_loss 0.9149 (0.8688) loss_zs_kd 1.5313 (1.7762) loss_oracle 0.9270 (1.0345) kd_loss 0.9785 (1.1271) acc 59.3750 (70.0521) lr 1.4818e-03 eta 0:23:26
epoch [19/50] batch [260/428] time 0.092 (0.104) data 0.000 (0.003) loss 1.8410 (1.9384) teacher_loss 0.8856 (0.8676) loss_zs_kd 2.0157 (1.7767) loss_oracle 0.9450 (1.0268) kd_loss 0.9657 (1.1147) acc 62.5000 (69.8798) lr 1.4818e-03 eta 0:23:19
epoch [19/50] batch [280/428] time 0.102 (0.104) data 0.001 (0.003) loss 1.8749 (1.9281) teacher_loss 0.9499 (0.8642) loss_zs_kd 1.8366 (1.7794) loss_oracle 0.8890 (1.0212) kd_loss 0.9610 (1.1066) acc 75.0000 (70.0446) lr 1.4818e-03 eta 0:23:11
epoch [19/50] batch [300/428] time 0.099 (0.104) data 0.000 (0.002) loss 1.5258 (1.9210) teacher_loss 0.5474 (0.8631) loss_zs_kd 1.6114 (1.7832) loss_oracle 0.9723 (1.0163) kd_loss 0.9845 (1.0995) acc 81.2500 (70.0625) lr 1.4818e-03 eta 0:23:08
epoch [19/50] batch [320/428] time 0.108 (0.104) data 0.000 (0.002) loss 1.6784 (1.9122) teacher_loss 0.6612 (0.8599) loss_zs_kd 2.2548 (1.7900) loss_oracle 1.0069 (1.0117) kd_loss 1.0276 (1.0928) acc 78.1250 (70.1758) lr 1.4818e-03 eta 0:23:08
epoch [19/50] batch [340/428] time 0.107 (0.104) data 0.000 (0.002) loss 1.9871 (1.9039) teacher_loss 0.9486 (0.8552) loss_zs_kd 2.1205 (1.8028) loss_oracle 1.0064 (1.0092) kd_loss 1.0705 (1.0884) acc 68.7500 (70.1746) lr 1.4818e-03 eta 0:23:08
epoch [19/50] batch [360/428] time 0.110 (0.104) data 0.000 (0.002) loss 1.7300 (1.9014) teacher_loss 0.6968 (0.8547) loss_zs_kd 1.7493 (1.8130) loss_oracle 1.0133 (1.0074) kd_loss 1.0530 (1.0859) acc 71.8750 (70.2604) lr 1.4818e-03 eta 0:23:06
epoch [19/50] batch [380/428] time 0.109 (0.104) data 0.000 (0.002) loss 1.9804 (1.8959) teacher_loss 0.9690 (0.8518) loss_zs_kd 1.8678 (1.8137) loss_oracle 0.9985 (1.0054) kd_loss 1.0243 (1.0829) acc 65.6250 (70.2796) lr 1.4818e-03 eta 0:23:06
epoch [19/50] batch [400/428] time 0.107 (0.104) data 0.000 (0.002) loss 1.9069 (1.8925) teacher_loss 0.8910 (0.8500) loss_zs_kd 2.0160 (1.8105) loss_oracle 0.9684 (1.0044) kd_loss 1.0634 (1.0805) acc 65.6250 (70.2422) lr 1.4818e-03 eta 0:23:06
epoch [19/50] batch [420/428] time 0.100 (0.104) data 0.000 (0.002) loss 1.7844 (1.8896) teacher_loss 0.7811 (0.8501) loss_zs_kd 1.7579 (1.8110) loss_oracle 0.9826 (1.0021) kd_loss 1.0240 (1.0770) acc 65.6250 (70.1339) lr 1.4818e-03 eta 0:23:05
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,614
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 47.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,005
* accuracy: 42.3%
* error: 57.7%
* macro_f1: 30.8%
******* Domain 1 best val acc:      63.4%, epoch: 13 *******
******* Domain 1 best val test acc: 41.3%, epoch: 13 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [20/50] batch [20/428] time 0.074 (0.144) data 0.000 (0.030) loss 1.6755 (1.7608) teacher_loss 0.7008 (0.7661) loss_zs_kd 1.4602 (1.6868) loss_oracle 0.9090 (0.9514) kd_loss 1.0404 (1.0379) acc 78.1250 (72.8125) lr 1.4258e-03 eta 0:31:51
epoch [20/50] batch [40/428] time 0.095 (0.114) data 0.000 (0.015) loss 1.9361 (1.7561) teacher_loss 0.9059 (0.7474) loss_zs_kd 1.9392 (1.6872) loss_oracle 0.9209 (0.9568) kd_loss 1.1395 (1.0607) acc 50.0000 (71.8750) lr 1.4258e-03 eta 0:25:14
epoch [20/50] batch [60/428] time 0.099 (0.107) data 0.000 (0.010) loss 1.7423 (1.7867) teacher_loss 0.6466 (0.7609) loss_zs_kd 1.6867 (1.7457) loss_oracle 1.0074 (0.9753) kd_loss 1.1841 (1.0764) acc 78.1250 (72.6562) lr 1.4258e-03 eta 0:23:30
epoch [20/50] batch [80/428] time 0.091 (0.103) data 0.000 (0.008) loss 2.3572 (1.8689) teacher_loss 1.2531 (0.8229) loss_zs_kd 1.7115 (1.7160) loss_oracle 1.0265 (0.9880) kd_loss 1.1817 (1.1040) acc 53.1250 (70.5078) lr 1.4258e-03 eta 0:22:41
epoch [20/50] batch [100/428] time 0.095 (0.101) data 0.000 (0.006) loss 2.1905 (1.9367) teacher_loss 1.1015 (0.8723) loss_zs_kd 1.7037 (1.6931) loss_oracle 0.9582 (0.9979) kd_loss 1.2196 (1.1308) acc 62.5000 (69.0625) lr 1.4258e-03 eta 0:22:12
epoch [20/50] batch [120/428] time 0.102 (0.099) data 0.000 (0.005) loss 1.8476 (1.9706) teacher_loss 0.6973 (0.8943) loss_zs_kd 1.4980 (1.6812) loss_oracle 1.1187 (1.0036) kd_loss 1.1818 (1.1491) acc 75.0000 (68.4635) lr 1.4258e-03 eta 0:21:45
epoch [20/50] batch [140/428] time 0.106 (0.100) data 0.000 (0.005) loss 2.1047 (1.9947) teacher_loss 1.0022 (0.9112) loss_zs_kd 1.9465 (1.6640) loss_oracle 1.0738 (1.0105) kd_loss 1.1311 (1.1564) acc 71.8750 (67.8571) lr 1.4258e-03 eta 0:21:50
epoch [20/50] batch [160/428] time 0.100 (0.100) data 0.000 (0.004) loss 1.9598 (2.0001) teacher_loss 0.8221 (0.9108) loss_zs_kd 1.7765 (1.6530) loss_oracle 1.1211 (1.0190) kd_loss 1.1544 (1.1595) acc 75.0000 (67.8711) lr 1.4258e-03 eta 0:21:55
epoch [20/50] batch [180/428] time 0.112 (0.101) data 0.000 (0.004) loss 2.0969 (2.0043) teacher_loss 1.0528 (0.9148) loss_zs_kd 1.6350 (1.6388) loss_oracle 0.9514 (1.0216) kd_loss 1.1368 (1.1573) acc 68.7500 (67.5694) lr 1.4258e-03 eta 0:22:00
epoch [20/50] batch [200/428] time 0.107 (0.101) data 0.000 (0.003) loss 1.8234 (1.9966) teacher_loss 0.7206 (0.9073) loss_zs_kd 1.4600 (1.6432) loss_oracle 1.0725 (1.0256) kd_loss 1.1330 (1.1531) acc 75.0000 (67.6719) lr 1.4258e-03 eta 0:21:57
epoch [20/50] batch [220/428] time 0.118 (0.101) data 0.000 (0.003) loss 1.7822 (1.9750) teacher_loss 0.7217 (0.8883) loss_zs_kd 1.9818 (1.6679) loss_oracle 1.0380 (1.0260) kd_loss 1.0830 (1.1474) acc 68.7500 (68.3949) lr 1.4258e-03 eta 0:22:00
epoch [20/50] batch [240/428] time 0.109 (0.101) data 0.000 (0.003) loss 2.1415 (1.9674) teacher_loss 1.0690 (0.8829) loss_zs_kd 1.7552 (1.6882) loss_oracle 0.9974 (1.0268) kd_loss 1.1478 (1.1423) acc 50.0000 (68.6458) lr 1.4258e-03 eta 0:22:01
epoch [20/50] batch [260/428] time 0.100 (0.102) data 0.000 (0.003) loss 2.0980 (1.9635) teacher_loss 1.0484 (0.8789) loss_zs_kd 1.7128 (1.6978) loss_oracle 1.0335 (1.0295) kd_loss 1.0657 (1.1397) acc 62.5000 (68.8462) lr 1.4258e-03 eta 0:22:03
epoch [20/50] batch [280/428] time 0.096 (0.102) data 0.000 (0.002) loss 1.9990 (1.9589) teacher_loss 0.9175 (0.8737) loss_zs_kd 1.6097 (1.7073) loss_oracle 1.0692 (1.0325) kd_loss 1.0938 (1.1380) acc 62.5000 (68.9286) lr 1.4258e-03 eta 0:22:03
epoch [20/50] batch [300/428] time 0.113 (0.102) data 0.000 (0.002) loss 2.0383 (1.9565) teacher_loss 0.9993 (0.8733) loss_zs_kd 2.1200 (1.7188) loss_oracle 1.0293 (1.0325) kd_loss 1.0487 (1.1338) acc 62.5000 (69.0417) lr 1.4258e-03 eta 0:22:05
epoch [20/50] batch [320/428] time 0.104 (0.102) data 0.000 (0.002) loss 1.7810 (1.9543) teacher_loss 0.7913 (0.8753) loss_zs_kd 1.5857 (1.7167) loss_oracle 0.9728 (1.0305) kd_loss 1.0067 (1.1275) acc 78.1250 (68.9941) lr 1.4258e-03 eta 0:22:05
epoch [20/50] batch [340/428] time 0.092 (0.103) data 0.000 (0.002) loss 1.9790 (1.9537) teacher_loss 0.9157 (0.8772) loss_zs_kd 1.7178 (1.7127) loss_oracle 1.0413 (1.0289) kd_loss 1.0853 (1.1241) acc 78.1250 (68.9798) lr 1.4258e-03 eta 0:22:05
epoch [20/50] batch [360/428] time 0.096 (0.103) data 0.000 (0.002) loss 2.0323 (1.9533) teacher_loss 1.0597 (0.8796) loss_zs_kd 1.6498 (1.7114) loss_oracle 0.9901 (1.0269) kd_loss 0.9552 (1.1205) acc 56.2500 (68.8889) lr 1.4258e-03 eta 0:22:04
epoch [20/50] batch [380/428] time 0.114 (0.103) data 0.000 (0.002) loss 1.8810 (1.9534) teacher_loss 0.9079 (0.8841) loss_zs_kd 1.6727 (1.7217) loss_oracle 0.9653 (1.0237) kd_loss 0.9810 (1.1149) acc 65.6250 (68.5691) lr 1.4258e-03 eta 0:22:03
epoch [20/50] batch [400/428] time 0.108 (0.103) data 0.000 (0.002) loss 1.9626 (1.9532) teacher_loss 1.0451 (0.8898) loss_zs_kd 1.6294 (1.7230) loss_oracle 0.9564 (1.0197) kd_loss 0.8786 (1.1070) acc 59.3750 (68.4141) lr 1.4258e-03 eta 0:22:02
epoch [20/50] batch [420/428] time 0.097 (0.103) data 0.000 (0.002) loss 1.8009 (1.9489) teacher_loss 0.8316 (0.8898) loss_zs_kd 1.6304 (1.7225) loss_oracle 0.9657 (1.0172) kd_loss 0.9729 (1.1010) acc 71.8750 (68.4970) lr 1.4258e-03 eta 0:22:01
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,729
* accuracy: 63.5%
* error: 36.5%
* macro_f1: 50.1%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,916
* accuracy: 40.4%
* error: 59.6%
* macro_f1: 29.7%
******* Domain 1 best val acc:      63.5%, epoch: 20 *******
******* Domain 1 best val test acc: 40.4%, epoch: 20 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [21/50] batch [20/428] time 0.121 (0.129) data 0.000 (0.032) loss 1.8849 (1.9357) teacher_loss 0.9435 (0.9584) loss_zs_kd 1.8512 (1.7418) loss_oracle 0.9459 (0.9574) kd_loss 0.9369 (0.9972) acc 65.6250 (67.5000) lr 1.3681e-03 eta 0:27:31
epoch [21/50] batch [40/428] time 0.102 (0.117) data 0.000 (0.016) loss 1.5131 (1.8537) teacher_loss 0.5553 (0.8872) loss_zs_kd 2.1150 (1.7599) loss_oracle 0.9468 (0.9457) kd_loss 0.9687 (0.9875) acc 84.3750 (70.1562) lr 1.3681e-03 eta 0:25:00
epoch [21/50] batch [60/428] time 0.108 (0.113) data 0.000 (0.011) loss 1.8971 (1.8255) teacher_loss 0.9099 (0.8620) loss_zs_kd 1.8097 (1.7638) loss_oracle 0.9830 (0.9450) kd_loss 0.9915 (0.9819) acc 65.6250 (70.8854) lr 1.3681e-03 eta 0:24:03
epoch [21/50] batch [80/428] time 0.108 (0.111) data 0.000 (0.008) loss 1.6218 (1.8090) teacher_loss 0.6025 (0.8450) loss_zs_kd 1.7903 (1.8240) loss_oracle 0.9573 (0.9424) kd_loss 1.0813 (0.9856) acc 75.0000 (71.6016) lr 1.3681e-03 eta 0:23:41
epoch [21/50] batch [100/428] time 0.100 (0.111) data 0.000 (0.007) loss 1.8892 (1.8072) teacher_loss 0.8608 (0.8352) loss_zs_kd 1.7462 (1.8153) loss_oracle 0.9603 (0.9454) kd_loss 1.0964 (0.9985) acc 71.8750 (72.1250) lr 1.3681e-03 eta 0:23:27
epoch [21/50] batch [120/428] time 0.113 (0.110) data 0.000 (0.006) loss 1.8243 (1.8113) teacher_loss 0.7859 (0.8315) loss_zs_kd 2.0313 (1.7963) loss_oracle 0.9892 (0.9515) kd_loss 1.0875 (1.0081) acc 62.5000 (72.1094) lr 1.3681e-03 eta 0:23:13
epoch [21/50] batch [140/428] time 0.105 (0.109) data 0.000 (0.005) loss 1.5587 (1.8087) teacher_loss 0.5709 (0.8239) loss_zs_kd 1.4690 (1.7795) loss_oracle 0.9192 (0.9530) kd_loss 1.0562 (1.0166) acc 84.3750 (72.5223) lr 1.3681e-03 eta 0:23:04
epoch [21/50] batch [160/428] time 0.109 (0.109) data 0.000 (0.004) loss 1.3971 (1.8100) teacher_loss 0.3987 (0.8189) loss_zs_kd 1.8607 (1.7671) loss_oracle 0.9590 (0.9560) kd_loss 1.0379 (1.0262) acc 90.6250 (72.6367) lr 1.3681e-03 eta 0:22:57
epoch [21/50] batch [180/428] time 0.105 (0.108) data 0.000 (0.004) loss 1.5365 (1.8106) teacher_loss 0.5360 (0.8148) loss_zs_kd 2.1272 (1.7764) loss_oracle 0.9549 (0.9576) kd_loss 1.0460 (1.0340) acc 84.3750 (72.6562) lr 1.3681e-03 eta 0:22:49
epoch [21/50] batch [200/428] time 0.092 (0.108) data 0.000 (0.003) loss 1.6125 (1.8053) teacher_loss 0.5050 (0.8032) loss_zs_kd 1.6846 (1.7710) loss_oracle 1.1053 (0.9635) kd_loss 1.1098 (1.0407) acc 78.1250 (72.8594) lr 1.3681e-03 eta 0:22:42
epoch [21/50] batch [220/428] time 0.104 (0.107) data 0.000 (0.003) loss 1.7167 (1.8039) teacher_loss 0.6744 (0.7974) loss_zs_kd 1.2221 (1.7578) loss_oracle 1.0123 (0.9692) kd_loss 1.0722 (1.0439) acc 75.0000 (73.0540) lr 1.3681e-03 eta 0:22:35
epoch [21/50] batch [240/428] time 0.100 (0.108) data 0.000 (0.003) loss 1.6650 (1.8055) teacher_loss 0.5977 (0.7962) loss_zs_kd 1.7805 (1.7587) loss_oracle 1.0415 (0.9722) kd_loss 1.0932 (1.0464) acc 81.2500 (73.0469) lr 1.3681e-03 eta 0:22:36
epoch [21/50] batch [260/428] time 0.103 (0.108) data 0.000 (0.003) loss 1.4894 (1.8035) teacher_loss 0.4233 (0.7909) loss_zs_kd 1.6758 (1.7617) loss_oracle 0.9952 (0.9743) kd_loss 1.1369 (1.0510) acc 87.5000 (73.3413) lr 1.3681e-03 eta 0:22:32
epoch [21/50] batch [280/428] time 0.101 (0.107) data 0.000 (0.003) loss 1.9443 (1.8089) teacher_loss 0.9022 (0.7942) loss_zs_kd 1.8200 (1.7597) loss_oracle 0.9977 (0.9763) kd_loss 1.0865 (1.0532) acc 65.6250 (73.1362) lr 1.3681e-03 eta 0:22:26
epoch [21/50] batch [300/428] time 0.106 (0.107) data 0.000 (0.002) loss 1.8532 (1.8100) teacher_loss 0.8269 (0.7934) loss_zs_kd 1.6719 (1.7584) loss_oracle 1.0389 (0.9785) kd_loss 1.0136 (1.0547) acc 65.6250 (73.1458) lr 1.3681e-03 eta 0:22:21
epoch [21/50] batch [320/428] time 0.103 (0.107) data 0.000 (0.002) loss 1.7532 (1.8104) teacher_loss 0.7309 (0.7940) loss_zs_kd 1.8273 (1.7597) loss_oracle 0.9571 (0.9781) kd_loss 1.0874 (1.0547) acc 75.0000 (73.0762) lr 1.3681e-03 eta 0:22:15
epoch [21/50] batch [340/428] time 0.107 (0.106) data 0.000 (0.002) loss 2.0555 (1.8182) teacher_loss 0.9923 (0.8010) loss_zs_kd 1.7199 (1.7591) loss_oracle 0.9602 (0.9791) kd_loss 1.1661 (1.0553) acc 71.8750 (72.7390) lr 1.3681e-03 eta 0:22:10
epoch [21/50] batch [360/428] time 0.099 (0.106) data 0.000 (0.002) loss 2.1743 (1.8303) teacher_loss 1.1507 (0.8111) loss_zs_kd 1.2737 (1.7546) loss_oracle 1.0013 (0.9809) kd_loss 1.0458 (1.0574) acc 56.2500 (72.2569) lr 1.3681e-03 eta 0:22:05
epoch [21/50] batch [380/428] time 0.099 (0.106) data 0.000 (0.002) loss 2.0961 (1.8447) teacher_loss 1.0134 (0.8221) loss_zs_kd 1.8477 (1.7503) loss_oracle 0.9990 (0.9834) kd_loss 1.1664 (1.0618) acc 65.6250 (71.8586) lr 1.3681e-03 eta 0:21:59
epoch [21/50] batch [400/428] time 0.105 (0.106) data 0.000 (0.002) loss 2.1119 (1.8554) teacher_loss 1.0063 (0.8291) loss_zs_kd 1.2363 (1.7449) loss_oracle 1.0605 (0.9869) kd_loss 1.1508 (1.0657) acc 68.7500 (71.5938) lr 1.3681e-03 eta 0:21:56
epoch [21/50] batch [420/428] time 0.096 (0.106) data 0.000 (0.002) loss 2.0911 (1.8622) teacher_loss 1.0165 (0.8327) loss_zs_kd 1.5318 (1.7305) loss_oracle 1.0581 (0.9907) kd_loss 1.0910 (1.0684) acc 62.5000 (71.3616) lr 1.3681e-03 eta 0:21:51
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,489
* accuracy: 59.4%
* error: 40.6%
* macro_f1: 47.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,164
* accuracy: 45.6%
* error: 54.4%
* macro_f1: 29.9%
******* Domain 1 best val acc:      63.5%, epoch: 20 *******
******* Domain 1 best val test acc: 40.4%, epoch: 20 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [22/50] batch [20/428] time 0.102 (0.135) data 0.000 (0.031) loss 1.7845 (2.0076) teacher_loss 0.6793 (0.9146) loss_zs_kd 1.4057 (1.5177) loss_oracle 1.0737 (1.0600) kd_loss 1.1367 (1.1261) acc 78.1250 (70.1562) lr 1.3090e-03 eta 0:27:48
epoch [22/50] batch [40/428] time 0.113 (0.119) data 0.000 (0.016) loss 1.9795 (2.0370) teacher_loss 0.8544 (0.9411) loss_zs_kd 1.7883 (1.5349) loss_oracle 1.0713 (1.0652) kd_loss 1.1788 (1.1265) acc 68.7500 (67.8906) lr 1.3090e-03 eta 0:24:33
epoch [22/50] batch [60/428] time 0.092 (0.113) data 0.001 (0.010) loss 1.9210 (2.0615) teacher_loss 0.8589 (0.9657) loss_zs_kd 1.8492 (1.5699) loss_oracle 1.0412 (1.0670) kd_loss 1.0829 (1.1245) acc 71.8750 (66.8229) lr 1.3090e-03 eta 0:23:11
epoch [22/50] batch [80/428] time 0.098 (0.110) data 0.000 (0.008) loss 1.9207 (2.0295) teacher_loss 0.8943 (0.9464) loss_zs_kd 1.8756 (1.5838) loss_oracle 1.0225 (1.0537) kd_loss 1.0304 (1.1124) acc 65.6250 (67.1875) lr 1.3090e-03 eta 0:22:30
epoch [22/50] batch [100/428] time 0.088 (0.107) data 0.000 (0.006) loss 1.6383 (1.9828) teacher_loss 0.5793 (0.9087) loss_zs_kd 2.0732 (1.6337) loss_oracle 1.0315 (1.0472) kd_loss 1.0866 (1.1008) acc 78.1250 (68.6562) lr 1.3090e-03 eta 0:21:55
epoch [22/50] batch [120/428] time 0.113 (0.105) data 0.000 (0.005) loss 1.7733 (1.9685) teacher_loss 0.6993 (0.8999) loss_zs_kd 1.6870 (1.6775) loss_oracle 1.0524 (1.0421) kd_loss 1.0956 (1.0950) acc 75.0000 (68.7500) lr 1.3090e-03 eta 0:21:33
epoch [22/50] batch [140/428] time 0.105 (0.105) data 0.000 (0.005) loss 1.7342 (1.9414) teacher_loss 0.6703 (0.8745) loss_zs_kd 1.8754 (1.7054) loss_oracle 1.0250 (1.0415) kd_loss 1.1027 (1.0922) acc 84.3750 (69.5982) lr 1.3090e-03 eta 0:21:27
epoch [22/50] batch [160/428] time 0.096 (0.105) data 0.000 (0.004) loss 1.5798 (1.9155) teacher_loss 0.5723 (0.8518) loss_zs_kd 2.0270 (1.7285) loss_oracle 1.0177 (1.0404) kd_loss 0.9971 (1.0870) acc 87.5000 (70.7227) lr 1.3090e-03 eta 0:21:22
epoch [22/50] batch [180/428] time 0.107 (0.104) data 0.000 (0.004) loss 2.0089 (1.8997) teacher_loss 1.0088 (0.8399) loss_zs_kd 2.4822 (1.7659) loss_oracle 1.0048 (1.0370) kd_loss 0.9952 (1.0826) acc 65.6250 (71.2326) lr 1.3090e-03 eta 0:21:18
epoch [22/50] batch [200/428] time 0.107 (0.104) data 0.000 (0.003) loss 1.7749 (1.8882) teacher_loss 0.7611 (0.8344) loss_zs_kd 2.2894 (1.7867) loss_oracle 0.9678 (1.0325) kd_loss 1.0599 (1.0752) acc 65.6250 (71.3750) lr 1.3090e-03 eta 0:21:15
epoch [22/50] batch [220/428] time 0.100 (0.104) data 0.000 (0.003) loss 2.0446 (1.8786) teacher_loss 1.0362 (0.8292) loss_zs_kd 1.6250 (1.8029) loss_oracle 0.9528 (1.0269) kd_loss 1.0640 (1.0720) acc 56.2500 (71.4631) lr 1.3090e-03 eta 0:21:13
epoch [22/50] batch [240/428] time 0.109 (0.104) data 0.000 (0.003) loss 1.9023 (1.8698) teacher_loss 0.8575 (0.8218) loss_zs_kd 1.7933 (1.8088) loss_oracle 1.0355 (1.0245) kd_loss 1.0541 (1.0713) acc 62.5000 (71.5625) lr 1.3090e-03 eta 0:21:08
epoch [22/50] batch [260/428] time 0.112 (0.104) data 0.000 (0.003) loss 1.7836 (1.8662) teacher_loss 0.7632 (0.8190) loss_zs_kd 1.6216 (1.8079) loss_oracle 0.9586 (1.0232) kd_loss 1.0823 (1.0712) acc 75.0000 (71.5264) lr 1.3090e-03 eta 0:21:07
epoch [22/50] batch [280/428] time 0.117 (0.105) data 0.000 (0.002) loss 2.0375 (1.8720) teacher_loss 0.9769 (0.8255) loss_zs_kd 2.0019 (1.8042) loss_oracle 1.0239 (1.0211) kd_loss 1.0973 (1.0719) acc 59.3750 (71.3616) lr 1.3090e-03 eta 0:21:08
epoch [22/50] batch [300/428] time 0.097 (0.105) data 0.000 (0.002) loss 1.8613 (1.8754) teacher_loss 0.8048 (0.8288) loss_zs_kd 2.0424 (1.7976) loss_oracle 1.0099 (1.0214) kd_loss 1.1031 (1.0718) acc 75.0000 (71.3229) lr 1.3090e-03 eta 0:21:06
epoch [22/50] batch [320/428] time 0.095 (0.105) data 0.000 (0.002) loss 1.8304 (1.8745) teacher_loss 0.7681 (0.8277) loss_zs_kd 1.8398 (1.7988) loss_oracle 1.0172 (1.0215) kd_loss 1.1075 (1.0721) acc 65.6250 (71.4258) lr 1.3090e-03 eta 0:21:03
epoch [22/50] batch [340/428] time 0.109 (0.104) data 0.000 (0.002) loss 1.7985 (1.8791) teacher_loss 0.8079 (0.8327) loss_zs_kd 1.8092 (1.7924) loss_oracle 0.9593 (1.0208) kd_loss 1.0218 (1.0720) acc 71.8750 (71.2132) lr 1.3090e-03 eta 0:21:00
epoch [22/50] batch [360/428] time 0.112 (0.104) data 0.000 (0.002) loss 1.7791 (1.8792) teacher_loss 0.7534 (0.8344) loss_zs_kd 1.9929 (1.7870) loss_oracle 1.0374 (1.0197) kd_loss 1.0139 (1.0699) acc 68.7500 (71.0938) lr 1.3090e-03 eta 0:20:57
epoch [22/50] batch [380/428] time 0.092 (0.104) data 0.000 (0.002) loss 1.7369 (1.8766) teacher_loss 0.7263 (0.8332) loss_zs_kd 1.6400 (1.7852) loss_oracle 0.9844 (1.0181) kd_loss 1.0368 (1.0687) acc 71.8750 (70.9704) lr 1.3090e-03 eta 0:20:54
epoch [22/50] batch [400/428] time 0.103 (0.104) data 0.000 (0.002) loss 1.8184 (1.8772) teacher_loss 0.7960 (0.8346) loss_zs_kd 1.9566 (1.7869) loss_oracle 0.9453 (1.0173) kd_loss 1.0996 (1.0679) acc 68.7500 (70.8750) lr 1.3090e-03 eta 0:20:52
epoch [22/50] batch [420/428] time 0.095 (0.104) data 0.000 (0.002) loss 1.7218 (1.8740) teacher_loss 0.7062 (0.8333) loss_zs_kd 2.2742 (1.7908) loss_oracle 0.9913 (1.0155) kd_loss 1.0398 (1.0658) acc 78.1250 (71.0268) lr 1.3090e-03 eta 0:20:48
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,644
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 47.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,068
* accuracy: 43.6%
* error: 56.4%
* macro_f1: 30.7%
******* Domain 1 best val acc:      63.5%, epoch: 20 *******
******* Domain 1 best val test acc: 40.4%, epoch: 20 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [23/50] batch [20/428] time 0.093 (0.120) data 0.000 (0.027) loss 1.6485 (1.7811) teacher_loss 0.6272 (0.7687) loss_zs_kd 1.9200 (1.8011) loss_oracle 1.0204 (0.9873) kd_loss 1.0222 (1.0374) acc 71.8750 (76.2500) lr 1.2487e-03 eta 0:23:56
epoch [23/50] batch [40/428] time 0.104 (0.109) data 0.000 (0.013) loss 1.7278 (1.7529) teacher_loss 0.6856 (0.7402) loss_zs_kd 1.9012 (1.8468) loss_oracle 1.0234 (0.9877) kd_loss 1.0610 (1.0376) acc 78.1250 (76.6406) lr 1.2487e-03 eta 0:21:36
epoch [23/50] batch [60/428] time 0.099 (0.106) data 0.001 (0.009) loss 1.6564 (1.7634) teacher_loss 0.6779 (0.7507) loss_zs_kd 1.9763 (1.9256) loss_oracle 0.9951 (0.9885) kd_loss 0.9620 (1.0368) acc 81.2500 (75.9375) lr 1.2487e-03 eta 0:21:09
epoch [23/50] batch [80/428] time 0.096 (0.106) data 0.000 (0.007) loss 2.0163 (1.7970) teacher_loss 0.9479 (0.7858) loss_zs_kd 1.8172 (1.9685) loss_oracle 1.0360 (0.9885) kd_loss 1.1009 (1.0339) acc 65.6250 (73.9062) lr 1.2487e-03 eta 0:20:56
epoch [23/50] batch [100/428] time 0.103 (0.105) data 0.000 (0.006) loss 1.8196 (1.8066) teacher_loss 0.8097 (0.7943) loss_zs_kd 1.9387 (1.9774) loss_oracle 1.0118 (0.9906) kd_loss 1.0082 (1.0341) acc 78.1250 (73.7188) lr 1.2487e-03 eta 0:20:46
epoch [23/50] batch [120/428] time 0.110 (0.105) data 0.000 (0.005) loss 1.9306 (1.8212) teacher_loss 0.8922 (0.8085) loss_zs_kd 1.6776 (1.9614) loss_oracle 1.0059 (0.9876) kd_loss 1.0710 (1.0379) acc 68.7500 (73.0990) lr 1.2487e-03 eta 0:20:43
epoch [23/50] batch [140/428] time 0.120 (0.104) data 0.000 (0.004) loss 2.2583 (1.8265) teacher_loss 1.2576 (0.8138) loss_zs_kd 1.8222 (1.9442) loss_oracle 1.0193 (0.9873) kd_loss 0.9819 (1.0381) acc 46.8750 (72.4554) lr 1.2487e-03 eta 0:20:34
epoch [23/50] batch [160/428] time 0.106 (0.104) data 0.000 (0.004) loss 1.8480 (1.8369) teacher_loss 0.8662 (0.8235) loss_zs_kd 1.5170 (1.9269) loss_oracle 0.9851 (0.9885) kd_loss 0.9784 (1.0383) acc 71.8750 (72.0508) lr 1.2487e-03 eta 0:20:33
epoch [23/50] batch [180/428] time 0.097 (0.104) data 0.000 (0.003) loss 1.7630 (1.8474) teacher_loss 0.7112 (0.8309) loss_zs_kd 1.9616 (1.9073) loss_oracle 0.9794 (0.9885) kd_loss 1.1242 (1.0445) acc 87.5000 (71.5278) lr 1.2487e-03 eta 0:20:31
epoch [23/50] batch [200/428] time 0.108 (0.104) data 0.000 (0.003) loss 1.8200 (1.8604) teacher_loss 0.7615 (0.8397) loss_zs_kd 1.6632 (1.8896) loss_oracle 1.0292 (0.9916) kd_loss 1.0878 (1.0497) acc 78.1250 (71.1250) lr 1.2487e-03 eta 0:20:28
epoch [23/50] batch [220/428] time 0.103 (0.104) data 0.000 (0.003) loss 2.0813 (1.8696) teacher_loss 1.0485 (0.8470) loss_zs_kd 1.6861 (1.8685) loss_oracle 1.0540 (0.9935) kd_loss 1.0116 (1.0516) acc 56.2500 (70.8097) lr 1.2487e-03 eta 0:20:27
epoch [23/50] batch [240/428] time 0.099 (0.104) data 0.000 (0.002) loss 2.0462 (1.8688) teacher_loss 0.9906 (0.8458) loss_zs_kd 1.7347 (1.8570) loss_oracle 1.0425 (0.9949) kd_loss 1.0686 (1.0510) acc 65.6250 (70.8854) lr 1.2487e-03 eta 0:20:26
epoch [23/50] batch [260/428] time 0.114 (0.104) data 0.000 (0.002) loss 1.8582 (1.8658) teacher_loss 0.8804 (0.8429) loss_zs_kd 2.0119 (1.8494) loss_oracle 0.9801 (0.9949) kd_loss 0.9755 (1.0509) acc 71.8750 (70.9014) lr 1.2487e-03 eta 0:20:24
epoch [23/50] batch [280/428] time 0.110 (0.104) data 0.000 (0.002) loss 1.4237 (1.8591) teacher_loss 0.4154 (0.8365) loss_zs_kd 1.6435 (1.8564) loss_oracle 1.0314 (0.9955) kd_loss 0.9850 (1.0497) acc 93.7500 (71.2946) lr 1.2487e-03 eta 0:20:21
epoch [23/50] batch [300/428] time 0.127 (0.104) data 0.000 (0.002) loss 1.5226 (1.8512) teacher_loss 0.5048 (0.8291) loss_zs_kd 1.9540 (1.8556) loss_oracle 1.0057 (0.9952) kd_loss 1.0299 (1.0491) acc 81.2500 (71.5938) lr 1.2487e-03 eta 0:20:20
epoch [23/50] batch [320/428] time 0.111 (0.105) data 0.000 (0.002) loss 1.8516 (1.8494) teacher_loss 0.8465 (0.8278) loss_zs_kd 2.0060 (1.8610) loss_oracle 0.9594 (0.9936) kd_loss 1.0509 (1.0494) acc 75.0000 (71.6406) lr 1.2487e-03 eta 0:20:20
epoch [23/50] batch [340/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.7579 (1.8434) teacher_loss 0.7139 (0.8217) loss_zs_kd 1.5225 (1.8560) loss_oracle 1.0257 (0.9934) kd_loss 1.0621 (1.0499) acc 84.3750 (71.9577) lr 1.2487e-03 eta 0:20:19
epoch [23/50] batch [360/428] time 0.103 (0.105) data 0.000 (0.002) loss 1.9782 (1.8398) teacher_loss 0.9793 (0.8187) loss_zs_kd 1.4890 (1.8510) loss_oracle 1.0184 (0.9930) kd_loss 0.9794 (1.0492) acc 65.6250 (72.1094) lr 1.2487e-03 eta 0:20:16
epoch [23/50] batch [380/428] time 0.104 (0.105) data 0.000 (0.002) loss 1.8257 (1.8369) teacher_loss 0.7611 (0.8140) loss_zs_kd 1.2977 (1.8392) loss_oracle 1.0542 (0.9951) kd_loss 1.0749 (1.0508) acc 78.1250 (72.2862) lr 1.2487e-03 eta 0:20:14
epoch [23/50] batch [400/428] time 0.109 (0.105) data 0.000 (0.002) loss 1.5394 (1.8356) teacher_loss 0.4705 (0.8118) loss_zs_kd 1.7184 (1.8365) loss_oracle 1.0506 (0.9962) kd_loss 1.0871 (1.0514) acc 87.5000 (72.3906) lr 1.2487e-03 eta 0:20:12
epoch [23/50] batch [420/428] time 0.104 (0.105) data 0.000 (0.002) loss 1.7372 (1.8345) teacher_loss 0.7148 (0.8101) loss_zs_kd 1.6962 (1.8332) loss_oracle 1.0664 (0.9976) kd_loss 0.9784 (1.0514) acc 71.8750 (72.3512) lr 1.2487e-03 eta 0:20:09
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,651
* accuracy: 62.1%
* error: 37.9%
* macro_f1: 50.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,052
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 29.7%
******* Domain 1 best val acc:      63.5%, epoch: 20 *******
******* Domain 1 best val test acc: 40.4%, epoch: 20 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [24/50] batch [20/428] time 0.107 (0.122) data 0.001 (0.026) loss 1.5514 (1.8116) teacher_loss 0.5138 (0.7829) loss_zs_kd 2.0650 (1.8247) loss_oracle 1.0064 (1.0137) kd_loss 1.0688 (1.0437) acc 87.5000 (74.2188) lr 1.1874e-03 eta 0:23:26
epoch [24/50] batch [40/428] time 0.075 (0.105) data 0.001 (0.013) loss 1.8352 (1.7846) teacher_loss 0.7729 (0.7492) loss_zs_kd 1.7832 (1.8144) loss_oracle 1.0607 (1.0164) kd_loss 1.0639 (1.0545) acc 68.7500 (75.2344) lr 1.1874e-03 eta 0:20:05
epoch [24/50] batch [60/428] time 0.095 (0.097) data 0.000 (0.009) loss 2.0688 (1.8004) teacher_loss 1.0582 (0.7632) loss_zs_kd 1.8263 (1.7964) loss_oracle 1.0174 (1.0191) kd_loss 1.0039 (1.0554) acc 56.2500 (74.3229) lr 1.1874e-03 eta 0:18:37
epoch [24/50] batch [80/428] time 0.105 (0.095) data 0.000 (0.007) loss 1.8596 (1.8179) teacher_loss 0.7913 (0.7780) loss_zs_kd 2.0852 (1.8046) loss_oracle 1.0687 (1.0233) kd_loss 1.0679 (1.0564) acc 68.7500 (73.4766) lr 1.1874e-03 eta 0:18:09
epoch [24/50] batch [100/428] time 0.103 (0.097) data 0.000 (0.005) loss 1.6844 (1.8206) teacher_loss 0.6099 (0.7782) loss_zs_kd 1.5516 (1.8032) loss_oracle 1.0782 (1.0278) kd_loss 1.0709 (1.0569) acc 84.3750 (73.0625) lr 1.1874e-03 eta 0:18:31
epoch [24/50] batch [120/428] time 0.098 (0.098) data 0.000 (0.005) loss 1.9395 (1.8307) teacher_loss 0.8647 (0.7869) loss_zs_kd 1.4846 (1.7919) loss_oracle 1.0257 (1.0308) kd_loss 1.1240 (1.0567) acc 71.8750 (72.6042) lr 1.1874e-03 eta 0:18:43
epoch [24/50] batch [140/428] time 0.106 (0.099) data 0.000 (0.004) loss 2.0633 (1.8446) teacher_loss 1.0083 (0.8023) loss_zs_kd 1.8547 (1.7917) loss_oracle 0.9685 (1.0286) kd_loss 1.1416 (1.0559) acc 68.7500 (72.0536) lr 1.1874e-03 eta 0:18:50
epoch [24/50] batch [160/428] time 0.098 (0.100) data 0.000 (0.003) loss 1.4802 (1.8351) teacher_loss 0.4202 (0.7931) loss_zs_kd 1.7907 (1.7705) loss_oracle 1.0623 (1.0282) kd_loss 1.0579 (1.0559) acc 90.6250 (72.5977) lr 1.1874e-03 eta 0:18:56
epoch [24/50] batch [180/428] time 0.116 (0.100) data 0.000 (0.003) loss 1.6803 (1.8269) teacher_loss 0.6676 (0.7853) loss_zs_kd 2.0392 (1.7813) loss_oracle 0.9978 (1.0273) kd_loss 1.0275 (1.0561) acc 71.8750 (72.7604) lr 1.1874e-03 eta 0:19:01
epoch [24/50] batch [200/428] time 0.111 (0.101) data 0.000 (0.003) loss 1.6263 (1.8182) teacher_loss 0.5817 (0.7783) loss_zs_kd 2.1009 (1.7990) loss_oracle 1.0365 (1.0251) kd_loss 1.0528 (1.0549) acc 78.1250 (73.0156) lr 1.1874e-03 eta 0:19:04
epoch [24/50] batch [220/428] time 0.097 (0.101) data 0.000 (0.003) loss 1.9048 (1.8226) teacher_loss 0.9320 (0.7849) loss_zs_kd 1.5075 (1.8071) loss_oracle 0.9488 (1.0230) kd_loss 0.9969 (1.0525) acc 68.7500 (72.7557) lr 1.1874e-03 eta 0:19:05
epoch [24/50] batch [240/428] time 0.084 (0.100) data 0.000 (0.002) loss 2.0016 (1.8303) teacher_loss 1.0365 (0.7961) loss_zs_kd 1.6018 (1.8034) loss_oracle 0.9399 (1.0194) kd_loss 0.9904 (1.0489) acc 71.8750 (72.4219) lr 1.1874e-03 eta 0:18:51
epoch [24/50] batch [260/428] time 0.105 (0.099) data 0.000 (0.002) loss 1.7872 (1.8295) teacher_loss 0.7633 (0.7999) loss_zs_kd 1.7545 (1.8089) loss_oracle 0.9736 (1.0155) kd_loss 1.0743 (1.0439) acc 71.8750 (72.3678) lr 1.1874e-03 eta 0:18:43
epoch [24/50] batch [280/428] time 0.079 (0.099) data 0.000 (0.002) loss 1.7395 (1.8308) teacher_loss 0.7687 (0.8035) loss_zs_kd 1.7506 (1.8115) loss_oracle 0.9487 (1.0130) kd_loss 0.9928 (1.0417) acc 68.7500 (72.2210) lr 1.1874e-03 eta 0:18:37
epoch [24/50] batch [300/428] time 0.092 (0.098) data 0.000 (0.002) loss 1.5917 (1.8294) teacher_loss 0.5421 (0.8027) loss_zs_kd 1.6623 (1.8148) loss_oracle 1.0121 (1.0122) kd_loss 1.0871 (1.0413) acc 84.3750 (72.2396) lr 1.1874e-03 eta 0:18:27
epoch [24/50] batch [320/428] time 0.090 (0.098) data 0.000 (0.002) loss 1.7780 (1.8290) teacher_loss 0.7483 (0.8019) loss_zs_kd 1.6188 (1.8196) loss_oracle 1.0063 (1.0119) kd_loss 1.0531 (1.0424) acc 84.3750 (72.2852) lr 1.1874e-03 eta 0:18:25
epoch [24/50] batch [340/428] time 0.109 (0.099) data 0.000 (0.002) loss 1.5409 (1.8267) teacher_loss 0.5378 (0.7993) loss_zs_kd 1.5839 (1.8160) loss_oracle 0.9856 (1.0123) kd_loss 1.0206 (1.0423) acc 84.3750 (72.3989) lr 1.1874e-03 eta 0:18:27
epoch [24/50] batch [360/428] time 0.113 (0.099) data 0.000 (0.002) loss 1.5920 (1.8276) teacher_loss 0.5851 (0.8011) loss_zs_kd 1.4677 (1.8088) loss_oracle 0.9723 (1.0110) kd_loss 1.0416 (1.0420) acc 81.2500 (72.3438) lr 1.1874e-03 eta 0:18:31
epoch [24/50] batch [380/428] time 0.104 (0.100) data 0.000 (0.002) loss 1.5625 (1.8216) teacher_loss 0.5422 (0.7962) loss_zs_kd 1.8187 (1.8124) loss_oracle 0.9740 (1.0097) kd_loss 1.0665 (1.0412) acc 90.6250 (72.6151) lr 1.1874e-03 eta 0:18:32
epoch [24/50] batch [400/428] time 0.109 (0.100) data 0.000 (0.002) loss 1.7423 (1.8227) teacher_loss 0.7906 (0.8002) loss_zs_kd 1.9474 (1.8173) loss_oracle 0.9462 (1.0079) kd_loss 0.9573 (1.0371) acc 75.0000 (72.5703) lr 1.1874e-03 eta 0:18:32
epoch [24/50] batch [420/428] time 0.092 (0.099) data 0.000 (0.001) loss 1.7190 (1.8219) teacher_loss 0.7531 (0.8018) loss_zs_kd 1.7855 (1.8233) loss_oracle 0.9272 (1.0056) kd_loss 1.0047 (1.0347) acc 75.0000 (72.4702) lr 1.1874e-03 eta 0:18:27
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,717
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 50.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,951
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 30.5%
******* Domain 1 best val acc:      63.5%, epoch: 20 *******
******* Domain 1 best val test acc: 40.4%, epoch: 20 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [25/50] batch [20/428] time 0.077 (0.136) data 0.000 (0.028) loss 2.0272 (1.9071) teacher_loss 0.9789 (0.9070) loss_zs_kd 2.3487 (1.8563) loss_oracle 1.0407 (0.9909) kd_loss 1.0558 (1.0094) acc 56.2500 (67.1875) lr 1.1253e-03 eta 0:25:09
epoch [25/50] batch [40/428] time 0.103 (0.117) data 0.000 (0.014) loss 1.8717 (1.8646) teacher_loss 0.9070 (0.8591) loss_zs_kd 1.9824 (1.9197) loss_oracle 0.9802 (0.9895) kd_loss 0.9493 (1.0215) acc 68.7500 (70.1562) lr 1.1253e-03 eta 0:21:42
epoch [25/50] batch [60/428] time 0.099 (0.113) data 0.000 (0.010) loss 1.8940 (1.8820) teacher_loss 0.8875 (0.8797) loss_zs_kd 1.4509 (1.8619) loss_oracle 0.9427 (0.9829) kd_loss 1.0703 (1.0216) acc 65.6250 (69.4792) lr 1.1253e-03 eta 0:20:49
epoch [25/50] batch [80/428] time 0.107 (0.112) data 0.000 (0.007) loss 1.7273 (1.8761) teacher_loss 0.7364 (0.8748) loss_zs_kd 1.8999 (1.8349) loss_oracle 0.9940 (0.9822) kd_loss 0.9879 (1.0203) acc 84.3750 (69.4531) lr 1.1253e-03 eta 0:20:39
epoch [25/50] batch [100/428] time 0.110 (0.111) data 0.000 (0.006) loss 2.0464 (1.8861) teacher_loss 1.0115 (0.8892) loss_zs_kd 1.9191 (1.8321) loss_oracle 0.9995 (0.9798) kd_loss 1.0703 (1.0140) acc 65.6250 (68.4375) lr 1.1253e-03 eta 0:20:21
epoch [25/50] batch [120/428] time 0.094 (0.108) data 0.000 (0.005) loss 2.3263 (1.9011) teacher_loss 1.2881 (0.8989) loss_zs_kd 1.6754 (1.8140) loss_oracle 1.0038 (0.9800) kd_loss 1.0725 (1.0245) acc 50.0000 (68.3594) lr 1.1253e-03 eta 0:19:48
epoch [25/50] batch [140/428] time 0.069 (0.105) data 0.000 (0.004) loss 2.4301 (1.9110) teacher_loss 1.3685 (0.9023) loss_zs_kd 1.7985 (1.7849) loss_oracle 1.0492 (0.9843) kd_loss 1.0739 (1.0331) acc 56.2500 (68.3259) lr 1.1253e-03 eta 0:19:13
epoch [25/50] batch [160/428] time 0.110 (0.103) data 0.000 (0.004) loss 1.9049 (1.9119) teacher_loss 0.8438 (0.8990) loss_zs_kd 1.5393 (1.7550) loss_oracle 1.0412 (0.9877) kd_loss 1.0810 (1.0381) acc 68.7500 (68.5742) lr 1.1253e-03 eta 0:18:51
epoch [25/50] batch [180/428] time 0.116 (0.103) data 0.000 (0.003) loss 1.8952 (1.9150) teacher_loss 0.8096 (0.8994) loss_zs_kd 1.9073 (1.7226) loss_oracle 1.0556 (0.9902) kd_loss 1.1155 (1.0409) acc 75.0000 (68.6458) lr 1.1253e-03 eta 0:18:50
epoch [25/50] batch [200/428] time 0.107 (0.103) data 0.000 (0.003) loss 2.1647 (1.9216) teacher_loss 1.1595 (0.9058) loss_zs_kd 1.9271 (1.7177) loss_oracle 0.9984 (0.9902) kd_loss 1.0120 (1.0412) acc 56.2500 (68.5312) lr 1.1253e-03 eta 0:18:48
epoch [25/50] batch [220/428] time 0.103 (0.104) data 0.000 (0.003) loss 1.6834 (1.9180) teacher_loss 0.6388 (0.9028) loss_zs_kd 2.0359 (1.7285) loss_oracle 1.0098 (0.9903) kd_loss 1.0794 (1.0400) acc 81.2500 (68.5085) lr 1.1253e-03 eta 0:18:49
epoch [25/50] batch [240/428] time 0.103 (0.104) data 0.000 (0.003) loss 1.6256 (1.9106) teacher_loss 0.6294 (0.8961) loss_zs_kd 1.8315 (1.7395) loss_oracle 0.9623 (0.9893) kd_loss 1.0302 (1.0399) acc 78.1250 (68.7891) lr 1.1253e-03 eta 0:18:47
epoch [25/50] batch [260/428] time 0.104 (0.104) data 0.000 (0.002) loss 1.6034 (1.9039) teacher_loss 0.6114 (0.8913) loss_zs_kd 1.8946 (1.7539) loss_oracle 0.9570 (0.9880) kd_loss 1.0269 (1.0372) acc 81.2500 (69.0385) lr 1.1253e-03 eta 0:18:47
epoch [25/50] batch [280/428] time 0.102 (0.104) data 0.000 (0.002) loss 2.1089 (1.9000) teacher_loss 1.1074 (0.8897) loss_zs_kd 1.6964 (1.7742) loss_oracle 0.9950 (0.9865) kd_loss 1.0081 (1.0342) acc 50.0000 (69.0179) lr 1.1253e-03 eta 0:18:46
epoch [25/50] batch [300/428] time 0.105 (0.104) data 0.000 (0.002) loss 1.6371 (1.8923) teacher_loss 0.7016 (0.8860) loss_zs_kd 2.0056 (1.7917) loss_oracle 0.9133 (0.9838) kd_loss 0.9577 (1.0288) acc 71.8750 (69.0521) lr 1.1253e-03 eta 0:18:43
epoch [25/50] batch [320/428] time 0.100 (0.104) data 0.000 (0.002) loss 1.7654 (1.8911) teacher_loss 0.8105 (0.8877) loss_zs_kd 1.6489 (1.8058) loss_oracle 0.9680 (0.9811) kd_loss 0.9418 (1.0257) acc 75.0000 (69.0430) lr 1.1253e-03 eta 0:18:42
epoch [25/50] batch [340/428] time 0.098 (0.104) data 0.000 (0.002) loss 1.6939 (1.8848) teacher_loss 0.7198 (0.8843) loss_zs_kd 1.9859 (1.8108) loss_oracle 0.9739 (0.9789) kd_loss 0.9741 (1.0221) acc 81.2500 (69.2004) lr 1.1253e-03 eta 0:18:42
epoch [25/50] batch [360/428] time 0.115 (0.104) data 0.000 (0.002) loss 1.8828 (1.8824) teacher_loss 0.9010 (0.8838) loss_zs_kd 1.3983 (1.8160) loss_oracle 0.9760 (0.9781) kd_loss 0.9876 (1.0191) acc 71.8750 (69.1580) lr 1.1253e-03 eta 0:18:40
epoch [25/50] batch [380/428] time 0.113 (0.104) data 0.000 (0.002) loss 1.9582 (1.8776) teacher_loss 1.0241 (0.8801) loss_zs_kd 1.8019 (1.8179) loss_oracle 0.8885 (0.9777) kd_loss 0.9797 (1.0171) acc 62.5000 (69.2681) lr 1.1253e-03 eta 0:18:39
epoch [25/50] batch [400/428] time 0.100 (0.104) data 0.000 (0.002) loss 1.7735 (1.8716) teacher_loss 0.7965 (0.8752) loss_zs_kd 1.9510 (1.8224) loss_oracle 0.9240 (0.9767) kd_loss 1.0299 (1.0161) acc 68.7500 (69.4844) lr 1.1253e-03 eta 0:18:37
epoch [25/50] batch [420/428] time 0.099 (0.104) data 0.000 (0.002) loss 2.0412 (1.8705) teacher_loss 0.9728 (0.8743) loss_zs_kd 1.5669 (1.8230) loss_oracle 1.0058 (0.9760) kd_loss 1.1310 (1.0163) acc 65.6250 (69.5759) lr 1.1253e-03 eta 0:18:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,736
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 51.0%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,145
* accuracy: 45.2%
* error: 54.8%
* macro_f1: 31.6%
******* Domain 1 best val acc:      63.6%, epoch: 25 *******
******* Domain 1 best val test acc: 45.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [26/50] batch [20/428] time 0.088 (0.143) data 0.000 (0.036) loss 1.7879 (1.8006) teacher_loss 0.7000 (0.8006) loss_zs_kd 2.0616 (1.7766) loss_oracle 1.0968 (0.9682) kd_loss 1.0789 (1.0317) acc 71.8750 (72.0312) lr 1.0628e-03 eta 0:25:27
epoch [26/50] batch [40/428] time 0.101 (0.120) data 0.000 (0.018) loss 1.6347 (1.8181) teacher_loss 0.6337 (0.8218) loss_zs_kd 1.9060 (1.8234) loss_oracle 0.9504 (0.9616) kd_loss 1.0516 (1.0310) acc 68.7500 (70.1562) lr 1.0628e-03 eta 0:21:22
epoch [26/50] batch [60/428] time 0.116 (0.115) data 0.000 (0.012) loss 2.1385 (1.8172) teacher_loss 1.1196 (0.8194) loss_zs_kd 1.6279 (1.8343) loss_oracle 0.9988 (0.9651) kd_loss 1.0391 (1.0306) acc 59.3750 (70.5208) lr 1.0628e-03 eta 0:20:21
epoch [26/50] batch [80/428] time 0.094 (0.111) data 0.000 (0.009) loss 1.8329 (1.8166) teacher_loss 0.9083 (0.8199) loss_zs_kd 1.8313 (1.8521) loss_oracle 0.9323 (0.9660) kd_loss 0.9169 (1.0275) acc 62.5000 (70.8984) lr 1.0628e-03 eta 0:19:41
epoch [26/50] batch [100/428] time 0.105 (0.110) data 0.000 (0.007) loss 1.4677 (1.8237) teacher_loss 0.5218 (0.8324) loss_zs_kd 1.8206 (1.8318) loss_oracle 0.9199 (0.9633) kd_loss 0.9719 (1.0192) acc 87.5000 (70.6875) lr 1.0628e-03 eta 0:19:24
epoch [26/50] batch [120/428] time 0.087 (0.110) data 0.000 (0.006) loss 1.6676 (1.8181) teacher_loss 0.6763 (0.8339) loss_zs_kd 1.6451 (1.8240) loss_oracle 0.9929 (0.9583) kd_loss 0.9896 (1.0101) acc 84.3750 (70.7031) lr 1.0628e-03 eta 0:19:26
epoch [26/50] batch [140/428] time 0.111 (0.109) data 0.000 (0.005) loss 1.7986 (1.8189) teacher_loss 0.7960 (0.8406) loss_zs_kd 1.9673 (1.8312) loss_oracle 0.9950 (0.9551) kd_loss 1.0102 (1.0014) acc 75.0000 (70.0000) lr 1.0628e-03 eta 0:19:15
epoch [26/50] batch [160/428] time 0.105 (0.109) data 0.001 (0.005) loss 1.8273 (1.8118) teacher_loss 0.8979 (0.8382) loss_zs_kd 1.9018 (1.8301) loss_oracle 0.9136 (0.9519) kd_loss 0.9452 (0.9953) acc 59.3750 (70.0781) lr 1.0628e-03 eta 0:19:06
epoch [26/50] batch [180/428] time 0.112 (0.108) data 0.000 (0.004) loss 1.8149 (1.8191) teacher_loss 0.8371 (0.8484) loss_zs_kd 1.5659 (1.8242) loss_oracle 0.9265 (0.9504) kd_loss 1.0292 (0.9911) acc 71.8750 (69.5139) lr 1.0628e-03 eta 0:19:00
epoch [26/50] batch [200/428] time 0.107 (0.108) data 0.000 (0.004) loss 2.1476 (1.8283) teacher_loss 1.2226 (0.8574) loss_zs_kd 1.2000 (1.8158) loss_oracle 0.8755 (0.9505) kd_loss 0.9744 (0.9912) acc 43.7500 (69.1562) lr 1.0628e-03 eta 0:18:53
epoch [26/50] batch [220/428] time 0.100 (0.108) data 0.000 (0.004) loss 1.7149 (1.8360) teacher_loss 0.6731 (0.8652) loss_zs_kd 1.7597 (1.8090) loss_oracle 0.9430 (0.9508) kd_loss 1.1406 (0.9909) acc 81.2500 (68.7926) lr 1.0628e-03 eta 0:18:48
epoch [26/50] batch [240/428] time 0.115 (0.107) data 0.000 (0.003) loss 1.7757 (1.8355) teacher_loss 0.8071 (0.8638) loss_zs_kd 2.0764 (1.8010) loss_oracle 0.9756 (0.9513) kd_loss 0.9615 (0.9921) acc 68.7500 (68.8151) lr 1.0628e-03 eta 0:18:44
epoch [26/50] batch [260/428] time 0.107 (0.107) data 0.000 (0.003) loss 2.2367 (1.8407) teacher_loss 1.1767 (0.8661) loss_zs_kd 1.5560 (1.8037) loss_oracle 1.0163 (0.9534) kd_loss 1.1036 (0.9959) acc 62.5000 (68.7500) lr 1.0628e-03 eta 0:18:39
epoch [26/50] batch [280/428] time 0.096 (0.107) data 0.000 (0.003) loss 1.7252 (1.8508) teacher_loss 0.6823 (0.8714) loss_zs_kd 1.8030 (1.7894) loss_oracle 0.9991 (0.9571) kd_loss 1.0866 (1.0018) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:18:34
epoch [26/50] batch [300/428] time 0.099 (0.107) data 0.000 (0.003) loss 1.7076 (1.8540) teacher_loss 0.6452 (0.8695) loss_zs_kd 1.6492 (1.7881) loss_oracle 1.0341 (0.9617) kd_loss 1.0907 (1.0074) acc 78.1250 (68.7917) lr 1.0628e-03 eta 0:18:30
epoch [26/50] batch [320/428] time 0.108 (0.107) data 0.000 (0.003) loss 1.9000 (1.8594) teacher_loss 0.8639 (0.8706) loss_zs_kd 1.5245 (1.7798) loss_oracle 0.9941 (0.9652) kd_loss 1.0780 (1.0124) acc 65.6250 (68.8867) lr 1.0628e-03 eta 0:18:27
epoch [26/50] batch [340/428] time 0.102 (0.107) data 0.000 (0.002) loss 2.0973 (1.8676) teacher_loss 1.0330 (0.8749) loss_zs_kd 1.8181 (1.7708) loss_oracle 1.0375 (0.9698) kd_loss 1.0910 (1.0155) acc 59.3750 (68.8695) lr 1.0628e-03 eta 0:18:23
epoch [26/50] batch [360/428] time 0.097 (0.106) data 0.000 (0.002) loss 1.8498 (1.8714) teacher_loss 0.8071 (0.8758) loss_zs_kd 1.7294 (1.7627) loss_oracle 1.0338 (0.9727) kd_loss 1.0515 (1.0184) acc 62.5000 (68.9149) lr 1.0628e-03 eta 0:18:19
epoch [26/50] batch [380/428] time 0.102 (0.106) data 0.000 (0.002) loss 1.9691 (1.8780) teacher_loss 0.9083 (0.8795) loss_zs_kd 1.4798 (1.7504) loss_oracle 1.0119 (0.9755) kd_loss 1.1097 (1.0216) acc 56.2500 (68.6842) lr 1.0628e-03 eta 0:18:15
epoch [26/50] batch [400/428] time 0.105 (0.106) data 0.000 (0.002) loss 1.8150 (1.8805) teacher_loss 0.7807 (0.8795) loss_zs_kd 1.7153 (1.7419) loss_oracle 0.9864 (0.9776) kd_loss 1.0822 (1.0244) acc 75.0000 (68.7656) lr 1.0628e-03 eta 0:18:12
epoch [26/50] batch [420/428] time 0.098 (0.106) data 0.000 (0.002) loss 1.7799 (1.8849) teacher_loss 0.7665 (0.8818) loss_zs_kd 1.5614 (1.7346) loss_oracle 1.0134 (0.9805) kd_loss 1.0133 (1.0257) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:18:08
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,412
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 48.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,287
* accuracy: 48.2%
* error: 51.8%
* macro_f1: 33.8%
******* Domain 1 best val acc:      63.6%, epoch: 25 *******
******* Domain 1 best val test acc: 45.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [27/50] batch [20/428] time 0.085 (0.134) data 0.000 (0.027) loss 1.9551 (1.9161) teacher_loss 0.9273 (0.8750) loss_zs_kd 1.6834 (1.6093) loss_oracle 1.0070 (1.0304) kd_loss 1.0486 (1.0517) acc 62.5000 (67.8125) lr 1.0000e-03 eta 0:22:53
epoch [27/50] batch [40/428] time 0.106 (0.119) data 0.000 (0.014) loss 2.2213 (1.9069) teacher_loss 1.1140 (0.8682) loss_zs_kd 1.5363 (1.6300) loss_oracle 1.1361 (1.0380) kd_loss 1.0785 (1.0393) acc 56.2500 (69.4531) lr 1.0000e-03 eta 0:20:15
epoch [27/50] batch [60/428] time 0.111 (0.115) data 0.001 (0.009) loss 1.7580 (1.8890) teacher_loss 0.7439 (0.8458) loss_zs_kd 1.5027 (1.6120) loss_oracle 1.0402 (1.0444) kd_loss 0.9881 (1.0420) acc 65.6250 (70.9375) lr 1.0000e-03 eta 0:19:32
epoch [27/50] batch [80/428] time 0.099 (0.112) data 0.000 (0.007) loss 1.8847 (1.8964) teacher_loss 0.8628 (0.8587) loss_zs_kd 1.6074 (1.6460) loss_oracle 1.0248 (1.0380) kd_loss 1.0191 (1.0374) acc 62.5000 (69.9219) lr 1.0000e-03 eta 0:19:03
epoch [27/50] batch [100/428] time 0.103 (0.111) data 0.000 (0.006) loss 1.8527 (1.8794) teacher_loss 0.7660 (0.8443) loss_zs_kd 1.7641 (1.6698) loss_oracle 1.0528 (1.0335) kd_loss 1.1207 (1.0368) acc 71.8750 (70.4375) lr 1.0000e-03 eta 0:18:49
epoch [27/50] batch [120/428] time 0.109 (0.110) data 0.000 (0.005) loss 1.8186 (1.8660) teacher_loss 0.7736 (0.8354) loss_zs_kd 1.9889 (1.6925) loss_oracle 0.9743 (1.0258) kd_loss 1.1157 (1.0353) acc 68.7500 (70.6510) lr 1.0000e-03 eta 0:18:34
epoch [27/50] batch [140/428] time 0.122 (0.110) data 0.000 (0.004) loss 1.7394 (1.8540) teacher_loss 0.6561 (0.8278) loss_zs_kd 1.5092 (1.7237) loss_oracle 1.0554 (1.0187) kd_loss 1.1112 (1.0336) acc 71.8750 (70.8259) lr 1.0000e-03 eta 0:18:32
epoch [27/50] batch [160/428] time 0.103 (0.109) data 0.000 (0.004) loss 1.8690 (1.8455) teacher_loss 0.8306 (0.8227) loss_zs_kd 2.3041 (1.7412) loss_oracle 1.0256 (1.0134) kd_loss 1.0512 (1.0321) acc 75.0000 (70.9766) lr 1.0000e-03 eta 0:18:21
epoch [27/50] batch [180/428] time 0.107 (0.109) data 0.000 (0.003) loss 1.9227 (1.8405) teacher_loss 0.8905 (0.8207) loss_zs_kd 2.0356 (1.7740) loss_oracle 0.9930 (1.0087) kd_loss 1.0713 (1.0310) acc 68.7500 (70.9896) lr 1.0000e-03 eta 0:18:15
epoch [27/50] batch [200/428] time 0.112 (0.108) data 0.000 (0.003) loss 1.7911 (1.8437) teacher_loss 0.7848 (0.8279) loss_zs_kd 1.4858 (1.7845) loss_oracle 0.9763 (1.0043) kd_loss 1.0363 (1.0274) acc 68.7500 (70.7656) lr 1.0000e-03 eta 0:18:09
epoch [27/50] batch [220/428] time 0.101 (0.108) data 0.000 (0.003) loss 1.8786 (1.8477) teacher_loss 0.8928 (0.8354) loss_zs_kd 1.7492 (1.7987) loss_oracle 0.9908 (1.0001) kd_loss 0.9809 (1.0243) acc 75.0000 (70.6818) lr 1.0000e-03 eta 0:18:03
epoch [27/50] batch [240/428] time 0.104 (0.108) data 0.000 (0.003) loss 1.7919 (1.8427) teacher_loss 0.7732 (0.8322) loss_zs_kd 1.8346 (1.8066) loss_oracle 1.0190 (0.9963) kd_loss 1.0184 (1.0247) acc 75.0000 (70.8854) lr 1.0000e-03 eta 0:17:59
epoch [27/50] batch [260/428] time 0.106 (0.107) data 0.000 (0.002) loss 1.6123 (1.8401) teacher_loss 0.6163 (0.8304) loss_zs_kd 2.1520 (1.8148) loss_oracle 0.9880 (0.9935) kd_loss 1.0039 (1.0259) acc 84.3750 (71.0337) lr 1.0000e-03 eta 0:17:55
epoch [27/50] batch [280/428] time 0.111 (0.107) data 0.000 (0.002) loss 1.8304 (1.8374) teacher_loss 0.8083 (0.8287) loss_zs_kd 1.8589 (1.8222) loss_oracle 1.0058 (0.9915) kd_loss 1.0385 (1.0258) acc 65.6250 (71.0268) lr 1.0000e-03 eta 0:17:52
epoch [27/50] batch [300/428] time 0.100 (0.107) data 0.000 (0.002) loss 1.6718 (1.8366) teacher_loss 0.6492 (0.8264) loss_zs_kd 1.9361 (1.8249) loss_oracle 1.0164 (0.9926) kd_loss 1.0289 (1.0279) acc 78.1250 (71.0938) lr 1.0000e-03 eta 0:17:48
epoch [27/50] batch [320/428] time 0.103 (0.107) data 0.000 (0.002) loss 2.0487 (1.8351) teacher_loss 1.0628 (0.8254) loss_zs_kd 2.0580 (1.8309) loss_oracle 0.9321 (0.9914) kd_loss 1.0398 (1.0280) acc 50.0000 (71.1816) lr 1.0000e-03 eta 0:17:44
epoch [27/50] batch [340/428] time 0.104 (0.107) data 0.000 (0.002) loss 1.8852 (1.8371) teacher_loss 0.9794 (0.8289) loss_zs_kd 1.8628 (1.8344) loss_oracle 0.8323 (0.9892) kd_loss 0.9793 (1.0272) acc 62.5000 (71.0662) lr 1.0000e-03 eta 0:17:40
epoch [27/50] batch [360/428] time 0.106 (0.107) data 0.000 (0.002) loss 1.6091 (1.8341) teacher_loss 0.6635 (0.8283) loss_zs_kd 2.1599 (1.8370) loss_oracle 0.9258 (0.9870) kd_loss 0.9653 (1.0245) acc 81.2500 (71.1806) lr 1.0000e-03 eta 0:17:37
epoch [27/50] batch [380/428] time 0.099 (0.107) data 0.000 (0.002) loss 1.8194 (1.8310) teacher_loss 0.8689 (0.8276) loss_zs_kd 2.0127 (1.8355) loss_oracle 0.9089 (0.9847) kd_loss 0.9921 (1.0222) acc 71.8750 (71.2418) lr 1.0000e-03 eta 0:17:34
epoch [27/50] batch [400/428] time 0.099 (0.107) data 0.000 (0.002) loss 1.7811 (1.8287) teacher_loss 0.8458 (0.8275) loss_zs_kd 2.2693 (1.8451) loss_oracle 0.8953 (0.9822) kd_loss 0.9753 (1.0202) acc 68.7500 (71.1953) lr 1.0000e-03 eta 0:17:31
epoch [27/50] batch [420/428] time 0.094 (0.106) data 0.000 (0.002) loss 1.8562 (1.8242) teacher_loss 0.9007 (0.8238) loss_zs_kd 1.6892 (1.8522) loss_oracle 0.9259 (0.9813) kd_loss 0.9851 (1.0195) acc 62.5000 (71.3170) lr 1.0000e-03 eta 0:17:27
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,706
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 49.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,931
* accuracy: 40.7%
* error: 59.3%
* macro_f1: 32.2%
******* Domain 1 best val acc:      63.6%, epoch: 25 *******
******* Domain 1 best val test acc: 45.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [28/50] batch [20/428] time 0.082 (0.142) data 0.000 (0.029) loss 1.9114 (1.7604) teacher_loss 0.9007 (0.7638) loss_zs_kd 2.0204 (2.0697) loss_oracle 0.9427 (0.9649) kd_loss 1.0787 (1.0283) acc 62.5000 (72.9688) lr 9.3721e-04 eta 0:23:18
epoch [28/50] batch [40/428] time 0.097 (0.120) data 0.000 (0.014) loss 1.9036 (1.7834) teacher_loss 0.8947 (0.7859) loss_zs_kd 1.7892 (1.9750) loss_oracle 1.0023 (0.9682) kd_loss 1.0155 (1.0267) acc 68.7500 (72.9688) lr 9.3721e-04 eta 0:19:33
epoch [28/50] batch [60/428] time 0.083 (0.114) data 0.000 (0.010) loss 1.6398 (1.7844) teacher_loss 0.6116 (0.7842) loss_zs_kd 1.8636 (1.9305) loss_oracle 1.0013 (0.9717) kd_loss 1.0552 (1.0287) acc 78.1250 (73.2812) lr 9.3721e-04 eta 0:18:30
epoch [28/50] batch [80/428] time 0.110 (0.109) data 0.000 (0.007) loss 1.7596 (1.7888) teacher_loss 0.7417 (0.7846) loss_zs_kd 1.6916 (1.8961) loss_oracle 1.0221 (0.9783) kd_loss 1.0137 (1.0301) acc 78.1250 (73.2031) lr 9.3721e-04 eta 0:17:46
epoch [28/50] batch [100/428] time 0.099 (0.108) data 0.000 (0.006) loss 1.7322 (1.8006) teacher_loss 0.7984 (0.7968) loss_zs_kd 1.6444 (1.8719) loss_oracle 0.9190 (0.9785) kd_loss 0.9486 (1.0292) acc 68.7500 (72.5938) lr 9.3721e-04 eta 0:17:32
epoch [28/50] batch [120/428] time 0.096 (0.106) data 0.000 (0.005) loss 2.2862 (1.7998) teacher_loss 1.3108 (0.7974) loss_zs_kd 1.4857 (1.8625) loss_oracle 0.9709 (0.9735) kd_loss 0.9799 (1.0312) acc 53.1250 (72.3698) lr 9.3721e-04 eta 0:17:12
epoch [28/50] batch [140/428] time 0.093 (0.105) data 0.000 (0.004) loss 1.9379 (1.8040) teacher_loss 0.8989 (0.8009) loss_zs_kd 2.0126 (1.8641) loss_oracle 0.9902 (0.9722) kd_loss 1.0876 (1.0339) acc 71.8750 (72.4107) lr 9.3721e-04 eta 0:16:55
epoch [28/50] batch [160/428] time 0.113 (0.103) data 0.000 (0.004) loss 1.8175 (1.8047) teacher_loss 0.8624 (0.8005) loss_zs_kd 1.8145 (1.8647) loss_oracle 0.9352 (0.9741) kd_loss 0.9751 (1.0344) acc 81.2500 (72.2461) lr 9.3721e-04 eta 0:16:41
epoch [28/50] batch [180/428] time 0.125 (0.104) data 0.000 (0.003) loss 1.9983 (1.8000) teacher_loss 0.9843 (0.7941) loss_zs_kd 2.1991 (1.8792) loss_oracle 0.9933 (0.9761) kd_loss 1.0346 (1.0357) acc 62.5000 (72.4132) lr 9.3721e-04 eta 0:16:40
epoch [28/50] batch [200/428] time 0.123 (0.104) data 0.000 (0.003) loss 1.7386 (1.7970) teacher_loss 0.7655 (0.7898) loss_zs_kd 2.0416 (1.8850) loss_oracle 0.9300 (0.9776) kd_loss 1.0163 (1.0368) acc 71.8750 (72.6562) lr 9.3721e-04 eta 0:16:40
epoch [28/50] batch [220/428] time 0.088 (0.104) data 0.000 (0.003) loss 2.1673 (1.8054) teacher_loss 1.1154 (0.7962) loss_zs_kd 1.9189 (1.8835) loss_oracle 1.0001 (0.9801) kd_loss 1.1036 (1.0384) acc 68.7500 (72.6420) lr 9.3721e-04 eta 0:16:36
epoch [28/50] batch [240/428] time 0.109 (0.104) data 0.000 (0.003) loss 1.7749 (1.8018) teacher_loss 0.6933 (0.7903) loss_zs_kd 1.7900 (1.8848) loss_oracle 1.0844 (0.9826) kd_loss 1.0789 (1.0405) acc 71.8750 (72.8646) lr 9.3721e-04 eta 0:16:34
epoch [28/50] batch [260/428] time 0.094 (0.104) data 0.000 (0.002) loss 1.6974 (1.7995) teacher_loss 0.7037 (0.7869) loss_zs_kd 1.7876 (1.8754) loss_oracle 0.9874 (0.9837) kd_loss 0.9998 (1.0415) acc 81.2500 (73.0048) lr 9.3721e-04 eta 0:16:34
epoch [28/50] batch [280/428] time 0.101 (0.104) data 0.000 (0.002) loss 2.0450 (1.8001) teacher_loss 1.0088 (0.7857) loss_zs_kd 1.8093 (1.8686) loss_oracle 0.9887 (0.9863) kd_loss 1.0837 (1.0425) acc 65.6250 (73.0134) lr 9.3721e-04 eta 0:16:33
epoch [28/50] batch [300/428] time 0.107 (0.104) data 0.000 (0.002) loss 1.8954 (1.8047) teacher_loss 0.8011 (0.7884) loss_zs_kd 1.8654 (1.8698) loss_oracle 1.0767 (0.9893) kd_loss 1.1119 (1.0433) acc 68.7500 (72.9375) lr 9.3721e-04 eta 0:16:32
epoch [28/50] batch [320/428] time 0.100 (0.104) data 0.000 (0.002) loss 1.9683 (1.8094) teacher_loss 0.9100 (0.7912) loss_zs_kd 1.8566 (1.8689) loss_oracle 1.0851 (0.9927) kd_loss 1.0316 (1.0436) acc 78.1250 (72.7734) lr 9.3721e-04 eta 0:16:29
epoch [28/50] batch [340/428] time 0.102 (0.104) data 0.000 (0.002) loss 2.0007 (1.8147) teacher_loss 0.8931 (0.7946) loss_zs_kd 1.8689 (1.8743) loss_oracle 1.1073 (0.9953) kd_loss 1.1079 (1.0449) acc 62.5000 (72.6103) lr 9.3721e-04 eta 0:16:26
epoch [28/50] batch [360/428] time 0.111 (0.104) data 0.000 (0.002) loss 1.5417 (1.8194) teacher_loss 0.5767 (0.7989) loss_zs_kd 1.3952 (1.8725) loss_oracle 0.9998 (0.9966) kd_loss 0.9302 (1.0445) acc 78.1250 (72.5174) lr 9.3721e-04 eta 0:16:25
epoch [28/50] batch [380/428] time 0.106 (0.104) data 0.000 (0.002) loss 1.8504 (1.8297) teacher_loss 0.8294 (0.8081) loss_zs_kd 1.7692 (1.8615) loss_oracle 1.0118 (0.9983) kd_loss 1.0303 (1.0449) acc 71.8750 (72.1628) lr 9.3721e-04 eta 0:16:23
epoch [28/50] batch [400/428] time 0.109 (0.104) data 0.000 (0.002) loss 2.3500 (1.8372) teacher_loss 1.2987 (0.8149) loss_zs_kd 1.6550 (1.8521) loss_oracle 1.0079 (0.9997) kd_loss 1.0946 (1.0450) acc 50.0000 (71.8906) lr 9.3721e-04 eta 0:16:21
epoch [28/50] batch [420/428] time 0.097 (0.104) data 0.000 (0.002) loss 1.7159 (1.8437) teacher_loss 0.7009 (0.8208) loss_zs_kd 1.9326 (1.8387) loss_oracle 0.9757 (1.0005) kd_loss 1.0541 (1.0453) acc 71.8750 (71.6518) lr 9.3721e-04 eta 0:16:17
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,439
* accuracy: 58.5%
* error: 41.5%
* macro_f1: 51.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,342
* accuracy: 49.4%
* error: 50.6%
* macro_f1: 33.3%
******* Domain 1 best val acc:      63.6%, epoch: 25 *******
******* Domain 1 best val test acc: 45.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [29/50] batch [20/428] time 0.097 (0.127) data 0.000 (0.025) loss 1.9935 (1.9865) teacher_loss 0.9889 (0.9641) loss_zs_kd 1.7021 (1.6123) loss_oracle 1.0577 (1.0147) kd_loss 0.9514 (1.0300) acc 65.6250 (66.5625) lr 8.7467e-04 eta 0:19:53
epoch [29/50] batch [40/428] time 0.111 (0.115) data 0.000 (0.013) loss 2.0979 (1.9765) teacher_loss 1.0367 (0.9474) loss_zs_kd 1.1510 (1.5789) loss_oracle 1.1121 (1.0198) kd_loss 1.0102 (1.0385) acc 59.3750 (67.6562) lr 8.7467e-04 eta 0:18:00
epoch [29/50] batch [60/428] time 0.104 (0.111) data 0.000 (0.008) loss 2.0270 (1.9467) teacher_loss 0.9903 (0.9203) loss_zs_kd 1.3607 (1.5721) loss_oracle 1.0656 (1.0162) kd_loss 1.0078 (1.0367) acc 68.7500 (68.5938) lr 8.7467e-04 eta 0:17:22
epoch [29/50] batch [80/428] time 0.115 (0.110) data 0.000 (0.006) loss 1.7456 (1.9307) teacher_loss 0.7230 (0.9028) loss_zs_kd 1.8427 (1.6130) loss_oracle 1.0332 (1.0197) kd_loss 1.0120 (1.0362) acc 71.8750 (68.7109) lr 8.7467e-04 eta 0:17:06
epoch [29/50] batch [100/428] time 0.096 (0.109) data 0.000 (0.005) loss 1.8163 (1.9251) teacher_loss 0.7611 (0.8985) loss_zs_kd 1.8195 (1.6497) loss_oracle 1.0531 (1.0198) kd_loss 1.0574 (1.0334) acc 71.8750 (68.8125) lr 8.7467e-04 eta 0:16:54
epoch [29/50] batch [120/428] time 0.104 (0.108) data 0.000 (0.004) loss 1.9183 (1.9174) teacher_loss 0.9056 (0.8932) loss_zs_kd 1.9583 (1.6831) loss_oracle 0.9958 (1.0177) kd_loss 1.0297 (1.0308) acc 62.5000 (68.9323) lr 8.7467e-04 eta 0:16:45
epoch [29/50] batch [140/428] time 0.104 (0.108) data 0.000 (0.004) loss 1.6944 (1.9103) teacher_loss 0.6759 (0.8861) loss_zs_kd 1.6672 (1.6930) loss_oracle 1.0489 (1.0183) kd_loss 0.9881 (1.0300) acc 84.3750 (69.0848) lr 8.7467e-04 eta 0:16:37
epoch [29/50] batch [160/428] time 0.104 (0.107) data 0.000 (0.003) loss 1.8007 (1.9093) teacher_loss 0.7738 (0.8826) loss_zs_kd 2.1176 (1.7014) loss_oracle 0.9370 (1.0199) kd_loss 1.1168 (1.0336) acc 75.0000 (69.3555) lr 8.7467e-04 eta 0:16:32
epoch [29/50] batch [180/428] time 0.110 (0.107) data 0.000 (0.003) loss 1.6246 (1.8940) teacher_loss 0.5743 (0.8675) loss_zs_kd 2.0783 (1.7136) loss_oracle 1.0113 (1.0195) kd_loss 1.0891 (1.0336) acc 78.1250 (70.0174) lr 8.7467e-04 eta 0:16:28
epoch [29/50] batch [200/428] time 0.109 (0.107) data 0.000 (0.003) loss 1.9414 (1.8896) teacher_loss 0.9049 (0.8638) loss_zs_kd 1.5567 (1.7272) loss_oracle 1.0306 (1.0183) kd_loss 1.0424 (1.0334) acc 75.0000 (70.2812) lr 8.7467e-04 eta 0:16:24
epoch [29/50] batch [220/428] time 0.118 (0.107) data 0.001 (0.003) loss 1.9575 (1.8883) teacher_loss 0.9488 (0.8630) loss_zs_kd 2.1816 (1.7215) loss_oracle 0.9969 (1.0182) kd_loss 1.0205 (1.0326) acc 53.1250 (70.1705) lr 8.7467e-04 eta 0:16:23
epoch [29/50] batch [240/428] time 0.084 (0.106) data 0.000 (0.002) loss 1.8949 (1.8877) teacher_loss 0.8597 (0.8623) loss_zs_kd 1.7993 (1.7209) loss_oracle 1.0178 (1.0177) kd_loss 1.0527 (1.0331) acc 68.7500 (70.1302) lr 8.7467e-04 eta 0:16:16
epoch [29/50] batch [260/428] time 0.092 (0.105) data 0.000 (0.002) loss 1.8056 (1.8854) teacher_loss 0.8010 (0.8594) loss_zs_kd 1.4890 (1.7168) loss_oracle 0.9843 (1.0168) kd_loss 1.0249 (1.0351) acc 68.7500 (70.2284) lr 8.7467e-04 eta 0:16:02
epoch [29/50] batch [280/428] time 0.096 (0.104) data 0.000 (0.002) loss 1.9345 (1.8847) teacher_loss 0.9486 (0.8594) loss_zs_kd 1.6771 (1.7141) loss_oracle 0.9804 (1.0166) kd_loss 0.9915 (1.0341) acc 78.1250 (70.1897) lr 8.7467e-04 eta 0:15:51
epoch [29/50] batch [300/428] time 0.080 (0.103) data 0.000 (0.002) loss 1.9470 (1.8824) teacher_loss 0.9172 (0.8571) loss_zs_kd 2.2389 (1.7186) loss_oracle 1.0236 (1.0157) kd_loss 1.0358 (1.0349) acc 62.5000 (70.3333) lr 8.7467e-04 eta 0:15:38
epoch [29/50] batch [320/428] time 0.096 (0.102) data 0.000 (0.002) loss 1.9548 (1.8803) teacher_loss 0.9290 (0.8544) loss_zs_kd 1.5691 (1.7203) loss_oracle 1.0470 (1.0166) kd_loss 1.0048 (1.0351) acc 65.6250 (70.4297) lr 8.7467e-04 eta 0:15:28
epoch [29/50] batch [340/428] time 0.085 (0.101) data 0.000 (0.002) loss 1.7292 (1.8811) teacher_loss 0.7361 (0.8555) loss_zs_kd 1.7418 (1.7219) loss_oracle 0.9472 (1.0164) kd_loss 1.0390 (1.0348) acc 71.8750 (70.3676) lr 8.7467e-04 eta 0:15:19
epoch [29/50] batch [360/428] time 0.085 (0.101) data 0.000 (0.002) loss 1.8609 (1.8861) teacher_loss 0.8293 (0.8606) loss_zs_kd 1.8081 (1.7268) loss_oracle 1.0462 (1.0172) kd_loss 1.0169 (1.0337) acc 68.7500 (70.0694) lr 8.7467e-04 eta 0:15:10
epoch [29/50] batch [380/428] time 0.080 (0.100) data 0.000 (0.002) loss 1.9355 (1.8827) teacher_loss 0.9029 (0.8573) loss_zs_kd 1.5156 (1.7283) loss_oracle 1.0064 (1.0176) kd_loss 1.0589 (1.0332) acc 71.8750 (70.1645) lr 8.7467e-04 eta 0:15:02
epoch [29/50] batch [400/428] time 0.115 (0.100) data 0.000 (0.002) loss 1.8520 (1.8841) teacher_loss 0.8542 (0.8584) loss_zs_kd 1.7562 (1.7334) loss_oracle 0.9960 (1.0187) kd_loss 0.9998 (1.0326) acc 75.0000 (70.2344) lr 8.7467e-04 eta 0:14:57
epoch [29/50] batch [420/428] time 0.088 (0.100) data 0.000 (0.001) loss 1.8244 (1.8801) teacher_loss 0.8049 (0.8538) loss_zs_kd 2.1284 (1.7364) loss_oracle 1.0191 (1.0200) kd_loss 1.0197 (1.0327) acc 68.7500 (70.4018) lr 8.7467e-04 eta 0:14:56
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,803
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 53.1%
Checkpoint saved to icml/multi-dg/tuning/18_kd0.5/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,193
* accuracy: 46.3%
* error: 53.7%
* macro_f1: 32.4%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [30/50] batch [20/428] time 0.099 (0.127) data 0.000 (0.024) loss 1.6734 (1.9477) teacher_loss 0.6811 (0.9241) loss_zs_kd 1.5653 (1.7652) loss_oracle 0.9832 (1.0279) kd_loss 1.0014 (1.0193) acc 81.2500 (69.6875) lr 8.1262e-04 eta 0:19:03
epoch [30/50] batch [40/428] time 0.104 (0.116) data 0.000 (0.012) loss 1.8556 (1.9315) teacher_loss 0.8650 (0.9141) loss_zs_kd 1.8109 (1.7671) loss_oracle 1.0140 (1.0199) kd_loss 0.9672 (1.0148) acc 71.8750 (68.9062) lr 8.1262e-04 eta 0:17:16
epoch [30/50] batch [60/428] time 0.097 (0.110) data 0.000 (0.008) loss 1.9213 (1.9433) teacher_loss 0.8718 (0.9234) loss_zs_kd 1.4965 (1.7483) loss_oracle 1.0747 (1.0252) kd_loss 1.0242 (1.0146) acc 68.7500 (68.1250) lr 8.1262e-04 eta 0:16:20
epoch [30/50] batch [80/428] time 0.099 (0.108) data 0.000 (0.006) loss 1.7743 (1.9260) teacher_loss 0.7640 (0.9088) loss_zs_kd 1.6214 (1.7471) loss_oracle 1.0061 (1.0238) kd_loss 1.0146 (1.0105) acc 71.8750 (68.7500) lr 8.1262e-04 eta 0:16:04
epoch [30/50] batch [100/428] time 0.100 (0.107) data 0.000 (0.005) loss 1.7890 (1.9222) teacher_loss 0.7841 (0.9073) loss_zs_kd 1.9635 (1.7588) loss_oracle 0.9804 (1.0191) kd_loss 1.0293 (1.0107) acc 68.7500 (68.3750) lr 8.1262e-04 eta 0:15:52
epoch [30/50] batch [120/428] time 0.096 (0.107) data 0.000 (0.004) loss 1.5761 (1.9045) teacher_loss 0.5096 (0.8881) loss_zs_kd 1.8654 (1.7615) loss_oracle 1.0763 (1.0196) kd_loss 1.0567 (1.0133) acc 87.5000 (69.1927) lr 8.1262e-04 eta 0:15:45
epoch [30/50] batch [140/428] time 0.102 (0.106) data 0.000 (0.004) loss 2.0087 (1.8916) teacher_loss 0.9992 (0.8760) loss_zs_kd 2.1855 (1.7675) loss_oracle 1.0548 (1.0168) kd_loss 0.9641 (1.0144) acc 56.2500 (69.4420) lr 8.1262e-04 eta 0:15:40
epoch [30/50] batch [160/428] time 0.101 (0.106) data 0.000 (0.003) loss 1.9956 (1.8897) teacher_loss 1.0009 (0.8745) loss_zs_kd 1.4761 (1.7710) loss_oracle 0.9991 (1.0156) kd_loss 0.9903 (1.0149) acc 65.6250 (69.3164) lr 8.1262e-04 eta 0:15:35
epoch [30/50] batch [180/428] time 0.108 (0.106) data 0.000 (0.003) loss 1.6698 (1.8830) teacher_loss 0.6447 (0.8686) loss_zs_kd 1.7273 (1.7883) loss_oracle 1.0332 (1.0148) kd_loss 1.0169 (1.0139) acc 87.5000 (69.4444) lr 8.1262e-04 eta 0:15:32
epoch [30/50] batch [200/428] time 0.101 (0.106) data 0.000 (0.003) loss 1.8146 (1.8801) teacher_loss 0.8290 (0.8675) loss_zs_kd 2.2148 (1.8069) loss_oracle 0.9064 (1.0119) kd_loss 1.0646 (1.0132) acc 75.0000 (69.3438) lr 8.1262e-04 eta 0:15:28
epoch [30/50] batch [220/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.9709 (1.8696) teacher_loss 1.0266 (0.8592) loss_zs_kd 2.2510 (1.8196) loss_oracle 0.9280 (1.0091) kd_loss 0.9605 (1.0116) acc 56.2500 (69.5597) lr 8.1262e-04 eta 0:15:24
epoch [30/50] batch [240/428] time 0.100 (0.105) data 0.000 (0.002) loss 1.6081 (1.8717) teacher_loss 0.6016 (0.8625) loss_zs_kd 1.9587 (1.8323) loss_oracle 1.0111 (1.0080) kd_loss 1.0020 (1.0104) acc 87.5000 (69.5182) lr 8.1262e-04 eta 0:15:21
epoch [30/50] batch [260/428] time 0.098 (0.105) data 0.000 (0.002) loss 1.5978 (1.8618) teacher_loss 0.6015 (0.8530) loss_zs_kd 1.6425 (1.8314) loss_oracle 0.9615 (1.0078) kd_loss 1.0311 (1.0099) acc 78.1250 (69.7837) lr 8.1262e-04 eta 0:15:17
epoch [30/50] batch [280/428] time 0.086 (0.105) data 0.000 (0.002) loss 1.8841 (1.8611) teacher_loss 0.9553 (0.8541) loss_zs_kd 1.7417 (1.8423) loss_oracle 0.9470 (1.0054) kd_loss 0.9106 (1.0086) acc 71.8750 (69.7545) lr 8.1262e-04 eta 0:15:14
epoch [30/50] batch [300/428] time 0.099 (0.105) data 0.000 (0.002) loss 1.7147 (1.8581) teacher_loss 0.7314 (0.8530) loss_zs_kd 1.8543 (1.8482) loss_oracle 1.0375 (1.0026) kd_loss 0.9291 (1.0075) acc 81.2500 (69.8646) lr 8.1262e-04 eta 0:15:13
epoch [30/50] batch [320/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.8235 (1.8608) teacher_loss 0.8368 (0.8572) loss_zs_kd 2.3164 (1.8504) loss_oracle 1.0136 (1.0010) kd_loss 0.9597 (1.0063) acc 56.2500 (69.7461) lr 8.1262e-04 eta 0:15:09
epoch [30/50] batch [340/428] time 0.102 (0.105) data 0.000 (0.002) loss 1.6256 (1.8596) teacher_loss 0.6229 (0.8575) loss_zs_kd 1.8732 (1.8482) loss_oracle 1.0028 (0.9989) kd_loss 1.0026 (1.0053) acc 81.2500 (69.6691) lr 8.1262e-04 eta 0:15:07
epoch [30/50] batch [360/428] time 0.102 (0.105) data 0.000 (0.002) loss 1.6133 (1.8607) teacher_loss 0.6553 (0.8596) loss_zs_kd 1.8126 (1.8461) loss_oracle 0.9619 (0.9974) kd_loss 0.9541 (1.0047) acc 81.2500 (69.6615) lr 8.1262e-04 eta 0:15:04
epoch [30/50] batch [380/428] time 0.114 (0.105) data 0.000 (0.001) loss 1.7211 (1.8600) teacher_loss 0.6976 (0.8581) loss_zs_kd 1.9881 (1.8448) loss_oracle 0.9482 (0.9984) kd_loss 1.0989 (1.0053) acc 81.2500 (69.7697) lr 8.1262e-04 eta 0:15:02
epoch [30/50] batch [400/428] time 0.106 (0.105) data 0.000 (0.001) loss 1.6818 (1.8569) teacher_loss 0.6545 (0.8547) loss_zs_kd 1.6321 (1.8428) loss_oracle 1.0164 (0.9991) kd_loss 1.0384 (1.0053) acc 78.1250 (69.8672) lr 8.1262e-04 eta 0:14:59
epoch [30/50] batch [420/428] time 0.094 (0.105) data 0.000 (0.001) loss 2.0737 (1.8573) teacher_loss 1.0122 (0.8541) loss_zs_kd 1.3593 (1.8430) loss_oracle 1.0393 (1.0001) kd_loss 1.0837 (1.0062) acc 62.5000 (69.8140) lr 8.1262e-04 eta 0:14:56
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,746
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 50.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,150
* accuracy: 45.3%
* error: 54.7%
* macro_f1: 31.8%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [31/50] batch [20/428] time 0.096 (0.135) data 0.000 (0.029) loss 1.7828 (1.8175) teacher_loss 0.7743 (0.8026) loss_zs_kd 2.1645 (1.9778) loss_oracle 0.9879 (1.0114) kd_loss 1.0292 (1.0183) acc 65.6250 (71.0938) lr 7.5131e-04 eta 0:19:13
epoch [31/50] batch [40/428] time 0.114 (0.120) data 0.000 (0.015) loss 1.6975 (1.8323) teacher_loss 0.6710 (0.8211) loss_zs_kd 1.5475 (1.9330) loss_oracle 1.0337 (1.0043) kd_loss 1.0193 (1.0181) acc 78.1250 (71.3281) lr 7.5131e-04 eta 0:17:02
epoch [31/50] batch [60/428] time 0.101 (0.115) data 0.000 (0.010) loss 1.7415 (1.8380) teacher_loss 0.7801 (0.8302) loss_zs_kd 1.7992 (1.9047) loss_oracle 0.9449 (1.0007) kd_loss 0.9780 (1.0149) acc 71.8750 (71.0417) lr 7.5131e-04 eta 0:16:18
epoch [31/50] batch [80/428] time 0.122 (0.113) data 0.000 (0.008) loss 1.6285 (1.8416) teacher_loss 0.6080 (0.8327) loss_zs_kd 1.7210 (1.8916) loss_oracle 1.0435 (1.0037) kd_loss 0.9975 (1.0140) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:15:56
epoch [31/50] batch [100/428] time 0.111 (0.111) data 0.000 (0.006) loss 1.8468 (1.8528) teacher_loss 0.7758 (0.8448) loss_zs_kd 1.9665 (1.8994) loss_oracle 1.0834 (1.0029) kd_loss 1.0587 (1.0132) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:15:37
epoch [31/50] batch [120/428] time 0.100 (0.110) data 0.000 (0.005) loss 1.4506 (1.8429) teacher_loss 0.4635 (0.8363) loss_zs_kd 2.0404 (1.8987) loss_oracle 0.9825 (1.0012) kd_loss 0.9916 (1.0119) acc 90.6250 (71.1198) lr 7.5131e-04 eta 0:15:25
epoch [31/50] batch [140/428] time 0.104 (0.109) data 0.000 (0.004) loss 1.7313 (1.8439) teacher_loss 0.7143 (0.8376) loss_zs_kd 1.5702 (1.9040) loss_oracle 1.0131 (1.0023) kd_loss 1.0210 (1.0104) acc 75.0000 (71.1830) lr 7.5131e-04 eta 0:15:18
epoch [31/50] batch [160/428] time 0.101 (0.108) data 0.000 (0.004) loss 1.8403 (1.8391) teacher_loss 0.8520 (0.8333) loss_zs_kd 2.0340 (1.9010) loss_oracle 0.9777 (1.0013) kd_loss 0.9988 (1.0102) acc 68.7500 (71.3672) lr 7.5131e-04 eta 0:15:09
epoch [31/50] batch [180/428] time 0.099 (0.108) data 0.000 (0.004) loss 1.6678 (1.8394) teacher_loss 0.6649 (0.8332) loss_zs_kd 2.0012 (1.8950) loss_oracle 1.0144 (1.0018) kd_loss 0.9914 (1.0106) acc 71.8750 (71.2674) lr 7.5131e-04 eta 0:15:04
epoch [31/50] batch [200/428] time 0.106 (0.108) data 0.000 (0.003) loss 2.0124 (1.8410) teacher_loss 0.9142 (0.8323) loss_zs_kd 1.5623 (1.8863) loss_oracle 1.0994 (1.0053) kd_loss 1.0970 (1.0120) acc 59.3750 (71.2344) lr 7.5131e-04 eta 0:15:01
epoch [31/50] batch [220/428] time 0.098 (0.107) data 0.000 (0.003) loss 1.9189 (1.8363) teacher_loss 0.9326 (0.8255) loss_zs_kd 1.8218 (1.8916) loss_oracle 0.9764 (1.0082) kd_loss 0.9961 (1.0135) acc 62.5000 (71.3068) lr 7.5131e-04 eta 0:14:56
epoch [31/50] batch [240/428] time 0.105 (0.107) data 0.000 (0.003) loss 1.7716 (1.8333) teacher_loss 0.7110 (0.8200) loss_zs_kd 2.2530 (1.8897) loss_oracle 1.0277 (1.0101) kd_loss 1.0936 (1.0165) acc 78.1250 (71.3672) lr 7.5131e-04 eta 0:14:52
epoch [31/50] batch [260/428] time 0.092 (0.107) data 0.000 (0.003) loss 1.8179 (1.8350) teacher_loss 0.7797 (0.8195) loss_zs_kd 1.6038 (1.8868) loss_oracle 1.0518 (1.0123) kd_loss 1.0246 (1.0187) acc 75.0000 (71.4663) lr 7.5131e-04 eta 0:14:47
epoch [31/50] batch [280/428] time 0.094 (0.107) data 0.000 (0.002) loss 1.9867 (1.8355) teacher_loss 0.9558 (0.8178) loss_zs_kd 1.8557 (1.8800) loss_oracle 1.0394 (1.0144) kd_loss 1.0223 (1.0209) acc 71.8750 (71.3839) lr 7.5131e-04 eta 0:14:43
epoch [31/50] batch [300/428] time 0.127 (0.107) data 0.000 (0.002) loss 1.6749 (1.8277) teacher_loss 0.5704 (0.8088) loss_zs_kd 1.7763 (1.8808) loss_oracle 1.0885 (1.0150) kd_loss 1.1205 (1.0228) acc 84.3750 (71.7708) lr 7.5131e-04 eta 0:14:40
epoch [31/50] batch [320/428] time 0.101 (0.107) data 0.000 (0.002) loss 1.7219 (1.8263) teacher_loss 0.6685 (0.8070) loss_zs_kd 2.1911 (1.8852) loss_oracle 1.0645 (1.0154) kd_loss 1.0424 (1.0231) acc 78.1250 (71.8457) lr 7.5131e-04 eta 0:14:39
epoch [31/50] batch [340/428] time 0.109 (0.107) data 0.000 (0.002) loss 1.6404 (1.8247) teacher_loss 0.5774 (0.8042) loss_zs_kd 2.1156 (1.8818) loss_oracle 1.0591 (1.0161) kd_loss 1.0669 (1.0249) acc 81.2500 (72.0037) lr 7.5131e-04 eta 0:14:36
epoch [31/50] batch [360/428] time 0.099 (0.106) data 0.000 (0.002) loss 1.7642 (1.8232) teacher_loss 0.6874 (0.8013) loss_zs_kd 1.5207 (1.8748) loss_oracle 1.0890 (1.0173) kd_loss 1.0646 (1.0266) acc 71.8750 (72.0660) lr 7.5131e-04 eta 0:14:32
epoch [31/50] batch [380/428] time 0.100 (0.106) data 0.000 (0.002) loss 2.1554 (1.8239) teacher_loss 1.0864 (0.8011) loss_zs_kd 2.0791 (1.8720) loss_oracle 1.0514 (1.0175) kd_loss 1.0865 (1.0280) acc 68.7500 (72.1053) lr 7.5131e-04 eta 0:14:29
epoch [31/50] batch [400/428] time 0.112 (0.106) data 0.000 (0.002) loss 1.7700 (1.8213) teacher_loss 0.7124 (0.7977) loss_zs_kd 2.1178 (1.8693) loss_oracle 1.0899 (1.0181) kd_loss 1.0253 (1.0292) acc 75.0000 (72.2266) lr 7.5131e-04 eta 0:14:27
epoch [31/50] batch [420/428] time 0.093 (0.106) data 0.000 (0.002) loss 2.1384 (1.8224) teacher_loss 1.0574 (0.7977) loss_zs_kd 1.7695 (1.8656) loss_oracle 1.0800 (1.0194) kd_loss 1.0821 (1.0299) acc 65.6250 (72.2545) lr 7.5131e-04 eta 0:14:22
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,756
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 50.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,146
* accuracy: 45.3%
* error: 54.7%
* macro_f1: 33.2%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [32/50] batch [20/428] time 0.119 (0.135) data 0.000 (0.024) loss 1.5715 (1.8574) teacher_loss 0.5296 (0.8248) loss_zs_kd 1.5038 (1.7990) loss_oracle 1.0596 (1.0343) kd_loss 1.0243 (1.0308) acc 90.6250 (72.3438) lr 6.9098e-04 eta 0:18:14
epoch [32/50] batch [40/428] time 0.108 (0.120) data 0.000 (0.012) loss 1.9468 (1.8447) teacher_loss 0.9154 (0.8095) loss_zs_kd 1.7882 (1.8044) loss_oracle 1.0030 (1.0370) kd_loss 1.0598 (1.0333) acc 71.8750 (73.1250) lr 6.9098e-04 eta 0:16:13
epoch [32/50] batch [60/428] time 0.107 (0.115) data 0.000 (0.008) loss 1.8823 (1.8289) teacher_loss 0.8429 (0.7975) loss_zs_kd 1.7774 (1.8557) loss_oracle 1.0194 (1.0350) kd_loss 1.0594 (1.0278) acc 68.7500 (72.8646) lr 6.9098e-04 eta 0:15:31
epoch [32/50] batch [80/428] time 0.102 (0.113) data 0.000 (0.006) loss 1.9013 (1.8361) teacher_loss 0.8668 (0.8060) loss_zs_kd 1.8737 (1.8450) loss_oracle 1.0476 (1.0330) kd_loss 1.0214 (1.0271) acc 65.6250 (72.1875) lr 6.9098e-04 eta 0:15:06
epoch [32/50] batch [100/428] time 0.105 (0.111) data 0.000 (0.005) loss 1.7802 (1.8469) teacher_loss 0.7785 (0.8189) loss_zs_kd 2.0345 (1.8262) loss_oracle 1.0372 (1.0331) kd_loss 0.9662 (1.0229) acc 78.1250 (71.7812) lr 6.9098e-04 eta 0:14:50
epoch [32/50] batch [120/428] time 0.116 (0.110) data 0.000 (0.004) loss 1.9706 (1.8574) teacher_loss 0.9825 (0.8338) loss_zs_kd 1.3121 (1.8049) loss_oracle 0.9545 (1.0306) kd_loss 1.0219 (1.0167) acc 56.2500 (71.0156) lr 6.9098e-04 eta 0:14:41
epoch [32/50] batch [140/428] time 0.098 (0.109) data 0.000 (0.004) loss 1.8110 (1.8586) teacher_loss 0.8221 (0.8344) loss_zs_kd 1.7436 (1.8023) loss_oracle 0.9860 (1.0316) kd_loss 0.9918 (1.0167) acc 71.8750 (70.7812) lr 6.9098e-04 eta 0:14:30
epoch [32/50] batch [160/428] time 0.110 (0.108) data 0.000 (0.003) loss 1.5902 (1.8640) teacher_loss 0.5560 (0.8407) loss_zs_kd 1.6719 (1.7907) loss_oracle 1.0946 (1.0305) kd_loss 0.9738 (1.0160) acc 84.3750 (70.6055) lr 6.9098e-04 eta 0:14:23
epoch [32/50] batch [180/428] time 0.100 (0.108) data 0.000 (0.003) loss 1.8819 (1.8674) teacher_loss 0.8532 (0.8439) loss_zs_kd 1.8860 (1.7929) loss_oracle 1.0534 (1.0304) kd_loss 1.0041 (1.0167) acc 65.6250 (70.4688) lr 6.9098e-04 eta 0:14:16
epoch [32/50] batch [200/428] time 0.087 (0.107) data 0.000 (0.003) loss 1.6158 (1.8718) teacher_loss 0.5761 (0.8475) loss_zs_kd 1.7618 (1.7928) loss_oracle 1.0507 (1.0307) kd_loss 1.0288 (1.0179) acc 81.2500 (70.2500) lr 6.9098e-04 eta 0:14:06
epoch [32/50] batch [220/428] time 0.093 (0.105) data 0.000 (0.002) loss 1.9306 (1.8713) teacher_loss 0.9040 (0.8462) loss_zs_kd 1.8812 (1.7976) loss_oracle 1.0376 (1.0311) kd_loss 1.0155 (1.0191) acc 59.3750 (70.3551) lr 6.9098e-04 eta 0:13:54
epoch [32/50] batch [240/428] time 0.089 (0.104) data 0.000 (0.002) loss 2.0198 (1.8631) teacher_loss 0.8974 (0.8374) loss_zs_kd 1.7329 (1.8007) loss_oracle 1.1324 (1.0305) kd_loss 1.1124 (1.0209) acc 68.7500 (70.6380) lr 6.9098e-04 eta 0:13:44
epoch [32/50] batch [260/428] time 0.097 (0.103) data 0.000 (0.002) loss 1.6463 (1.8629) teacher_loss 0.5703 (0.8368) loss_zs_kd 1.8031 (1.8019) loss_oracle 1.0515 (1.0306) kd_loss 1.1005 (1.0216) acc 78.1250 (70.5288) lr 6.9098e-04 eta 0:13:33
epoch [32/50] batch [280/428] time 0.118 (0.103) data 0.000 (0.002) loss 2.4501 (1.8625) teacher_loss 1.3986 (0.8363) loss_zs_kd 1.5644 (1.8060) loss_oracle 1.0335 (1.0301) kd_loss 1.0694 (1.0223) acc 43.7500 (70.5134) lr 6.9098e-04 eta 0:13:27
epoch [32/50] batch [300/428] time 0.103 (0.103) data 0.000 (0.002) loss 1.8487 (1.8624) teacher_loss 0.8097 (0.8363) loss_zs_kd 1.5590 (1.8006) loss_oracle 1.0202 (1.0286) kd_loss 1.0578 (1.0236) acc 71.8750 (70.5833) lr 6.9098e-04 eta 0:13:25
epoch [32/50] batch [320/428] time 0.105 (0.103) data 0.000 (0.002) loss 1.8908 (1.8604) teacher_loss 0.8653 (0.8345) loss_zs_kd 1.7545 (1.7995) loss_oracle 0.9866 (1.0274) kd_loss 1.0645 (1.0244) acc 65.6250 (70.5566) lr 6.9098e-04 eta 0:13:22
epoch [32/50] batch [340/428] time 0.109 (0.103) data 0.000 (0.002) loss 1.6030 (1.8592) teacher_loss 0.5215 (0.8322) loss_zs_kd 1.6532 (1.8026) loss_oracle 1.1145 (1.0276) kd_loss 1.0483 (1.0264) acc 81.2500 (70.6985) lr 6.9098e-04 eta 0:13:20
epoch [32/50] batch [360/428] time 0.100 (0.103) data 0.000 (0.002) loss 1.9302 (1.8589) teacher_loss 0.9193 (0.8311) loss_zs_kd 1.6285 (1.7985) loss_oracle 1.0496 (1.0285) kd_loss 0.9723 (1.0270) acc 59.3750 (70.6597) lr 6.9098e-04 eta 0:13:21
epoch [32/50] batch [380/428] time 0.086 (0.103) data 0.000 (0.002) loss 2.1199 (1.8580) teacher_loss 1.1322 (0.8309) loss_zs_kd 1.2260 (1.7991) loss_oracle 1.0194 (1.0279) kd_loss 0.9559 (1.0262) acc 56.2500 (70.7155) lr 6.9098e-04 eta 0:13:19
epoch [32/50] batch [400/428] time 0.110 (0.103) data 0.000 (0.001) loss 2.0779 (1.8557) teacher_loss 1.0667 (0.8295) loss_zs_kd 1.7717 (1.8020) loss_oracle 1.0299 (1.0272) kd_loss 0.9924 (1.0253) acc 68.7500 (70.7734) lr 6.9098e-04 eta 0:13:17
epoch [32/50] batch [420/428] time 0.089 (0.103) data 0.000 (0.001) loss 1.7371 (1.8580) teacher_loss 0.6704 (0.8325) loss_zs_kd 1.5200 (1.8016) loss_oracle 1.0994 (1.0261) kd_loss 1.0340 (1.0249) acc 75.0000 (70.7143) lr 6.9098e-04 eta 0:13:14
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,795
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 51.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,059
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 31.0%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [33/50] batch [20/428] time 0.105 (0.126) data 0.000 (0.022) loss 1.8951 (1.8639) teacher_loss 0.9232 (0.8687) loss_zs_kd 1.3801 (1.6720) loss_oracle 0.9757 (1.0033) kd_loss 0.9681 (0.9871) acc 62.5000 (69.2188) lr 6.3188e-04 eta 0:16:09
epoch [33/50] batch [40/428] time 0.108 (0.114) data 0.000 (0.011) loss 1.8266 (1.8421) teacher_loss 0.8188 (0.8473) loss_zs_kd 1.6535 (1.7295) loss_oracle 1.0085 (0.9977) kd_loss 1.0071 (0.9920) acc 68.7500 (70.4688) lr 6.3188e-04 eta 0:14:37
epoch [33/50] batch [60/428] time 0.111 (0.111) data 0.000 (0.008) loss 1.9169 (1.8349) teacher_loss 0.9523 (0.8349) loss_zs_kd 1.7389 (1.7833) loss_oracle 1.0090 (1.0004) kd_loss 0.9201 (0.9997) acc 62.5000 (71.1458) lr 6.3188e-04 eta 0:14:08
epoch [33/50] batch [80/428] time 0.115 (0.110) data 0.000 (0.006) loss 1.8464 (1.8580) teacher_loss 0.8013 (0.8590) loss_zs_kd 1.4481 (1.7880) loss_oracle 1.0413 (1.0014) kd_loss 1.0489 (0.9967) acc 62.5000 (70.1562) lr 6.3188e-04 eta 0:13:59
epoch [33/50] batch [100/428] time 0.107 (0.109) data 0.000 (0.005) loss 2.1110 (1.8533) teacher_loss 1.1033 (0.8553) loss_zs_kd 1.6040 (1.7908) loss_oracle 0.9663 (0.9997) kd_loss 1.0491 (0.9961) acc 65.6250 (70.6875) lr 6.3188e-04 eta 0:13:49
epoch [33/50] batch [120/428] time 0.100 (0.108) data 0.000 (0.004) loss 1.7136 (1.8534) teacher_loss 0.6996 (0.8567) loss_zs_kd 1.7574 (1.7998) loss_oracle 0.9954 (0.9970) kd_loss 1.0326 (0.9965) acc 75.0000 (70.3906) lr 6.3188e-04 eta 0:13:42
epoch [33/50] batch [140/428] time 0.109 (0.108) data 0.000 (0.003) loss 1.8054 (1.8415) teacher_loss 0.7489 (0.8447) loss_zs_kd 1.6200 (1.8044) loss_oracle 1.0064 (0.9959) kd_loss 1.1066 (0.9979) acc 65.6250 (70.8929) lr 6.3188e-04 eta 0:13:35
epoch [33/50] batch [160/428] time 0.098 (0.107) data 0.000 (0.003) loss 1.8108 (1.8326) teacher_loss 0.7559 (0.8340) loss_zs_kd 2.0260 (1.8125) loss_oracle 1.0493 (0.9973) kd_loss 1.0605 (1.0000) acc 71.8750 (71.4453) lr 6.3188e-04 eta 0:13:30
epoch [33/50] batch [180/428] time 0.096 (0.107) data 0.000 (0.003) loss 1.9525 (1.8375) teacher_loss 0.9399 (0.8374) loss_zs_kd 2.1011 (1.8212) loss_oracle 0.9908 (0.9976) kd_loss 1.0344 (1.0026) acc 68.7500 (71.2500) lr 6.3188e-04 eta 0:13:26
epoch [33/50] batch [200/428] time 0.111 (0.107) data 0.000 (0.002) loss 1.9496 (1.8345) teacher_loss 0.9512 (0.8320) loss_zs_kd 1.6665 (1.8211) loss_oracle 0.9931 (0.9993) kd_loss 1.0037 (1.0057) acc 78.1250 (71.4531) lr 6.3188e-04 eta 0:13:21
epoch [33/50] batch [220/428] time 0.123 (0.107) data 0.000 (0.002) loss 1.9715 (1.8352) teacher_loss 1.0019 (0.8328) loss_zs_kd 1.7404 (1.8178) loss_oracle 0.9662 (0.9992) kd_loss 0.9729 (1.0055) acc 68.7500 (71.4773) lr 6.3188e-04 eta 0:13:18
epoch [33/50] batch [240/428] time 0.102 (0.106) data 0.000 (0.002) loss 1.8141 (1.8340) teacher_loss 0.8743 (0.8323) loss_zs_kd 2.0567 (1.8171) loss_oracle 0.9637 (0.9975) kd_loss 0.9160 (1.0059) acc 75.0000 (71.4974) lr 6.3188e-04 eta 0:13:12
epoch [33/50] batch [260/428] time 0.097 (0.105) data 0.000 (0.002) loss 1.5631 (1.8300) teacher_loss 0.6110 (0.8274) loss_zs_kd 1.6423 (1.8207) loss_oracle 0.9452 (0.9982) kd_loss 0.9591 (1.0072) acc 75.0000 (71.6346) lr 6.3188e-04 eta 0:13:05
epoch [33/50] batch [280/428] time 0.111 (0.105) data 0.001 (0.002) loss 1.8501 (1.8318) teacher_loss 0.8025 (0.8283) loss_zs_kd 1.8168 (1.8268) loss_oracle 1.0378 (0.9994) kd_loss 1.0575 (1.0077) acc 68.7500 (71.5960) lr 6.3188e-04 eta 0:13:01
epoch [33/50] batch [300/428] time 0.104 (0.105) data 0.000 (0.002) loss 1.9432 (1.8310) teacher_loss 0.9730 (0.8271) loss_zs_kd 2.0970 (1.8273) loss_oracle 0.9230 (0.9993) kd_loss 1.0173 (1.0085) acc 68.7500 (71.6354) lr 6.3188e-04 eta 0:12:58
epoch [33/50] batch [320/428] time 0.115 (0.105) data 0.000 (0.002) loss 1.9190 (1.8304) teacher_loss 0.9074 (0.8262) loss_zs_kd 1.8223 (1.8326) loss_oracle 1.0123 (0.9997) kd_loss 1.0108 (1.0086) acc 68.7500 (71.6797) lr 6.3188e-04 eta 0:12:54
epoch [33/50] batch [340/428] time 0.088 (0.105) data 0.000 (0.002) loss 1.7226 (1.8343) teacher_loss 0.6901 (0.8297) loss_zs_kd 1.7962 (1.8343) loss_oracle 1.0831 (1.0006) kd_loss 0.9818 (1.0087) acc 71.8750 (71.4062) lr 6.3188e-04 eta 0:12:51
epoch [33/50] batch [360/428] time 0.092 (0.105) data 0.000 (0.001) loss 1.6582 (1.8326) teacher_loss 0.6495 (0.8283) loss_zs_kd 1.9295 (1.8362) loss_oracle 1.0328 (1.0003) kd_loss 0.9846 (1.0084) acc 71.8750 (71.4149) lr 6.3188e-04 eta 0:12:48
epoch [33/50] batch [380/428] time 0.102 (0.105) data 0.000 (0.001) loss 1.6804 (1.8314) teacher_loss 0.6520 (0.8272) loss_zs_kd 2.0498 (1.8372) loss_oracle 1.0698 (0.9995) kd_loss 0.9871 (1.0089) acc 81.2500 (71.4885) lr 6.3188e-04 eta 0:12:45
epoch [33/50] batch [400/428] time 0.102 (0.105) data 0.000 (0.001) loss 1.9834 (1.8320) teacher_loss 0.9331 (0.8272) loss_zs_kd 1.8605 (1.8380) loss_oracle 1.0212 (1.0002) kd_loss 1.0795 (1.0094) acc 71.8750 (71.5625) lr 6.3188e-04 eta 0:12:44
epoch [33/50] batch [420/428] time 0.064 (0.104) data 0.000 (0.001) loss 1.7452 (1.8302) teacher_loss 0.6843 (0.8257) loss_zs_kd 2.0806 (1.8408) loss_oracle 1.0184 (0.9999) kd_loss 1.1033 (1.0092) acc 75.0000 (71.5327) lr 6.3188e-04 eta 0:12:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,774
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,057
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 30.7%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [34/50] batch [20/428] time 0.100 (0.133) data 0.000 (0.025) loss 1.5822 (1.7929) teacher_loss 0.5167 (0.7773) loss_zs_kd 1.8879 (1.8671) loss_oracle 1.0319 (0.9932) kd_loss 1.0992 (1.0381) acc 87.5000 (73.2812) lr 5.7422e-04 eta 0:16:06
epoch [34/50] batch [40/428] time 0.106 (0.118) data 0.000 (0.013) loss 1.9230 (1.8077) teacher_loss 0.9171 (0.7949) loss_zs_kd 2.1396 (1.8764) loss_oracle 0.9930 (0.9996) kd_loss 1.0187 (1.0259) acc 65.6250 (71.2500) lr 5.7422e-04 eta 0:14:17
epoch [34/50] batch [60/428] time 0.104 (0.114) data 0.001 (0.008) loss 1.7199 (1.7933) teacher_loss 0.6583 (0.7781) loss_zs_kd 1.9360 (1.8823) loss_oracle 1.0543 (1.0051) kd_loss 1.0689 (1.0253) acc 81.2500 (72.2396) lr 5.7422e-04 eta 0:13:39
epoch [34/50] batch [80/428] time 0.093 (0.111) data 0.000 (0.006) loss 1.8100 (1.7843) teacher_loss 0.7790 (0.7690) loss_zs_kd 2.0454 (1.8998) loss_oracle 0.9968 (1.0066) kd_loss 1.0651 (1.0240) acc 71.8750 (72.9297) lr 5.7422e-04 eta 0:13:20
epoch [34/50] batch [100/428] time 0.104 (0.110) data 0.000 (0.005) loss 1.8166 (1.7808) teacher_loss 0.8013 (0.7680) loss_zs_kd 2.1457 (1.9053) loss_oracle 0.9933 (1.0013) kd_loss 1.0373 (1.0243) acc 71.8750 (72.6250) lr 5.7422e-04 eta 0:13:10
epoch [34/50] batch [120/428] time 0.103 (0.110) data 0.000 (0.004) loss 1.7693 (1.7915) teacher_loss 0.7927 (0.7818) loss_zs_kd 1.7030 (1.8980) loss_oracle 0.9571 (0.9989) kd_loss 0.9963 (1.0204) acc 68.7500 (71.8750) lr 5.7422e-04 eta 0:13:05
epoch [34/50] batch [140/428] time 0.096 (0.109) data 0.000 (0.004) loss 1.5844 (1.7984) teacher_loss 0.5746 (0.7906) loss_zs_kd 1.9787 (1.8987) loss_oracle 0.9845 (0.9983) kd_loss 1.0351 (1.0174) acc 78.1250 (71.9643) lr 5.7422e-04 eta 0:12:56
epoch [34/50] batch [160/428] time 0.102 (0.108) data 0.000 (0.003) loss 2.1767 (1.8017) teacher_loss 1.1716 (0.7964) loss_zs_kd 1.7101 (1.9085) loss_oracle 1.0584 (0.9954) kd_loss 0.9517 (1.0151) acc 59.3750 (71.7969) lr 5.7422e-04 eta 0:12:49
epoch [34/50] batch [180/428] time 0.110 (0.108) data 0.000 (0.003) loss 1.6753 (1.8084) teacher_loss 0.6516 (0.8024) loss_zs_kd 1.9145 (1.9092) loss_oracle 0.9946 (0.9964) kd_loss 1.0529 (1.0156) acc 68.7500 (71.4931) lr 5.7422e-04 eta 0:12:42
epoch [34/50] batch [200/428] time 0.106 (0.107) data 0.000 (0.003) loss 2.0541 (1.8105) teacher_loss 0.9873 (0.8039) loss_zs_kd 1.6239 (1.9011) loss_oracle 1.0547 (0.9965) kd_loss 1.0790 (1.0168) acc 62.5000 (71.3906) lr 5.7422e-04 eta 0:12:38
epoch [34/50] batch [220/428] time 0.113 (0.107) data 0.000 (0.003) loss 1.9846 (1.8117) teacher_loss 0.9390 (0.8047) loss_zs_kd 2.2872 (1.9033) loss_oracle 1.0351 (0.9973) kd_loss 1.0562 (1.0165) acc 62.5000 (71.2500) lr 5.7422e-04 eta 0:12:34
epoch [34/50] batch [240/428] time 0.113 (0.107) data 0.000 (0.002) loss 1.7852 (1.8103) teacher_loss 0.7688 (0.8009) loss_zs_kd 1.9431 (1.9017) loss_oracle 1.0347 (1.0005) kd_loss 0.9981 (1.0185) acc 65.6250 (71.3151) lr 5.7422e-04 eta 0:12:30
epoch [34/50] batch [260/428] time 0.104 (0.106) data 0.000 (0.002) loss 1.5219 (1.8077) teacher_loss 0.4229 (0.7967) loss_zs_kd 1.6771 (1.9054) loss_oracle 1.1046 (1.0019) kd_loss 1.0935 (1.0200) acc 87.5000 (71.6106) lr 5.7422e-04 eta 0:12:26
epoch [34/50] batch [280/428] time 0.110 (0.106) data 0.000 (0.002) loss 2.0767 (1.8156) teacher_loss 1.0630 (0.8033) loss_zs_kd 1.4516 (1.9037) loss_oracle 0.9864 (1.0039) kd_loss 1.0410 (1.0207) acc 59.3750 (71.4732) lr 5.7422e-04 eta 0:12:23
epoch [34/50] batch [300/428] time 0.103 (0.106) data 0.000 (0.002) loss 1.7745 (1.8125) teacher_loss 0.7254 (0.7978) loss_zs_kd 1.7790 (1.9000) loss_oracle 1.0498 (1.0061) kd_loss 1.0485 (1.0232) acc 78.1250 (71.6667) lr 5.7422e-04 eta 0:12:20
epoch [34/50] batch [320/428] time 0.104 (0.106) data 0.000 (0.002) loss 1.5804 (1.8128) teacher_loss 0.5651 (0.7982) loss_zs_kd 1.8419 (1.8964) loss_oracle 1.0124 (1.0067) kd_loss 1.0182 (1.0226) acc 84.3750 (71.6602) lr 5.7422e-04 eta 0:12:17
epoch [34/50] batch [340/428] time 0.112 (0.106) data 0.000 (0.002) loss 1.9998 (1.8135) teacher_loss 1.0114 (0.7988) loss_zs_kd 1.9215 (1.9021) loss_oracle 0.9791 (1.0069) kd_loss 0.9978 (1.0224) acc 65.6250 (71.7923) lr 5.7422e-04 eta 0:12:15
epoch [34/50] batch [360/428] time 0.100 (0.106) data 0.000 (0.002) loss 1.7569 (1.8130) teacher_loss 0.7069 (0.7983) loss_zs_kd 1.7987 (1.9028) loss_oracle 1.0633 (1.0069) kd_loss 1.0366 (1.0224) acc 75.0000 (71.7535) lr 5.7422e-04 eta 0:12:12
epoch [34/50] batch [380/428] time 0.108 (0.106) data 0.000 (0.002) loss 1.7033 (1.8137) teacher_loss 0.6631 (0.7995) loss_zs_kd 1.8927 (1.8990) loss_oracle 1.0126 (1.0065) kd_loss 1.0678 (1.0218) acc 71.8750 (71.7188) lr 5.7422e-04 eta 0:12:09
epoch [34/50] batch [400/428] time 0.107 (0.106) data 0.000 (0.002) loss 1.8574 (1.8134) teacher_loss 0.8486 (0.7991) loss_zs_kd 1.7527 (1.8885) loss_oracle 1.0126 (1.0067) kd_loss 1.0051 (1.0220) acc 78.1250 (71.8516) lr 5.7422e-04 eta 0:12:07
epoch [34/50] batch [420/428] time 0.103 (0.106) data 0.000 (0.001) loss 1.6863 (1.8133) teacher_loss 0.7175 (0.7993) loss_zs_kd 1.6099 (1.8886) loss_oracle 0.9933 (1.0071) kd_loss 0.9443 (1.0211) acc 75.0000 (71.8378) lr 5.7422e-04 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,734
* accuracy: 63.5%
* error: 36.5%
* macro_f1: 49.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,184
* accuracy: 46.1%
* error: 53.9%
* macro_f1: 31.9%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [35/50] batch [20/428] time 0.117 (0.130) data 0.000 (0.025) loss 1.6748 (1.8669) teacher_loss 0.6468 (0.8483) loss_zs_kd 1.5456 (1.9269) loss_oracle 1.0363 (1.0160) kd_loss 1.0196 (1.0213) acc 81.2500 (69.0625) lr 5.1825e-04 eta 0:14:48
epoch [35/50] batch [40/428] time 0.105 (0.117) data 0.000 (0.012) loss 1.7765 (1.8443) teacher_loss 0.7034 (0.8234) loss_zs_kd 1.8642 (1.8516) loss_oracle 1.0711 (1.0123) kd_loss 1.0751 (1.0294) acc 68.7500 (70.8594) lr 5.1825e-04 eta 0:13:17
epoch [35/50] batch [60/428] time 0.102 (0.113) data 0.001 (0.008) loss 1.6517 (1.8081) teacher_loss 0.6441 (0.7902) loss_zs_kd 1.8804 (1.8676) loss_oracle 0.9676 (1.0080) kd_loss 1.0477 (1.0278) acc 78.1250 (72.6562) lr 5.1825e-04 eta 0:12:46
epoch [35/50] batch [80/428] time 0.111 (0.111) data 0.000 (0.006) loss 1.8200 (1.8039) teacher_loss 0.8086 (0.7855) loss_zs_kd 2.2753 (1.8901) loss_oracle 1.0414 (1.0073) kd_loss 0.9815 (1.0295) acc 75.0000 (72.8906) lr 5.1825e-04 eta 0:12:29
epoch [35/50] batch [100/428] time 0.098 (0.110) data 0.000 (0.005) loss 1.8016 (1.8021) teacher_loss 0.7472 (0.7826) loss_zs_kd 1.5815 (1.8910) loss_oracle 1.0809 (1.0084) kd_loss 1.0278 (1.0307) acc 68.7500 (72.6250) lr 5.1825e-04 eta 0:12:19
epoch [35/50] batch [120/428] time 0.103 (0.109) data 0.000 (0.004) loss 2.3426 (1.7860) teacher_loss 1.3076 (0.7642) loss_zs_kd 2.2680 (1.8910) loss_oracle 0.9755 (1.0119) kd_loss 1.0945 (1.0317) acc 62.5000 (73.4375) lr 5.1825e-04 eta 0:12:12
epoch [35/50] batch [140/428] time 0.105 (0.110) data 0.000 (0.004) loss 1.5682 (1.7942) teacher_loss 0.5520 (0.7727) loss_zs_kd 1.6105 (1.8895) loss_oracle 1.0390 (1.0119) kd_loss 0.9932 (1.0311) acc 84.3750 (73.1250) lr 5.1825e-04 eta 0:12:15
epoch [35/50] batch [160/428] time 0.099 (0.109) data 0.000 (0.003) loss 1.9163 (1.8036) teacher_loss 0.8599 (0.7806) loss_zs_kd 1.6577 (1.8715) loss_oracle 1.0545 (1.0149) kd_loss 1.0585 (1.0312) acc 75.0000 (72.6953) lr 5.1825e-04 eta 0:12:07
epoch [35/50] batch [180/428] time 0.119 (0.109) data 0.000 (0.003) loss 1.9002 (1.8081) teacher_loss 0.8855 (0.7857) loss_zs_kd 2.1643 (1.8591) loss_oracle 0.9874 (1.0146) kd_loss 1.0419 (1.0303) acc 62.5000 (72.4306) lr 5.1825e-04 eta 0:12:03
epoch [35/50] batch [200/428] time 0.112 (0.108) data 0.000 (0.003) loss 1.7759 (1.8164) teacher_loss 0.7302 (0.7937) loss_zs_kd 1.7850 (1.8650) loss_oracle 1.0015 (1.0147) kd_loss 1.0900 (1.0307) acc 71.8750 (72.1406) lr 5.1825e-04 eta 0:11:58
epoch [35/50] batch [220/428] time 0.101 (0.108) data 0.000 (0.002) loss 1.6126 (1.8238) teacher_loss 0.5340 (0.7998) loss_zs_kd 2.0977 (1.8652) loss_oracle 1.0856 (1.0169) kd_loss 1.0716 (1.0311) acc 84.3750 (71.9886) lr 5.1825e-04 eta 0:11:53
epoch [35/50] batch [240/428] time 0.097 (0.107) data 0.000 (0.002) loss 2.0758 (1.8249) teacher_loss 1.0804 (0.8006) loss_zs_kd 2.0867 (1.8622) loss_oracle 1.0096 (1.0175) kd_loss 0.9811 (1.0312) acc 56.2500 (72.0312) lr 5.1825e-04 eta 0:11:48
epoch [35/50] batch [260/428] time 0.099 (0.107) data 0.000 (0.002) loss 1.6288 (1.8272) teacher_loss 0.5561 (0.8018) loss_zs_kd 1.9787 (1.8527) loss_oracle 1.0437 (1.0195) kd_loss 1.1017 (1.0313) acc 81.2500 (72.1154) lr 5.1825e-04 eta 0:11:44
epoch [35/50] batch [280/428] time 0.102 (0.107) data 0.000 (0.002) loss 1.6168 (1.8235) teacher_loss 0.5948 (0.7976) loss_zs_kd 1.8572 (1.8547) loss_oracle 1.0114 (1.0206) kd_loss 1.0325 (1.0312) acc 81.2500 (72.2768) lr 5.1825e-04 eta 0:11:40
epoch [35/50] batch [300/428] time 0.110 (0.107) data 0.000 (0.002) loss 1.6312 (1.8276) teacher_loss 0.6189 (0.8016) loss_zs_kd 1.8100 (1.8574) loss_oracle 0.9979 (1.0214) kd_loss 1.0267 (1.0305) acc 84.3750 (72.1562) lr 5.1825e-04 eta 0:11:37
epoch [35/50] batch [320/428] time 0.111 (0.106) data 0.000 (0.002) loss 1.8386 (1.8289) teacher_loss 0.8505 (0.8039) loss_zs_kd 1.5993 (1.8620) loss_oracle 0.9869 (1.0205) kd_loss 0.9892 (1.0295) acc 71.8750 (71.9922) lr 5.1825e-04 eta 0:11:33
epoch [35/50] batch [340/428] time 0.106 (0.106) data 0.000 (0.002) loss 1.8247 (1.8305) teacher_loss 0.8317 (0.8052) loss_zs_kd 1.8354 (1.8501) loss_oracle 0.9887 (1.0207) kd_loss 0.9973 (1.0298) acc 65.6250 (71.8566) lr 5.1825e-04 eta 0:11:31
epoch [35/50] batch [360/428] time 0.101 (0.106) data 0.000 (0.002) loss 2.0818 (1.8330) teacher_loss 1.0459 (0.8073) loss_zs_kd 2.0786 (1.8473) loss_oracle 1.0432 (1.0214) kd_loss 1.0286 (1.0300) acc 56.2500 (71.6146) lr 5.1825e-04 eta 0:11:28
epoch [35/50] batch [380/428] time 0.096 (0.106) data 0.000 (0.002) loss 1.7717 (1.8295) teacher_loss 0.7124 (0.8038) loss_zs_kd 1.8847 (1.8424) loss_oracle 1.0324 (1.0215) kd_loss 1.0863 (1.0300) acc 78.1250 (71.7516) lr 5.1825e-04 eta 0:11:25
epoch [35/50] batch [400/428] time 0.116 (0.106) data 0.000 (0.001) loss 1.7605 (1.8282) teacher_loss 0.7440 (0.8022) loss_zs_kd 1.8686 (1.8440) loss_oracle 0.9850 (1.0219) kd_loss 1.0481 (1.0301) acc 75.0000 (71.8047) lr 5.1825e-04 eta 0:11:23
epoch [35/50] batch [420/428] time 0.101 (0.106) data 0.000 (0.001) loss 1.8789 (1.8323) teacher_loss 0.8297 (0.8069) loss_zs_kd 1.8548 (1.8429) loss_oracle 1.0740 (1.0221) kd_loss 1.0243 (1.0288) acc 71.8750 (71.5551) lr 5.1825e-04 eta 0:11:20
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,747
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 49.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,137
* accuracy: 45.1%
* error: 54.9%
* macro_f1: 31.7%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [36/50] batch [20/428] time 0.097 (0.117) data 0.000 (0.024) loss 1.8814 (1.8564) teacher_loss 0.8286 (0.8348) loss_zs_kd 1.7855 (1.8164) loss_oracle 1.0710 (1.0245) kd_loss 1.0347 (1.0187) acc 81.2500 (70.4688) lr 4.6417e-04 eta 0:12:28
epoch [36/50] batch [40/428] time 0.083 (0.104) data 0.000 (0.012) loss 1.5916 (1.8516) teacher_loss 0.5419 (0.8351) loss_zs_kd 1.6181 (1.8054) loss_oracle 1.0121 (1.0193) kd_loss 1.0873 (1.0138) acc 87.5000 (70.8594) lr 4.6417e-04 eta 0:11:04
epoch [36/50] batch [60/428] time 0.083 (0.101) data 0.001 (0.008) loss 1.9849 (1.8499) teacher_loss 0.9664 (0.8365) loss_zs_kd 1.7599 (1.7747) loss_oracle 1.0179 (1.0173) kd_loss 1.0190 (1.0096) acc 65.6250 (70.2604) lr 4.6417e-04 eta 0:10:40
epoch [36/50] batch [80/428] time 0.083 (0.099) data 0.000 (0.006) loss 1.8963 (1.8329) teacher_loss 0.8544 (0.8176) loss_zs_kd 2.3696 (1.7729) loss_oracle 1.0549 (1.0189) kd_loss 1.0290 (1.0117) acc 65.6250 (70.7422) lr 4.6417e-04 eta 0:10:26
epoch [36/50] batch [100/428] time 0.088 (0.098) data 0.000 (0.005) loss 1.9150 (1.8269) teacher_loss 0.8839 (0.8097) loss_zs_kd 1.7421 (1.7703) loss_oracle 1.0040 (1.0199) kd_loss 1.0583 (1.0144) acc 65.6250 (71.1875) lr 4.6417e-04 eta 0:10:21
epoch [36/50] batch [120/428] time 0.110 (0.097) data 0.000 (0.004) loss 1.9720 (1.8317) teacher_loss 0.9428 (0.8139) loss_zs_kd 1.8813 (1.7690) loss_oracle 1.0327 (1.0201) kd_loss 1.0256 (1.0155) acc 62.5000 (70.9896) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [140/428] time 0.108 (0.097) data 0.000 (0.004) loss 2.0805 (1.8320) teacher_loss 1.0831 (0.8157) loss_zs_kd 2.0282 (1.7720) loss_oracle 0.9848 (1.0173) kd_loss 1.0100 (1.0153) acc 59.3750 (70.9375) lr 4.6417e-04 eta 0:10:09
epoch [36/50] batch [160/428] time 0.112 (0.098) data 0.000 (0.003) loss 1.4675 (1.8233) teacher_loss 0.4508 (0.8072) loss_zs_kd 2.2258 (1.7797) loss_oracle 0.9780 (1.0156) kd_loss 1.0554 (1.0165) acc 84.3750 (71.3477) lr 4.6417e-04 eta 0:10:10
epoch [36/50] batch [180/428] time 0.090 (0.098) data 0.000 (0.003) loss 1.6331 (1.8237) teacher_loss 0.5770 (0.8078) loss_zs_kd 1.7478 (1.7788) loss_oracle 1.0870 (1.0151) kd_loss 1.0253 (1.0165) acc 71.8750 (71.3715) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [200/428] time 0.102 (0.099) data 0.000 (0.003) loss 1.7424 (1.8244) teacher_loss 0.7032 (0.8069) loss_zs_kd 1.7513 (1.7839) loss_oracle 1.0627 (1.0172) kd_loss 1.0157 (1.0177) acc 81.2500 (71.5781) lr 4.6417e-04 eta 0:10:15
epoch [36/50] batch [220/428] time 0.098 (0.099) data 0.000 (0.002) loss 2.0828 (1.8266) teacher_loss 1.0343 (0.8086) loss_zs_kd 1.9438 (1.7818) loss_oracle 1.0281 (1.0166) kd_loss 1.0690 (1.0194) acc 59.3750 (71.4205) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [240/428] time 0.112 (0.099) data 0.000 (0.002) loss 1.7806 (1.8314) teacher_loss 0.7896 (0.8123) loss_zs_kd 1.6974 (1.7886) loss_oracle 1.0106 (1.0182) kd_loss 0.9714 (1.0201) acc 87.5000 (71.3542) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [260/428] time 0.106 (0.099) data 0.000 (0.002) loss 1.7959 (1.8315) teacher_loss 0.7698 (0.8119) loss_zs_kd 2.0066 (1.7969) loss_oracle 1.0302 (1.0187) kd_loss 1.0220 (1.0206) acc 71.8750 (71.4423) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [280/428] time 0.101 (0.100) data 0.000 (0.002) loss 1.8788 (1.8278) teacher_loss 0.8570 (0.8076) loss_zs_kd 1.5506 (1.8064) loss_oracle 1.0448 (1.0199) kd_loss 0.9988 (1.0205) acc 75.0000 (71.6518) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [300/428] time 0.103 (0.100) data 0.000 (0.002) loss 1.9522 (1.8322) teacher_loss 0.9361 (0.8115) loss_zs_kd 1.6992 (1.8105) loss_oracle 1.0196 (1.0211) kd_loss 1.0125 (1.0203) acc 75.0000 (71.6458) lr 4.6417e-04 eta 0:10:11
epoch [36/50] batch [320/428] time 0.101 (0.100) data 0.000 (0.002) loss 1.6480 (1.8358) teacher_loss 0.6530 (0.8150) loss_zs_kd 2.0712 (1.8124) loss_oracle 1.0096 (1.0217) kd_loss 0.9804 (1.0198) acc 78.1250 (71.5723) lr 4.6417e-04 eta 0:10:11
epoch [36/50] batch [340/428] time 0.099 (0.100) data 0.000 (0.002) loss 1.7934 (1.8378) teacher_loss 0.8070 (0.8168) loss_zs_kd 2.1928 (1.8140) loss_oracle 0.9878 (1.0219) kd_loss 0.9850 (1.0200) acc 65.6250 (71.4522) lr 4.6417e-04 eta 0:10:09
epoch [36/50] batch [360/428] time 0.103 (0.100) data 0.000 (0.002) loss 1.9537 (1.8416) teacher_loss 0.9442 (0.8203) loss_zs_kd 1.7254 (1.8141) loss_oracle 1.0198 (1.0227) kd_loss 0.9993 (1.0198) acc 68.7500 (71.3455) lr 4.6417e-04 eta 0:10:08
epoch [36/50] batch [380/428] time 0.114 (0.101) data 0.000 (0.002) loss 2.2515 (1.8458) teacher_loss 1.2337 (0.8251) loss_zs_kd 1.5110 (1.8091) loss_oracle 1.0449 (1.0222) kd_loss 0.9907 (1.0192) acc 62.5000 (71.1266) lr 4.6417e-04 eta 0:10:07
epoch [36/50] batch [400/428] time 0.102 (0.101) data 0.000 (0.001) loss 1.9326 (1.8451) teacher_loss 0.9014 (0.8243) loss_zs_kd 1.7584 (1.8021) loss_oracle 1.0508 (1.0221) kd_loss 1.0116 (1.0195) acc 65.6250 (71.0547) lr 4.6417e-04 eta 0:10:06
epoch [36/50] batch [420/428] time 0.096 (0.101) data 0.000 (0.001) loss 1.8840 (1.8470) teacher_loss 0.8716 (0.8260) loss_zs_kd 2.2306 (1.8016) loss_oracle 1.0068 (1.0224) kd_loss 1.0181 (1.0194) acc 65.6250 (70.9226) lr 4.6417e-04 eta 0:10:04
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,723
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 50.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,314
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 32.5%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [37/50] batch [20/428] time 0.100 (0.125) data 0.000 (0.025) loss 1.6340 (1.7543) teacher_loss 0.5681 (0.7419) loss_zs_kd 2.0002 (1.8125) loss_oracle 1.0037 (1.0031) kd_loss 1.1282 (1.0218) acc 81.2500 (73.1250) lr 4.1221e-04 eta 0:12:26
epoch [37/50] batch [40/428] time 0.104 (0.115) data 0.000 (0.013) loss 1.9405 (1.8336) teacher_loss 0.9464 (0.8252) loss_zs_kd 1.5720 (1.8464) loss_oracle 0.9736 (0.9990) kd_loss 1.0145 (1.0177) acc 65.6250 (70.4688) lr 4.1221e-04 eta 0:11:26
epoch [37/50] batch [60/428] time 0.105 (0.112) data 0.000 (0.008) loss 1.7054 (1.8344) teacher_loss 0.7392 (0.8303) loss_zs_kd 2.2586 (1.8527) loss_oracle 0.9373 (0.9935) kd_loss 0.9950 (1.0147) acc 71.8750 (70.6250) lr 4.1221e-04 eta 0:11:05
epoch [37/50] batch [80/428] time 0.114 (0.111) data 0.000 (0.006) loss 2.3796 (1.8326) teacher_loss 1.3959 (0.8287) loss_zs_kd 2.4600 (1.8785) loss_oracle 1.0232 (0.9948) kd_loss 0.9442 (1.0129) acc 59.3750 (71.0547) lr 4.1221e-04 eta 0:10:53
epoch [37/50] batch [100/428] time 0.091 (0.109) data 0.000 (0.005) loss 1.7765 (1.8303) teacher_loss 0.7924 (0.8228) loss_zs_kd 2.0213 (1.8829) loss_oracle 0.9379 (1.0000) kd_loss 1.0304 (1.0150) acc 75.0000 (71.5000) lr 4.1221e-04 eta 0:10:44
epoch [37/50] batch [120/428] time 0.092 (0.109) data 0.000 (0.004) loss 2.0458 (1.8350) teacher_loss 1.0093 (0.8267) loss_zs_kd 2.4753 (1.8683) loss_oracle 1.0164 (1.0019) kd_loss 1.0566 (1.0147) acc 65.6250 (71.2760) lr 4.1221e-04 eta 0:10:37
epoch [37/50] batch [140/428] time 0.099 (0.108) data 0.000 (0.004) loss 2.0165 (1.8392) teacher_loss 1.0009 (0.8277) loss_zs_kd 2.0120 (1.8601) loss_oracle 1.0519 (1.0044) kd_loss 0.9793 (1.0186) acc 62.5000 (70.9821) lr 4.1221e-04 eta 0:10:32
epoch [37/50] batch [160/428] time 0.109 (0.108) data 0.000 (0.003) loss 1.7360 (1.8310) teacher_loss 0.7482 (0.8175) loss_zs_kd 1.5154 (1.8573) loss_oracle 0.9947 (1.0070) kd_loss 0.9809 (1.0201) acc 71.8750 (71.4648) lr 4.1221e-04 eta 0:10:28
epoch [37/50] batch [180/428] time 0.101 (0.108) data 0.000 (0.003) loss 2.1780 (1.8299) teacher_loss 1.1767 (0.8170) loss_zs_kd 2.1481 (1.8635) loss_oracle 0.9556 (1.0069) kd_loss 1.0471 (1.0188) acc 50.0000 (71.3889) lr 4.1221e-04 eta 0:10:25
epoch [37/50] batch [200/428] time 0.108 (0.107) data 0.000 (0.003) loss 1.6598 (1.8309) teacher_loss 0.6202 (0.8187) loss_zs_kd 1.8247 (1.8694) loss_oracle 1.0343 (1.0070) kd_loss 1.0449 (1.0175) acc 78.1250 (71.2969) lr 4.1221e-04 eta 0:10:21
epoch [37/50] batch [220/428] time 0.100 (0.107) data 0.000 (0.003) loss 1.9058 (1.8299) teacher_loss 0.8807 (0.8165) loss_zs_kd 2.1299 (1.8671) loss_oracle 1.0304 (1.0086) kd_loss 1.0198 (1.0184) acc 65.6250 (71.5341) lr 4.1221e-04 eta 0:10:18
epoch [37/50] batch [240/428] time 0.087 (0.107) data 0.000 (0.002) loss 1.6581 (1.8260) teacher_loss 0.6588 (0.8132) loss_zs_kd 1.6889 (1.8596) loss_oracle 1.0036 (1.0087) kd_loss 0.9950 (1.0170) acc 75.0000 (71.7578) lr 4.1221e-04 eta 0:10:16
epoch [37/50] batch [260/428] time 0.101 (0.107) data 0.000 (0.002) loss 1.8588 (1.8222) teacher_loss 0.7987 (0.8081) loss_zs_kd 1.4113 (1.8526) loss_oracle 1.0510 (1.0100) kd_loss 1.0691 (1.0182) acc 71.8750 (71.8990) lr 4.1221e-04 eta 0:10:13
epoch [37/50] batch [280/428] time 0.098 (0.107) data 0.000 (0.002) loss 1.5414 (1.8199) teacher_loss 0.4943 (0.8051) loss_zs_kd 2.1595 (1.8606) loss_oracle 1.0159 (1.0113) kd_loss 1.0783 (1.0183) acc 84.3750 (72.0312) lr 4.1221e-04 eta 0:10:09
epoch [37/50] batch [300/428] time 0.103 (0.107) data 0.000 (0.002) loss 1.8410 (1.8215) teacher_loss 0.8001 (0.8062) loss_zs_kd 1.8591 (1.8608) loss_oracle 1.0590 (1.0127) kd_loss 1.0228 (1.0181) acc 71.8750 (71.9167) lr 4.1221e-04 eta 0:10:06
epoch [37/50] batch [320/428] time 0.117 (0.106) data 0.000 (0.002) loss 1.9200 (1.8217) teacher_loss 0.9323 (0.8067) loss_zs_kd 1.6942 (1.8645) loss_oracle 1.0103 (1.0127) kd_loss 0.9650 (1.0173) acc 75.0000 (71.9434) lr 4.1221e-04 eta 0:10:03
epoch [37/50] batch [340/428] time 0.100 (0.106) data 0.000 (0.002) loss 1.3906 (1.8243) teacher_loss 0.3888 (0.8090) loss_zs_kd 2.0287 (1.8638) loss_oracle 0.9736 (1.0126) kd_loss 1.0301 (1.0182) acc 87.5000 (71.8382) lr 4.1221e-04 eta 0:10:01
epoch [37/50] batch [360/428] time 0.102 (0.106) data 0.000 (0.002) loss 1.9669 (1.8243) teacher_loss 0.9658 (0.8087) loss_zs_kd 1.8745 (1.8641) loss_oracle 1.0225 (1.0128) kd_loss 0.9796 (1.0183) acc 68.7500 (71.8837) lr 4.1221e-04 eta 0:09:58
epoch [37/50] batch [380/428] time 0.108 (0.106) data 0.000 (0.002) loss 1.7650 (1.8292) teacher_loss 0.8128 (0.8141) loss_zs_kd 1.7727 (1.8613) loss_oracle 1.0022 (1.0130) kd_loss 0.9022 (1.0171) acc 71.8750 (71.6694) lr 4.1221e-04 eta 0:09:56
epoch [37/50] batch [400/428] time 0.098 (0.106) data 0.000 (0.002) loss 1.6774 (1.8220) teacher_loss 0.6614 (0.8072) loss_zs_kd 1.5712 (1.8584) loss_oracle 0.9639 (1.0127) kd_loss 1.0682 (1.0170) acc 75.0000 (71.9453) lr 4.1221e-04 eta 0:09:53
epoch [37/50] batch [420/428] time 0.097 (0.106) data 0.000 (0.001) loss 1.9343 (1.8233) teacher_loss 0.8984 (0.8080) loss_zs_kd 1.8536 (1.8567) loss_oracle 1.0168 (1.0135) kd_loss 1.0551 (1.0172) acc 68.7500 (72.0238) lr 4.1221e-04 eta 0:09:51
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,768
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 50.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,243
* accuracy: 47.3%
* error: 52.7%
* macro_f1: 31.4%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [38/50] batch [20/428] time 0.110 (0.129) data 0.000 (0.026) loss 1.9142 (1.7906) teacher_loss 0.9119 (0.7753) loss_zs_kd 1.5162 (1.7505) loss_oracle 1.0122 (1.0261) kd_loss 0.9925 (1.0045) acc 71.8750 (72.6562) lr 3.6258e-04 eta 0:11:53
epoch [38/50] batch [40/428] time 0.113 (0.117) data 0.000 (0.013) loss 1.7565 (1.7867) teacher_loss 0.7514 (0.7755) loss_zs_kd 1.8239 (1.8101) loss_oracle 0.9767 (1.0164) kd_loss 1.0335 (1.0060) acc 65.6250 (72.5000) lr 3.6258e-04 eta 0:10:44
epoch [38/50] batch [60/428] time 0.106 (0.113) data 0.000 (0.009) loss 2.1354 (1.7904) teacher_loss 1.1676 (0.7798) loss_zs_kd 1.8948 (1.8138) loss_oracle 0.9506 (1.0137) kd_loss 0.9850 (1.0075) acc 65.6250 (72.4479) lr 3.6258e-04 eta 0:10:22
epoch [38/50] batch [80/428] time 0.091 (0.111) data 0.000 (0.007) loss 2.2843 (1.7994) teacher_loss 1.3380 (0.7888) loss_zs_kd 1.7437 (1.8267) loss_oracle 0.9577 (1.0118) kd_loss 0.9348 (1.0095) acc 53.1250 (71.6406) lr 3.6258e-04 eta 0:10:08
epoch [38/50] batch [100/428] time 0.104 (0.110) data 0.000 (0.005) loss 1.4528 (1.7995) teacher_loss 0.4268 (0.7882) loss_zs_kd 1.9353 (1.8322) loss_oracle 1.0149 (1.0118) kd_loss 1.0371 (1.0108) acc 84.3750 (71.9688) lr 3.6258e-04 eta 0:10:00
epoch [38/50] batch [120/428] time 0.099 (0.109) data 0.000 (0.005) loss 1.6845 (1.7935) teacher_loss 0.7434 (0.7847) loss_zs_kd 1.5154 (1.8573) loss_oracle 0.9217 (1.0097) kd_loss 0.9606 (1.0078) acc 75.0000 (72.3958) lr 3.6258e-04 eta 0:09:55
epoch [38/50] batch [140/428] time 0.092 (0.107) data 0.000 (0.004) loss 1.6279 (1.7982) teacher_loss 0.6091 (0.7903) loss_zs_kd 2.0556 (1.8739) loss_oracle 1.0145 (1.0086) kd_loss 1.0231 (1.0070) acc 81.2500 (72.3438) lr 3.6258e-04 eta 0:09:39
epoch [38/50] batch [160/428] time 0.102 (0.106) data 0.000 (0.003) loss 1.7057 (1.8032) teacher_loss 0.6678 (0.7961) loss_zs_kd 2.1327 (1.8758) loss_oracle 1.0404 (1.0071) kd_loss 1.0353 (1.0070) acc 75.0000 (71.9922) lr 3.6258e-04 eta 0:09:34
epoch [38/50] batch [180/428] time 0.106 (0.106) data 0.000 (0.003) loss 1.7307 (1.8026) teacher_loss 0.6727 (0.7959) loss_zs_kd 1.8843 (1.8704) loss_oracle 1.0480 (1.0058) kd_loss 1.0679 (1.0074) acc 71.8750 (72.0660) lr 3.6258e-04 eta 0:09:31
epoch [38/50] batch [200/428] time 0.110 (0.106) data 0.000 (0.003) loss 1.8497 (1.8137) teacher_loss 0.8581 (0.8083) loss_zs_kd 1.6247 (1.8684) loss_oracle 0.9734 (1.0036) kd_loss 1.0097 (1.0072) acc 68.7500 (71.7188) lr 3.6258e-04 eta 0:09:28
epoch [38/50] batch [220/428] time 0.107 (0.106) data 0.000 (0.003) loss 1.8690 (1.8097) teacher_loss 0.8255 (0.8045) loss_zs_kd 1.8933 (1.8692) loss_oracle 1.0230 (1.0021) kd_loss 1.0640 (1.0084) acc 78.1250 (71.9176) lr 3.6258e-04 eta 0:09:26
epoch [38/50] batch [240/428] time 0.113 (0.106) data 0.000 (0.002) loss 1.7341 (1.8104) teacher_loss 0.7307 (0.8053) loss_zs_kd 1.6850 (1.8707) loss_oracle 0.9677 (1.0013) kd_loss 1.0392 (1.0088) acc 75.0000 (71.8750) lr 3.6258e-04 eta 0:09:24
epoch [38/50] batch [260/428] time 0.097 (0.106) data 0.000 (0.002) loss 1.6502 (1.8076) teacher_loss 0.6280 (0.8020) loss_zs_kd 2.2774 (1.8699) loss_oracle 0.9995 (1.0011) kd_loss 1.0450 (1.0101) acc 78.1250 (71.7909) lr 3.6258e-04 eta 0:09:21
epoch [38/50] batch [280/428] time 0.104 (0.106) data 0.000 (0.002) loss 1.7553 (1.8096) teacher_loss 0.7607 (0.8031) loss_zs_kd 2.0612 (1.8710) loss_oracle 0.9767 (1.0021) kd_loss 1.0126 (1.0110) acc 78.1250 (71.7522) lr 3.6258e-04 eta 0:09:20
epoch [38/50] batch [300/428] time 0.103 (0.106) data 0.000 (0.002) loss 1.5688 (1.8119) teacher_loss 0.4968 (0.8053) loss_zs_kd 1.8910 (1.8709) loss_oracle 1.0604 (1.0022) kd_loss 1.0836 (1.0111) acc 93.7500 (71.6875) lr 3.6258e-04 eta 0:09:18
epoch [38/50] batch [320/428] time 0.110 (0.106) data 0.000 (0.002) loss 1.8722 (1.8111) teacher_loss 0.8407 (0.8037) loss_zs_kd 1.8223 (1.8715) loss_oracle 1.0218 (1.0029) kd_loss 1.0412 (1.0118) acc 65.6250 (71.7969) lr 3.6258e-04 eta 0:09:15
epoch [38/50] batch [340/428] time 0.094 (0.106) data 0.000 (0.002) loss 2.0625 (1.8146) teacher_loss 1.0529 (0.8075) loss_zs_kd 1.5655 (1.8671) loss_oracle 1.0400 (1.0033) kd_loss 0.9792 (1.0109) acc 59.3750 (71.7555) lr 3.6258e-04 eta 0:09:12
epoch [38/50] batch [360/428] time 0.096 (0.106) data 0.000 (0.002) loss 1.5453 (1.8183) teacher_loss 0.5289 (0.8109) loss_zs_kd 1.6846 (1.8702) loss_oracle 1.0012 (1.0036) kd_loss 1.0316 (1.0113) acc 84.3750 (71.7014) lr 3.6258e-04 eta 0:09:09
epoch [38/50] batch [380/428] time 0.105 (0.105) data 0.000 (0.002) loss 2.1066 (1.8206) teacher_loss 1.1401 (0.8126) loss_zs_kd 1.7517 (1.8717) loss_oracle 0.9847 (1.0041) kd_loss 0.9483 (1.0119) acc 53.1250 (71.5954) lr 3.6258e-04 eta 0:09:06
epoch [38/50] batch [400/428] time 0.105 (0.105) data 0.000 (0.002) loss 1.6504 (1.8255) teacher_loss 0.5836 (0.8174) loss_zs_kd 1.8911 (1.8732) loss_oracle 1.0355 (1.0033) kd_loss 1.0981 (1.0127) acc 90.6250 (71.5000) lr 3.6258e-04 eta 0:09:03
epoch [38/50] batch [420/428] time 0.092 (0.105) data 0.000 (0.001) loss 1.4898 (1.8223) teacher_loss 0.4664 (0.8147) loss_zs_kd 1.7036 (1.8695) loss_oracle 1.0472 (1.0026) kd_loss 0.9995 (1.0126) acc 87.5000 (71.6369) lr 3.6258e-04 eta 0:08:59
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,796
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 51.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,186
* accuracy: 46.1%
* error: 53.9%
* macro_f1: 32.3%
******* Domain 1 best val acc:      64.7%, epoch: 29 *******
******* Domain 1 best val test acc: 46.3%, epoch: 29 *******
******* Domain 1 best test acc:     52.6%, epoch: 18 *******
epoch [39/50] batch [20/428] time 0.100 (0.126) data 0.000 (0.024) loss 1.7808 (1.8078) teacher_loss 0.7409 (0.8006) loss_zs_kd 1.9954 (1.7967) loss_oracle 1.0111 (0.9887) kd_loss 1.0687 (1.0255) acc 68.7500 (70.1562) lr 3.1545e-04 eta 0:10:45
epoch [39/50] batch [40/428] time 0.099 (0.114) data 0.000 (0.012) loss 1.8865 (1.8360) teacher_loss 0.8547 (0.8271) loss_zs_kd 1.6573 (1.8097) loss_oracle 1.0128 (0.9954) kd_loss 1.0508 (1.0224) acc 75.0000 (70.3125) lr 3.1545e-04 eta 0:09:40
epoch [39/50] batch [60/428] time 0.078 (0.110) data 0.001 (0.008) loss 2.0078 (1.8356) teacher_loss 0.9891 (0.8233) loss_zs_kd 1.8406 (1.8267) loss_oracle 1.0074 (0.9993) kd_loss 1.0299 (1.0254) acc 71.8750 (69.8438) lr 3.1545e-04 eta 0:09:16

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_38', 'location_43', 'location_46']
Target     ['location_100']
# classes  10
# train_x  13,713
# val      5,876
# test     4,741
---------  ---------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/428] time 0.095 (0.147) data 0.000 (0.029) loss 3.4586 (3.4000) teacher_loss 2.5110 (2.4742) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0083 (0.0047) acc 31.2500 (23.5938) lr 1.0000e-05 eta 0:52:15
epoch [1/50] batch [40/428] time 0.092 (0.122) data 0.000 (0.015) loss 3.4750 (3.3253) teacher_loss 2.4987 (2.4004) loss_zs_kd 0.0017 (0.0004) loss_oracle 0.0061 (0.0066) acc 18.7500 (25.7812) lr 1.0000e-05 eta 0:43:18
epoch [1/50] batch [60/428] time 0.084 (0.111) data 0.000 (0.010) loss 3.4727 (3.3022) teacher_loss 2.5710 (2.3780) loss_zs_kd 0.0044 (0.0013) loss_oracle 0.0125 (0.0091) acc 28.1250 (26.3021) lr 1.0000e-05 eta 0:39:32
epoch [1/50] batch [80/428] time 0.091 (0.108) data 0.000 (0.008) loss 3.1995 (3.2793) teacher_loss 2.2729 (2.3551) loss_zs_kd 0.0079 (0.0028) loss_oracle 0.0382 (0.0115) acc 31.2500 (26.6406) lr 1.0000e-05 eta 0:38:24
epoch [1/50] batch [100/428] time 0.098 (0.107) data 0.000 (0.006) loss 3.3195 (3.2687) teacher_loss 2.3492 (2.3319) loss_zs_kd 0.0135 (0.0049) loss_oracle 0.1099 (0.0270) acc 28.1250 (27.0312) lr 1.0000e-05 eta 0:37:58
epoch [1/50] batch [120/428] time 0.090 (0.105) data 0.000 (0.005) loss 3.2626 (3.2598) teacher_loss 2.2643 (2.3087) loss_zs_kd 0.0291 (0.0076) loss_oracle 0.2898 (0.0584) acc 37.5000 (27.6823) lr 1.0000e-05 eta 0:37:08
epoch [1/50] batch [140/428] time 0.099 (0.103) data 0.000 (0.004) loss 3.4035 (3.2819) teacher_loss 2.2071 (2.3049) loss_zs_kd 0.0460 (0.0114) loss_oracle 0.4274 (0.1047) acc 21.8750 (27.8125) lr 1.0000e-05 eta 0:36:37
epoch [1/50] batch [160/428] time 0.121 (0.102) data 0.000 (0.004) loss 3.4510 (3.2849) teacher_loss 2.0185 (2.2749) loss_zs_kd 0.1480 (0.0211) loss_oracle 0.8699 (0.1661) acc 37.5000 (28.3984) lr 1.0000e-05 eta 0:36:15
epoch [1/50] batch [180/428] time 0.101 (0.102) data 0.000 (0.004) loss 3.6414 (3.2944) teacher_loss 2.3319 (2.2424) loss_zs_kd 0.1935 (0.0463) loss_oracle 0.7864 (0.2395) acc 28.1250 (29.2188) lr 1.0000e-05 eta 0:36:12
epoch [1/50] batch [200/428] time 0.071 (0.102) data 0.000 (0.003) loss 3.5013 (3.3162) teacher_loss 1.9698 (2.2185) loss_zs_kd 0.3494 (0.0721) loss_oracle 1.0129 (0.3138) acc 43.7500 (29.7344) lr 1.0000e-05 eta 0:36:02
epoch [1/50] batch [220/428] time 0.159 (0.102) data 0.000 (0.003) loss 3.7494 (3.3274) teacher_loss 2.3816 (2.1980) loss_zs_kd 0.2364 (0.0928) loss_oracle 0.7043 (0.3647) acc 31.2500 (30.3835) lr 1.0000e-05 eta 0:35:50
epoch [1/50] batch [240/428] time 0.207 (0.102) data 0.000 (0.003) loss 3.4362 (3.3337) teacher_loss 1.9445 (2.1775) loss_zs_kd 0.3025 (0.1136) loss_oracle 0.9014 (0.4070) acc 37.5000 (30.9115) lr 1.0000e-05 eta 0:35:58
epoch [1/50] batch [260/428] time 0.149 (0.103) data 0.000 (0.003) loss 3.9396 (3.3366) teacher_loss 2.4204 (2.1573) loss_zs_kd 0.2817 (0.1322) loss_oracle 0.9848 (0.4455) acc 34.3750 (31.3822) lr 1.0000e-05 eta 0:36:19
epoch [1/50] batch [280/428] time 0.080 (0.104) data 0.000 (0.002) loss 3.1703 (3.3332) teacher_loss 1.6045 (2.1343) loss_zs_kd 0.4544 (0.1502) loss_oracle 1.0047 (0.4771) acc 50.0000 (31.9531) lr 1.0000e-05 eta 0:36:29
epoch [1/50] batch [300/428] time 0.082 (0.103) data 0.000 (0.002) loss 3.7408 (3.3352) teacher_loss 2.1609 (2.1144) loss_zs_kd 0.4689 (0.1671) loss_oracle 1.0490 (0.5125) acc 25.0000 (32.4583) lr 1.0000e-05 eta 0:36:10
epoch [1/50] batch [320/428] time 0.085 (0.103) data 0.000 (0.002) loss 3.4185 (3.3365) teacher_loss 1.7951 (2.0954) loss_zs_kd 0.4809 (0.1842) loss_oracle 1.1028 (0.5456) acc 37.5000 (32.8711) lr 1.0000e-05 eta 0:36:05
epoch [1/50] batch [340/428] time 0.080 (0.102) data 0.000 (0.002) loss 3.5324 (3.3367) teacher_loss 1.9447 (2.0790) loss_zs_kd 0.3666 (0.1991) loss_oracle 1.0439 (0.5736) acc 40.6250 (33.2537) lr 1.0000e-05 eta 0:35:53
epoch [1/50] batch [360/428] time 0.081 (0.103) data 0.000 (0.002) loss 3.1850 (3.3364) teacher_loss 1.5967 (2.0622) loss_zs_kd 0.4916 (0.2137) loss_oracle 1.0434 (0.5991) acc 50.0000 (33.6111) lr 1.0000e-05 eta 0:36:06
epoch [1/50] batch [380/428] time 0.067 (0.103) data 0.000 (0.002) loss 3.6930 (3.3406) teacher_loss 2.1736 (2.0517) loss_zs_kd 0.5229 (0.2268) loss_oracle 1.0679 (0.6223) acc 25.0000 (33.8322) lr 1.0000e-05 eta 0:36:13
epoch [1/50] batch [400/428] time 0.092 (0.103) data 0.000 (0.002) loss 3.2505 (3.3404) teacher_loss 1.6637 (2.0372) loss_zs_kd 0.6545 (0.2422) loss_oracle 1.0547 (0.6433) acc 53.1250 (34.2109) lr 1.0000e-05 eta 0:36:08
epoch [1/50] batch [420/428] time 0.090 (0.103) data 0.000 (0.002) loss 3.6242 (3.3378) teacher_loss 2.0326 (2.0232) loss_zs_kd 0.4841 (0.2532) loss_oracle 1.0343 (0.6612) acc 34.3750 (34.5833) lr 1.0000e-05 eta 0:36:01
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,422
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 25.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,088
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 28.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      41.2%, epoch: 1 *******
******* Domain 1 best val test acc: 44.0%, epoch: 1 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [2/50] batch [20/428] time 0.096 (0.131) data 0.000 (0.034) loss 3.2511 (3.4198) teacher_loss 1.7492 (1.8821) loss_zs_kd 0.5494 (0.3989) loss_oracle 1.0682 (1.0204) acc 46.8750 (38.1250) lr 2.0000e-03 eta 0:45:41
epoch [2/50] batch [40/428] time 0.089 (0.111) data 0.000 (0.017) loss 3.3214 (3.2952) teacher_loss 1.7473 (1.7676) loss_zs_kd 0.7010 (0.5088) loss_oracle 1.0261 (1.0106) acc 40.6250 (40.0000) lr 2.0000e-03 eta 0:38:40
epoch [2/50] batch [60/428] time 0.089 (0.104) data 0.000 (0.011) loss 3.0102 (3.2159) teacher_loss 1.4667 (1.6797) loss_zs_kd 0.6525 (0.5371) loss_oracle 1.0239 (1.0126) acc 62.5000 (42.7604) lr 2.0000e-03 eta 0:36:08
epoch [2/50] batch [80/428] time 0.092 (0.100) data 0.000 (0.009) loss 3.1740 (3.1432) teacher_loss 1.6500 (1.6088) loss_zs_kd 0.7908 (0.5848) loss_oracle 1.0288 (1.0194) acc 50.0000 (45.2734) lr 2.0000e-03 eta 0:34:46
epoch [2/50] batch [100/428] time 0.082 (0.099) data 0.000 (0.007) loss 3.0787 (3.0911) teacher_loss 1.6000 (1.5593) loss_zs_kd 0.8812 (0.6933) loss_oracle 1.0244 (1.0189) acc 43.7500 (47.1562) lr 2.0000e-03 eta 0:34:33
epoch [2/50] batch [120/428] time 0.069 (0.097) data 0.000 (0.006) loss 3.3128 (3.0759) teacher_loss 1.8337 (1.5493) loss_zs_kd 1.0772 (0.7200) loss_oracle 1.0296 (1.0162) acc 31.2500 (47.3438) lr 2.0000e-03 eta 0:33:50
epoch [2/50] batch [140/428] time 0.150 (0.097) data 0.000 (0.005) loss 2.5282 (3.0328) teacher_loss 1.0795 (1.5094) loss_zs_kd 1.1108 (0.7896) loss_oracle 0.9882 (1.0146) acc 65.6250 (48.3929) lr 2.0000e-03 eta 0:33:47
epoch [2/50] batch [160/428] time 0.125 (0.096) data 0.000 (0.004) loss 2.7751 (3.0049) teacher_loss 1.1966 (1.4811) loss_zs_kd 1.1619 (0.8488) loss_oracle 1.0329 (1.0129) acc 62.5000 (49.3555) lr 2.0000e-03 eta 0:33:28
epoch [2/50] batch [180/428] time 0.074 (0.096) data 0.000 (0.004) loss 2.5795 (2.9803) teacher_loss 1.0058 (1.4532) loss_zs_kd 1.2846 (0.8987) loss_oracle 1.0798 (1.0152) acc 65.6250 (50.2257) lr 2.0000e-03 eta 0:33:08
epoch [2/50] batch [200/428] time 0.158 (0.097) data 0.000 (0.004) loss 2.5558 (2.9567) teacher_loss 1.0430 (1.4280) loss_zs_kd 1.1492 (0.9202) loss_oracle 1.0350 (1.0176) acc 62.5000 (51.2812) lr 2.0000e-03 eta 0:33:37
epoch [2/50] batch [220/428] time 0.084 (0.097) data 0.000 (0.003) loss 2.4381 (2.9226) teacher_loss 0.9579 (1.3935) loss_zs_kd 1.1876 (0.9688) loss_oracle 1.0093 (1.0188) acc 68.7500 (52.5142) lr 2.0000e-03 eta 0:33:36
epoch [2/50] batch [240/428] time 0.079 (0.097) data 0.000 (0.003) loss 2.4084 (2.8942) teacher_loss 0.8396 (1.3646) loss_zs_kd 1.4118 (1.0027) loss_oracle 1.0939 (1.0194) acc 75.0000 (53.6328) lr 2.0000e-03 eta 0:33:21
epoch [2/50] batch [260/428] time 0.088 (0.096) data 0.000 (0.003) loss 2.4223 (2.8744) teacher_loss 0.7876 (1.3431) loss_zs_kd 1.4413 (1.0484) loss_oracle 1.1058 (1.0207) acc 78.1250 (54.3870) lr 2.0000e-03 eta 0:33:07
epoch [2/50] batch [280/428] time 0.064 (0.097) data 0.000 (0.003) loss 2.8983 (2.8651) teacher_loss 1.3439 (1.3328) loss_zs_kd 1.4231 (1.0780) loss_oracle 1.0884 (1.0235) acc 65.6250 (54.7545) lr 2.0000e-03 eta 0:33:16
epoch [2/50] batch [300/428] time 0.151 (0.097) data 0.000 (0.002) loss 2.9319 (2.8557) teacher_loss 1.3822 (1.3232) loss_zs_kd 1.5624 (1.1023) loss_oracle 1.0419 (1.0251) acc 50.0000 (55.0208) lr 2.0000e-03 eta 0:33:15
epoch [2/50] batch [320/428] time 0.146 (0.097) data 0.000 (0.002) loss 2.6658 (2.8436) teacher_loss 1.1220 (1.3098) loss_zs_kd 1.5474 (1.1296) loss_oracle 1.0757 (1.0264) acc 53.1250 (55.3027) lr 2.0000e-03 eta 0:33:30
epoch [2/50] batch [340/428] time 0.073 (0.097) data 0.000 (0.002) loss 2.4923 (2.8298) teacher_loss 0.9029 (1.2946) loss_zs_kd 1.6182 (1.1590) loss_oracle 1.0760 (1.0283) acc 62.5000 (55.6434) lr 2.0000e-03 eta 0:33:24
epoch [2/50] batch [360/428] time 0.093 (0.097) data 0.000 (0.002) loss 2.1369 (2.8171) teacher_loss 0.6420 (1.2800) loss_zs_kd 1.1204 (1.1731) loss_oracle 0.9996 (1.0304) acc 84.3750 (56.0243) lr 2.0000e-03 eta 0:33:12
epoch [2/50] batch [380/428] time 0.088 (0.097) data 0.000 (0.002) loss 2.6041 (2.8111) teacher_loss 1.0978 (1.2739) loss_zs_kd 1.4343 (1.1806) loss_oracle 1.0219 (1.0310) acc 62.5000 (56.0362) lr 2.0000e-03 eta 0:33:09
epoch [2/50] batch [400/428] time 0.090 (0.096) data 0.000 (0.002) loss 2.6115 (2.8095) teacher_loss 1.1400 (1.2741) loss_zs_kd 1.4026 (1.1865) loss_oracle 1.0020 (1.0307) acc 68.7500 (55.9062) lr 2.0000e-03 eta 0:32:59
epoch [2/50] batch [420/428] time 0.087 (0.096) data 0.000 (0.002) loss 2.5140 (2.8032) teacher_loss 1.0158 (1.2687) loss_zs_kd 1.5931 (1.2106) loss_oracle 1.0104 (1.0316) acc 65.6250 (56.1384) lr 2.0000e-03 eta 0:32:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,909
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 28.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,818
* accuracy: 38.3%
* error: 61.7%
* macro_f1: 25.6%
******* Domain 1 best val acc:      49.5%, epoch: 2 *******
******* Domain 1 best val test acc: 38.3%, epoch: 2 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [3/50] batch [20/428] time 0.106 (0.130) data 0.000 (0.025) loss 2.8339 (2.7730) teacher_loss 1.3029 (1.2796) loss_zs_kd 1.3845 (1.2911) loss_oracle 1.0565 (1.0318) acc 59.3750 (53.9062) lr 1.9980e-03 eta 0:44:35
epoch [3/50] batch [40/428] time 0.092 (0.115) data 0.000 (0.013) loss 2.8646 (2.7532) teacher_loss 1.4032 (1.2801) loss_zs_kd 1.2356 (1.2386) loss_oracle 1.0358 (1.0190) acc 46.8750 (53.5156) lr 1.9980e-03 eta 0:39:13
epoch [3/50] batch [60/428] time 0.111 (0.111) data 0.001 (0.009) loss 2.9076 (2.7284) teacher_loss 1.3886 (1.2590) loss_zs_kd 1.2782 (1.2724) loss_oracle 1.0570 (1.0177) acc 50.0000 (55.2083) lr 1.9980e-03 eta 0:37:43
epoch [3/50] batch [80/428] time 0.099 (0.108) data 0.000 (0.007) loss 2.3116 (2.7124) teacher_loss 0.8765 (1.2385) loss_zs_kd 1.4709 (1.3141) loss_oracle 0.9853 (1.0230) acc 71.8750 (55.8594) lr 1.9980e-03 eta 0:36:51
epoch [3/50] batch [100/428] time 0.159 (0.104) data 0.000 (0.005) loss 2.9990 (2.7083) teacher_loss 1.4567 (1.2272) loss_zs_kd 1.5049 (1.3135) loss_oracle 1.0513 (1.0287) acc 53.1250 (56.6562) lr 1.9980e-03 eta 0:35:35
epoch [3/50] batch [120/428] time 0.077 (0.106) data 0.000 (0.004) loss 2.8238 (2.6966) teacher_loss 1.2310 (1.1965) loss_zs_kd 1.4634 (1.3383) loss_oracle 1.1159 (1.0404) acc 65.6250 (57.8646) lr 1.9980e-03 eta 0:35:54
epoch [3/50] batch [140/428] time 0.191 (0.106) data 0.000 (0.004) loss 2.7531 (2.6875) teacher_loss 1.1970 (1.1793) loss_zs_kd 1.8327 (1.3678) loss_oracle 1.1051 (1.0469) acc 50.0000 (58.4598) lr 1.9980e-03 eta 0:36:06
epoch [3/50] batch [160/428] time 0.074 (0.106) data 0.000 (0.003) loss 2.7766 (2.6838) teacher_loss 1.3560 (1.1805) loss_zs_kd 1.4275 (1.3991) loss_oracle 0.9779 (1.0424) acc 53.1250 (58.5547) lr 1.9980e-03 eta 0:35:50
epoch [3/50] batch [180/428] time 0.213 (0.106) data 0.001 (0.003) loss 2.4512 (2.6672) teacher_loss 0.8516 (1.1648) loss_zs_kd 1.8655 (1.4177) loss_oracle 1.0603 (1.0419) acc 75.0000 (59.0451) lr 1.9980e-03 eta 0:36:01
epoch [3/50] batch [200/428] time 0.106 (0.104) data 0.000 (0.003) loss 2.5768 (2.6642) teacher_loss 0.9515 (1.1505) loss_zs_kd 1.4573 (1.4517) loss_oracle 1.1148 (1.0507) acc 62.5000 (59.7500) lr 1.9980e-03 eta 0:35:17
epoch [3/50] batch [220/428] time 0.077 (0.104) data 0.000 (0.003) loss 2.6131 (2.6581) teacher_loss 1.0409 (1.1393) loss_zs_kd 1.9169 (1.4720) loss_oracle 1.0793 (1.0556) acc 62.5000 (60.0284) lr 1.9980e-03 eta 0:35:23
epoch [3/50] batch [240/428] time 0.072 (0.104) data 0.000 (0.002) loss 2.4005 (2.6520) teacher_loss 0.8096 (1.1281) loss_zs_kd 1.5080 (1.4729) loss_oracle 1.1353 (1.0594) acc 78.1250 (60.4948) lr 1.9980e-03 eta 0:35:19
epoch [3/50] batch [260/428] time 0.082 (0.105) data 0.000 (0.002) loss 2.8886 (2.6493) teacher_loss 1.2669 (1.1205) loss_zs_kd 1.4644 (1.4806) loss_oracle 1.1268 (1.0641) acc 56.2500 (60.8534) lr 1.9980e-03 eta 0:35:31
epoch [3/50] batch [280/428] time 0.076 (0.105) data 0.000 (0.002) loss 2.5263 (2.6523) teacher_loss 0.9154 (1.1176) loss_zs_kd 1.5858 (1.4796) loss_oracle 1.1308 (1.0679) acc 62.5000 (61.0045) lr 1.9980e-03 eta 0:35:29
epoch [3/50] batch [300/428] time 0.093 (0.104) data 0.000 (0.002) loss 2.5672 (2.6493) teacher_loss 0.9261 (1.1087) loss_zs_kd 1.3242 (1.4735) loss_oracle 1.0976 (1.0701) acc 71.8750 (61.4062) lr 1.9980e-03 eta 0:35:11
epoch [3/50] batch [320/428] time 0.082 (0.104) data 0.000 (0.002) loss 2.3708 (2.6365) teacher_loss 0.7386 (1.0931) loss_zs_kd 1.3901 (1.4715) loss_oracle 1.1165 (1.0709) acc 75.0000 (62.0215) lr 1.9980e-03 eta 0:35:07
epoch [3/50] batch [340/428] time 0.089 (0.103) data 0.000 (0.002) loss 2.5774 (2.6326) teacher_loss 0.9183 (1.0830) loss_zs_kd 1.4483 (1.4828) loss_oracle 1.1200 (1.0749) acc 71.8750 (62.5000) lr 1.9980e-03 eta 0:34:50
epoch [3/50] batch [360/428] time 0.108 (0.103) data 0.000 (0.002) loss 2.5601 (2.6268) teacher_loss 0.9410 (1.0720) loss_zs_kd 1.5502 (1.4899) loss_oracle 1.1471 (1.0787) acc 71.8750 (62.8646) lr 1.9980e-03 eta 0:34:46
epoch [3/50] batch [380/428] time 0.115 (0.103) data 0.000 (0.002) loss 2.7585 (2.6257) teacher_loss 1.1988 (1.0680) loss_zs_kd 1.3388 (1.4901) loss_oracle 1.1035 (1.0811) acc 56.2500 (62.9194) lr 1.9980e-03 eta 0:34:41
epoch [3/50] batch [400/428] time 0.085 (0.103) data 0.000 (0.002) loss 2.6242 (2.6218) teacher_loss 1.0040 (1.0628) loss_zs_kd 1.8720 (1.4890) loss_oracle 1.1672 (1.0829) acc 68.7500 (63.1484) lr 1.9980e-03 eta 0:34:31
epoch [3/50] batch [420/428] time 0.093 (0.103) data 0.000 (0.001) loss 2.3730 (2.6157) teacher_loss 0.7950 (1.0547) loss_zs_kd 1.7298 (1.4947) loss_oracle 1.0912 (1.0844) acc 75.0000 (63.4301) lr 1.9980e-03 eta 0:34:27
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,116
* accuracy: 53.0%
* error: 47.0%
* macro_f1: 34.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,147
* accuracy: 45.3%
* error: 54.7%
* macro_f1: 27.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      53.0%, epoch: 3 *******
******* Domain 1 best val test acc: 45.3%, epoch: 3 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [4/50] batch [20/428] time 0.085 (0.125) data 0.000 (0.024) loss 2.8852 (2.5203) teacher_loss 1.2132 (0.9277) loss_zs_kd 1.4183 (1.5193) loss_oracle 1.1258 (1.0988) acc 50.0000 (67.0312) lr 1.9921e-03 eta 0:41:54
epoch [4/50] batch [40/428] time 0.179 (0.116) data 0.000 (0.012) loss 2.6143 (2.5502) teacher_loss 0.9570 (0.9488) loss_zs_kd 1.6202 (1.5075) loss_oracle 1.1437 (1.1111) acc 75.0000 (67.5000) lr 1.9921e-03 eta 0:38:52
epoch [4/50] batch [60/428] time 0.155 (0.115) data 0.001 (0.008) loss 2.9243 (2.5630) teacher_loss 1.3549 (0.9644) loss_zs_kd 1.5328 (1.5229) loss_oracle 1.1006 (1.1129) acc 56.2500 (66.4583) lr 1.9921e-03 eta 0:38:21
epoch [4/50] batch [80/428] time 0.087 (0.113) data 0.000 (0.006) loss 2.7045 (2.5666) teacher_loss 1.1535 (0.9735) loss_zs_kd 1.2122 (1.5073) loss_oracle 1.0895 (1.1112) acc 65.6250 (66.0156) lr 1.9921e-03 eta 0:37:49
epoch [4/50] batch [100/428] time 0.079 (0.112) data 0.000 (0.005) loss 2.3801 (2.5801) teacher_loss 0.8273 (0.9861) loss_zs_kd 1.6184 (1.5068) loss_oracle 1.1150 (1.1131) acc 71.8750 (65.5625) lr 1.9921e-03 eta 0:37:16
epoch [4/50] batch [120/428] time 0.076 (0.109) data 0.000 (0.004) loss 2.5658 (2.5765) teacher_loss 1.0868 (0.9873) loss_zs_kd 1.2467 (1.4783) loss_oracle 1.0536 (1.1111) acc 46.8750 (65.6771) lr 1.9921e-03 eta 0:36:12
epoch [4/50] batch [140/428] time 0.076 (0.109) data 0.000 (0.004) loss 2.6575 (2.5866) teacher_loss 1.1014 (1.0039) loss_zs_kd 1.3958 (1.4432) loss_oracle 1.1077 (1.1076) acc 62.5000 (65.4464) lr 1.9921e-03 eta 0:36:26
epoch [4/50] batch [160/428] time 0.077 (0.110) data 0.000 (0.003) loss 2.5252 (2.6026) teacher_loss 0.9121 (1.0227) loss_zs_kd 1.2211 (1.4338) loss_oracle 1.1497 (1.1055) acc 68.7500 (64.4922) lr 1.9921e-03 eta 0:36:34
epoch [4/50] batch [180/428] time 0.106 (0.111) data 0.000 (0.003) loss 3.0129 (2.6108) teacher_loss 1.4401 (1.0310) loss_zs_kd 1.2070 (1.4110) loss_oracle 1.0316 (1.1046) acc 43.7500 (63.9583) lr 1.9921e-03 eta 0:36:58
epoch [4/50] batch [200/428] time 0.091 (0.108) data 0.000 (0.003) loss 2.5184 (2.6097) teacher_loss 0.9785 (1.0290) loss_zs_kd 1.2054 (1.3922) loss_oracle 1.0907 (1.1045) acc 65.6250 (64.0781) lr 1.9921e-03 eta 0:35:59
epoch [4/50] batch [220/428] time 0.092 (0.107) data 0.000 (0.002) loss 2.5336 (2.6187) teacher_loss 0.9867 (1.0368) loss_zs_kd 1.3765 (1.3913) loss_oracle 1.1015 (1.1053) acc 62.5000 (63.8210) lr 1.9921e-03 eta 0:35:25
epoch [4/50] batch [240/428] time 0.088 (0.106) data 0.000 (0.002) loss 2.5426 (2.6098) teacher_loss 0.9535 (1.0276) loss_zs_kd 1.4408 (1.3901) loss_oracle 1.1029 (1.1041) acc 68.7500 (64.1406) lr 1.9921e-03 eta 0:35:05
epoch [4/50] batch [260/428] time 0.096 (0.105) data 0.000 (0.002) loss 2.6014 (2.6079) teacher_loss 1.0075 (1.0241) loss_zs_kd 1.5990 (1.4047) loss_oracle 1.0893 (1.1039) acc 56.2500 (64.1106) lr 1.9921e-03 eta 0:34:52
epoch [4/50] batch [280/428] time 0.105 (0.105) data 0.000 (0.002) loss 2.4115 (2.6016) teacher_loss 0.8530 (1.0183) loss_zs_kd 1.4689 (1.4067) loss_oracle 1.0740 (1.1035) acc 75.0000 (64.4085) lr 1.9921e-03 eta 0:34:48
epoch [4/50] batch [300/428] time 0.104 (0.105) data 0.000 (0.002) loss 2.3457 (2.5985) teacher_loss 0.7758 (1.0154) loss_zs_kd 1.4929 (1.4093) loss_oracle 1.0998 (1.1029) acc 78.1250 (64.6354) lr 1.9921e-03 eta 0:34:42
epoch [4/50] batch [320/428] time 0.090 (0.105) data 0.000 (0.002) loss 2.6311 (2.5921) teacher_loss 1.0455 (1.0078) loss_zs_kd 1.7886 (1.4198) loss_oracle 1.0835 (1.1026) acc 62.5000 (64.9023) lr 1.9921e-03 eta 0:34:36
epoch [4/50] batch [340/428] time 0.098 (0.105) data 0.000 (0.002) loss 2.6417 (2.5836) teacher_loss 1.0782 (0.9994) loss_zs_kd 1.7989 (1.4365) loss_oracle 1.0957 (1.1016) acc 62.5000 (65.2849) lr 1.9921e-03 eta 0:34:38
epoch [4/50] batch [360/428] time 0.097 (0.105) data 0.000 (0.002) loss 2.5080 (2.5800) teacher_loss 0.8927 (0.9952) loss_zs_kd 1.5969 (1.4538) loss_oracle 1.0667 (1.1007) acc 65.6250 (65.3906) lr 1.9921e-03 eta 0:34:32
epoch [4/50] batch [380/428] time 0.088 (0.105) data 0.000 (0.002) loss 2.5309 (2.5725) teacher_loss 0.9208 (0.9883) loss_zs_kd 1.8745 (1.4639) loss_oracle 1.0916 (1.0996) acc 68.7500 (65.5921) lr 1.9921e-03 eta 0:34:26
epoch [4/50] batch [400/428] time 0.095 (0.104) data 0.000 (0.001) loss 2.4831 (2.5693) teacher_loss 0.9394 (0.9848) loss_zs_kd 1.3673 (1.4725) loss_oracle 1.0844 (1.0987) acc 78.1250 (65.7422) lr 1.9921e-03 eta 0:34:14
epoch [4/50] batch [420/428] time 0.087 (0.104) data 0.000 (0.001) loss 2.5285 (2.5681) teacher_loss 0.9527 (0.9831) loss_zs_kd 1.7759 (1.4859) loss_oracle 1.0755 (1.0979) acc 65.6250 (65.8557) lr 1.9921e-03 eta 0:34:09
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,942
* accuracy: 50.1%
* error: 49.9%
* macro_f1: 33.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,778
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 25.2%
******* Domain 1 best val acc:      53.0%, epoch: 3 *******
******* Domain 1 best val test acc: 45.3%, epoch: 3 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [5/50] batch [20/428] time 0.079 (0.123) data 0.000 (0.026) loss 2.3700 (2.4587) teacher_loss 0.7910 (0.8822) loss_zs_kd 1.5559 (1.7891) loss_oracle 1.0820 (1.0771) acc 78.1250 (69.0625) lr 1.9823e-03 eta 0:40:21
epoch [5/50] batch [40/428] time 0.073 (0.113) data 0.001 (0.013) loss 2.4125 (2.4599) teacher_loss 0.8620 (0.8841) loss_zs_kd 1.7097 (1.7842) loss_oracle 1.0904 (1.0745) acc 65.6250 (69.5312) lr 1.9823e-03 eta 0:37:00
epoch [5/50] batch [60/428] time 0.168 (0.109) data 0.000 (0.009) loss 2.3602 (2.4329) teacher_loss 0.7648 (0.8567) loss_zs_kd 1.7552 (1.8389) loss_oracle 1.0869 (1.0747) acc 71.8750 (70.7292) lr 1.9823e-03 eta 0:35:31
epoch [5/50] batch [80/428] time 0.174 (0.109) data 0.000 (0.007) loss 2.6423 (2.4661) teacher_loss 1.0782 (0.8866) loss_zs_kd 1.7745 (1.8262) loss_oracle 1.0179 (1.0730) acc 59.3750 (69.5703) lr 1.9823e-03 eta 0:35:27
epoch [5/50] batch [100/428] time 0.080 (0.105) data 0.000 (0.005) loss 2.2986 (2.4836) teacher_loss 0.7525 (0.9040) loss_zs_kd 1.7224 (1.7904) loss_oracle 1.0828 (1.0746) acc 68.7500 (69.1875) lr 1.9823e-03 eta 0:34:20
epoch [5/50] batch [120/428] time 0.081 (0.101) data 0.000 (0.005) loss 2.7213 (2.4862) teacher_loss 1.1002 (0.9076) loss_zs_kd 1.6525 (1.7616) loss_oracle 1.0775 (1.0724) acc 56.2500 (69.1146) lr 1.9823e-03 eta 0:33:03
epoch [5/50] batch [140/428] time 0.077 (0.098) data 0.000 (0.004) loss 2.4390 (2.4912) teacher_loss 0.8480 (0.9151) loss_zs_kd 1.0609 (1.7072) loss_oracle 1.0322 (1.0701) acc 68.7500 (68.8839) lr 1.9823e-03 eta 0:32:00
epoch [5/50] batch [160/428] time 0.088 (0.096) data 0.000 (0.003) loss 2.6028 (2.5027) teacher_loss 1.0516 (0.9264) loss_zs_kd 1.4668 (1.6950) loss_oracle 1.0539 (1.0703) acc 62.5000 (68.4961) lr 1.9823e-03 eta 0:31:09
epoch [5/50] batch [180/428] time 0.080 (0.094) data 0.000 (0.003) loss 2.6453 (2.5053) teacher_loss 1.0679 (0.9282) loss_zs_kd 1.6700 (1.6787) loss_oracle 1.0627 (1.0704) acc 62.5000 (68.6806) lr 1.9823e-03 eta 0:30:43
epoch [5/50] batch [200/428] time 0.082 (0.093) data 0.000 (0.003) loss 2.4645 (2.5062) teacher_loss 0.9124 (0.9316) loss_zs_kd 1.1381 (1.6590) loss_oracle 1.0653 (1.0689) acc 75.0000 (68.6250) lr 1.9823e-03 eta 0:30:21
epoch [5/50] batch [220/428] time 0.085 (0.093) data 0.000 (0.003) loss 2.6484 (2.5214) teacher_loss 1.0740 (0.9477) loss_zs_kd 1.4346 (1.6272) loss_oracle 1.0484 (1.0670) acc 62.5000 (67.9688) lr 1.9823e-03 eta 0:30:04
epoch [5/50] batch [240/428] time 0.088 (0.092) data 0.000 (0.002) loss 2.9603 (2.5374) teacher_loss 1.3915 (0.9660) loss_zs_kd 1.4084 (1.6100) loss_oracle 1.0435 (1.0650) acc 53.1250 (67.0573) lr 1.9823e-03 eta 0:29:51
epoch [5/50] batch [260/428] time 0.085 (0.092) data 0.000 (0.002) loss 2.6095 (2.5485) teacher_loss 1.0573 (0.9779) loss_zs_kd 1.4846 (1.5940) loss_oracle 1.0451 (1.0632) acc 62.5000 (66.5024) lr 1.9823e-03 eta 0:29:38
epoch [5/50] batch [280/428] time 0.086 (0.091) data 0.000 (0.002) loss 2.3973 (2.5427) teacher_loss 0.8205 (0.9741) loss_zs_kd 1.3559 (1.5851) loss_oracle 1.0507 (1.0626) acc 71.8750 (66.6964) lr 1.9823e-03 eta 0:29:25
epoch [5/50] batch [300/428] time 0.088 (0.090) data 0.000 (0.002) loss 2.4640 (2.5366) teacher_loss 0.9378 (0.9692) loss_zs_kd 1.7305 (1.5869) loss_oracle 1.0345 (1.0622) acc 65.6250 (66.9583) lr 1.9823e-03 eta 0:29:14
epoch [5/50] batch [320/428] time 0.080 (0.090) data 0.000 (0.002) loss 2.3865 (2.5302) teacher_loss 0.8917 (0.9636) loss_zs_kd 1.5146 (1.5905) loss_oracle 1.0135 (1.0616) acc 59.3750 (67.2168) lr 1.9823e-03 eta 0:28:56
epoch [5/50] batch [340/428] time 0.087 (0.089) data 0.000 (0.002) loss 2.3792 (2.5317) teacher_loss 0.8077 (0.9654) loss_zs_kd 1.2090 (1.5755) loss_oracle 1.0724 (1.0622) acc 75.0000 (67.2610) lr 1.9823e-03 eta 0:28:46
epoch [5/50] batch [360/428] time 0.087 (0.089) data 0.000 (0.002) loss 2.0742 (2.5281) teacher_loss 0.5950 (0.9617) loss_zs_kd 1.3783 (1.5712) loss_oracle 1.0384 (1.0627) acc 81.2500 (67.3785) lr 1.9823e-03 eta 0:28:38
epoch [5/50] batch [380/428] time 0.082 (0.089) data 0.000 (0.002) loss 2.5707 (2.5198) teacher_loss 1.0307 (0.9547) loss_zs_kd 2.0108 (1.5789) loss_oracle 1.0318 (1.0624) acc 75.0000 (67.7220) lr 1.9823e-03 eta 0:28:31
epoch [5/50] batch [400/428] time 0.090 (0.088) data 0.000 (0.002) loss 2.5259 (2.5200) teacher_loss 1.0141 (0.9547) loss_zs_kd 1.2937 (1.5831) loss_oracle 1.0608 (1.0624) acc 62.5000 (67.7500) lr 1.9823e-03 eta 0:28:21
epoch [5/50] batch [420/428] time 0.084 (0.088) data 0.000 (0.002) loss 2.2729 (2.5132) teacher_loss 0.7228 (0.9482) loss_zs_kd 1.6868 (1.5872) loss_oracle 1.0729 (1.0621) acc 71.8750 (67.9167) lr 1.9823e-03 eta 0:28:14
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,197
* accuracy: 54.4%
* error: 45.6%
* macro_f1: 38.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,789
* accuracy: 37.7%
* error: 62.3%
* macro_f1: 25.0%
******* Domain 1 best val acc:      54.4%, epoch: 5 *******
******* Domain 1 best val test acc: 37.7%, epoch: 5 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [6/50] batch [20/428] time 0.075 (0.110) data 0.000 (0.026) loss 2.8488 (2.4611) teacher_loss 1.2851 (0.9017) loss_zs_kd 1.7724 (1.6019) loss_oracle 1.0976 (1.0670) acc 62.5000 (69.2188) lr 1.9686e-03 eta 0:35:08
epoch [6/50] batch [40/428] time 0.098 (0.096) data 0.000 (0.013) loss 2.2830 (2.4477) teacher_loss 0.7245 (0.8890) loss_zs_kd 1.7221 (1.6036) loss_oracle 1.1034 (1.0687) acc 75.0000 (69.2969) lr 1.9686e-03 eta 0:30:48
epoch [6/50] batch [60/428] time 0.088 (0.093) data 0.000 (0.009) loss 2.3572 (2.4642) teacher_loss 0.8102 (0.9043) loss_zs_kd 1.7455 (1.6342) loss_oracle 1.0136 (1.0657) acc 81.2500 (68.8542) lr 1.9686e-03 eta 0:29:36
epoch [6/50] batch [80/428] time 0.085 (0.091) data 0.000 (0.007) loss 2.3510 (2.4851) teacher_loss 0.8624 (0.9251) loss_zs_kd 1.7594 (1.6503) loss_oracle 0.9951 (1.0624) acc 68.7500 (68.0859) lr 1.9686e-03 eta 0:29:02
epoch [6/50] batch [100/428] time 0.081 (0.090) data 0.000 (0.005) loss 2.4002 (2.4978) teacher_loss 0.7905 (0.9371) loss_zs_kd 2.0128 (1.6484) loss_oracle 1.0479 (1.0600) acc 71.8750 (67.2812) lr 1.9686e-03 eta 0:28:38
epoch [6/50] batch [120/428] time 0.085 (0.089) data 0.000 (0.005) loss 2.6446 (2.4844) teacher_loss 1.0493 (0.9242) loss_zs_kd 1.8196 (1.6692) loss_oracle 1.0527 (1.0573) acc 59.3750 (67.7083) lr 1.9686e-03 eta 0:28:22
epoch [6/50] batch [140/428] time 0.085 (0.088) data 0.000 (0.004) loss 2.4087 (2.4782) teacher_loss 0.8032 (0.9175) loss_zs_kd 1.5515 (1.6633) loss_oracle 1.0807 (1.0574) acc 78.1250 (68.3705) lr 1.9686e-03 eta 0:28:11
epoch [6/50] batch [160/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.8674 (2.4762) teacher_loss 1.3153 (0.9158) loss_zs_kd 1.7586 (1.6575) loss_oracle 1.0727 (1.0575) acc 59.3750 (68.7500) lr 1.9686e-03 eta 0:27:48
epoch [6/50] batch [180/428] time 0.088 (0.089) data 0.000 (0.003) loss 2.6120 (2.4781) teacher_loss 1.0772 (0.9190) loss_zs_kd 1.5068 (1.6492) loss_oracle 0.9891 (1.0560) acc 59.3750 (68.6806) lr 1.9686e-03 eta 0:28:15
epoch [6/50] batch [200/428] time 0.082 (0.088) data 0.000 (0.003) loss 2.3072 (2.4731) teacher_loss 0.7264 (0.9155) loss_zs_kd 1.8322 (1.6463) loss_oracle 1.0481 (1.0548) acc 87.5000 (68.8594) lr 1.9686e-03 eta 0:28:01
epoch [6/50] batch [220/428] time 0.089 (0.088) data 0.000 (0.003) loss 2.7775 (2.4728) teacher_loss 1.2557 (0.9176) loss_zs_kd 1.2470 (1.6365) loss_oracle 1.0194 (1.0529) acc 62.5000 (68.8352) lr 1.9686e-03 eta 0:27:55
epoch [6/50] batch [240/428] time 0.084 (0.088) data 0.000 (0.002) loss 2.3071 (2.4671) teacher_loss 0.7754 (0.9156) loss_zs_kd 1.6229 (1.6210) loss_oracle 1.1045 (1.0514) acc 75.0000 (69.0365) lr 1.9686e-03 eta 0:27:48
epoch [6/50] batch [260/428] time 0.092 (0.088) data 0.000 (0.002) loss 2.5222 (2.4631) teacher_loss 0.9998 (0.9145) loss_zs_kd 1.5579 (1.6125) loss_oracle 0.9749 (1.0496) acc 59.3750 (68.9784) lr 1.9686e-03 eta 0:27:42
epoch [6/50] batch [280/428] time 0.083 (0.087) data 0.001 (0.002) loss 2.4074 (2.4672) teacher_loss 0.9194 (0.9213) loss_zs_kd 1.6445 (1.6097) loss_oracle 1.0317 (1.0483) acc 75.0000 (68.5603) lr 1.9686e-03 eta 0:27:33
epoch [6/50] batch [300/428] time 0.081 (0.087) data 0.000 (0.002) loss 2.4276 (2.4662) teacher_loss 0.8772 (0.9209) loss_zs_kd 1.6188 (1.6156) loss_oracle 1.0865 (1.0484) acc 71.8750 (68.6042) lr 1.9686e-03 eta 0:27:29
epoch [6/50] batch [320/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.6383 (2.4661) teacher_loss 1.1664 (0.9215) loss_zs_kd 1.7481 (1.6272) loss_oracle 0.9781 (1.0480) acc 56.2500 (68.6133) lr 1.9686e-03 eta 0:27:17
epoch [6/50] batch [340/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.2722 (2.4636) teacher_loss 0.7022 (0.9196) loss_zs_kd 1.2725 (1.6134) loss_oracle 1.0481 (1.0467) acc 75.0000 (68.7592) lr 1.9686e-03 eta 0:27:16
epoch [6/50] batch [360/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.4853 (2.4661) teacher_loss 0.9145 (0.9208) loss_zs_kd 1.4940 (1.6050) loss_oracle 1.0449 (1.0460) acc 71.8750 (68.7413) lr 1.9686e-03 eta 0:27:07
epoch [6/50] batch [380/428] time 0.076 (0.086) data 0.000 (0.002) loss 2.6785 (2.4654) teacher_loss 1.1517 (0.9205) loss_zs_kd 1.5647 (1.6019) loss_oracle 1.0180 (1.0453) acc 62.5000 (68.7993) lr 1.9686e-03 eta 0:26:56
epoch [6/50] batch [400/428] time 0.086 (0.085) data 0.000 (0.002) loss 2.4336 (2.4605) teacher_loss 0.8601 (0.9168) loss_zs_kd 1.3025 (1.5973) loss_oracle 1.0592 (1.0435) acc 75.0000 (68.9375) lr 1.9686e-03 eta 0:26:47
epoch [6/50] batch [420/428] time 0.078 (0.085) data 0.000 (0.002) loss 2.4213 (2.4564) teacher_loss 0.8025 (0.9129) loss_zs_kd 1.7110 (1.5971) loss_oracle 1.0880 (1.0435) acc 68.7500 (69.1741) lr 1.9686e-03 eta 0:26:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,215
* accuracy: 54.7%
* error: 45.3%
* macro_f1: 41.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,913
* accuracy: 40.4%
* error: 59.6%
* macro_f1: 26.3%
******* Domain 1 best val acc:      54.7%, epoch: 6 *******
******* Domain 1 best val test acc: 40.4%, epoch: 6 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [7/50] batch [20/428] time 0.085 (0.113) data 0.000 (0.030) loss 2.5621 (2.2777) teacher_loss 1.0536 (0.7460) loss_zs_kd 1.7371 (1.8148) loss_oracle 1.0467 (1.0384) acc 62.5000 (75.6250) lr 1.9511e-03 eta 0:35:28
epoch [7/50] batch [40/428] time 0.080 (0.097) data 0.000 (0.015) loss 2.2079 (2.3285) teacher_loss 0.6527 (0.7998) loss_zs_kd 1.6579 (1.7361) loss_oracle 1.0499 (1.0407) acc 81.2500 (73.5938) lr 1.9511e-03 eta 0:30:29
epoch [7/50] batch [60/428] time 0.081 (0.093) data 0.001 (0.010) loss 2.5784 (2.3619) teacher_loss 1.0650 (0.8381) loss_zs_kd 1.4037 (1.6401) loss_oracle 1.0340 (1.0363) acc 65.6250 (72.1354) lr 1.9511e-03 eta 0:29:06
epoch [7/50] batch [80/428] time 0.074 (0.089) data 0.000 (0.008) loss 2.3640 (2.3526) teacher_loss 0.9144 (0.8323) loss_zs_kd 1.6861 (1.6157) loss_oracle 0.9301 (1.0307) acc 75.0000 (72.5000) lr 1.9511e-03 eta 0:27:55
epoch [7/50] batch [100/428] time 0.082 (0.088) data 0.000 (0.006) loss 2.0360 (2.3610) teacher_loss 0.5380 (0.8419) loss_zs_kd 1.5183 (1.6247) loss_oracle 1.0312 (1.0305) acc 84.3750 (71.8438) lr 1.9511e-03 eta 0:27:24
epoch [7/50] batch [120/428] time 0.083 (0.087) data 0.000 (0.005) loss 2.5275 (2.3645) teacher_loss 1.0170 (0.8452) loss_zs_kd 1.6753 (1.5916) loss_oracle 1.0448 (1.0312) acc 59.3750 (71.4583) lr 1.9511e-03 eta 0:27:07
epoch [7/50] batch [140/428] time 0.075 (0.086) data 0.000 (0.005) loss 3.1496 (2.3805) teacher_loss 1.5923 (0.8623) loss_zs_kd 1.5999 (1.5713) loss_oracle 1.0368 (1.0300) acc 43.7500 (70.8929) lr 1.9511e-03 eta 0:26:55
epoch [7/50] batch [160/428] time 0.082 (0.085) data 0.000 (0.004) loss 2.1294 (2.3698) teacher_loss 0.6443 (0.8526) loss_zs_kd 1.9452 (1.5800) loss_oracle 1.0017 (1.0304) acc 78.1250 (71.4453) lr 1.9511e-03 eta 0:26:31
epoch [7/50] batch [180/428] time 0.083 (0.085) data 0.000 (0.004) loss 2.3980 (2.3726) teacher_loss 0.8936 (0.8555) loss_zs_kd 1.6185 (1.5793) loss_oracle 1.0365 (1.0311) acc 65.6250 (71.2674) lr 1.9511e-03 eta 0:26:27
epoch [7/50] batch [200/428] time 0.078 (0.085) data 0.000 (0.003) loss 2.1832 (2.3791) teacher_loss 0.7127 (0.8636) loss_zs_kd 1.8516 (1.5720) loss_oracle 1.0080 (1.0318) acc 78.1250 (70.8594) lr 1.9511e-03 eta 0:26:18
epoch [7/50] batch [220/428] time 0.081 (0.084) data 0.000 (0.003) loss 2.5770 (2.3880) teacher_loss 0.9794 (0.8721) loss_zs_kd 1.7621 (1.5729) loss_oracle 1.0780 (1.0324) acc 65.6250 (70.4972) lr 1.9511e-03 eta 0:26:07
epoch [7/50] batch [240/428] time 0.079 (0.084) data 0.000 (0.003) loss 2.5866 (2.3865) teacher_loss 1.0483 (0.8720) loss_zs_kd 1.6878 (1.5751) loss_oracle 0.9937 (1.0316) acc 65.6250 (70.5469) lr 1.9511e-03 eta 0:25:56
epoch [7/50] batch [260/428] time 0.085 (0.084) data 0.000 (0.003) loss 2.2744 (2.3891) teacher_loss 0.7761 (0.8756) loss_zs_kd 1.6527 (1.5756) loss_oracle 0.9947 (1.0324) acc 75.0000 (70.5529) lr 1.9511e-03 eta 0:25:54
epoch [7/50] batch [280/428] time 0.087 (0.084) data 0.000 (0.002) loss 2.5386 (2.3812) teacher_loss 1.0540 (0.8695) loss_zs_kd 2.0541 (1.5853) loss_oracle 1.0471 (1.0313) acc 62.5000 (70.7254) lr 1.9511e-03 eta 0:25:52
epoch [7/50] batch [300/428] time 0.074 (0.084) data 0.000 (0.002) loss 2.1590 (2.3783) teacher_loss 0.6615 (0.8664) loss_zs_kd 1.5441 (1.5939) loss_oracle 0.9873 (1.0311) acc 75.0000 (71.0000) lr 1.9511e-03 eta 0:26:03
epoch [7/50] batch [320/428] time 0.076 (0.084) data 0.000 (0.002) loss 2.2741 (2.3732) teacher_loss 0.7641 (0.8630) loss_zs_kd 1.5985 (1.6049) loss_oracle 1.0434 (1.0306) acc 71.8750 (71.1523) lr 1.9511e-03 eta 0:25:59
epoch [7/50] batch [340/428] time 0.080 (0.084) data 0.000 (0.002) loss 2.5432 (2.3727) teacher_loss 1.0775 (0.8640) loss_zs_kd 1.6502 (1.6007) loss_oracle 1.0066 (1.0300) acc 68.7500 (71.1305) lr 1.9511e-03 eta 0:26:00
epoch [7/50] batch [360/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.3354 (2.3733) teacher_loss 0.7950 (0.8663) loss_zs_kd 1.4623 (1.6018) loss_oracle 1.0865 (1.0296) acc 71.8750 (70.9115) lr 1.9511e-03 eta 0:25:58
epoch [7/50] batch [380/428] time 0.078 (0.084) data 0.000 (0.002) loss 2.1619 (2.3684) teacher_loss 0.7000 (0.8636) loss_zs_kd 1.4391 (1.6121) loss_oracle 1.0181 (1.0299) acc 81.2500 (71.0526) lr 1.9511e-03 eta 0:25:57
epoch [7/50] batch [400/428] time 0.084 (0.084) data 0.000 (0.002) loss 2.8804 (2.3675) teacher_loss 1.2900 (0.8637) loss_zs_kd 1.6911 (1.6193) loss_oracle 1.0384 (1.0296) acc 40.6250 (71.0469) lr 1.9511e-03 eta 0:25:51
epoch [7/50] batch [420/428] time 0.072 (0.084) data 0.000 (0.002) loss 2.5248 (2.3744) teacher_loss 0.7410 (0.8673) loss_zs_kd 1.4205 (1.6159) loss_oracle 1.1028 (1.0298) acc 75.0000 (71.0417) lr 1.9511e-03 eta 0:25:47
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,341
* accuracy: 56.9%
* error: 43.1%
* macro_f1: 38.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,754
* accuracy: 37.0%
* error: 63.0%
* macro_f1: 25.3%
******* Domain 1 best val acc:      56.9%, epoch: 7 *******
******* Domain 1 best val test acc: 37.0%, epoch: 7 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [8/50] batch [20/428] time 0.089 (0.108) data 0.000 (0.025) loss 2.7075 (2.8340) teacher_loss 0.9482 (1.1079) loss_zs_kd 1.0144 (1.5016) loss_oracle 1.1353 (1.0616) acc 65.6250 (61.4062) lr 1.9298e-03 eta 0:33:05
epoch [8/50] batch [40/428] time 0.084 (0.097) data 0.000 (0.012) loss 2.9200 (2.8271) teacher_loss 1.1905 (1.0970) loss_zs_kd 1.5552 (1.4414) loss_oracle 1.0924 (1.0792) acc 50.0000 (62.2656) lr 1.9298e-03 eta 0:29:35
epoch [8/50] batch [60/428] time 0.080 (0.092) data 0.000 (0.008) loss 2.4286 (2.8102) teacher_loss 0.8000 (1.0869) loss_zs_kd 1.3469 (1.4248) loss_oracle 1.0845 (1.0754) acc 68.7500 (62.2917) lr 1.9298e-03 eta 0:28:13
epoch [8/50] batch [80/428] time 0.087 (0.091) data 0.000 (0.006) loss 2.8284 (2.7610) teacher_loss 1.2094 (1.0696) loss_zs_kd 1.5936 (1.4397) loss_oracle 1.0558 (1.0693) acc 59.3750 (62.8906) lr 1.9298e-03 eta 0:27:47
epoch [8/50] batch [100/428] time 0.085 (0.090) data 0.000 (0.005) loss 2.3039 (2.7141) teacher_loss 0.7221 (1.0457) loss_zs_kd 2.0492 (1.4931) loss_oracle 1.0578 (1.0667) acc 71.8750 (63.5938) lr 1.9298e-03 eta 0:27:25
epoch [8/50] batch [120/428] time 0.082 (0.090) data 0.000 (0.004) loss 2.4424 (2.6671) teacher_loss 0.8997 (1.0182) loss_zs_kd 1.5090 (1.5306) loss_oracle 1.0403 (1.0626) acc 65.6250 (64.7917) lr 1.9298e-03 eta 0:27:16
epoch [8/50] batch [140/428] time 0.083 (0.089) data 0.000 (0.004) loss 2.6271 (2.6393) teacher_loss 0.9852 (1.0050) loss_zs_kd 1.7182 (1.5480) loss_oracle 1.0991 (1.0611) acc 59.3750 (65.0893) lr 1.9298e-03 eta 0:26:59
epoch [8/50] batch [160/428] time 0.079 (0.088) data 0.000 (0.003) loss 2.5699 (2.6113) teacher_loss 0.9428 (0.9881) loss_zs_kd 1.8004 (1.5684) loss_oracle 1.0888 (1.0590) acc 62.5000 (65.6055) lr 1.9298e-03 eta 0:26:42
epoch [8/50] batch [180/428] time 0.086 (0.087) data 0.000 (0.003) loss 2.5407 (2.5868) teacher_loss 1.0201 (0.9729) loss_zs_kd 1.6092 (1.5838) loss_oracle 1.0233 (1.0583) acc 65.6250 (66.1632) lr 1.9298e-03 eta 0:26:30
epoch [8/50] batch [200/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.4885 (2.5670) teacher_loss 0.8801 (0.9596) loss_zs_kd 1.7020 (1.5904) loss_oracle 1.0872 (1.0578) acc 65.6250 (66.6406) lr 1.9298e-03 eta 0:26:29
epoch [8/50] batch [220/428] time 0.092 (0.087) data 0.001 (0.003) loss 2.2779 (2.5454) teacher_loss 0.6972 (0.9410) loss_zs_kd 2.1336 (1.6126) loss_oracle 1.0754 (1.0598) acc 78.1250 (67.3011) lr 1.9298e-03 eta 0:26:23
epoch [8/50] batch [240/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.4534 (2.5257) teacher_loss 0.9491 (0.9250) loss_zs_kd 1.9168 (1.6325) loss_oracle 1.0103 (1.0595) acc 71.8750 (68.0599) lr 1.9298e-03 eta 0:26:22
epoch [8/50] batch [260/428] time 0.085 (0.087) data 0.000 (0.002) loss 2.3354 (2.5108) teacher_loss 0.8157 (0.9140) loss_zs_kd 1.8100 (1.6454) loss_oracle 1.0994 (1.0611) acc 68.7500 (68.5216) lr 1.9298e-03 eta 0:26:12
epoch [8/50] batch [280/428] time 0.080 (0.086) data 0.000 (0.002) loss 2.3093 (2.4991) teacher_loss 0.7363 (0.9059) loss_zs_kd 1.8147 (1.6555) loss_oracle 1.0550 (1.0608) acc 78.1250 (68.8281) lr 1.9298e-03 eta 0:26:07
epoch [8/50] batch [300/428] time 0.076 (0.086) data 0.000 (0.002) loss 2.3794 (2.4883) teacher_loss 0.8830 (0.8985) loss_zs_kd 1.8778 (1.6688) loss_oracle 0.9871 (1.0596) acc 65.6250 (68.9375) lr 1.9298e-03 eta 0:26:02
epoch [8/50] batch [320/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.5349 (2.4750) teacher_loss 0.9475 (0.8895) loss_zs_kd 2.0497 (1.6809) loss_oracle 1.0774 (1.0578) acc 65.6250 (69.2480) lr 1.9298e-03 eta 0:25:58
epoch [8/50] batch [340/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.1926 (2.4683) teacher_loss 0.5980 (0.8832) loss_zs_kd 2.3891 (1.6951) loss_oracle 1.0808 (1.0580) acc 81.2500 (69.5129) lr 1.9298e-03 eta 0:25:53
epoch [8/50] batch [360/428] time 0.081 (0.086) data 0.000 (0.002) loss 2.3327 (2.4619) teacher_loss 0.8718 (0.8799) loss_zs_kd 1.4937 (1.7017) loss_oracle 0.9958 (1.0571) acc 65.6250 (69.6962) lr 1.9298e-03 eta 0:25:50
epoch [8/50] batch [380/428] time 0.084 (0.086) data 0.001 (0.002) loss 2.2995 (2.4550) teacher_loss 0.6504 (0.8749) loss_zs_kd 1.5229 (1.6966) loss_oracle 1.0761 (1.0559) acc 75.0000 (69.8602) lr 1.9298e-03 eta 0:25:52
epoch [8/50] batch [400/428] time 0.091 (0.086) data 0.000 (0.002) loss 1.9502 (2.4458) teacher_loss 0.4288 (0.8675) loss_zs_kd 1.8660 (1.6995) loss_oracle 1.0229 (1.0548) acc 84.3750 (70.0156) lr 1.9298e-03 eta 0:25:49
epoch [8/50] batch [420/428] time 0.071 (0.086) data 0.000 (0.001) loss 2.5630 (2.4403) teacher_loss 0.9470 (0.8633) loss_zs_kd 1.5247 (1.7072) loss_oracle 1.0635 (1.0534) acc 65.6250 (70.0893) lr 1.9298e-03 eta 0:25:50
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,443
* accuracy: 58.6%
* error: 41.4%
* macro_f1: 43.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,786
* accuracy: 37.7%
* error: 62.3%
* macro_f1: 24.8%
******* Domain 1 best val acc:      58.6%, epoch: 8 *******
******* Domain 1 best val test acc: 37.7%, epoch: 8 *******
******* Domain 1 best test acc:     45.3%, epoch: 3 *******
epoch [9/50] batch [20/428] time 0.081 (0.106) data 0.000 (0.025) loss 2.0862 (2.3596) teacher_loss 0.5352 (0.7941) loss_zs_kd 1.7913 (1.7818) loss_oracle 1.0448 (1.0389) acc 84.3750 (72.9688) lr 1.9048e-03 eta 0:31:43
epoch [9/50] batch [40/428] time 0.084 (0.096) data 0.000 (0.013) loss 2.5697 (2.3529) teacher_loss 1.0487 (0.7919) loss_zs_kd 1.6937 (1.7237) loss_oracle 1.0254 (1.0463) acc 59.3750 (71.8750) lr 1.9048e-03 eta 0:28:38
epoch [9/50] batch [60/428] time 0.074 (0.090) data 0.001 (0.009) loss 2.2216 (2.3459) teacher_loss 0.6236 (0.7863) loss_zs_kd 1.5795 (1.7430) loss_oracle 1.0537 (1.0483) acc 75.0000 (72.2396) lr 1.9048e-03 eta 0:26:52
epoch [9/50] batch [80/428] time 0.083 (0.087) data 0.000 (0.006) loss 2.5859 (2.3527) teacher_loss 0.9819 (0.7931) loss_zs_kd 1.8416 (1.7185) loss_oracle 1.0510 (1.0450) acc 62.5000 (71.8359) lr 1.9048e-03 eta 0:25:55
epoch [9/50] batch [100/428] time 0.075 (0.086) data 0.000 (0.005) loss 2.4216 (2.3587) teacher_loss 0.8351 (0.7993) loss_zs_kd 1.6252 (1.7154) loss_oracle 1.0590 (1.0436) acc 68.7500 (71.9062) lr 1.9048e-03 eta 0:25:43
epoch [9/50] batch [120/428] time 0.078 (0.085) data 0.000 (0.004) loss 2.7129 (2.3489) teacher_loss 1.1628 (0.7918) loss_zs_kd 1.8731 (1.7421) loss_oracle 1.0218 (1.0427) acc 59.3750 (72.1615) lr 1.9048e-03 eta 0:25:25
epoch [9/50] batch [140/428] time 0.077 (0.085) data 0.000 (0.004) loss 2.4227 (2.3390) teacher_loss 0.9127 (0.7821) loss_zs_kd 1.7202 (1.7380) loss_oracle 1.0463 (1.0424) acc 65.6250 (72.5893) lr 1.9048e-03 eta 0:25:14
epoch [9/50] batch [160/428] time 0.135 (0.085) data 0.001 (0.003) loss 2.5784 (2.3336) teacher_loss 1.0248 (0.7783) loss_zs_kd 1.7821 (1.7441) loss_oracle 1.0609 (1.0402) acc 68.7500 (72.6953) lr 1.9048e-03 eta 0:25:17
epoch [9/50] batch [180/428] time 0.092 (0.086) data 0.000 (0.003) loss 2.3471 (2.3336) teacher_loss 0.7679 (0.7788) loss_zs_kd 2.2574 (1.7503) loss_oracle 1.0292 (1.0386) acc 78.1250 (72.5174) lr 1.9048e-03 eta 0:25:27
epoch [9/50] batch [200/428] time 0.074 (0.085) data 0.000 (0.003) loss 2.2590 (2.3334) teacher_loss 0.6510 (0.7786) loss_zs_kd 1.5419 (1.7677) loss_oracle 1.0024 (1.0399) acc 81.2500 (72.6875) lr 1.9048e-03 eta 0:25:18
epoch [9/50] batch [220/428] time 0.083 (0.085) data 0.000 (0.003) loss 2.2375 (2.3285) teacher_loss 0.7425 (0.7753) loss_zs_kd 2.2295 (1.7699) loss_oracle 1.0167 (1.0399) acc 75.0000 (72.8835) lr 1.9048e-03 eta 0:25:10
epoch [9/50] batch [240/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.4202 (2.3272) teacher_loss 0.8779 (0.7739) loss_zs_kd 2.2161 (1.7983) loss_oracle 1.0477 (1.0406) acc 78.1250 (72.9557) lr 1.9048e-03 eta 0:25:02
epoch [9/50] batch [260/428] time 0.071 (0.085) data 0.000 (0.002) loss 2.5520 (2.3357) teacher_loss 0.9060 (0.7778) loss_zs_kd 2.2240 (1.8078) loss_oracle 1.0802 (1.0425) acc 56.2500 (72.7163) lr 1.9048e-03 eta 0:24:57
epoch [9/50] batch [280/428] time 0.063 (0.083) data 0.000 (0.002) loss 2.3213 (2.3397) teacher_loss 0.7215 (0.7796) loss_zs_kd 1.9308 (1.8174) loss_oracle 1.0467 (1.0429) acc 65.6250 (72.7009) lr 1.9048e-03 eta 0:24:28
epoch [9/50] batch [300/428] time 0.091 (0.083) data 0.000 (0.002) loss 2.3962 (2.3461) teacher_loss 0.8107 (0.7856) loss_zs_kd 2.0510 (1.8269) loss_oracle 1.0200 (1.0424) acc 81.2500 (72.7188) lr 1.9048e-03 eta 0:24:24
epoch [9/50] batch [320/428] time 0.062 (0.082) data 0.000 (0.002) loss 2.6721 (2.3551) teacher_loss 1.0911 (0.7916) loss_zs_kd 1.5662 (1.8228) loss_oracle 1.0588 (1.0442) acc 53.1250 (72.5195) lr 1.9048e-03 eta 0:24:09
epoch [9/50] batch [340/428] time 0.083 (0.081) data 0.000 (0.002) loss 2.5296 (2.3603) teacher_loss 0.9651 (0.7964) loss_zs_kd 1.4788 (1.8149) loss_oracle 1.0321 (1.0445) acc 68.7500 (72.2794) lr 1.9048e-03 eta 0:23:53
epoch [9/50] batch [360/428] time 0.079 (0.081) data 0.000 (0.002) loss 2.4263 (2.3589) teacher_loss 0.8208 (0.7957) loss_zs_kd 1.9177 (1.8128) loss_oracle 1.0290 (1.0445) acc 68.7500 (72.3611) lr 1.9048e-03 eta 0:23:42
epoch [9/50] batch [380/428] time 0.084 (0.081) data 0.000 (0.002) loss 2.5695 (2.3632) teacher_loss 1.0315 (0.7993) loss_zs_kd 1.7632 (1.8184) loss_oracle 1.0638 (1.0450) acc 65.6250 (72.1053) lr 1.9048e-03 eta 0:23:40
epoch [9/50] batch [400/428] time 0.075 (0.081) data 0.000 (0.002) loss 2.7560 (2.3679) teacher_loss 1.1864 (0.8036) loss_zs_kd 1.5897 (1.8111) loss_oracle 1.0286 (1.0460) acc 62.5000 (71.9375) lr 1.9048e-03 eta 0:23:41
epoch [9/50] batch [420/428] time 0.071 (0.081) data 0.000 (0.001) loss 2.0585 (2.3672) teacher_loss 0.4743 (0.8018) loss_zs_kd 1.6743 (1.8028) loss_oracle 1.0488 (1.0466) acc 81.2500 (71.9792) lr 1.9048e-03 eta 0:23:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,435
* accuracy: 58.5%
* error: 41.5%
* macro_f1: 44.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,243
* accuracy: 47.3%
* error: 52.7%
* macro_f1: 28.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      58.6%, epoch: 8 *******
******* Domain 1 best val test acc: 37.7%, epoch: 8 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [10/50] batch [20/428] time 0.085 (0.117) data 0.000 (0.029) loss 2.3668 (2.3325) teacher_loss 0.7465 (0.7614) loss_zs_kd 1.7204 (1.6934) loss_oracle 1.0665 (1.0404) acc 65.6250 (72.9688) lr 1.8763e-03 eta 0:34:12
epoch [10/50] batch [40/428] time 0.083 (0.101) data 0.000 (0.015) loss 2.1938 (2.3553) teacher_loss 0.6191 (0.7804) loss_zs_kd 1.9137 (1.7629) loss_oracle 1.0511 (1.0469) acc 75.0000 (72.1094) lr 1.8763e-03 eta 0:29:34
epoch [10/50] batch [60/428] time 0.082 (0.096) data 0.001 (0.010) loss 2.4708 (2.3463) teacher_loss 0.8040 (0.7734) loss_zs_kd 1.5829 (1.7535) loss_oracle 1.1214 (1.0505) acc 65.6250 (72.5521) lr 1.8763e-03 eta 0:28:00
epoch [10/50] batch [80/428] time 0.083 (0.094) data 0.000 (0.008) loss 2.3999 (2.3344) teacher_loss 0.7793 (0.7622) loss_zs_kd 1.8087 (1.7836) loss_oracle 1.0849 (1.0526) acc 68.7500 (73.0859) lr 1.8763e-03 eta 0:27:24
epoch [10/50] batch [100/428] time 0.081 (0.093) data 0.000 (0.006) loss 2.2001 (2.3394) teacher_loss 0.6407 (0.7664) loss_zs_kd 1.8155 (1.8023) loss_oracle 1.0288 (1.0529) acc 84.3750 (72.9062) lr 1.8763e-03 eta 0:26:56
epoch [10/50] batch [120/428] time 0.088 (0.091) data 0.000 (0.005) loss 2.3161 (2.3405) teacher_loss 0.7422 (0.7667) loss_zs_kd 2.1351 (1.8236) loss_oracle 1.0214 (1.0526) acc 75.0000 (72.9427) lr 1.8763e-03 eta 0:26:33
epoch [10/50] batch [140/428] time 0.077 (0.091) data 0.000 (0.004) loss 2.2516 (2.3313) teacher_loss 0.7052 (0.7605) loss_zs_kd 1.9500 (1.8506) loss_oracle 1.0429 (1.0529) acc 78.1250 (73.4152) lr 1.8763e-03 eta 0:26:28
epoch [10/50] batch [160/428] time 0.087 (0.091) data 0.000 (0.004) loss 2.4207 (2.3339) teacher_loss 0.8098 (0.7656) loss_zs_kd 1.5713 (1.8636) loss_oracle 1.0696 (1.0519) acc 62.5000 (73.0859) lr 1.8763e-03 eta 0:26:15
epoch [10/50] batch [180/428] time 0.078 (0.090) data 0.000 (0.004) loss 2.2509 (2.3355) teacher_loss 0.8007 (0.7692) loss_zs_kd 1.8567 (1.8701) loss_oracle 0.9787 (1.0511) acc 75.0000 (73.2292) lr 1.8763e-03 eta 0:26:09
epoch [10/50] batch [200/428] time 0.084 (0.090) data 0.001 (0.003) loss 2.2462 (2.3384) teacher_loss 0.7709 (0.7721) loss_zs_kd 1.8854 (1.8630) loss_oracle 1.0181 (1.0509) acc 68.7500 (72.9688) lr 1.8763e-03 eta 0:25:55
epoch [10/50] batch [220/428] time 0.077 (0.089) data 0.000 (0.003) loss 2.2657 (2.3469) teacher_loss 0.6434 (0.7811) loss_zs_kd 1.8039 (1.8458) loss_oracle 1.0712 (1.0493) acc 81.2500 (72.7557) lr 1.8763e-03 eta 0:25:48
epoch [10/50] batch [240/428] time 0.090 (0.089) data 0.000 (0.003) loss 2.7480 (2.3485) teacher_loss 1.1163 (0.7842) loss_zs_kd 1.7945 (1.8452) loss_oracle 1.0501 (1.0482) acc 62.5000 (72.8125) lr 1.8763e-03 eta 0:25:40
epoch [10/50] batch [260/428] time 0.078 (0.089) data 0.000 (0.003) loss 2.3255 (2.3451) teacher_loss 0.7207 (0.7827) loss_zs_kd 2.1658 (1.8572) loss_oracle 1.0665 (1.0465) acc 68.7500 (72.8606) lr 1.8763e-03 eta 0:25:35
epoch [10/50] batch [280/428] time 0.082 (0.089) data 0.000 (0.002) loss 2.5637 (2.3462) teacher_loss 0.9133 (0.7841) loss_zs_kd 1.7896 (1.8618) loss_oracle 1.0584 (1.0455) acc 71.8750 (72.9018) lr 1.8763e-03 eta 0:25:28
epoch [10/50] batch [300/428] time 0.073 (0.089) data 0.000 (0.002) loss 2.0941 (2.3577) teacher_loss 0.4584 (0.7927) loss_zs_kd 1.6186 (1.8643) loss_oracle 1.0621 (1.0454) acc 87.5000 (72.5312) lr 1.8763e-03 eta 0:25:36
epoch [10/50] batch [320/428] time 0.063 (0.089) data 0.000 (0.002) loss 2.1685 (2.3657) teacher_loss 0.5126 (0.7976) loss_zs_kd 1.7363 (1.8561) loss_oracle 1.0953 (1.0466) acc 87.5000 (72.4219) lr 1.8763e-03 eta 0:25:29
epoch [10/50] batch [340/428] time 0.084 (0.089) data 0.000 (0.002) loss 2.9542 (2.3732) teacher_loss 1.4012 (0.8046) loss_zs_kd 1.5776 (1.8527) loss_oracle 1.0643 (1.0466) acc 62.5000 (72.1599) lr 1.8763e-03 eta 0:25:24
epoch [10/50] batch [360/428] time 0.081 (0.088) data 0.000 (0.002) loss 2.3397 (2.3730) teacher_loss 0.7765 (0.8056) loss_zs_kd 1.7947 (1.8563) loss_oracle 1.0603 (1.0462) acc 68.7500 (72.1788) lr 1.8763e-03 eta 0:25:16
epoch [10/50] batch [380/428] time 0.095 (0.088) data 0.000 (0.002) loss 2.5023 (2.3713) teacher_loss 0.9612 (0.8052) loss_zs_kd 1.7099 (1.8473) loss_oracle 1.0194 (1.0463) acc 68.7500 (72.3273) lr 1.8763e-03 eta 0:25:10
epoch [10/50] batch [400/428] time 0.083 (0.088) data 0.000 (0.002) loss 2.1602 (2.3687) teacher_loss 0.6350 (0.8039) loss_zs_kd 1.8329 (1.8384) loss_oracle 1.0169 (1.0460) acc 75.0000 (72.4766) lr 1.8763e-03 eta 0:25:05
epoch [10/50] batch [420/428] time 0.073 (0.087) data 0.000 (0.002) loss 2.1118 (2.3698) teacher_loss 0.5913 (0.8063) loss_zs_kd 1.7117 (1.8290) loss_oracle 1.0241 (1.0462) acc 75.0000 (72.4033) lr 1.8763e-03 eta 0:24:58
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,312
* accuracy: 56.4%
* error: 43.6%
* macro_f1: 45.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,824
* accuracy: 38.5%
* error: 61.5%
* macro_f1: 25.6%
******* Domain 1 best val acc:      58.6%, epoch: 8 *******
******* Domain 1 best val test acc: 37.7%, epoch: 8 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [11/50] batch [20/428] time 0.079 (0.113) data 0.000 (0.026) loss 2.3223 (2.3671) teacher_loss 0.7846 (0.7948) loss_zs_kd 1.8881 (1.7604) loss_oracle 1.0593 (1.0542) acc 71.8750 (72.5000) lr 1.8443e-03 eta 0:32:13
epoch [11/50] batch [40/428] time 0.064 (0.100) data 0.000 (0.013) loss 2.3994 (2.3203) teacher_loss 0.8804 (0.7609) loss_zs_kd 1.9679 (1.7548) loss_oracle 1.0053 (1.0473) acc 71.8750 (73.5938) lr 1.8443e-03 eta 0:28:34
epoch [11/50] batch [60/428] time 0.086 (0.093) data 0.000 (0.009) loss 2.5006 (2.3172) teacher_loss 0.8985 (0.7608) loss_zs_kd 2.1281 (1.8102) loss_oracle 1.0556 (1.0439) acc 59.3750 (73.9062) lr 1.8443e-03 eta 0:26:21
epoch [11/50] batch [80/428] time 0.093 (0.091) data 0.000 (0.007) loss 2.3270 (2.3061) teacher_loss 0.8547 (0.7566) loss_zs_kd 1.4683 (1.7930) loss_oracle 1.0217 (1.0380) acc 75.0000 (74.4141) lr 1.8443e-03 eta 0:25:43
epoch [11/50] batch [100/428] time 0.086 (0.089) data 0.000 (0.005) loss 2.1955 (2.3193) teacher_loss 0.6417 (0.7689) loss_zs_kd 1.7590 (1.7631) loss_oracle 0.9934 (1.0380) acc 81.2500 (74.2500) lr 1.8443e-03 eta 0:25:19
epoch [11/50] batch [120/428] time 0.081 (0.088) data 0.000 (0.005) loss 2.2527 (2.3212) teacher_loss 0.7222 (0.7694) loss_zs_kd 1.8422 (1.7358) loss_oracle 1.0047 (1.0377) acc 68.7500 (74.5052) lr 1.8443e-03 eta 0:25:03
epoch [11/50] batch [140/428] time 0.105 (0.088) data 0.000 (0.004) loss 2.7083 (2.3336) teacher_loss 1.2036 (0.7784) loss_zs_kd 1.8451 (1.7268) loss_oracle 0.9828 (1.0392) acc 62.5000 (73.9509) lr 1.8443e-03 eta 0:24:55
epoch [11/50] batch [160/428] time 0.089 (0.087) data 0.000 (0.003) loss 2.8943 (2.3489) teacher_loss 1.2940 (0.7912) loss_zs_kd 1.6937 (1.7297) loss_oracle 1.0549 (1.0408) acc 59.3750 (73.4961) lr 1.8443e-03 eta 0:24:43
epoch [11/50] batch [180/428] time 0.093 (0.087) data 0.000 (0.003) loss 2.5927 (2.3736) teacher_loss 0.9402 (0.8100) loss_zs_kd 1.6476 (1.7057) loss_oracle 1.0796 (1.0421) acc 65.6250 (72.6389) lr 1.8443e-03 eta 0:24:41
epoch [11/50] batch [200/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.6409 (2.4078) teacher_loss 1.0740 (0.8335) loss_zs_kd 1.3235 (1.6803) loss_oracle 1.0103 (1.0433) acc 59.3750 (71.5469) lr 1.8443e-03 eta 0:24:35
epoch [11/50] batch [220/428] time 0.086 (0.087) data 0.000 (0.003) loss 2.4703 (2.4236) teacher_loss 0.9325 (0.8449) loss_zs_kd 1.3914 (1.6764) loss_oracle 0.9730 (1.0426) acc 68.7500 (71.0369) lr 1.8443e-03 eta 0:24:31
epoch [11/50] batch [240/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.8577 (2.4275) teacher_loss 1.2001 (0.8469) loss_zs_kd 2.2225 (1.6818) loss_oracle 1.0855 (1.0435) acc 68.7500 (71.1328) lr 1.8443e-03 eta 0:24:28
epoch [11/50] batch [260/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.2881 (2.4374) teacher_loss 0.7655 (0.8559) loss_zs_kd 1.7083 (1.6825) loss_oracle 1.0576 (1.0445) acc 68.7500 (70.7212) lr 1.8443e-03 eta 0:24:19
epoch [11/50] batch [280/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.5475 (2.4316) teacher_loss 0.9629 (0.8514) loss_zs_kd 1.9326 (1.6819) loss_oracle 1.0576 (1.0439) acc 71.8750 (70.8482) lr 1.8443e-03 eta 0:24:15
epoch [11/50] batch [300/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.6167 (2.4311) teacher_loss 0.9998 (0.8512) loss_zs_kd 1.9202 (1.6902) loss_oracle 1.0730 (1.0445) acc 71.8750 (70.6042) lr 1.8443e-03 eta 0:24:11
epoch [11/50] batch [320/428] time 0.087 (0.086) data 0.001 (0.002) loss 2.4256 (2.4377) teacher_loss 0.8373 (0.8580) loss_zs_kd 2.0427 (1.7069) loss_oracle 1.0808 (1.0450) acc 71.8750 (70.1660) lr 1.8443e-03 eta 0:24:08
epoch [11/50] batch [340/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.6499 (2.4416) teacher_loss 1.0297 (0.8619) loss_zs_kd 1.5649 (1.7096) loss_oracle 1.0341 (1.0451) acc 56.2500 (69.9908) lr 1.8443e-03 eta 0:24:07
epoch [11/50] batch [360/428] time 0.076 (0.086) data 0.000 (0.002) loss 2.4793 (2.4396) teacher_loss 0.8858 (0.8610) loss_zs_kd 1.7244 (1.7127) loss_oracle 1.0092 (1.0450) acc 71.8750 (69.8698) lr 1.8443e-03 eta 0:24:05
epoch [11/50] batch [380/428] time 0.075 (0.086) data 0.000 (0.002) loss 2.5622 (2.4397) teacher_loss 0.9679 (0.8619) loss_zs_kd 1.6701 (1.7133) loss_oracle 1.0527 (1.0444) acc 65.6250 (69.8520) lr 1.8443e-03 eta 0:23:55
epoch [11/50] batch [400/428] time 0.087 (0.085) data 0.000 (0.002) loss 2.4387 (2.4443) teacher_loss 0.8573 (0.8663) loss_zs_kd 1.7917 (1.7108) loss_oracle 1.0293 (1.0435) acc 68.7500 (69.6719) lr 1.8443e-03 eta 0:23:48
epoch [11/50] batch [420/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.3368 (2.4486) teacher_loss 0.7583 (0.8694) loss_zs_kd 1.7162 (1.7131) loss_oracle 0.9942 (1.0428) acc 71.8750 (69.5536) lr 1.8443e-03 eta 0:23:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,621
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 48.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,971
* accuracy: 41.6%
* error: 58.4%
* macro_f1: 27.5%
******* Domain 1 best val acc:      61.6%, epoch: 11 *******
******* Domain 1 best val test acc: 41.6%, epoch: 11 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [12/50] batch [20/428] time 0.074 (0.120) data 0.000 (0.037) loss 2.4027 (2.4372) teacher_loss 0.9478 (0.8682) loss_zs_kd 1.6332 (1.6639) loss_oracle 0.9683 (1.0305) acc 71.8750 (70.0000) lr 1.8090e-03 eta 0:33:28
epoch [12/50] batch [40/428] time 0.081 (0.099) data 0.000 (0.018) loss 2.5278 (2.4155) teacher_loss 0.9355 (0.8404) loss_zs_kd 2.1734 (1.6746) loss_oracle 1.0456 (1.0333) acc 65.6250 (71.4062) lr 1.8090e-03 eta 0:27:34
epoch [12/50] batch [60/428] time 0.088 (0.095) data 0.001 (0.012) loss 2.4598 (2.4184) teacher_loss 0.8954 (0.8498) loss_zs_kd 1.6033 (1.6880) loss_oracle 0.9870 (1.0312) acc 65.6250 (70.3125) lr 1.8090e-03 eta 0:26:21
epoch [12/50] batch [80/428] time 0.084 (0.092) data 0.000 (0.009) loss 2.2213 (2.4062) teacher_loss 0.6492 (0.8403) loss_zs_kd 1.7378 (1.6895) loss_oracle 1.0439 (1.0292) acc 84.3750 (70.5469) lr 1.8090e-03 eta 0:25:35
epoch [12/50] batch [100/428] time 0.089 (0.091) data 0.000 (0.008) loss 2.7395 (2.3998) teacher_loss 1.1829 (0.8371) loss_zs_kd 2.0893 (1.7070) loss_oracle 1.0466 (1.0299) acc 59.3750 (70.9062) lr 1.8090e-03 eta 0:25:11
epoch [12/50] batch [120/428] time 0.089 (0.090) data 0.000 (0.006) loss 2.3883 (2.3916) teacher_loss 0.8546 (0.8309) loss_zs_kd 1.7825 (1.7633) loss_oracle 1.0389 (1.0291) acc 75.0000 (71.1719) lr 1.8090e-03 eta 0:24:50
epoch [12/50] batch [140/428] time 0.080 (0.089) data 0.000 (0.005) loss 2.3936 (2.3855) teacher_loss 0.8305 (0.8275) loss_zs_kd 1.5688 (1.7648) loss_oracle 0.9932 (1.0276) acc 68.7500 (71.2500) lr 1.8090e-03 eta 0:24:39
epoch [12/50] batch [160/428] time 0.072 (0.090) data 0.000 (0.005) loss 2.2437 (2.3788) teacher_loss 0.7245 (0.8217) loss_zs_kd 1.9907 (1.7677) loss_oracle 1.0221 (1.0271) acc 75.0000 (71.3867) lr 1.8090e-03 eta 0:24:44
epoch [12/50] batch [180/428] time 0.081 (0.089) data 0.000 (0.004) loss 2.3712 (2.3702) teacher_loss 0.8121 (0.8136) loss_zs_kd 1.5421 (1.7699) loss_oracle 1.0445 (1.0264) acc 75.0000 (71.7361) lr 1.8090e-03 eta 0:24:25
epoch [12/50] batch [200/428] time 0.080 (0.088) data 0.000 (0.004) loss 2.1928 (2.3628) teacher_loss 0.6420 (0.8081) loss_zs_kd 1.8299 (1.7732) loss_oracle 1.0231 (1.0257) acc 78.1250 (71.9688) lr 1.8090e-03 eta 0:24:13
epoch [12/50] batch [220/428] time 0.080 (0.088) data 0.000 (0.004) loss 2.3828 (2.3601) teacher_loss 0.7753 (0.8081) loss_zs_kd 1.3992 (1.7781) loss_oracle 1.0531 (1.0249) acc 75.0000 (71.9886) lr 1.8090e-03 eta 0:24:07
epoch [12/50] batch [240/428] time 0.087 (0.088) data 0.000 (0.003) loss 2.4367 (2.3662) teacher_loss 0.8846 (0.8147) loss_zs_kd 1.5090 (1.7815) loss_oracle 1.0265 (1.0257) acc 62.5000 (71.7057) lr 1.8090e-03 eta 0:24:01
epoch [12/50] batch [260/428] time 0.087 (0.087) data 0.000 (0.003) loss 2.2321 (2.3618) teacher_loss 0.7793 (0.8119) loss_zs_kd 1.4383 (1.7844) loss_oracle 0.9928 (1.0251) acc 71.8750 (71.6587) lr 1.8090e-03 eta 0:23:56
epoch [12/50] batch [280/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.1464 (2.3638) teacher_loss 0.6152 (0.8153) loss_zs_kd 1.9116 (1.7798) loss_oracle 1.0462 (1.0244) acc 81.2500 (71.6518) lr 1.8090e-03 eta 0:23:49
epoch [12/50] batch [300/428] time 0.083 (0.087) data 0.000 (0.003) loss 2.4307 (2.3647) teacher_loss 0.8902 (0.8178) loss_zs_kd 1.9164 (1.7832) loss_oracle 1.0359 (1.0241) acc 71.8750 (71.6250) lr 1.8090e-03 eta 0:23:40
epoch [12/50] batch [320/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.2856 (2.3697) teacher_loss 0.7451 (0.8248) loss_zs_kd 1.7527 (1.7894) loss_oracle 1.0406 (1.0237) acc 65.6250 (71.3477) lr 1.8090e-03 eta 0:23:33
epoch [12/50] batch [340/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.6262 (2.3679) teacher_loss 1.1735 (0.8248) loss_zs_kd 1.6116 (1.7837) loss_oracle 1.0366 (1.0224) acc 53.1250 (71.2960) lr 1.8090e-03 eta 0:23:22
epoch [12/50] batch [360/428] time 0.067 (0.085) data 0.000 (0.002) loss 2.0782 (2.3657) teacher_loss 0.5510 (0.8239) loss_zs_kd 1.6815 (1.7770) loss_oracle 1.0125 (1.0211) acc 78.1250 (71.3889) lr 1.8090e-03 eta 0:23:10
epoch [12/50] batch [380/428] time 0.070 (0.084) data 0.000 (0.002) loss 2.3834 (2.3628) teacher_loss 0.8300 (0.8222) loss_zs_kd 1.1617 (1.7581) loss_oracle 0.9651 (1.0197) acc 75.0000 (71.3898) lr 1.8090e-03 eta 0:22:51
epoch [12/50] batch [400/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.3610 (2.3611) teacher_loss 0.8792 (0.8212) loss_zs_kd 1.7670 (1.7534) loss_oracle 0.9904 (1.0190) acc 71.8750 (71.3750) lr 1.8090e-03 eta 0:22:46
epoch [12/50] batch [420/428] time 0.078 (0.084) data 0.000 (0.002) loss 2.4763 (2.3651) teacher_loss 0.9695 (0.8259) loss_zs_kd 1.6422 (1.7586) loss_oracle 1.0279 (1.0185) acc 75.0000 (71.2277) lr 1.8090e-03 eta 0:22:45
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,440
* accuracy: 58.5%
* error: 41.5%
* macro_f1: 42.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,848
* accuracy: 39.0%
* error: 61.0%
* macro_f1: 24.9%
******* Domain 1 best val acc:      61.6%, epoch: 11 *******
******* Domain 1 best val test acc: 41.6%, epoch: 11 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [13/50] batch [20/428] time 0.089 (0.118) data 0.000 (0.031) loss 2.2773 (2.4236) teacher_loss 0.7113 (0.8960) loss_zs_kd 2.1843 (2.1275) loss_oracle 1.0517 (1.0144) acc 75.0000 (67.1875) lr 1.7705e-03 eta 0:31:59
epoch [13/50] batch [40/428] time 0.084 (0.099) data 0.000 (0.016) loss 2.4014 (2.4300) teacher_loss 0.8769 (0.9106) loss_zs_kd 2.0383 (2.1077) loss_oracle 1.0328 (1.0083) acc 71.8750 (69.1406) lr 1.7705e-03 eta 0:26:41
epoch [13/50] batch [60/428] time 0.088 (0.094) data 0.001 (0.011) loss 2.3488 (2.3916) teacher_loss 0.8397 (0.8717) loss_zs_kd 1.7948 (1.9825) loss_oracle 0.9780 (1.0065) acc 68.7500 (69.7917) lr 1.7705e-03 eta 0:25:23
epoch [13/50] batch [80/428] time 0.074 (0.091) data 0.000 (0.008) loss 2.3120 (2.3974) teacher_loss 0.8860 (0.8831) loss_zs_kd 1.6996 (1.9403) loss_oracle 1.0202 (1.0028) acc 75.0000 (68.9844) lr 1.7705e-03 eta 0:24:25
epoch [13/50] batch [100/428] time 0.076 (0.088) data 0.000 (0.006) loss 2.4365 (2.3902) teacher_loss 0.9450 (0.8773) loss_zs_kd 2.1189 (1.9405) loss_oracle 1.0055 (1.0027) acc 59.3750 (69.1875) lr 1.7705e-03 eta 0:23:47
epoch [13/50] batch [120/428] time 0.083 (0.087) data 0.000 (0.005) loss 2.2540 (2.4037) teacher_loss 0.8077 (0.8958) loss_zs_kd 1.9793 (1.9594) loss_oracle 0.9831 (1.0013) acc 75.0000 (68.6719) lr 1.7705e-03 eta 0:23:30
epoch [13/50] batch [140/428] time 0.082 (0.087) data 0.000 (0.005) loss 2.2815 (2.4010) teacher_loss 0.8043 (0.8984) loss_zs_kd 1.5986 (1.9652) loss_oracle 0.9759 (0.9978) acc 78.1250 (68.4375) lr 1.7705e-03 eta 0:23:19
epoch [13/50] batch [160/428] time 0.080 (0.087) data 0.000 (0.004) loss 2.4374 (2.4084) teacher_loss 0.9527 (0.9114) loss_zs_kd 1.5563 (1.9401) loss_oracle 0.9585 (0.9952) acc 65.6250 (68.1641) lr 1.7705e-03 eta 0:23:19
epoch [13/50] batch [180/428] time 0.087 (0.087) data 0.000 (0.004) loss 2.1689 (2.3936) teacher_loss 0.6959 (0.9017) loss_zs_kd 1.9346 (1.9302) loss_oracle 0.9709 (0.9906) acc 81.2500 (68.5938) lr 1.7705e-03 eta 0:23:14
epoch [13/50] batch [200/428] time 0.079 (0.087) data 0.000 (0.003) loss 2.2204 (2.3865) teacher_loss 0.7764 (0.8945) loss_zs_kd 2.0149 (1.9125) loss_oracle 0.9325 (0.9880) acc 75.0000 (68.7031) lr 1.7705e-03 eta 0:23:10
epoch [13/50] batch [220/428] time 0.086 (0.086) data 0.000 (0.003) loss 2.2387 (2.3812) teacher_loss 0.7891 (0.8910) loss_zs_kd 1.8851 (1.9055) loss_oracle 0.9953 (0.9858) acc 71.8750 (68.5653) lr 1.7705e-03 eta 0:23:07
epoch [13/50] batch [240/428] time 0.097 (0.086) data 0.000 (0.003) loss 2.4269 (2.3762) teacher_loss 0.9648 (0.8887) loss_zs_kd 1.6955 (1.8944) loss_oracle 0.9098 (0.9830) acc 68.7500 (68.5677) lr 1.7705e-03 eta 0:23:05
epoch [13/50] batch [260/428] time 0.091 (0.086) data 0.000 (0.003) loss 2.2515 (2.3741) teacher_loss 0.7494 (0.8891) loss_zs_kd 1.7872 (1.8892) loss_oracle 0.9315 (0.9802) acc 81.2500 (68.6298) lr 1.7705e-03 eta 0:23:02
epoch [13/50] batch [280/428] time 0.091 (0.086) data 0.000 (0.003) loss 2.3364 (2.3736) teacher_loss 0.9435 (0.8917) loss_zs_kd 1.5728 (1.8801) loss_oracle 0.9329 (0.9776) acc 59.3750 (68.2701) lr 1.7705e-03 eta 0:22:53
epoch [13/50] batch [300/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.2786 (2.3755) teacher_loss 0.8193 (0.8944) loss_zs_kd 1.9055 (1.8734) loss_oracle 0.9683 (0.9758) acc 68.7500 (68.0521) lr 1.7705e-03 eta 0:23:00
epoch [13/50] batch [320/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.4512 (2.3714) teacher_loss 1.0009 (0.8920) loss_zs_kd 1.6780 (1.8690) loss_oracle 0.9507 (0.9732) acc 65.6250 (68.1543) lr 1.7705e-03 eta 0:22:58
epoch [13/50] batch [340/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.2552 (2.3739) teacher_loss 0.7563 (0.8950) loss_zs_kd 1.8960 (1.8680) loss_oracle 0.9293 (0.9711) acc 78.1250 (67.9412) lr 1.7705e-03 eta 0:22:55
epoch [13/50] batch [360/428] time 0.085 (0.087) data 0.000 (0.002) loss 2.5660 (2.3708) teacher_loss 1.1097 (0.8925) loss_zs_kd 1.3690 (1.8631) loss_oracle 0.9445 (0.9694) acc 56.2500 (67.9861) lr 1.7705e-03 eta 0:22:56
epoch [13/50] batch [380/428] time 0.063 (0.086) data 0.000 (0.002) loss 2.7000 (2.3742) teacher_loss 1.2752 (0.8963) loss_zs_kd 1.7016 (1.8557) loss_oracle 0.9365 (0.9674) acc 43.7500 (67.8125) lr 1.7705e-03 eta 0:22:52
epoch [13/50] batch [400/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.3006 (2.3695) teacher_loss 0.8014 (0.8932) loss_zs_kd 1.9292 (1.8520) loss_oracle 0.9505 (0.9653) acc 65.6250 (67.8984) lr 1.7705e-03 eta 0:22:47
epoch [13/50] batch [420/428] time 0.073 (0.086) data 0.000 (0.002) loss 2.4771 (2.3681) teacher_loss 1.0383 (0.8924) loss_zs_kd 1.5726 (1.8515) loss_oracle 0.9269 (0.9634) acc 59.3750 (67.9836) lr 1.7705e-03 eta 0:22:41
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,718
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 50.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,953
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 28.9%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [14/50] batch [20/428] time 0.082 (0.120) data 0.000 (0.031) loss 2.5749 (2.3678) teacher_loss 1.1517 (0.9478) loss_zs_kd 2.0908 (1.9992) loss_oracle 0.9232 (0.9206) acc 56.2500 (66.2500) lr 1.7290e-03 eta 0:31:33
epoch [14/50] batch [40/428] time 0.082 (0.106) data 0.000 (0.016) loss 2.5790 (2.3232) teacher_loss 1.1544 (0.8978) loss_zs_kd 2.0998 (2.0084) loss_oracle 0.8434 (0.9180) acc 62.5000 (67.8125) lr 1.7290e-03 eta 0:27:53
epoch [14/50] batch [60/428] time 0.094 (0.098) data 0.001 (0.011) loss 1.9758 (2.3174) teacher_loss 0.5176 (0.8787) loss_zs_kd 1.6595 (1.8996) loss_oracle 0.9285 (0.9201) acc 81.2500 (68.5417) lr 1.7290e-03 eta 0:25:39
epoch [14/50] batch [80/428] time 0.088 (0.094) data 0.000 (0.008) loss 1.9912 (2.3118) teacher_loss 0.5853 (0.8622) loss_zs_kd 1.4203 (1.8542) loss_oracle 0.8859 (0.9204) acc 78.1250 (69.4922) lr 1.7290e-03 eta 0:24:47
epoch [14/50] batch [100/428] time 0.073 (0.092) data 0.000 (0.006) loss 2.4953 (2.3189) teacher_loss 1.0532 (0.8541) loss_zs_kd 1.6003 (1.8350) loss_oracle 0.9574 (0.9258) acc 68.7500 (69.8750) lr 1.7290e-03 eta 0:24:09
epoch [14/50] batch [120/428] time 0.090 (0.091) data 0.000 (0.005) loss 2.2023 (2.3126) teacher_loss 0.7963 (0.8510) loss_zs_kd 1.9891 (1.8669) loss_oracle 0.9187 (0.9231) acc 71.8750 (70.0260) lr 1.7290e-03 eta 0:23:53
epoch [14/50] batch [140/428] time 0.084 (0.090) data 0.000 (0.005) loss 2.2578 (2.3068) teacher_loss 0.7906 (0.8489) loss_zs_kd 1.9481 (1.8709) loss_oracle 0.9286 (0.9219) acc 71.8750 (70.2232) lr 1.7290e-03 eta 0:23:35
epoch [14/50] batch [160/428] time 0.082 (0.089) data 0.001 (0.004) loss 2.3634 (2.3055) teacher_loss 0.9206 (0.8442) loss_zs_kd 1.9429 (1.8724) loss_oracle 0.9461 (0.9218) acc 71.8750 (70.3320) lr 1.7290e-03 eta 0:23:22
epoch [14/50] batch [180/428] time 0.075 (0.089) data 0.000 (0.004) loss 2.2747 (2.3126) teacher_loss 0.8002 (0.8474) loss_zs_kd 1.7990 (1.8576) loss_oracle 0.9032 (0.9248) acc 71.8750 (70.0000) lr 1.7290e-03 eta 0:23:14
epoch [14/50] batch [200/428] time 0.089 (0.089) data 0.000 (0.003) loss 2.2293 (2.3187) teacher_loss 0.6050 (0.8458) loss_zs_kd 1.8527 (1.8545) loss_oracle 1.0294 (0.9288) acc 81.2500 (70.2344) lr 1.7290e-03 eta 0:23:09
epoch [14/50] batch [220/428] time 0.086 (0.089) data 0.001 (0.003) loss 2.2613 (2.3272) teacher_loss 0.8136 (0.8519) loss_zs_kd 1.6529 (1.8356) loss_oracle 0.8929 (0.9303) acc 68.7500 (70.0000) lr 1.7290e-03 eta 0:23:04
epoch [14/50] batch [240/428] time 0.085 (0.088) data 0.000 (0.003) loss 2.2023 (2.3264) teacher_loss 0.7043 (0.8502) loss_zs_kd 1.4720 (1.8212) loss_oracle 0.9541 (0.9302) acc 68.7500 (70.0521) lr 1.7290e-03 eta 0:22:57
epoch [14/50] batch [260/428] time 0.091 (0.088) data 0.000 (0.003) loss 2.2398 (2.3294) teacher_loss 0.8708 (0.8538) loss_zs_kd 1.4992 (1.8009) loss_oracle 0.8901 (0.9298) acc 62.5000 (69.8317) lr 1.7290e-03 eta 0:22:53
epoch [14/50] batch [280/428] time 0.088 (0.088) data 0.000 (0.003) loss 2.4976 (2.3274) teacher_loss 0.8410 (0.8490) loss_zs_kd 1.5543 (1.7964) loss_oracle 1.0434 (0.9317) acc 65.6250 (69.9777) lr 1.7290e-03 eta 0:22:49
epoch [14/50] batch [300/428] time 0.088 (0.088) data 0.000 (0.002) loss 2.6653 (2.3367) teacher_loss 1.2866 (0.8526) loss_zs_kd 1.8419 (1.8016) loss_oracle 0.8998 (0.9342) acc 53.1250 (69.8125) lr 1.7290e-03 eta 0:22:44
epoch [14/50] batch [320/428] time 0.083 (0.088) data 0.000 (0.002) loss 2.2843 (2.3432) teacher_loss 0.7889 (0.8546) loss_zs_kd 1.2144 (1.7873) loss_oracle 0.9455 (0.9370) acc 71.8750 (69.7852) lr 1.7290e-03 eta 0:22:40
epoch [14/50] batch [340/428] time 0.096 (0.088) data 0.000 (0.002) loss 2.3053 (2.3395) teacher_loss 0.8031 (0.8493) loss_zs_kd 2.0867 (1.7938) loss_oracle 0.9430 (0.9375) acc 68.7500 (70.0827) lr 1.7290e-03 eta 0:22:36
epoch [14/50] batch [360/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.2180 (2.3390) teacher_loss 0.7905 (0.8478) loss_zs_kd 1.5918 (1.7971) loss_oracle 0.9463 (0.9380) acc 81.2500 (70.2257) lr 1.7290e-03 eta 0:22:32
epoch [14/50] batch [380/428] time 0.090 (0.087) data 0.001 (0.002) loss 2.4688 (2.3346) teacher_loss 0.9511 (0.8439) loss_zs_kd 1.7325 (1.7969) loss_oracle 0.9579 (0.9377) acc 65.6250 (70.3618) lr 1.7290e-03 eta 0:22:27
epoch [14/50] batch [400/428] time 0.088 (0.087) data 0.000 (0.002) loss 2.6350 (2.3350) teacher_loss 1.0863 (0.8436) loss_zs_kd 1.8188 (1.7954) loss_oracle 0.9897 (0.9384) acc 65.6250 (70.4297) lr 1.7290e-03 eta 0:22:22
epoch [14/50] batch [420/428] time 0.077 (0.087) data 0.000 (0.002) loss 2.4461 (2.3325) teacher_loss 0.8985 (0.8405) loss_zs_kd 2.2258 (1.8009) loss_oracle 0.9464 (0.9387) acc 62.5000 (70.4836) lr 1.7290e-03 eta 0:22:26
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,635
* accuracy: 61.9%
* error: 38.1%
* macro_f1: 49.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,071
* accuracy: 43.7%
* error: 56.3%
* macro_f1: 30.5%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [15/50] batch [20/428] time 0.087 (0.114) data 0.000 (0.025) loss 2.2971 (2.3020) teacher_loss 0.7248 (0.7237) loss_zs_kd 1.5436 (1.8500) loss_oracle 1.0089 (0.9726) acc 75.0000 (74.0625) lr 1.6845e-03 eta 0:29:20
epoch [15/50] batch [40/428] time 0.082 (0.099) data 0.000 (0.013) loss 2.3369 (2.3452) teacher_loss 0.7932 (0.7707) loss_zs_kd 2.0407 (1.7320) loss_oracle 0.9252 (0.9732) acc 71.8750 (72.5000) lr 1.6845e-03 eta 0:25:21
epoch [15/50] batch [60/428] time 0.097 (0.095) data 0.000 (0.009) loss 2.3506 (2.3617) teacher_loss 0.7832 (0.8016) loss_zs_kd 2.0693 (1.7288) loss_oracle 0.9533 (0.9641) acc 65.6250 (71.5625) lr 1.6845e-03 eta 0:24:16
epoch [15/50] batch [80/428] time 0.095 (0.093) data 0.000 (0.007) loss 2.6133 (2.3523) teacher_loss 1.0505 (0.8010) loss_zs_kd 2.0156 (1.7311) loss_oracle 0.9633 (0.9613) acc 68.7500 (72.0312) lr 1.6845e-03 eta 0:23:52
epoch [15/50] batch [100/428] time 0.082 (0.092) data 0.000 (0.005) loss 2.6168 (2.3521) teacher_loss 1.0575 (0.8087) loss_zs_kd 1.9965 (1.7625) loss_oracle 1.0288 (0.9580) acc 68.7500 (71.6875) lr 1.6845e-03 eta 0:23:26
epoch [15/50] batch [120/428] time 0.082 (0.091) data 0.000 (0.004) loss 2.8308 (2.3589) teacher_loss 1.3994 (0.8193) loss_zs_kd 1.3394 (1.7596) loss_oracle 0.9635 (0.9568) acc 59.3750 (71.1458) lr 1.6845e-03 eta 0:23:05
epoch [15/50] batch [140/428] time 0.081 (0.089) data 0.000 (0.004) loss 2.5935 (2.3651) teacher_loss 1.0351 (0.8265) loss_zs_kd 1.9959 (1.7448) loss_oracle 0.8969 (0.9549) acc 62.5000 (71.0938) lr 1.6845e-03 eta 0:22:42
epoch [15/50] batch [160/428] time 0.082 (0.090) data 0.000 (0.003) loss 2.5276 (2.3694) teacher_loss 0.9720 (0.8334) loss_zs_kd 1.8023 (1.7438) loss_oracle 1.0095 (0.9519) acc 56.2500 (70.5664) lr 1.6845e-03 eta 0:22:53
epoch [15/50] batch [180/428] time 0.080 (0.090) data 0.000 (0.003) loss 2.6503 (2.3797) teacher_loss 1.0495 (0.8419) loss_zs_kd 1.6799 (1.7294) loss_oracle 0.9420 (0.9502) acc 62.5000 (70.1736) lr 1.6845e-03 eta 0:22:43
epoch [15/50] batch [200/428] time 0.092 (0.089) data 0.001 (0.003) loss 1.8945 (2.3750) teacher_loss 0.4455 (0.8417) loss_zs_kd 1.6953 (1.7217) loss_oracle 0.8826 (0.9485) acc 93.7500 (70.3750) lr 1.6845e-03 eta 0:22:36
epoch [15/50] batch [220/428] time 0.077 (0.089) data 0.000 (0.003) loss 2.5578 (2.3701) teacher_loss 1.0293 (0.8397) loss_zs_kd 1.7317 (1.7354) loss_oracle 1.0222 (0.9484) acc 68.7500 (70.5540) lr 1.6845e-03 eta 0:22:26
epoch [15/50] batch [240/428] time 0.086 (0.088) data 0.000 (0.002) loss 2.4831 (2.3660) teacher_loss 0.9216 (0.8374) loss_zs_kd 1.7827 (1.7449) loss_oracle 0.9450 (0.9481) acc 68.7500 (70.4036) lr 1.6845e-03 eta 0:22:18
epoch [15/50] batch [260/428] time 0.087 (0.088) data 0.000 (0.002) loss 2.2621 (2.3650) teacher_loss 0.7050 (0.8349) loss_zs_kd 1.8751 (1.7403) loss_oracle 0.9749 (0.9485) acc 68.7500 (70.4327) lr 1.6845e-03 eta 0:22:13
epoch [15/50] batch [280/428] time 0.088 (0.088) data 0.000 (0.002) loss 2.3105 (2.3599) teacher_loss 0.8198 (0.8294) loss_zs_kd 1.6396 (1.7376) loss_oracle 0.9943 (0.9486) acc 75.0000 (70.5915) lr 1.6845e-03 eta 0:22:08
epoch [15/50] batch [300/428] time 0.085 (0.088) data 0.000 (0.002) loss 2.6126 (2.3560) teacher_loss 1.1101 (0.8269) loss_zs_kd 1.7130 (1.7464) loss_oracle 0.9455 (0.9492) acc 59.3750 (70.6250) lr 1.6845e-03 eta 0:22:03
epoch [15/50] batch [320/428] time 0.087 (0.088) data 0.000 (0.002) loss 2.6892 (2.3547) teacher_loss 1.1701 (0.8272) loss_zs_kd 1.9656 (1.7512) loss_oracle 0.9912 (0.9504) acc 62.5000 (70.4980) lr 1.6845e-03 eta 0:22:00
epoch [15/50] batch [340/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.2441 (2.3559) teacher_loss 0.8144 (0.8310) loss_zs_kd 1.5348 (1.7567) loss_oracle 0.9059 (0.9504) acc 71.8750 (70.4412) lr 1.6845e-03 eta 0:21:55
epoch [15/50] batch [360/428] time 0.087 (0.087) data 0.000 (0.002) loss 2.4293 (2.3502) teacher_loss 1.0880 (0.8287) loss_zs_kd 1.7632 (1.7621) loss_oracle 0.9559 (0.9490) acc 65.6250 (70.5208) lr 1.6845e-03 eta 0:21:50
epoch [15/50] batch [380/428] time 0.074 (0.087) data 0.000 (0.002) loss 2.6114 (2.3470) teacher_loss 1.1500 (0.8298) loss_zs_kd 2.3791 (1.7828) loss_oracle 0.9281 (0.9479) acc 56.2500 (70.4605) lr 1.6845e-03 eta 0:21:50
epoch [15/50] batch [400/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.4603 (2.3462) teacher_loss 1.0344 (0.8319) loss_zs_kd 1.9108 (1.7927) loss_oracle 0.9238 (0.9471) acc 65.6250 (70.3125) lr 1.6845e-03 eta 0:21:44
epoch [15/50] batch [420/428] time 0.077 (0.087) data 0.000 (0.001) loss 2.4133 (2.3483) teacher_loss 0.8751 (0.8339) loss_zs_kd 1.3005 (1.7847) loss_oracle 0.9500 (0.9468) acc 65.6250 (70.2232) lr 1.6845e-03 eta 0:21:40
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,673
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,886
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 27.7%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [16/50] batch [20/428] time 0.083 (0.116) data 0.000 (0.024) loss 2.8305 (2.3455) teacher_loss 1.1883 (0.7811) loss_zs_kd 2.2682 (1.7568) loss_oracle 0.8746 (0.9652) acc 56.2500 (73.4375) lr 1.6374e-03 eta 0:29:01
epoch [16/50] batch [40/428] time 0.072 (0.102) data 0.000 (0.012) loss 2.2872 (2.3842) teacher_loss 0.7113 (0.8084) loss_zs_kd 1.7514 (1.8089) loss_oracle 0.9313 (0.9732) acc 68.7500 (71.4062) lr 1.6374e-03 eta 0:25:18
epoch [16/50] batch [60/428] time 0.074 (0.095) data 0.000 (0.008) loss 2.7505 (2.4017) teacher_loss 1.1663 (0.8141) loss_zs_kd 1.6974 (1.7914) loss_oracle 1.0322 (0.9854) acc 56.2500 (71.5104) lr 1.6374e-03 eta 0:23:35
epoch [16/50] batch [80/428] time 0.080 (0.090) data 0.000 (0.006) loss 2.0888 (2.3688) teacher_loss 0.4949 (0.7876) loss_zs_kd 1.7212 (1.8237) loss_oracle 0.9787 (0.9830) acc 81.2500 (73.0078) lr 1.6374e-03 eta 0:22:21
epoch [16/50] batch [100/428] time 0.070 (0.088) data 0.000 (0.005) loss 2.4689 (2.3494) teacher_loss 0.9390 (0.7806) loss_zs_kd 2.3788 (1.8436) loss_oracle 0.9264 (0.9764) acc 71.8750 (73.2812) lr 1.6374e-03 eta 0:21:47
epoch [16/50] batch [120/428] time 0.077 (0.086) data 0.000 (0.004) loss 2.1326 (2.3481) teacher_loss 0.5815 (0.7901) loss_zs_kd 1.7855 (1.8723) loss_oracle 0.9762 (0.9702) acc 81.2500 (72.8125) lr 1.6374e-03 eta 0:21:13
epoch [16/50] batch [140/428] time 0.076 (0.085) data 0.000 (0.004) loss 2.1683 (2.3359) teacher_loss 0.6451 (0.7779) loss_zs_kd 1.8987 (1.8626) loss_oracle 0.9839 (0.9708) acc 81.2500 (73.0134) lr 1.6374e-03 eta 0:20:56
epoch [16/50] batch [160/428] time 0.082 (0.084) data 0.000 (0.003) loss 2.4513 (2.3314) teacher_loss 0.9878 (0.7818) loss_zs_kd 1.9393 (1.8668) loss_oracle 0.9299 (0.9681) acc 65.6250 (72.8711) lr 1.6374e-03 eta 0:20:38
epoch [16/50] batch [180/428] time 0.084 (0.083) data 0.000 (0.003) loss 1.9448 (2.3301) teacher_loss 0.4863 (0.7919) loss_zs_kd 1.7854 (1.8682) loss_oracle 0.9716 (0.9652) acc 90.6250 (72.4132) lr 1.6374e-03 eta 0:20:29
epoch [16/50] batch [200/428] time 0.079 (0.083) data 0.000 (0.003) loss 2.2176 (2.3350) teacher_loss 0.6717 (0.8000) loss_zs_kd 1.9104 (1.8613) loss_oracle 0.9624 (0.9645) acc 68.7500 (72.2188) lr 1.6374e-03 eta 0:20:22
epoch [16/50] batch [220/428] time 0.087 (0.083) data 0.000 (0.002) loss 2.0927 (2.3352) teacher_loss 0.6663 (0.8044) loss_zs_kd 1.7942 (1.8491) loss_oracle 0.9576 (0.9634) acc 81.2500 (72.2159) lr 1.6374e-03 eta 0:20:20
epoch [16/50] batch [240/428] time 0.085 (0.083) data 0.000 (0.002) loss 2.2202 (2.3348) teacher_loss 0.7699 (0.8041) loss_zs_kd 1.6461 (1.8325) loss_oracle 0.9376 (0.9637) acc 81.2500 (72.3047) lr 1.6374e-03 eta 0:20:19
epoch [16/50] batch [260/428] time 0.098 (0.083) data 0.000 (0.002) loss 2.6647 (2.3376) teacher_loss 1.0797 (0.8069) loss_zs_kd 1.5441 (1.8331) loss_oracle 0.9798 (0.9632) acc 59.3750 (72.1875) lr 1.6374e-03 eta 0:20:19
epoch [16/50] batch [280/428] time 0.080 (0.084) data 0.000 (0.002) loss 2.6056 (2.3389) teacher_loss 1.0003 (0.8089) loss_zs_kd 1.6715 (1.8248) loss_oracle 0.9336 (0.9620) acc 68.7500 (72.1540) lr 1.6374e-03 eta 0:20:28
epoch [16/50] batch [300/428] time 0.078 (0.083) data 0.000 (0.002) loss 2.4755 (2.3394) teacher_loss 0.9744 (0.8093) loss_zs_kd 1.7322 (1.8257) loss_oracle 0.9558 (0.9622) acc 71.8750 (72.2083) lr 1.6374e-03 eta 0:20:23
epoch [16/50] batch [320/428] time 0.077 (0.083) data 0.000 (0.002) loss 2.4168 (2.3371) teacher_loss 0.9429 (0.8076) loss_zs_kd 1.9617 (1.8297) loss_oracle 0.9406 (0.9623) acc 59.3750 (72.3145) lr 1.6374e-03 eta 0:20:16
epoch [16/50] batch [340/428] time 0.084 (0.083) data 0.000 (0.002) loss 2.3100 (2.3304) teacher_loss 0.8369 (0.8033) loss_zs_kd 1.8659 (1.8300) loss_oracle 0.9612 (0.9615) acc 59.3750 (72.5184) lr 1.6374e-03 eta 0:20:11
epoch [16/50] batch [360/428] time 0.081 (0.083) data 0.000 (0.002) loss 2.4123 (2.3306) teacher_loss 0.8993 (0.8048) loss_zs_kd 1.7608 (1.8189) loss_oracle 0.9678 (0.9610) acc 62.5000 (72.5434) lr 1.6374e-03 eta 0:20:10
epoch [16/50] batch [380/428] time 0.090 (0.083) data 0.000 (0.002) loss 2.1766 (2.3286) teacher_loss 0.5344 (0.8008) loss_zs_kd 1.9707 (1.8136) loss_oracle 1.0477 (0.9619) acc 78.1250 (72.7138) lr 1.6374e-03 eta 0:20:09
epoch [16/50] batch [400/428] time 0.083 (0.083) data 0.000 (0.001) loss 2.3178 (2.3309) teacher_loss 0.6859 (0.8009) loss_zs_kd 1.9582 (1.8094) loss_oracle 1.0070 (0.9636) acc 75.0000 (72.6328) lr 1.6374e-03 eta 0:20:09
epoch [16/50] batch [420/428] time 0.078 (0.083) data 0.000 (0.001) loss 2.0487 (2.3344) teacher_loss 0.5151 (0.8030) loss_zs_kd 1.9474 (1.8075) loss_oracle 0.9871 (0.9651) acc 84.3750 (72.5595) lr 1.6374e-03 eta 0:20:06
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,695
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 51.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,102
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 32.4%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [17/50] batch [20/428] time 0.073 (0.122) data 0.001 (0.029) loss 2.2352 (2.2992) teacher_loss 0.6533 (0.7426) loss_zs_kd 1.6640 (1.6984) loss_oracle 0.9669 (0.9776) acc 75.0000 (75.3125) lr 1.5878e-03 eta 0:29:27
epoch [17/50] batch [40/428] time 0.081 (0.099) data 0.000 (0.014) loss 2.4000 (2.3011) teacher_loss 0.8944 (0.7499) loss_zs_kd 1.7644 (1.7151) loss_oracle 0.9841 (0.9776) acc 65.6250 (75.8594) lr 1.5878e-03 eta 0:23:59
epoch [17/50] batch [60/428] time 0.081 (0.092) data 0.000 (0.010) loss 2.0877 (2.3016) teacher_loss 0.5985 (0.7414) loss_zs_kd 1.5424 (1.7138) loss_oracle 0.9738 (0.9846) acc 78.1250 (75.5729) lr 1.5878e-03 eta 0:22:13
epoch [17/50] batch [80/428] time 0.090 (0.089) data 0.000 (0.007) loss 2.2363 (2.2932) teacher_loss 0.7245 (0.7396) loss_zs_kd 1.7273 (1.7458) loss_oracle 0.9464 (0.9800) acc 71.8750 (75.7812) lr 1.5878e-03 eta 0:21:32
epoch [17/50] batch [100/428] time 0.083 (0.088) data 0.000 (0.006) loss 2.0391 (2.2845) teacher_loss 0.5204 (0.7329) loss_zs_kd 1.8587 (1.7736) loss_oracle 1.0431 (0.9810) acc 87.5000 (75.7812) lr 1.5878e-03 eta 0:21:16
epoch [17/50] batch [120/428] time 0.073 (0.087) data 0.000 (0.005) loss 2.5901 (2.3028) teacher_loss 1.0024 (0.7489) loss_zs_kd 1.8796 (1.7581) loss_oracle 1.0125 (0.9811) acc 68.7500 (75.3906) lr 1.5878e-03 eta 0:20:55
epoch [17/50] batch [140/428] time 0.083 (0.086) data 0.000 (0.004) loss 2.0169 (2.2966) teacher_loss 0.4630 (0.7426) loss_zs_kd 1.9859 (1.7482) loss_oracle 0.9774 (0.9793) acc 90.6250 (75.4911) lr 1.5878e-03 eta 0:20:43
epoch [17/50] batch [160/428] time 0.084 (0.086) data 0.000 (0.004) loss 2.3731 (2.3061) teacher_loss 0.8739 (0.7500) loss_zs_kd 1.8710 (1.7330) loss_oracle 0.9588 (0.9817) acc 71.8750 (75.1562) lr 1.5878e-03 eta 0:20:31
epoch [17/50] batch [180/428] time 0.076 (0.085) data 0.000 (0.003) loss 2.4328 (2.3133) teacher_loss 0.7971 (0.7578) loss_zs_kd 1.5476 (1.7242) loss_oracle 1.0385 (0.9845) acc 78.1250 (74.9479) lr 1.5878e-03 eta 0:20:20
epoch [17/50] batch [200/428] time 0.095 (0.085) data 0.000 (0.003) loss 1.9434 (2.3143) teacher_loss 0.3871 (0.7579) loss_zs_kd 1.6824 (1.7286) loss_oracle 0.9714 (0.9859) acc 87.5000 (74.6094) lr 1.5878e-03 eta 0:20:20
epoch [17/50] batch [220/428] time 0.089 (0.085) data 0.000 (0.003) loss 2.4321 (2.3084) teacher_loss 0.9261 (0.7531) loss_zs_kd 2.2335 (1.7355) loss_oracle 1.0123 (0.9869) acc 65.6250 (74.7017) lr 1.5878e-03 eta 0:20:19
epoch [17/50] batch [240/428] time 0.074 (0.085) data 0.000 (0.003) loss 2.3938 (2.3115) teacher_loss 0.7656 (0.7566) loss_zs_kd 1.8182 (1.7380) loss_oracle 0.9811 (0.9883) acc 71.8750 (74.5182) lr 1.5878e-03 eta 0:20:15
epoch [17/50] batch [260/428] time 0.084 (0.085) data 0.000 (0.002) loss 2.5066 (2.3219) teacher_loss 0.9291 (0.7672) loss_zs_kd 1.9314 (1.7292) loss_oracle 1.0204 (0.9885) acc 65.6250 (74.1587) lr 1.5878e-03 eta 0:20:13
epoch [17/50] batch [280/428] time 0.077 (0.085) data 0.000 (0.002) loss 2.3073 (2.3222) teacher_loss 0.7736 (0.7671) loss_zs_kd 2.1699 (1.7381) loss_oracle 0.9571 (0.9890) acc 71.8750 (74.0737) lr 1.5878e-03 eta 0:20:07
epoch [17/50] batch [300/428] time 0.078 (0.084) data 0.000 (0.002) loss 2.2131 (2.3227) teacher_loss 0.6795 (0.7691) loss_zs_kd 2.2267 (1.7448) loss_oracle 0.9599 (0.9893) acc 78.1250 (74.0521) lr 1.5878e-03 eta 0:20:03
epoch [17/50] batch [320/428] time 0.081 (0.084) data 0.001 (0.002) loss 2.4234 (2.3216) teacher_loss 0.9369 (0.7689) loss_zs_kd 2.0375 (1.7453) loss_oracle 0.9795 (0.9895) acc 71.8750 (74.0137) lr 1.5878e-03 eta 0:19:57
epoch [17/50] batch [340/428] time 0.088 (0.084) data 0.000 (0.002) loss 2.3017 (2.3246) teacher_loss 0.7706 (0.7725) loss_zs_kd 1.7123 (1.7448) loss_oracle 1.0297 (0.9893) acc 71.8750 (73.8787) lr 1.5878e-03 eta 0:19:55
epoch [17/50] batch [360/428] time 0.092 (0.084) data 0.000 (0.002) loss 2.2828 (2.3284) teacher_loss 0.7450 (0.7756) loss_zs_kd 1.5823 (1.7434) loss_oracle 1.0059 (0.9903) acc 75.0000 (73.8021) lr 1.5878e-03 eta 0:19:55
epoch [17/50] batch [380/428] time 0.078 (0.084) data 0.000 (0.002) loss 2.2236 (2.3306) teacher_loss 0.6622 (0.7772) loss_zs_kd 1.6865 (1.7436) loss_oracle 0.9926 (0.9901) acc 78.1250 (73.7664) lr 1.5878e-03 eta 0:19:48
epoch [17/50] batch [400/428] time 0.087 (0.084) data 0.001 (0.002) loss 2.4235 (2.3344) teacher_loss 0.9686 (0.7808) loss_zs_kd 2.0084 (1.7375) loss_oracle 0.9657 (0.9910) acc 68.7500 (73.6875) lr 1.5878e-03 eta 0:19:45
epoch [17/50] batch [420/428] time 0.064 (0.084) data 0.000 (0.002) loss 2.1675 (2.3367) teacher_loss 0.6343 (0.7834) loss_zs_kd 1.7668 (1.7370) loss_oracle 0.9847 (0.9911) acc 87.5000 (73.5193) lr 1.5878e-03 eta 0:19:45
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,698
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 51.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,825
* accuracy: 38.5%
* error: 61.5%
* macro_f1: 26.2%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     47.3%, epoch: 9 *******
epoch [18/50] batch [20/428] time 0.074 (0.112) data 0.000 (0.027) loss 2.3236 (2.2673) teacher_loss 0.7510 (0.7197) loss_zs_kd 1.5333 (1.8281) loss_oracle 0.9845 (1.0025) acc 65.6250 (74.2188) lr 1.5358e-03 eta 0:26:22
epoch [18/50] batch [40/428] time 0.094 (0.098) data 0.000 (0.014) loss 2.1393 (2.3037) teacher_loss 0.5875 (0.7531) loss_zs_kd 1.6459 (1.8367) loss_oracle 1.0105 (1.0054) acc 75.0000 (73.2031) lr 1.5358e-03 eta 0:22:53
epoch [18/50] batch [60/428] time 0.085 (0.093) data 0.001 (0.009) loss 2.5620 (2.2822) teacher_loss 1.0517 (0.7403) loss_zs_kd 2.1326 (1.8580) loss_oracle 0.9155 (1.0011) acc 71.8750 (74.0104) lr 1.5358e-03 eta 0:21:46
epoch [18/50] batch [80/428] time 0.080 (0.091) data 0.000 (0.007) loss 2.7428 (2.3258) teacher_loss 1.1830 (0.7815) loss_zs_kd 1.5925 (1.8608) loss_oracle 0.9998 (1.0014) acc 62.5000 (73.2812) lr 1.5358e-03 eta 0:21:13
epoch [18/50] batch [100/428] time 0.081 (0.089) data 0.000 (0.006) loss 1.9558 (2.3423) teacher_loss 0.4477 (0.7970) loss_zs_kd 1.7085 (1.8003) loss_oracle 1.0240 (1.0036) acc 84.3750 (72.6250) lr 1.5358e-03 eta 0:20:47
epoch [18/50] batch [120/428] time 0.094 (0.088) data 0.000 (0.005) loss 2.2250 (2.3483) teacher_loss 0.7340 (0.8040) loss_zs_kd 1.5892 (1.7703) loss_oracle 0.9723 (1.0051) acc 65.6250 (72.1094) lr 1.5358e-03 eta 0:20:39
epoch [18/50] batch [140/428] time 0.064 (0.086) data 0.000 (0.004) loss 2.2958 (2.3613) teacher_loss 0.7938 (0.8170) loss_zs_kd 1.4160 (1.7551) loss_oracle 0.9656 (1.0060) acc 62.5000 (71.5402) lr 1.5358e-03 eta 0:20:03
epoch [18/50] batch [160/428] time 0.067 (0.083) data 0.000 (0.004) loss 2.3609 (2.3547) teacher_loss 0.7299 (0.8126) loss_zs_kd 1.6210 (1.7436) loss_oracle 1.0145 (1.0052) acc 68.7500 (71.8359) lr 1.5358e-03 eta 0:19:23
epoch [18/50] batch [180/428] time 0.063 (0.082) data 0.000 (0.003) loss 2.5464 (2.3521) teacher_loss 1.0515 (0.8117) loss_zs_kd 1.6499 (1.7378) loss_oracle 0.9781 (1.0058) acc 68.7500 (72.1701) lr 1.5358e-03 eta 0:19:08
epoch [18/50] batch [200/428] time 0.068 (0.081) data 0.000 (0.003) loss 2.2252 (2.3455) teacher_loss 0.6706 (0.8053) loss_zs_kd 1.5736 (1.7393) loss_oracle 0.9748 (1.0054) acc 75.0000 (72.5781) lr 1.5358e-03 eta 0:18:42
epoch [18/50] batch [220/428] time 0.063 (0.079) data 0.000 (0.003) loss 2.5160 (2.3485) teacher_loss 0.9600 (0.8105) loss_zs_kd 1.7901 (1.7508) loss_oracle 0.9839 (1.0049) acc 68.7500 (72.4432) lr 1.5358e-03 eta 0:18:18
epoch [18/50] batch [240/428] time 0.076 (0.078) data 0.000 (0.002) loss 2.1441 (2.3496) teacher_loss 0.6615 (0.8126) loss_zs_kd 1.4132 (1.7494) loss_oracle 1.0112 (1.0038) acc 84.3750 (72.3047) lr 1.5358e-03 eta 0:18:00
epoch [18/50] batch [260/428] time 0.064 (0.077) data 0.000 (0.002) loss 2.5296 (2.3460) teacher_loss 0.9457 (0.8083) loss_zs_kd 2.1105 (1.7584) loss_oracle 1.0150 (1.0037) acc 71.8750 (72.3678) lr 1.5358e-03 eta 0:17:45
epoch [18/50] batch [280/428] time 0.067 (0.076) data 0.000 (0.002) loss 2.0382 (2.3356) teacher_loss 0.4807 (0.7994) loss_zs_kd 2.0587 (1.7702) loss_oracle 1.0266 (1.0033) acc 87.5000 (72.6786) lr 1.5358e-03 eta 0:17:32
epoch [18/50] batch [300/428] time 0.064 (0.075) data 0.000 (0.002) loss 2.1270 (2.3370) teacher_loss 0.5952 (0.8007) loss_zs_kd 2.2069 (1.7808) loss_oracle 0.9767 (1.0025) acc 75.0000 (72.5208) lr 1.5358e-03 eta 0:17:20
epoch [18/50] batch [320/428] time 0.068 (0.075) data 0.000 (0.002) loss 2.1613 (2.3331) teacher_loss 0.6912 (0.7983) loss_zs_kd 1.9427 (1.8006) loss_oracle 0.9649 (1.0005) acc 71.8750 (72.5879) lr 1.5358e-03 eta 0:17:09
epoch [18/50] batch [340/428] time 0.061 (0.074) data 0.000 (0.002) loss 2.2546 (2.3308) teacher_loss 0.7317 (0.7962) loss_zs_kd 1.6626 (1.8074) loss_oracle 0.9906 (0.9998) acc 78.1250 (72.6195) lr 1.5358e-03 eta 0:17:00
epoch [18/50] batch [360/428] time 0.077 (0.073) data 0.000 (0.002) loss 2.4065 (2.3303) teacher_loss 0.8899 (0.7970) loss_zs_kd 1.4927 (1.8089) loss_oracle 1.0182 (0.9988) acc 65.6250 (72.5694) lr 1.5358e-03 eta 0:16:51
epoch [18/50] batch [380/428] time 0.061 (0.073) data 0.000 (0.002) loss 2.7904 (2.3328) teacher_loss 1.1617 (0.7984) loss_zs_kd 1.8856 (1.8133) loss_oracle 1.0281 (0.9987) acc 62.5000 (72.5905) lr 1.5358e-03 eta 0:16:43
epoch [18/50] batch [400/428] time 0.070 (0.073) data 0.000 (0.002) loss 2.5105 (2.3448) teacher_loss 0.7648 (0.8061) loss_zs_kd 1.4682 (1.8077) loss_oracle 1.0146 (0.9987) acc 78.1250 (72.3125) lr 1.5358e-03 eta 0:16:35
epoch [18/50] batch [420/428] time 0.071 (0.072) data 0.000 (0.002) loss 2.7490 (2.3654) teacher_loss 1.0555 (0.8177) loss_zs_kd 1.4138 (1.7963) loss_oracle 1.0362 (0.9999) acc 65.6250 (71.9196) lr 1.5358e-03 eta 0:16:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,488
* accuracy: 59.4%
* error: 40.6%
* macro_f1: 48.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,481
* accuracy: 52.3%
* error: 47.7%
* macro_f1: 33.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [19/50] batch [20/428] time 0.067 (0.095) data 0.000 (0.031) loss 2.3711 (2.6827) teacher_loss 0.6814 (0.9557) loss_zs_kd 1.6489 (1.4473) loss_oracle 1.0047 (1.0494) acc 81.2500 (67.5000) lr 1.4818e-03 eta 0:21:39
epoch [19/50] batch [40/428] time 0.062 (0.080) data 0.000 (0.016) loss 2.6808 (2.7226) teacher_loss 0.9027 (1.0003) loss_zs_kd 1.1181 (1.4898) loss_oracle 1.1211 (1.0619) acc 68.7500 (66.2500) lr 1.4818e-03 eta 0:18:14
epoch [19/50] batch [60/428] time 0.065 (0.075) data 0.000 (0.011) loss 2.5572 (2.7118) teacher_loss 0.8209 (1.0003) loss_zs_kd 1.4663 (1.4841) loss_oracle 1.0989 (1.0637) acc 65.6250 (65.8854) lr 1.4818e-03 eta 0:17:01
epoch [19/50] batch [80/428] time 0.064 (0.072) data 0.000 (0.008) loss 2.5310 (2.6661) teacher_loss 0.8928 (0.9690) loss_zs_kd 1.5367 (1.5112) loss_oracle 1.0796 (1.0611) acc 68.7500 (67.1484) lr 1.4818e-03 eta 0:16:20
epoch [19/50] batch [100/428] time 0.068 (0.071) data 0.000 (0.006) loss 2.6564 (2.6399) teacher_loss 1.0200 (0.9563) loss_zs_kd 1.7242 (1.5740) loss_oracle 1.0478 (1.0555) acc 59.3750 (67.5312) lr 1.4818e-03 eta 0:16:01
epoch [19/50] batch [120/428] time 0.066 (0.070) data 0.001 (0.005) loss 2.4254 (2.6088) teacher_loss 0.7647 (0.9343) loss_zs_kd 2.0278 (1.6122) loss_oracle 1.0831 (1.0558) acc 75.0000 (68.1771) lr 1.4818e-03 eta 0:15:45
epoch [19/50] batch [140/428] time 0.069 (0.069) data 0.000 (0.005) loss 2.1805 (2.5784) teacher_loss 0.5855 (0.9173) loss_zs_kd 1.7672 (1.6571) loss_oracle 1.0012 (1.0521) acc 87.5000 (68.7054) lr 1.4818e-03 eta 0:15:36
epoch [19/50] batch [160/428] time 0.077 (0.069) data 0.000 (0.004) loss 2.7411 (2.5455) teacher_loss 1.1171 (0.8949) loss_zs_kd 1.9231 (1.6852) loss_oracle 1.0650 (1.0495) acc 62.5000 (69.4922) lr 1.4818e-03 eta 0:15:36
epoch [19/50] batch [180/428] time 0.082 (0.071) data 0.000 (0.004) loss 2.2742 (2.5167) teacher_loss 0.8076 (0.8774) loss_zs_kd 1.9546 (1.7221) loss_oracle 0.9831 (1.0468) acc 75.0000 (70.0694) lr 1.4818e-03 eta 0:15:53
epoch [19/50] batch [200/428] time 0.083 (0.072) data 0.000 (0.003) loss 2.1383 (2.4979) teacher_loss 0.5808 (0.8700) loss_zs_kd 2.2694 (1.7533) loss_oracle 1.0289 (1.0424) acc 78.1250 (70.2500) lr 1.4818e-03 eta 0:16:09
epoch [19/50] batch [220/428] time 0.085 (0.073) data 0.000 (0.003) loss 2.2085 (2.4851) teacher_loss 0.7996 (0.8695) loss_zs_kd 1.9672 (1.7730) loss_oracle 0.9633 (1.0378) acc 71.8750 (70.2557) lr 1.4818e-03 eta 0:16:22
epoch [19/50] batch [240/428] time 0.088 (0.074) data 0.000 (0.003) loss 2.4044 (2.4730) teacher_loss 0.9149 (0.8688) loss_zs_kd 1.5313 (1.7762) loss_oracle 0.9679 (1.0328) acc 59.3750 (70.0521) lr 1.4818e-03 eta 0:16:32
epoch [19/50] batch [260/428] time 0.084 (0.075) data 0.000 (0.003) loss 2.3581 (2.4620) teacher_loss 0.8856 (0.8676) loss_zs_kd 2.0157 (1.7767) loss_oracle 0.9798 (1.0287) acc 62.5000 (69.8798) lr 1.4818e-03 eta 0:16:43
epoch [19/50] batch [280/428] time 0.094 (0.075) data 0.000 (0.003) loss 2.3788 (2.4512) teacher_loss 0.9499 (0.8642) loss_zs_kd 1.8366 (1.7794) loss_oracle 0.9354 (1.0250) acc 75.0000 (70.0446) lr 1.4818e-03 eta 0:16:52
epoch [19/50] batch [300/428] time 0.078 (0.076) data 0.000 (0.002) loss 2.0310 (2.4434) teacher_loss 0.5474 (0.8631) loss_zs_kd 1.6114 (1.7832) loss_oracle 0.9918 (1.0217) acc 81.2500 (70.0625) lr 1.4818e-03 eta 0:16:59
epoch [19/50] batch [320/428] time 0.084 (0.076) data 0.000 (0.002) loss 2.1947 (2.4343) teacher_loss 0.6612 (0.8599) loss_zs_kd 2.2548 (1.7900) loss_oracle 1.0173 (1.0188) acc 78.1250 (70.1758) lr 1.4818e-03 eta 0:17:02
epoch [19/50] batch [340/428] time 0.084 (0.077) data 0.000 (0.002) loss 2.5145 (2.4255) teacher_loss 0.9486 (0.8552) loss_zs_kd 2.1205 (1.8028) loss_oracle 1.0151 (1.0169) acc 68.7500 (70.1746) lr 1.4818e-03 eta 0:17:08
epoch [19/50] batch [360/428] time 0.083 (0.077) data 0.000 (0.002) loss 2.2473 (2.4222) teacher_loss 0.6968 (0.8547) loss_zs_kd 1.7493 (1.8130) loss_oracle 1.0157 (1.0153) acc 71.8750 (70.2604) lr 1.4818e-03 eta 0:17:12
epoch [19/50] batch [380/428] time 0.176 (0.078) data 0.000 (0.002) loss 2.4950 (2.4163) teacher_loss 0.9690 (0.8518) loss_zs_kd 1.8678 (1.8137) loss_oracle 1.0175 (1.0135) acc 65.6250 (70.2796) lr 1.4818e-03 eta 0:17:22
epoch [19/50] batch [400/428] time 0.077 (0.079) data 0.000 (0.002) loss 2.4242 (2.4125) teacher_loss 0.8910 (0.8500) loss_zs_kd 2.0160 (1.8105) loss_oracle 0.9889 (1.0127) acc 65.6250 (70.2422) lr 1.4818e-03 eta 0:17:24
epoch [19/50] batch [420/428] time 0.081 (0.079) data 0.000 (0.002) loss 2.3078 (2.4091) teacher_loss 0.7811 (0.8501) loss_zs_kd 1.7579 (1.8110) loss_oracle 1.0087 (1.0109) acc 65.6250 (70.1339) lr 1.4818e-03 eta 0:17:25
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,629
* accuracy: 61.8%
* error: 38.2%
* macro_f1: 47.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,997
* accuracy: 42.1%
* error: 57.9%
* macro_f1: 30.7%
******* Domain 1 best val acc:      63.3%, epoch: 13 *******
******* Domain 1 best val test acc: 41.2%, epoch: 13 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [20/50] batch [20/428] time 0.080 (0.110) data 0.000 (0.025) loss 2.2169 (2.2762) teacher_loss 0.7008 (0.7661) loss_zs_kd 1.4602 (1.6868) loss_oracle 0.9452 (0.9752) acc 78.1250 (72.8125) lr 1.4258e-03 eta 0:24:12
epoch [20/50] batch [40/428] time 0.079 (0.094) data 0.000 (0.013) loss 2.4760 (2.2747) teacher_loss 0.9059 (0.7474) loss_zs_kd 1.9392 (1.6872) loss_oracle 0.9462 (0.9761) acc 50.0000 (71.8750) lr 1.4258e-03 eta 0:20:38
epoch [20/50] batch [60/428] time 0.075 (0.088) data 0.001 (0.009) loss 2.2736 (2.3043) teacher_loss 0.6466 (0.7609) loss_zs_kd 1.6867 (1.7457) loss_oracle 1.0134 (0.9877) acc 78.1250 (72.6562) lr 1.4258e-03 eta 0:19:24
epoch [20/50] batch [80/428] time 0.082 (0.086) data 0.000 (0.007) loss 2.8631 (2.3851) teacher_loss 1.2531 (0.8229) loss_zs_kd 1.7115 (1.7160) loss_oracle 1.0355 (0.9947) acc 53.1250 (70.5078) lr 1.4258e-03 eta 0:18:58
epoch [20/50] batch [100/428] time 0.081 (0.086) data 0.000 (0.005) loss 2.7041 (2.4520) teacher_loss 1.1015 (0.8723) loss_zs_kd 1.7037 (1.6931) loss_oracle 0.9869 (1.0009) acc 62.5000 (69.0625) lr 1.4258e-03 eta 0:18:51
epoch [20/50] batch [120/428] time 0.079 (0.087) data 0.000 (0.004) loss 2.3386 (2.4851) teacher_loss 0.6973 (0.8943) loss_zs_kd 1.4980 (1.6812) loss_oracle 1.0818 (1.0037) acc 75.0000 (68.4635) lr 1.4258e-03 eta 0:19:09
epoch [20/50] batch [140/428] time 0.090 (0.088) data 0.000 (0.004) loss 2.5642 (2.5052) teacher_loss 1.0022 (0.9112) loss_zs_kd 1.9465 (1.6640) loss_oracle 1.0433 (1.0068) acc 71.8750 (67.8571) lr 1.4258e-03 eta 0:19:09
epoch [20/50] batch [160/428] time 0.084 (0.087) data 0.000 (0.003) loss 2.4006 (2.5057) teacher_loss 0.8221 (0.9108) loss_zs_kd 1.7765 (1.6530) loss_oracle 1.0638 (1.0113) acc 75.0000 (67.8711) lr 1.4258e-03 eta 0:18:59
epoch [20/50] batch [180/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.5903 (2.5066) teacher_loss 1.0528 (0.9148) loss_zs_kd 1.6350 (1.6388) loss_oracle 0.9366 (1.0124) acc 68.7500 (67.5694) lr 1.4258e-03 eta 0:18:53
epoch [20/50] batch [200/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.3130 (2.4981) teacher_loss 0.7206 (0.9073) loss_zs_kd 1.4600 (1.6432) loss_oracle 1.0510 (1.0152) acc 75.0000 (67.6719) lr 1.4258e-03 eta 0:18:46
epoch [20/50] batch [220/428] time 0.081 (0.086) data 0.000 (0.003) loss 2.2802 (2.4783) teacher_loss 0.7217 (0.8883) loss_zs_kd 1.9818 (1.6679) loss_oracle 1.0334 (1.0165) acc 68.7500 (68.3949) lr 1.4258e-03 eta 0:18:43
epoch [20/50] batch [240/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.6645 (2.4715) teacher_loss 1.0690 (0.8829) loss_zs_kd 1.7552 (1.6882) loss_oracle 1.0042 (1.0183) acc 50.0000 (68.6458) lr 1.4258e-03 eta 0:18:40
epoch [20/50] batch [260/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.5680 (2.4662) teacher_loss 1.0484 (0.8789) loss_zs_kd 1.7128 (1.6978) loss_oracle 1.0231 (1.0206) acc 62.5000 (68.8462) lr 1.4258e-03 eta 0:18:36
epoch [20/50] batch [280/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.4770 (2.4604) teacher_loss 0.9175 (0.8737) loss_zs_kd 1.6097 (1.7073) loss_oracle 1.0403 (1.0226) acc 62.5000 (68.9286) lr 1.4258e-03 eta 0:18:32
epoch [20/50] batch [300/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.5159 (2.4583) teacher_loss 0.9993 (0.8733) loss_zs_kd 2.1200 (1.7188) loss_oracle 1.0092 (1.0232) acc 62.5000 (69.0417) lr 1.4258e-03 eta 0:18:29
epoch [20/50] batch [320/428] time 0.078 (0.085) data 0.000 (0.002) loss 2.2577 (2.4557) teacher_loss 0.7913 (0.8753) loss_zs_kd 1.5857 (1.7167) loss_oracle 1.0006 (1.0223) acc 78.1250 (68.9941) lr 1.4258e-03 eta 0:18:24
epoch [20/50] batch [340/428] time 0.094 (0.085) data 0.001 (0.002) loss 2.4583 (2.4546) teacher_loss 0.9157 (0.8772) loss_zs_kd 1.7178 (1.7127) loss_oracle 1.0264 (1.0212) acc 78.1250 (68.9798) lr 1.4258e-03 eta 0:18:20
epoch [20/50] batch [360/428] time 0.086 (0.085) data 0.000 (0.002) loss 2.4974 (2.4534) teacher_loss 1.0597 (0.8796) loss_zs_kd 1.6498 (1.7114) loss_oracle 0.9974 (1.0202) acc 56.2500 (68.8889) lr 1.4258e-03 eta 0:18:18
epoch [20/50] batch [380/428] time 0.078 (0.085) data 0.000 (0.002) loss 2.3795 (2.4540) teacher_loss 0.9079 (0.8841) loss_zs_kd 1.6727 (1.7217) loss_oracle 1.0094 (1.0189) acc 65.6250 (68.5691) lr 1.4258e-03 eta 0:18:12
epoch [20/50] batch [400/428] time 0.076 (0.084) data 0.000 (0.002) loss 2.4189 (2.4541) teacher_loss 1.0451 (0.8898) loss_zs_kd 1.6294 (1.7230) loss_oracle 0.9711 (1.0166) acc 59.3750 (68.4141) lr 1.4258e-03 eta 0:18:06
epoch [20/50] batch [420/428] time 0.072 (0.084) data 0.000 (0.001) loss 2.3150 (2.4502) teacher_loss 0.8316 (0.8898) loss_zs_kd 1.6304 (1.7225) loss_oracle 0.9877 (1.0151) acc 71.8750 (68.4970) lr 1.4258e-03 eta 0:18:02
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,740
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 50.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,876
* accuracy: 39.6%
* error: 60.4%
* macro_f1: 28.7%
******* Domain 1 best val acc:      63.6%, epoch: 20 *******
******* Domain 1 best val test acc: 39.6%, epoch: 20 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [21/50] batch [20/428] time 0.076 (0.111) data 0.000 (0.024) loss 2.3837 (2.4472) teacher_loss 0.9435 (0.9584) loss_zs_kd 1.8512 (1.7418) loss_oracle 0.9809 (0.9774) acc 65.6250 (67.5000) lr 1.3681e-03 eta 0:23:45
epoch [21/50] batch [40/428] time 0.087 (0.098) data 0.000 (0.012) loss 2.0116 (2.3728) teacher_loss 0.5553 (0.8872) loss_zs_kd 2.1150 (1.7599) loss_oracle 0.9789 (0.9749) acc 84.3750 (70.1562) lr 1.3681e-03 eta 0:20:57
epoch [21/50] batch [60/428] time 0.084 (0.093) data 0.000 (0.008) loss 2.4221 (2.3461) teacher_loss 0.9099 (0.8620) loss_zs_kd 1.8097 (1.7638) loss_oracle 1.0111 (0.9755) acc 65.6250 (70.8854) lr 1.3681e-03 eta 0:19:43
epoch [21/50] batch [80/428] time 0.084 (0.090) data 0.000 (0.006) loss 2.1704 (2.3321) teacher_loss 0.6025 (0.8450) loss_zs_kd 1.7903 (1.8240) loss_oracle 1.0062 (0.9752) acc 75.0000 (71.6016) lr 1.3681e-03 eta 0:19:13
epoch [21/50] batch [100/428] time 0.078 (0.089) data 0.000 (0.005) loss 2.4009 (2.3304) teacher_loss 0.8608 (0.8352) loss_zs_kd 1.7462 (1.8153) loss_oracle 0.9720 (0.9772) acc 71.8750 (72.1250) lr 1.3681e-03 eta 0:18:56
epoch [21/50] batch [120/428] time 0.078 (0.088) data 0.000 (0.004) loss 2.3426 (2.3343) teacher_loss 0.7859 (0.8315) loss_zs_kd 2.0313 (1.7963) loss_oracle 1.0191 (0.9812) acc 62.5000 (72.1094) lr 1.3681e-03 eta 0:18:42
epoch [21/50] batch [140/428] time 0.072 (0.087) data 0.000 (0.004) loss 2.1164 (2.3323) teacher_loss 0.5709 (0.8239) loss_zs_kd 1.4690 (1.7795) loss_oracle 0.9717 (0.9820) acc 84.3750 (72.5223) lr 1.3681e-03 eta 0:18:29
epoch [21/50] batch [160/428] time 0.079 (0.087) data 0.000 (0.003) loss 1.9193 (2.3333) teacher_loss 0.3987 (0.8189) loss_zs_kd 1.8607 (1.7671) loss_oracle 0.9825 (0.9836) acc 90.6250 (72.6367) lr 1.3681e-03 eta 0:18:17
epoch [21/50] batch [180/428] time 0.076 (0.086) data 0.000 (0.003) loss 2.0334 (2.3329) teacher_loss 0.5360 (0.8148) loss_zs_kd 2.1272 (1.7764) loss_oracle 0.9676 (0.9837) acc 84.3750 (72.6562) lr 1.3681e-03 eta 0:18:10
epoch [21/50] batch [200/428] time 0.083 (0.086) data 0.000 (0.003) loss 2.1505 (2.3278) teacher_loss 0.5050 (0.8032) loss_zs_kd 1.6846 (1.7710) loss_oracle 1.1037 (0.9876) acc 78.1250 (72.8594) lr 1.3681e-03 eta 0:18:04
epoch [21/50] batch [220/428] time 0.092 (0.086) data 0.000 (0.002) loss 2.2159 (2.3260) teacher_loss 0.6744 (0.7974) loss_zs_kd 1.2221 (1.7578) loss_oracle 1.0065 (0.9916) acc 75.0000 (73.0540) lr 1.3681e-03 eta 0:18:02
epoch [21/50] batch [240/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.2319 (2.3277) teacher_loss 0.5977 (0.7962) loss_zs_kd 1.7805 (1.7587) loss_oracle 1.0677 (0.9939) acc 81.2500 (73.0469) lr 1.3681e-03 eta 0:17:55
epoch [21/50] batch [260/428] time 0.075 (0.086) data 0.000 (0.002) loss 2.0405 (2.3267) teacher_loss 0.4233 (0.7909) loss_zs_kd 1.6758 (1.7617) loss_oracle 1.0036 (0.9957) acc 87.5000 (73.3413) lr 1.3681e-03 eta 0:18:01
epoch [21/50] batch [280/428] time 0.075 (0.086) data 0.000 (0.002) loss 2.4783 (2.3318) teacher_loss 0.9022 (0.7942) loss_zs_kd 1.8200 (1.7597) loss_oracle 1.0130 (0.9973) acc 65.6250 (73.1362) lr 1.3681e-03 eta 0:17:57
epoch [21/50] batch [300/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.3765 (2.3323) teacher_loss 0.8269 (0.7934) loss_zs_kd 1.6719 (1.7584) loss_oracle 1.0518 (0.9990) acc 65.6250 (73.1458) lr 1.3681e-03 eta 0:17:54
epoch [21/50] batch [320/428] time 0.073 (0.085) data 0.000 (0.002) loss 2.2639 (2.3316) teacher_loss 0.7309 (0.7940) loss_zs_kd 1.8273 (1.7597) loss_oracle 0.9774 (0.9982) acc 75.0000 (73.0762) lr 1.3681e-03 eta 0:17:47
epoch [21/50] batch [340/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.5820 (2.3381) teacher_loss 0.9923 (0.8010) loss_zs_kd 1.7199 (1.7591) loss_oracle 0.9677 (0.9988) acc 71.8750 (72.7390) lr 1.3681e-03 eta 0:17:43
epoch [21/50] batch [360/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.6519 (2.3483) teacher_loss 1.1507 (0.8111) loss_zs_kd 1.2737 (1.7546) loss_oracle 1.0046 (0.9996) acc 56.2500 (72.2569) lr 1.3681e-03 eta 0:17:39
epoch [21/50] batch [380/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.6007 (2.3606) teacher_loss 1.0134 (0.8221) loss_zs_kd 1.8477 (1.7503) loss_oracle 0.9940 (1.0004) acc 65.6250 (71.8586) lr 1.3681e-03 eta 0:17:34
epoch [21/50] batch [400/428] time 0.074 (0.085) data 0.000 (0.001) loss 2.5781 (2.3685) teacher_loss 1.0063 (0.8291) loss_zs_kd 1.2363 (1.7449) loss_oracle 1.0461 (1.0019) acc 68.7500 (71.5938) lr 1.3681e-03 eta 0:17:31
epoch [21/50] batch [420/428] time 0.077 (0.084) data 0.000 (0.001) loss 2.5219 (2.3724) teacher_loss 1.0165 (0.8327) loss_zs_kd 1.5318 (1.7305) loss_oracle 1.0077 (1.0028) acc 62.5000 (71.3616) lr 1.3681e-03 eta 0:17:26
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,556
* accuracy: 60.5%
* error: 39.5%
* macro_f1: 48.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,072
* accuracy: 43.7%
* error: 56.3%
* macro_f1: 28.8%
******* Domain 1 best val acc:      63.6%, epoch: 20 *******
******* Domain 1 best val test acc: 39.6%, epoch: 20 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [22/50] batch [20/428] time 0.081 (0.107) data 0.000 (0.026) loss 2.2254 (2.4534) teacher_loss 0.6793 (0.9146) loss_zs_kd 1.4057 (1.5177) loss_oracle 1.0279 (1.0220) acc 78.1250 (70.1562) lr 1.3090e-03 eta 0:22:01
epoch [22/50] batch [40/428] time 0.075 (0.091) data 0.001 (0.013) loss 2.4202 (2.4726) teacher_loss 0.8544 (0.9411) loss_zs_kd 1.7883 (1.5349) loss_oracle 0.9964 (1.0186) acc 68.7500 (67.8906) lr 1.3090e-03 eta 0:18:50
epoch [22/50] batch [60/428] time 0.074 (0.087) data 0.000 (0.009) loss 2.3341 (2.4962) teacher_loss 0.8589 (0.9657) loss_zs_kd 1.8492 (1.5699) loss_oracle 0.9983 (1.0202) acc 71.8750 (66.8229) lr 1.3090e-03 eta 0:17:52
epoch [22/50] batch [80/428] time 0.083 (0.084) data 0.000 (0.007) loss 2.3952 (2.4720) teacher_loss 0.8943 (0.9464) loss_zs_kd 1.8756 (1.5838) loss_oracle 1.0196 (1.0148) acc 65.6250 (67.1875) lr 1.3090e-03 eta 0:17:21
epoch [22/50] batch [100/428] time 0.077 (0.083) data 0.000 (0.005) loss 2.1586 (2.4369) teacher_loss 0.5793 (0.9087) loss_zs_kd 2.0732 (1.6337) loss_oracle 1.0283 (1.0157) acc 78.1250 (68.6562) lr 1.3090e-03 eta 0:17:02
epoch [22/50] batch [120/428] time 0.074 (0.082) data 0.000 (0.004) loss 2.2758 (2.4343) teacher_loss 0.6993 (0.8999) loss_zs_kd 1.6870 (1.6775) loss_oracle 1.0152 (1.0171) acc 75.0000 (68.7500) lr 1.3090e-03 eta 0:16:47
epoch [22/50] batch [140/428] time 0.079 (0.081) data 0.000 (0.004) loss 2.2229 (2.4140) teacher_loss 0.6703 (0.8745) loss_zs_kd 1.8754 (1.7054) loss_oracle 0.9979 (1.0189) acc 84.3750 (69.5982) lr 1.3090e-03 eta 0:16:38
epoch [22/50] batch [160/428] time 0.083 (0.081) data 0.000 (0.003) loss 2.0639 (2.3932) teacher_loss 0.5723 (0.8518) loss_zs_kd 2.0270 (1.7285) loss_oracle 1.0160 (1.0202) acc 87.5000 (70.7227) lr 1.3090e-03 eta 0:16:30
epoch [22/50] batch [180/428] time 0.082 (0.081) data 0.000 (0.003) loss 2.4928 (2.3826) teacher_loss 1.0088 (0.8399) loss_zs_kd 2.4822 (1.7659) loss_oracle 1.0351 (1.0210) acc 65.6250 (71.2326) lr 1.3090e-03 eta 0:16:25
epoch [22/50] batch [200/428] time 0.082 (0.081) data 0.000 (0.003) loss 2.3189 (2.3745) teacher_loss 0.7611 (0.8344) loss_zs_kd 2.2894 (1.7867) loss_oracle 0.9817 (1.0192) acc 65.6250 (71.3750) lr 1.3090e-03 eta 0:16:30
epoch [22/50] batch [220/428] time 0.077 (0.081) data 0.000 (0.003) loss 2.6134 (2.3696) teacher_loss 1.0362 (0.8292) loss_zs_kd 1.6250 (1.8029) loss_oracle 1.0129 (1.0179) acc 56.2500 (71.4631) lr 1.3090e-03 eta 0:16:29
epoch [22/50] batch [240/428] time 0.088 (0.081) data 0.000 (0.002) loss 2.4419 (2.3635) teacher_loss 0.8575 (0.8218) loss_zs_kd 1.7933 (1.8088) loss_oracle 1.0699 (1.0178) acc 62.5000 (71.5625) lr 1.3090e-03 eta 0:16:26
epoch [22/50] batch [260/428] time 0.082 (0.081) data 0.000 (0.002) loss 2.2992 (2.3616) teacher_loss 0.7632 (0.8190) loss_zs_kd 1.6216 (1.8079) loss_oracle 0.9796 (1.0182) acc 75.0000 (71.5264) lr 1.3090e-03 eta 0:16:23
epoch [22/50] batch [280/428] time 0.084 (0.081) data 0.000 (0.002) loss 2.4996 (2.3663) teacher_loss 0.9769 (0.8255) loss_zs_kd 2.0019 (1.8042) loss_oracle 1.0270 (1.0172) acc 59.3750 (71.3616) lr 1.3090e-03 eta 0:16:21
epoch [22/50] batch [300/428] time 0.079 (0.081) data 0.000 (0.002) loss 2.2894 (2.3671) teacher_loss 0.8048 (0.8288) loss_zs_kd 2.0424 (1.7976) loss_oracle 0.9906 (1.0172) acc 75.0000 (71.3229) lr 1.3090e-03 eta 0:16:21
epoch [22/50] batch [320/428] time 0.093 (0.081) data 0.000 (0.002) loss 2.3123 (2.3655) teacher_loss 0.7681 (0.8277) loss_zs_kd 1.8398 (1.7988) loss_oracle 1.0390 (1.0179) acc 65.6250 (71.4258) lr 1.3090e-03 eta 0:16:22
epoch [22/50] batch [340/428] time 0.080 (0.081) data 0.000 (0.002) loss 2.3031 (2.3692) teacher_loss 0.8079 (0.8327) loss_zs_kd 1.8092 (1.7924) loss_oracle 0.9877 (1.0174) acc 71.8750 (71.2132) lr 1.3090e-03 eta 0:16:23
epoch [22/50] batch [360/428] time 0.084 (0.082) data 0.000 (0.002) loss 2.1913 (2.3678) teacher_loss 0.7534 (0.8344) loss_zs_kd 1.9929 (1.7870) loss_oracle 1.0027 (1.0164) acc 68.7500 (71.0938) lr 1.3090e-03 eta 0:16:23
epoch [22/50] batch [380/428] time 0.084 (0.082) data 0.000 (0.002) loss 2.2507 (2.3659) teacher_loss 0.7263 (0.8332) loss_zs_kd 1.6400 (1.7852) loss_oracle 0.9942 (1.0156) acc 71.8750 (70.9704) lr 1.3090e-03 eta 0:16:23
epoch [22/50] batch [400/428] time 0.160 (0.082) data 0.001 (0.002) loss 2.3216 (2.3684) teacher_loss 0.7960 (0.8346) loss_zs_kd 1.9566 (1.7869) loss_oracle 0.9538 (1.0158) acc 68.7500 (70.8750) lr 1.3090e-03 eta 0:16:27
epoch [22/50] batch [420/428] time 0.080 (0.082) data 0.000 (0.001) loss 2.2762 (2.3676) teacher_loss 0.7062 (0.8333) loss_zs_kd 2.2742 (1.7908) loss_oracle 1.0168 (1.0157) acc 78.1250 (71.0268) lr 1.3090e-03 eta 0:16:25
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,659
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 47.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,057
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 30.8%
******* Domain 1 best val acc:      63.6%, epoch: 20 *******
******* Domain 1 best val test acc: 39.6%, epoch: 20 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [23/50] batch [20/428] time 0.083 (0.112) data 0.000 (0.026) loss 2.1907 (2.3088) teacher_loss 0.6272 (0.7687) loss_zs_kd 1.9200 (1.8011) loss_oracle 1.0540 (1.0089) acc 71.8750 (76.2500) lr 1.2487e-03 eta 0:22:20
epoch [23/50] batch [40/428] time 0.089 (0.097) data 0.000 (0.013) loss 2.2448 (2.2824) teacher_loss 0.6856 (0.7402) loss_zs_kd 1.9012 (1.8468) loss_oracle 1.0401 (1.0106) acc 78.1250 (76.6406) lr 1.2487e-03 eta 0:19:19
epoch [23/50] batch [60/428] time 0.083 (0.092) data 0.001 (0.009) loss 2.1481 (2.2944) teacher_loss 0.6779 (0.7507) loss_zs_kd 1.9763 (1.9256) loss_oracle 1.0170 (1.0136) acc 81.2500 (75.9375) lr 1.2487e-03 eta 0:18:11
epoch [23/50] batch [80/428] time 0.087 (0.090) data 0.000 (0.007) loss 2.5511 (2.3267) teacher_loss 0.9479 (0.7858) loss_zs_kd 1.8172 (1.9685) loss_oracle 1.0530 (1.0131) acc 65.6250 (73.9062) lr 1.2487e-03 eta 0:17:48
epoch [23/50] batch [100/428] time 0.079 (0.088) data 0.000 (0.005) loss 2.3396 (2.3317) teacher_loss 0.8097 (0.7943) loss_zs_kd 1.9387 (1.9774) loss_oracle 1.0410 (1.0140) acc 78.1250 (73.7188) lr 1.2487e-03 eta 0:17:26
epoch [23/50] batch [120/428] time 0.081 (0.087) data 0.000 (0.005) loss 2.4341 (2.3418) teacher_loss 0.8922 (0.8085) loss_zs_kd 1.6776 (1.9614) loss_oracle 1.0305 (1.0097) acc 68.7500 (73.0990) lr 1.2487e-03 eta 0:17:13
epoch [23/50] batch [140/428] time 0.087 (0.086) data 0.000 (0.004) loss 2.7070 (2.3419) teacher_loss 1.2576 (0.8138) loss_zs_kd 1.8222 (1.9442) loss_oracle 1.0137 (1.0081) acc 46.8750 (72.4554) lr 1.2487e-03 eta 0:17:02
epoch [23/50] batch [160/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.2775 (2.3474) teacher_loss 0.8662 (0.8235) loss_zs_kd 1.5170 (1.9269) loss_oracle 0.9822 (1.0080) acc 71.8750 (72.0508) lr 1.2487e-03 eta 0:17:07
epoch [23/50] batch [180/428] time 0.081 (0.087) data 0.000 (0.003) loss 2.2531 (2.3527) teacher_loss 0.7112 (0.8309) loss_zs_kd 1.9616 (1.9073) loss_oracle 1.0065 (1.0068) acc 87.5000 (71.5278) lr 1.2487e-03 eta 0:17:03
epoch [23/50] batch [200/428] time 0.087 (0.086) data 0.000 (0.003) loss 2.2418 (2.3586) teacher_loss 0.7615 (0.8397) loss_zs_kd 1.6632 (1.8896) loss_oracle 1.0039 (1.0064) acc 78.1250 (71.1250) lr 1.2487e-03 eta 0:16:56
epoch [23/50] batch [220/428] time 0.081 (0.086) data 0.000 (0.003) loss 2.5104 (2.3629) teacher_loss 1.0485 (0.8470) loss_zs_kd 1.6861 (1.8685) loss_oracle 1.0422 (1.0057) acc 56.2500 (70.8097) lr 1.2487e-03 eta 0:16:53
epoch [23/50] batch [240/428] time 0.078 (0.086) data 0.001 (0.002) loss 2.5257 (2.3586) teacher_loss 0.9906 (0.8458) loss_zs_kd 1.7347 (1.8570) loss_oracle 1.0461 (1.0052) acc 65.6250 (70.8854) lr 1.2487e-03 eta 0:16:47
epoch [23/50] batch [260/428] time 0.096 (0.086) data 0.000 (0.002) loss 2.3570 (2.3578) teacher_loss 0.8804 (0.8429) loss_zs_kd 2.0119 (1.8494) loss_oracle 1.0017 (1.0057) acc 71.8750 (70.9014) lr 1.2487e-03 eta 0:16:44
epoch [23/50] batch [280/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.9051 (2.3534) teacher_loss 0.4154 (0.8365) loss_zs_kd 1.6435 (1.8564) loss_oracle 1.0351 (1.0070) acc 93.7500 (71.2946) lr 1.2487e-03 eta 0:16:40
epoch [23/50] batch [300/428] time 0.089 (0.085) data 0.000 (0.002) loss 2.0501 (2.3478) teacher_loss 0.5048 (0.8291) loss_zs_kd 1.9540 (1.8556) loss_oracle 1.0134 (1.0077) acc 81.2500 (71.5938) lr 1.2487e-03 eta 0:16:38
epoch [23/50] batch [320/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.4128 (2.3494) teacher_loss 0.8465 (0.8278) loss_zs_kd 2.0060 (1.8610) loss_oracle 0.9945 (1.0080) acc 75.0000 (71.6406) lr 1.2487e-03 eta 0:16:36
epoch [23/50] batch [340/428] time 0.086 (0.085) data 0.000 (0.002) loss 2.2516 (2.3453) teacher_loss 0.7139 (0.8217) loss_zs_kd 1.5225 (1.8560) loss_oracle 1.0205 (1.0086) acc 84.3750 (71.9577) lr 1.2487e-03 eta 0:16:34
epoch [23/50] batch [360/428] time 0.090 (0.085) data 0.000 (0.002) loss 2.4751 (2.3421) teacher_loss 0.9793 (0.8187) loss_zs_kd 1.4890 (1.8510) loss_oracle 1.0390 (1.0087) acc 65.6250 (72.1094) lr 1.2487e-03 eta 0:16:33
epoch [23/50] batch [380/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.3904 (2.3398) teacher_loss 0.7611 (0.8140) loss_zs_kd 1.2977 (1.8392) loss_oracle 1.0829 (1.0101) acc 78.1250 (72.2862) lr 1.2487e-03 eta 0:16:31
epoch [23/50] batch [400/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.0457 (2.3392) teacher_loss 0.4705 (0.8118) loss_zs_kd 1.7184 (1.8365) loss_oracle 1.0321 (1.0114) acc 87.5000 (72.3906) lr 1.2487e-03 eta 0:16:27
epoch [23/50] batch [420/428] time 0.083 (0.085) data 0.000 (0.002) loss 2.2371 (2.3396) teacher_loss 0.7148 (0.8101) loss_zs_kd 1.6962 (1.8332) loss_oracle 1.0691 (1.0132) acc 71.8750 (72.3512) lr 1.2487e-03 eta 0:16:24
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,677
* accuracy: 62.6%
* error: 37.4%
* macro_f1: 50.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,005
* accuracy: 42.3%
* error: 57.7%
* macro_f1: 28.9%
******* Domain 1 best val acc:      63.6%, epoch: 20 *******
******* Domain 1 best val test acc: 39.6%, epoch: 20 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [24/50] batch [20/428] time 0.086 (0.123) data 0.000 (0.028) loss 2.0625 (2.3314) teacher_loss 0.5138 (0.7829) loss_zs_kd 2.0650 (1.8247) loss_oracle 1.0363 (1.0316) acc 87.5000 (74.2188) lr 1.1874e-03 eta 0:23:38
epoch [24/50] batch [40/428] time 0.083 (0.104) data 0.000 (0.014) loss 2.3418 (2.3046) teacher_loss 0.7729 (0.7492) loss_zs_kd 1.7832 (1.8144) loss_oracle 1.0891 (1.0352) acc 68.7500 (75.2344) lr 1.1874e-03 eta 0:20:01
epoch [24/50] batch [60/428] time 0.082 (0.098) data 0.001 (0.010) loss 2.5306 (2.3112) teacher_loss 1.0582 (0.7632) loss_zs_kd 1.8263 (1.7964) loss_oracle 1.0164 (1.0355) acc 56.2500 (74.3229) lr 1.1874e-03 eta 0:18:46
epoch [24/50] batch [80/428] time 0.083 (0.095) data 0.000 (0.007) loss 2.3756 (2.3213) teacher_loss 0.7913 (0.7780) loss_zs_kd 2.0852 (1.8046) loss_oracle 1.0747 (1.0352) acc 68.7500 (73.4766) lr 1.1874e-03 eta 0:18:05
epoch [24/50] batch [100/428] time 0.086 (0.091) data 0.000 (0.006) loss 2.1484 (2.3198) teacher_loss 0.6099 (0.7782) loss_zs_kd 1.5516 (1.8032) loss_oracle 1.0418 (1.0366) acc 84.3750 (73.0625) lr 1.1874e-03 eta 0:17:25
epoch [24/50] batch [120/428] time 0.082 (0.090) data 0.000 (0.005) loss 2.4180 (2.3282) teacher_loss 0.8647 (0.7869) loss_zs_kd 1.4846 (1.7919) loss_oracle 0.9929 (1.0364) acc 71.8750 (72.6042) lr 1.1874e-03 eta 0:17:09
epoch [24/50] batch [140/428] time 0.089 (0.089) data 0.001 (0.004) loss 2.6083 (2.3427) teacher_loss 1.0083 (0.8023) loss_zs_kd 1.8547 (1.7917) loss_oracle 0.9935 (1.0349) acc 68.7500 (72.0536) lr 1.1874e-03 eta 0:16:59
epoch [24/50] batch [160/428] time 0.090 (0.088) data 0.000 (0.004) loss 2.0056 (2.3340) teacher_loss 0.4202 (0.7931) loss_zs_kd 1.7907 (1.7705) loss_oracle 1.0818 (1.0350) acc 90.6250 (72.5977) lr 1.1874e-03 eta 0:16:45
epoch [24/50] batch [180/428] time 0.088 (0.088) data 0.000 (0.003) loss 2.1960 (2.3283) teacher_loss 0.6676 (0.7853) loss_zs_kd 2.0392 (1.7813) loss_oracle 1.0030 (1.0356) acc 71.8750 (72.7604) lr 1.1874e-03 eta 0:16:38
epoch [24/50] batch [200/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.1469 (2.3224) teacher_loss 0.5817 (0.7783) loss_zs_kd 2.1009 (1.7990) loss_oracle 1.0450 (1.0350) acc 78.1250 (73.0156) lr 1.1874e-03 eta 0:16:34
epoch [24/50] batch [220/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.4890 (2.3292) teacher_loss 0.9320 (0.7849) loss_zs_kd 1.5075 (1.8071) loss_oracle 0.9993 (1.0343) acc 68.7500 (72.7557) lr 1.1874e-03 eta 0:16:28
epoch [24/50] batch [240/428] time 0.072 (0.086) data 0.000 (0.003) loss 2.5532 (2.3392) teacher_loss 1.0365 (0.7961) loss_zs_kd 1.6018 (1.8034) loss_oracle 1.0056 (1.0325) acc 71.8750 (72.4219) lr 1.1874e-03 eta 0:16:16
epoch [24/50] batch [260/428] time 0.089 (0.086) data 0.001 (0.002) loss 2.3190 (2.3406) teacher_loss 0.7633 (0.7999) loss_zs_kd 1.7545 (1.8089) loss_oracle 1.0034 (1.0308) acc 71.8750 (72.3678) lr 1.1874e-03 eta 0:16:12
epoch [24/50] batch [280/428] time 0.071 (0.087) data 0.000 (0.002) loss 2.2689 (2.3430) teacher_loss 0.7687 (0.8035) loss_zs_kd 1.7506 (1.8115) loss_oracle 0.9830 (1.0288) acc 68.7500 (72.2210) lr 1.1874e-03 eta 0:16:16
epoch [24/50] batch [300/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.1218 (2.3425) teacher_loss 0.5421 (0.8027) loss_zs_kd 1.6623 (1.8148) loss_oracle 1.0244 (1.0286) acc 84.3750 (72.2396) lr 1.1874e-03 eta 0:16:11
epoch [24/50] batch [320/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.3262 (2.3437) teacher_loss 0.7483 (0.8019) loss_zs_kd 1.6188 (1.8196) loss_oracle 1.0438 (1.0289) acc 84.3750 (72.2852) lr 1.1874e-03 eta 0:16:08
epoch [24/50] batch [340/428] time 0.097 (0.086) data 0.000 (0.002) loss 2.0740 (2.3422) teacher_loss 0.5378 (0.7993) loss_zs_kd 1.5839 (1.8160) loss_oracle 1.0291 (1.0296) acc 84.3750 (72.3989) lr 1.1874e-03 eta 0:16:06
epoch [24/50] batch [360/428] time 0.097 (0.086) data 0.000 (0.002) loss 2.1438 (2.3442) teacher_loss 0.5851 (0.8011) loss_zs_kd 1.4677 (1.8088) loss_oracle 1.0076 (1.0289) acc 81.2500 (72.3438) lr 1.1874e-03 eta 0:16:02
epoch [24/50] batch [380/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.0949 (2.3392) teacher_loss 0.5422 (0.7962) loss_zs_kd 1.8187 (1.8124) loss_oracle 0.9807 (1.0283) acc 90.6250 (72.6151) lr 1.1874e-03 eta 0:15:59
epoch [24/50] batch [400/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.2670 (2.3408) teacher_loss 0.7906 (0.8002) loss_zs_kd 1.9474 (1.8173) loss_oracle 0.9821 (1.0276) acc 75.0000 (72.5703) lr 1.1874e-03 eta 0:15:57
epoch [24/50] batch [420/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.2417 (2.3403) teacher_loss 0.7531 (0.8018) loss_zs_kd 1.7855 (1.8233) loss_oracle 0.9804 (1.0261) acc 75.0000 (72.4702) lr 1.1874e-03 eta 0:15:55
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,734
* accuracy: 63.5%
* error: 36.5%
* macro_f1: 50.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,946
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 31.4%
******* Domain 1 best val acc:      63.6%, epoch: 20 *******
******* Domain 1 best val test acc: 39.6%, epoch: 20 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [25/50] batch [20/428] time 0.077 (0.125) data 0.000 (0.034) loss 2.5465 (2.4120) teacher_loss 0.9789 (0.9070) loss_zs_kd 2.3487 (1.8563) loss_oracle 1.0592 (1.0127) acc 56.2500 (67.1875) lr 1.1253e-03 eta 0:23:11
epoch [25/50] batch [40/428] time 0.089 (0.103) data 0.000 (0.017) loss 2.3635 (2.3682) teacher_loss 0.9070 (0.8591) loss_zs_kd 1.9824 (1.9197) loss_oracle 1.0050 (1.0077) acc 68.7500 (70.1562) lr 1.1253e-03 eta 0:19:00
epoch [25/50] batch [60/428] time 0.088 (0.095) data 0.000 (0.011) loss 2.4097 (2.3838) teacher_loss 0.8875 (0.8797) loss_zs_kd 1.4509 (1.8619) loss_oracle 0.9561 (0.9995) acc 65.6250 (69.4792) lr 1.1253e-03 eta 0:17:32
epoch [25/50] batch [80/428] time 0.084 (0.093) data 0.000 (0.009) loss 2.2183 (2.3760) teacher_loss 0.7364 (0.8748) loss_zs_kd 1.8999 (1.8349) loss_oracle 1.0040 (1.0000) acc 84.3750 (69.4531) lr 1.1253e-03 eta 0:17:07
epoch [25/50] batch [100/428] time 0.079 (0.091) data 0.000 (0.007) loss 2.5192 (2.3832) teacher_loss 1.0115 (0.8892) loss_zs_kd 1.9191 (1.8321) loss_oracle 1.0170 (0.9984) acc 65.6250 (68.4375) lr 1.1253e-03 eta 0:16:46
epoch [25/50] batch [120/428] time 0.078 (0.090) data 0.000 (0.006) loss 2.7825 (2.3928) teacher_loss 1.2881 (0.8989) loss_zs_kd 1.6754 (1.8140) loss_oracle 0.9893 (0.9956) acc 50.0000 (68.3594) lr 1.1253e-03 eta 0:16:29
epoch [25/50] batch [140/428] time 0.083 (0.088) data 0.001 (0.005) loss 2.8672 (2.3972) teacher_loss 1.3685 (0.9023) loss_zs_kd 1.7985 (1.7849) loss_oracle 1.0424 (0.9964) acc 56.2500 (68.3259) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [160/428] time 0.076 (0.087) data 0.000 (0.004) loss 2.3690 (2.3949) teacher_loss 0.8438 (0.8990) loss_zs_kd 1.5393 (1.7550) loss_oracle 1.0199 (0.9971) acc 68.7500 (68.5742) lr 1.1253e-03 eta 0:15:57
epoch [25/50] batch [180/428] time 0.078 (0.087) data 0.000 (0.004) loss 2.3593 (2.3941) teacher_loss 0.8096 (0.8994) loss_zs_kd 1.9073 (1.7226) loss_oracle 1.0454 (0.9965) acc 75.0000 (68.6458) lr 1.1253e-03 eta 0:15:47
epoch [25/50] batch [200/428] time 0.086 (0.086) data 0.000 (0.004) loss 2.5970 (2.3992) teacher_loss 1.1595 (0.9058) loss_zs_kd 1.9271 (1.7177) loss_oracle 1.0006 (0.9959) acc 56.2500 (68.5312) lr 1.1253e-03 eta 0:15:42
epoch [25/50] batch [220/428] time 0.074 (0.086) data 0.000 (0.003) loss 2.2152 (2.3974) teacher_loss 0.6388 (0.9028) loss_zs_kd 2.0359 (1.7285) loss_oracle 1.0307 (0.9977) acc 81.2500 (68.5085) lr 1.1253e-03 eta 0:15:38
epoch [25/50] batch [240/428] time 0.088 (0.086) data 0.000 (0.003) loss 2.1371 (2.3930) teacher_loss 0.6294 (0.8961) loss_zs_kd 1.8315 (1.7395) loss_oracle 0.9820 (0.9977) acc 78.1250 (68.7891) lr 1.1253e-03 eta 0:15:36
epoch [25/50] batch [260/428] time 0.090 (0.086) data 0.000 (0.003) loss 2.1515 (2.3894) teacher_loss 0.6114 (0.8913) loss_zs_kd 1.8946 (1.7539) loss_oracle 1.0000 (0.9984) acc 81.2500 (69.0385) lr 1.1253e-03 eta 0:15:33
epoch [25/50] batch [280/428] time 0.091 (0.086) data 0.001 (0.003) loss 2.6333 (2.3883) teacher_loss 1.1074 (0.8897) loss_zs_kd 1.6964 (1.7742) loss_oracle 1.0146 (0.9984) acc 50.0000 (69.0179) lr 1.1253e-03 eta 0:15:29
epoch [25/50] batch [300/428] time 0.087 (0.086) data 0.000 (0.003) loss 2.1612 (2.3827) teacher_loss 0.7016 (0.8860) loss_zs_kd 2.0056 (1.7917) loss_oracle 0.9699 (0.9975) acc 71.8750 (69.0521) lr 1.1253e-03 eta 0:15:26
epoch [25/50] batch [320/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.2877 (2.3842) teacher_loss 0.8105 (0.8877) loss_zs_kd 1.6489 (1.8058) loss_oracle 1.0093 (0.9967) acc 75.0000 (69.0430) lr 1.1253e-03 eta 0:15:24
epoch [25/50] batch [340/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.1882 (2.3796) teacher_loss 0.7198 (0.8843) loss_zs_kd 1.9859 (1.8108) loss_oracle 0.9880 (0.9957) acc 81.2500 (69.2004) lr 1.1253e-03 eta 0:15:22
epoch [25/50] batch [360/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.3999 (2.3787) teacher_loss 0.9010 (0.8838) loss_zs_kd 1.3983 (1.8160) loss_oracle 0.9869 (0.9956) acc 71.8750 (69.1580) lr 1.1253e-03 eta 0:15:21
epoch [25/50] batch [380/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.4602 (2.3748) teacher_loss 1.0241 (0.8801) loss_zs_kd 1.8019 (1.8179) loss_oracle 0.9172 (0.9955) acc 62.5000 (69.2681) lr 1.1253e-03 eta 0:15:19
epoch [25/50] batch [400/428] time 0.148 (0.086) data 0.000 (0.002) loss 2.3494 (2.3699) teacher_loss 0.7965 (0.8752) loss_zs_kd 1.9510 (1.8224) loss_oracle 0.9794 (0.9946) acc 68.7500 (69.4844) lr 1.1253e-03 eta 0:15:19
epoch [25/50] batch [420/428] time 0.072 (0.086) data 0.000 (0.002) loss 2.6295 (2.3705) teacher_loss 0.9728 (0.8743) loss_zs_kd 1.5669 (1.8230) loss_oracle 1.0079 (0.9945) acc 65.6250 (69.5759) lr 1.1253e-03 eta 0:15:19
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,753
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 51.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,094
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 30.9%
******* Domain 1 best val acc:      63.9%, epoch: 25 *******
******* Domain 1 best val test acc: 44.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [26/50] batch [20/428] time 0.084 (0.110) data 0.000 (0.026) loss 2.2985 (2.3348) teacher_loss 0.7000 (0.8006) loss_zs_kd 2.0616 (1.7766) loss_oracle 1.0817 (0.9947) acc 71.8750 (72.0312) lr 1.0628e-03 eta 0:19:38
epoch [26/50] batch [40/428] time 0.083 (0.097) data 0.000 (0.013) loss 2.1589 (2.3417) teacher_loss 0.6337 (0.8218) loss_zs_kd 1.9060 (1.8234) loss_oracle 0.9845 (0.9850) acc 68.7500 (70.1562) lr 1.0628e-03 eta 0:17:14
epoch [26/50] batch [60/428] time 0.089 (0.093) data 0.000 (0.009) loss 2.6686 (2.3410) teacher_loss 1.1196 (0.8194) loss_zs_kd 1.6279 (1.8343) loss_oracle 1.0256 (0.9879) acc 59.3750 (70.5208) lr 1.0628e-03 eta 0:16:25
epoch [26/50] batch [80/428] time 0.086 (0.091) data 0.000 (0.007) loss 2.3407 (2.3404) teacher_loss 0.9083 (0.8199) loss_zs_kd 1.8313 (1.8521) loss_oracle 0.9727 (0.9890) acc 62.5000 (70.8984) lr 1.0628e-03 eta 0:16:05
epoch [26/50] batch [100/428] time 0.062 (0.088) data 0.000 (0.005) loss 1.9707 (2.3465) teacher_loss 0.5218 (0.8324) loss_zs_kd 1.8206 (1.8318) loss_oracle 0.9414 (0.9888) acc 87.5000 (70.6875) lr 1.0628e-03 eta 0:15:32
epoch [26/50] batch [120/428] time 0.087 (0.085) data 0.000 (0.005) loss 2.1752 (2.3394) teacher_loss 0.6763 (0.8339) loss_zs_kd 1.6451 (1.8240) loss_oracle 1.0005 (0.9858) acc 84.3750 (70.7031) lr 1.0628e-03 eta 0:15:01
epoch [26/50] batch [140/428] time 0.132 (0.087) data 0.001 (0.004) loss 2.3235 (2.3395) teacher_loss 0.7960 (0.8406) loss_zs_kd 1.9673 (1.8312) loss_oracle 1.0019 (0.9836) acc 75.0000 (70.0000) lr 1.0628e-03 eta 0:15:20
epoch [26/50] batch [160/428] time 0.075 (0.087) data 0.000 (0.004) loss 2.3379 (2.3304) teacher_loss 0.8979 (0.8382) loss_zs_kd 1.9018 (1.8301) loss_oracle 0.9461 (0.9804) acc 59.3750 (70.0781) lr 1.0628e-03 eta 0:15:13
epoch [26/50] batch [180/428] time 0.087 (0.086) data 0.001 (0.003) loss 2.3570 (2.3372) teacher_loss 0.8371 (0.8484) loss_zs_kd 1.5659 (1.8242) loss_oracle 0.9690 (0.9795) acc 71.8750 (69.5139) lr 1.0628e-03 eta 0:15:09
epoch [26/50] batch [200/428] time 0.079 (0.086) data 0.000 (0.003) loss 2.6676 (2.3457) teacher_loss 1.2226 (0.8574) loss_zs_kd 1.2000 (1.8158) loss_oracle 0.9138 (0.9793) acc 43.7500 (69.1562) lr 1.0628e-03 eta 0:15:03
epoch [26/50] batch [220/428] time 0.097 (0.086) data 0.000 (0.003) loss 2.3038 (2.3537) teacher_loss 0.6731 (0.8652) loss_zs_kd 1.7597 (1.8090) loss_oracle 0.9770 (0.9795) acc 81.2500 (68.7926) lr 1.0628e-03 eta 0:15:01
epoch [26/50] batch [240/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.2772 (2.3529) teacher_loss 0.8071 (0.8638) loss_zs_kd 2.0764 (1.8010) loss_oracle 1.0102 (0.9795) acc 68.7500 (68.8151) lr 1.0628e-03 eta 0:14:58
epoch [26/50] batch [260/428] time 0.085 (0.085) data 0.000 (0.002) loss 2.7113 (2.3561) teacher_loss 1.1767 (0.8661) loss_zs_kd 1.5560 (1.8037) loss_oracle 0.9795 (0.9800) acc 62.5000 (68.7500) lr 1.0628e-03 eta 0:14:48
epoch [26/50] batch [280/428] time 0.084 (0.085) data 0.000 (0.002) loss 2.2101 (2.3633) teacher_loss 0.6823 (0.8714) loss_zs_kd 1.8030 (1.7894) loss_oracle 0.9973 (0.9813) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:14:43
epoch [26/50] batch [300/428] time 0.074 (0.085) data 0.000 (0.002) loss 2.1789 (2.3634) teacher_loss 0.6452 (0.8695) loss_zs_kd 1.6492 (1.7881) loss_oracle 1.0268 (0.9832) acc 78.1250 (68.7917) lr 1.0628e-03 eta 0:14:38
epoch [26/50] batch [320/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.3841 (2.3662) teacher_loss 0.8639 (0.8706) loss_zs_kd 1.5245 (1.7798) loss_oracle 1.0040 (0.9842) acc 65.6250 (68.8867) lr 1.0628e-03 eta 0:14:32
epoch [26/50] batch [340/428] time 0.082 (0.084) data 0.000 (0.002) loss 2.5455 (2.3717) teacher_loss 1.0330 (0.8749) loss_zs_kd 1.8181 (1.7708) loss_oracle 1.0032 (0.9866) acc 59.3750 (68.8695) lr 1.0628e-03 eta 0:14:29
epoch [26/50] batch [360/428] time 0.080 (0.084) data 0.000 (0.002) loss 2.3036 (2.3726) teacher_loss 0.8071 (0.8758) loss_zs_kd 1.7294 (1.7627) loss_oracle 1.0220 (0.9874) acc 62.5000 (68.9149) lr 1.0628e-03 eta 0:14:29
epoch [26/50] batch [380/428] time 0.073 (0.084) data 0.000 (0.002) loss 2.4415 (2.3766) teacher_loss 0.9083 (0.8795) loss_zs_kd 1.4798 (1.7504) loss_oracle 0.9921 (0.9885) acc 56.2500 (68.6842) lr 1.0628e-03 eta 0:14:26
epoch [26/50] batch [400/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.2676 (2.3771) teacher_loss 0.7807 (0.8795) loss_zs_kd 1.7153 (1.7419) loss_oracle 0.9831 (0.9890) acc 75.0000 (68.7656) lr 1.0628e-03 eta 0:14:24
epoch [26/50] batch [420/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.2128 (2.3789) teacher_loss 0.7665 (0.8818) loss_zs_kd 1.5614 (1.7346) loss_oracle 0.9894 (0.9903) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:14:22
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,494
* accuracy: 59.5%
* error: 40.5%
* macro_f1: 49.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,227
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 33.4%
******* Domain 1 best val acc:      63.9%, epoch: 25 *******
******* Domain 1 best val test acc: 44.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [27/50] batch [20/428] time 0.079 (0.118) data 0.000 (0.029) loss 2.3718 (2.3613) teacher_loss 0.9273 (0.8750) loss_zs_kd 1.6834 (1.6093) loss_oracle 0.9735 (1.0052) acc 62.5000 (67.8125) lr 1.0000e-03 eta 0:20:12
epoch [27/50] batch [40/428] time 0.093 (0.102) data 0.000 (0.015) loss 2.6862 (2.3498) teacher_loss 1.1140 (0.8682) loss_zs_kd 1.5363 (1.6300) loss_oracle 1.0933 (1.0172) acc 56.2500 (69.4531) lr 1.0000e-03 eta 0:17:20
epoch [27/50] batch [60/428] time 0.081 (0.096) data 0.001 (0.010) loss 2.1972 (2.3289) teacher_loss 0.7439 (0.8458) loss_zs_kd 1.5027 (1.6120) loss_oracle 1.0150 (1.0184) acc 65.6250 (70.9375) lr 1.0000e-03 eta 0:16:22
epoch [27/50] batch [80/428] time 0.095 (0.094) data 0.000 (0.008) loss 2.4012 (2.3441) teacher_loss 0.8628 (0.8587) loss_zs_kd 1.6074 (1.6460) loss_oracle 1.0427 (1.0149) acc 62.5000 (69.9219) lr 1.0000e-03 eta 0:15:56
epoch [27/50] batch [100/428] time 0.081 (0.092) data 0.000 (0.006) loss 2.4157 (2.3402) teacher_loss 0.7660 (0.8443) loss_zs_kd 1.7641 (1.6698) loss_oracle 1.0408 (1.0161) acc 71.8750 (70.4375) lr 1.0000e-03 eta 0:15:35
epoch [27/50] batch [120/428] time 0.083 (0.090) data 0.001 (0.005) loss 2.4137 (2.3384) teacher_loss 0.7736 (0.8354) loss_zs_kd 1.9889 (1.6925) loss_oracle 0.9936 (1.0146) acc 68.7500 (70.6510) lr 1.0000e-03 eta 0:15:10
epoch [27/50] batch [140/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.3098 (2.3337) teacher_loss 0.6561 (0.8278) loss_zs_kd 1.5092 (1.7237) loss_oracle 1.0649 (1.0125) acc 71.8750 (70.8259) lr 1.0000e-03 eta 0:14:56
epoch [27/50] batch [160/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.4079 (2.3301) teacher_loss 0.8306 (0.8227) loss_zs_kd 2.3041 (1.7412) loss_oracle 1.0335 (1.0101) acc 75.0000 (70.9766) lr 1.0000e-03 eta 0:14:45
epoch [27/50] batch [180/428] time 0.090 (0.087) data 0.001 (0.004) loss 2.5063 (2.3306) teacher_loss 0.8905 (0.8207) loss_zs_kd 2.0356 (1.7740) loss_oracle 1.0227 (1.0084) acc 68.7500 (70.9896) lr 1.0000e-03 eta 0:14:38
epoch [27/50] batch [200/428] time 0.075 (0.087) data 0.001 (0.003) loss 2.3658 (2.3373) teacher_loss 0.7848 (0.8279) loss_zs_kd 1.4858 (1.7845) loss_oracle 1.0163 (1.0066) acc 68.7500 (70.7656) lr 1.0000e-03 eta 0:14:34
epoch [27/50] batch [220/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.4049 (2.3436) teacher_loss 0.8928 (0.8354) loss_zs_kd 1.7492 (1.7987) loss_oracle 1.0240 (1.0042) acc 75.0000 (70.6818) lr 1.0000e-03 eta 0:14:30
epoch [27/50] batch [240/428] time 0.089 (0.086) data 0.000 (0.003) loss 2.3118 (2.3418) teacher_loss 0.7732 (0.8322) loss_zs_kd 1.8346 (1.8066) loss_oracle 1.0401 (1.0023) acc 75.0000 (70.8854) lr 1.0000e-03 eta 0:14:27
epoch [27/50] batch [260/428] time 0.119 (0.087) data 0.000 (0.003) loss 2.1350 (2.3428) teacher_loss 0.6163 (0.8304) loss_zs_kd 2.1520 (1.8148) loss_oracle 1.0041 (1.0009) acc 84.3750 (71.0337) lr 1.0000e-03 eta 0:14:30
epoch [27/50] batch [280/428] time 0.090 (0.087) data 0.000 (0.002) loss 2.3737 (2.3420) teacher_loss 0.8083 (0.8287) loss_zs_kd 1.8589 (1.8222) loss_oracle 1.0093 (1.0000) acc 65.6250 (71.0268) lr 1.0000e-03 eta 0:14:28
epoch [27/50] batch [300/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.2059 (2.3441) teacher_loss 0.6492 (0.8264) loss_zs_kd 1.9361 (1.8249) loss_oracle 1.0275 (1.0018) acc 78.1250 (71.0938) lr 1.0000e-03 eta 0:14:25
epoch [27/50] batch [320/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.5654 (2.3436) teacher_loss 1.0628 (0.8254) loss_zs_kd 2.0580 (1.8309) loss_oracle 0.9487 (1.0010) acc 50.0000 (71.1816) lr 1.0000e-03 eta 0:14:22
epoch [27/50] batch [340/428] time 0.093 (0.087) data 0.000 (0.002) loss 2.4114 (2.3464) teacher_loss 0.9794 (0.8289) loss_zs_kd 1.8628 (1.8344) loss_oracle 0.8648 (0.9995) acc 62.5000 (71.0662) lr 1.0000e-03 eta 0:14:19
epoch [27/50] batch [360/428] time 0.092 (0.087) data 0.000 (0.002) loss 2.1222 (2.3436) teacher_loss 0.6635 (0.8283) loss_zs_kd 2.1599 (1.8370) loss_oracle 0.9587 (0.9981) acc 81.2500 (71.1806) lr 1.0000e-03 eta 0:14:18
epoch [27/50] batch [380/428] time 0.076 (0.087) data 0.000 (0.002) loss 2.3470 (2.3408) teacher_loss 0.8689 (0.8276) loss_zs_kd 2.0127 (1.8355) loss_oracle 0.9396 (0.9965) acc 71.8750 (71.2418) lr 1.0000e-03 eta 0:14:16
epoch [27/50] batch [400/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.2751 (2.3387) teacher_loss 0.8458 (0.8275) loss_zs_kd 2.2693 (1.8451) loss_oracle 0.9308 (0.9945) acc 68.7500 (71.1953) lr 1.0000e-03 eta 0:14:12
epoch [27/50] batch [420/428] time 0.074 (0.086) data 0.000 (0.002) loss 2.3813 (2.3350) teacher_loss 0.9007 (0.8238) loss_zs_kd 1.6892 (1.8522) loss_oracle 0.9587 (0.9940) acc 62.5000 (71.3170) lr 1.0000e-03 eta 0:14:08
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,687
* accuracy: 62.7%
* error: 37.3%
* macro_f1: 49.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,846
* accuracy: 38.9%
* error: 61.1%
* macro_f1: 31.4%
******* Domain 1 best val acc:      63.9%, epoch: 25 *******
******* Domain 1 best val test acc: 44.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [28/50] batch [20/428] time 0.074 (0.126) data 0.000 (0.034) loss 2.4420 (2.2936) teacher_loss 0.9007 (0.7638) loss_zs_kd 2.0204 (2.0697) loss_oracle 0.9543 (0.9860) acc 62.5000 (72.9688) lr 9.3721e-04 eta 0:20:33
epoch [28/50] batch [40/428] time 0.093 (0.106) data 0.000 (0.017) loss 2.4198 (2.3079) teacher_loss 0.8947 (0.7859) loss_zs_kd 1.7892 (1.9750) loss_oracle 1.0238 (0.9846) acc 68.7500 (72.9688) lr 9.3721e-04 eta 0:17:14
epoch [28/50] batch [60/428] time 0.086 (0.098) data 0.001 (0.012) loss 2.1746 (2.3082) teacher_loss 0.6116 (0.7842) loss_zs_kd 1.8636 (1.9305) loss_oracle 1.0085 (0.9874) acc 78.1250 (73.2812) lr 9.3721e-04 eta 0:16:01
epoch [28/50] batch [80/428] time 0.075 (0.095) data 0.000 (0.009) loss 2.2551 (2.3137) teacher_loss 0.7417 (0.7846) loss_zs_kd 1.6916 (1.8961) loss_oracle 1.0357 (0.9946) acc 78.1250 (73.2031) lr 9.3721e-04 eta 0:15:26
epoch [28/50] batch [100/428] time 0.088 (0.093) data 0.000 (0.007) loss 2.2450 (2.3243) teacher_loss 0.7984 (0.7968) loss_zs_kd 1.6444 (1.8719) loss_oracle 0.9329 (0.9942) acc 68.7500 (72.5938) lr 9.3721e-04 eta 0:15:07
epoch [28/50] batch [120/428] time 0.086 (0.092) data 0.000 (0.006) loss 2.7723 (2.3240) teacher_loss 1.3108 (0.7974) loss_zs_kd 1.4857 (1.8625) loss_oracle 0.9769 (0.9894) acc 53.1250 (72.3698) lr 9.3721e-04 eta 0:14:54
epoch [28/50] batch [140/428] time 0.079 (0.091) data 0.000 (0.005) loss 2.4617 (2.3279) teacher_loss 0.8989 (0.8009) loss_zs_kd 2.0126 (1.8641) loss_oracle 0.9968 (0.9876) acc 71.8750 (72.4107) lr 9.3721e-04 eta 0:14:42
epoch [28/50] batch [160/428] time 0.079 (0.090) data 0.000 (0.005) loss 2.2976 (2.3275) teacher_loss 0.8624 (0.8005) loss_zs_kd 1.8145 (1.8647) loss_oracle 0.9517 (0.9884) acc 81.2500 (72.2461) lr 9.3721e-04 eta 0:14:27
epoch [28/50] batch [180/428] time 0.083 (0.089) data 0.000 (0.004) loss 2.5336 (2.3232) teacher_loss 0.9843 (0.7941) loss_zs_kd 2.1991 (1.8792) loss_oracle 1.0152 (0.9901) acc 62.5000 (72.4132) lr 9.3721e-04 eta 0:14:21
epoch [28/50] batch [200/428] time 0.087 (0.089) data 0.000 (0.004) loss 2.2582 (2.3210) teacher_loss 0.7655 (0.7898) loss_zs_kd 2.0416 (1.8850) loss_oracle 0.9539 (0.9918) acc 71.8750 (72.6562) lr 9.3721e-04 eta 0:14:15
epoch [28/50] batch [220/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.7001 (2.3297) teacher_loss 1.1154 (0.7962) loss_zs_kd 1.9189 (1.8835) loss_oracle 0.9892 (0.9939) acc 68.7500 (72.6420) lr 9.3721e-04 eta 0:14:10
epoch [28/50] batch [240/428] time 0.089 (0.088) data 0.000 (0.003) loss 2.3335 (2.3273) teacher_loss 0.6933 (0.7903) loss_zs_kd 1.7900 (1.8848) loss_oracle 1.0965 (0.9966) acc 71.8750 (72.8646) lr 9.3721e-04 eta 0:14:06
epoch [28/50] batch [260/428] time 0.087 (0.088) data 0.000 (0.003) loss 2.1996 (2.3253) teacher_loss 0.7037 (0.7869) loss_zs_kd 1.7876 (1.8754) loss_oracle 0.9891 (0.9975) acc 81.2500 (73.0048) lr 9.3721e-04 eta 0:14:03
epoch [28/50] batch [280/428] time 0.087 (0.088) data 0.000 (0.003) loss 2.5474 (2.3246) teacher_loss 1.0088 (0.7857) loss_zs_kd 1.8093 (1.8686) loss_oracle 1.0086 (0.9992) acc 65.6250 (73.0134) lr 9.3721e-04 eta 0:14:01
epoch [28/50] batch [300/428] time 0.090 (0.088) data 0.000 (0.003) loss 2.4244 (2.3277) teacher_loss 0.8011 (0.7884) loss_zs_kd 1.8654 (1.8698) loss_oracle 1.0644 (1.0012) acc 68.7500 (72.9375) lr 9.3721e-04 eta 0:13:56
epoch [28/50] batch [320/428] time 0.088 (0.087) data 0.000 (0.002) loss 2.4316 (2.3300) teacher_loss 0.9100 (0.7912) loss_zs_kd 1.8566 (1.8689) loss_oracle 1.0704 (1.0035) acc 78.1250 (72.7734) lr 9.3721e-04 eta 0:13:53
epoch [28/50] batch [340/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.5128 (2.3341) teacher_loss 0.8931 (0.7946) loss_zs_kd 1.8689 (1.8743) loss_oracle 1.0954 (1.0052) acc 62.5000 (72.6103) lr 9.3721e-04 eta 0:13:49
epoch [28/50] batch [360/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.9608 (2.3370) teacher_loss 0.5767 (0.7989) loss_zs_kd 1.3952 (1.8725) loss_oracle 0.9855 (1.0056) acc 78.1250 (72.5174) lr 9.3721e-04 eta 0:13:46
epoch [28/50] batch [380/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.3007 (2.3447) teacher_loss 0.8294 (0.8081) loss_zs_kd 1.7692 (1.8615) loss_oracle 0.9974 (1.0061) acc 71.8750 (72.1628) lr 9.3721e-04 eta 0:13:42
epoch [28/50] batch [400/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.7897 (2.3489) teacher_loss 1.2987 (0.8149) loss_zs_kd 1.6550 (1.8521) loss_oracle 0.9725 (1.0059) acc 50.0000 (71.8906) lr 9.3721e-04 eta 0:13:42
epoch [28/50] batch [420/428] time 0.081 (0.087) data 0.001 (0.002) loss 2.1598 (2.3526) teacher_loss 0.7009 (0.8208) loss_zs_kd 1.9326 (1.8387) loss_oracle 0.9696 (1.0056) acc 71.8750 (71.6518) lr 9.3721e-04 eta 0:13:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,530
* accuracy: 60.1%
* error: 39.9%
* macro_f1: 52.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,307
* accuracy: 48.7%
* error: 51.3%
* macro_f1: 32.8%
******* Domain 1 best val acc:      63.9%, epoch: 25 *******
******* Domain 1 best val test acc: 44.2%, epoch: 25 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [29/50] batch [20/428] time 0.079 (0.116) data 0.000 (0.028) loss 2.3871 (2.4473) teacher_loss 0.9889 (0.9641) loss_zs_kd 1.7021 (1.6123) loss_oracle 1.0322 (1.0032) acc 65.6250 (66.5625) lr 8.7467e-04 eta 0:18:07
epoch [29/50] batch [40/428] time 0.088 (0.098) data 0.000 (0.014) loss 2.5122 (2.4297) teacher_loss 1.0367 (0.9474) loss_zs_kd 1.1510 (1.5789) loss_oracle 1.0783 (1.0027) acc 59.3750 (67.6562) lr 8.7467e-04 eta 0:15:18
epoch [29/50] batch [60/428] time 0.076 (0.090) data 0.001 (0.010) loss 2.4520 (2.3965) teacher_loss 0.9903 (0.9203) loss_zs_kd 1.3607 (1.5721) loss_oracle 1.0208 (0.9985) acc 68.7500 (68.5938) lr 8.7467e-04 eta 0:14:03
epoch [29/50] batch [80/428] time 0.077 (0.087) data 0.000 (0.007) loss 2.1846 (2.3818) teacher_loss 0.7230 (0.9028) loss_zs_kd 1.8427 (1.6130) loss_oracle 1.0262 (1.0014) acc 71.8750 (68.7109) lr 8.7467e-04 eta 0:13:29
epoch [29/50] batch [100/428] time 0.080 (0.085) data 0.000 (0.006) loss 2.2725 (2.3770) teacher_loss 0.7611 (0.8985) loss_zs_kd 1.8195 (1.6497) loss_oracle 1.0388 (1.0021) acc 71.8750 (68.8125) lr 8.7467e-04 eta 0:13:13
epoch [29/50] batch [120/428] time 0.073 (0.084) data 0.000 (0.005) loss 2.3776 (2.3684) teacher_loss 0.9056 (0.8932) loss_zs_kd 1.9583 (1.6831) loss_oracle 0.9778 (0.9995) acc 62.5000 (68.9323) lr 8.7467e-04 eta 0:13:01
epoch [29/50] batch [140/428] time 0.074 (0.084) data 0.000 (0.004) loss 2.1780 (2.3650) teacher_loss 0.6759 (0.8861) loss_zs_kd 1.6672 (1.6930) loss_oracle 1.0521 (1.0014) acc 84.3750 (69.0848) lr 8.7467e-04 eta 0:13:00
epoch [29/50] batch [160/428] time 0.069 (0.083) data 0.000 (0.004) loss 2.3511 (2.3723) teacher_loss 0.7738 (0.8826) loss_zs_kd 2.1176 (1.7014) loss_oracle 0.9448 (1.0054) acc 75.0000 (69.3555) lr 8.7467e-04 eta 0:12:48
epoch [29/50] batch [180/428] time 0.083 (0.082) data 0.000 (0.003) loss 2.1557 (2.3643) teacher_loss 0.5743 (0.8675) loss_zs_kd 2.0783 (1.7136) loss_oracle 1.0126 (1.0083) acc 78.1250 (70.0174) lr 8.7467e-04 eta 0:12:40
epoch [29/50] batch [200/428] time 0.084 (0.083) data 0.000 (0.003) loss 2.4625 (2.3664) teacher_loss 0.9049 (0.8638) loss_zs_kd 1.5567 (1.7272) loss_oracle 1.0376 (1.0104) acc 75.0000 (70.2812) lr 8.7467e-04 eta 0:12:40
epoch [29/50] batch [220/428] time 0.085 (0.082) data 0.000 (0.003) loss 2.4598 (2.3688) teacher_loss 0.9488 (0.8630) loss_zs_kd 2.1816 (1.7215) loss_oracle 1.0081 (1.0119) acc 53.1250 (70.1705) lr 8.7467e-04 eta 0:12:35
epoch [29/50] batch [240/428] time 0.075 (0.082) data 0.000 (0.003) loss 2.3723 (2.3695) teacher_loss 0.8597 (0.8623) loss_zs_kd 1.7993 (1.7209) loss_oracle 1.0034 (1.0119) acc 68.7500 (70.1302) lr 8.7467e-04 eta 0:12:31
epoch [29/50] batch [260/428] time 0.084 (0.082) data 0.000 (0.002) loss 2.3144 (2.3704) teacher_loss 0.8010 (0.8594) loss_zs_kd 1.4890 (1.7168) loss_oracle 0.9835 (1.0122) acc 68.7500 (70.2284) lr 8.7467e-04 eta 0:12:28
epoch [29/50] batch [280/428] time 0.079 (0.082) data 0.000 (0.002) loss 2.4047 (2.3710) teacher_loss 0.9486 (0.8594) loss_zs_kd 1.6771 (1.7141) loss_oracle 0.9823 (1.0130) acc 78.1250 (70.1897) lr 8.7467e-04 eta 0:12:24
epoch [29/50] batch [300/428] time 0.075 (0.081) data 0.000 (0.002) loss 2.4215 (2.3703) teacher_loss 0.9172 (0.8571) loss_zs_kd 2.2389 (1.7186) loss_oracle 1.0165 (1.0128) acc 62.5000 (70.3333) lr 8.7467e-04 eta 0:12:22
epoch [29/50] batch [320/428] time 0.069 (0.081) data 0.000 (0.002) loss 2.4438 (2.3691) teacher_loss 0.9290 (0.8544) loss_zs_kd 1.5691 (1.7203) loss_oracle 1.0532 (1.0137) acc 65.6250 (70.4297) lr 8.7467e-04 eta 0:12:18
epoch [29/50] batch [340/428] time 0.076 (0.081) data 0.000 (0.002) loss 2.1768 (2.3686) teacher_loss 0.7361 (0.8555) loss_zs_kd 1.7418 (1.7219) loss_oracle 0.9427 (1.0132) acc 71.8750 (70.3676) lr 8.7467e-04 eta 0:12:15
epoch [29/50] batch [360/428] time 0.078 (0.081) data 0.000 (0.002) loss 2.2920 (2.3708) teacher_loss 0.8293 (0.8606) loss_zs_kd 1.8081 (1.7268) loss_oracle 1.0240 (1.0132) acc 68.7500 (70.0694) lr 8.7467e-04 eta 0:12:12
epoch [29/50] batch [380/428] time 0.079 (0.081) data 0.000 (0.002) loss 2.4454 (2.3670) teacher_loss 0.9029 (0.8573) loss_zs_kd 1.5156 (1.7283) loss_oracle 1.0010 (1.0132) acc 71.8750 (70.1645) lr 8.7467e-04 eta 0:12:09
epoch [29/50] batch [400/428] time 0.074 (0.081) data 0.000 (0.002) loss 2.3232 (2.3686) teacher_loss 0.8542 (0.8584) loss_zs_kd 1.7562 (1.7334) loss_oracle 0.9864 (1.0145) acc 75.0000 (70.2344) lr 8.7467e-04 eta 0:12:09
epoch [29/50] batch [420/428] time 0.076 (0.081) data 0.000 (0.002) loss 2.2877 (2.3647) teacher_loss 0.8049 (0.8538) loss_zs_kd 2.1284 (1.7364) loss_oracle 1.0324 (1.0157) acc 68.7500 (70.4018) lr 8.7467e-04 eta 0:12:07
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,828
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 53.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,111
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.7%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [30/50] batch [20/428] time 0.078 (0.122) data 0.000 (0.027) loss 2.1367 (2.4023) teacher_loss 0.6811 (0.9241) loss_zs_kd 1.5653 (1.7652) loss_oracle 0.9782 (1.0158) acc 81.2500 (69.6875) lr 8.1262e-04 eta 0:18:10
epoch [30/50] batch [40/428] time 0.084 (0.103) data 0.000 (0.014) loss 2.3086 (2.3851) teacher_loss 0.8650 (0.9141) loss_zs_kd 1.8109 (1.7671) loss_oracle 1.0083 (1.0088) acc 71.8750 (68.9062) lr 8.1262e-04 eta 0:15:19
epoch [30/50] batch [60/428] time 0.092 (0.096) data 0.000 (0.009) loss 2.3634 (2.4004) teacher_loss 0.8718 (0.9234) loss_zs_kd 1.4965 (1.7483) loss_oracle 1.0577 (1.0169) acc 68.7500 (68.1250) lr 8.1262e-04 eta 0:14:14
epoch [30/50] batch [80/428] time 0.086 (0.092) data 0.000 (0.007) loss 2.2149 (2.3801) teacher_loss 0.7640 (0.9088) loss_zs_kd 1.6214 (1.7471) loss_oracle 0.9779 (1.0148) acc 71.8750 (68.7500) lr 8.1262e-04 eta 0:13:39
epoch [30/50] batch [100/428] time 0.085 (0.090) data 0.000 (0.006) loss 2.3159 (2.3820) teacher_loss 0.7841 (0.9073) loss_zs_kd 1.9635 (1.7588) loss_oracle 1.0140 (1.0118) acc 68.7500 (68.3750) lr 8.1262e-04 eta 0:13:23
epoch [30/50] batch [120/428] time 0.079 (0.089) data 0.000 (0.005) loss 2.0863 (2.3725) teacher_loss 0.5096 (0.8881) loss_zs_kd 1.8654 (1.7615) loss_oracle 1.0537 (1.0144) acc 87.5000 (69.1927) lr 8.1262e-04 eta 0:13:11
epoch [30/50] batch [140/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.4853 (2.3642) teacher_loss 0.9992 (0.8760) loss_zs_kd 2.1855 (1.7675) loss_oracle 1.0532 (1.0131) acc 56.2500 (69.4420) lr 8.1262e-04 eta 0:12:57
epoch [30/50] batch [160/428] time 0.088 (0.088) data 0.000 (0.004) loss 2.4980 (2.3662) teacher_loss 1.0009 (0.8745) loss_zs_kd 1.4761 (1.7710) loss_oracle 1.0222 (1.0135) acc 65.6250 (69.3164) lr 8.1262e-04 eta 0:12:53
epoch [30/50] batch [180/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.1626 (2.3620) teacher_loss 0.6447 (0.8686) loss_zs_kd 1.7273 (1.7883) loss_oracle 1.0143 (1.0139) acc 87.5000 (69.4444) lr 8.1262e-04 eta 0:12:49
epoch [30/50] batch [200/428] time 0.084 (0.087) data 0.000 (0.003) loss 2.3400 (2.3627) teacher_loss 0.8290 (0.8675) loss_zs_kd 2.2148 (1.8069) loss_oracle 0.9237 (1.0131) acc 75.0000 (69.3438) lr 8.1262e-04 eta 0:12:41
epoch [30/50] batch [220/428] time 0.075 (0.086) data 0.000 (0.003) loss 2.4496 (2.3550) teacher_loss 1.0266 (0.8592) loss_zs_kd 2.2510 (1.8196) loss_oracle 0.9578 (1.0120) acc 56.2500 (69.5597) lr 8.1262e-04 eta 0:12:35
epoch [30/50] batch [240/428] time 0.073 (0.086) data 0.000 (0.003) loss 2.0955 (2.3585) teacher_loss 0.6016 (0.8625) loss_zs_kd 1.9587 (1.8323) loss_oracle 1.0035 (1.0116) acc 87.5000 (69.5182) lr 8.1262e-04 eta 0:12:28
epoch [30/50] batch [260/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.0902 (2.3506) teacher_loss 0.6015 (0.8530) loss_zs_kd 1.6425 (1.8314) loss_oracle 0.9842 (1.0124) acc 78.1250 (69.7837) lr 8.1262e-04 eta 0:12:20
epoch [30/50] batch [280/428] time 0.084 (0.084) data 0.001 (0.002) loss 2.3874 (2.3518) teacher_loss 0.9553 (0.8541) loss_zs_kd 1.7417 (1.8423) loss_oracle 0.9874 (1.0110) acc 71.8750 (69.7545) lr 8.1262e-04 eta 0:12:14
epoch [30/50] batch [300/428] time 0.076 (0.085) data 0.000 (0.002) loss 2.2218 (2.3507) teacher_loss 0.7314 (0.8530) loss_zs_kd 1.8543 (1.8482) loss_oracle 1.0612 (1.0097) acc 81.2500 (69.8646) lr 8.1262e-04 eta 0:12:18
epoch [30/50] batch [320/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.3034 (2.3548) teacher_loss 0.8368 (0.8572) loss_zs_kd 2.3164 (1.8504) loss_oracle 1.0291 (1.0090) acc 56.2500 (69.7461) lr 8.1262e-04 eta 0:12:15
epoch [30/50] batch [340/428] time 0.089 (0.085) data 0.000 (0.002) loss 2.1299 (2.3531) teacher_loss 0.6229 (0.8575) loss_zs_kd 1.8732 (1.8482) loss_oracle 1.0103 (1.0070) acc 81.2500 (69.6691) lr 8.1262e-04 eta 0:12:13
epoch [30/50] batch [360/428] time 0.085 (0.085) data 0.000 (0.002) loss 2.0910 (2.3546) teacher_loss 0.6553 (0.8596) loss_zs_kd 1.8126 (1.8461) loss_oracle 0.9734 (1.0057) acc 81.2500 (69.6615) lr 8.1262e-04 eta 0:12:11
epoch [30/50] batch [380/428] time 0.069 (0.085) data 0.000 (0.002) loss 2.2747 (2.3548) teacher_loss 0.6976 (0.8581) loss_zs_kd 1.9881 (1.8448) loss_oracle 0.9691 (1.0068) acc 81.2500 (69.7697) lr 8.1262e-04 eta 0:12:07
epoch [30/50] batch [400/428] time 0.077 (0.084) data 0.000 (0.002) loss 2.1939 (2.3522) teacher_loss 0.6545 (0.8547) loss_zs_kd 1.6321 (1.8428) loss_oracle 1.0292 (1.0073) acc 78.1250 (69.8672) lr 8.1262e-04 eta 0:12:03
epoch [30/50] batch [420/428] time 0.071 (0.084) data 0.000 (0.002) loss 2.6233 (2.3533) teacher_loss 1.0122 (0.8541) loss_zs_kd 1.3593 (1.8430) loss_oracle 1.0456 (1.0082) acc 62.5000 (69.8140) lr 8.1262e-04 eta 0:11:59
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,760
* accuracy: 64.0%
* error: 36.0%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,127
* accuracy: 44.9%
* error: 55.1%
* macro_f1: 31.5%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [31/50] batch [20/428] time 0.066 (0.125) data 0.000 (0.033) loss 2.2786 (2.3370) teacher_loss 0.7743 (0.8026) loss_zs_kd 2.1645 (1.9778) loss_oracle 0.9889 (1.0219) acc 65.6250 (71.0938) lr 7.5131e-04 eta 0:17:49
epoch [31/50] batch [40/428] time 0.078 (0.102) data 0.000 (0.017) loss 2.1999 (2.3503) teacher_loss 0.6710 (0.8211) loss_zs_kd 1.5475 (1.9330) loss_oracle 1.0073 (1.0135) acc 78.1250 (71.3281) lr 7.5131e-04 eta 0:14:31
epoch [31/50] batch [60/428] time 0.082 (0.096) data 0.001 (0.011) loss 2.2330 (2.3528) teacher_loss 0.7801 (0.8302) loss_zs_kd 1.7992 (1.9047) loss_oracle 0.9554 (1.0095) acc 71.8750 (71.0417) lr 7.5131e-04 eta 0:13:35
epoch [31/50] batch [80/428] time 0.083 (0.093) data 0.000 (0.008) loss 2.1160 (2.3560) teacher_loss 0.6080 (0.8327) loss_zs_kd 1.7210 (1.8916) loss_oracle 1.0456 (1.0128) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:13:08
epoch [31/50] batch [100/428] time 0.082 (0.092) data 0.000 (0.007) loss 2.3460 (2.3658) teacher_loss 0.7758 (0.8448) loss_zs_kd 1.9665 (1.8994) loss_oracle 1.0743 (1.0121) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:12:55
epoch [31/50] batch [120/428] time 0.086 (0.091) data 0.000 (0.006) loss 1.9064 (2.3546) teacher_loss 0.4635 (0.8363) loss_zs_kd 2.0404 (1.8987) loss_oracle 0.9593 (1.0107) acc 90.6250 (71.1198) lr 7.5131e-04 eta 0:12:44
epoch [31/50] batch [140/428] time 0.081 (0.089) data 0.000 (0.005) loss 2.2646 (2.3544) teacher_loss 0.7143 (0.8376) loss_zs_kd 1.5702 (1.9040) loss_oracle 1.0300 (1.0115) acc 75.0000 (71.1830) lr 7.5131e-04 eta 0:12:29
epoch [31/50] batch [160/428] time 0.082 (0.088) data 0.000 (0.004) loss 2.3618 (2.3493) teacher_loss 0.8520 (0.8333) loss_zs_kd 2.0340 (1.9010) loss_oracle 1.0081 (1.0107) acc 68.7500 (71.3672) lr 7.5131e-04 eta 0:12:22
epoch [31/50] batch [180/428] time 0.090 (0.088) data 0.000 (0.004) loss 2.1571 (2.3484) teacher_loss 0.6649 (0.8332) loss_zs_kd 2.0012 (1.8950) loss_oracle 1.0137 (1.0109) acc 71.8750 (71.2674) lr 7.5131e-04 eta 0:12:17
epoch [31/50] batch [200/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.5569 (2.3490) teacher_loss 0.9142 (0.8323) loss_zs_kd 1.5623 (1.8863) loss_oracle 1.0923 (1.0134) acc 59.3750 (71.2344) lr 7.5131e-04 eta 0:12:14
epoch [31/50] batch [220/428] time 0.085 (0.088) data 0.000 (0.003) loss 2.4019 (2.3439) teacher_loss 0.9326 (0.8255) loss_zs_kd 1.8218 (1.8916) loss_oracle 0.9655 (1.0159) acc 62.5000 (71.3068) lr 7.5131e-04 eta 0:12:10
epoch [31/50] batch [240/428] time 0.084 (0.088) data 0.000 (0.003) loss 2.2622 (2.3414) teacher_loss 0.7110 (0.8200) loss_zs_kd 2.2530 (1.8897) loss_oracle 1.0067 (1.0172) acc 78.1250 (71.3672) lr 7.5131e-04 eta 0:12:08
epoch [31/50] batch [260/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.3518 (2.3441) teacher_loss 0.7797 (0.8195) loss_zs_kd 1.6038 (1.8868) loss_oracle 1.0711 (1.0192) acc 75.0000 (71.4663) lr 7.5131e-04 eta 0:12:04
epoch [31/50] batch [280/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.4991 (2.3452) teacher_loss 0.9558 (0.8178) loss_zs_kd 1.8557 (1.8800) loss_oracle 1.0318 (1.0208) acc 71.8750 (71.3839) lr 7.5131e-04 eta 0:12:01
epoch [31/50] batch [300/428] time 0.083 (0.087) data 0.000 (0.002) loss 2.2308 (2.3383) teacher_loss 0.5704 (0.8088) loss_zs_kd 1.7763 (1.8808) loss_oracle 1.0987 (1.0214) acc 84.3750 (71.7708) lr 7.5131e-04 eta 0:11:58
epoch [31/50] batch [320/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.2200 (2.3365) teacher_loss 0.6685 (0.8070) loss_zs_kd 2.1911 (1.8852) loss_oracle 1.0502 (1.0213) acc 78.1250 (71.8457) lr 7.5131e-04 eta 0:11:52
epoch [31/50] batch [340/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.1675 (2.3356) teacher_loss 0.5774 (0.8042) loss_zs_kd 2.1156 (1.8818) loss_oracle 1.0675 (1.0220) acc 81.2500 (72.0037) lr 7.5131e-04 eta 0:11:50
epoch [31/50] batch [360/428] time 0.089 (0.086) data 0.000 (0.002) loss 2.3101 (2.3352) teacher_loss 0.6874 (0.8013) loss_zs_kd 1.5207 (1.8748) loss_oracle 1.1078 (1.0234) acc 71.8750 (72.0660) lr 7.5131e-04 eta 0:11:47
epoch [31/50] batch [380/428] time 0.077 (0.086) data 0.000 (0.002) loss 2.6761 (2.3361) teacher_loss 1.0864 (0.8011) loss_zs_kd 2.0791 (1.8720) loss_oracle 1.0725 (1.0234) acc 68.7500 (72.1053) lr 7.5131e-04 eta 0:11:45
epoch [31/50] batch [400/428] time 0.138 (0.086) data 0.000 (0.002) loss 2.2671 (2.3338) teacher_loss 0.7124 (0.7977) loss_zs_kd 2.1178 (1.8693) loss_oracle 1.0856 (1.0237) acc 75.0000 (72.2266) lr 7.5131e-04 eta 0:11:43
epoch [31/50] batch [420/428] time 0.080 (0.086) data 0.000 (0.002) loss 2.6792 (2.3346) teacher_loss 1.0574 (0.7977) loss_zs_kd 1.7695 (1.8656) loss_oracle 1.0932 (1.0245) acc 65.6250 (72.2545) lr 7.5131e-04 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,755
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 50.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,102
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 32.7%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [32/50] batch [20/428] time 0.077 (0.110) data 0.000 (0.027) loss 2.0566 (2.3451) teacher_loss 0.5296 (0.8248) loss_zs_kd 1.5038 (1.7990) loss_oracle 1.0394 (1.0216) acc 90.6250 (72.3438) lr 6.9098e-04 eta 0:14:54
epoch [32/50] batch [40/428] time 0.074 (0.094) data 0.000 (0.014) loss 2.4364 (2.3397) teacher_loss 0.9154 (0.8095) loss_zs_kd 1.7882 (1.8044) loss_oracle 0.9916 (1.0284) acc 71.8750 (73.1250) lr 6.9098e-04 eta 0:12:37
epoch [32/50] batch [60/428] time 0.078 (0.087) data 0.000 (0.009) loss 2.3736 (2.3177) teacher_loss 0.8429 (0.7975) loss_zs_kd 1.7774 (1.8557) loss_oracle 1.0219 (1.0268) acc 68.7500 (72.8646) lr 6.9098e-04 eta 0:11:44
epoch [32/50] batch [80/428] time 0.082 (0.086) data 0.000 (0.007) loss 2.3561 (2.3206) teacher_loss 0.8668 (0.8060) loss_zs_kd 1.8737 (1.8450) loss_oracle 1.0472 (1.0249) acc 65.6250 (72.1875) lr 6.9098e-04 eta 0:11:31
epoch [32/50] batch [100/428] time 0.080 (0.085) data 0.000 (0.006) loss 2.2254 (2.3276) teacher_loss 0.7785 (0.8189) loss_zs_kd 2.0345 (1.8262) loss_oracle 1.0258 (1.0262) acc 78.1250 (71.7812) lr 6.9098e-04 eta 0:11:21
epoch [32/50] batch [120/428] time 0.074 (0.084) data 0.000 (0.005) loss 2.4219 (2.3338) teacher_loss 0.9825 (0.8338) loss_zs_kd 1.3121 (1.8049) loss_oracle 0.9440 (1.0240) acc 56.2500 (71.0156) lr 6.9098e-04 eta 0:11:13
epoch [32/50] batch [140/428] time 0.076 (0.084) data 0.000 (0.004) loss 2.2876 (2.3340) teacher_loss 0.8221 (0.8344) loss_zs_kd 1.7436 (1.8023) loss_oracle 0.9814 (1.0248) acc 71.8750 (70.7812) lr 6.9098e-04 eta 0:11:12
epoch [32/50] batch [160/428] time 0.078 (0.084) data 0.000 (0.004) loss 2.0472 (2.3385) teacher_loss 0.5560 (0.8407) loss_zs_kd 1.6719 (1.7907) loss_oracle 1.0993 (1.0239) acc 84.3750 (70.6055) lr 6.9098e-04 eta 0:11:13
epoch [32/50] batch [180/428] time 0.077 (0.084) data 0.000 (0.003) loss 2.3544 (2.3420) teacher_loss 0.8532 (0.8439) loss_zs_kd 1.8860 (1.7929) loss_oracle 1.0669 (1.0242) acc 65.6250 (70.4688) lr 6.9098e-04 eta 0:11:11
epoch [32/50] batch [200/428] time 0.089 (0.084) data 0.000 (0.003) loss 2.1166 (2.3473) teacher_loss 0.5761 (0.8475) loss_zs_kd 1.7618 (1.7928) loss_oracle 1.0550 (1.0247) acc 81.2500 (70.2500) lr 6.9098e-04 eta 0:11:09
epoch [32/50] batch [220/428] time 0.082 (0.084) data 0.000 (0.003) loss 2.4082 (2.3483) teacher_loss 0.9040 (0.8462) loss_zs_kd 1.8812 (1.7976) loss_oracle 1.0398 (1.0260) acc 59.3750 (70.3551) lr 6.9098e-04 eta 0:11:04
epoch [32/50] batch [240/428] time 0.087 (0.084) data 0.000 (0.003) loss 2.5540 (2.3417) teacher_loss 0.8974 (0.8374) loss_zs_kd 1.7329 (1.8007) loss_oracle 1.1146 (1.0259) acc 68.7500 (70.6380) lr 6.9098e-04 eta 0:11:03
epoch [32/50] batch [260/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.1678 (2.3420) teacher_loss 0.5703 (0.8368) loss_zs_kd 1.8031 (1.8019) loss_oracle 1.0489 (1.0260) acc 78.1250 (70.5288) lr 6.9098e-04 eta 0:11:01
epoch [32/50] batch [280/428] time 0.098 (0.084) data 0.000 (0.002) loss 2.9676 (2.3431) teacher_loss 1.3986 (0.8363) loss_zs_kd 1.5644 (1.8060) loss_oracle 1.0456 (1.0263) acc 43.7500 (70.5134) lr 6.9098e-04 eta 0:10:57
epoch [32/50] batch [300/428] time 0.082 (0.084) data 0.000 (0.002) loss 2.3374 (2.3447) teacher_loss 0.8097 (0.8363) loss_zs_kd 1.5590 (1.8006) loss_oracle 1.0080 (1.0251) acc 71.8750 (70.5833) lr 6.9098e-04 eta 0:10:56
epoch [32/50] batch [320/428] time 0.089 (0.084) data 0.000 (0.002) loss 2.4364 (2.3445) teacher_loss 0.8653 (0.8345) loss_zs_kd 1.7545 (1.7995) loss_oracle 1.0170 (1.0247) acc 65.6250 (70.5566) lr 6.9098e-04 eta 0:10:56
epoch [32/50] batch [340/428] time 0.076 (0.084) data 0.000 (0.002) loss 2.1142 (2.3453) teacher_loss 0.5215 (0.8322) loss_zs_kd 1.6532 (1.8026) loss_oracle 1.1135 (1.0253) acc 81.2500 (70.6985) lr 6.9098e-04 eta 0:10:54
epoch [32/50] batch [360/428] time 0.092 (0.084) data 0.000 (0.002) loss 2.3940 (2.3462) teacher_loss 0.9193 (0.8311) loss_zs_kd 1.6285 (1.7985) loss_oracle 1.0472 (1.0264) acc 59.3750 (70.6597) lr 6.9098e-04 eta 0:10:54
epoch [32/50] batch [380/428] time 0.078 (0.084) data 0.000 (0.002) loss 2.6024 (2.3461) teacher_loss 1.1322 (0.8309) loss_zs_kd 1.2260 (1.7991) loss_oracle 1.0155 (1.0261) acc 56.2500 (70.7155) lr 6.9098e-04 eta 0:10:53
epoch [32/50] batch [400/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.6105 (2.3451) teacher_loss 1.0667 (0.8295) loss_zs_kd 1.7717 (1.8020) loss_oracle 1.0745 (1.0264) acc 68.7500 (70.7734) lr 6.9098e-04 eta 0:10:51
epoch [32/50] batch [420/428] time 0.080 (0.084) data 0.000 (0.002) loss 2.2624 (2.3487) teacher_loss 0.6704 (0.8325) loss_zs_kd 1.5200 (1.8016) loss_oracle 1.1098 (1.0259) acc 75.0000 (70.7143) lr 6.9098e-04 eta 0:10:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,801
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,026
* accuracy: 42.7%
* error: 57.3%
* macro_f1: 30.7%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [33/50] batch [20/428] time 0.080 (0.106) data 0.000 (0.026) loss 2.3937 (2.3639) teacher_loss 0.9232 (0.8687) loss_zs_kd 1.3801 (1.6720) loss_oracle 0.9839 (1.0153) acc 62.5000 (69.2188) lr 6.3188e-04 eta 0:13:36
epoch [33/50] batch [40/428] time 0.060 (0.087) data 0.000 (0.013) loss 2.3357 (2.3429) teacher_loss 0.8188 (0.8473) loss_zs_kd 1.6535 (1.7295) loss_oracle 1.0280 (1.0116) acc 68.7500 (70.4688) lr 6.3188e-04 eta 0:11:08
epoch [33/50] batch [60/428] time 0.088 (0.084) data 0.000 (0.009) loss 2.3650 (2.3375) teacher_loss 0.9523 (0.8349) loss_zs_kd 1.7389 (1.7833) loss_oracle 1.0046 (1.0129) acc 62.5000 (71.1458) lr 6.3188e-04 eta 0:10:45
epoch [33/50] batch [80/428] time 0.087 (0.084) data 0.000 (0.007) loss 2.3981 (2.3609) teacher_loss 0.8013 (0.8590) loss_zs_kd 1.4481 (1.7880) loss_oracle 1.0805 (1.0156) acc 62.5000 (70.1562) lr 6.3188e-04 eta 0:10:41
epoch [33/50] batch [100/428] time 0.079 (0.083) data 0.000 (0.005) loss 2.6316 (2.3556) teacher_loss 1.1033 (0.8553) loss_zs_kd 1.6040 (1.7908) loss_oracle 0.9719 (1.0143) acc 65.6250 (70.6875) lr 6.3188e-04 eta 0:10:34
epoch [33/50] batch [120/428] time 0.082 (0.083) data 0.000 (0.005) loss 2.2334 (2.3562) teacher_loss 0.6996 (0.8567) loss_zs_kd 1.7574 (1.7998) loss_oracle 1.0154 (1.0112) acc 75.0000 (70.3906) lr 6.3188e-04 eta 0:10:26
epoch [33/50] batch [140/428] time 0.078 (0.083) data 0.000 (0.004) loss 2.3803 (2.3459) teacher_loss 0.7489 (0.8447) loss_zs_kd 1.6200 (1.8044) loss_oracle 1.0396 (1.0102) acc 65.6250 (70.8929) lr 6.3188e-04 eta 0:10:27
epoch [33/50] batch [160/428] time 0.088 (0.083) data 0.000 (0.003) loss 2.3523 (2.3392) teacher_loss 0.7559 (0.8340) loss_zs_kd 2.0260 (1.8125) loss_oracle 1.0759 (1.0117) acc 71.8750 (71.4453) lr 6.3188e-04 eta 0:10:26
epoch [33/50] batch [180/428] time 0.073 (0.083) data 0.000 (0.003) loss 2.4882 (2.3463) teacher_loss 0.9399 (0.8374) loss_zs_kd 2.1011 (1.8212) loss_oracle 1.0087 (1.0126) acc 68.7500 (71.2500) lr 6.3188e-04 eta 0:10:23
epoch [33/50] batch [200/428] time 0.082 (0.082) data 0.000 (0.003) loss 2.4508 (2.3449) teacher_loss 0.9512 (0.8320) loss_zs_kd 1.6665 (1.8211) loss_oracle 1.0007 (1.0141) acc 78.1250 (71.4531) lr 6.3188e-04 eta 0:10:17
epoch [33/50] batch [220/428] time 0.082 (0.082) data 0.000 (0.003) loss 2.4948 (2.3458) teacher_loss 1.0019 (0.8328) loss_zs_kd 1.7404 (1.8178) loss_oracle 0.9954 (1.0143) acc 68.7500 (71.4773) lr 6.3188e-04 eta 0:10:13
epoch [33/50] batch [240/428] time 0.082 (0.082) data 0.000 (0.002) loss 2.2610 (2.3446) teacher_loss 0.8743 (0.8323) loss_zs_kd 2.0567 (1.8171) loss_oracle 0.9849 (1.0125) acc 75.0000 (71.4974) lr 6.3188e-04 eta 0:10:14
epoch [33/50] batch [260/428] time 0.087 (0.083) data 0.000 (0.002) loss 2.0903 (2.3414) teacher_loss 0.6110 (0.8274) loss_zs_kd 1.6423 (1.8207) loss_oracle 0.9899 (1.0131) acc 75.0000 (71.6346) lr 6.3188e-04 eta 0:10:15
epoch [33/50] batch [280/428] time 0.076 (0.083) data 0.000 (0.002) loss 2.3911 (2.3437) teacher_loss 0.8025 (0.8283) loss_zs_kd 1.8168 (1.8268) loss_oracle 1.0558 (1.0144) acc 68.7500 (71.5960) lr 6.3188e-04 eta 0:10:18
epoch [33/50] batch [300/428] time 0.076 (0.083) data 0.000 (0.002) loss 2.4589 (2.3435) teacher_loss 0.9730 (0.8271) loss_zs_kd 2.0970 (1.8273) loss_oracle 0.9590 (1.0144) acc 68.7500 (71.6354) lr 6.3188e-04 eta 0:10:15
epoch [33/50] batch [320/428] time 0.081 (0.083) data 0.000 (0.002) loss 2.4161 (2.3426) teacher_loss 0.9074 (0.8262) loss_zs_kd 1.8223 (1.8326) loss_oracle 1.0176 (1.0146) acc 68.7500 (71.6797) lr 6.3188e-04 eta 0:10:13
epoch [33/50] batch [340/428] time 0.078 (0.083) data 0.000 (0.002) loss 2.2005 (2.3455) teacher_loss 0.6901 (0.8297) loss_zs_kd 1.7962 (1.8343) loss_oracle 1.0689 (1.0148) acc 71.8750 (71.4062) lr 6.3188e-04 eta 0:10:10
epoch [33/50] batch [360/428] time 0.085 (0.083) data 0.000 (0.002) loss 2.1560 (2.3431) teacher_loss 0.6495 (0.8283) loss_zs_kd 1.9295 (1.8362) loss_oracle 1.0390 (1.0142) acc 71.8750 (71.4149) lr 6.3188e-04 eta 0:10:07
epoch [33/50] batch [380/428] time 0.082 (0.082) data 0.000 (0.002) loss 2.1325 (2.3419) teacher_loss 0.6520 (0.8272) loss_zs_kd 2.0498 (1.8372) loss_oracle 1.0659 (1.0134) acc 81.2500 (71.4885) lr 6.3188e-04 eta 0:10:04
epoch [33/50] batch [400/428] time 0.083 (0.083) data 0.000 (0.002) loss 2.5043 (2.3420) teacher_loss 0.9331 (0.8272) loss_zs_kd 1.8605 (1.8380) loss_oracle 1.0235 (1.0136) acc 71.8750 (71.5625) lr 6.3188e-04 eta 0:10:02
epoch [33/50] batch [420/428] time 0.074 (0.082) data 0.000 (0.001) loss 2.2682 (2.3396) teacher_loss 0.6843 (0.8257) loss_zs_kd 2.0806 (1.8408) loss_oracle 1.0153 (1.0130) acc 75.0000 (71.5327) lr 6.3188e-04 eta 0:10:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,790
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 51.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,037
* accuracy: 43.0%
* error: 57.0%
* macro_f1: 30.6%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [34/50] batch [20/428] time 0.080 (0.121) data 0.000 (0.024) loss 2.1210 (2.3129) teacher_loss 0.5167 (0.7773) loss_zs_kd 1.8879 (1.8671) loss_oracle 1.0373 (1.0052) acc 87.5000 (73.2812) lr 5.7422e-04 eta 0:14:36
epoch [34/50] batch [40/428] time 0.079 (0.102) data 0.000 (0.012) loss 2.4092 (2.3189) teacher_loss 0.9171 (0.7949) loss_zs_kd 2.1396 (1.8764) loss_oracle 1.0028 (1.0111) acc 65.6250 (71.2500) lr 5.7422e-04 eta 0:12:19
epoch [34/50] batch [60/428] time 0.075 (0.094) data 0.000 (0.008) loss 2.2352 (2.3020) teacher_loss 0.6583 (0.7781) loss_zs_kd 1.9360 (1.8823) loss_oracle 1.0560 (1.0141) acc 81.2500 (72.2396) lr 5.7422e-04 eta 0:11:15
epoch [34/50] batch [80/428] time 0.080 (0.091) data 0.000 (0.006) loss 2.3447 (2.2927) teacher_loss 0.7790 (0.7690) loss_zs_kd 2.0454 (1.8998) loss_oracle 1.0137 (1.0150) acc 71.8750 (72.9297) lr 5.7422e-04 eta 0:10:51
epoch [34/50] batch [100/428] time 0.083 (0.089) data 0.000 (0.005) loss 2.3111 (2.2907) teacher_loss 0.8013 (0.7680) loss_zs_kd 2.1457 (1.9053) loss_oracle 1.0035 (1.0105) acc 71.8750 (72.6250) lr 5.7422e-04 eta 0:10:39
epoch [34/50] batch [120/428] time 0.080 (0.088) data 0.000 (0.004) loss 2.2748 (2.3019) teacher_loss 0.7927 (0.7818) loss_zs_kd 1.7030 (1.8980) loss_oracle 0.9706 (1.0093) acc 68.7500 (71.8750) lr 5.7422e-04 eta 0:10:30
epoch [34/50] batch [140/428] time 0.075 (0.087) data 0.000 (0.004) loss 2.0960 (2.3078) teacher_loss 0.5746 (0.7906) loss_zs_kd 1.9787 (1.8987) loss_oracle 0.9954 (1.0087) acc 78.1250 (71.9643) lr 5.7422e-04 eta 0:10:21
epoch [34/50] batch [160/428] time 0.078 (0.086) data 0.000 (0.003) loss 2.6491 (2.3109) teacher_loss 1.1716 (0.7964) loss_zs_kd 1.7101 (1.9085) loss_oracle 1.0733 (1.0071) acc 59.3750 (71.7969) lr 5.7422e-04 eta 0:10:15
epoch [34/50] batch [180/428] time 0.065 (0.084) data 0.000 (0.003) loss 2.1806 (2.3170) teacher_loss 0.6516 (0.8024) loss_zs_kd 1.9145 (1.9092) loss_oracle 0.9919 (1.0079) acc 68.7500 (71.4931) lr 5.7422e-04 eta 0:09:56
epoch [34/50] batch [200/428] time 0.061 (0.082) data 0.000 (0.003) loss 2.5600 (2.3189) teacher_loss 0.9873 (0.8039) loss_zs_kd 1.6239 (1.9011) loss_oracle 1.0534 (1.0078) acc 62.5000 (71.3906) lr 5.7422e-04 eta 0:09:38
epoch [34/50] batch [220/428] time 0.076 (0.080) data 0.000 (0.002) loss 2.4927 (2.3194) teacher_loss 0.9390 (0.8047) loss_zs_kd 2.2872 (1.9033) loss_oracle 1.0274 (1.0083) acc 62.5000 (71.2500) lr 5.7422e-04 eta 0:09:24
epoch [34/50] batch [240/428] time 0.061 (0.079) data 0.000 (0.002) loss 2.2914 (2.3180) teacher_loss 0.7688 (0.8009) loss_zs_kd 1.9431 (1.9017) loss_oracle 1.0367 (1.0102) acc 65.6250 (71.3151) lr 5.7422e-04 eta 0:09:13
epoch [34/50] batch [260/428] time 0.082 (0.078) data 0.000 (0.002) loss 2.0568 (2.3161) teacher_loss 0.4229 (0.7967) loss_zs_kd 1.6771 (1.9054) loss_oracle 1.1047 (1.0116) acc 87.5000 (71.6106) lr 5.7422e-04 eta 0:09:05
epoch [34/50] batch [280/428] time 0.077 (0.078) data 0.000 (0.002) loss 2.5967 (2.3243) teacher_loss 1.0630 (0.8033) loss_zs_kd 1.4516 (1.9037) loss_oracle 0.9959 (1.0130) acc 59.3750 (71.4732) lr 5.7422e-04 eta 0:09:04
epoch [34/50] batch [300/428] time 0.073 (0.077) data 0.000 (0.002) loss 2.2771 (2.3221) teacher_loss 0.7254 (0.7978) loss_zs_kd 1.7790 (1.9000) loss_oracle 1.0379 (1.0150) acc 78.1250 (71.6667) lr 5.7422e-04 eta 0:08:59
epoch [34/50] batch [320/428] time 0.098 (0.078) data 0.001 (0.002) loss 2.0891 (2.3217) teacher_loss 0.5651 (0.7982) loss_zs_kd 1.8419 (1.8964) loss_oracle 1.0202 (1.0153) acc 84.3750 (71.6602) lr 5.7422e-04 eta 0:09:00
epoch [34/50] batch [340/428] time 0.083 (0.078) data 0.000 (0.002) loss 2.5007 (2.3220) teacher_loss 1.0114 (0.7988) loss_zs_kd 1.9215 (1.9021) loss_oracle 0.9988 (1.0155) acc 65.6250 (71.7923) lr 5.7422e-04 eta 0:09:01
epoch [34/50] batch [360/428] time 0.081 (0.078) data 0.000 (0.002) loss 2.2804 (2.3212) teacher_loss 0.7069 (0.7983) loss_zs_kd 1.7987 (1.9028) loss_oracle 1.0742 (1.0152) acc 75.0000 (71.7535) lr 5.7422e-04 eta 0:09:02
epoch [34/50] batch [380/428] time 0.068 (0.078) data 0.001 (0.002) loss 2.2173 (2.3216) teacher_loss 0.6631 (0.7995) loss_zs_kd 1.8927 (1.8990) loss_oracle 1.0131 (1.0148) acc 71.8750 (71.7188) lr 5.7422e-04 eta 0:09:00
epoch [34/50] batch [400/428] time 0.079 (0.078) data 0.000 (0.002) loss 2.3604 (2.3210) teacher_loss 0.8486 (0.7991) loss_zs_kd 1.7527 (1.8885) loss_oracle 1.0088 (1.0146) acc 78.1250 (71.8516) lr 5.7422e-04 eta 0:08:54
epoch [34/50] batch [420/428] time 0.076 (0.077) data 0.000 (0.001) loss 2.1497 (2.3201) teacher_loss 0.7175 (0.7993) loss_zs_kd 1.6099 (1.8886) loss_oracle 0.9948 (1.0148) acc 75.0000 (71.8378) lr 5.7422e-04 eta 0:08:48
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,728
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 49.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,143
* accuracy: 45.2%
* error: 54.8%
* macro_f1: 31.8%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [35/50] batch [20/428] time 0.078 (0.118) data 0.000 (0.035) loss 2.1830 (2.3703) teacher_loss 0.6468 (0.8483) loss_zs_kd 1.5456 (1.9269) loss_oracle 1.0452 (1.0214) acc 81.2500 (69.0625) lr 5.1825e-04 eta 0:13:28
epoch [35/50] batch [40/428] time 0.082 (0.101) data 0.000 (0.017) loss 2.2982 (2.3504) teacher_loss 0.7034 (0.8234) loss_zs_kd 1.8642 (1.8516) loss_oracle 1.0680 (1.0169) acc 68.7500 (70.8594) lr 5.1825e-04 eta 0:11:28
epoch [35/50] batch [60/428] time 0.071 (0.095) data 0.000 (0.012) loss 2.1596 (2.3135) teacher_loss 0.6441 (0.7902) loss_zs_kd 1.8804 (1.8676) loss_oracle 0.9775 (1.0132) acc 78.1250 (72.6562) lr 5.1825e-04 eta 0:10:42
epoch [35/50] batch [80/428] time 0.078 (0.091) data 0.000 (0.009) loss 2.2958 (2.3097) teacher_loss 0.8086 (0.7855) loss_zs_kd 2.2753 (1.8901) loss_oracle 1.0387 (1.0113) acc 75.0000 (72.8906) lr 5.1825e-04 eta 0:10:15
epoch [35/50] batch [100/428] time 0.082 (0.090) data 0.000 (0.007) loss 2.2905 (2.3085) teacher_loss 0.7472 (0.7826) loss_zs_kd 1.5815 (1.8910) loss_oracle 1.0743 (1.0125) acc 68.7500 (72.6250) lr 5.1825e-04 eta 0:10:05
epoch [35/50] batch [120/428] time 0.085 (0.089) data 0.000 (0.006) loss 2.8793 (2.2925) teacher_loss 1.3076 (0.7642) loss_zs_kd 2.2680 (1.8910) loss_oracle 0.9856 (1.0155) acc 62.5000 (73.4375) lr 5.1825e-04 eta 0:09:58
epoch [35/50] batch [140/428] time 0.076 (0.088) data 0.000 (0.005) loss 2.0349 (2.2997) teacher_loss 0.5520 (0.7727) loss_zs_kd 1.6105 (1.8895) loss_oracle 1.0226 (1.0149) acc 84.3750 (73.1250) lr 5.1825e-04 eta 0:09:50
epoch [35/50] batch [160/428] time 0.067 (0.087) data 0.000 (0.005) loss 2.4302 (2.3080) teacher_loss 0.8599 (0.7806) loss_zs_kd 1.6577 (1.8715) loss_oracle 1.0516 (1.0173) acc 75.0000 (72.6953) lr 5.1825e-04 eta 0:09:41
epoch [35/50] batch [180/428] time 0.077 (0.087) data 0.000 (0.004) loss 2.3953 (2.3108) teacher_loss 0.8855 (0.7857) loss_zs_kd 2.1643 (1.8591) loss_oracle 0.9984 (1.0163) acc 62.5000 (72.4306) lr 5.1825e-04 eta 0:09:39
epoch [35/50] batch [200/428] time 0.078 (0.086) data 0.000 (0.004) loss 2.3072 (2.3189) teacher_loss 0.7302 (0.7937) loss_zs_kd 1.7850 (1.8650) loss_oracle 0.9999 (1.0163) acc 71.8750 (72.1406) lr 5.1825e-04 eta 0:09:34
epoch [35/50] batch [220/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.1038 (2.3258) teacher_loss 0.5340 (0.7998) loss_zs_kd 2.0977 (1.8652) loss_oracle 1.0621 (1.0181) acc 84.3750 (71.9886) lr 5.1825e-04 eta 0:09:27
epoch [35/50] batch [240/428] time 0.089 (0.085) data 0.000 (0.003) loss 2.5642 (2.3269) teacher_loss 1.0804 (0.8006) loss_zs_kd 2.0867 (1.8622) loss_oracle 1.0183 (1.0185) acc 56.2500 (72.0312) lr 5.1825e-04 eta 0:09:23
epoch [35/50] batch [260/428] time 0.074 (0.085) data 0.000 (0.003) loss 2.1629 (2.3290) teacher_loss 0.5561 (0.8018) loss_zs_kd 1.9787 (1.8527) loss_oracle 1.0489 (1.0201) acc 81.2500 (72.1154) lr 5.1825e-04 eta 0:09:18
epoch [35/50] batch [280/428] time 0.090 (0.084) data 0.000 (0.003) loss 2.1063 (2.3251) teacher_loss 0.5948 (0.7976) loss_zs_kd 1.8572 (1.8547) loss_oracle 1.0143 (1.0212) acc 81.2500 (72.2768) lr 5.1825e-04 eta 0:09:12
epoch [35/50] batch [300/428] time 0.071 (0.084) data 0.000 (0.003) loss 2.1404 (2.3288) teacher_loss 0.6189 (0.8016) loss_zs_kd 1.8100 (1.8574) loss_oracle 1.0045 (1.0218) acc 84.3750 (72.1562) lr 5.1825e-04 eta 0:09:10
epoch [35/50] batch [320/428] time 0.073 (0.084) data 0.000 (0.002) loss 2.3284 (2.3302) teacher_loss 0.8505 (0.8039) loss_zs_kd 1.5993 (1.8620) loss_oracle 0.9876 (1.0211) acc 71.8750 (71.9922) lr 5.1825e-04 eta 0:09:07
epoch [35/50] batch [340/428] time 0.084 (0.084) data 0.000 (0.002) loss 2.3301 (2.3319) teacher_loss 0.8317 (0.8052) loss_zs_kd 1.8354 (1.8501) loss_oracle 1.0066 (1.0211) acc 65.6250 (71.8566) lr 5.1825e-04 eta 0:09:03
epoch [35/50] batch [360/428] time 0.081 (0.083) data 0.000 (0.002) loss 2.6003 (2.3349) teacher_loss 1.0459 (0.8073) loss_zs_kd 2.0786 (1.8473) loss_oracle 1.0436 (1.0218) acc 56.2500 (71.6146) lr 5.1825e-04 eta 0:09:00
epoch [35/50] batch [380/428] time 0.087 (0.083) data 0.000 (0.002) loss 2.2803 (2.3319) teacher_loss 0.7124 (0.8038) loss_zs_kd 1.8847 (1.8424) loss_oracle 1.0220 (1.0221) acc 78.1250 (71.7516) lr 5.1825e-04 eta 0:08:58
epoch [35/50] batch [400/428] time 0.075 (0.083) data 0.000 (0.002) loss 2.2617 (2.3309) teacher_loss 0.7440 (0.8022) loss_zs_kd 1.8686 (1.8440) loss_oracle 0.9812 (1.0226) acc 75.0000 (71.8047) lr 5.1825e-04 eta 0:08:56
epoch [35/50] batch [420/428] time 0.071 (0.083) data 0.000 (0.002) loss 2.3620 (2.3349) teacher_loss 0.8297 (0.8069) loss_zs_kd 1.8548 (1.8429) loss_oracle 1.0576 (1.0230) acc 71.8750 (71.5551) lr 5.1825e-04 eta 0:08:52
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,746
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 49.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,109
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.3%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [36/50] batch [20/428] time 0.079 (0.120) data 0.000 (0.032) loss 2.3994 (2.3596) teacher_loss 0.8286 (0.8348) loss_zs_kd 1.7855 (1.8164) loss_oracle 1.0713 (1.0285) acc 81.2500 (70.4688) lr 4.6417e-04 eta 0:12:50
epoch [36/50] batch [40/428] time 0.082 (0.100) data 0.000 (0.016) loss 2.1107 (2.3507) teacher_loss 0.5419 (0.8351) loss_zs_kd 1.6181 (1.8054) loss_oracle 0.9956 (1.0221) acc 87.5000 (70.8594) lr 4.6417e-04 eta 0:10:41
epoch [36/50] batch [60/428] time 0.082 (0.093) data 0.001 (0.011) loss 2.5102 (2.3486) teacher_loss 0.9664 (0.8365) loss_zs_kd 1.7599 (1.7747) loss_oracle 1.0359 (1.0219) acc 65.6250 (70.2604) lr 4.6417e-04 eta 0:09:53
epoch [36/50] batch [80/428] time 0.082 (0.091) data 0.000 (0.008) loss 2.3754 (2.3325) teacher_loss 0.8544 (0.8176) loss_zs_kd 2.3696 (1.7729) loss_oracle 1.0419 (1.0238) acc 65.6250 (70.7422) lr 4.6417e-04 eta 0:09:36
epoch [36/50] batch [100/428] time 0.084 (0.090) data 0.000 (0.007) loss 2.4433 (2.3275) teacher_loss 0.8839 (0.8097) loss_zs_kd 1.7421 (1.7703) loss_oracle 1.0178 (1.0244) acc 65.6250 (71.1875) lr 4.6417e-04 eta 0:09:26
epoch [36/50] batch [120/428] time 0.084 (0.088) data 0.000 (0.006) loss 2.4697 (2.3324) teacher_loss 0.9428 (0.8139) loss_zs_kd 1.8813 (1.7690) loss_oracle 1.0301 (1.0242) acc 62.5000 (70.9896) lr 4.6417e-04 eta 0:09:16
epoch [36/50] batch [140/428] time 0.083 (0.087) data 0.000 (0.005) loss 2.5820 (2.3320) teacher_loss 1.0831 (0.8157) loss_zs_kd 2.0282 (1.7720) loss_oracle 0.9824 (1.0214) acc 59.3750 (70.9375) lr 4.6417e-04 eta 0:09:09
epoch [36/50] batch [160/428] time 0.088 (0.087) data 0.000 (0.004) loss 1.9653 (2.3235) teacher_loss 0.4508 (0.8072) loss_zs_kd 2.2258 (1.7797) loss_oracle 0.9850 (1.0199) acc 84.3750 (71.3477) lr 4.6417e-04 eta 0:09:06
epoch [36/50] batch [180/428] time 0.087 (0.087) data 0.000 (0.004) loss 2.1298 (2.3235) teacher_loss 0.5770 (0.8078) loss_zs_kd 1.7478 (1.7788) loss_oracle 1.0745 (1.0189) acc 71.8750 (71.3715) lr 4.6417e-04 eta 0:09:03
epoch [36/50] batch [200/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.2524 (2.3242) teacher_loss 0.7032 (0.8069) loss_zs_kd 1.7513 (1.7839) loss_oracle 1.0736 (1.0208) acc 81.2500 (71.5781) lr 4.6417e-04 eta 0:08:59
epoch [36/50] batch [220/428] time 0.087 (0.087) data 0.000 (0.003) loss 2.6044 (2.3266) teacher_loss 1.0343 (0.8086) loss_zs_kd 1.9438 (1.7818) loss_oracle 1.0255 (1.0195) acc 59.3750 (71.4205) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [240/428] time 0.086 (0.087) data 0.000 (0.003) loss 2.2558 (2.3312) teacher_loss 0.7896 (0.8123) loss_zs_kd 1.6974 (1.7886) loss_oracle 1.0083 (1.0206) acc 87.5000 (71.3542) lr 4.6417e-04 eta 0:08:54
epoch [36/50] batch [260/428] time 0.083 (0.086) data 0.000 (0.003) loss 2.3078 (2.3313) teacher_loss 0.7698 (0.8119) loss_zs_kd 2.0066 (1.7969) loss_oracle 1.0352 (1.0211) acc 71.8750 (71.4423) lr 4.6417e-04 eta 0:08:51
epoch [36/50] batch [280/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.3802 (2.3274) teacher_loss 0.8570 (0.8076) loss_zs_kd 1.5506 (1.8064) loss_oracle 1.0470 (1.0221) acc 75.0000 (71.6518) lr 4.6417e-04 eta 0:08:50
epoch [36/50] batch [300/428] time 0.093 (0.086) data 0.001 (0.002) loss 2.4162 (2.3307) teacher_loss 0.9361 (0.8115) loss_zs_kd 1.6992 (1.8105) loss_oracle 0.9984 (1.0226) acc 75.0000 (71.6458) lr 4.6417e-04 eta 0:08:47
epoch [36/50] batch [320/428] time 0.158 (0.087) data 0.000 (0.002) loss 2.1329 (2.3338) teacher_loss 0.6530 (0.8150) loss_zs_kd 2.0712 (1.8124) loss_oracle 1.0284 (1.0227) acc 78.1250 (71.5723) lr 4.6417e-04 eta 0:08:48
epoch [36/50] batch [340/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.2574 (2.3354) teacher_loss 0.8070 (0.8168) loss_zs_kd 2.1928 (1.8140) loss_oracle 0.9867 (1.0229) acc 65.6250 (71.4522) lr 4.6417e-04 eta 0:08:45
epoch [36/50] batch [360/428] time 0.093 (0.086) data 0.000 (0.002) loss 2.4459 (2.3387) teacher_loss 0.9442 (0.8203) loss_zs_kd 1.7254 (1.8141) loss_oracle 1.0304 (1.0234) acc 68.7500 (71.3455) lr 4.6417e-04 eta 0:08:43
epoch [36/50] batch [380/428] time 0.081 (0.086) data 0.001 (0.002) loss 2.7432 (2.3425) teacher_loss 1.2337 (0.8251) loss_zs_kd 1.5110 (1.8091) loss_oracle 1.0281 (1.0229) acc 62.5000 (71.1266) lr 4.6417e-04 eta 0:08:39
epoch [36/50] batch [400/428] time 0.089 (0.086) data 0.000 (0.002) loss 2.4254 (2.3419) teacher_loss 0.9014 (0.8243) loss_zs_kd 1.7584 (1.8021) loss_oracle 1.0473 (1.0227) acc 65.6250 (71.0547) lr 4.6417e-04 eta 0:08:37
epoch [36/50] batch [420/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.3801 (2.3441) teacher_loss 0.8716 (0.8260) loss_zs_kd 2.2306 (1.8016) loss_oracle 1.0136 (1.0232) acc 65.6250 (70.9226) lr 4.6417e-04 eta 0:08:34
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,715
* accuracy: 63.2%
* error: 36.8%
* macro_f1: 50.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,303
* accuracy: 48.6%
* error: 51.4%
* macro_f1: 32.1%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [37/50] batch [20/428] time 0.073 (0.119) data 0.000 (0.033) loss 2.1681 (2.2615) teacher_loss 0.5681 (0.7419) loss_zs_kd 2.0002 (1.8125) loss_oracle 1.0063 (1.0106) acc 81.2500 (73.1250) lr 4.1221e-04 eta 0:11:51
epoch [37/50] batch [40/428] time 0.087 (0.102) data 0.000 (0.017) loss 2.4811 (2.3412) teacher_loss 0.9464 (0.8252) loss_zs_kd 1.5720 (1.8464) loss_oracle 0.9994 (1.0081) acc 65.6250 (70.4688) lr 4.1221e-04 eta 0:10:04
epoch [37/50] batch [60/428] time 0.078 (0.097) data 0.000 (0.011) loss 2.1967 (2.3427) teacher_loss 0.7392 (0.8303) loss_zs_kd 2.2586 (1.8527) loss_oracle 0.9520 (1.0038) acc 71.8750 (70.6250) lr 4.1221e-04 eta 0:09:36
epoch [37/50] batch [80/428] time 0.083 (0.094) data 0.000 (0.009) loss 2.8294 (2.3392) teacher_loss 1.3959 (0.8287) loss_zs_kd 2.4600 (1.8785) loss_oracle 1.0277 (1.0050) acc 59.3750 (71.0547) lr 4.1221e-04 eta 0:09:13
epoch [37/50] batch [100/428] time 0.088 (0.092) data 0.000 (0.007) loss 2.2959 (2.3371) teacher_loss 0.7924 (0.8228) loss_zs_kd 2.0213 (1.8829) loss_oracle 0.9510 (1.0097) acc 75.0000 (71.5000) lr 4.1221e-04 eta 0:09:00
epoch [37/50] batch [120/428] time 0.079 (0.090) data 0.000 (0.006) loss 2.5777 (2.3413) teacher_loss 1.0093 (0.8267) loss_zs_kd 2.4753 (1.8683) loss_oracle 1.0301 (1.0108) acc 65.6250 (71.2760) lr 4.1221e-04 eta 0:08:46
epoch [37/50] batch [140/428] time 0.077 (0.089) data 0.000 (0.005) loss 2.5160 (2.3464) teacher_loss 1.0009 (0.8277) loss_zs_kd 2.0120 (1.8601) loss_oracle 1.0665 (1.0124) acc 62.5000 (70.9821) lr 4.1221e-04 eta 0:08:38
epoch [37/50] batch [160/428] time 0.079 (0.088) data 0.000 (0.004) loss 2.2277 (2.3379) teacher_loss 0.7482 (0.8175) loss_zs_kd 1.5154 (1.8573) loss_oracle 1.0067 (1.0144) acc 71.8750 (71.4648) lr 4.1221e-04 eta 0:08:32
epoch [37/50] batch [180/428] time 0.088 (0.087) data 0.000 (0.004) loss 2.6977 (2.3360) teacher_loss 1.1767 (0.8170) loss_zs_kd 2.1481 (1.8635) loss_oracle 0.9718 (1.0142) acc 50.0000 (71.3889) lr 4.1221e-04 eta 0:08:26
epoch [37/50] batch [200/428] time 0.080 (0.087) data 0.000 (0.004) loss 2.1754 (2.3365) teacher_loss 0.6202 (0.8187) loss_zs_kd 1.8247 (1.8694) loss_oracle 1.0339 (1.0140) acc 78.1250 (71.2969) lr 4.1221e-04 eta 0:08:22
epoch [37/50] batch [220/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.4022 (2.3353) teacher_loss 0.8807 (0.8165) loss_zs_kd 2.1299 (1.8671) loss_oracle 1.0284 (1.0151) acc 65.6250 (71.5341) lr 4.1221e-04 eta 0:08:19
epoch [37/50] batch [240/428] time 0.081 (0.086) data 0.000 (0.003) loss 2.1598 (2.3310) teacher_loss 0.6588 (0.8132) loss_zs_kd 1.6889 (1.8596) loss_oracle 1.0097 (1.0150) acc 75.0000 (71.7578) lr 4.1221e-04 eta 0:08:15
epoch [37/50] batch [260/428] time 0.083 (0.086) data 0.000 (0.003) loss 2.3837 (2.3274) teacher_loss 0.7987 (0.8081) loss_zs_kd 1.4113 (1.8526) loss_oracle 1.0424 (1.0157) acc 71.8750 (71.8990) lr 4.1221e-04 eta 0:08:12
epoch [37/50] batch [280/428] time 0.079 (0.086) data 0.000 (0.003) loss 2.0482 (2.3248) teacher_loss 0.4943 (0.8051) loss_zs_kd 2.1595 (1.8606) loss_oracle 1.0129 (1.0167) acc 84.3750 (72.0312) lr 4.1221e-04 eta 0:08:09
epoch [37/50] batch [300/428] time 0.080 (0.086) data 0.000 (0.002) loss 2.3218 (2.3263) teacher_loss 0.8001 (0.8062) loss_zs_kd 1.8591 (1.8608) loss_oracle 1.0486 (1.0177) acc 71.8750 (71.9167) lr 4.1221e-04 eta 0:08:07
epoch [37/50] batch [320/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.3934 (2.3261) teacher_loss 0.9323 (0.8067) loss_zs_kd 1.6942 (1.8645) loss_oracle 1.0017 (1.0178) acc 75.0000 (71.9434) lr 4.1221e-04 eta 0:08:05
epoch [37/50] batch [340/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.8795 (2.3291) teacher_loss 0.3888 (0.8090) loss_zs_kd 2.0287 (1.8638) loss_oracle 0.9729 (1.0176) acc 87.5000 (71.8382) lr 4.1221e-04 eta 0:08:03
epoch [37/50] batch [360/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.4353 (2.3290) teacher_loss 0.9658 (0.8087) loss_zs_kd 1.8745 (1.8641) loss_oracle 1.0096 (1.0178) acc 68.7500 (71.8837) lr 4.1221e-04 eta 0:08:02
epoch [37/50] batch [380/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.2401 (2.3336) teacher_loss 0.8128 (0.8141) loss_zs_kd 1.7727 (1.8613) loss_oracle 1.0157 (1.0181) acc 71.8750 (71.6694) lr 4.1221e-04 eta 0:07:59
epoch [37/50] batch [400/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.2159 (2.3262) teacher_loss 0.6614 (0.8072) loss_zs_kd 1.5712 (1.8584) loss_oracle 0.9907 (1.0177) acc 75.0000 (71.9453) lr 4.1221e-04 eta 0:07:57
epoch [37/50] batch [420/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.4535 (2.3274) teacher_loss 0.8984 (0.8080) loss_zs_kd 1.8536 (1.8567) loss_oracle 1.0214 (1.0184) acc 68.7500 (72.0238) lr 4.1221e-04 eta 0:07:55
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,768
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 49.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,216
* accuracy: 46.7%
* error: 53.3%
* macro_f1: 31.2%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [38/50] batch [20/428] time 0.076 (0.108) data 0.000 (0.024) loss 2.4185 (2.2874) teacher_loss 0.9119 (0.7753) loss_zs_kd 1.5162 (1.7505) loss_oracle 1.0147 (1.0288) acc 71.8750 (72.6562) lr 3.6258e-04 eta 0:09:59
epoch [38/50] batch [40/428] time 0.084 (0.094) data 0.000 (0.012) loss 2.2743 (2.2869) teacher_loss 0.7514 (0.7755) loss_zs_kd 1.8239 (1.8101) loss_oracle 0.9975 (1.0215) acc 65.6250 (72.5000) lr 3.6258e-04 eta 0:08:39
epoch [38/50] batch [60/428] time 0.078 (0.088) data 0.000 (0.008) loss 2.6342 (2.2921) teacher_loss 1.1676 (0.7798) loss_zs_kd 1.8948 (1.8138) loss_oracle 0.9560 (1.0186) acc 65.6250 (72.4479) lr 3.6258e-04 eta 0:08:06
epoch [38/50] batch [80/428] time 0.080 (0.086) data 0.000 (0.006) loss 2.7720 (2.3025) teacher_loss 1.3380 (0.7888) loss_zs_kd 1.7437 (1.8267) loss_oracle 0.9778 (1.0175) acc 53.1250 (71.6406) lr 3.6258e-04 eta 0:07:51
epoch [38/50] batch [100/428] time 0.075 (0.085) data 0.000 (0.005) loss 1.9662 (2.3023) teacher_loss 0.4268 (0.7882) loss_zs_kd 1.9353 (1.8322) loss_oracle 1.0214 (1.0172) acc 84.3750 (71.9688) lr 3.6258e-04 eta 0:07:41
epoch [38/50] batch [120/428] time 0.081 (0.084) data 0.000 (0.004) loss 2.1749 (2.2947) teacher_loss 0.7434 (0.7847) loss_zs_kd 1.5154 (1.8573) loss_oracle 0.9371 (1.0149) acc 75.0000 (72.3958) lr 3.6258e-04 eta 0:07:35
epoch [38/50] batch [140/428] time 0.083 (0.084) data 0.000 (0.004) loss 2.1214 (2.2991) teacher_loss 0.6091 (0.7903) loss_zs_kd 2.0556 (1.8739) loss_oracle 1.0166 (1.0143) acc 81.2500 (72.3438) lr 3.6258e-04 eta 0:07:33
epoch [38/50] batch [160/428] time 0.087 (0.083) data 0.000 (0.003) loss 2.2062 (2.3041) teacher_loss 0.6678 (0.7961) loss_zs_kd 2.1327 (1.8758) loss_oracle 1.0473 (1.0132) acc 75.0000 (71.9922) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [180/428] time 0.123 (0.084) data 0.001 (0.003) loss 2.2576 (2.3038) teacher_loss 0.6727 (0.7959) loss_zs_kd 1.8843 (1.8704) loss_oracle 1.0521 (1.0122) acc 71.8750 (72.0660) lr 3.6258e-04 eta 0:07:30
epoch [38/50] batch [200/428] time 0.079 (0.084) data 0.000 (0.003) loss 2.3518 (2.3153) teacher_loss 0.8581 (0.8083) loss_zs_kd 1.6247 (1.8684) loss_oracle 0.9763 (1.0104) acc 68.7500 (71.7188) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [220/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.3955 (2.3112) teacher_loss 0.8255 (0.8045) loss_zs_kd 1.8933 (1.8692) loss_oracle 1.0344 (1.0088) acc 78.1250 (71.9176) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [240/428] time 0.073 (0.084) data 0.000 (0.002) loss 2.2530 (2.3117) teacher_loss 0.7307 (0.8053) loss_zs_kd 1.6850 (1.8707) loss_oracle 0.9756 (1.0079) acc 75.0000 (71.8750) lr 3.6258e-04 eta 0:07:25
epoch [38/50] batch [260/428] time 0.084 (0.083) data 0.000 (0.002) loss 2.1614 (2.3091) teacher_loss 0.6280 (0.8020) loss_zs_kd 2.2774 (1.8699) loss_oracle 1.0079 (1.0074) acc 78.1250 (71.7909) lr 3.6258e-04 eta 0:07:19
epoch [38/50] batch [280/428] time 0.076 (0.083) data 0.000 (0.002) loss 2.2462 (2.3112) teacher_loss 0.7607 (0.8031) loss_zs_kd 2.0612 (1.8710) loss_oracle 0.9746 (1.0082) acc 78.1250 (71.7522) lr 3.6258e-04 eta 0:07:16
epoch [38/50] batch [300/428] time 0.079 (0.083) data 0.000 (0.002) loss 2.0815 (2.3135) teacher_loss 0.4968 (0.8053) loss_zs_kd 1.8910 (1.8709) loss_oracle 1.0488 (1.0080) acc 93.7500 (71.6875) lr 3.6258e-04 eta 0:07:14
epoch [38/50] batch [320/428] time 0.074 (0.082) data 0.000 (0.002) loss 2.3729 (2.3128) teacher_loss 0.8407 (0.8037) loss_zs_kd 1.8223 (1.8715) loss_oracle 1.0048 (1.0084) acc 65.6250 (71.7969) lr 3.6258e-04 eta 0:07:11
epoch [38/50] batch [340/428] time 0.080 (0.082) data 0.000 (0.002) loss 2.5404 (2.3157) teacher_loss 1.0529 (0.8075) loss_zs_kd 1.5655 (1.8671) loss_oracle 1.0217 (1.0085) acc 59.3750 (71.7555) lr 3.6258e-04 eta 0:07:10
epoch [38/50] batch [360/428] time 0.074 (0.082) data 0.000 (0.002) loss 2.0324 (2.3193) teacher_loss 0.5289 (0.8109) loss_zs_kd 1.6846 (1.8702) loss_oracle 0.9866 (1.0086) acc 84.3750 (71.7014) lr 3.6258e-04 eta 0:07:08
epoch [38/50] batch [380/428] time 0.081 (0.082) data 0.000 (0.002) loss 2.5965 (2.3215) teacher_loss 1.1401 (0.8126) loss_zs_kd 1.7517 (1.8717) loss_oracle 1.0199 (1.0089) acc 53.1250 (71.5954) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [400/428] time 0.075 (0.082) data 0.000 (0.001) loss 2.1741 (2.3268) teacher_loss 0.5836 (0.8174) loss_zs_kd 1.8911 (1.8732) loss_oracle 1.0319 (1.0083) acc 90.6250 (71.5000) lr 3.6258e-04 eta 0:07:05
epoch [38/50] batch [420/428] time 0.087 (0.082) data 0.001 (0.001) loss 1.9796 (2.3238) teacher_loss 0.4664 (0.8147) loss_zs_kd 1.7036 (1.8695) loss_oracle 1.0388 (1.0078) acc 87.5000 (71.6369) lr 3.6258e-04 eta 0:07:02
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,807
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,159
* accuracy: 45.5%
* error: 54.5%
* macro_f1: 31.9%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [39/50] batch [20/428] time 0.071 (0.116) data 0.000 (0.030) loss 2.3043 (2.3127) teacher_loss 0.7409 (0.8006) loss_zs_kd 1.9954 (1.7967) loss_oracle 1.0042 (0.9938) acc 68.7500 (70.1562) lr 3.1545e-04 eta 0:09:54
epoch [39/50] batch [40/428] time 0.087 (0.099) data 0.000 (0.015) loss 2.3987 (2.3397) teacher_loss 0.8547 (0.8271) loss_zs_kd 1.6573 (1.8097) loss_oracle 1.0114 (0.9993) acc 75.0000 (70.3125) lr 3.1545e-04 eta 0:08:25
epoch [39/50] batch [60/428] time 0.077 (0.094) data 0.000 (0.010) loss 2.5211 (2.3402) teacher_loss 0.9891 (0.8233) loss_zs_kd 1.8406 (1.8267) loss_oracle 1.0095 (1.0031) acc 71.8750 (69.8438) lr 3.1545e-04 eta 0:07:55
epoch [39/50] batch [80/428] time 0.081 (0.090) data 0.000 (0.008) loss 2.5985 (2.3472) teacher_loss 1.0743 (0.8286) loss_zs_kd 2.0289 (1.8430) loss_oracle 0.9687 (1.0046) acc 59.3750 (69.8047) lr 3.1545e-04 eta 0:07:35
epoch [39/50] batch [100/428] time 0.074 (0.088) data 0.000 (0.006) loss 2.0815 (2.3447) teacher_loss 0.6197 (0.8289) loss_zs_kd 1.8195 (1.8283) loss_oracle 0.9628 (1.0067) acc 75.0000 (69.9688) lr 3.1545e-04 eta 0:07:23
epoch [39/50] batch [120/428] time 0.081 (0.087) data 0.000 (0.005) loss 2.4718 (2.3532) teacher_loss 0.9505 (0.8352) loss_zs_kd 1.5405 (1.8182) loss_oracle 0.9833 (1.0079) acc 65.6250 (69.8958) lr 3.1545e-04 eta 0:07:17
epoch [39/50] batch [140/428] time 0.079 (0.086) data 0.000 (0.005) loss 2.3283 (2.3501) teacher_loss 0.7951 (0.8332) loss_zs_kd 1.8608 (1.8184) loss_oracle 1.0673 (1.0087) acc 71.8750 (70.2232) lr 3.1545e-04 eta 0:07:09
epoch [39/50] batch [160/428] time 0.091 (0.086) data 0.000 (0.004) loss 2.3603 (2.3415) teacher_loss 0.8629 (0.8257) loss_zs_kd 1.6035 (1.8254) loss_oracle 1.0103 (1.0070) acc 71.8750 (70.3711) lr 3.1545e-04 eta 0:07:05
epoch [39/50] batch [180/428] time 0.085 (0.085) data 0.000 (0.004) loss 2.0566 (2.3378) teacher_loss 0.5326 (0.8226) loss_zs_kd 1.7055 (1.8236) loss_oracle 1.0320 (1.0081) acc 84.3750 (70.5208) lr 3.1545e-04 eta 0:07:03
epoch [39/50] batch [200/428] time 0.082 (0.085) data 0.000 (0.003) loss 2.4949 (2.3342) teacher_loss 0.9474 (0.8199) loss_zs_kd 1.9525 (1.8345) loss_oracle 0.9805 (1.0077) acc 65.6250 (70.7344) lr 3.1545e-04 eta 0:06:59
epoch [39/50] batch [220/428] time 0.078 (0.085) data 0.000 (0.003) loss 2.2357 (2.3377) teacher_loss 0.6855 (0.8231) loss_zs_kd 1.8423 (1.8325) loss_oracle 1.0149 (1.0078) acc 78.1250 (70.6108) lr 3.1545e-04 eta 0:06:57
epoch [39/50] batch [240/428] time 0.082 (0.085) data 0.000 (0.003) loss 2.6637 (2.3380) teacher_loss 1.1114 (0.8233) loss_zs_kd 1.8838 (1.8321) loss_oracle 1.0448 (1.0085) acc 68.7500 (70.5729) lr 3.1545e-04 eta 0:06:54
epoch [39/50] batch [260/428] time 0.094 (0.085) data 0.000 (0.003) loss 2.3441 (2.3337) teacher_loss 0.8233 (0.8195) loss_zs_kd 1.8069 (1.8318) loss_oracle 1.0302 (1.0088) acc 65.6250 (70.7212) lr 3.1545e-04 eta 0:06:53
epoch [39/50] batch [280/428] time 0.084 (0.085) data 0.000 (0.002) loss 2.2960 (2.3311) teacher_loss 0.8174 (0.8177) loss_zs_kd 1.9241 (1.8313) loss_oracle 0.9019 (1.0091) acc 71.8750 (70.8371) lr 3.1545e-04 eta 0:06:51
epoch [39/50] batch [300/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.3666 (2.3355) teacher_loss 0.8363 (0.8217) loss_zs_kd 1.6226 (1.8252) loss_oracle 0.9882 (1.0094) acc 68.7500 (70.7604) lr 3.1545e-04 eta 0:06:49
epoch [39/50] batch [320/428] time 0.150 (0.085) data 0.001 (0.002) loss 2.1904 (2.3331) teacher_loss 0.6431 (0.8189) loss_zs_kd 1.4652 (1.8252) loss_oracle 1.0127 (1.0100) acc 78.1250 (71.0156) lr 3.1545e-04 eta 0:06:51
epoch [39/50] batch [340/428] time 0.085 (0.085) data 0.000 (0.002) loss 2.4114 (2.3337) teacher_loss 0.8649 (0.8185) loss_zs_kd 2.3796 (1.8288) loss_oracle 1.0318 (1.0100) acc 62.5000 (70.9743) lr 3.1545e-04 eta 0:06:46
epoch [39/50] batch [360/428] time 0.086 (0.085) data 0.000 (0.002) loss 2.2595 (2.3294) teacher_loss 0.7418 (0.8140) loss_zs_kd 1.9663 (1.8343) loss_oracle 1.0007 (1.0111) acc 78.1250 (71.2587) lr 3.1545e-04 eta 0:06:45
epoch [39/50] batch [380/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.5209 (2.3304) teacher_loss 1.0398 (0.8147) loss_zs_kd 2.0173 (1.8333) loss_oracle 0.9897 (1.0118) acc 68.7500 (71.3898) lr 3.1545e-04 eta 0:06:43
epoch [39/50] batch [400/428] time 0.076 (0.085) data 0.000 (0.002) loss 2.4848 (2.3321) teacher_loss 0.9758 (0.8162) loss_zs_kd 1.7804 (1.8356) loss_oracle 1.0061 (1.0125) acc 62.5000 (71.4375) lr 3.1545e-04 eta 0:06:40
epoch [39/50] batch [420/428] time 0.075 (0.084) data 0.000 (0.002) loss 2.7714 (2.3334) teacher_loss 1.2898 (0.8176) loss_zs_kd 1.9082 (1.8328) loss_oracle 0.9577 (1.0128) acc 53.1250 (71.3318) lr 3.1545e-04 eta 0:06:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,804
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 51.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,143
* accuracy: 45.2%
* error: 54.8%
* macro_f1: 31.4%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [40/50] batch [20/428] time 0.085 (0.122) data 0.000 (0.034) loss 2.3931 (2.2691) teacher_loss 0.8980 (0.7627) loss_zs_kd 1.6265 (1.8693) loss_oracle 1.0393 (1.0166) acc 75.0000 (74.2188) lr 2.7103e-04 eta 0:09:32
epoch [40/50] batch [40/428] time 0.074 (0.103) data 0.000 (0.017) loss 2.5087 (2.2578) teacher_loss 0.9800 (0.7490) loss_zs_kd 1.5430 (1.9179) loss_oracle 1.0234 (1.0099) acc 65.6250 (74.2188) lr 2.7103e-04 eta 0:08:00
epoch [40/50] batch [60/428] time 0.088 (0.100) data 0.000 (0.012) loss 2.4419 (2.2685) teacher_loss 0.9448 (0.7565) loss_zs_kd 1.4237 (1.9026) loss_oracle 1.0103 (1.0136) acc 65.6250 (73.1771) lr 2.7103e-04 eta 0:07:45
epoch [40/50] batch [80/428] time 0.082 (0.094) data 0.000 (0.009) loss 2.2977 (2.2830) teacher_loss 0.7757 (0.7730) loss_zs_kd 2.1456 (1.9155) loss_oracle 1.0177 (1.0161) acc 65.6250 (72.8125) lr 2.7103e-04 eta 0:07:15
epoch [40/50] batch [100/428] time 0.086 (0.091) data 0.000 (0.007) loss 2.2229 (2.2804) teacher_loss 0.6931 (0.7683) loss_zs_kd 1.6521 (1.9078) loss_oracle 1.0488 (1.0178) acc 71.8750 (72.7812) lr 2.7103e-04 eta 0:07:01
epoch [40/50] batch [120/428] time 0.086 (0.090) data 0.000 (0.006) loss 2.3999 (2.2889) teacher_loss 0.9152 (0.7770) loss_zs_kd 1.7669 (1.9051) loss_oracle 1.0510 (1.0185) acc 68.7500 (72.5521) lr 2.7103e-04 eta 0:06:54
epoch [40/50] batch [140/428] time 0.078 (0.090) data 0.000 (0.005) loss 2.1562 (2.2898) teacher_loss 0.6598 (0.7792) loss_zs_kd 1.8233 (1.8965) loss_oracle 1.0420 (1.0186) acc 71.8750 (72.5670) lr 2.7103e-04 eta 0:06:49
epoch [40/50] batch [160/428] time 0.083 (0.089) data 0.000 (0.005) loss 2.8025 (2.2994) teacher_loss 1.3180 (0.7884) loss_zs_kd 2.0530 (1.8917) loss_oracle 0.9986 (1.0186) acc 50.0000 (72.1484) lr 2.7103e-04 eta 0:06:43
epoch [40/50] batch [180/428] time 0.087 (0.088) data 0.000 (0.004) loss 2.5479 (2.2981) teacher_loss 1.0805 (0.7865) loss_zs_kd 1.8885 (1.8983) loss_oracle 1.0446 (1.0189) acc 65.6250 (72.1528) lr 2.7103e-04 eta 0:06:40
epoch [40/50] batch [200/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.4153 (2.3015) teacher_loss 0.9696 (0.7895) loss_zs_kd 2.1436 (1.9000) loss_oracle 1.0083 (1.0180) acc 68.7500 (71.8438) lr 2.7103e-04 eta 0:06:34
epoch [40/50] batch [220/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.1471 (2.3042) teacher_loss 0.6584 (0.7924) loss_zs_kd 2.0572 (1.9037) loss_oracle 1.0388 (1.0181) acc 81.2500 (71.8182) lr 2.7103e-04 eta 0:06:32
epoch [40/50] batch [240/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.3942 (2.3060) teacher_loss 1.0010 (0.7958) loss_zs_kd 1.5732 (1.9035) loss_oracle 0.9940 (1.0169) acc 62.5000 (71.7448) lr 2.7103e-04 eta 0:06:29
epoch [40/50] batch [260/428] time 0.079 (0.087) data 0.000 (0.003) loss 2.3682 (2.3080) teacher_loss 0.7982 (0.7975) loss_zs_kd 1.5130 (1.9076) loss_oracle 1.0207 (1.0166) acc 71.8750 (71.6947) lr 2.7103e-04 eta 0:06:26
epoch [40/50] batch [280/428] time 0.081 (0.087) data 0.000 (0.003) loss 2.3655 (2.3095) teacher_loss 0.8271 (0.7999) loss_zs_kd 1.9250 (1.9030) loss_oracle 1.0568 (1.0167) acc 71.8750 (71.5737) lr 2.7103e-04 eta 0:06:23
epoch [40/50] batch [300/428] time 0.099 (0.087) data 0.001 (0.003) loss 2.4163 (2.3111) teacher_loss 0.8807 (0.8013) loss_zs_kd 1.8088 (1.8971) loss_oracle 1.0176 (1.0177) acc 71.8750 (71.5938) lr 2.7103e-04 eta 0:06:21
epoch [40/50] batch [320/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.4676 (2.3111) teacher_loss 0.9489 (0.8014) loss_zs_kd 1.6473 (1.8983) loss_oracle 0.9939 (1.0179) acc 68.7500 (71.8066) lr 2.7103e-04 eta 0:06:17
epoch [40/50] batch [340/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.4199 (2.3111) teacher_loss 0.9187 (0.8013) loss_zs_kd 1.8843 (1.8945) loss_oracle 1.0292 (1.0186) acc 71.8750 (71.8474) lr 2.7103e-04 eta 0:06:15
epoch [40/50] batch [360/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.3819 (2.3087) teacher_loss 0.8827 (0.7981) loss_zs_kd 1.9761 (1.9031) loss_oracle 0.9633 (1.0197) acc 65.6250 (71.9618) lr 2.7103e-04 eta 0:06:13
epoch [40/50] batch [380/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.4129 (2.3093) teacher_loss 0.9393 (0.7992) loss_zs_kd 1.7415 (1.9026) loss_oracle 1.0559 (1.0203) acc 65.6250 (71.9655) lr 2.7103e-04 eta 0:06:11
epoch [40/50] batch [400/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.2496 (2.3101) teacher_loss 0.7584 (0.8009) loss_zs_kd 1.8392 (1.9000) loss_oracle 0.9976 (1.0203) acc 78.1250 (71.9531) lr 2.7103e-04 eta 0:06:08
epoch [40/50] batch [420/428] time 0.072 (0.085) data 0.000 (0.002) loss 2.3212 (2.3116) teacher_loss 0.8231 (0.8022) loss_zs_kd 1.8475 (1.8997) loss_oracle 1.0077 (1.0207) acc 71.8750 (71.9196) lr 2.7103e-04 eta 0:06:05
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,109
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.6%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [41/50] batch [20/428] time 0.084 (0.109) data 0.000 (0.035) loss 2.2984 (2.2762) teacher_loss 0.8017 (0.7781) loss_zs_kd 1.4732 (1.8461) loss_oracle 1.0315 (1.0256) acc 68.7500 (73.1250) lr 2.2949e-04 eta 0:07:42
epoch [41/50] batch [40/428] time 0.075 (0.094) data 0.000 (0.018) loss 2.0885 (2.3002) teacher_loss 0.5837 (0.7932) loss_zs_kd 2.2602 (1.8665) loss_oracle 1.0302 (1.0279) acc 84.3750 (72.1875) lr 2.2949e-04 eta 0:06:38
epoch [41/50] batch [60/428] time 0.085 (0.090) data 0.000 (0.012) loss 2.1491 (2.3246) teacher_loss 0.6634 (0.8201) loss_zs_kd 1.9604 (1.8947) loss_oracle 1.0139 (1.0234) acc 84.3750 (71.2500) lr 2.2949e-04 eta 0:06:18
epoch [41/50] batch [80/428] time 0.077 (0.088) data 0.000 (0.009) loss 2.5000 (2.3290) teacher_loss 0.9666 (0.8216) loss_zs_kd 2.0646 (1.9041) loss_oracle 1.0252 (1.0245) acc 68.7500 (70.7031) lr 2.2949e-04 eta 0:06:09
epoch [41/50] batch [100/428] time 0.081 (0.086) data 0.000 (0.007) loss 2.2728 (2.3267) teacher_loss 0.7456 (0.8181) loss_zs_kd 1.8810 (1.8968) loss_oracle 0.9733 (1.0234) acc 68.7500 (70.8125) lr 2.2949e-04 eta 0:06:00
epoch [41/50] batch [120/428] time 0.085 (0.086) data 0.000 (0.006) loss 2.0890 (2.3277) teacher_loss 0.6221 (0.8194) loss_zs_kd 1.7565 (1.8861) loss_oracle 1.0169 (1.0224) acc 78.1250 (71.2240) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [140/428] time 0.083 (0.085) data 0.000 (0.005) loss 2.5524 (2.3257) teacher_loss 1.0868 (0.8157) loss_zs_kd 2.1905 (1.8902) loss_oracle 1.0175 (1.0228) acc 62.5000 (71.0714) lr 2.2949e-04 eta 0:05:53
epoch [41/50] batch [160/428] time 0.078 (0.085) data 0.000 (0.005) loss 2.3464 (2.3246) teacher_loss 0.7718 (0.8151) loss_zs_kd 1.6603 (1.8794) loss_oracle 1.0530 (1.0222) acc 75.0000 (70.9766) lr 2.2949e-04 eta 0:05:49
epoch [41/50] batch [180/428] time 0.085 (0.085) data 0.000 (0.004) loss 2.1942 (2.3214) teacher_loss 0.6548 (0.8117) loss_zs_kd 1.6846 (1.8764) loss_oracle 1.0579 (1.0212) acc 78.1250 (71.2153) lr 2.2949e-04 eta 0:05:47
epoch [41/50] batch [200/428] time 0.083 (0.086) data 0.000 (0.004) loss 2.2123 (2.3196) teacher_loss 0.6613 (0.8100) loss_zs_kd 2.3098 (1.8733) loss_oracle 1.1152 (1.0206) acc 78.1250 (71.2344) lr 2.2949e-04 eta 0:05:49
epoch [41/50] batch [220/428] time 0.088 (0.085) data 0.000 (0.003) loss 2.4573 (2.3220) teacher_loss 0.9895 (0.8117) loss_zs_kd 1.8110 (1.8672) loss_oracle 1.0053 (1.0209) acc 75.0000 (71.3068) lr 2.2949e-04 eta 0:05:45
epoch [41/50] batch [240/428] time 0.087 (0.085) data 0.000 (0.003) loss 2.0279 (2.3189) teacher_loss 0.5652 (0.8096) loss_zs_kd 1.8011 (1.8609) loss_oracle 0.9999 (1.0215) acc 87.5000 (71.3021) lr 2.2949e-04 eta 0:05:43
epoch [41/50] batch [260/428] time 0.080 (0.085) data 0.000 (0.003) loss 2.6742 (2.3213) teacher_loss 1.1787 (0.8107) loss_zs_kd 1.7432 (1.8598) loss_oracle 1.0499 (1.0214) acc 62.5000 (71.2620) lr 2.2949e-04 eta 0:05:40
epoch [41/50] batch [280/428] time 0.079 (0.084) data 0.000 (0.003) loss 2.2731 (2.3237) teacher_loss 0.7877 (0.8134) loss_zs_kd 1.4830 (1.8521) loss_oracle 0.9778 (1.0218) acc 75.0000 (71.3393) lr 2.2949e-04 eta 0:05:36
epoch [41/50] batch [300/428] time 0.079 (0.084) data 0.000 (0.003) loss 2.3696 (2.3260) teacher_loss 0.8986 (0.8150) loss_zs_kd 1.8148 (1.8459) loss_oracle 1.0084 (1.0212) acc 62.5000 (71.2708) lr 2.2949e-04 eta 0:05:34
epoch [41/50] batch [320/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.3146 (2.3262) teacher_loss 0.7732 (0.8146) loss_zs_kd 1.8938 (1.8348) loss_oracle 1.0138 (1.0211) acc 71.8750 (71.2988) lr 2.2949e-04 eta 0:05:31
epoch [41/50] batch [340/428] time 0.087 (0.084) data 0.000 (0.002) loss 2.3743 (2.3252) teacher_loss 0.7370 (0.8127) loss_zs_kd 1.6386 (1.8382) loss_oracle 1.0745 (1.0205) acc 71.8750 (71.4890) lr 2.2949e-04 eta 0:05:30
epoch [41/50] batch [360/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.0359 (2.3203) teacher_loss 0.4903 (0.8078) loss_zs_kd 1.5294 (1.8341) loss_oracle 1.0197 (1.0204) acc 87.5000 (71.7014) lr 2.2949e-04 eta 0:05:27
epoch [41/50] batch [380/428] time 0.079 (0.083) data 0.000 (0.002) loss 2.2638 (2.3186) teacher_loss 0.7437 (0.8064) loss_zs_kd 1.3558 (1.8338) loss_oracle 1.0381 (1.0203) acc 68.7500 (71.7516) lr 2.2949e-04 eta 0:05:24
epoch [41/50] batch [400/428] time 0.084 (0.083) data 0.000 (0.002) loss 2.1179 (2.3217) teacher_loss 0.6412 (0.8096) loss_zs_kd 1.8411 (1.8321) loss_oracle 0.9330 (1.0201) acc 71.8750 (71.6172) lr 2.2949e-04 eta 0:05:22
epoch [41/50] batch [420/428] time 0.076 (0.083) data 0.000 (0.002) loss 2.3750 (2.3267) teacher_loss 0.8278 (0.8140) loss_zs_kd 2.0923 (1.8357) loss_oracle 1.0270 (1.0201) acc 68.7500 (71.4360) lr 2.2949e-04 eta 0:05:20
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,802
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,202
* accuracy: 46.4%
* error: 53.6%
* macro_f1: 32.0%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [42/50] batch [20/428] time 0.090 (0.110) data 0.000 (0.025) loss 2.4085 (2.2662) teacher_loss 0.8684 (0.7520) loss_zs_kd 1.2148 (1.8052) loss_oracle 1.0254 (1.0107) acc 62.5000 (74.2188) lr 1.9098e-04 eta 0:07:02
epoch [42/50] batch [40/428] time 0.085 (0.097) data 0.000 (0.012) loss 2.3095 (2.3055) teacher_loss 0.8612 (0.7811) loss_zs_kd 1.9823 (1.7906) loss_oracle 1.0301 (1.0198) acc 68.7500 (73.4375) lr 1.9098e-04 eta 0:06:08
epoch [42/50] batch [60/428] time 0.088 (0.091) data 0.000 (0.008) loss 2.6232 (2.3220) teacher_loss 1.1509 (0.7953) loss_zs_kd 1.9367 (1.8095) loss_oracle 0.9887 (1.0232) acc 56.2500 (71.8750) lr 1.9098e-04 eta 0:05:46
epoch [42/50] batch [80/428] time 0.088 (0.090) data 0.000 (0.006) loss 2.1820 (2.3298) teacher_loss 0.6726 (0.8014) loss_zs_kd 1.8479 (1.8013) loss_oracle 1.0489 (1.0238) acc 71.8750 (71.9531) lr 1.9098e-04 eta 0:05:38
epoch [42/50] batch [100/428] time 0.078 (0.089) data 0.000 (0.005) loss 2.4173 (2.3314) teacher_loss 0.8758 (0.8024) loss_zs_kd 1.6088 (1.8023) loss_oracle 1.0221 (1.0264) acc 68.7500 (71.5312) lr 1.9098e-04 eta 0:05:32
epoch [42/50] batch [120/428] time 0.085 (0.088) data 0.000 (0.004) loss 2.5706 (2.3291) teacher_loss 0.9094 (0.7997) loss_zs_kd 1.4961 (1.8111) loss_oracle 1.0958 (1.0265) acc 68.7500 (71.8490) lr 1.9098e-04 eta 0:05:27
epoch [42/50] batch [140/428] time 0.095 (0.087) data 0.001 (0.004) loss 2.4355 (2.3378) teacher_loss 0.8771 (0.8087) loss_zs_kd 1.4369 (1.8077) loss_oracle 1.0183 (1.0260) acc 68.7500 (71.4062) lr 1.9098e-04 eta 0:05:24
epoch [42/50] batch [160/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.3712 (2.3366) teacher_loss 0.8276 (0.8093) loss_zs_kd 2.1563 (1.8115) loss_oracle 1.0380 (1.0249) acc 68.7500 (71.5234) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [180/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.3171 (2.3337) teacher_loss 0.8825 (0.8072) loss_zs_kd 1.6849 (1.8159) loss_oracle 0.9164 (1.0244) acc 68.7500 (71.4583) lr 1.9098e-04 eta 0:05:15
epoch [42/50] batch [200/428] time 0.087 (0.086) data 0.000 (0.003) loss 2.1949 (2.3280) teacher_loss 0.5882 (0.8017) loss_zs_kd 1.4150 (1.8162) loss_oracle 1.0514 (1.0247) acc 81.2500 (71.7344) lr 1.9098e-04 eta 0:05:12
epoch [42/50] batch [220/428] time 0.080 (0.085) data 0.000 (0.003) loss 2.1381 (2.3237) teacher_loss 0.6176 (0.7986) loss_zs_kd 1.7679 (1.8208) loss_oracle 1.0154 (1.0251) acc 81.2500 (72.0455) lr 1.9098e-04 eta 0:05:10
epoch [42/50] batch [240/428] time 0.087 (0.085) data 0.000 (0.002) loss 2.2755 (2.3238) teacher_loss 0.7898 (0.7994) loss_zs_kd 1.4896 (1.8167) loss_oracle 1.0274 (1.0250) acc 78.1250 (72.0833) lr 1.9098e-04 eta 0:05:08
epoch [42/50] batch [260/428] time 0.082 (0.085) data 0.001 (0.002) loss 2.5806 (2.3205) teacher_loss 1.0608 (0.7973) loss_zs_kd 1.7700 (1.8171) loss_oracle 0.9977 (1.0250) acc 68.7500 (72.2236) lr 1.9098e-04 eta 0:05:05
epoch [42/50] batch [280/428] time 0.084 (0.085) data 0.000 (0.002) loss 2.4055 (2.3237) teacher_loss 0.9097 (0.8001) loss_zs_kd 1.7488 (1.8208) loss_oracle 1.0060 (1.0253) acc 62.5000 (72.1987) lr 1.9098e-04 eta 0:05:04
epoch [42/50] batch [300/428] time 0.077 (0.085) data 0.000 (0.002) loss 2.2861 (2.3242) teacher_loss 0.7788 (0.8013) loss_zs_kd 1.6675 (1.8208) loss_oracle 0.9832 (1.0246) acc 71.8750 (71.9792) lr 1.9098e-04 eta 0:05:01
epoch [42/50] batch [320/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.5147 (2.3266) teacher_loss 0.9692 (0.8040) loss_zs_kd 1.9897 (1.8168) loss_oracle 1.0216 (1.0242) acc 62.5000 (71.9141) lr 1.9098e-04 eta 0:04:59
epoch [42/50] batch [340/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.1434 (2.3257) teacher_loss 0.5500 (0.8037) loss_zs_kd 1.9354 (1.8188) loss_oracle 1.0566 (1.0234) acc 78.1250 (71.9210) lr 1.9098e-04 eta 0:04:59
epoch [42/50] batch [360/428] time 0.089 (0.085) data 0.000 (0.002) loss 2.0923 (2.3227) teacher_loss 0.5582 (0.8016) loss_zs_kd 1.9283 (1.8216) loss_oracle 0.9919 (1.0229) acc 84.3750 (71.9271) lr 1.9098e-04 eta 0:04:57
epoch [42/50] batch [380/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.2596 (2.3229) teacher_loss 0.6881 (0.8006) loss_zs_kd 1.7795 (1.8161) loss_oracle 0.9823 (1.0230) acc 68.7500 (71.8997) lr 1.9098e-04 eta 0:04:55
epoch [42/50] batch [400/428] time 0.066 (0.085) data 0.000 (0.002) loss 2.3589 (2.3198) teacher_loss 0.8040 (0.7978) loss_zs_kd 1.9157 (1.8153) loss_oracle 1.0145 (1.0226) acc 62.5000 (71.9531) lr 1.9098e-04 eta 0:04:53
epoch [42/50] batch [420/428] time 0.084 (0.085) data 0.000 (0.001) loss 2.1900 (2.3190) teacher_loss 0.6676 (0.7960) loss_zs_kd 1.6960 (1.8120) loss_oracle 1.0509 (1.0232) acc 78.1250 (72.0833) lr 1.9098e-04 eta 0:04:50
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,814
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,185
* accuracy: 46.1%
* error: 53.9%
* macro_f1: 30.3%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [43/50] batch [20/428] time 0.069 (0.096) data 0.000 (0.028) loss 2.5091 (2.3116) teacher_loss 0.9997 (0.7804) loss_zs_kd 1.9694 (1.8267) loss_oracle 1.0104 (1.0281) acc 56.2500 (74.8438) lr 1.5567e-04 eta 0:05:26
epoch [43/50] batch [40/428] time 0.079 (0.086) data 0.000 (0.014) loss 2.5115 (2.3137) teacher_loss 0.9797 (0.7851) loss_zs_kd 1.7321 (1.8136) loss_oracle 1.0427 (1.0295) acc 71.8750 (74.2969) lr 1.5567e-04 eta 0:04:51
epoch [43/50] batch [60/428] time 0.080 (0.086) data 0.001 (0.010) loss 2.2542 (2.2884) teacher_loss 0.7602 (0.7635) loss_zs_kd 1.4705 (1.8130) loss_oracle 0.9837 (1.0292) acc 71.8750 (74.2708) lr 1.5567e-04 eta 0:04:50
epoch [43/50] batch [80/428] time 0.091 (0.088) data 0.000 (0.007) loss 2.2622 (2.3032) teacher_loss 0.8179 (0.7834) loss_zs_kd 1.9887 (1.8402) loss_oracle 0.9666 (1.0225) acc 68.7500 (73.2422) lr 1.5567e-04 eta 0:04:54
epoch [43/50] batch [100/428] time 0.093 (0.087) data 0.000 (0.006) loss 2.6309 (2.3062) teacher_loss 1.0703 (0.7863) loss_zs_kd 1.7851 (1.8430) loss_oracle 1.0256 (1.0238) acc 65.6250 (73.1250) lr 1.5567e-04 eta 0:04:49
epoch [43/50] batch [120/428] time 0.087 (0.087) data 0.000 (0.005) loss 2.3864 (2.3089) teacher_loss 0.8201 (0.7900) loss_zs_kd 1.6917 (1.8533) loss_oracle 1.0456 (1.0217) acc 71.8750 (72.5781) lr 1.5567e-04 eta 0:04:46
epoch [43/50] batch [140/428] time 0.079 (0.087) data 0.000 (0.004) loss 2.6514 (2.3116) teacher_loss 1.0386 (0.7919) loss_zs_kd 2.2606 (1.8462) loss_oracle 1.0711 (1.0229) acc 62.5000 (72.5000) lr 1.5567e-04 eta 0:04:44
epoch [43/50] batch [160/428] time 0.082 (0.086) data 0.000 (0.004) loss 2.3051 (2.3114) teacher_loss 0.7878 (0.7905) loss_zs_kd 1.5040 (1.8420) loss_oracle 0.9980 (1.0214) acc 68.7500 (72.4219) lr 1.5567e-04 eta 0:04:41
epoch [43/50] batch [180/428] time 0.084 (0.086) data 0.000 (0.003) loss 2.3121 (2.3144) teacher_loss 0.7758 (0.7922) loss_zs_kd 1.6288 (1.8390) loss_oracle 0.9839 (1.0217) acc 71.8750 (72.1875) lr 1.5567e-04 eta 0:04:39
epoch [43/50] batch [200/428] time 0.087 (0.086) data 0.000 (0.003) loss 2.4820 (2.3110) teacher_loss 0.9564 (0.7904) loss_zs_kd 1.6898 (1.8400) loss_oracle 1.0014 (1.0218) acc 62.5000 (72.1562) lr 1.5567e-04 eta 0:04:37
epoch [43/50] batch [220/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.4587 (2.3155) teacher_loss 0.9662 (0.7957) loss_zs_kd 1.6772 (1.8390) loss_oracle 1.0027 (1.0212) acc 65.6250 (72.2727) lr 1.5567e-04 eta 0:04:35
epoch [43/50] batch [240/428] time 0.089 (0.086) data 0.000 (0.003) loss 2.3734 (2.3127) teacher_loss 0.7479 (0.7928) loss_zs_kd 1.6706 (1.8413) loss_oracle 1.0815 (1.0216) acc 78.1250 (72.3568) lr 1.5567e-04 eta 0:04:33
epoch [43/50] batch [260/428] time 0.092 (0.086) data 0.000 (0.002) loss 2.3024 (2.3163) teacher_loss 0.7367 (0.7965) loss_zs_kd 1.5453 (1.8445) loss_oracle 0.9836 (1.0209) acc 65.6250 (72.2716) lr 1.5567e-04 eta 0:04:31
epoch [43/50] batch [280/428] time 0.085 (0.086) data 0.001 (0.002) loss 2.4280 (2.3211) teacher_loss 0.9495 (0.8015) loss_zs_kd 1.7461 (1.8422) loss_oracle 1.0273 (1.0205) acc 68.7500 (71.9754) lr 1.5567e-04 eta 0:04:29
epoch [43/50] batch [300/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.1629 (2.3199) teacher_loss 0.6634 (0.7997) loss_zs_kd 2.0915 (1.8411) loss_oracle 1.0341 (1.0205) acc 78.1250 (72.0729) lr 1.5567e-04 eta 0:04:28
epoch [43/50] batch [320/428] time 0.096 (0.086) data 0.001 (0.002) loss 2.4259 (2.3186) teacher_loss 0.8822 (0.7977) loss_zs_kd 1.5801 (1.8404) loss_oracle 1.0369 (1.0205) acc 68.7500 (72.1680) lr 1.5567e-04 eta 0:04:26
epoch [43/50] batch [340/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.2040 (2.3140) teacher_loss 0.6529 (0.7936) loss_zs_kd 1.8578 (1.8402) loss_oracle 1.0358 (1.0204) acc 75.0000 (72.3346) lr 1.5567e-04 eta 0:04:24
epoch [43/50] batch [360/428] time 0.088 (0.086) data 0.001 (0.002) loss 2.2796 (2.3129) teacher_loss 0.8376 (0.7931) loss_zs_kd 1.5215 (1.8389) loss_oracle 1.0301 (1.0200) acc 71.8750 (72.3264) lr 1.5567e-04 eta 0:04:22
epoch [43/50] batch [380/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.2729 (2.3127) teacher_loss 0.8019 (0.7935) loss_zs_kd 1.7458 (1.8377) loss_oracle 1.0229 (1.0195) acc 75.0000 (72.2862) lr 1.5567e-04 eta 0:04:20
epoch [43/50] batch [400/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.1534 (2.3113) teacher_loss 0.6555 (0.7928) loss_zs_kd 1.6921 (1.8377) loss_oracle 1.0212 (1.0190) acc 78.1250 (72.2344) lr 1.5567e-04 eta 0:04:18
epoch [43/50] batch [420/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.3549 (2.3095) teacher_loss 0.8663 (0.7907) loss_zs_kd 1.9095 (1.8335) loss_oracle 0.9689 (1.0190) acc 62.5000 (72.4107) lr 1.5567e-04 eta 0:04:16
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,809
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,189
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 31.6%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [44/50] batch [20/428] time 0.077 (0.109) data 0.000 (0.029) loss 2.3828 (2.3206) teacher_loss 0.8829 (0.8179) loss_zs_kd 1.8483 (1.8483) loss_oracle 1.0104 (1.0251) acc 65.6250 (70.3125) lr 1.2369e-04 eta 0:05:24
epoch [44/50] batch [40/428] time 0.074 (0.095) data 0.000 (0.015) loss 2.3254 (2.2992) teacher_loss 0.8388 (0.7861) loss_zs_kd 2.2475 (1.8361) loss_oracle 0.9867 (1.0219) acc 75.0000 (72.7344) lr 1.2369e-04 eta 0:04:40
epoch [44/50] batch [60/428] time 0.079 (0.089) data 0.000 (0.010) loss 2.2160 (2.2925) teacher_loss 0.7385 (0.7861) loss_zs_kd 1.5105 (1.8527) loss_oracle 1.0304 (1.0148) acc 78.1250 (72.5521) lr 1.2369e-04 eta 0:04:21
epoch [44/50] batch [80/428] time 0.080 (0.087) data 0.000 (0.007) loss 2.5692 (2.2945) teacher_loss 1.0496 (0.7834) loss_zs_kd 1.6481 (1.8414) loss_oracle 1.0412 (1.0152) acc 71.8750 (73.3203) lr 1.2369e-04 eta 0:04:14
epoch [44/50] batch [100/428] time 0.079 (0.086) data 0.000 (0.006) loss 2.2486 (2.2944) teacher_loss 0.7312 (0.7822) loss_zs_kd 1.5324 (1.8306) loss_oracle 0.9973 (1.0146) acc 62.5000 (73.3750) lr 1.2369e-04 eta 0:04:09
epoch [44/50] batch [120/428] time 0.082 (0.085) data 0.000 (0.005) loss 2.4725 (2.3059) teacher_loss 0.9822 (0.7937) loss_zs_kd 1.4770 (1.8275) loss_oracle 0.9904 (1.0169) acc 68.7500 (73.0208) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [140/428] time 0.078 (0.085) data 0.000 (0.004) loss 2.1431 (2.3043) teacher_loss 0.6417 (0.7930) loss_zs_kd 2.2202 (1.8320) loss_oracle 0.9677 (1.0163) acc 78.1250 (72.9018) lr 1.2369e-04 eta 0:04:03
epoch [44/50] batch [160/428] time 0.093 (0.085) data 0.000 (0.004) loss 2.2290 (2.3013) teacher_loss 0.6932 (0.7898) loss_zs_kd 1.6516 (1.8437) loss_oracle 1.0144 (1.0156) acc 75.0000 (73.0664) lr 1.2369e-04 eta 0:04:01
epoch [44/50] batch [180/428] time 0.082 (0.085) data 0.000 (0.003) loss 2.2726 (2.3078) teacher_loss 0.7890 (0.7971) loss_zs_kd 1.5805 (1.8486) loss_oracle 0.9948 (1.0160) acc 68.7500 (72.7083) lr 1.2369e-04 eta 0:03:59
epoch [44/50] batch [200/428] time 0.065 (0.086) data 0.001 (0.003) loss 2.2924 (2.3104) teacher_loss 0.8510 (0.8006) loss_zs_kd 1.7412 (1.8490) loss_oracle 1.0196 (1.0145) acc 75.0000 (72.6406) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [220/428] time 0.084 (0.086) data 0.000 (0.003) loss 2.2115 (2.3061) teacher_loss 0.6905 (0.7957) loss_zs_kd 2.1530 (1.8494) loss_oracle 1.0269 (1.0158) acc 75.0000 (72.6278) lr 1.2369e-04 eta 0:03:57
epoch [44/50] batch [240/428] time 0.087 (0.086) data 0.000 (0.003) loss 2.2721 (2.3068) teacher_loss 0.7564 (0.7947) loss_zs_kd 1.8721 (1.8504) loss_oracle 0.9629 (1.0168) acc 62.5000 (72.4089) lr 1.2369e-04 eta 0:03:55
epoch [44/50] batch [260/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.2319 (2.3085) teacher_loss 0.7561 (0.7976) loss_zs_kd 1.5086 (1.8470) loss_oracle 0.9636 (1.0159) acc 75.0000 (72.3798) lr 1.2369e-04 eta 0:03:53
epoch [44/50] batch [280/428] time 0.091 (0.085) data 0.000 (0.002) loss 2.1031 (2.3084) teacher_loss 0.6595 (0.7980) loss_zs_kd 1.6212 (1.8486) loss_oracle 0.9785 (1.0158) acc 78.1250 (72.2433) lr 1.2369e-04 eta 0:03:51
epoch [44/50] batch [300/428] time 0.089 (0.085) data 0.000 (0.002) loss 2.3296 (2.3091) teacher_loss 0.8163 (0.7983) loss_zs_kd 1.4548 (1.8404) loss_oracle 0.9719 (1.0154) acc 59.3750 (72.2604) lr 1.2369e-04 eta 0:03:49
epoch [44/50] batch [320/428] time 0.095 (0.085) data 0.000 (0.002) loss 2.5017 (2.3083) teacher_loss 1.0358 (0.7973) loss_zs_kd 1.4189 (1.8339) loss_oracle 0.9938 (1.0156) acc 71.8750 (72.4512) lr 1.2369e-04 eta 0:03:47
epoch [44/50] batch [340/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.3142 (2.3074) teacher_loss 0.7723 (0.7970) loss_zs_kd 1.9829 (1.8352) loss_oracle 1.0447 (1.0154) acc 68.7500 (72.4265) lr 1.2369e-04 eta 0:03:45
epoch [44/50] batch [360/428] time 0.078 (0.085) data 0.000 (0.002) loss 2.2414 (2.3107) teacher_loss 0.7738 (0.8001) loss_zs_kd 1.9717 (1.8314) loss_oracle 1.0088 (1.0157) acc 75.0000 (72.3611) lr 1.2369e-04 eta 0:03:43
epoch [44/50] batch [380/428] time 0.075 (0.085) data 0.000 (0.002) loss 1.9669 (2.3110) teacher_loss 0.5002 (0.8000) loss_zs_kd 1.9914 (1.8346) loss_oracle 1.0026 (1.0165) acc 90.6250 (72.4013) lr 1.2369e-04 eta 0:03:41
epoch [44/50] batch [400/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.3222 (2.3099) teacher_loss 0.7440 (0.7986) loss_zs_kd 1.9362 (1.8346) loss_oracle 1.0365 (1.0166) acc 75.0000 (72.4844) lr 1.2369e-04 eta 0:03:39
epoch [44/50] batch [420/428] time 0.075 (0.084) data 0.000 (0.002) loss 2.1577 (2.3094) teacher_loss 0.6906 (0.7988) loss_zs_kd 1.6925 (1.8392) loss_oracle 0.9499 (1.0167) acc 78.1250 (72.5521) lr 1.2369e-04 eta 0:03:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,813
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 51.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,131
* accuracy: 44.9%
* error: 55.1%
* macro_f1: 31.4%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [45/50] batch [20/428] time 0.077 (0.116) data 0.000 (0.027) loss 2.1263 (2.2682) teacher_loss 0.6779 (0.7596) loss_zs_kd 1.7344 (1.8156) loss_oracle 0.9735 (0.9981) acc 84.3750 (72.3438) lr 9.5173e-05 eta 0:04:56
epoch [45/50] batch [40/428] time 0.078 (0.098) data 0.000 (0.013) loss 2.2655 (2.2862) teacher_loss 0.7659 (0.7804) loss_zs_kd 1.6646 (1.7925) loss_oracle 0.9546 (1.0035) acc 75.0000 (71.3281) lr 9.5173e-05 eta 0:04:08
epoch [45/50] batch [60/428] time 0.083 (0.093) data 0.001 (0.009) loss 2.4164 (2.3072) teacher_loss 0.8743 (0.7952) loss_zs_kd 2.1926 (1.8135) loss_oracle 1.0571 (1.0068) acc 78.1250 (71.6146) lr 9.5173e-05 eta 0:03:53
epoch [45/50] batch [80/428] time 0.086 (0.091) data 0.000 (0.007) loss 2.2614 (2.2964) teacher_loss 0.7711 (0.7858) loss_zs_kd 1.4891 (1.8006) loss_oracle 1.0880 (1.0087) acc 75.0000 (71.9922) lr 9.5173e-05 eta 0:03:46
epoch [45/50] batch [100/428] time 0.085 (0.089) data 0.000 (0.006) loss 2.4651 (2.2951) teacher_loss 0.9169 (0.7830) loss_zs_kd 1.9515 (1.8027) loss_oracle 1.0152 (1.0116) acc 71.8750 (72.6250) lr 9.5173e-05 eta 0:03:39
epoch [45/50] batch [120/428] time 0.054 (0.087) data 0.000 (0.005) loss 2.2873 (2.2920) teacher_loss 0.7624 (0.7783) loss_zs_kd 1.7135 (1.8070) loss_oracle 1.0155 (1.0128) acc 68.7500 (73.0729) lr 9.5173e-05 eta 0:03:34
epoch [45/50] batch [140/428] time 0.079 (0.086) data 0.000 (0.004) loss 2.2569 (2.3005) teacher_loss 0.7399 (0.7877) loss_zs_kd 1.8973 (1.8109) loss_oracle 0.9938 (1.0128) acc 68.7500 (72.5893) lr 9.5173e-05 eta 0:03:27
epoch [45/50] batch [160/428] time 0.087 (0.085) data 0.001 (0.004) loss 2.2419 (2.3061) teacher_loss 0.7608 (0.7916) loss_zs_kd 1.9602 (1.8103) loss_oracle 0.9798 (1.0134) acc 71.8750 (72.4609) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [180/428] time 0.085 (0.085) data 0.000 (0.003) loss 2.2670 (2.3114) teacher_loss 0.8116 (0.7946) loss_zs_kd 1.5664 (1.8087) loss_oracle 1.0127 (1.0162) acc 75.0000 (72.3611) lr 9.5173e-05 eta 0:03:22
epoch [45/50] batch [200/428] time 0.091 (0.085) data 0.000 (0.003) loss 2.3191 (2.3081) teacher_loss 0.7890 (0.7944) loss_zs_kd 1.8761 (1.8113) loss_oracle 1.0350 (1.0145) acc 71.8750 (72.3750) lr 9.5173e-05 eta 0:03:21
epoch [45/50] batch [220/428] time 0.084 (0.085) data 0.000 (0.003) loss 2.3080 (2.3042) teacher_loss 0.8032 (0.7923) loss_zs_kd 1.7922 (1.8171) loss_oracle 1.0507 (1.0130) acc 78.1250 (72.4290) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [240/428] time 0.080 (0.085) data 0.001 (0.002) loss 2.1906 (2.3057) teacher_loss 0.7100 (0.7929) loss_zs_kd 1.7685 (1.8151) loss_oracle 0.9987 (1.0135) acc 71.8750 (72.2786) lr 9.5173e-05 eta 0:03:17
epoch [45/50] batch [260/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.2279 (2.3051) teacher_loss 0.7177 (0.7926) loss_zs_kd 1.6122 (1.8134) loss_oracle 0.9755 (1.0137) acc 78.1250 (72.3317) lr 9.5173e-05 eta 0:03:14
epoch [45/50] batch [280/428] time 0.085 (0.084) data 0.000 (0.002) loss 2.1016 (2.3027) teacher_loss 0.5666 (0.7912) loss_zs_kd 2.0384 (1.8128) loss_oracle 1.0427 (1.0131) acc 81.2500 (72.4107) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [300/428] time 0.094 (0.085) data 0.000 (0.002) loss 2.3867 (2.3028) teacher_loss 0.8372 (0.7910) loss_zs_kd 1.5278 (1.8095) loss_oracle 0.9599 (1.0135) acc 68.7500 (72.4271) lr 9.5173e-05 eta 0:03:11
epoch [45/50] batch [320/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.5228 (2.3009) teacher_loss 1.0030 (0.7889) loss_zs_kd 1.4144 (1.8129) loss_oracle 1.0530 (1.0137) acc 71.8750 (72.4805) lr 9.5173e-05 eta 0:03:10
epoch [45/50] batch [340/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.1290 (2.3014) teacher_loss 0.6374 (0.7894) loss_zs_kd 1.9880 (1.8120) loss_oracle 1.0473 (1.0145) acc 81.2500 (72.4540) lr 9.5173e-05 eta 0:03:08
epoch [45/50] batch [360/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.4924 (2.3029) teacher_loss 0.9280 (0.7899) loss_zs_kd 1.6369 (1.8122) loss_oracle 1.0592 (1.0148) acc 56.2500 (72.3524) lr 9.5173e-05 eta 0:03:06
epoch [45/50] batch [380/428] time 0.074 (0.084) data 0.000 (0.002) loss 2.3644 (2.3019) teacher_loss 0.8476 (0.7885) loss_zs_kd 1.8718 (1.8148) loss_oracle 0.9802 (1.0154) acc 71.8750 (72.3849) lr 9.5173e-05 eta 0:03:03
epoch [45/50] batch [400/428] time 0.084 (0.084) data 0.000 (0.002) loss 2.4904 (2.3024) teacher_loss 0.9562 (0.7884) loss_zs_kd 1.8173 (1.8179) loss_oracle 1.0566 (1.0157) acc 68.7500 (72.3047) lr 9.5173e-05 eta 0:03:01
epoch [45/50] batch [420/428] time 0.071 (0.084) data 0.000 (0.002) loss 2.1102 (2.3035) teacher_loss 0.5532 (0.7898) loss_zs_kd 1.7112 (1.8175) loss_oracle 1.0683 (1.0152) acc 84.3750 (72.2470) lr 9.5173e-05 eta 0:02:59
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,810
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,114
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 31.1%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [46/50] batch [20/428] time 0.069 (0.102) data 0.000 (0.024) loss 2.3169 (2.3249) teacher_loss 0.8064 (0.7978) loss_zs_kd 1.7725 (1.8686) loss_oracle 0.9988 (1.0266) acc 62.5000 (72.9688) lr 7.0224e-05 eta 0:03:35
epoch [46/50] batch [40/428] time 0.083 (0.088) data 0.000 (0.012) loss 2.5104 (2.3181) teacher_loss 0.9715 (0.7969) loss_zs_kd 1.8228 (1.8918) loss_oracle 1.0281 (1.0239) acc 68.7500 (72.6562) lr 7.0224e-05 eta 0:03:04
epoch [46/50] batch [60/428] time 0.070 (0.088) data 0.000 (0.008) loss 2.2541 (2.2843) teacher_loss 0.7553 (0.7636) loss_zs_kd 2.0480 (1.8728) loss_oracle 1.0283 (1.0222) acc 71.8750 (74.3750) lr 7.0224e-05 eta 0:03:03
epoch [46/50] batch [80/428] time 0.079 (0.086) data 0.000 (0.006) loss 2.1496 (2.2935) teacher_loss 0.5740 (0.7703) loss_zs_kd 1.9516 (1.8480) loss_oracle 1.0181 (1.0221) acc 78.1250 (73.6719) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [100/428] time 0.095 (0.085) data 0.000 (0.005) loss 2.3215 (2.2980) teacher_loss 0.8154 (0.7755) loss_zs_kd 1.8452 (1.8495) loss_oracle 0.9811 (1.0218) acc 81.2500 (73.1875) lr 7.0224e-05 eta 0:02:54
epoch [46/50] batch [120/428] time 0.081 (0.085) data 0.000 (0.004) loss 2.5710 (2.3028) teacher_loss 1.0218 (0.7826) loss_zs_kd 1.9100 (1.8418) loss_oracle 1.0707 (1.0200) acc 59.3750 (72.8385) lr 7.0224e-05 eta 0:02:51
epoch [46/50] batch [140/428] time 0.086 (0.085) data 0.000 (0.004) loss 2.3264 (2.3127) teacher_loss 0.8207 (0.7915) loss_zs_kd 1.8123 (1.8511) loss_oracle 1.0128 (1.0208) acc 65.6250 (72.4554) lr 7.0224e-05 eta 0:02:50
epoch [46/50] batch [160/428] time 0.082 (0.085) data 0.000 (0.003) loss 2.5664 (2.3157) teacher_loss 0.9778 (0.7956) loss_zs_kd 1.6968 (1.8427) loss_oracle 1.0303 (1.0184) acc 59.3750 (72.3438) lr 7.0224e-05 eta 0:02:47
epoch [46/50] batch [180/428] time 0.092 (0.085) data 0.000 (0.003) loss 2.6077 (2.3232) teacher_loss 1.0919 (0.8017) loss_zs_kd 1.9533 (1.8376) loss_oracle 1.0334 (1.0186) acc 53.1250 (72.1875) lr 7.0224e-05 eta 0:02:46
epoch [46/50] batch [200/428] time 0.082 (0.085) data 0.000 (0.003) loss 1.9537 (2.3244) teacher_loss 0.5072 (0.8031) loss_zs_kd 1.7847 (1.8369) loss_oracle 1.0090 (1.0178) acc 78.1250 (71.8750) lr 7.0224e-05 eta 0:02:44
epoch [46/50] batch [220/428] time 0.086 (0.085) data 0.000 (0.002) loss 2.5708 (2.3244) teacher_loss 1.0327 (0.8046) loss_zs_kd 1.9600 (1.8323) loss_oracle 1.0265 (1.0164) acc 53.1250 (71.6193) lr 7.0224e-05 eta 0:02:42
epoch [46/50] batch [240/428] time 0.087 (0.085) data 0.000 (0.002) loss 2.8979 (2.3237) teacher_loss 1.3688 (0.8027) loss_zs_kd 1.7056 (1.8329) loss_oracle 0.9835 (1.0168) acc 56.2500 (71.6927) lr 7.0224e-05 eta 0:02:40
epoch [46/50] batch [260/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.2745 (2.3226) teacher_loss 0.7730 (0.8009) loss_zs_kd 1.9654 (1.8330) loss_oracle 1.0631 (1.0178) acc 75.0000 (71.8630) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [280/428] time 0.083 (0.085) data 0.000 (0.002) loss 2.3660 (2.3195) teacher_loss 0.8820 (0.7984) loss_zs_kd 2.0309 (1.8282) loss_oracle 0.9190 (1.0169) acc 78.1250 (72.0647) lr 7.0224e-05 eta 0:02:37
epoch [46/50] batch [300/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.0540 (2.3184) teacher_loss 0.4788 (0.7967) loss_zs_kd 1.9417 (1.8233) loss_oracle 1.0340 (1.0183) acc 78.1250 (72.1250) lr 7.0224e-05 eta 0:02:36
epoch [46/50] batch [320/428] time 0.090 (0.085) data 0.000 (0.002) loss 2.6967 (2.3178) teacher_loss 1.1054 (0.7956) loss_zs_kd 1.5274 (1.8201) loss_oracle 1.0762 (1.0188) acc 65.6250 (72.2461) lr 7.0224e-05 eta 0:02:35
epoch [46/50] batch [340/428] time 0.061 (0.085) data 0.000 (0.002) loss 2.2886 (2.3189) teacher_loss 0.8100 (0.7968) loss_zs_kd 1.8159 (1.8226) loss_oracle 1.0128 (1.0190) acc 65.6250 (72.1967) lr 7.0224e-05 eta 0:02:33
epoch [46/50] batch [360/428] time 0.091 (0.085) data 0.000 (0.002) loss 2.2803 (2.3218) teacher_loss 0.7433 (0.7996) loss_zs_kd 1.6050 (1.8207) loss_oracle 1.0043 (1.0195) acc 65.6250 (72.1441) lr 7.0224e-05 eta 0:02:31
epoch [46/50] batch [380/428] time 0.091 (0.085) data 0.000 (0.002) loss 2.2322 (2.3192) teacher_loss 0.6396 (0.7972) loss_zs_kd 1.7388 (1.8202) loss_oracle 1.0760 (1.0191) acc 75.0000 (72.0724) lr 7.0224e-05 eta 0:02:28
epoch [46/50] batch [400/428] time 0.090 (0.084) data 0.001 (0.001) loss 2.4691 (2.3192) teacher_loss 0.9702 (0.7969) loss_zs_kd 1.6360 (1.8230) loss_oracle 0.9965 (1.0191) acc 68.7500 (72.0078) lr 7.0224e-05 eta 0:02:26
epoch [46/50] batch [420/428] time 0.082 (0.084) data 0.000 (0.001) loss 2.1323 (2.3185) teacher_loss 0.5907 (0.7960) loss_zs_kd 1.4137 (1.8225) loss_oracle 1.0679 (1.0192) acc 81.2500 (71.9717) lr 7.0224e-05 eta 0:02:25
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,125
* accuracy: 44.8%
* error: 55.2%
* macro_f1: 31.3%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [47/50] batch [20/428] time 0.076 (0.108) data 0.000 (0.032) loss 2.4407 (2.3724) teacher_loss 0.8707 (0.8650) loss_zs_kd 1.9367 (1.7216) loss_oracle 1.0516 (1.0136) acc 62.5000 (68.1250) lr 4.8943e-05 eta 0:03:02
epoch [47/50] batch [40/428] time 0.077 (0.096) data 0.000 (0.016) loss 2.3244 (2.3545) teacher_loss 0.8643 (0.8440) loss_zs_kd 1.8616 (1.7891) loss_oracle 1.0244 (1.0210) acc 65.6250 (69.2188) lr 4.8943e-05 eta 0:02:39
epoch [47/50] batch [60/428] time 0.080 (0.092) data 0.000 (0.011) loss 2.3671 (2.3551) teacher_loss 0.8461 (0.8359) loss_zs_kd 1.3894 (1.7774) loss_oracle 1.0913 (1.0264) acc 68.7500 (70.4167) lr 4.8943e-05 eta 0:02:31
epoch [47/50] batch [80/428] time 0.093 (0.090) data 0.000 (0.008) loss 2.5218 (2.3501) teacher_loss 1.0033 (0.8335) loss_zs_kd 1.7227 (1.8111) loss_oracle 1.0565 (1.0237) acc 56.2500 (70.0000) lr 4.8943e-05 eta 0:02:26
epoch [47/50] batch [100/428] time 0.095 (0.089) data 0.000 (0.007) loss 2.5108 (2.3321) teacher_loss 1.0068 (0.8161) loss_zs_kd 1.8938 (1.8190) loss_oracle 1.0769 (1.0237) acc 65.6250 (70.7812) lr 4.8943e-05 eta 0:02:24
epoch [47/50] batch [120/428] time 0.087 (0.089) data 0.000 (0.006) loss 2.2250 (2.3344) teacher_loss 0.6482 (0.8179) loss_zs_kd 1.6687 (1.8237) loss_oracle 1.0556 (1.0234) acc 78.1250 (70.9635) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [140/428] time 0.075 (0.088) data 0.000 (0.005) loss 2.2051 (2.3283) teacher_loss 0.6751 (0.8107) loss_zs_kd 1.4684 (1.8136) loss_oracle 1.0059 (1.0229) acc 68.7500 (71.2723) lr 4.8943e-05 eta 0:02:17
epoch [47/50] batch [160/428] time 0.080 (0.087) data 0.000 (0.004) loss 2.1665 (2.3227) teacher_loss 0.6486 (0.8053) loss_zs_kd 1.7389 (1.8151) loss_oracle 1.0262 (1.0225) acc 81.2500 (71.7383) lr 4.8943e-05 eta 0:02:15
epoch [47/50] batch [180/428] time 0.068 (0.088) data 0.000 (0.004) loss 2.2101 (2.3183) teacher_loss 0.6912 (0.7995) loss_zs_kd 1.8006 (1.8207) loss_oracle 1.0178 (1.0224) acc 71.8750 (71.8403) lr 4.8943e-05 eta 0:02:14
epoch [47/50] batch [200/428] time 0.079 (0.087) data 0.000 (0.003) loss 2.4359 (2.3144) teacher_loss 0.9133 (0.7957) loss_zs_kd 1.7884 (1.8233) loss_oracle 0.9896 (1.0227) acc 62.5000 (71.9844) lr 4.8943e-05 eta 0:02:11
epoch [47/50] batch [220/428] time 0.091 (0.086) data 0.000 (0.003) loss 2.0745 (2.3065) teacher_loss 0.5079 (0.7884) loss_zs_kd 1.8162 (1.8237) loss_oracle 1.0212 (1.0227) acc 87.5000 (72.2869) lr 4.8943e-05 eta 0:02:08
epoch [47/50] batch [240/428] time 0.079 (0.086) data 0.000 (0.003) loss 2.2993 (2.3058) teacher_loss 0.8306 (0.7887) loss_zs_kd 2.1566 (1.8238) loss_oracle 1.0419 (1.0223) acc 78.1250 (72.3828) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [260/428] time 0.089 (0.085) data 0.000 (0.003) loss 2.2457 (2.3052) teacher_loss 0.7864 (0.7871) loss_zs_kd 1.6200 (1.8269) loss_oracle 1.0109 (1.0226) acc 68.7500 (72.4159) lr 4.8943e-05 eta 0:02:04
epoch [47/50] batch [280/428] time 0.080 (0.085) data 0.000 (0.003) loss 2.1911 (2.3041) teacher_loss 0.7501 (0.7869) loss_zs_kd 2.0820 (1.8370) loss_oracle 0.9802 (1.0216) acc 81.2500 (72.5781) lr 4.8943e-05 eta 0:02:01
epoch [47/50] batch [300/428] time 0.082 (0.084) data 0.000 (0.002) loss 2.4748 (2.3007) teacher_loss 0.9790 (0.7826) loss_zs_kd 1.8573 (1.8381) loss_oracle 0.9689 (1.0214) acc 68.7500 (72.7188) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [320/428] time 0.083 (0.084) data 0.000 (0.002) loss 2.2161 (2.2975) teacher_loss 0.7408 (0.7801) loss_zs_kd 1.8780 (1.8446) loss_oracle 0.9550 (1.0212) acc 78.1250 (72.8125) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [340/428] time 0.084 (0.084) data 0.000 (0.002) loss 2.2220 (2.2994) teacher_loss 0.7856 (0.7824) loss_zs_kd 2.3707 (1.8508) loss_oracle 0.9577 (1.0208) acc 75.0000 (72.7574) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [360/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.2814 (2.3007) teacher_loss 0.7710 (0.7839) loss_zs_kd 1.4993 (1.8465) loss_oracle 1.0235 (1.0203) acc 68.7500 (72.6910) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [380/428] time 0.089 (0.084) data 0.000 (0.002) loss 2.2729 (2.2970) teacher_loss 0.7464 (0.7803) loss_zs_kd 2.0822 (1.8456) loss_oracle 0.9897 (1.0203) acc 71.8750 (72.8618) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [400/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.2136 (2.2968) teacher_loss 0.6962 (0.7800) loss_zs_kd 1.9109 (1.8473) loss_oracle 1.0052 (1.0203) acc 78.1250 (72.9062) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [420/428] time 0.076 (0.084) data 0.000 (0.002) loss 2.3104 (2.2980) teacher_loss 0.7662 (0.7822) loss_zs_kd 2.2030 (1.8450) loss_oracle 0.9881 (1.0199) acc 75.0000 (72.8199) lr 4.8943e-05 eta 0:01:48
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,812
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,115
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 31.1%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [48/50] batch [20/428] time 0.078 (0.121) data 0.000 (0.025) loss 2.2333 (2.2282) teacher_loss 0.7649 (0.7177) loss_zs_kd 1.4158 (1.7766) loss_oracle 0.9703 (1.0156) acc 71.8750 (75.6250) lr 3.1417e-05 eta 0:02:33
epoch [48/50] batch [40/428] time 0.081 (0.102) data 0.000 (0.012) loss 2.2992 (2.2993) teacher_loss 0.8327 (0.7860) loss_zs_kd 1.5471 (1.8080) loss_oracle 1.0359 (1.0146) acc 65.6250 (72.5781) lr 3.1417e-05 eta 0:02:06
epoch [48/50] batch [60/428] time 0.090 (0.097) data 0.000 (0.008) loss 2.1532 (2.2941) teacher_loss 0.6223 (0.7797) loss_zs_kd 1.7186 (1.8073) loss_oracle 1.0646 (1.0178) acc 81.2500 (72.8125) lr 3.1417e-05 eta 0:01:58
epoch [48/50] batch [80/428] time 0.087 (0.095) data 0.000 (0.006) loss 2.1021 (2.2936) teacher_loss 0.5863 (0.7789) loss_zs_kd 1.2050 (1.8032) loss_oracle 0.9811 (1.0189) acc 75.0000 (73.2812) lr 3.1417e-05 eta 0:01:53
epoch [48/50] batch [100/428] time 0.089 (0.092) data 0.000 (0.005) loss 2.2267 (2.3069) teacher_loss 0.7209 (0.7950) loss_zs_kd 1.9660 (1.7840) loss_oracle 1.0274 (1.0177) acc 71.8750 (72.3750) lr 3.1417e-05 eta 0:01:49
epoch [48/50] batch [120/428] time 0.083 (0.090) data 0.000 (0.004) loss 2.0482 (2.3103) teacher_loss 0.5372 (0.7940) loss_zs_kd 1.6516 (1.7896) loss_oracle 1.0185 (1.0200) acc 84.3750 (72.3958) lr 3.1417e-05 eta 0:01:45
epoch [48/50] batch [140/428] time 0.087 (0.090) data 0.000 (0.004) loss 2.2183 (2.3095) teacher_loss 0.7287 (0.7945) loss_zs_kd 2.1125 (1.8020) loss_oracle 1.0062 (1.0199) acc 78.1250 (72.3438) lr 3.1417e-05 eta 0:01:42
epoch [48/50] batch [160/428] time 0.083 (0.089) data 0.000 (0.003) loss 2.3280 (2.3058) teacher_loss 0.8601 (0.7942) loss_zs_kd 1.9915 (1.8096) loss_oracle 0.9870 (1.0177) acc 65.6250 (72.3828) lr 3.1417e-05 eta 0:01:40
epoch [48/50] batch [180/428] time 0.091 (0.089) data 0.001 (0.003) loss 2.0441 (2.3040) teacher_loss 0.5677 (0.7922) loss_zs_kd 2.2903 (1.8137) loss_oracle 0.9899 (1.0179) acc 84.3750 (72.6389) lr 3.1417e-05 eta 0:01:38
epoch [48/50] batch [200/428] time 0.074 (0.088) data 0.000 (0.003) loss 2.2478 (2.3053) teacher_loss 0.6941 (0.7926) loss_zs_kd 1.8493 (1.8291) loss_oracle 1.0379 (1.0172) acc 75.0000 (72.4375) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [220/428] time 0.082 (0.088) data 0.000 (0.003) loss 2.2264 (2.3034) teacher_loss 0.7580 (0.7916) loss_zs_kd 1.9834 (1.8285) loss_oracle 0.9941 (1.0166) acc 75.0000 (72.6420) lr 3.1417e-05 eta 0:01:33
epoch [48/50] batch [240/428] time 0.081 (0.087) data 0.000 (0.002) loss 2.3549 (2.3053) teacher_loss 0.8586 (0.7938) loss_zs_kd 2.2388 (1.8361) loss_oracle 0.9702 (1.0165) acc 62.5000 (72.4349) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [260/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.5198 (2.3083) teacher_loss 0.9723 (0.7957) loss_zs_kd 1.9680 (1.8356) loss_oracle 1.0889 (1.0170) acc 62.5000 (72.3197) lr 3.1417e-05 eta 0:01:28
epoch [48/50] batch [280/428] time 0.081 (0.086) data 0.000 (0.002) loss 2.3681 (2.3088) teacher_loss 0.9187 (0.7955) loss_zs_kd 1.9791 (1.8372) loss_oracle 0.9718 (1.0173) acc 68.7500 (72.4107) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [300/428] time 0.090 (0.086) data 0.000 (0.002) loss 2.0612 (2.3070) teacher_loss 0.5811 (0.7929) loss_zs_kd 1.9713 (1.8357) loss_oracle 1.0679 (1.0179) acc 81.2500 (72.3750) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [320/428] time 0.070 (0.086) data 0.000 (0.002) loss 2.1619 (2.3082) teacher_loss 0.6676 (0.7938) loss_zs_kd 2.3390 (1.8462) loss_oracle 1.0071 (1.0181) acc 81.2500 (72.4121) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [340/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.1931 (2.3074) teacher_loss 0.6492 (0.7922) loss_zs_kd 1.8857 (1.8453) loss_oracle 1.0545 (1.0179) acc 81.2500 (72.3713) lr 3.1417e-05 eta 0:01:21
epoch [48/50] batch [360/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.2731 (2.3049) teacher_loss 0.7370 (0.7903) loss_zs_kd 1.5839 (1.8433) loss_oracle 1.0486 (1.0175) acc 68.7500 (72.4219) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [380/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.4413 (2.3028) teacher_loss 0.9182 (0.7884) loss_zs_kd 2.1916 (1.8436) loss_oracle 1.0380 (1.0177) acc 65.6250 (72.4589) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [400/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.2331 (2.3048) teacher_loss 0.7243 (0.7902) loss_zs_kd 1.9035 (1.8447) loss_oracle 0.9858 (1.0174) acc 68.7500 (72.3359) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [420/428] time 0.076 (0.085) data 0.000 (0.001) loss 2.2255 (2.3044) teacher_loss 0.7340 (0.7904) loss_zs_kd 1.8497 (1.8456) loss_oracle 1.0040 (1.0172) acc 68.7500 (72.3289) lr 3.1417e-05 eta 0:01:13
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,815
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,119
* accuracy: 44.7%
* error: 55.3%
* macro_f1: 31.3%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [49/50] batch [20/428] time 0.074 (0.107) data 0.000 (0.023) loss 2.0997 (2.3238) teacher_loss 0.6157 (0.8106) loss_zs_kd 1.6923 (1.8792) loss_oracle 1.0429 (1.0145) acc 84.3750 (72.8125) lr 1.7713e-05 eta 0:01:29
epoch [49/50] batch [40/428] time 0.083 (0.096) data 0.000 (0.012) loss 1.9897 (2.3310) teacher_loss 0.4860 (0.8179) loss_zs_kd 2.1711 (1.8744) loss_oracle 1.0522 (1.0135) acc 87.5000 (70.7031) lr 1.7713e-05 eta 0:01:17
epoch [49/50] batch [60/428] time 0.069 (0.094) data 0.000 (0.008) loss 2.1097 (2.3323) teacher_loss 0.5362 (0.8174) loss_zs_kd 1.7395 (1.8445) loss_oracle 1.0692 (1.0150) acc 87.5000 (71.3021) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [80/428] time 0.085 (0.090) data 0.000 (0.006) loss 2.5844 (2.3436) teacher_loss 1.0491 (0.8263) loss_zs_kd 1.8660 (1.8278) loss_oracle 1.0229 (1.0165) acc 71.8750 (71.3672) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [100/428] time 0.090 (0.088) data 0.000 (0.005) loss 2.2389 (2.3506) teacher_loss 0.6930 (0.8326) loss_zs_kd 1.8470 (1.8301) loss_oracle 1.0268 (1.0162) acc 71.8750 (71.3438) lr 1.7713e-05 eta 0:01:06
epoch [49/50] batch [120/428] time 0.078 (0.087) data 0.000 (0.004) loss 2.3043 (2.3464) teacher_loss 0.7683 (0.8303) loss_zs_kd 1.7233 (1.8125) loss_oracle 1.0364 (1.0163) acc 75.0000 (71.1458) lr 1.7713e-05 eta 0:01:04
epoch [49/50] batch [140/428] time 0.083 (0.087) data 0.000 (0.004) loss 2.5516 (2.3522) teacher_loss 1.0227 (0.8352) loss_zs_kd 1.8982 (1.8120) loss_oracle 1.0742 (1.0177) acc 65.6250 (70.7812) lr 1.7713e-05 eta 0:01:02
epoch [49/50] batch [160/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.2761 (2.3372) teacher_loss 0.7635 (0.8195) loss_zs_kd 2.1145 (1.8180) loss_oracle 1.0345 (1.0184) acc 78.1250 (71.5039) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [180/428] time 0.085 (0.086) data 0.000 (0.003) loss 2.2683 (2.3350) teacher_loss 0.7002 (0.8156) loss_zs_kd 1.9400 (1.8145) loss_oracle 1.0610 (1.0195) acc 75.0000 (71.7014) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [200/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.3113 (2.3266) teacher_loss 0.7891 (0.8085) loss_zs_kd 1.8373 (1.8168) loss_oracle 0.9941 (1.0186) acc 65.6250 (72.0156) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [220/428] time 0.088 (0.086) data 0.000 (0.002) loss 1.9663 (2.3186) teacher_loss 0.4507 (0.8006) loss_zs_kd 1.9688 (1.8183) loss_oracle 1.0331 (1.0196) acc 87.5000 (72.2727) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [240/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.2626 (2.3138) teacher_loss 0.7269 (0.7960) loss_zs_kd 1.8647 (1.8160) loss_oracle 1.0414 (1.0201) acc 71.8750 (72.2786) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [260/428] time 0.076 (0.085) data 0.000 (0.002) loss 2.3044 (2.3119) teacher_loss 0.8314 (0.7940) loss_zs_kd 1.8824 (1.8201) loss_oracle 1.0099 (1.0199) acc 75.0000 (72.3558) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [280/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.1757 (2.3130) teacher_loss 0.6521 (0.7949) loss_zs_kd 1.8040 (1.8267) loss_oracle 1.0514 (1.0193) acc 84.3750 (72.4777) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [300/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.0533 (2.3105) teacher_loss 0.5021 (0.7921) loss_zs_kd 2.1074 (1.8277) loss_oracle 1.0504 (1.0198) acc 87.5000 (72.5208) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [320/428] time 0.077 (0.085) data 0.000 (0.002) loss 2.3280 (2.3109) teacher_loss 0.8002 (0.7921) loss_zs_kd 1.8233 (1.8263) loss_oracle 0.9755 (1.0206) acc 71.8750 (72.4219) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [340/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.0099 (2.3082) teacher_loss 0.4764 (0.7889) loss_zs_kd 2.3425 (1.8345) loss_oracle 1.0802 (1.0206) acc 84.3750 (72.5092) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [360/428] time 0.092 (0.085) data 0.000 (0.002) loss 2.0138 (2.3074) teacher_loss 0.5093 (0.7883) loss_zs_kd 1.7454 (1.8347) loss_oracle 0.9887 (1.0200) acc 87.5000 (72.5000) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [380/428] time 0.079 (0.085) data 0.000 (0.001) loss 1.8742 (2.3085) teacher_loss 0.3889 (0.7900) loss_zs_kd 1.5161 (1.8379) loss_oracle 0.9861 (1.0195) acc 84.3750 (72.5082) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [400/428] time 0.083 (0.085) data 0.000 (0.001) loss 2.3592 (2.3050) teacher_loss 0.8536 (0.7860) loss_zs_kd 1.6253 (1.8408) loss_oracle 1.0302 (1.0196) acc 71.8750 (72.5234) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [420/428] time 0.084 (0.085) data 0.000 (0.001) loss 2.1235 (2.3053) teacher_loss 0.6760 (0.7870) loss_zs_kd 1.8897 (1.8421) loss_oracle 1.0050 (1.0197) acc 78.1250 (72.5446) lr 1.7713e-05 eta 0:00:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,815
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,111
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.0%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
epoch [50/50] batch [20/428] time 0.078 (0.116) data 0.000 (0.028) loss 2.4339 (2.3083) teacher_loss 0.9317 (0.8005) loss_zs_kd 1.6874 (1.7164) loss_oracle 1.0251 (1.0136) acc 68.7500 (72.8125) lr 7.8853e-06 eta 0:00:47
epoch [50/50] batch [40/428] time 0.082 (0.100) data 0.000 (0.014) loss 2.4477 (2.3108) teacher_loss 0.8879 (0.8037) loss_zs_kd 2.0760 (1.7944) loss_oracle 1.0278 (1.0092) acc 65.6250 (71.8750) lr 7.8853e-06 eta 0:00:38
epoch [50/50] batch [60/428] time 0.078 (0.094) data 0.001 (0.010) loss 2.0611 (2.3156) teacher_loss 0.5246 (0.8072) loss_zs_kd 1.6462 (1.8046) loss_oracle 1.0195 (1.0142) acc 84.3750 (72.2396) lr 7.8853e-06 eta 0:00:34
epoch [50/50] batch [80/428] time 0.079 (0.092) data 0.000 (0.007) loss 2.4430 (2.3156) teacher_loss 0.9153 (0.8049) loss_zs_kd 1.9530 (1.8127) loss_oracle 1.0444 (1.0142) acc 62.5000 (72.4219) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [100/428] time 0.080 (0.091) data 0.000 (0.006) loss 2.3278 (2.3095) teacher_loss 0.8675 (0.7981) loss_zs_kd 1.8916 (1.8153) loss_oracle 0.9689 (1.0149) acc 65.6250 (72.5000) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [120/428] time 0.082 (0.089) data 0.000 (0.005) loss 2.0577 (2.3004) teacher_loss 0.5439 (0.7880) loss_zs_kd 2.0757 (1.8243) loss_oracle 0.9985 (1.0167) acc 84.3750 (72.8906) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [140/428] time 0.086 (0.089) data 0.000 (0.004) loss 2.6667 (2.3080) teacher_loss 1.1221 (0.7946) loss_zs_kd 1.8408 (1.8259) loss_oracle 1.0182 (1.0174) acc 62.5000 (72.7679) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [160/428] time 0.087 (0.088) data 0.000 (0.004) loss 2.3109 (2.3120) teacher_loss 0.8349 (0.7985) loss_zs_kd 2.2214 (1.8344) loss_oracle 1.0206 (1.0171) acc 71.8750 (72.8125) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [180/428] time 0.074 (0.089) data 0.000 (0.003) loss 2.4547 (2.3156) teacher_loss 0.8835 (0.8018) loss_zs_kd 1.4994 (1.8282) loss_oracle 0.9904 (1.0162) acc 68.7500 (72.4132) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [200/428] time 0.078 (0.088) data 0.000 (0.003) loss 2.2662 (2.3156) teacher_loss 0.7382 (0.8009) loss_zs_kd 1.9205 (1.8281) loss_oracle 0.9833 (1.0173) acc 75.0000 (72.4688) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [220/428] time 0.070 (0.087) data 0.000 (0.003) loss 2.2108 (2.3182) teacher_loss 0.6830 (0.8031) loss_zs_kd 1.4724 (1.8243) loss_oracle 1.0592 (1.0173) acc 87.5000 (72.2017) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [240/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.3112 (2.3187) teacher_loss 0.7605 (0.8029) loss_zs_kd 1.8202 (1.8266) loss_oracle 1.0064 (1.0177) acc 68.7500 (72.1224) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [260/428] time 0.081 (0.087) data 0.000 (0.002) loss 2.2748 (2.3220) teacher_loss 0.7697 (0.8077) loss_zs_kd 1.7572 (1.8199) loss_oracle 0.9681 (1.0172) acc 59.3750 (71.8990) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [280/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.1606 (2.3150) teacher_loss 0.6854 (0.8010) loss_zs_kd 2.4263 (1.8238) loss_oracle 0.9743 (1.0172) acc 68.7500 (72.0982) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [300/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.4773 (2.3140) teacher_loss 0.9358 (0.7994) loss_zs_kd 1.3412 (1.8246) loss_oracle 1.0174 (1.0169) acc 65.6250 (72.1562) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [320/428] time 0.076 (0.086) data 0.000 (0.002) loss 2.7471 (2.3150) teacher_loss 1.2145 (0.8003) loss_zs_kd 1.9023 (1.8257) loss_oracle 1.0189 (1.0174) acc 68.7500 (72.1387) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [340/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.7286 (2.3191) teacher_loss 1.2225 (0.8044) loss_zs_kd 1.7629 (1.8253) loss_oracle 1.0416 (1.0178) acc 50.0000 (71.9301) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [360/428] time 0.083 (0.085) data 0.000 (0.002) loss 2.1306 (2.3188) teacher_loss 0.5808 (0.8044) loss_zs_kd 1.9349 (1.8251) loss_oracle 1.0457 (1.0180) acc 71.8750 (71.9271) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [380/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.5693 (2.3168) teacher_loss 1.0730 (0.8026) loss_zs_kd 1.5998 (1.8286) loss_oracle 1.0361 (1.0183) acc 71.8750 (71.9737) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [400/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.3644 (2.3113) teacher_loss 0.8742 (0.7970) loss_zs_kd 1.9372 (1.8322) loss_oracle 0.9802 (1.0183) acc 71.8750 (72.2031) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [420/428] time 0.070 (0.085) data 0.000 (0.002) loss 2.1439 (2.3105) teacher_loss 0.6211 (0.7967) loss_zs_kd 1.8107 (1.8341) loss_oracle 0.9809 (1.0182) acc 78.1250 (72.2321) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,817
* accuracy: 65.0%
* error: 35.0%
* macro_f1: 52.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,113
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 31.1%
******* Domain 1 best val acc:      65.1%, epoch: 29 *******
******* Domain 1 best val test acc: 44.5%, epoch: 29 *******
******* Domain 1 best test acc:     52.3%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:45:53

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_38', 'location_46']
Target     ['location_43']
# classes  10
# train_x  14,252
# val      6,108
# test     3,970
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/445] time 0.068 (0.133) data 0.000 (0.029) loss 3.2503 (3.2253) teacher_loss 2.4124 (2.3187) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0238 (0.0071) acc 25.0000 (30.1562) lr 1.0000e-05 eta 0:49:23
epoch [1/50] batch [40/445] time 0.077 (0.105) data 0.000 (0.015) loss 3.6665 (3.1805) teacher_loss 2.6892 (2.2785) loss_zs_kd 0.0021 (0.0006) loss_oracle 0.0492 (0.0198) acc 21.8750 (31.6406) lr 1.0000e-05 eta 0:38:59
epoch [1/50] batch [60/445] time 0.089 (0.097) data 0.000 (0.010) loss 2.9472 (3.1971) teacher_loss 2.0696 (2.2807) loss_zs_kd 0.0059 (0.0021) loss_oracle 0.0545 (0.0330) acc 37.5000 (31.3542) lr 1.0000e-05 eta 0:36:00
epoch [1/50] batch [80/445] time 0.075 (0.093) data 0.000 (0.008) loss 3.1106 (3.1755) teacher_loss 2.2195 (2.2502) loss_zs_kd 0.0150 (0.0041) loss_oracle 0.1190 (0.0429) acc 21.8750 (31.7969) lr 1.0000e-05 eta 0:34:22
epoch [1/50] batch [100/445] time 0.080 (0.091) data 0.000 (0.006) loss 3.0221 (3.1606) teacher_loss 2.0245 (2.2190) loss_zs_kd 0.0250 (0.0074) loss_oracle 0.2873 (0.0721) acc 34.3750 (32.0938) lr 1.0000e-05 eta 0:33:37
epoch [1/50] batch [120/445] time 0.083 (0.089) data 0.000 (0.005) loss 3.5122 (3.1759) teacher_loss 2.1839 (2.2019) loss_zs_kd 0.0634 (0.0133) loss_oracle 0.7575 (0.1396) acc 34.3750 (32.6042) lr 1.0000e-05 eta 0:32:45
epoch [1/50] batch [140/445] time 0.068 (0.088) data 0.000 (0.004) loss 3.3810 (3.2078) teacher_loss 1.8370 (2.1659) loss_zs_kd 0.3533 (0.0455) loss_oracle 1.0786 (0.2589) acc 43.7500 (33.2366) lr 1.0000e-05 eta 0:32:25
epoch [1/50] batch [160/445] time 0.059 (0.085) data 0.000 (0.004) loss 3.0785 (3.2186) teacher_loss 1.5731 (2.1196) loss_zs_kd 0.3163 (0.0968) loss_oracle 0.9768 (0.3510) acc 50.0000 (34.3359) lr 1.0000e-05 eta 0:31:18
epoch [1/50] batch [180/445] time 0.062 (0.083) data 0.000 (0.004) loss 3.3353 (3.2175) teacher_loss 1.9320 (2.0759) loss_zs_kd 0.3918 (0.1323) loss_oracle 1.0223 (0.4219) acc 43.7500 (35.0174) lr 1.0000e-05 eta 0:30:25
epoch [1/50] batch [200/445] time 0.073 (0.081) data 0.000 (0.003) loss 3.3519 (3.2141) teacher_loss 1.7953 (2.0400) loss_zs_kd 0.4895 (0.1580) loss_oracle 1.0613 (0.4761) acc 40.6250 (35.5000) lr 1.0000e-05 eta 0:29:43
epoch [1/50] batch [220/445] time 0.093 (0.081) data 0.000 (0.003) loss 2.9171 (3.2071) teacher_loss 1.4979 (2.0075) loss_zs_kd 0.4374 (0.1855) loss_oracle 0.9329 (0.5223) acc 43.7500 (36.2358) lr 1.0000e-05 eta 0:29:42
epoch [1/50] batch [240/445] time 0.085 (0.081) data 0.000 (0.003) loss 3.4473 (3.2095) teacher_loss 1.9109 (1.9837) loss_zs_kd 0.6271 (0.2185) loss_oracle 1.0326 (0.5619) acc 21.8750 (36.6536) lr 1.0000e-05 eta 0:29:40
epoch [1/50] batch [260/445] time 0.088 (0.081) data 0.000 (0.003) loss 3.3954 (3.2076) teacher_loss 1.8257 (1.9577) loss_zs_kd 0.5858 (0.2449) loss_oracle 1.0551 (0.5981) acc 34.3750 (37.1995) lr 1.0000e-05 eta 0:29:42
epoch [1/50] batch [280/445] time 0.079 (0.081) data 0.000 (0.002) loss 3.0296 (3.2084) teacher_loss 1.5275 (1.9405) loss_zs_kd 0.5916 (0.2678) loss_oracle 0.9828 (0.6281) acc 43.7500 (37.5781) lr 1.0000e-05 eta 0:29:41
epoch [1/50] batch [300/445] time 0.089 (0.081) data 0.000 (0.002) loss 3.2094 (3.2007) teacher_loss 1.6119 (1.9122) loss_zs_kd 0.6796 (0.3009) loss_oracle 1.0985 (0.6578) acc 46.8750 (38.2708) lr 1.0000e-05 eta 0:29:43
epoch [1/50] batch [320/445] time 0.077 (0.081) data 0.000 (0.002) loss 3.0698 (3.1972) teacher_loss 1.4594 (1.8893) loss_zs_kd 0.9902 (0.3350) loss_oracle 1.1021 (0.6842) acc 43.7500 (38.8867) lr 1.0000e-05 eta 0:29:44
epoch [1/50] batch [340/445] time 0.120 (0.081) data 0.000 (0.002) loss 3.1327 (3.1938) teacher_loss 1.5302 (1.8706) loss_zs_kd 0.6227 (0.3637) loss_oracle 1.0580 (0.7057) acc 40.6250 (39.3474) lr 1.0000e-05 eta 0:29:42
epoch [1/50] batch [360/445] time 0.085 (0.082) data 0.000 (0.002) loss 2.8524 (3.1861) teacher_loss 1.4230 (1.8541) loss_zs_kd 0.4968 (0.3750) loss_oracle 1.0073 (0.7231) acc 40.6250 (39.6615) lr 1.0000e-05 eta 0:29:52
epoch [1/50] batch [380/445] time 0.073 (0.082) data 0.000 (0.002) loss 3.0181 (3.1795) teacher_loss 1.4209 (1.8366) loss_zs_kd 0.6543 (0.3862) loss_oracle 1.0895 (0.7389) acc 53.1250 (40.0329) lr 1.0000e-05 eta 0:29:49
epoch [1/50] batch [400/445] time 0.084 (0.082) data 0.000 (0.002) loss 3.2912 (3.1817) teacher_loss 1.7247 (1.8294) loss_zs_kd 0.5572 (0.3981) loss_oracle 1.0653 (0.7533) acc 31.2500 (40.0859) lr 1.0000e-05 eta 0:29:44
epoch [1/50] batch [420/445] time 0.080 (0.082) data 0.000 (0.002) loss 3.1033 (3.1756) teacher_loss 1.4875 (1.8134) loss_zs_kd 1.0792 (0.4193) loss_oracle 1.1044 (0.7690) acc 46.8750 (40.4464) lr 1.0000e-05 eta 0:29:44
epoch [1/50] batch [440/445] time 0.076 (0.082) data 0.000 (0.002) loss 3.3905 (3.1748) teacher_loss 1.8602 (1.8020) loss_zs_kd 0.7868 (0.4428) loss_oracle 1.0717 (0.7836) acc 34.3750 (40.7244) lr 1.0000e-05 eta 0:29:41
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 2,693
* accuracy: 44.1%
* error: 55.9%
* macro_f1: 28.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,592
* accuracy: 40.1%
* error: 59.9%
* macro_f1: 28.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      44.1%, epoch: 1 *******
******* Domain 3 best val test acc: 40.1%, epoch: 1 *******
******* Domain 3 best test acc:     40.1%, epoch: 1 *******
epoch [2/50] batch [20/445] time 0.082 (0.108) data 0.000 (0.026) loss 3.2850 (3.2282) teacher_loss 1.7374 (1.7033) loss_zs_kd 0.5890 (0.5643) loss_oracle 0.9680 (1.0108) acc 46.8750 (43.9062) lr 2.0000e-03 eta 0:39:07
epoch [2/50] batch [40/445] time 0.077 (0.094) data 0.000 (0.013) loss 2.9417 (3.1095) teacher_loss 1.3766 (1.5825) loss_zs_kd 0.6296 (0.5966) loss_oracle 1.0383 (1.0126) acc 53.1250 (45.5469) lr 2.0000e-03 eta 0:33:58
epoch [2/50] batch [60/445] time 0.082 (0.089) data 0.000 (0.009) loss 3.2372 (3.0702) teacher_loss 1.6389 (1.5348) loss_zs_kd 0.6815 (0.7071) loss_oracle 1.0913 (1.0209) acc 37.5000 (47.2917) lr 2.0000e-03 eta 0:32:18
epoch [2/50] batch [80/445] time 0.092 (0.091) data 0.000 (0.007) loss 3.1774 (3.0762) teacher_loss 1.6050 (1.5290) loss_zs_kd 0.6038 (0.6842) loss_oracle 1.0734 (1.0352) acc 46.8750 (46.9922) lr 2.0000e-03 eta 0:32:47
epoch [2/50] batch [100/445] time 0.090 (0.090) data 0.000 (0.005) loss 3.0211 (3.0505) teacher_loss 1.4861 (1.5013) loss_zs_kd 0.7208 (0.6610) loss_oracle 1.0539 (1.0397) acc 56.2500 (47.6250) lr 2.0000e-03 eta 0:32:24
epoch [2/50] batch [120/445] time 0.081 (0.089) data 0.000 (0.005) loss 2.9665 (3.0213) teacher_loss 1.4332 (1.4772) loss_zs_kd 0.4873 (0.6527) loss_oracle 1.0226 (1.0386) acc 46.8750 (48.4896) lr 2.0000e-03 eta 0:32:07
epoch [2/50] batch [140/445] time 0.081 (0.088) data 0.000 (0.004) loss 2.6904 (2.9977) teacher_loss 1.1491 (1.4552) loss_zs_kd 0.5494 (0.6470) loss_oracle 0.9708 (1.0350) acc 56.2500 (49.0848) lr 2.0000e-03 eta 0:31:54
epoch [2/50] batch [160/445] time 0.082 (0.088) data 0.000 (0.004) loss 2.7006 (2.9726) teacher_loss 1.2355 (1.4362) loss_zs_kd 0.5478 (0.6419) loss_oracle 0.9774 (1.0302) acc 53.1250 (49.6289) lr 2.0000e-03 eta 0:31:45
epoch [2/50] batch [180/445] time 0.082 (0.087) data 0.000 (0.003) loss 2.6875 (2.9494) teacher_loss 1.2223 (1.4192) loss_zs_kd 0.6757 (0.6441) loss_oracle 0.9948 (1.0254) acc 62.5000 (50.1215) lr 2.0000e-03 eta 0:31:31
epoch [2/50] batch [200/445] time 0.081 (0.087) data 0.000 (0.003) loss 2.6681 (2.9213) teacher_loss 1.2066 (1.3964) loss_zs_kd 0.5115 (0.6423) loss_oracle 0.9494 (1.0198) acc 56.2500 (50.8594) lr 2.0000e-03 eta 0:31:24
epoch [2/50] batch [220/445] time 0.086 (0.086) data 0.000 (0.003) loss 2.5971 (2.8945) teacher_loss 1.1140 (1.3765) loss_zs_kd 0.8233 (0.6447) loss_oracle 0.9560 (1.0146) acc 59.3750 (51.4205) lr 2.0000e-03 eta 0:31:02
epoch [2/50] batch [240/445] time 0.076 (0.086) data 0.000 (0.002) loss 2.8257 (2.8742) teacher_loss 1.3578 (1.3612) loss_zs_kd 0.7699 (0.6501) loss_oracle 0.9211 (1.0088) acc 43.7500 (51.8359) lr 2.0000e-03 eta 0:30:44
epoch [2/50] batch [260/445] time 0.086 (0.085) data 0.000 (0.002) loss 2.5087 (2.8535) teacher_loss 1.0537 (1.3467) loss_zs_kd 0.6516 (0.6499) loss_oracle 0.9525 (1.0039) acc 59.3750 (52.4279) lr 2.0000e-03 eta 0:30:27
epoch [2/50] batch [280/445] time 0.086 (0.085) data 0.000 (0.002) loss 2.4748 (2.8311) teacher_loss 1.0548 (1.3308) loss_zs_kd 0.5863 (0.6594) loss_oracle 0.9467 (0.9993) acc 62.5000 (53.1027) lr 2.0000e-03 eta 0:30:21
epoch [2/50] batch [300/445] time 0.086 (0.085) data 0.001 (0.002) loss 2.8578 (2.8123) teacher_loss 1.3559 (1.3167) loss_zs_kd 0.7743 (0.6674) loss_oracle 0.9663 (0.9957) acc 46.8750 (53.7604) lr 2.0000e-03 eta 0:30:19
epoch [2/50] batch [320/445] time 0.075 (0.084) data 0.000 (0.002) loss 2.6345 (2.8027) teacher_loss 1.1505 (1.3108) loss_zs_kd 0.7902 (0.6657) loss_oracle 0.9629 (0.9915) acc 65.6250 (54.0430) lr 2.0000e-03 eta 0:30:09
epoch [2/50] batch [340/445] time 0.081 (0.084) data 0.000 (0.002) loss 2.6024 (2.7894) teacher_loss 1.1645 (1.2995) loss_zs_kd 0.8584 (0.6686) loss_oracle 0.9430 (0.9892) acc 65.6250 (54.4945) lr 2.0000e-03 eta 0:30:03
epoch [2/50] batch [360/445] time 0.088 (0.084) data 0.000 (0.002) loss 2.2592 (2.7734) teacher_loss 0.8460 (1.2887) loss_zs_kd 0.9115 (0.6714) loss_oracle 0.9546 (0.9851) acc 78.1250 (54.9045) lr 2.0000e-03 eta 0:30:04
epoch [2/50] batch [380/445] time 0.090 (0.084) data 0.000 (0.002) loss 2.4353 (2.7563) teacher_loss 1.0198 (1.2765) loss_zs_kd 0.8316 (0.6761) loss_oracle 0.9215 (0.9818) acc 71.8750 (55.2878) lr 2.0000e-03 eta 0:30:04
epoch [2/50] batch [400/445] time 0.076 (0.084) data 0.000 (0.002) loss 2.2532 (2.7418) teacher_loss 0.8592 (1.2663) loss_zs_kd 0.7139 (0.6835) loss_oracle 0.9105 (0.9793) acc 71.8750 (55.7578) lr 2.0000e-03 eta 0:30:01
epoch [2/50] batch [420/445] time 0.083 (0.084) data 0.001 (0.002) loss 2.3587 (2.7295) teacher_loss 0.9882 (1.2592) loss_zs_kd 1.1494 (0.6986) loss_oracle 0.9383 (0.9760) acc 68.7500 (56.0119) lr 2.0000e-03 eta 0:29:54
epoch [2/50] batch [440/445] time 0.068 (0.084) data 0.000 (0.001) loss 2.8757 (2.7217) teacher_loss 1.5033 (1.2556) loss_zs_kd 0.8449 (0.7068) loss_oracle 0.9457 (0.9736) acc 43.7500 (56.1577) lr 2.0000e-03 eta 0:29:45
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,469
* accuracy: 56.8%
* error: 43.2%
* macro_f1: 39.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,817
* accuracy: 45.8%
* error: 54.2%
* macro_f1: 27.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      56.8%, epoch: 2 *******
******* Domain 3 best val test acc: 45.8%, epoch: 2 *******
******* Domain 3 best test acc:     45.8%, epoch: 2 *******
epoch [3/50] batch [20/445] time 0.081 (0.115) data 0.000 (0.030) loss 2.2538 (2.4758) teacher_loss 0.8394 (1.0972) loss_zs_kd 0.9399 (0.8355) loss_oracle 0.9036 (0.8999) acc 68.7500 (58.1250) lr 1.9980e-03 eta 0:40:50
epoch [3/50] batch [40/445] time 0.071 (0.096) data 0.000 (0.015) loss 2.4976 (2.4817) teacher_loss 1.1971 (1.1086) loss_zs_kd 1.1732 (0.8669) loss_oracle 0.8358 (0.9042) acc 59.3750 (60.3906) lr 1.9980e-03 eta 0:34:14
epoch [3/50] batch [60/445] time 0.071 (0.090) data 0.000 (0.010) loss 2.5492 (2.4651) teacher_loss 1.1470 (1.0864) loss_zs_kd 1.1270 (0.9031) loss_oracle 0.9073 (0.9051) acc 56.2500 (60.8333) lr 1.9980e-03 eta 0:31:52
epoch [3/50] batch [80/445] time 0.081 (0.088) data 0.000 (0.008) loss 2.4742 (2.4602) teacher_loss 1.0838 (1.0810) loss_zs_kd 1.0340 (0.9093) loss_oracle 0.9034 (0.9051) acc 75.0000 (61.4062) lr 1.9980e-03 eta 0:31:17
epoch [3/50] batch [100/445] time 0.087 (0.088) data 0.000 (0.006) loss 2.6078 (2.4603) teacher_loss 1.2031 (1.0803) loss_zs_kd 1.0548 (0.9248) loss_oracle 0.9066 (0.9061) acc 53.1250 (61.7188) lr 1.9980e-03 eta 0:31:04
epoch [3/50] batch [120/445] time 0.085 (0.087) data 0.000 (0.005) loss 2.1959 (2.4462) teacher_loss 0.9112 (1.0691) loss_zs_kd 1.1862 (0.9340) loss_oracle 0.8637 (0.9058) acc 68.7500 (62.3698) lr 1.9980e-03 eta 0:30:56
epoch [3/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.005) loss 2.8114 (2.4383) teacher_loss 1.4356 (1.0611) loss_zs_kd 1.3929 (0.9855) loss_oracle 0.9514 (0.9084) acc 56.2500 (62.9241) lr 1.9980e-03 eta 0:30:48
epoch [3/50] batch [160/445] time 0.078 (0.087) data 0.000 (0.004) loss 2.4072 (2.4408) teacher_loss 1.0685 (1.0663) loss_zs_kd 0.8055 (0.9788) loss_oracle 0.9358 (0.9089) acc 71.8750 (62.7539) lr 1.9980e-03 eta 0:30:36
epoch [3/50] batch [180/445] time 0.082 (0.086) data 0.000 (0.004) loss 2.4505 (2.4492) teacher_loss 1.1059 (1.0774) loss_zs_kd 0.9358 (0.9716) loss_oracle 0.9194 (0.9088) acc 59.3750 (62.2743) lr 1.9980e-03 eta 0:30:27
epoch [3/50] batch [200/445] time 0.126 (0.087) data 0.000 (0.003) loss 2.1400 (2.4396) teacher_loss 0.7646 (1.0688) loss_zs_kd 0.9838 (0.9682) loss_oracle 0.9357 (0.9095) acc 71.8750 (62.4375) lr 1.9980e-03 eta 0:30:51
epoch [3/50] batch [220/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.2387 (2.4226) teacher_loss 0.8406 (1.0526) loss_zs_kd 1.1531 (0.9753) loss_oracle 0.9219 (0.9100) acc 78.1250 (63.0824) lr 1.9980e-03 eta 0:30:48
epoch [3/50] batch [240/445] time 0.094 (0.087) data 0.000 (0.003) loss 2.2934 (2.4107) teacher_loss 0.9623 (1.0415) loss_zs_kd 1.0677 (0.9922) loss_oracle 0.9166 (0.9111) acc 65.6250 (63.6719) lr 1.9980e-03 eta 0:30:40
epoch [3/50] batch [260/445] time 0.086 (0.087) data 0.000 (0.003) loss 1.9426 (2.4120) teacher_loss 0.6429 (1.0453) loss_zs_kd 0.9675 (0.9873) loss_oracle 0.8477 (0.9100) acc 75.0000 (63.3053) lr 1.9980e-03 eta 0:30:29
epoch [3/50] batch [280/445] time 0.078 (0.086) data 0.000 (0.002) loss 2.3583 (2.4077) teacher_loss 1.0384 (1.0444) loss_zs_kd 1.0296 (0.9898) loss_oracle 0.9155 (0.9078) acc 65.6250 (63.2924) lr 1.9980e-03 eta 0:30:14
epoch [3/50] batch [300/445] time 0.076 (0.086) data 0.000 (0.002) loss 2.7023 (2.4066) teacher_loss 1.4001 (1.0467) loss_zs_kd 1.1597 (0.9943) loss_oracle 0.8835 (0.9067) acc 59.3750 (63.3438) lr 1.9980e-03 eta 0:30:03
epoch [3/50] batch [320/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.2199 (2.4076) teacher_loss 0.8776 (1.0499) loss_zs_kd 0.9931 (0.9992) loss_oracle 0.9180 (0.9059) acc 68.7500 (63.1250) lr 1.9980e-03 eta 0:29:55
epoch [3/50] batch [340/445] time 0.074 (0.085) data 0.000 (0.002) loss 2.6070 (2.4045) teacher_loss 1.3055 (1.0501) loss_zs_kd 0.8341 (1.0031) loss_oracle 0.8786 (0.9043) acc 53.1250 (63.1801) lr 1.9980e-03 eta 0:29:45
epoch [3/50] batch [360/445] time 0.073 (0.085) data 0.000 (0.002) loss 2.5522 (2.4026) teacher_loss 1.2235 (1.0512) loss_zs_kd 1.0453 (1.0026) loss_oracle 0.9287 (0.9037) acc 62.5000 (63.2378) lr 1.9980e-03 eta 0:29:37
epoch [3/50] batch [380/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.3859 (2.3959) teacher_loss 1.0684 (1.0470) loss_zs_kd 1.2537 (1.0108) loss_oracle 0.9165 (0.9031) acc 59.3750 (63.2812) lr 1.9980e-03 eta 0:29:35
epoch [3/50] batch [400/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.1358 (2.3906) teacher_loss 0.8517 (1.0449) loss_zs_kd 1.0300 (1.0153) loss_oracle 0.8530 (0.9014) acc 71.8750 (63.3516) lr 1.9980e-03 eta 0:29:32
epoch [3/50] batch [420/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.4225 (2.3885) teacher_loss 1.1559 (1.0450) loss_zs_kd 1.5828 (1.0308) loss_oracle 0.8648 (0.9008) acc 68.7500 (63.4077) lr 1.9980e-03 eta 0:29:24
epoch [3/50] batch [440/445] time 0.078 (0.084) data 0.000 (0.002) loss 2.5300 (2.3860) teacher_loss 1.2561 (1.0462) loss_zs_kd 1.0969 (1.0396) loss_oracle 0.8531 (0.8988) acc 53.1250 (63.3949) lr 1.9980e-03 eta 0:29:21
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,713
* accuracy: 60.8%
* error: 39.2%
* macro_f1: 47.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,710
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 27.9%
******* Domain 3 best val acc:      60.8%, epoch: 3 *******
******* Domain 3 best val test acc: 43.1%, epoch: 3 *******
******* Domain 3 best test acc:     45.8%, epoch: 2 *******
epoch [4/50] batch [20/445] time 0.077 (0.112) data 0.000 (0.028) loss 2.4834 (2.3655) teacher_loss 1.2141 (1.0945) loss_zs_kd 1.0265 (1.0842) loss_oracle 0.8733 (0.8646) acc 53.1250 (59.8438) lr 1.9921e-03 eta 0:38:59
epoch [4/50] batch [40/445] time 0.083 (0.099) data 0.000 (0.014) loss 2.3877 (2.3420) teacher_loss 1.1098 (1.0753) loss_zs_kd 0.9943 (1.0071) loss_oracle 0.8693 (0.8704) acc 56.2500 (60.3125) lr 1.9921e-03 eta 0:34:25
epoch [4/50] batch [60/445] time 0.082 (0.094) data 0.000 (0.009) loss 1.9406 (2.3267) teacher_loss 0.7116 (1.0607) loss_zs_kd 0.9454 (1.0102) loss_oracle 0.8825 (0.8724) acc 81.2500 (61.7188) lr 1.9921e-03 eta 0:32:32
epoch [4/50] batch [80/445] time 0.080 (0.090) data 0.000 (0.007) loss 2.1358 (2.3147) teacher_loss 0.8388 (1.0439) loss_zs_kd 0.9817 (0.9929) loss_oracle 0.8822 (0.8779) acc 71.8750 (62.1094) lr 1.9921e-03 eta 0:31:13
epoch [4/50] batch [100/445] time 0.079 (0.089) data 0.000 (0.006) loss 2.3612 (2.3138) teacher_loss 1.0968 (1.0408) loss_zs_kd 1.1110 (1.0057) loss_oracle 0.8921 (0.8777) acc 65.6250 (62.2812) lr 1.9921e-03 eta 0:30:43
epoch [4/50] batch [120/445] time 0.071 (0.087) data 0.000 (0.005) loss 1.9640 (2.2957) teacher_loss 0.6916 (1.0273) loss_zs_kd 1.3202 (1.0274) loss_oracle 0.8452 (0.8734) acc 78.1250 (63.1250) lr 1.9921e-03 eta 0:30:12
epoch [4/50] batch [140/445] time 0.080 (0.085) data 0.000 (0.004) loss 1.9719 (2.2877) teacher_loss 0.7195 (1.0213) loss_zs_kd 1.6235 (1.0717) loss_oracle 0.8566 (0.8722) acc 81.2500 (63.7946) lr 1.9921e-03 eta 0:29:32
epoch [4/50] batch [160/445] time 0.081 (0.085) data 0.000 (0.004) loss 2.1893 (2.2798) teacher_loss 0.9322 (1.0141) loss_zs_kd 1.4225 (1.1436) loss_oracle 0.9180 (0.8727) acc 65.6250 (64.0234) lr 1.9921e-03 eta 0:29:13
epoch [4/50] batch [180/445] time 0.072 (0.083) data 0.000 (0.003) loss 2.4450 (2.2865) teacher_loss 1.1381 (1.0190) loss_zs_kd 0.9529 (1.1517) loss_oracle 0.9206 (0.8776) acc 56.2500 (63.9757) lr 1.9921e-03 eta 0:28:50
epoch [4/50] batch [200/445] time 0.086 (0.083) data 0.000 (0.003) loss 2.3079 (2.2912) teacher_loss 1.0199 (1.0234) loss_zs_kd 1.1021 (1.1380) loss_oracle 0.8851 (0.8777) acc 53.1250 (63.7812) lr 1.9921e-03 eta 0:28:44
epoch [4/50] batch [220/445] time 0.085 (0.082) data 0.000 (0.003) loss 2.0129 (2.2835) teacher_loss 0.8589 (1.0156) loss_zs_kd 0.9467 (1.1242) loss_oracle 0.8121 (0.8784) acc 71.8750 (64.1619) lr 1.9921e-03 eta 0:28:21
epoch [4/50] batch [240/445] time 0.078 (0.082) data 0.000 (0.003) loss 2.5921 (2.2794) teacher_loss 1.2543 (1.0117) loss_zs_kd 1.1397 (1.1157) loss_oracle 0.9503 (0.8804) acc 50.0000 (64.2969) lr 1.9921e-03 eta 0:28:14
epoch [4/50] batch [260/445] time 0.078 (0.081) data 0.000 (0.002) loss 2.1626 (2.2795) teacher_loss 0.8817 (1.0112) loss_zs_kd 1.0843 (1.1169) loss_oracle 0.8758 (0.8800) acc 59.3750 (64.2067) lr 1.9921e-03 eta 0:28:03
epoch [4/50] batch [280/445] time 0.077 (0.081) data 0.000 (0.002) loss 2.5278 (2.2721) teacher_loss 1.2165 (1.0045) loss_zs_kd 1.2241 (1.1299) loss_oracle 0.9078 (0.8782) acc 59.3750 (64.6205) lr 1.9921e-03 eta 0:27:47
epoch [4/50] batch [300/445] time 0.064 (0.080) data 0.000 (0.002) loss 2.1228 (2.2680) teacher_loss 0.8854 (1.0008) loss_zs_kd 1.2466 (1.1278) loss_oracle 0.8180 (0.8774) acc 65.6250 (64.8854) lr 1.9921e-03 eta 0:27:31
epoch [4/50] batch [320/445] time 0.091 (0.080) data 0.000 (0.002) loss 2.1362 (2.2689) teacher_loss 0.9284 (1.0017) loss_zs_kd 1.2531 (1.1314) loss_oracle 0.8220 (0.8770) acc 71.8750 (64.8633) lr 1.9921e-03 eta 0:27:29
epoch [4/50] batch [340/445] time 0.091 (0.080) data 0.000 (0.002) loss 2.3317 (2.2626) teacher_loss 1.0702 (0.9962) loss_zs_kd 2.2319 (1.1722) loss_oracle 0.8841 (0.8758) acc 59.3750 (65.1379) lr 1.9921e-03 eta 0:27:31
epoch [4/50] batch [360/445] time 0.079 (0.081) data 0.000 (0.002) loss 2.3539 (2.2609) teacher_loss 1.1194 (0.9946) loss_zs_kd 2.4329 (1.2349) loss_oracle 0.8251 (0.8756) acc 59.3750 (65.2257) lr 1.9921e-03 eta 0:27:49
epoch [4/50] batch [380/445] time 0.083 (0.081) data 0.000 (0.002) loss 1.8613 (2.2531) teacher_loss 0.6786 (0.9880) loss_zs_kd 0.9650 (1.2603) loss_oracle 0.8153 (0.8739) acc 84.3750 (65.5181) lr 1.9921e-03 eta 0:27:46
epoch [4/50] batch [400/445] time 0.080 (0.081) data 0.000 (0.002) loss 2.2939 (2.2519) teacher_loss 1.0474 (0.9877) loss_zs_kd 1.3591 (1.2500) loss_oracle 0.8604 (0.8733) acc 65.6250 (65.5234) lr 1.9921e-03 eta 0:27:50
epoch [4/50] batch [420/445] time 0.095 (0.082) data 0.000 (0.002) loss 2.1475 (2.2455) teacher_loss 0.9284 (0.9832) loss_zs_kd 1.1902 (1.2458) loss_oracle 0.8633 (0.8725) acc 68.7500 (65.7738) lr 1.9921e-03 eta 0:27:54
epoch [4/50] batch [440/445] time 0.071 (0.082) data 0.000 (0.002) loss 2.1488 (2.2483) teacher_loss 0.9224 (0.9866) loss_zs_kd 1.0429 (1.2410) loss_oracle 0.9005 (0.8732) acc 68.7500 (65.5966) lr 1.9921e-03 eta 0:27:52
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,682
* accuracy: 60.3%
* error: 39.7%
* macro_f1: 47.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,559
* accuracy: 39.3%
* error: 60.7%
* macro_f1: 24.6%
******* Domain 3 best val acc:      60.8%, epoch: 3 *******
******* Domain 3 best val test acc: 43.1%, epoch: 3 *******
******* Domain 3 best test acc:     45.8%, epoch: 2 *******
epoch [5/50] batch [20/445] time 0.084 (0.117) data 0.000 (0.035) loss 2.0995 (2.3662) teacher_loss 0.8340 (1.1040) loss_zs_kd 1.2217 (0.9770) loss_oracle 0.8975 (0.9097) acc 75.0000 (60.7812) lr 1.9823e-03 eta 0:39:55
epoch [5/50] batch [40/445] time 0.075 (0.099) data 0.000 (0.018) loss 2.0621 (2.2774) teacher_loss 0.8737 (1.0385) loss_zs_kd 1.1247 (1.0008) loss_oracle 0.8598 (0.8887) acc 65.6250 (62.8125) lr 1.9823e-03 eta 0:33:48
epoch [5/50] batch [60/445] time 0.082 (0.094) data 0.000 (0.012) loss 2.4936 (2.2512) teacher_loss 1.2254 (1.0092) loss_zs_kd 1.0452 (1.0130) loss_oracle 0.8935 (0.8883) acc 62.5000 (63.5938) lr 1.9823e-03 eta 0:31:55
epoch [5/50] batch [80/445] time 0.084 (0.091) data 0.000 (0.009) loss 2.2562 (2.2602) teacher_loss 0.9545 (1.0115) loss_zs_kd 1.0806 (1.0161) loss_oracle 0.9380 (0.8916) acc 62.5000 (64.0625) lr 1.9823e-03 eta 0:30:51
epoch [5/50] batch [100/445] time 0.079 (0.092) data 0.000 (0.007) loss 2.2244 (2.2544) teacher_loss 0.9315 (1.0001) loss_zs_kd 1.1850 (1.0154) loss_oracle 0.9084 (0.8951) acc 59.3750 (64.3750) lr 1.9823e-03 eta 0:31:19
epoch [5/50] batch [120/445] time 0.086 (0.091) data 0.000 (0.006) loss 2.1663 (2.2377) teacher_loss 0.9121 (0.9851) loss_zs_kd 1.2050 (1.0511) loss_oracle 0.8101 (0.8912) acc 68.7500 (65.2604) lr 1.9823e-03 eta 0:30:52
epoch [5/50] batch [140/445] time 0.089 (0.090) data 0.000 (0.005) loss 2.1035 (2.2369) teacher_loss 0.9241 (0.9833) loss_zs_kd 1.0917 (1.0797) loss_oracle 0.7905 (0.8907) acc 62.5000 (65.4018) lr 1.9823e-03 eta 0:30:35
epoch [5/50] batch [160/445] time 0.079 (0.088) data 0.000 (0.005) loss 1.8746 (2.2278) teacher_loss 0.6684 (0.9762) loss_zs_kd 1.4556 (1.1124) loss_oracle 0.8645 (0.8871) acc 78.1250 (65.7812) lr 1.9823e-03 eta 0:29:57
epoch [5/50] batch [180/445] time 0.075 (0.087) data 0.000 (0.004) loss 1.9179 (2.2220) teacher_loss 0.7151 (0.9718) loss_zs_kd 1.2943 (1.1396) loss_oracle 0.8266 (0.8831) acc 71.8750 (66.1806) lr 1.9823e-03 eta 0:29:16
epoch [5/50] batch [200/445] time 0.081 (0.084) data 0.000 (0.004) loss 2.2007 (2.2143) teacher_loss 0.9916 (0.9658) loss_zs_kd 0.9911 (1.1446) loss_oracle 0.8225 (0.8800) acc 75.0000 (66.5156) lr 1.9823e-03 eta 0:28:30
epoch [5/50] batch [220/445] time 0.085 (0.084) data 0.001 (0.003) loss 1.9110 (2.2151) teacher_loss 0.7241 (0.9689) loss_zs_kd 0.8559 (1.1474) loss_oracle 0.7309 (0.8777) acc 71.8750 (66.5199) lr 1.9823e-03 eta 0:28:29
epoch [5/50] batch [240/445] time 0.092 (0.084) data 0.001 (0.003) loss 2.1338 (2.2140) teacher_loss 0.9906 (0.9709) loss_zs_kd 0.8467 (1.1378) loss_oracle 0.8142 (0.8730) acc 68.7500 (66.4323) lr 1.9823e-03 eta 0:28:28
epoch [5/50] batch [260/445] time 0.081 (0.084) data 0.000 (0.003) loss 2.4594 (2.2130) teacher_loss 1.2494 (0.9728) loss_zs_kd 0.9738 (1.1275) loss_oracle 0.8109 (0.8695) acc 53.1250 (66.3341) lr 1.9823e-03 eta 0:28:21
epoch [5/50] batch [280/445] time 0.081 (0.084) data 0.000 (0.003) loss 2.2341 (2.2140) teacher_loss 1.0504 (0.9767) loss_zs_kd 1.3150 (1.1276) loss_oracle 0.7679 (0.8660) acc 62.5000 (66.1607) lr 1.9823e-03 eta 0:28:19
epoch [5/50] batch [300/445] time 0.082 (0.084) data 0.000 (0.003) loss 2.0760 (2.2229) teacher_loss 0.8665 (0.9872) loss_zs_kd 0.9338 (1.1247) loss_oracle 0.8094 (0.8646) acc 75.0000 (65.7708) lr 1.9823e-03 eta 0:28:11
epoch [5/50] batch [320/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.0704 (2.2251) teacher_loss 0.8887 (0.9905) loss_zs_kd 0.9849 (1.1236) loss_oracle 0.7931 (0.8643) acc 62.5000 (65.6250) lr 1.9823e-03 eta 0:28:11
epoch [5/50] batch [340/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.3785 (2.2303) teacher_loss 1.1411 (0.9956) loss_zs_kd 0.9452 (1.1147) loss_oracle 0.9059 (0.8651) acc 62.5000 (65.4136) lr 1.9823e-03 eta 0:28:04
epoch [5/50] batch [360/445] time 0.086 (0.084) data 0.000 (0.002) loss 2.1015 (2.2298) teacher_loss 0.9186 (0.9953) loss_zs_kd 1.2233 (1.1107) loss_oracle 0.7791 (0.8642) acc 71.8750 (65.5122) lr 1.9823e-03 eta 0:28:03
epoch [5/50] batch [380/445] time 0.079 (0.083) data 0.000 (0.002) loss 1.8857 (2.2236) teacher_loss 0.6530 (0.9887) loss_zs_kd 1.2622 (1.1123) loss_oracle 0.8930 (0.8646) acc 81.2500 (65.8470) lr 1.9823e-03 eta 0:27:56
epoch [5/50] batch [400/445] time 0.077 (0.083) data 0.000 (0.002) loss 2.1806 (2.2252) teacher_loss 0.9549 (0.9904) loss_zs_kd 0.9409 (1.1114) loss_oracle 0.8308 (0.8644) acc 65.6250 (65.7109) lr 1.9823e-03 eta 0:27:48
epoch [5/50] batch [420/445] time 0.084 (0.083) data 0.000 (0.002) loss 2.1345 (2.2240) teacher_loss 0.9463 (0.9897) loss_zs_kd 1.3122 (1.1190) loss_oracle 0.8229 (0.8637) acc 75.0000 (65.7961) lr 1.9823e-03 eta 0:27:46
epoch [5/50] batch [440/445] time 0.077 (0.083) data 0.000 (0.002) loss 2.6300 (2.2222) teacher_loss 1.3197 (0.9878) loss_zs_kd 1.0696 (1.1211) loss_oracle 0.9206 (0.8629) acc 56.2500 (65.8878) lr 1.9823e-03 eta 0:27:41
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,075
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 51.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,858
* accuracy: 46.8%
* error: 53.2%
* macro_f1: 28.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      66.7%, epoch: 5 *******
******* Domain 3 best val test acc: 46.8%, epoch: 5 *******
******* Domain 3 best test acc:     46.8%, epoch: 5 *******
epoch [6/50] batch [20/445] time 0.069 (0.117) data 0.000 (0.030) loss 2.1014 (2.2691) teacher_loss 0.9538 (1.0568) loss_zs_kd 1.0483 (1.0945) loss_oracle 0.7616 (0.8233) acc 71.8750 (64.6875) lr 1.9686e-03 eta 0:38:56
epoch [6/50] batch [40/445] time 0.087 (0.100) data 0.000 (0.015) loss 1.9735 (2.2593) teacher_loss 0.7864 (1.0534) loss_zs_kd 0.8977 (1.1100) loss_oracle 0.7994 (0.8254) acc 71.8750 (63.9844) lr 1.9686e-03 eta 0:33:18
epoch [6/50] batch [60/445] time 0.086 (0.094) data 0.001 (0.010) loss 2.2819 (2.2142) teacher_loss 1.0851 (0.9991) loss_zs_kd 1.1191 (1.1059) loss_oracle 0.8362 (0.8351) acc 56.2500 (65.2083) lr 1.9686e-03 eta 0:31:11
epoch [6/50] batch [80/445] time 0.084 (0.091) data 0.000 (0.008) loss 2.1401 (2.2126) teacher_loss 0.8971 (0.9964) loss_zs_kd 1.1794 (1.1139) loss_oracle 0.8694 (0.8371) acc 68.7500 (65.4688) lr 1.9686e-03 eta 0:30:23
epoch [6/50] batch [100/445] time 0.086 (0.090) data 0.000 (0.006) loss 2.2076 (2.2203) teacher_loss 1.0125 (1.0024) loss_zs_kd 1.2286 (1.1197) loss_oracle 0.8782 (0.8394) acc 62.5000 (65.6250) lr 1.9686e-03 eta 0:30:00
epoch [6/50] batch [120/445] time 0.081 (0.089) data 0.000 (0.005) loss 2.2313 (2.2223) teacher_loss 0.9479 (0.9995) loss_zs_kd 1.0259 (1.1033) loss_oracle 0.8980 (0.8446) acc 62.5000 (65.5729) lr 1.9686e-03 eta 0:29:31
epoch [6/50] batch [140/445] time 0.080 (0.088) data 0.000 (0.004) loss 1.8910 (2.2089) teacher_loss 0.6645 (0.9806) loss_zs_kd 1.0995 (1.0971) loss_oracle 0.8217 (0.8503) acc 71.8750 (66.1607) lr 1.9686e-03 eta 0:29:12
epoch [6/50] batch [160/445] time 0.081 (0.088) data 0.000 (0.004) loss 2.0457 (2.1938) teacher_loss 0.8950 (0.9670) loss_zs_kd 0.9589 (1.0965) loss_oracle 0.8201 (0.8487) acc 68.7500 (66.8555) lr 1.9686e-03 eta 0:29:05
epoch [6/50] batch [180/445] time 0.076 (0.087) data 0.000 (0.004) loss 2.2582 (2.1926) teacher_loss 1.0599 (0.9660) loss_zs_kd 1.1137 (1.0945) loss_oracle 0.8887 (0.8481) acc 65.6250 (66.8924) lr 1.9686e-03 eta 0:28:40
epoch [6/50] batch [200/445] time 0.071 (0.086) data 0.000 (0.003) loss 1.9087 (2.1890) teacher_loss 0.6811 (0.9613) loss_zs_kd 1.1058 (1.0956) loss_oracle 0.8674 (0.8501) acc 75.0000 (66.8906) lr 1.9686e-03 eta 0:28:19
epoch [6/50] batch [220/445] time 0.075 (0.085) data 0.000 (0.003) loss 2.2112 (2.1885) teacher_loss 1.0011 (0.9616) loss_zs_kd 1.1275 (1.0951) loss_oracle 0.8502 (0.8500) acc 68.7500 (66.8466) lr 1.9686e-03 eta 0:28:02
epoch [6/50] batch [240/445] time 0.074 (0.086) data 0.000 (0.003) loss 2.1504 (2.1928) teacher_loss 0.9033 (0.9672) loss_zs_kd 1.1668 (1.1007) loss_oracle 0.8635 (0.8496) acc 68.7500 (66.3802) lr 1.9686e-03 eta 0:28:20
epoch [6/50] batch [260/445] time 0.092 (0.086) data 0.000 (0.003) loss 2.4164 (2.1916) teacher_loss 1.1732 (0.9657) loss_zs_kd 1.0053 (1.0962) loss_oracle 0.8891 (0.8507) acc 50.0000 (66.4062) lr 1.9686e-03 eta 0:28:23
epoch [6/50] batch [280/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.3132 (2.1911) teacher_loss 1.0393 (0.9646) loss_zs_kd 1.2244 (1.0992) loss_oracle 0.8934 (0.8515) acc 68.7500 (66.2835) lr 1.9686e-03 eta 0:28:12
epoch [6/50] batch [300/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.5980 (2.1984) teacher_loss 1.2891 (0.9726) loss_zs_kd 0.9429 (1.0917) loss_oracle 0.9100 (0.8511) acc 50.0000 (66.0000) lr 1.9686e-03 eta 0:28:08
epoch [6/50] batch [320/445] time 0.093 (0.086) data 0.000 (0.002) loss 2.2382 (2.1992) teacher_loss 0.9702 (0.9735) loss_zs_kd 1.1535 (1.0871) loss_oracle 0.8740 (0.8511) acc 62.5000 (65.9277) lr 1.9686e-03 eta 0:28:07
epoch [6/50] batch [340/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.2560 (2.1997) teacher_loss 0.9755 (0.9709) loss_zs_kd 1.0754 (1.0882) loss_oracle 0.8636 (0.8528) acc 65.6250 (65.9651) lr 1.9686e-03 eta 0:28:03
epoch [6/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.3051 (2.2015) teacher_loss 1.0377 (0.9714) loss_zs_kd 1.0878 (1.0942) loss_oracle 0.8952 (0.8533) acc 56.2500 (65.9549) lr 1.9686e-03 eta 0:28:03
epoch [6/50] batch [380/445] time 0.088 (0.085) data 0.000 (0.002) loss 2.2876 (2.1998) teacher_loss 1.0645 (0.9707) loss_zs_kd 1.1217 (1.0973) loss_oracle 0.8830 (0.8519) acc 65.6250 (66.0444) lr 1.9686e-03 eta 0:27:57
epoch [6/50] batch [400/445] time 0.087 (0.085) data 0.000 (0.002) loss 2.3291 (2.1991) teacher_loss 1.1262 (0.9718) loss_zs_kd 1.2803 (1.1007) loss_oracle 0.8257 (0.8500) acc 56.2500 (65.9609) lr 1.9686e-03 eta 0:27:54
epoch [6/50] batch [420/445] time 0.091 (0.085) data 0.000 (0.002) loss 2.3205 (2.1988) teacher_loss 1.0747 (0.9715) loss_zs_kd 1.1601 (1.1057) loss_oracle 0.8601 (0.8504) acc 62.5000 (65.9747) lr 1.9686e-03 eta 0:27:53
epoch [6/50] batch [440/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.3094 (2.1991) teacher_loss 1.1154 (0.9724) loss_zs_kd 1.2508 (1.1087) loss_oracle 0.8320 (0.8493) acc 56.2500 (65.9659) lr 1.9686e-03 eta 0:27:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,827
* accuracy: 62.7%
* error: 37.3%
* macro_f1: 47.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,629
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 24.2%
******* Domain 3 best val acc:      66.7%, epoch: 5 *******
******* Domain 3 best val test acc: 46.8%, epoch: 5 *******
******* Domain 3 best test acc:     46.8%, epoch: 5 *******
epoch [7/50] batch [20/445] time 0.079 (0.110) data 0.000 (0.026) loss 2.3373 (2.1716) teacher_loss 1.1096 (0.9654) loss_zs_kd 1.1646 (1.1010) loss_oracle 0.8113 (0.8039) acc 59.3750 (68.1250) lr 1.9511e-03 eta 0:35:54
epoch [7/50] batch [40/445] time 0.083 (0.096) data 0.000 (0.013) loss 2.2502 (2.1936) teacher_loss 1.0577 (1.0051) loss_zs_kd 1.0097 (1.0431) loss_oracle 0.7725 (0.7958) acc 65.6250 (66.7188) lr 1.9511e-03 eta 0:31:15
epoch [7/50] batch [60/445] time 0.080 (0.092) data 0.000 (0.009) loss 2.0689 (2.1590) teacher_loss 0.8637 (0.9695) loss_zs_kd 1.0022 (1.0293) loss_oracle 0.8098 (0.8019) acc 81.2500 (67.5521) lr 1.9511e-03 eta 0:29:50
epoch [7/50] batch [80/445] time 0.076 (0.089) data 0.000 (0.007) loss 2.0299 (2.1593) teacher_loss 0.8308 (0.9674) loss_zs_kd 1.3302 (1.0536) loss_oracle 0.7708 (0.8002) acc 71.8750 (67.1875) lr 1.9511e-03 eta 0:28:47
epoch [7/50] batch [100/445] time 0.091 (0.087) data 0.000 (0.005) loss 2.5790 (2.1728) teacher_loss 1.3429 (0.9750) loss_zs_kd 0.9969 (1.0814) loss_oracle 0.7930 (0.8060) acc 46.8750 (66.1562) lr 1.9511e-03 eta 0:28:18
epoch [7/50] batch [120/445] time 0.081 (0.087) data 0.000 (0.005) loss 2.1897 (2.1807) teacher_loss 1.0240 (0.9820) loss_zs_kd 1.1307 (1.1054) loss_oracle 0.7932 (0.8058) acc 68.7500 (65.9375) lr 1.9511e-03 eta 0:28:04
epoch [7/50] batch [140/445] time 0.093 (0.086) data 0.000 (0.004) loss 1.8339 (2.1751) teacher_loss 0.6572 (0.9764) loss_zs_kd 1.2730 (1.1141) loss_oracle 0.8023 (0.8073) acc 75.0000 (65.9375) lr 1.9511e-03 eta 0:28:00
epoch [7/50] batch [160/445] time 0.084 (0.086) data 0.000 (0.004) loss 2.1632 (2.1719) teacher_loss 1.0118 (0.9746) loss_zs_kd 1.3029 (1.1206) loss_oracle 0.7719 (0.8066) acc 56.2500 (65.7812) lr 1.9511e-03 eta 0:27:54
epoch [7/50] batch [180/445] time 0.080 (0.086) data 0.000 (0.003) loss 2.5120 (2.1650) teacher_loss 1.3318 (0.9712) loss_zs_kd 1.0395 (1.1215) loss_oracle 0.8166 (0.8052) acc 46.8750 (65.6771) lr 1.9511e-03 eta 0:27:45
epoch [7/50] batch [200/445] time 0.075 (0.085) data 0.000 (0.003) loss 2.3824 (2.1690) teacher_loss 1.1909 (0.9755) loss_zs_kd 1.3167 (1.1298) loss_oracle 0.8175 (0.8061) acc 46.8750 (65.3906) lr 1.9511e-03 eta 0:27:33
epoch [7/50] batch [220/445] time 0.075 (0.085) data 0.000 (0.003) loss 2.2501 (2.1699) teacher_loss 1.0618 (0.9777) loss_zs_kd 0.9282 (1.1156) loss_oracle 0.8357 (0.8073) acc 68.7500 (65.2557) lr 1.9511e-03 eta 0:27:23
epoch [7/50] batch [240/445] time 0.087 (0.085) data 0.000 (0.002) loss 2.4787 (2.1719) teacher_loss 1.2721 (0.9793) loss_zs_kd 0.9939 (1.1099) loss_oracle 0.8932 (0.8099) acc 62.5000 (65.1693) lr 1.9511e-03 eta 0:27:18
epoch [7/50] batch [260/445] time 0.089 (0.085) data 0.000 (0.002) loss 2.0240 (2.1712) teacher_loss 0.8833 (0.9787) loss_zs_kd 0.9716 (1.0986) loss_oracle 0.8014 (0.8103) acc 62.5000 (65.3606) lr 1.9511e-03 eta 0:27:14
epoch [7/50] batch [280/445] time 0.086 (0.084) data 0.000 (0.002) loss 2.3579 (2.1688) teacher_loss 1.1937 (0.9775) loss_zs_kd 0.9059 (1.0961) loss_oracle 0.7909 (0.8101) acc 59.3750 (65.3906) lr 1.9511e-03 eta 0:27:09
epoch [7/50] batch [300/445] time 0.079 (0.084) data 0.000 (0.002) loss 2.1978 (2.1661) teacher_loss 1.0224 (0.9747) loss_zs_kd 1.2391 (1.0988) loss_oracle 0.7750 (0.8101) acc 68.7500 (65.5729) lr 1.9511e-03 eta 0:27:01
epoch [7/50] batch [320/445] time 0.083 (0.084) data 0.000 (0.002) loss 1.6301 (2.1603) teacher_loss 0.4699 (0.9694) loss_zs_kd 0.9095 (1.0942) loss_oracle 0.7701 (0.8099) acc 87.5000 (65.7617) lr 1.9511e-03 eta 0:26:56
epoch [7/50] batch [340/445] time 0.090 (0.084) data 0.000 (0.002) loss 1.9414 (2.1592) teacher_loss 0.8477 (0.9707) loss_zs_kd 0.9398 (1.0924) loss_oracle 0.8098 (0.8099) acc 71.8750 (65.7169) lr 1.9511e-03 eta 0:26:54
epoch [7/50] batch [360/445] time 0.136 (0.085) data 0.000 (0.002) loss 2.2555 (2.1603) teacher_loss 1.1333 (0.9734) loss_zs_kd 1.1564 (1.0930) loss_oracle 0.7755 (0.8100) acc 56.2500 (65.5816) lr 1.9511e-03 eta 0:27:09
epoch [7/50] batch [380/445] time 0.088 (0.085) data 0.000 (0.002) loss 1.9501 (2.1517) teacher_loss 0.7787 (0.9651) loss_zs_kd 1.3194 (1.1026) loss_oracle 0.8088 (0.8102) acc 68.7500 (65.9539) lr 1.9511e-03 eta 0:27:02
epoch [7/50] batch [400/445] time 0.077 (0.084) data 0.000 (0.002) loss 2.2357 (2.1485) teacher_loss 0.9584 (0.9609) loss_zs_kd 1.3212 (1.1086) loss_oracle 0.9113 (0.8119) acc 71.8750 (66.2344) lr 1.9511e-03 eta 0:26:58
epoch [7/50] batch [420/445] time 0.077 (0.084) data 0.000 (0.002) loss 1.9305 (2.1441) teacher_loss 0.7587 (0.9568) loss_zs_kd 1.3572 (1.1210) loss_oracle 0.7881 (0.8124) acc 75.0000 (66.4211) lr 1.9511e-03 eta 0:26:51
epoch [7/50] batch [440/445] time 0.077 (0.084) data 0.000 (0.001) loss 2.3338 (2.1412) teacher_loss 1.1742 (0.9530) loss_zs_kd 1.2201 (1.1375) loss_oracle 0.8174 (0.8137) acc 56.2500 (66.5128) lr 1.9511e-03 eta 0:26:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,051
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 50.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,902
* accuracy: 47.9%
* error: 52.1%
* macro_f1: 30.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      66.7%, epoch: 5 *******
******* Domain 3 best val test acc: 46.8%, epoch: 5 *******
******* Domain 3 best test acc:     47.9%, epoch: 7 *******
epoch [8/50] batch [20/445] time 0.084 (0.115) data 0.000 (0.025) loss 1.9184 (2.1273) teacher_loss 0.7623 (0.9160) loss_zs_kd 1.1284 (1.1209) loss_oracle 0.8305 (0.8517) acc 68.7500 (66.4062) lr 1.9298e-03 eta 0:36:46
epoch [8/50] batch [40/445] time 0.078 (0.097) data 0.000 (0.013) loss 1.6026 (2.0917) teacher_loss 0.4166 (0.8917) loss_zs_kd 1.2969 (1.1682) loss_oracle 0.8148 (0.8458) acc 93.7500 (68.2031) lr 1.9298e-03 eta 0:30:45
epoch [8/50] batch [60/445] time 0.084 (0.092) data 0.001 (0.009) loss 2.0147 (2.0830) teacher_loss 0.8773 (0.8978) loss_zs_kd 1.0773 (1.1710) loss_oracle 0.8245 (0.8411) acc 71.8750 (68.6979) lr 1.9298e-03 eta 0:29:16
epoch [8/50] batch [80/445] time 0.084 (0.091) data 0.000 (0.007) loss 2.4426 (2.1152) teacher_loss 1.1266 (0.9259) loss_zs_kd 1.0086 (1.1508) loss_oracle 0.9704 (0.8474) acc 50.0000 (68.0078) lr 1.9298e-03 eta 0:28:45
epoch [8/50] batch [100/445] time 0.080 (0.093) data 0.001 (0.005) loss 2.4342 (2.1265) teacher_loss 1.2402 (0.9260) loss_zs_kd 0.9457 (1.1229) loss_oracle 0.8205 (0.8503) acc 62.5000 (67.9062) lr 1.9298e-03 eta 0:29:30
epoch [8/50] batch [120/445] time 0.077 (0.090) data 0.000 (0.004) loss 2.0385 (2.1284) teacher_loss 0.8661 (0.9282) loss_zs_kd 1.0776 (1.1101) loss_oracle 0.8420 (0.8505) acc 71.8750 (67.9688) lr 1.9298e-03 eta 0:28:37
epoch [8/50] batch [140/445] time 0.096 (0.089) data 0.001 (0.004) loss 2.0095 (2.1264) teacher_loss 0.8549 (0.9274) loss_zs_kd 1.1050 (1.1055) loss_oracle 0.7644 (0.8503) acc 62.5000 (68.2143) lr 1.9298e-03 eta 0:28:09
epoch [8/50] batch [160/445] time 0.077 (0.088) data 0.000 (0.003) loss 1.8890 (2.1156) teacher_loss 0.7644 (0.9240) loss_zs_kd 1.0332 (1.1188) loss_oracle 0.7666 (0.8429) acc 68.7500 (68.1641) lr 1.9298e-03 eta 0:27:55
epoch [8/50] batch [180/445] time 0.090 (0.088) data 0.000 (0.003) loss 1.9103 (2.1080) teacher_loss 0.8578 (0.9235) loss_zs_kd 0.9266 (1.1211) loss_oracle 0.7667 (0.8376) acc 62.5000 (68.3507) lr 1.9298e-03 eta 0:27:45
epoch [8/50] batch [200/445] time 0.080 (0.087) data 0.000 (0.003) loss 2.2089 (2.1103) teacher_loss 0.9990 (0.9273) loss_zs_kd 1.0348 (1.1211) loss_oracle 0.7977 (0.8354) acc 59.3750 (68.1406) lr 1.9298e-03 eta 0:27:35
epoch [8/50] batch [220/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.9196 (2.1089) teacher_loss 0.8049 (0.9312) loss_zs_kd 1.0575 (1.1229) loss_oracle 0.7278 (0.8306) acc 68.7500 (67.9830) lr 1.9298e-03 eta 0:27:23
epoch [8/50] batch [240/445] time 0.079 (0.087) data 0.000 (0.002) loss 2.3927 (2.1063) teacher_loss 1.2183 (0.9336) loss_zs_kd 0.9533 (1.1312) loss_oracle 0.8623 (0.8277) acc 56.2500 (68.0339) lr 1.9298e-03 eta 0:27:14
epoch [8/50] batch [260/445] time 0.086 (0.086) data 0.000 (0.002) loss 2.0474 (2.1022) teacher_loss 0.8722 (0.9331) loss_zs_kd 1.2141 (1.1327) loss_oracle 0.7355 (0.8241) acc 68.7500 (68.0529) lr 1.9298e-03 eta 0:27:05
epoch [8/50] batch [280/445] time 0.079 (0.086) data 0.000 (0.002) loss 1.8871 (2.0955) teacher_loss 0.6424 (0.9289) loss_zs_kd 1.2954 (1.1377) loss_oracle 0.8837 (0.8232) acc 81.2500 (68.0804) lr 1.9298e-03 eta 0:27:03
epoch [8/50] batch [300/445] time 0.075 (0.086) data 0.000 (0.002) loss 1.9041 (2.0935) teacher_loss 0.7418 (0.9278) loss_zs_kd 1.6580 (1.1534) loss_oracle 0.8996 (0.8237) acc 78.1250 (68.1042) lr 1.9298e-03 eta 0:26:55
epoch [8/50] batch [320/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.2419 (2.0893) teacher_loss 1.0325 (0.9270) loss_zs_kd 1.2121 (1.1642) loss_oracle 0.7902 (0.8232) acc 65.6250 (68.1934) lr 1.9298e-03 eta 0:26:49
epoch [8/50] batch [340/445] time 0.084 (0.085) data 0.001 (0.002) loss 1.8401 (2.0881) teacher_loss 0.7135 (0.9275) loss_zs_kd 1.0846 (1.1666) loss_oracle 0.7959 (0.8220) acc 75.0000 (68.1710) lr 1.9298e-03 eta 0:26:44
epoch [8/50] batch [360/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.1491 (2.0888) teacher_loss 0.9340 (0.9275) loss_zs_kd 1.3064 (1.1734) loss_oracle 0.9118 (0.8226) acc 62.5000 (68.1510) lr 1.9298e-03 eta 0:26:35
epoch [8/50] batch [380/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.2068 (2.0892) teacher_loss 0.9592 (0.9254) loss_zs_kd 1.4194 (1.1798) loss_oracle 0.9331 (0.8268) acc 68.7500 (68.1579) lr 1.9298e-03 eta 0:26:29
epoch [8/50] batch [400/445] time 0.088 (0.085) data 0.000 (0.002) loss 1.8221 (2.0893) teacher_loss 0.5826 (0.9231) loss_zs_kd 1.5857 (1.1872) loss_oracle 0.9068 (0.8303) acc 84.3750 (68.2188) lr 1.9298e-03 eta 0:26:25
epoch [8/50] batch [420/445] time 0.082 (0.085) data 0.000 (0.001) loss 2.1411 (2.0910) teacher_loss 0.8796 (0.9226) loss_zs_kd 1.4412 (1.1982) loss_oracle 0.9376 (0.8339) acc 65.6250 (68.3408) lr 1.9298e-03 eta 0:26:24
epoch [8/50] batch [440/445] time 0.079 (0.084) data 0.001 (0.001) loss 1.8212 (2.0914) teacher_loss 0.7406 (0.9246) loss_zs_kd 1.2778 (1.1966) loss_oracle 0.8212 (0.8335) acc 68.7500 (68.2528) lr 1.9298e-03 eta 0:26:16
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,740
* accuracy: 61.2%
* error: 38.8%
* macro_f1: 49.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,515
* accuracy: 38.2%
* error: 61.8%
* macro_f1: 23.1%
******* Domain 3 best val acc:      66.7%, epoch: 5 *******
******* Domain 3 best val test acc: 46.8%, epoch: 5 *******
******* Domain 3 best test acc:     47.9%, epoch: 7 *******
epoch [9/50] batch [20/445] time 0.077 (0.098) data 0.000 (0.027) loss 1.9977 (2.0949) teacher_loss 0.8937 (0.9811) loss_zs_kd 1.0851 (1.1623) loss_oracle 0.8841 (0.8088) acc 68.7500 (65.7812) lr 1.9048e-03 eta 0:30:30
epoch [9/50] batch [40/445] time 0.087 (0.091) data 0.000 (0.014) loss 2.0248 (2.0800) teacher_loss 0.9431 (0.9589) loss_zs_kd 1.0109 (1.1156) loss_oracle 0.7670 (0.8222) acc 68.7500 (67.8125) lr 1.9048e-03 eta 0:28:10
epoch [9/50] batch [60/445] time 0.096 (0.088) data 0.001 (0.009) loss 2.0460 (2.1047) teacher_loss 0.8491 (0.9616) loss_zs_kd 1.2201 (1.1076) loss_oracle 0.7952 (0.8341) acc 68.7500 (67.3438) lr 1.9048e-03 eta 0:27:12
epoch [9/50] batch [80/445] time 0.086 (0.086) data 0.000 (0.007) loss 2.3528 (2.1363) teacher_loss 0.9919 (0.9748) loss_zs_kd 1.3323 (1.1051) loss_oracle 0.9674 (0.8441) acc 68.7500 (66.8750) lr 1.9048e-03 eta 0:26:44
epoch [9/50] batch [100/445] time 0.085 (0.086) data 0.000 (0.006) loss 1.9308 (2.1362) teacher_loss 0.8137 (0.9708) loss_zs_kd 1.2250 (1.1133) loss_oracle 0.8266 (0.8489) acc 75.0000 (67.0625) lr 1.9048e-03 eta 0:26:30
epoch [9/50] batch [120/445] time 0.072 (0.085) data 0.000 (0.005) loss 2.0854 (2.1249) teacher_loss 1.0005 (0.9604) loss_zs_kd 1.0445 (1.1200) loss_oracle 0.7971 (0.8506) acc 62.5000 (67.4479) lr 1.9048e-03 eta 0:26:18
epoch [9/50] batch [140/445] time 0.094 (0.084) data 0.000 (0.004) loss 2.0921 (2.1172) teacher_loss 0.9553 (0.9532) loss_zs_kd 1.2236 (1.1138) loss_oracle 0.8306 (0.8533) acc 59.3750 (67.4330) lr 1.9048e-03 eta 0:26:03
epoch [9/50] batch [160/445] time 0.080 (0.084) data 0.000 (0.004) loss 2.2727 (2.1225) teacher_loss 1.1092 (0.9556) loss_zs_kd 1.0374 (1.1104) loss_oracle 0.9701 (0.8582) acc 62.5000 (67.0508) lr 1.9048e-03 eta 0:25:56
epoch [9/50] batch [180/445] time 0.080 (0.084) data 0.000 (0.003) loss 2.0482 (2.1175) teacher_loss 0.8420 (0.9512) loss_zs_kd 1.3380 (1.1049) loss_oracle 0.8912 (0.8599) acc 65.6250 (67.0139) lr 1.9048e-03 eta 0:25:57
epoch [9/50] batch [200/445] time 0.080 (0.084) data 0.000 (0.003) loss 1.8843 (2.1184) teacher_loss 0.7540 (0.9516) loss_zs_kd 1.2660 (1.1105) loss_oracle 0.8206 (0.8614) acc 75.0000 (67.0625) lr 1.9048e-03 eta 0:25:58
epoch [9/50] batch [220/445] time 0.093 (0.084) data 0.000 (0.003) loss 1.9803 (2.1138) teacher_loss 0.8559 (0.9489) loss_zs_kd 1.0807 (1.1179) loss_oracle 0.8689 (0.8606) acc 62.5000 (67.1449) lr 1.9048e-03 eta 0:25:58
epoch [9/50] batch [240/445] time 0.122 (0.085) data 0.001 (0.003) loss 2.3387 (2.1273) teacher_loss 1.0645 (0.9583) loss_zs_kd 1.2868 (1.1243) loss_oracle 0.9691 (0.8642) acc 68.7500 (66.8880) lr 1.9048e-03 eta 0:26:14
epoch [9/50] batch [260/445] time 0.077 (0.085) data 0.000 (0.002) loss 2.1308 (2.1301) teacher_loss 0.7960 (0.9561) loss_zs_kd 1.6169 (1.1446) loss_oracle 0.9180 (0.8696) acc 84.3750 (67.0192) lr 1.9048e-03 eta 0:26:07
epoch [9/50] batch [280/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.0440 (2.1317) teacher_loss 0.8493 (0.9524) loss_zs_kd 0.8724 (1.1588) loss_oracle 0.8363 (0.8747) acc 75.0000 (67.0982) lr 1.9048e-03 eta 0:25:59
epoch [9/50] batch [300/445] time 0.077 (0.085) data 0.000 (0.002) loss 2.3339 (2.1391) teacher_loss 0.9476 (0.9503) loss_zs_kd 1.1852 (1.1608) loss_oracle 1.0483 (0.8798) acc 68.7500 (67.0417) lr 1.9048e-03 eta 0:25:59
epoch [9/50] batch [320/445] time 0.080 (0.085) data 0.000 (0.002) loss 2.2484 (2.1454) teacher_loss 0.9872 (0.9501) loss_zs_kd 1.0191 (1.1692) loss_oracle 0.9422 (0.8866) acc 53.1250 (67.0508) lr 1.9048e-03 eta 0:25:55
epoch [9/50] batch [340/445] time 0.087 (0.084) data 0.001 (0.002) loss 1.8971 (2.1440) teacher_loss 0.7017 (0.9486) loss_zs_kd 1.2196 (1.1682) loss_oracle 0.8877 (0.8902) acc 75.0000 (67.0404) lr 1.9048e-03 eta 0:25:50
epoch [9/50] batch [360/445] time 0.083 (0.084) data 0.000 (0.002) loss 2.3419 (2.1429) teacher_loss 1.1619 (0.9471) loss_zs_kd 0.9845 (1.1646) loss_oracle 0.9665 (0.8918) acc 62.5000 (67.0226) lr 1.9048e-03 eta 0:25:48
epoch [9/50] batch [380/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.0892 (2.1419) teacher_loss 0.9361 (0.9468) loss_zs_kd 1.7730 (1.1689) loss_oracle 0.8245 (0.8912) acc 68.7500 (67.0559) lr 1.9048e-03 eta 0:25:45
epoch [9/50] batch [400/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.3390 (2.1425) teacher_loss 1.1500 (0.9479) loss_zs_kd 1.1908 (1.1753) loss_oracle 0.8522 (0.8899) acc 62.5000 (66.9688) lr 1.9048e-03 eta 0:25:43
epoch [9/50] batch [420/445] time 0.083 (0.084) data 0.000 (0.002) loss 1.9624 (2.1429) teacher_loss 0.8891 (0.9503) loss_zs_kd 1.1696 (1.1712) loss_oracle 0.8076 (0.8876) acc 71.8750 (66.9122) lr 1.9048e-03 eta 0:25:43
epoch [9/50] batch [440/445] time 0.074 (0.084) data 0.000 (0.002) loss 2.0090 (2.1405) teacher_loss 0.7747 (0.9504) loss_zs_kd 1.3079 (1.1735) loss_oracle 0.9670 (0.8853) acc 75.0000 (66.8111) lr 1.9048e-03 eta 0:25:37
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,089
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 51.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,946
* accuracy: 49.0%
* error: 51.0%
* macro_f1: 29.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      66.9%, epoch: 9 *******
******* Domain 3 best val test acc: 49.0%, epoch: 9 *******
******* Domain 3 best test acc:     49.0%, epoch: 9 *******
epoch [10/50] batch [20/445] time 0.085 (0.115) data 0.000 (0.027) loss 2.0591 (2.0237) teacher_loss 0.8304 (0.8734) loss_zs_kd 1.1914 (1.2886) loss_oracle 0.8660 (0.8494) acc 68.7500 (69.6875) lr 1.8763e-03 eta 0:34:57
epoch [10/50] batch [40/445] time 0.082 (0.099) data 0.000 (0.014) loss 2.0132 (2.0637) teacher_loss 0.8268 (0.8989) loss_zs_kd 1.5032 (1.2849) loss_oracle 0.8137 (0.8520) acc 68.7500 (69.1406) lr 1.8763e-03 eta 0:29:54
epoch [10/50] batch [60/445] time 0.081 (0.092) data 0.000 (0.009) loss 1.7874 (2.0876) teacher_loss 0.6227 (0.9187) loss_zs_kd 0.9047 (1.2701) loss_oracle 0.7700 (0.8412) acc 81.2500 (68.9062) lr 1.8763e-03 eta 0:27:58
epoch [10/50] batch [80/445] time 0.086 (0.090) data 0.000 (0.007) loss 2.3961 (2.0803) teacher_loss 1.2764 (0.9261) loss_zs_kd 1.1645 (1.2689) loss_oracle 0.8194 (0.8286) acc 59.3750 (68.2031) lr 1.8763e-03 eta 0:27:16
epoch [10/50] batch [100/445] time 0.083 (0.088) data 0.000 (0.006) loss 1.6653 (2.0707) teacher_loss 0.6320 (0.9251) loss_zs_kd 1.2475 (1.2695) loss_oracle 0.7377 (0.8209) acc 75.0000 (67.7812) lr 1.8763e-03 eta 0:26:32
epoch [10/50] batch [120/445] time 0.080 (0.087) data 0.000 (0.005) loss 2.0591 (2.0696) teacher_loss 0.9351 (0.9298) loss_zs_kd 1.1054 (1.2424) loss_oracle 0.8091 (0.8204) acc 65.6250 (67.2656) lr 1.8763e-03 eta 0:26:16
epoch [10/50] batch [140/445] time 0.083 (0.087) data 0.000 (0.004) loss 1.8740 (2.0653) teacher_loss 0.8488 (0.9299) loss_zs_kd 1.4714 (1.2398) loss_oracle 0.7415 (0.8152) acc 75.0000 (67.2545) lr 1.8763e-03 eta 0:26:06
epoch [10/50] batch [160/445] time 0.090 (0.086) data 0.000 (0.004) loss 1.9073 (2.0534) teacher_loss 0.7956 (0.9266) loss_zs_kd 1.5214 (1.2490) loss_oracle 0.7972 (0.8086) acc 75.0000 (67.6953) lr 1.8763e-03 eta 0:25:51
epoch [10/50] batch [180/445] time 0.081 (0.085) data 0.000 (0.003) loss 2.5012 (2.0613) teacher_loss 1.3351 (0.9364) loss_zs_kd 1.0584 (1.2481) loss_oracle 0.8291 (0.8069) acc 65.6250 (67.2917) lr 1.8763e-03 eta 0:25:42
epoch [10/50] batch [200/445] time 0.084 (0.085) data 0.000 (0.003) loss 1.9489 (2.0592) teacher_loss 0.8234 (0.9358) loss_zs_kd 1.1730 (1.2493) loss_oracle 0.8845 (0.8090) acc 65.6250 (67.2500) lr 1.8763e-03 eta 0:25:31
epoch [10/50] batch [220/445] time 0.080 (0.084) data 0.000 (0.003) loss 1.8627 (2.0598) teacher_loss 0.7988 (0.9398) loss_zs_kd 1.2882 (1.2421) loss_oracle 0.7351 (0.8078) acc 68.7500 (66.8466) lr 1.8763e-03 eta 0:25:17
epoch [10/50] batch [240/445] time 0.081 (0.084) data 0.000 (0.003) loss 1.9497 (2.0567) teacher_loss 0.9394 (0.9413) loss_zs_kd 1.2720 (1.2329) loss_oracle 0.7150 (0.8046) acc 71.8750 (66.9531) lr 1.8763e-03 eta 0:25:05
epoch [10/50] batch [260/445] time 0.080 (0.084) data 0.000 (0.002) loss 1.8805 (2.0482) teacher_loss 0.8458 (0.9377) loss_zs_kd 1.0990 (1.2285) loss_oracle 0.7543 (0.8019) acc 65.6250 (67.1154) lr 1.8763e-03 eta 0:25:02
epoch [10/50] batch [280/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.4601 (2.0471) teacher_loss 1.1413 (0.9368) loss_zs_kd 1.1797 (1.2200) loss_oracle 1.0024 (0.8036) acc 46.8750 (67.0312) lr 1.8763e-03 eta 0:25:03
epoch [10/50] batch [300/445] time 0.078 (0.084) data 0.000 (0.002) loss 1.9064 (2.0427) teacher_loss 0.7438 (0.9282) loss_zs_kd 1.3048 (1.2178) loss_oracle 0.8705 (0.8073) acc 71.8750 (67.3125) lr 1.8763e-03 eta 0:25:02
epoch [10/50] batch [320/445] time 0.080 (0.083) data 0.000 (0.002) loss 1.6726 (2.0411) teacher_loss 0.6112 (0.9244) loss_zs_kd 1.4218 (1.2241) loss_oracle 0.7446 (0.8099) acc 75.0000 (67.5195) lr 1.8763e-03 eta 0:24:56
epoch [10/50] batch [340/445] time 0.083 (0.083) data 0.000 (0.002) loss 1.7077 (2.0439) teacher_loss 0.5809 (0.9282) loss_zs_kd 1.2242 (1.2281) loss_oracle 0.7744 (0.8092) acc 78.1250 (67.4173) lr 1.8763e-03 eta 0:24:53
epoch [10/50] batch [360/445] time 0.134 (0.084) data 0.001 (0.002) loss 2.0250 (2.0448) teacher_loss 0.8952 (0.9299) loss_zs_kd 0.8743 (1.2248) loss_oracle 0.7863 (0.8087) acc 71.8750 (67.3351) lr 1.8763e-03 eta 0:25:01
epoch [10/50] batch [380/445] time 0.071 (0.084) data 0.000 (0.002) loss 1.8528 (2.0476) teacher_loss 0.7130 (0.9296) loss_zs_kd 1.2632 (1.2203) loss_oracle 0.7819 (0.8110) acc 84.3750 (67.3109) lr 1.8763e-03 eta 0:24:58
epoch [10/50] batch [400/445] time 0.084 (0.084) data 0.000 (0.002) loss 1.9191 (2.0488) teacher_loss 0.7880 (0.9265) loss_zs_kd 1.1529 (1.2176) loss_oracle 0.8629 (0.8153) acc 68.7500 (67.3516) lr 1.8763e-03 eta 0:24:51
epoch [10/50] batch [420/445] time 0.077 (0.083) data 0.000 (0.002) loss 2.2658 (2.0519) teacher_loss 1.1004 (0.9266) loss_zs_kd 1.4523 (1.2177) loss_oracle 0.9699 (0.8180) acc 50.0000 (67.3065) lr 1.8763e-03 eta 0:24:46
epoch [10/50] batch [440/445] time 0.076 (0.083) data 0.000 (0.001) loss 2.0309 (2.0521) teacher_loss 0.9101 (0.9277) loss_zs_kd 1.2630 (1.2179) loss_oracle 0.8185 (0.8173) acc 65.6250 (67.2798) lr 1.8763e-03 eta 0:24:43
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,159
* accuracy: 68.1%
* error: 31.9%
* macro_f1: 53.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,972
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 31.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [11/50] batch [20/445] time 0.073 (0.114) data 0.000 (0.031) loss 2.1427 (2.0488) teacher_loss 1.0549 (0.9619) loss_zs_kd 1.1508 (1.1362) loss_oracle 0.7990 (0.7913) acc 53.1250 (65.0000) lr 1.8443e-03 eta 0:33:38
epoch [11/50] batch [40/445] time 0.086 (0.097) data 0.000 (0.015) loss 2.4390 (2.0407) teacher_loss 1.2011 (0.9191) loss_zs_kd 1.2454 (1.1609) loss_oracle 0.9536 (0.8199) acc 59.3750 (67.8125) lr 1.8443e-03 eta 0:28:38
epoch [11/50] batch [60/445] time 0.087 (0.093) data 0.000 (0.010) loss 2.3729 (2.1145) teacher_loss 0.8602 (0.9388) loss_zs_kd 1.3663 (1.1763) loss_oracle 0.9907 (0.8419) acc 65.6250 (66.7188) lr 1.8443e-03 eta 0:27:32
epoch [11/50] batch [80/445] time 0.084 (0.090) data 0.000 (0.008) loss 2.2129 (2.1830) teacher_loss 0.8445 (0.9377) loss_zs_kd 1.2433 (1.1765) loss_oracle 1.0219 (0.8670) acc 71.8750 (66.8359) lr 1.8443e-03 eta 0:26:37
epoch [11/50] batch [100/445] time 0.075 (0.092) data 0.000 (0.006) loss 1.9467 (2.1972) teacher_loss 0.6128 (0.9322) loss_zs_kd 1.1092 (1.1832) loss_oracle 0.8691 (0.8819) acc 81.2500 (67.1875) lr 1.8443e-03 eta 0:27:06
epoch [11/50] batch [120/445] time 0.085 (0.090) data 0.000 (0.005) loss 2.3115 (2.1904) teacher_loss 1.1119 (0.9312) loss_zs_kd 1.2966 (1.2019) loss_oracle 0.8544 (0.8805) acc 53.1250 (67.1875) lr 1.8443e-03 eta 0:26:27
epoch [11/50] batch [140/445] time 0.084 (0.089) data 0.000 (0.005) loss 2.1175 (2.1805) teacher_loss 0.9544 (0.9288) loss_zs_kd 1.2243 (1.2085) loss_oracle 0.7876 (0.8773) acc 62.5000 (67.2991) lr 1.8443e-03 eta 0:26:04
epoch [11/50] batch [160/445] time 0.082 (0.088) data 0.000 (0.004) loss 2.0482 (2.1809) teacher_loss 0.8473 (0.9318) loss_zs_kd 1.2432 (1.2255) loss_oracle 0.8979 (0.8759) acc 75.0000 (67.2266) lr 1.8443e-03 eta 0:25:46
epoch [11/50] batch [180/445] time 0.071 (0.086) data 0.000 (0.004) loss 2.0170 (2.1757) teacher_loss 0.9068 (0.9321) loss_zs_kd 1.2658 (1.2358) loss_oracle 0.8404 (0.8785) acc 62.5000 (67.2569) lr 1.8443e-03 eta 0:25:11
epoch [11/50] batch [200/445] time 0.087 (0.085) data 0.000 (0.003) loss 2.1172 (2.1596) teacher_loss 0.9102 (0.9283) loss_zs_kd 1.4748 (1.2424) loss_oracle 0.8162 (0.8731) acc 68.7500 (67.2656) lr 1.8443e-03 eta 0:24:56
epoch [11/50] batch [220/445] time 0.078 (0.085) data 0.000 (0.003) loss 1.7034 (2.1497) teacher_loss 0.5515 (0.9245) loss_zs_kd 1.4163 (1.2543) loss_oracle 0.7782 (0.8676) acc 84.3750 (67.4716) lr 1.8443e-03 eta 0:24:52
epoch [11/50] batch [240/445] time 0.082 (0.085) data 0.000 (0.003) loss 1.8232 (2.1496) teacher_loss 0.7652 (0.9257) loss_zs_kd 0.9750 (1.2642) loss_oracle 0.7590 (0.8643) acc 75.0000 (67.6823) lr 1.8443e-03 eta 0:24:46
epoch [11/50] batch [260/445] time 0.087 (0.085) data 0.000 (0.003) loss 1.7901 (2.1464) teacher_loss 0.7139 (0.9313) loss_zs_kd 1.2138 (1.2538) loss_oracle 0.7542 (0.8610) acc 65.6250 (67.5481) lr 1.8443e-03 eta 0:24:44
epoch [11/50] batch [280/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.4889 (2.1477) teacher_loss 1.3128 (0.9389) loss_zs_kd 1.0660 (1.2357) loss_oracle 0.8508 (0.8591) acc 46.8750 (67.1763) lr 1.8443e-03 eta 0:24:41
epoch [11/50] batch [300/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.0686 (2.1475) teacher_loss 0.9116 (0.9415) loss_zs_kd 1.1326 (1.2195) loss_oracle 0.8629 (0.8541) acc 71.8750 (67.0729) lr 1.8443e-03 eta 0:24:38
epoch [11/50] batch [320/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.1160 (2.1471) teacher_loss 0.8976 (0.9422) loss_zs_kd 1.1135 (1.2056) loss_oracle 0.8490 (0.8509) acc 78.1250 (67.1582) lr 1.8443e-03 eta 0:24:36
epoch [11/50] batch [340/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.6921 (2.1564) teacher_loss 1.1248 (0.9430) loss_zs_kd 1.1032 (1.2065) loss_oracle 0.9913 (0.8522) acc 71.8750 (66.9853) lr 1.8443e-03 eta 0:24:33
epoch [11/50] batch [360/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.3900 (2.1721) teacher_loss 1.0192 (0.9425) loss_zs_kd 1.4825 (1.2090) loss_oracle 0.9389 (0.8608) acc 62.5000 (66.9792) lr 1.8443e-03 eta 0:24:33
epoch [11/50] batch [380/445] time 0.083 (0.084) data 0.000 (0.002) loss 2.1463 (2.1791) teacher_loss 0.8432 (0.9411) loss_zs_kd 1.0338 (1.2092) loss_oracle 0.8526 (0.8633) acc 78.1250 (67.0066) lr 1.8443e-03 eta 0:24:29
epoch [11/50] batch [400/445] time 0.086 (0.084) data 0.000 (0.002) loss 2.5737 (2.1783) teacher_loss 1.3818 (0.9387) loss_zs_kd 1.0667 (1.2093) loss_oracle 0.8047 (0.8625) acc 59.3750 (67.0625) lr 1.8443e-03 eta 0:24:24
epoch [11/50] batch [420/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.1480 (2.1782) teacher_loss 0.9985 (0.9424) loss_zs_kd 0.9534 (1.2060) loss_oracle 0.9398 (0.8645) acc 68.7500 (66.9271) lr 1.8443e-03 eta 0:24:24
epoch [11/50] batch [440/445] time 0.076 (0.084) data 0.000 (0.002) loss 1.9509 (2.1760) teacher_loss 0.8191 (0.9435) loss_zs_kd 0.9914 (1.2027) loss_oracle 0.8141 (0.8657) acc 65.6250 (66.9318) lr 1.8443e-03 eta 0:24:21
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,810
* accuracy: 62.4%
* error: 37.6%
* macro_f1: 48.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,699
* accuracy: 42.8%
* error: 57.2%
* macro_f1: 25.8%
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [12/50] batch [20/445] time 0.065 (0.104) data 0.000 (0.026) loss 2.3006 (2.2628) teacher_loss 1.0195 (0.9961) loss_zs_kd 1.2269 (1.2145) loss_oracle 0.9083 (0.8859) acc 59.3750 (64.8438) lr 1.8090e-03 eta 0:30:11
epoch [12/50] batch [40/445] time 0.074 (0.093) data 0.000 (0.013) loss 2.0399 (2.2488) teacher_loss 0.8712 (1.0093) loss_zs_kd 1.1053 (1.2451) loss_oracle 0.8506 (0.8993) acc 68.7500 (63.9844) lr 1.8090e-03 eta 0:26:46
epoch [12/50] batch [60/445] time 0.079 (0.089) data 0.000 (0.009) loss 1.9952 (2.2069) teacher_loss 0.8688 (0.9992) loss_zs_kd 0.9797 (1.2091) loss_oracle 0.8397 (0.8874) acc 65.6250 (64.2188) lr 1.8090e-03 eta 0:25:40
epoch [12/50] batch [80/445] time 0.075 (0.086) data 0.000 (0.007) loss 2.1473 (2.2027) teacher_loss 0.8914 (0.9987) loss_zs_kd 0.8875 (1.1848) loss_oracle 0.8635 (0.8805) acc 62.5000 (64.4531) lr 1.8090e-03 eta 0:24:43
epoch [12/50] batch [100/445] time 0.081 (0.084) data 0.000 (0.005) loss 2.3886 (2.2005) teacher_loss 1.1656 (0.9948) loss_zs_kd 1.1814 (1.1938) loss_oracle 0.9327 (0.8847) acc 71.8750 (65.0625) lr 1.8090e-03 eta 0:24:09
epoch [12/50] batch [120/445] time 0.074 (0.083) data 0.000 (0.005) loss 2.3483 (2.1895) teacher_loss 1.2569 (0.9962) loss_zs_kd 1.0111 (1.1644) loss_oracle 0.8396 (0.8831) acc 46.8750 (65.0781) lr 1.8090e-03 eta 0:23:51
epoch [12/50] batch [140/445] time 0.086 (0.083) data 0.000 (0.004) loss 2.0321 (2.1832) teacher_loss 0.9027 (0.9971) loss_zs_kd 1.1415 (1.1446) loss_oracle 0.8537 (0.8816) acc 68.7500 (65.0000) lr 1.8090e-03 eta 0:23:48
epoch [12/50] batch [160/445] time 0.084 (0.083) data 0.000 (0.003) loss 2.3137 (2.1777) teacher_loss 1.0276 (0.9886) loss_zs_kd 1.4662 (1.1411) loss_oracle 1.0192 (0.8824) acc 62.5000 (65.3516) lr 1.8090e-03 eta 0:23:43
epoch [12/50] batch [180/445] time 0.088 (0.083) data 0.000 (0.003) loss 1.9534 (2.1724) teacher_loss 0.8443 (0.9872) loss_zs_kd 1.0291 (1.1436) loss_oracle 0.8852 (0.8837) acc 65.6250 (65.2778) lr 1.8090e-03 eta 0:23:40
epoch [12/50] batch [200/445] time 0.085 (0.083) data 0.000 (0.003) loss 1.9014 (2.1689) teacher_loss 0.6689 (0.9850) loss_zs_kd 1.0904 (1.1372) loss_oracle 0.9674 (0.8861) acc 71.8750 (65.3750) lr 1.8090e-03 eta 0:23:42
epoch [12/50] batch [220/445] time 0.082 (0.083) data 0.000 (0.003) loss 2.1239 (2.1677) teacher_loss 0.9030 (0.9814) loss_zs_kd 0.8273 (1.1395) loss_oracle 0.9155 (0.8902) acc 75.0000 (65.5256) lr 1.8090e-03 eta 0:23:44
epoch [12/50] batch [240/445] time 0.140 (0.084) data 0.001 (0.002) loss 2.3426 (2.1699) teacher_loss 1.1100 (0.9791) loss_zs_kd 1.1796 (1.1374) loss_oracle 0.9459 (0.8983) acc 62.5000 (65.4688) lr 1.8090e-03 eta 0:23:56
epoch [12/50] batch [260/445] time 0.086 (0.084) data 0.000 (0.002) loss 2.2494 (2.1686) teacher_loss 1.0552 (0.9783) loss_zs_kd 0.9341 (1.1331) loss_oracle 0.8844 (0.9002) acc 71.8750 (65.5409) lr 1.8090e-03 eta 0:24:02
epoch [12/50] batch [280/445] time 0.086 (0.084) data 0.000 (0.002) loss 2.3938 (2.1659) teacher_loss 0.9475 (0.9733) loss_zs_kd 1.0442 (1.1282) loss_oracle 0.9980 (0.9005) acc 59.3750 (65.6138) lr 1.8090e-03 eta 0:23:55
epoch [12/50] batch [300/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.3039 (2.1672) teacher_loss 1.1156 (0.9707) loss_zs_kd 1.1581 (1.1352) loss_oracle 0.8585 (0.9012) acc 65.6250 (65.7083) lr 1.8090e-03 eta 0:23:49
epoch [12/50] batch [320/445] time 0.088 (0.084) data 0.000 (0.002) loss 1.9362 (2.1672) teacher_loss 0.7646 (0.9713) loss_zs_kd 1.3418 (1.1387) loss_oracle 0.9863 (0.9009) acc 75.0000 (65.5762) lr 1.8090e-03 eta 0:23:49
epoch [12/50] batch [340/445] time 0.089 (0.084) data 0.000 (0.002) loss 2.2649 (2.1632) teacher_loss 1.1161 (0.9674) loss_zs_kd 0.9412 (1.1438) loss_oracle 0.8590 (0.9016) acc 62.5000 (65.7445) lr 1.8090e-03 eta 0:23:44
epoch [12/50] batch [360/445] time 0.071 (0.083) data 0.000 (0.002) loss 1.8956 (2.1647) teacher_loss 0.7897 (0.9693) loss_zs_kd 1.0446 (1.1471) loss_oracle 0.7851 (0.9000) acc 71.8750 (65.7031) lr 1.8090e-03 eta 0:23:36
epoch [12/50] batch [380/445] time 0.083 (0.083) data 0.000 (0.002) loss 1.9123 (2.1644) teacher_loss 0.7439 (0.9686) loss_zs_kd 1.0940 (1.1519) loss_oracle 0.8485 (0.8999) acc 71.8750 (65.6990) lr 1.8090e-03 eta 0:23:30
epoch [12/50] batch [400/445] time 0.094 (0.083) data 0.000 (0.002) loss 2.3474 (2.1662) teacher_loss 1.0257 (0.9697) loss_zs_kd 1.3413 (1.1575) loss_oracle 0.9530 (0.9006) acc 62.5000 (65.7969) lr 1.8090e-03 eta 0:23:27
epoch [12/50] batch [420/445] time 0.087 (0.083) data 0.000 (0.001) loss 1.9397 (2.1624) teacher_loss 0.7701 (0.9666) loss_zs_kd 1.2047 (1.1595) loss_oracle 0.8596 (0.9001) acc 65.6250 (65.9301) lr 1.8090e-03 eta 0:23:27
epoch [12/50] batch [440/445] time 0.082 (0.083) data 0.000 (0.001) loss 2.5210 (2.1608) teacher_loss 1.2576 (0.9653) loss_zs_kd 1.1469 (1.1606) loss_oracle 0.9643 (0.9006) acc 56.2500 (65.9446) lr 1.8090e-03 eta 0:23:25
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,041
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 50.0%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,836
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 26.9%
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [13/50] batch [20/445] time 0.077 (0.105) data 0.000 (0.023) loss 2.3163 (2.0960) teacher_loss 0.9663 (0.8441) loss_zs_kd 1.4809 (1.2905) loss_oracle 0.9517 (0.9158) acc 68.7500 (70.4688) lr 1.7705e-03 eta 0:29:31
epoch [13/50] batch [40/445] time 0.080 (0.091) data 0.000 (0.012) loss 2.0478 (2.1349) teacher_loss 0.9152 (0.8851) loss_zs_kd 1.1844 (1.2743) loss_oracle 0.8076 (0.9224) acc 68.7500 (68.6719) lr 1.7705e-03 eta 0:25:38
epoch [13/50] batch [60/445] time 0.077 (0.087) data 0.000 (0.008) loss 2.1575 (2.1300) teacher_loss 0.9087 (0.8941) loss_zs_kd 1.1796 (1.2843) loss_oracle 0.9958 (0.9276) acc 68.7500 (69.0625) lr 1.7705e-03 eta 0:24:24
epoch [13/50] batch [80/445] time 0.083 (0.085) data 0.000 (0.006) loss 2.3823 (2.1577) teacher_loss 1.0842 (0.9102) loss_zs_kd 1.5737 (1.2723) loss_oracle 0.9715 (0.9318) acc 68.7500 (68.0469) lr 1.7705e-03 eta 0:23:45
epoch [13/50] batch [100/445] time 0.080 (0.085) data 0.000 (0.005) loss 2.4200 (2.1960) teacher_loss 1.1618 (0.9332) loss_zs_kd 1.5868 (1.3120) loss_oracle 0.9380 (0.9487) acc 59.3750 (67.1562) lr 1.7705e-03 eta 0:23:42
epoch [13/50] batch [120/445] time 0.080 (0.084) data 0.001 (0.004) loss 2.2447 (2.1985) teacher_loss 0.9326 (0.9358) loss_zs_kd 1.2795 (1.3036) loss_oracle 0.9441 (0.9553) acc 71.8750 (67.1615) lr 1.7705e-03 eta 0:23:24
epoch [13/50] batch [140/445] time 0.081 (0.083) data 0.000 (0.004) loss 2.1548 (2.1992) teacher_loss 0.8243 (0.9287) loss_zs_kd 1.1271 (1.3064) loss_oracle 1.0205 (0.9556) acc 71.8750 (67.2321) lr 1.7705e-03 eta 0:23:16
epoch [13/50] batch [160/445] time 0.089 (0.083) data 0.000 (0.003) loss 2.3850 (2.1926) teacher_loss 1.2096 (0.9271) loss_zs_kd 0.8738 (1.2961) loss_oracle 0.8459 (0.9470) acc 53.1250 (67.0898) lr 1.7705e-03 eta 0:23:06
epoch [13/50] batch [180/445] time 0.085 (0.083) data 0.000 (0.003) loss 2.4444 (2.1884) teacher_loss 0.9871 (0.9241) loss_zs_kd 1.8736 (1.3109) loss_oracle 0.9724 (0.9409) acc 62.5000 (67.1354) lr 1.7705e-03 eta 0:23:07
epoch [13/50] batch [200/445] time 0.077 (0.083) data 0.000 (0.003) loss 2.0641 (2.1949) teacher_loss 0.8765 (0.9317) loss_zs_kd 1.4753 (1.3176) loss_oracle 0.8411 (0.9331) acc 71.8750 (67.0938) lr 1.7705e-03 eta 0:23:02
epoch [13/50] batch [220/445] time 0.076 (0.082) data 0.000 (0.002) loss 2.3899 (2.1897) teacher_loss 1.0588 (0.9314) loss_zs_kd 1.3201 (1.3323) loss_oracle 0.8661 (0.9214) acc 62.5000 (67.0739) lr 1.7705e-03 eta 0:22:53
epoch [13/50] batch [240/445] time 0.091 (0.082) data 0.000 (0.002) loss 2.0828 (2.1799) teacher_loss 0.8120 (0.9239) loss_zs_kd 1.6607 (1.3452) loss_oracle 0.8717 (0.9121) acc 68.7500 (67.4870) lr 1.7705e-03 eta 0:22:55
epoch [13/50] batch [260/445] time 0.089 (0.083) data 0.000 (0.002) loss 1.9296 (2.1746) teacher_loss 0.7918 (0.9199) loss_zs_kd 1.4198 (1.3540) loss_oracle 0.7561 (0.9046) acc 78.1250 (67.6923) lr 1.7705e-03 eta 0:22:54
epoch [13/50] batch [280/445] time 0.090 (0.083) data 0.000 (0.002) loss 2.1239 (2.1801) teacher_loss 0.8979 (0.9210) loss_zs_kd 1.3286 (1.3544) loss_oracle 0.8876 (0.9032) acc 71.8750 (67.7232) lr 1.7705e-03 eta 0:22:56
epoch [13/50] batch [300/445] time 0.085 (0.083) data 0.000 (0.002) loss 2.1686 (2.1800) teacher_loss 0.8888 (0.9231) loss_zs_kd 1.2419 (1.3529) loss_oracle 0.8845 (0.8975) acc 68.7500 (67.7500) lr 1.7705e-03 eta 0:22:56
epoch [13/50] batch [320/445] time 0.081 (0.083) data 0.000 (0.002) loss 2.2444 (2.1716) teacher_loss 1.1096 (0.9205) loss_zs_kd 1.3831 (1.3562) loss_oracle 0.7830 (0.8911) acc 53.1250 (67.8027) lr 1.7705e-03 eta 0:22:54
epoch [13/50] batch [340/445] time 0.077 (0.083) data 0.000 (0.002) loss 2.0323 (2.1683) teacher_loss 0.7408 (0.9216) loss_zs_kd 1.1510 (1.3488) loss_oracle 0.8705 (0.8855) acc 78.1250 (67.7665) lr 1.7705e-03 eta 0:22:53
epoch [13/50] batch [360/445] time 0.074 (0.083) data 0.000 (0.002) loss 2.3001 (2.1641) teacher_loss 1.0460 (0.9214) loss_zs_kd 1.2036 (1.3377) loss_oracle 0.8511 (0.8805) acc 75.0000 (67.8125) lr 1.7705e-03 eta 0:22:48
epoch [13/50] batch [380/445] time 0.082 (0.083) data 0.000 (0.002) loss 1.9417 (2.1627) teacher_loss 0.8027 (0.9219) loss_zs_kd 1.3356 (1.3325) loss_oracle 0.7158 (0.8766) acc 78.1250 (67.8207) lr 1.7705e-03 eta 0:22:46
epoch [13/50] batch [400/445] time 0.082 (0.084) data 0.001 (0.001) loss 2.1908 (2.1615) teacher_loss 0.9970 (0.9233) loss_zs_kd 1.0095 (1.3253) loss_oracle 0.8288 (0.8725) acc 65.6250 (67.8047) lr 1.7705e-03 eta 0:22:59
epoch [13/50] batch [420/445] time 0.077 (0.084) data 0.000 (0.001) loss 2.5665 (2.1569) teacher_loss 1.4234 (0.9228) loss_zs_kd 1.4072 (1.3229) loss_oracle 0.8836 (0.8692) acc 46.8750 (67.8497) lr 1.7705e-03 eta 0:22:58
epoch [13/50] batch [440/445] time 0.077 (0.083) data 0.000 (0.001) loss 2.6662 (2.1522) teacher_loss 1.2659 (0.9204) loss_zs_kd 1.1450 (1.3206) loss_oracle 0.8873 (0.8660) acc 59.3750 (67.9261) lr 1.7705e-03 eta 0:22:54
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,963
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 48.9%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,539
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 22.1%
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [14/50] batch [20/445] time 0.077 (0.108) data 0.000 (0.025) loss 2.2433 (2.1850) teacher_loss 1.0090 (0.8964) loss_zs_kd 1.3318 (1.3436) loss_oracle 0.9075 (0.8991) acc 75.0000 (70.1562) lr 1.7290e-03 eta 0:29:30
epoch [14/50] batch [40/445] time 0.072 (0.094) data 0.000 (0.012) loss 2.0777 (2.1743) teacher_loss 0.8017 (0.9090) loss_zs_kd 1.2340 (1.3903) loss_oracle 0.8199 (0.8773) acc 71.8750 (69.4531) lr 1.7290e-03 eta 0:25:39
epoch [14/50] batch [60/445] time 0.073 (0.088) data 0.000 (0.008) loss 1.9471 (2.1893) teacher_loss 0.7910 (0.9188) loss_zs_kd 1.4551 (1.3893) loss_oracle 0.8971 (0.8647) acc 68.7500 (69.6354) lr 1.7290e-03 eta 0:24:07
epoch [14/50] batch [80/445] time 0.092 (0.087) data 0.000 (0.006) loss 1.7796 (2.1460) teacher_loss 0.7316 (0.9130) loss_zs_kd 1.3507 (1.3703) loss_oracle 0.8048 (0.8522) acc 78.1250 (69.3359) lr 1.7290e-03 eta 0:23:39
epoch [14/50] batch [100/445] time 0.084 (0.086) data 0.000 (0.005) loss 2.0416 (2.1250) teacher_loss 1.0232 (0.9159) loss_zs_kd 1.2779 (1.3402) loss_oracle 0.7289 (0.8362) acc 65.6250 (68.9688) lr 1.7290e-03 eta 0:23:27
epoch [14/50] batch [120/445] time 0.086 (0.085) data 0.000 (0.004) loss 2.1982 (2.1112) teacher_loss 1.1247 (0.9134) loss_zs_kd 1.1459 (1.3263) loss_oracle 0.8541 (0.8340) acc 50.0000 (68.3854) lr 1.7290e-03 eta 0:23:17
epoch [14/50] batch [140/445] time 0.080 (0.088) data 0.000 (0.004) loss 1.7222 (2.1135) teacher_loss 0.6043 (0.9176) loss_zs_kd 1.2370 (1.3254) loss_oracle 0.8005 (0.8384) acc 78.1250 (68.1250) lr 1.7290e-03 eta 0:23:56
epoch [14/50] batch [160/445] time 0.068 (0.087) data 0.000 (0.003) loss 1.9517 (2.1090) teacher_loss 0.7664 (0.9153) loss_zs_kd 1.0523 (1.3167) loss_oracle 0.7435 (0.8386) acc 78.1250 (68.0859) lr 1.7290e-03 eta 0:23:33
epoch [14/50] batch [180/445] time 0.088 (0.085) data 0.000 (0.003) loss 2.1768 (2.1187) teacher_loss 1.0480 (0.9219) loss_zs_kd 1.2055 (1.3207) loss_oracle 0.7824 (0.8458) acc 53.1250 (67.7604) lr 1.7290e-03 eta 0:23:09
epoch [14/50] batch [200/445] time 0.079 (0.084) data 0.000 (0.003) loss 2.3343 (2.1212) teacher_loss 0.9930 (0.9150) loss_zs_kd 1.1429 (1.3173) loss_oracle 1.0117 (0.8552) acc 65.6250 (67.8594) lr 1.7290e-03 eta 0:22:51
epoch [14/50] batch [220/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.0923 (2.1255) teacher_loss 0.8548 (0.9092) loss_zs_kd 1.0611 (1.3178) loss_oracle 0.9094 (0.8627) acc 78.1250 (68.2244) lr 1.7290e-03 eta 0:22:40
epoch [14/50] batch [240/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.3289 (2.1344) teacher_loss 0.8950 (0.9084) loss_zs_kd 1.4429 (1.3263) loss_oracle 0.9368 (0.8700) acc 68.7500 (68.1380) lr 1.7290e-03 eta 0:22:38
epoch [14/50] batch [260/445] time 0.076 (0.084) data 0.000 (0.002) loss 2.3978 (2.1570) teacher_loss 1.0445 (0.9141) loss_zs_kd 1.4547 (1.3351) loss_oracle 0.9417 (0.8763) acc 62.5000 (67.9688) lr 1.7290e-03 eta 0:22:39
epoch [14/50] batch [280/445] time 0.081 (0.083) data 0.000 (0.002) loss 1.9654 (2.1601) teacher_loss 0.8147 (0.9116) loss_zs_kd 1.1531 (1.3352) loss_oracle 0.8338 (0.8772) acc 68.7500 (68.0804) lr 1.7290e-03 eta 0:22:29
epoch [14/50] batch [300/445] time 0.079 (0.083) data 0.000 (0.002) loss 2.3467 (2.1616) teacher_loss 0.9958 (0.9121) loss_zs_kd 1.4548 (1.3357) loss_oracle 0.8826 (0.8778) acc 59.3750 (68.0833) lr 1.7290e-03 eta 0:22:20
epoch [14/50] batch [320/445] time 0.091 (0.083) data 0.000 (0.002) loss 2.2097 (2.1697) teacher_loss 0.7996 (0.9105) loss_zs_kd 1.6295 (1.3428) loss_oracle 0.9127 (0.8804) acc 78.1250 (68.2617) lr 1.7290e-03 eta 0:22:19
epoch [14/50] batch [340/445] time 0.079 (0.083) data 0.000 (0.002) loss 2.2112 (2.1737) teacher_loss 0.9346 (0.9108) loss_zs_kd 1.4055 (1.3507) loss_oracle 0.7962 (0.8811) acc 65.6250 (68.1893) lr 1.7290e-03 eta 0:22:19
epoch [14/50] batch [360/445] time 0.090 (0.083) data 0.000 (0.002) loss 2.5537 (2.1825) teacher_loss 1.0145 (0.9117) loss_zs_kd 1.1125 (1.3502) loss_oracle 0.8294 (0.8825) acc 68.7500 (68.2552) lr 1.7290e-03 eta 0:22:19
epoch [14/50] batch [380/445] time 0.080 (0.083) data 0.000 (0.002) loss 1.8597 (2.1821) teacher_loss 0.5688 (0.9065) loss_zs_kd 1.2785 (1.3554) loss_oracle 0.8100 (0.8831) acc 81.2500 (68.3635) lr 1.7290e-03 eta 0:22:19
epoch [14/50] batch [400/445] time 0.070 (0.083) data 0.000 (0.001) loss 2.1461 (2.1806) teacher_loss 0.8096 (0.9044) loss_zs_kd 1.1235 (1.3539) loss_oracle 0.8577 (0.8816) acc 65.6250 (68.4609) lr 1.7290e-03 eta 0:22:13
epoch [14/50] batch [420/445] time 0.081 (0.083) data 0.000 (0.001) loss 2.1704 (2.1829) teacher_loss 0.8699 (0.9057) loss_zs_kd 1.3572 (1.3528) loss_oracle 0.8808 (0.8815) acc 68.7500 (68.4896) lr 1.7290e-03 eta 0:22:08
epoch [14/50] batch [440/445] time 0.081 (0.083) data 0.000 (0.001) loss 2.1344 (2.1814) teacher_loss 0.9344 (0.9068) loss_zs_kd 0.9908 (1.3477) loss_oracle 0.8447 (0.8798) acc 62.5000 (68.4233) lr 1.7290e-03 eta 0:22:07
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,122
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 52.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,828
* accuracy: 46.0%
* error: 54.0%
* macro_f1: 27.0%
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [15/50] batch [20/445] time 0.086 (0.113) data 0.000 (0.033) loss 2.2220 (2.2686) teacher_loss 0.8670 (0.9212) loss_zs_kd 1.5057 (1.3981) loss_oracle 0.8404 (0.8895) acc 65.6250 (68.5938) lr 1.6845e-03 eta 0:30:02
epoch [15/50] batch [40/445] time 0.085 (0.097) data 0.000 (0.016) loss 2.2006 (2.2214) teacher_loss 0.9534 (0.8968) loss_zs_kd 1.1993 (1.3721) loss_oracle 0.8645 (0.8791) acc 75.0000 (68.9062) lr 1.6845e-03 eta 0:25:48
epoch [15/50] batch [60/445] time 0.085 (0.093) data 0.000 (0.011) loss 2.1827 (2.2341) teacher_loss 0.8355 (0.9020) loss_zs_kd 1.0880 (1.3460) loss_oracle 0.8400 (0.8812) acc 65.6250 (68.2812) lr 1.6845e-03 eta 0:24:38
epoch [15/50] batch [80/445] time 0.080 (0.090) data 0.000 (0.008) loss 2.5127 (2.2344) teacher_loss 1.1980 (0.9021) loss_zs_kd 1.4596 (1.3224) loss_oracle 0.8556 (0.8799) acc 56.2500 (67.8125) lr 1.6845e-03 eta 0:24:02
epoch [15/50] batch [100/445] time 0.074 (0.089) data 0.000 (0.007) loss 2.1226 (2.2158) teacher_loss 0.7884 (0.8918) loss_zs_kd 1.4089 (1.3406) loss_oracle 0.9010 (0.8762) acc 71.8750 (68.3125) lr 1.6845e-03 eta 0:23:31
epoch [15/50] batch [120/445] time 0.083 (0.088) data 0.000 (0.006) loss 2.1360 (2.2180) teacher_loss 0.8465 (0.8951) loss_zs_kd 1.4935 (1.3644) loss_oracle 0.8663 (0.8773) acc 65.6250 (68.5677) lr 1.6845e-03 eta 0:23:15
epoch [15/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.005) loss 2.1032 (2.2176) teacher_loss 0.6941 (0.8895) loss_zs_kd 1.4883 (1.3556) loss_oracle 0.8632 (0.8781) acc 68.7500 (68.7500) lr 1.6845e-03 eta 0:23:04
epoch [15/50] batch [160/445] time 0.093 (0.086) data 0.000 (0.004) loss 2.0161 (2.2071) teacher_loss 0.6387 (0.8749) loss_zs_kd 1.7855 (1.3774) loss_oracle 0.9041 (0.8765) acc 81.2500 (69.3945) lr 1.6845e-03 eta 0:22:49
epoch [15/50] batch [180/445] time 0.094 (0.086) data 0.000 (0.004) loss 2.0370 (2.2000) teacher_loss 0.7617 (0.8754) loss_zs_kd 1.4240 (1.3831) loss_oracle 0.9190 (0.8749) acc 68.7500 (69.4097) lr 1.6845e-03 eta 0:22:44
epoch [15/50] batch [200/445] time 0.086 (0.086) data 0.000 (0.003) loss 2.1786 (2.1993) teacher_loss 0.8564 (0.8846) loss_zs_kd 1.3311 (1.3898) loss_oracle 0.8599 (0.8724) acc 75.0000 (69.1406) lr 1.6845e-03 eta 0:22:37
epoch [15/50] batch [220/445] time 0.078 (0.086) data 0.000 (0.003) loss 2.3767 (2.2017) teacher_loss 1.0655 (0.8907) loss_zs_kd 1.4861 (1.3838) loss_oracle 0.8869 (0.8705) acc 68.7500 (68.8920) lr 1.6845e-03 eta 0:22:33
epoch [15/50] batch [240/445] time 0.083 (0.085) data 0.000 (0.003) loss 2.5229 (2.2036) teacher_loss 1.1231 (0.8925) loss_zs_kd 1.2676 (1.3741) loss_oracle 0.8629 (0.8707) acc 53.1250 (68.8281) lr 1.6845e-03 eta 0:22:27
epoch [15/50] batch [260/445] time 0.090 (0.085) data 0.000 (0.003) loss 2.4046 (2.2045) teacher_loss 1.1167 (0.8898) loss_zs_kd 1.5448 (1.3787) loss_oracle 0.9160 (0.8738) acc 62.5000 (68.9423) lr 1.6845e-03 eta 0:22:23
epoch [15/50] batch [280/445] time 0.110 (0.085) data 0.000 (0.003) loss 2.2743 (2.2106) teacher_loss 0.9726 (0.8932) loss_zs_kd 1.3870 (1.3763) loss_oracle 0.9582 (0.8768) acc 65.6250 (68.9062) lr 1.6845e-03 eta 0:22:20
epoch [15/50] batch [300/445] time 0.077 (0.085) data 0.000 (0.002) loss 2.3112 (2.2084) teacher_loss 0.9464 (0.8900) loss_zs_kd 1.3014 (1.3731) loss_oracle 0.9422 (0.8786) acc 65.6250 (69.0417) lr 1.6845e-03 eta 0:22:17
epoch [15/50] batch [320/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.2810 (2.2070) teacher_loss 0.9865 (0.8891) loss_zs_kd 1.2976 (1.3708) loss_oracle 0.8618 (0.8787) acc 56.2500 (69.0137) lr 1.6845e-03 eta 0:22:10
epoch [15/50] batch [340/445] time 0.071 (0.084) data 0.000 (0.002) loss 2.2230 (2.2101) teacher_loss 0.9841 (0.8937) loss_zs_kd 1.2972 (1.3688) loss_oracle 0.7788 (0.8769) acc 62.5000 (68.8235) lr 1.6845e-03 eta 0:22:03
epoch [15/50] batch [360/445] time 0.074 (0.084) data 0.000 (0.002) loss 2.0438 (2.2080) teacher_loss 0.7535 (0.8932) loss_zs_kd 1.2744 (1.3756) loss_oracle 0.8284 (0.8752) acc 75.0000 (68.8281) lr 1.6845e-03 eta 0:21:59
epoch [15/50] batch [380/445] time 0.080 (0.084) data 0.000 (0.002) loss 1.9627 (2.2030) teacher_loss 0.8116 (0.8924) loss_zs_kd 1.3670 (1.3747) loss_oracle 0.8299 (0.8725) acc 68.7500 (68.8322) lr 1.6845e-03 eta 0:21:54
epoch [15/50] batch [400/445] time 0.070 (0.084) data 0.000 (0.002) loss 2.0456 (2.1972) teacher_loss 0.8725 (0.8913) loss_zs_kd 1.1170 (1.3667) loss_oracle 0.7743 (0.8696) acc 68.7500 (68.8516) lr 1.6845e-03 eta 0:21:47
epoch [15/50] batch [420/445] time 0.068 (0.083) data 0.000 (0.002) loss 1.9605 (2.1958) teacher_loss 0.6944 (0.8944) loss_zs_kd 1.1289 (1.3577) loss_oracle 0.7972 (0.8672) acc 75.0000 (68.6533) lr 1.6845e-03 eta 0:21:32
epoch [15/50] batch [440/445] time 0.072 (0.082) data 0.000 (0.002) loss 1.8930 (2.1951) teacher_loss 0.7326 (0.8957) loss_zs_kd 1.3849 (1.3580) loss_oracle 0.8678 (0.8659) acc 75.0000 (68.6506) lr 1.6845e-03 eta 0:21:21
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,080
* accuracy: 66.8%
* error: 33.2%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,866
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 27.9%
******* Domain 3 best val acc:      68.1%, epoch: 10 *******
******* Domain 3 best val test acc: 49.7%, epoch: 10 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [16/50] batch [20/445] time 0.076 (0.110) data 0.000 (0.028) loss 2.0859 (2.1429) teacher_loss 0.9082 (0.9249) loss_zs_kd 1.5271 (1.4983) loss_oracle 0.8263 (0.8268) acc 65.6250 (67.5000) lr 1.6374e-03 eta 0:28:31
epoch [16/50] batch [40/445] time 0.190 (0.095) data 0.000 (0.014) loss 1.9695 (2.1467) teacher_loss 0.7447 (0.9213) loss_zs_kd 1.3799 (1.4263) loss_oracle 0.8879 (0.8240) acc 75.0000 (67.0312) lr 1.6374e-03 eta 0:24:34
epoch [16/50] batch [60/445] time 0.082 (0.095) data 0.000 (0.009) loss 2.0875 (2.1228) teacher_loss 0.9125 (0.9007) loss_zs_kd 1.4989 (1.4026) loss_oracle 0.8106 (0.8185) acc 62.5000 (68.1250) lr 1.6374e-03 eta 0:24:35
epoch [16/50] batch [80/445] time 0.086 (0.092) data 0.000 (0.007) loss 2.0655 (2.1361) teacher_loss 0.8626 (0.9118) loss_zs_kd 1.2699 (1.3895) loss_oracle 0.8457 (0.8254) acc 68.7500 (67.7734) lr 1.6374e-03 eta 0:23:48
epoch [16/50] batch [100/445] time 0.095 (0.090) data 0.000 (0.006) loss 2.4883 (2.1471) teacher_loss 1.1305 (0.9109) loss_zs_kd 1.5439 (1.3920) loss_oracle 0.8562 (0.8312) acc 68.7500 (67.9688) lr 1.6374e-03 eta 0:23:13
epoch [16/50] batch [120/445] time 0.088 (0.089) data 0.000 (0.005) loss 2.0980 (2.1556) teacher_loss 0.9191 (0.9109) loss_zs_kd 1.0959 (1.3772) loss_oracle 0.8434 (0.8352) acc 59.3750 (67.4479) lr 1.6374e-03 eta 0:22:58
epoch [16/50] batch [140/445] time 0.080 (0.089) data 0.000 (0.004) loss 1.9407 (2.1608) teacher_loss 0.5229 (0.9103) loss_zs_kd 1.5369 (1.3765) loss_oracle 0.8802 (0.8360) acc 81.2500 (67.6116) lr 1.6374e-03 eta 0:22:46
epoch [16/50] batch [160/445] time 0.075 (0.088) data 0.000 (0.004) loss 2.0614 (2.1588) teacher_loss 0.8383 (0.9018) loss_zs_kd 1.4057 (1.3694) loss_oracle 0.8524 (0.8421) acc 78.1250 (67.9688) lr 1.6374e-03 eta 0:22:35
epoch [16/50] batch [180/445] time 0.087 (0.088) data 0.000 (0.003) loss 2.0437 (2.1575) teacher_loss 0.8250 (0.9014) loss_zs_kd 1.7266 (1.3673) loss_oracle 0.9108 (0.8456) acc 68.7500 (68.0382) lr 1.6374e-03 eta 0:22:28
epoch [16/50] batch [200/445] time 0.082 (0.087) data 0.000 (0.003) loss 2.2026 (2.1554) teacher_loss 0.9340 (0.9000) loss_zs_kd 1.3218 (1.3633) loss_oracle 0.8725 (0.8486) acc 68.7500 (68.0781) lr 1.6374e-03 eta 0:22:14
epoch [16/50] batch [220/445] time 0.078 (0.086) data 0.000 (0.003) loss 2.1863 (2.1535) teacher_loss 0.9014 (0.8951) loss_zs_kd 1.6466 (1.3705) loss_oracle 0.8656 (0.8515) acc 75.0000 (68.1676) lr 1.6374e-03 eta 0:21:59
epoch [16/50] batch [240/445] time 0.089 (0.085) data 0.000 (0.003) loss 2.2957 (2.1569) teacher_loss 0.9849 (0.8947) loss_zs_kd 1.2269 (1.3682) loss_oracle 0.8332 (0.8535) acc 59.3750 (68.1901) lr 1.6374e-03 eta 0:21:46
epoch [16/50] batch [260/445] time 0.081 (0.085) data 0.000 (0.002) loss 1.7266 (2.1545) teacher_loss 0.4089 (0.8867) loss_zs_kd 1.6245 (1.3794) loss_oracle 0.9095 (0.8569) acc 87.5000 (68.6538) lr 1.6374e-03 eta 0:21:44
epoch [16/50] batch [280/445] time 0.079 (0.085) data 0.000 (0.002) loss 2.2604 (2.1575) teacher_loss 0.9788 (0.8809) loss_zs_kd 1.5009 (1.3876) loss_oracle 0.9087 (0.8598) acc 59.3750 (68.7165) lr 1.6374e-03 eta 0:21:41
epoch [16/50] batch [300/445] time 0.086 (0.085) data 0.000 (0.002) loss 1.7833 (2.1531) teacher_loss 0.5603 (0.8737) loss_zs_kd 1.5390 (1.3933) loss_oracle 0.8737 (0.8623) acc 78.1250 (68.8542) lr 1.6374e-03 eta 0:21:37
epoch [16/50] batch [320/445] time 0.091 (0.085) data 0.000 (0.002) loss 2.4993 (2.1584) teacher_loss 1.2421 (0.8736) loss_zs_kd 1.4358 (1.4068) loss_oracle 0.8047 (0.8652) acc 65.6250 (69.0039) lr 1.6374e-03 eta 0:21:35
epoch [16/50] batch [340/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.3611 (2.1622) teacher_loss 1.1889 (0.8761) loss_zs_kd 1.7318 (1.4149) loss_oracle 0.8195 (0.8659) acc 56.2500 (68.8971) lr 1.6374e-03 eta 0:21:34
epoch [16/50] batch [360/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.3254 (2.1663) teacher_loss 1.0179 (0.8800) loss_zs_kd 1.0625 (1.4064) loss_oracle 0.8442 (0.8663) acc 71.8750 (68.8455) lr 1.6374e-03 eta 0:21:27
epoch [16/50] batch [380/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.1308 (2.1680) teacher_loss 0.8441 (0.8835) loss_zs_kd 1.3462 (1.3939) loss_oracle 0.8466 (0.8655) acc 71.8750 (68.7829) lr 1.6374e-03 eta 0:21:25
epoch [16/50] batch [400/445] time 0.087 (0.084) data 0.000 (0.002) loss 2.1538 (2.1693) teacher_loss 0.9323 (0.8876) loss_zs_kd 1.2124 (1.3855) loss_oracle 0.8529 (0.8645) acc 68.7500 (68.7031) lr 1.6374e-03 eta 0:21:22
epoch [16/50] batch [420/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.3244 (2.1676) teacher_loss 1.0459 (0.8878) loss_zs_kd 1.2235 (1.3768) loss_oracle 0.8976 (0.8626) acc 59.3750 (68.7054) lr 1.6374e-03 eta 0:21:20
epoch [16/50] batch [440/445] time 0.110 (0.085) data 0.001 (0.002) loss 1.7396 (2.1666) teacher_loss 0.4336 (0.8867) loss_zs_kd 1.1665 (1.3770) loss_oracle 0.8290 (0.8620) acc 84.3750 (68.8068) lr 1.6374e-03 eta 0:21:19
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,164
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 53.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,853
* accuracy: 46.7%
* error: 53.3%
* macro_f1: 29.9%
******* Domain 3 best val acc:      68.2%, epoch: 16 *******
******* Domain 3 best val test acc: 46.7%, epoch: 16 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [17/50] batch [20/445] time 0.083 (0.116) data 0.000 (0.030) loss 2.0479 (2.2534) teacher_loss 0.6860 (0.9461) loss_zs_kd 1.5055 (1.3270) loss_oracle 0.8711 (0.8660) acc 75.0000 (65.4688) lr 1.5878e-03 eta 0:29:15
epoch [17/50] batch [40/445] time 0.075 (0.098) data 0.000 (0.015) loss 2.6844 (2.2200) teacher_loss 1.4269 (0.9291) loss_zs_kd 1.5928 (1.4254) loss_oracle 0.8343 (0.8612) acc 46.8750 (66.0938) lr 1.5878e-03 eta 0:24:39
epoch [17/50] batch [60/445] time 0.081 (0.093) data 0.001 (0.010) loss 2.3275 (2.2087) teacher_loss 0.9906 (0.9270) loss_zs_kd 1.4166 (1.3824) loss_oracle 0.9261 (0.8578) acc 71.8750 (67.0312) lr 1.5878e-03 eta 0:23:17
epoch [17/50] batch [80/445] time 0.087 (0.091) data 0.000 (0.008) loss 2.1629 (2.1707) teacher_loss 0.7383 (0.8887) loss_zs_kd 1.4248 (1.3461) loss_oracle 0.8351 (0.8547) acc 75.0000 (68.7891) lr 1.5878e-03 eta 0:22:49
epoch [17/50] batch [100/445] time 0.085 (0.090) data 0.000 (0.006) loss 2.4291 (2.1825) teacher_loss 0.9922 (0.8785) loss_zs_kd 1.2453 (1.3778) loss_oracle 0.9272 (0.8602) acc 65.6250 (69.5000) lr 1.5878e-03 eta 0:22:25
epoch [17/50] batch [120/445] time 0.095 (0.089) data 0.001 (0.005) loss 2.2621 (2.1859) teacher_loss 1.0338 (0.8834) loss_zs_kd 1.0273 (1.3843) loss_oracle 0.8538 (0.8650) acc 62.5000 (69.2448) lr 1.5878e-03 eta 0:22:14
epoch [17/50] batch [140/445] time 0.086 (0.088) data 0.000 (0.005) loss 2.4024 (2.1917) teacher_loss 1.0760 (0.8918) loss_zs_kd 1.4414 (1.3699) loss_oracle 0.8802 (0.8675) acc 59.3750 (68.9732) lr 1.5878e-03 eta 0:21:55
epoch [17/50] batch [160/445] time 0.079 (0.088) data 0.000 (0.004) loss 2.5152 (2.1904) teacher_loss 1.1722 (0.8922) loss_zs_kd 1.0044 (1.3601) loss_oracle 0.8337 (0.8686) acc 59.3750 (69.1797) lr 1.5878e-03 eta 0:21:50
epoch [17/50] batch [180/445] time 0.114 (0.088) data 0.000 (0.004) loss 1.8543 (2.1834) teacher_loss 0.6220 (0.8861) loss_zs_kd 1.1665 (1.3469) loss_oracle 0.8433 (0.8664) acc 75.0000 (69.4444) lr 1.5878e-03 eta 0:22:00
epoch [17/50] batch [200/445] time 0.085 (0.088) data 0.000 (0.003) loss 1.9153 (2.1802) teacher_loss 0.6406 (0.8865) loss_zs_kd 1.3530 (1.3475) loss_oracle 0.8447 (0.8624) acc 78.1250 (69.5000) lr 1.5878e-03 eta 0:21:59
epoch [17/50] batch [220/445] time 0.088 (0.088) data 0.000 (0.003) loss 2.0832 (2.1764) teacher_loss 0.8410 (0.8868) loss_zs_kd 1.5531 (1.3370) loss_oracle 0.8286 (0.8601) acc 71.8750 (69.3892) lr 1.5878e-03 eta 0:21:53
epoch [17/50] batch [240/445] time 0.075 (0.088) data 0.000 (0.003) loss 2.2100 (2.1771) teacher_loss 0.8635 (0.8864) loss_zs_kd 1.3974 (1.3389) loss_oracle 0.8952 (0.8594) acc 62.5000 (69.3229) lr 1.5878e-03 eta 0:21:52
epoch [17/50] batch [260/445] time 0.082 (0.088) data 0.000 (0.003) loss 2.1192 (2.1769) teacher_loss 0.8583 (0.8847) loss_zs_kd 1.5412 (1.3476) loss_oracle 0.8807 (0.8602) acc 71.8750 (69.3389) lr 1.5878e-03 eta 0:21:45
epoch [17/50] batch [280/445] time 0.091 (0.087) data 0.000 (0.002) loss 2.1774 (2.1734) teacher_loss 0.9581 (0.8825) loss_zs_kd 1.4224 (1.3474) loss_oracle 0.7897 (0.8589) acc 65.6250 (69.5312) lr 1.5878e-03 eta 0:21:37
epoch [17/50] batch [300/445] time 0.083 (0.087) data 0.000 (0.002) loss 2.0138 (2.1768) teacher_loss 0.7285 (0.8899) loss_zs_kd 0.9683 (1.3496) loss_oracle 0.8809 (0.8584) acc 78.1250 (69.1458) lr 1.5878e-03 eta 0:21:35
epoch [17/50] batch [320/445] time 0.083 (0.087) data 0.000 (0.002) loss 1.7537 (2.1748) teacher_loss 0.5999 (0.8907) loss_zs_kd 1.4190 (1.3496) loss_oracle 0.7979 (0.8588) acc 81.2500 (68.9355) lr 1.5878e-03 eta 0:21:32
epoch [17/50] batch [340/445] time 0.083 (0.087) data 0.000 (0.002) loss 1.9657 (2.1756) teacher_loss 0.6863 (0.8929) loss_zs_kd 1.3056 (1.3527) loss_oracle 0.8664 (0.8592) acc 78.1250 (68.8419) lr 1.5878e-03 eta 0:21:28
epoch [17/50] batch [360/445] time 0.098 (0.087) data 0.001 (0.002) loss 2.3833 (2.1770) teacher_loss 1.0600 (0.8945) loss_zs_kd 1.4542 (1.3554) loss_oracle 0.9147 (0.8598) acc 62.5000 (68.7500) lr 1.5878e-03 eta 0:21:25
epoch [17/50] batch [380/445] time 0.083 (0.087) data 0.000 (0.002) loss 2.2712 (2.1759) teacher_loss 0.8805 (0.8934) loss_zs_kd 1.3223 (1.3544) loss_oracle 0.8824 (0.8604) acc 71.8750 (68.7911) lr 1.5878e-03 eta 0:21:19
epoch [17/50] batch [400/445] time 0.079 (0.086) data 0.000 (0.002) loss 2.4652 (2.1828) teacher_loss 1.1246 (0.8985) loss_zs_kd 1.4162 (1.3547) loss_oracle 0.8940 (0.8621) acc 65.6250 (68.5625) lr 1.5878e-03 eta 0:21:13
epoch [17/50] batch [420/445] time 0.079 (0.086) data 0.000 (0.002) loss 2.1600 (2.1856) teacher_loss 0.8207 (0.9000) loss_zs_kd 1.2094 (1.3560) loss_oracle 0.8182 (0.8631) acc 75.0000 (68.5938) lr 1.5878e-03 eta 0:21:10
epoch [17/50] batch [440/445] time 0.071 (0.086) data 0.000 (0.002) loss 1.9999 (2.1824) teacher_loss 0.7920 (0.8965) loss_zs_kd 1.1882 (1.3569) loss_oracle 0.8343 (0.8625) acc 78.1250 (68.7145) lr 1.5878e-03 eta 0:21:04
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,053
* accuracy: 66.4%
* error: 33.6%
* macro_f1: 51.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,785
* accuracy: 45.0%
* error: 55.0%
* macro_f1: 28.9%
******* Domain 3 best val acc:      68.2%, epoch: 16 *******
******* Domain 3 best val test acc: 46.7%, epoch: 16 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [18/50] batch [20/445] time 0.070 (0.109) data 0.000 (0.028) loss 2.5575 (2.2521) teacher_loss 1.1118 (0.9166) loss_zs_kd 1.1306 (1.2910) loss_oracle 0.9736 (0.8877) acc 65.6250 (67.3438) lr 1.5358e-03 eta 0:26:39
epoch [18/50] batch [40/445] time 0.076 (0.094) data 0.000 (0.014) loss 2.0923 (2.2029) teacher_loss 0.8514 (0.9042) loss_zs_kd 1.0547 (1.2951) loss_oracle 0.8997 (0.8724) acc 68.7500 (67.6562) lr 1.5358e-03 eta 0:22:54
epoch [18/50] batch [60/445] time 0.075 (0.087) data 0.000 (0.009) loss 1.9717 (2.1804) teacher_loss 0.7832 (0.8947) loss_zs_kd 1.3669 (1.2994) loss_oracle 0.7786 (0.8670) acc 75.0000 (68.2812) lr 1.5358e-03 eta 0:21:08
epoch [18/50] batch [80/445] time 0.082 (0.084) data 0.000 (0.007) loss 2.2300 (2.1870) teacher_loss 0.9997 (0.9053) loss_zs_kd 1.3013 (1.3122) loss_oracle 0.7976 (0.8636) acc 65.6250 (67.5391) lr 1.5358e-03 eta 0:20:33
epoch [18/50] batch [100/445] time 0.062 (0.082) data 0.000 (0.006) loss 2.1528 (2.1907) teacher_loss 0.8766 (0.9062) loss_zs_kd 1.4449 (1.3298) loss_oracle 0.8714 (0.8647) acc 68.7500 (67.5625) lr 1.5358e-03 eta 0:19:53
epoch [18/50] batch [120/445] time 0.057 (0.078) data 0.000 (0.005) loss 2.4056 (2.1960) teacher_loss 1.1160 (0.9072) loss_zs_kd 1.6356 (1.3206) loss_oracle 0.9177 (0.8671) acc 59.3750 (67.7865) lr 1.5358e-03 eta 0:19:01
epoch [18/50] batch [140/445] time 0.059 (0.076) data 0.000 (0.004) loss 1.7943 (2.1860) teacher_loss 0.5221 (0.9005) loss_zs_kd 1.5364 (1.3167) loss_oracle 0.8576 (0.8633) acc 84.3750 (68.0357) lr 1.5358e-03 eta 0:18:25
epoch [18/50] batch [160/445] time 0.060 (0.074) data 0.000 (0.004) loss 1.8687 (2.1786) teacher_loss 0.6277 (0.8952) loss_zs_kd 1.4874 (1.3097) loss_oracle 0.8230 (0.8627) acc 81.2500 (68.4180) lr 1.5358e-03 eta 0:17:56
epoch [18/50] batch [180/445] time 0.064 (0.073) data 0.000 (0.003) loss 1.9290 (2.1713) teacher_loss 0.6892 (0.8920) loss_zs_kd 1.3676 (1.3038) loss_oracle 0.8583 (0.8621) acc 78.1250 (68.5938) lr 1.5358e-03 eta 0:17:38
epoch [18/50] batch [200/445] time 0.081 (0.073) data 0.000 (0.003) loss 2.0687 (2.1676) teacher_loss 0.7413 (0.8924) loss_zs_kd 1.4992 (1.3000) loss_oracle 0.8570 (0.8579) acc 68.7500 (68.6406) lr 1.5358e-03 eta 0:17:42
epoch [18/50] batch [220/445] time 0.076 (0.074) data 0.000 (0.003) loss 1.8420 (2.1713) teacher_loss 0.7272 (0.8966) loss_zs_kd 1.4711 (1.3130) loss_oracle 0.7310 (0.8563) acc 81.2500 (68.7074) lr 1.5358e-03 eta 0:17:49
epoch [18/50] batch [240/445] time 0.071 (0.074) data 0.000 (0.003) loss 2.0512 (2.1734) teacher_loss 0.7377 (0.8974) loss_zs_kd 1.2403 (1.3139) loss_oracle 0.8742 (0.8572) acc 71.8750 (68.6328) lr 1.5358e-03 eta 0:17:51
epoch [18/50] batch [260/445] time 0.075 (0.074) data 0.000 (0.002) loss 2.2669 (2.1650) teacher_loss 0.9849 (0.8905) loss_zs_kd 1.2114 (1.3122) loss_oracle 0.8314 (0.8564) acc 62.5000 (68.8221) lr 1.5358e-03 eta 0:17:53
epoch [18/50] batch [280/445] time 0.075 (0.075) data 0.000 (0.002) loss 2.0780 (2.1627) teacher_loss 0.8801 (0.8878) loss_zs_kd 1.3246 (1.3138) loss_oracle 0.8030 (0.8563) acc 68.7500 (69.0402) lr 1.5358e-03 eta 0:17:59
epoch [18/50] batch [300/445] time 0.082 (0.076) data 0.000 (0.002) loss 1.8899 (2.1611) teacher_loss 0.6508 (0.8866) loss_zs_kd 1.2771 (1.3136) loss_oracle 0.8840 (0.8570) acc 81.2500 (69.0521) lr 1.5358e-03 eta 0:18:07
epoch [18/50] batch [320/445] time 0.098 (0.076) data 0.001 (0.002) loss 2.0347 (2.1611) teacher_loss 0.7730 (0.8857) loss_zs_kd 1.4090 (1.3211) loss_oracle 0.8938 (0.8579) acc 71.8750 (69.1504) lr 1.5358e-03 eta 0:18:15
epoch [18/50] batch [340/445] time 0.074 (0.078) data 0.000 (0.002) loss 2.3476 (2.1607) teacher_loss 1.0325 (0.8839) loss_zs_kd 1.6676 (1.3254) loss_oracle 0.8943 (0.8579) acc 62.5000 (69.1728) lr 1.5358e-03 eta 0:18:34
epoch [18/50] batch [360/445] time 0.081 (0.078) data 0.000 (0.002) loss 2.1613 (2.1606) teacher_loss 0.9300 (0.8840) loss_zs_kd 1.1583 (1.3229) loss_oracle 0.8645 (0.8576) acc 68.7500 (69.1406) lr 1.5358e-03 eta 0:18:35
epoch [18/50] batch [380/445] time 0.081 (0.078) data 0.000 (0.002) loss 2.0356 (2.1624) teacher_loss 0.7489 (0.8883) loss_zs_kd 1.3338 (1.3173) loss_oracle 0.8452 (0.8562) acc 71.8750 (68.9309) lr 1.5358e-03 eta 0:18:36
epoch [18/50] batch [400/445] time 0.078 (0.078) data 0.000 (0.002) loss 2.0937 (2.1598) teacher_loss 0.8432 (0.8858) loss_zs_kd 1.0767 (1.3146) loss_oracle 0.8268 (0.8560) acc 68.7500 (69.0312) lr 1.5358e-03 eta 0:18:36
epoch [18/50] batch [420/445] time 0.083 (0.078) data 0.000 (0.002) loss 2.2822 (2.1585) teacher_loss 0.9271 (0.8836) loss_zs_kd 1.1695 (1.3173) loss_oracle 0.9277 (0.8576) acc 65.6250 (69.2188) lr 1.5358e-03 eta 0:18:39
epoch [18/50] batch [440/445] time 0.076 (0.078) data 0.000 (0.002) loss 2.0732 (2.1564) teacher_loss 0.8324 (0.8812) loss_zs_kd 1.4036 (1.3195) loss_oracle 0.8136 (0.8580) acc 59.3750 (69.2827) lr 1.5358e-03 eta 0:18:35
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,943
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 53.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,669
* accuracy: 42.0%
* error: 58.0%
* macro_f1: 25.2%
******* Domain 3 best val acc:      68.2%, epoch: 16 *******
******* Domain 3 best val test acc: 46.7%, epoch: 16 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [19/50] batch [20/445] time 0.074 (0.111) data 0.000 (0.029) loss 1.8466 (2.0931) teacher_loss 0.6181 (0.8442) loss_zs_kd 1.4254 (1.1974) loss_oracle 0.7847 (0.8439) acc 87.5000 (71.4062) lr 1.4818e-03 eta 0:26:23
epoch [19/50] batch [40/445] time 0.078 (0.096) data 0.000 (0.015) loss 2.3340 (2.1148) teacher_loss 1.1620 (0.8733) loss_zs_kd 1.5853 (1.2413) loss_oracle 0.8128 (0.8455) acc 56.2500 (70.4688) lr 1.4818e-03 eta 0:22:45
epoch [19/50] batch [60/445] time 0.079 (0.091) data 0.001 (0.010) loss 1.6528 (2.1209) teacher_loss 0.3989 (0.8657) loss_zs_kd 1.4172 (1.2650) loss_oracle 0.8389 (0.8482) acc 96.8750 (70.9375) lr 1.4818e-03 eta 0:21:26
epoch [19/50] batch [80/445] time 0.078 (0.092) data 0.000 (0.008) loss 1.9374 (2.1293) teacher_loss 0.7145 (0.8678) loss_zs_kd 1.1432 (1.2533) loss_oracle 0.7923 (0.8481) acc 71.8750 (70.8594) lr 1.4818e-03 eta 0:21:42
epoch [19/50] batch [100/445] time 0.084 (0.090) data 0.000 (0.006) loss 1.9063 (2.1321) teacher_loss 0.5821 (0.8694) loss_zs_kd 1.4302 (1.2472) loss_oracle 0.8755 (0.8520) acc 87.5000 (70.9375) lr 1.4818e-03 eta 0:21:16
epoch [19/50] batch [120/445] time 0.076 (0.089) data 0.000 (0.005) loss 2.4343 (2.1419) teacher_loss 1.1369 (0.8717) loss_zs_kd 1.3458 (1.2539) loss_oracle 0.8879 (0.8575) acc 71.8750 (70.9375) lr 1.4818e-03 eta 0:21:00
epoch [19/50] batch [140/445] time 0.071 (0.088) data 0.000 (0.004) loss 2.0623 (2.1312) teacher_loss 0.8238 (0.8623) loss_zs_kd 1.3445 (1.2736) loss_oracle 0.8863 (0.8567) acc 71.8750 (71.1607) lr 1.4818e-03 eta 0:20:34
epoch [19/50] batch [160/445] time 0.077 (0.087) data 0.000 (0.004) loss 1.9841 (2.1319) teacher_loss 0.7265 (0.8631) loss_zs_kd 1.4812 (1.3017) loss_oracle 0.8404 (0.8557) acc 75.0000 (70.9180) lr 1.4818e-03 eta 0:20:19
epoch [19/50] batch [180/445] time 0.072 (0.085) data 0.000 (0.004) loss 2.4710 (2.1339) teacher_loss 1.1122 (0.8669) loss_zs_kd 1.4844 (1.3051) loss_oracle 0.8592 (0.8540) acc 68.7500 (70.7292) lr 1.4818e-03 eta 0:19:55
epoch [19/50] batch [200/445] time 0.079 (0.085) data 0.000 (0.003) loss 2.1009 (2.1348) teacher_loss 0.9520 (0.8692) loss_zs_kd 1.4575 (1.3045) loss_oracle 0.7698 (0.8531) acc 65.6250 (70.7031) lr 1.4818e-03 eta 0:19:50
epoch [19/50] batch [220/445] time 0.093 (0.084) data 0.000 (0.003) loss 1.9305 (2.1332) teacher_loss 0.7548 (0.8700) loss_zs_kd 1.3837 (1.2972) loss_oracle 0.8444 (0.8527) acc 78.1250 (70.4545) lr 1.4818e-03 eta 0:19:43
epoch [19/50] batch [240/445] time 0.091 (0.084) data 0.000 (0.003) loss 2.4957 (2.1333) teacher_loss 1.1787 (0.8705) loss_zs_kd 1.4429 (1.2973) loss_oracle 0.8947 (0.8521) acc 65.6250 (70.3776) lr 1.4818e-03 eta 0:19:39
epoch [19/50] batch [260/445] time 0.083 (0.084) data 0.000 (0.003) loss 1.8991 (2.1322) teacher_loss 0.7288 (0.8708) loss_zs_kd 1.6130 (1.2980) loss_oracle 0.8786 (0.8523) acc 71.8750 (70.2885) lr 1.4818e-03 eta 0:19:39
epoch [19/50] batch [280/445] time 0.083 (0.084) data 0.000 (0.002) loss 2.1060 (2.1313) teacher_loss 0.9007 (0.8706) loss_zs_kd 1.1994 (1.3087) loss_oracle 0.8309 (0.8515) acc 71.8750 (70.2902) lr 1.4818e-03 eta 0:19:37
epoch [19/50] batch [300/445] time 0.071 (0.084) data 0.000 (0.002) loss 2.2470 (2.1323) teacher_loss 0.9697 (0.8717) loss_zs_kd 1.4217 (1.3153) loss_oracle 0.8536 (0.8508) acc 71.8750 (70.2708) lr 1.4818e-03 eta 0:19:33
epoch [19/50] batch [320/445] time 0.084 (0.084) data 0.000 (0.002) loss 1.9075 (2.1295) teacher_loss 0.6540 (0.8696) loss_zs_kd 1.1157 (1.3149) loss_oracle 0.8687 (0.8515) acc 84.3750 (70.3418) lr 1.4818e-03 eta 0:19:26
epoch [19/50] batch [340/445] time 0.089 (0.084) data 0.000 (0.002) loss 1.9821 (2.1328) teacher_loss 0.7514 (0.8728) loss_zs_kd 1.3990 (1.3107) loss_oracle 0.8292 (0.8533) acc 71.8750 (70.1103) lr 1.4818e-03 eta 0:19:24
epoch [19/50] batch [360/445] time 0.081 (0.084) data 0.000 (0.002) loss 2.1299 (2.1332) teacher_loss 0.7996 (0.8727) loss_zs_kd 1.5257 (1.3118) loss_oracle 0.9705 (0.8545) acc 71.8750 (70.1128) lr 1.4818e-03 eta 0:19:23
epoch [19/50] batch [380/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.2105 (2.1366) teacher_loss 0.8946 (0.8748) loss_zs_kd 1.3799 (1.3091) loss_oracle 0.8878 (0.8567) acc 62.5000 (69.9507) lr 1.4818e-03 eta 0:19:21
epoch [19/50] batch [400/445] time 0.075 (0.084) data 0.000 (0.002) loss 2.1408 (2.1387) teacher_loss 0.9742 (0.8768) loss_zs_kd 1.3406 (1.3081) loss_oracle 0.7970 (0.8578) acc 59.3750 (69.7656) lr 1.4818e-03 eta 0:19:19
epoch [19/50] batch [420/445] time 0.083 (0.084) data 0.000 (0.002) loss 1.6765 (2.1368) teacher_loss 0.4371 (0.8745) loss_zs_kd 1.2993 (1.3119) loss_oracle 0.9322 (0.8590) acc 93.7500 (69.9479) lr 1.4818e-03 eta 0:19:15
epoch [19/50] batch [440/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.6783 (2.1389) teacher_loss 1.3499 (0.8757) loss_zs_kd 1.7290 (1.3149) loss_oracle 0.8344 (0.8607) acc 53.1250 (69.9503) lr 1.4818e-03 eta 0:19:12
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,225
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 54.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,922
* accuracy: 48.4%
* error: 51.6%
* macro_f1: 31.7%
******* Domain 3 best val acc:      69.2%, epoch: 19 *******
******* Domain 3 best val test acc: 48.4%, epoch: 19 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [20/50] batch [20/445] time 0.084 (0.123) data 0.000 (0.034) loss 1.8794 (2.0778) teacher_loss 0.6485 (0.8164) loss_zs_kd 1.5841 (1.3517) loss_oracle 0.8691 (0.8714) acc 78.1250 (71.2500) lr 1.4258e-03 eta 0:28:09
epoch [20/50] batch [40/445] time 0.080 (0.103) data 0.000 (0.017) loss 1.9841 (2.1060) teacher_loss 0.7455 (0.8532) loss_zs_kd 1.7407 (1.3536) loss_oracle 0.8278 (0.8683) acc 71.8750 (69.2188) lr 1.4258e-03 eta 0:23:37
epoch [20/50] batch [60/445] time 0.086 (0.096) data 0.000 (0.011) loss 1.9152 (2.1113) teacher_loss 0.6631 (0.8552) loss_zs_kd 1.3855 (1.3465) loss_oracle 0.8953 (0.8661) acc 78.1250 (69.4792) lr 1.4258e-03 eta 0:21:58
epoch [20/50] batch [80/445] time 0.079 (0.093) data 0.000 (0.009) loss 2.1789 (2.1129) teacher_loss 0.8641 (0.8478) loss_zs_kd 1.1226 (1.3452) loss_oracle 0.8523 (0.8695) acc 75.0000 (69.9609) lr 1.4258e-03 eta 0:21:13
epoch [20/50] batch [100/445] time 0.087 (0.090) data 0.000 (0.007) loss 1.9815 (2.1140) teacher_loss 0.6917 (0.8388) loss_zs_kd 1.5723 (1.3541) loss_oracle 0.8793 (0.8732) acc 75.0000 (70.0000) lr 1.4258e-03 eta 0:20:38
epoch [20/50] batch [120/445] time 0.092 (0.089) data 0.000 (0.006) loss 2.1757 (2.1323) teacher_loss 0.8821 (0.8569) loss_zs_kd 1.3094 (1.3506) loss_oracle 0.8782 (0.8724) acc 75.0000 (69.7656) lr 1.4258e-03 eta 0:20:21
epoch [20/50] batch [140/445] time 0.085 (0.089) data 0.000 (0.005) loss 2.2958 (2.1392) teacher_loss 1.0170 (0.8613) loss_zs_kd 1.4700 (1.3533) loss_oracle 0.8947 (0.8730) acc 68.7500 (69.6652) lr 1.4258e-03 eta 0:20:11
epoch [20/50] batch [160/445] time 0.080 (0.088) data 0.000 (0.004) loss 2.5789 (2.1396) teacher_loss 1.2399 (0.8618) loss_zs_kd 1.4235 (1.3569) loss_oracle 0.9248 (0.8741) acc 59.3750 (69.8047) lr 1.4258e-03 eta 0:19:56
epoch [20/50] batch [180/445] time 0.085 (0.088) data 0.000 (0.004) loss 1.9883 (2.1384) teacher_loss 0.6562 (0.8597) loss_zs_kd 1.5128 (1.3550) loss_oracle 0.8875 (0.8755) acc 75.0000 (70.2604) lr 1.4258e-03 eta 0:19:51
epoch [20/50] batch [200/445] time 0.080 (0.089) data 0.000 (0.004) loss 2.2981 (2.1411) teacher_loss 0.9687 (0.8596) loss_zs_kd 1.5324 (1.3705) loss_oracle 0.9265 (0.8778) acc 62.5000 (70.1406) lr 1.4258e-03 eta 0:20:10
epoch [20/50] batch [220/445] time 0.086 (0.088) data 0.000 (0.003) loss 2.2385 (2.1442) teacher_loss 0.9707 (0.8613) loss_zs_kd 1.4854 (1.3780) loss_oracle 0.8413 (0.8771) acc 65.6250 (69.8864) lr 1.4258e-03 eta 0:19:57
epoch [20/50] batch [240/445] time 0.082 (0.088) data 0.000 (0.003) loss 2.0374 (2.1528) teacher_loss 0.8497 (0.8670) loss_zs_kd 1.3610 (1.3814) loss_oracle 0.8591 (0.8779) acc 78.1250 (69.5703) lr 1.4258e-03 eta 0:19:49
epoch [20/50] batch [260/445] time 0.082 (0.088) data 0.000 (0.003) loss 1.9765 (2.1527) teacher_loss 0.7730 (0.8688) loss_zs_kd 1.2721 (1.3784) loss_oracle 0.8427 (0.8788) acc 68.7500 (69.7356) lr 1.4258e-03 eta 0:19:46
epoch [20/50] batch [280/445] time 0.079 (0.087) data 0.000 (0.003) loss 2.2890 (2.1560) teacher_loss 1.0421 (0.8751) loss_zs_kd 1.1899 (1.3679) loss_oracle 0.8616 (0.8776) acc 59.3750 (69.5536) lr 1.4258e-03 eta 0:19:36
epoch [20/50] batch [300/445] time 0.086 (0.087) data 0.000 (0.003) loss 1.9521 (2.1552) teacher_loss 0.6497 (0.8742) loss_zs_kd 1.4534 (1.3650) loss_oracle 0.8893 (0.8794) acc 78.1250 (69.6562) lr 1.4258e-03 eta 0:19:31
epoch [20/50] batch [320/445] time 0.090 (0.087) data 0.000 (0.002) loss 1.8696 (2.1491) teacher_loss 0.6301 (0.8699) loss_zs_kd 1.2051 (1.3648) loss_oracle 0.8289 (0.8796) acc 71.8750 (69.7266) lr 1.4258e-03 eta 0:19:30
epoch [20/50] batch [340/445] time 0.086 (0.086) data 0.000 (0.002) loss 2.1450 (2.1516) teacher_loss 0.8184 (0.8679) loss_zs_kd 1.5489 (1.3631) loss_oracle 0.8297 (0.8814) acc 71.8750 (69.7426) lr 1.4258e-03 eta 0:19:23
epoch [20/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.5257 (2.1531) teacher_loss 1.1088 (0.8676) loss_zs_kd 1.1622 (1.3649) loss_oracle 1.0044 (0.8813) acc 65.6250 (69.7569) lr 1.4258e-03 eta 0:19:17
epoch [20/50] batch [380/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.0279 (2.1547) teacher_loss 0.7093 (0.8680) loss_zs_kd 1.2501 (1.3683) loss_oracle 0.9067 (0.8813) acc 71.8750 (69.8684) lr 1.4258e-03 eta 0:19:16
epoch [20/50] batch [400/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.1532 (2.1529) teacher_loss 0.8277 (0.8652) loss_zs_kd 1.6041 (1.3748) loss_oracle 0.8772 (0.8809) acc 75.0000 (69.9219) lr 1.4258e-03 eta 0:19:10
epoch [20/50] batch [420/445] time 0.086 (0.086) data 0.000 (0.002) loss 2.1331 (2.1551) teacher_loss 0.8669 (0.8648) loss_zs_kd 1.4962 (1.3850) loss_oracle 0.9028 (0.8826) acc 65.6250 (70.0000) lr 1.4258e-03 eta 0:19:08
epoch [20/50] batch [440/445] time 0.077 (0.086) data 0.000 (0.002) loss 2.0515 (2.1551) teacher_loss 0.7813 (0.8627) loss_zs_kd 1.1149 (1.3895) loss_oracle 0.8080 (0.8828) acc 71.8750 (70.0213) lr 1.4258e-03 eta 0:19:03
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,200
* accuracy: 68.8%
* error: 31.2%
* macro_f1: 53.2%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,924
* accuracy: 48.5%
* error: 51.5%
* macro_f1: 28.4%
******* Domain 3 best val acc:      69.2%, epoch: 19 *******
******* Domain 3 best val test acc: 48.4%, epoch: 19 *******
******* Domain 3 best test acc:     49.7%, epoch: 10 *******
epoch [21/50] batch [20/445] time 0.076 (0.113) data 0.000 (0.029) loss 2.2189 (2.1997) teacher_loss 0.9358 (0.8675) loss_zs_kd 1.5949 (1.4849) loss_oracle 0.8997 (0.8980) acc 65.6250 (68.2812) lr 1.3681e-03 eta 0:25:09
epoch [21/50] batch [40/445] time 0.081 (0.097) data 0.000 (0.015) loss 2.0607 (2.1735) teacher_loss 0.7863 (0.8540) loss_zs_kd 1.2226 (1.4278) loss_oracle 0.8609 (0.8807) acc 78.1250 (69.7656) lr 1.3681e-03 eta 0:21:30
epoch [21/50] batch [60/445] time 0.077 (0.092) data 0.001 (0.010) loss 2.3710 (2.1721) teacher_loss 1.0738 (0.8572) loss_zs_kd 1.2471 (1.3976) loss_oracle 0.8760 (0.8807) acc 59.3750 (68.5938) lr 1.3681e-03 eta 0:20:20
epoch [21/50] batch [80/445] time 0.086 (0.090) data 0.000 (0.008) loss 2.1822 (2.1579) teacher_loss 0.8611 (0.8471) loss_zs_kd 1.2247 (1.3940) loss_oracle 0.8734 (0.8741) acc 71.8750 (69.1016) lr 1.3681e-03 eta 0:19:47
epoch [21/50] batch [100/445] time 0.081 (0.089) data 0.000 (0.006) loss 2.0731 (2.1470) teacher_loss 0.8495 (0.8399) loss_zs_kd 1.4890 (1.4106) loss_oracle 0.8355 (0.8744) acc 71.8750 (69.5625) lr 1.3681e-03 eta 0:19:35
epoch [21/50] batch [120/445] time 0.093 (0.088) data 0.000 (0.005) loss 2.3339 (2.1466) teacher_loss 0.9613 (0.8397) loss_zs_kd 1.3279 (1.4112) loss_oracle 0.9163 (0.8759) acc 62.5000 (69.6615) lr 1.3681e-03 eta 0:19:25
epoch [21/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.004) loss 2.0982 (2.1440) teacher_loss 0.7464 (0.8408) loss_zs_kd 1.2721 (1.4034) loss_oracle 0.8726 (0.8728) acc 75.0000 (69.6652) lr 1.3681e-03 eta 0:19:09
epoch [21/50] batch [160/445] time 0.081 (0.086) data 0.000 (0.004) loss 2.0139 (2.1456) teacher_loss 0.7114 (0.8420) loss_zs_kd 1.3771 (1.3956) loss_oracle 0.8825 (0.8722) acc 78.1250 (69.5898) lr 1.3681e-03 eta 0:18:58
epoch [21/50] batch [180/445] time 0.079 (0.086) data 0.000 (0.004) loss 1.7154 (2.1450) teacher_loss 0.5506 (0.8440) loss_zs_kd 1.3670 (1.3887) loss_oracle 0.8147 (0.8717) acc 90.6250 (69.6007) lr 1.3681e-03 eta 0:18:52
epoch [21/50] batch [200/445] time 0.080 (0.085) data 0.000 (0.003) loss 2.3669 (2.1563) teacher_loss 1.0404 (0.8564) loss_zs_kd 0.8916 (1.3755) loss_oracle 0.8914 (0.8698) acc 62.5000 (69.0625) lr 1.3681e-03 eta 0:18:42
epoch [21/50] batch [220/445] time 0.077 (0.085) data 0.001 (0.003) loss 1.9976 (2.1522) teacher_loss 0.6602 (0.8529) loss_zs_kd 1.8555 (1.3686) loss_oracle 0.9018 (0.8697) acc 75.0000 (69.1761) lr 1.3681e-03 eta 0:18:35
epoch [21/50] batch [240/445] time 0.080 (0.084) data 0.000 (0.003) loss 1.9730 (2.1529) teacher_loss 0.6249 (0.8514) loss_zs_kd 1.6217 (1.3699) loss_oracle 0.8505 (0.8681) acc 81.2500 (69.3750) lr 1.3681e-03 eta 0:18:25
epoch [21/50] batch [260/445] time 0.078 (0.084) data 0.000 (0.003) loss 2.1035 (2.1506) teacher_loss 0.7689 (0.8485) loss_zs_kd 1.2820 (1.3760) loss_oracle 0.8547 (0.8672) acc 78.1250 (69.6034) lr 1.3681e-03 eta 0:18:25
epoch [21/50] batch [280/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.4427 (2.1513) teacher_loss 1.0585 (0.8483) loss_zs_kd 0.9831 (1.3779) loss_oracle 0.8912 (0.8675) acc 71.8750 (69.5312) lr 1.3681e-03 eta 0:18:24
epoch [21/50] batch [300/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.3236 (2.1526) teacher_loss 0.9865 (0.8489) loss_zs_kd 1.3947 (1.3770) loss_oracle 0.8466 (0.8674) acc 62.5000 (69.4896) lr 1.3681e-03 eta 0:18:23
epoch [21/50] batch [320/445] time 0.083 (0.085) data 0.000 (0.002) loss 2.0706 (2.1536) teacher_loss 0.8266 (0.8501) loss_zs_kd 1.7883 (1.3829) loss_oracle 0.8354 (0.8673) acc 68.7500 (69.4336) lr 1.3681e-03 eta 0:18:21
epoch [21/50] batch [340/445] time 0.080 (0.085) data 0.000 (0.002) loss 2.2678 (2.1517) teacher_loss 0.9925 (0.8493) loss_zs_kd 1.8800 (1.3877) loss_oracle 0.8429 (0.8676) acc 71.8750 (69.5772) lr 1.3681e-03 eta 0:18:32
epoch [21/50] batch [360/445] time 0.079 (0.085) data 0.000 (0.002) loss 2.1013 (2.1496) teacher_loss 0.8975 (0.8491) loss_zs_kd 1.3329 (1.3872) loss_oracle 0.8106 (0.8660) acc 62.5000 (69.5312) lr 1.3681e-03 eta 0:18:29
epoch [21/50] batch [380/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.0740 (2.1491) teacher_loss 0.7602 (0.8491) loss_zs_kd 2.0021 (1.3901) loss_oracle 0.8597 (0.8657) acc 81.2500 (69.6793) lr 1.3681e-03 eta 0:18:24
epoch [21/50] batch [400/445] time 0.081 (0.085) data 0.000 (0.002) loss 1.7874 (2.1465) teacher_loss 0.5010 (0.8478) loss_zs_kd 1.2891 (1.3931) loss_oracle 0.8899 (0.8649) acc 78.1250 (69.6953) lr 1.3681e-03 eta 0:18:21
epoch [21/50] batch [420/445] time 0.073 (0.085) data 0.000 (0.002) loss 2.5751 (2.1472) teacher_loss 1.1974 (0.8490) loss_zs_kd 1.6447 (1.3930) loss_oracle 0.8838 (0.8646) acc 53.1250 (69.6429) lr 1.3681e-03 eta 0:18:16
epoch [21/50] batch [440/445] time 0.074 (0.084) data 0.000 (0.002) loss 2.2900 (2.1448) teacher_loss 0.9546 (0.8460) loss_zs_kd 1.5635 (1.3971) loss_oracle 0.9036 (0.8645) acc 62.5000 (69.7443) lr 1.3681e-03 eta 0:18:09
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,170
* accuracy: 68.3%
* error: 31.7%
* macro_f1: 52.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,974
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 28.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      69.2%, epoch: 19 *******
******* Domain 3 best val test acc: 48.4%, epoch: 19 *******
******* Domain 3 best test acc:     49.7%, epoch: 21 *******
epoch [22/50] batch [20/445] time 0.086 (0.127) data 0.000 (0.037) loss 2.0837 (2.1535) teacher_loss 0.7203 (0.8069) loss_zs_kd 1.6142 (1.5702) loss_oracle 0.8187 (0.8848) acc 75.0000 (71.5625) lr 1.3090e-03 eta 0:27:11
epoch [22/50] batch [40/445] time 0.083 (0.105) data 0.000 (0.019) loss 2.0296 (2.1997) teacher_loss 0.7521 (0.8320) loss_zs_kd 1.5870 (1.5309) loss_oracle 0.7698 (0.8752) acc 75.0000 (71.5625) lr 1.3090e-03 eta 0:22:32
epoch [22/50] batch [60/445] time 0.087 (0.097) data 0.000 (0.013) loss 2.2340 (2.1963) teacher_loss 0.9449 (0.8520) loss_zs_kd 1.3203 (1.5051) loss_oracle 0.8790 (0.8710) acc 62.5000 (69.7917) lr 1.3090e-03 eta 0:20:46
epoch [22/50] batch [80/445] time 0.079 (0.098) data 0.000 (0.010) loss 2.2398 (2.1853) teacher_loss 0.9728 (0.8625) loss_zs_kd 1.0193 (1.4589) loss_oracle 0.8405 (0.8641) acc 68.7500 (69.3750) lr 1.3090e-03 eta 0:20:51
epoch [22/50] batch [100/445] time 0.069 (0.093) data 0.000 (0.008) loss 2.0434 (2.1846) teacher_loss 0.8179 (0.8702) loss_zs_kd 1.0466 (1.4297) loss_oracle 0.8510 (0.8603) acc 75.0000 (69.1562) lr 1.3090e-03 eta 0:19:55
epoch [22/50] batch [120/445] time 0.084 (0.091) data 0.000 (0.007) loss 2.2596 (2.1712) teacher_loss 0.9078 (0.8628) loss_zs_kd 1.2209 (1.4255) loss_oracle 0.8598 (0.8582) acc 71.8750 (69.2969) lr 1.3090e-03 eta 0:19:25
epoch [22/50] batch [140/445] time 0.078 (0.089) data 0.000 (0.006) loss 2.1976 (2.1766) teacher_loss 0.8562 (0.8676) loss_zs_kd 1.5943 (1.4303) loss_oracle 0.9513 (0.8587) acc 65.6250 (69.5536) lr 1.3090e-03 eta 0:18:58
epoch [22/50] batch [160/445] time 0.079 (0.088) data 0.000 (0.005) loss 2.1654 (2.1718) teacher_loss 0.8768 (0.8695) loss_zs_kd 1.4240 (1.4238) loss_oracle 0.8343 (0.8556) acc 65.6250 (69.6484) lr 1.3090e-03 eta 0:18:39
epoch [22/50] batch [180/445] time 0.079 (0.088) data 0.001 (0.004) loss 1.8619 (2.1618) teacher_loss 0.6541 (0.8641) loss_zs_kd 1.3717 (1.4197) loss_oracle 0.7803 (0.8544) acc 78.1250 (69.8958) lr 1.3090e-03 eta 0:18:36
epoch [22/50] batch [200/445] time 0.083 (0.087) data 0.000 (0.004) loss 2.1066 (2.1586) teacher_loss 0.8458 (0.8622) loss_zs_kd 1.6611 (1.4304) loss_oracle 0.9125 (0.8563) acc 78.1250 (70.0000) lr 1.3090e-03 eta 0:18:29
epoch [22/50] batch [220/445] time 0.086 (0.087) data 0.000 (0.004) loss 1.8955 (2.1594) teacher_loss 0.6548 (0.8634) loss_zs_kd 1.3684 (1.4482) loss_oracle 0.8274 (0.8578) acc 78.1250 (69.9148) lr 1.3090e-03 eta 0:18:25
epoch [22/50] batch [240/445] time 0.088 (0.087) data 0.000 (0.003) loss 2.1706 (2.1586) teacher_loss 0.8447 (0.8621) loss_zs_kd 1.2006 (1.4502) loss_oracle 0.8624 (0.8584) acc 68.7500 (70.0000) lr 1.3090e-03 eta 0:18:22
epoch [22/50] batch [260/445] time 0.087 (0.087) data 0.000 (0.003) loss 2.2924 (2.1544) teacher_loss 0.9809 (0.8592) loss_zs_kd 1.5275 (1.4475) loss_oracle 0.8480 (0.8586) acc 65.6250 (70.1923) lr 1.3090e-03 eta 0:18:18
epoch [22/50] batch [280/445] time 0.086 (0.087) data 0.000 (0.003) loss 2.0991 (2.1519) teacher_loss 0.8226 (0.8580) loss_zs_kd 1.4919 (1.4508) loss_oracle 0.8450 (0.8593) acc 71.8750 (70.2344) lr 1.3090e-03 eta 0:18:15
epoch [22/50] batch [300/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.2899 (2.1471) teacher_loss 0.9357 (0.8523) loss_zs_kd 1.4758 (1.4561) loss_oracle 0.8154 (0.8604) acc 68.7500 (70.4479) lr 1.3090e-03 eta 0:18:11
epoch [22/50] batch [320/445] time 0.084 (0.087) data 0.000 (0.003) loss 2.1072 (2.1462) teacher_loss 0.8166 (0.8517) loss_zs_kd 1.2583 (1.4541) loss_oracle 0.8639 (0.8617) acc 65.6250 (70.4199) lr 1.3090e-03 eta 0:18:09
epoch [22/50] batch [340/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.2532 (2.1433) teacher_loss 0.8355 (0.8473) loss_zs_kd 1.5523 (1.4587) loss_oracle 0.9244 (0.8620) acc 68.7500 (70.4963) lr 1.3090e-03 eta 0:18:06
epoch [22/50] batch [360/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.2241 (2.1442) teacher_loss 0.8569 (0.8459) loss_zs_kd 1.8516 (1.4627) loss_oracle 0.9056 (0.8636) acc 59.3750 (70.3733) lr 1.3090e-03 eta 0:18:00
epoch [22/50] batch [380/445] time 0.082 (0.086) data 0.000 (0.002) loss 1.8322 (2.1438) teacher_loss 0.5901 (0.8448) loss_zs_kd 1.3674 (1.4656) loss_oracle 0.8059 (0.8646) acc 78.1250 (70.3289) lr 1.3090e-03 eta 0:17:56
epoch [22/50] batch [400/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.4046 (2.1449) teacher_loss 1.0502 (0.8451) loss_zs_kd 1.2779 (1.4619) loss_oracle 0.9929 (0.8657) acc 68.7500 (70.3828) lr 1.3090e-03 eta 0:17:55
epoch [22/50] batch [420/445] time 0.083 (0.086) data 0.000 (0.002) loss 1.7351 (2.1433) teacher_loss 0.5176 (0.8428) loss_zs_kd 1.3820 (1.4622) loss_oracle 0.8996 (0.8667) acc 90.6250 (70.4762) lr 1.3090e-03 eta 0:17:53
epoch [22/50] batch [440/445] time 0.075 (0.086) data 0.000 (0.002) loss 2.3202 (2.1426) teacher_loss 1.0267 (0.8424) loss_zs_kd 1.2260 (1.4630) loss_oracle 0.9022 (0.8672) acc 68.7500 (70.5398) lr 1.3090e-03 eta 0:17:47
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,232
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 55.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,020
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 30.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      69.3%, epoch: 22 *******
******* Domain 3 best val test acc: 50.9%, epoch: 22 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [23/50] batch [20/445] time 0.081 (0.110) data 0.000 (0.026) loss 2.1615 (2.1147) teacher_loss 0.8446 (0.8221) loss_zs_kd 1.6949 (1.4296) loss_oracle 0.9241 (0.8805) acc 75.0000 (70.9375) lr 1.2487e-03 eta 0:22:48
epoch [23/50] batch [40/445] time 0.079 (0.094) data 0.000 (0.013) loss 2.1297 (2.1299) teacher_loss 0.8766 (0.8418) loss_zs_kd 1.3541 (1.4120) loss_oracle 0.8200 (0.8746) acc 59.3750 (71.0156) lr 1.2487e-03 eta 0:19:29
epoch [23/50] batch [60/445] time 0.084 (0.090) data 0.000 (0.009) loss 2.4732 (2.1465) teacher_loss 1.1941 (0.8682) loss_zs_kd 1.4174 (1.4059) loss_oracle 0.8988 (0.8651) acc 53.1250 (69.8438) lr 1.2487e-03 eta 0:18:30
epoch [23/50] batch [80/445] time 0.085 (0.088) data 0.000 (0.007) loss 2.3864 (2.1320) teacher_loss 1.0582 (0.8619) loss_zs_kd 1.3937 (1.4194) loss_oracle 0.8283 (0.8577) acc 50.0000 (69.4922) lr 1.2487e-03 eta 0:18:07
epoch [23/50] batch [100/445] time 0.081 (0.087) data 0.000 (0.005) loss 1.8156 (2.1303) teacher_loss 0.5952 (0.8614) loss_zs_kd 1.4422 (1.4093) loss_oracle 0.8021 (0.8563) acc 81.2500 (69.3750) lr 1.2487e-03 eta 0:17:50
epoch [23/50] batch [120/445] time 0.085 (0.086) data 0.000 (0.005) loss 2.2180 (2.1299) teacher_loss 0.8778 (0.8545) loss_zs_kd 1.4643 (1.4201) loss_oracle 0.7920 (0.8565) acc 62.5000 (70.0260) lr 1.2487e-03 eta 0:17:43
epoch [23/50] batch [140/445] time 0.085 (0.086) data 0.000 (0.004) loss 2.3879 (2.1355) teacher_loss 1.0279 (0.8557) loss_zs_kd 1.4184 (1.4290) loss_oracle 0.8608 (0.8578) acc 71.8750 (70.2232) lr 1.2487e-03 eta 0:17:39
epoch [23/50] batch [160/445] time 0.071 (0.085) data 0.000 (0.004) loss 2.8632 (2.1377) teacher_loss 1.3925 (0.8560) loss_zs_kd 0.9723 (1.4235) loss_oracle 1.1090 (0.8616) acc 46.8750 (70.1367) lr 1.2487e-03 eta 0:17:30
epoch [23/50] batch [180/445] time 0.081 (0.085) data 0.000 (0.003) loss 2.0972 (2.1394) teacher_loss 0.8157 (0.8578) loss_zs_kd 1.5657 (1.4345) loss_oracle 0.8588 (0.8633) acc 71.8750 (69.9306) lr 1.2487e-03 eta 0:17:17
epoch [23/50] batch [200/445] time 0.099 (0.086) data 0.000 (0.003) loss 2.0977 (2.1422) teacher_loss 0.7927 (0.8586) loss_zs_kd 1.4288 (1.4462) loss_oracle 0.8879 (0.8653) acc 68.7500 (69.8750) lr 1.2487e-03 eta 0:17:29
epoch [23/50] batch [220/445] time 0.085 (0.085) data 0.000 (0.003) loss 2.2836 (2.1425) teacher_loss 1.0394 (0.8596) loss_zs_kd 1.3816 (1.4529) loss_oracle 0.9130 (0.8681) acc 62.5000 (69.8295) lr 1.2487e-03 eta 0:17:22
epoch [23/50] batch [240/445] time 0.092 (0.085) data 0.000 (0.002) loss 2.5119 (2.1475) teacher_loss 1.2248 (0.8632) loss_zs_kd 1.6014 (1.4557) loss_oracle 0.7719 (0.8698) acc 56.2500 (69.5182) lr 1.2487e-03 eta 0:17:21
epoch [23/50] batch [260/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.4684 (2.1490) teacher_loss 1.1815 (0.8629) loss_zs_kd 1.4974 (1.4552) loss_oracle 0.9918 (0.8711) acc 62.5000 (69.6394) lr 1.2487e-03 eta 0:17:16
epoch [23/50] batch [280/445] time 0.077 (0.085) data 0.000 (0.002) loss 2.4438 (2.1418) teacher_loss 1.1263 (0.8563) loss_zs_kd 1.6529 (1.4525) loss_oracle 0.7726 (0.8691) acc 71.8750 (69.8996) lr 1.2487e-03 eta 0:17:12
epoch [23/50] batch [300/445] time 0.093 (0.085) data 0.000 (0.002) loss 1.9474 (2.1378) teacher_loss 0.6585 (0.8533) loss_zs_kd 1.4200 (1.4470) loss_oracle 0.9486 (0.8684) acc 81.2500 (70.0312) lr 1.2487e-03 eta 0:17:10
epoch [23/50] batch [320/445] time 0.087 (0.085) data 0.000 (0.002) loss 2.0613 (2.1392) teacher_loss 0.7636 (0.8547) loss_zs_kd 1.6059 (1.4462) loss_oracle 0.8280 (0.8689) acc 71.8750 (70.0293) lr 1.2487e-03 eta 0:17:09
epoch [23/50] batch [340/445] time 0.091 (0.085) data 0.000 (0.002) loss 2.2474 (2.1373) teacher_loss 0.9157 (0.8535) loss_zs_kd 1.3427 (1.4403) loss_oracle 0.9178 (0.8685) acc 68.7500 (70.1103) lr 1.2487e-03 eta 0:17:07
epoch [23/50] batch [360/445] time 0.093 (0.085) data 0.000 (0.002) loss 2.4260 (2.1370) teacher_loss 1.1529 (0.8522) loss_zs_kd 1.1798 (1.4368) loss_oracle 0.7922 (0.8690) acc 50.0000 (70.0781) lr 1.2487e-03 eta 0:17:06
epoch [23/50] batch [380/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.1489 (2.1387) teacher_loss 0.8426 (0.8516) loss_zs_kd 1.4533 (1.4377) loss_oracle 0.8861 (0.8703) acc 75.0000 (70.0822) lr 1.2487e-03 eta 0:17:01
epoch [23/50] batch [400/445] time 0.095 (0.084) data 0.000 (0.002) loss 1.9291 (2.1442) teacher_loss 0.5791 (0.8550) loss_zs_kd 1.4375 (1.4385) loss_oracle 0.8808 (0.8723) acc 81.2500 (70.0781) lr 1.2487e-03 eta 0:16:58
epoch [23/50] batch [420/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.2601 (2.1439) teacher_loss 0.9201 (0.8545) loss_zs_kd 1.4796 (1.4376) loss_oracle 0.9779 (0.8728) acc 62.5000 (70.0521) lr 1.2487e-03 eta 0:16:54
epoch [23/50] batch [440/445] time 0.082 (0.084) data 0.000 (0.001) loss 2.2158 (2.1430) teacher_loss 0.9519 (0.8537) loss_zs_kd 1.8296 (1.4384) loss_oracle 0.8202 (0.8727) acc 65.6250 (70.0852) lr 1.2487e-03 eta 0:16:49
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,180
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 52.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,892
* accuracy: 47.7%
* error: 52.3%
* macro_f1: 27.8%
******* Domain 3 best val acc:      69.3%, epoch: 22 *******
******* Domain 3 best val test acc: 50.9%, epoch: 22 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [24/50] batch [20/445] time 0.089 (0.115) data 0.000 (0.025) loss 1.7314 (2.0843) teacher_loss 0.4275 (0.8097) loss_zs_kd 1.3274 (1.4191) loss_oracle 0.8433 (0.8505) acc 75.0000 (69.6875) lr 1.1874e-03 eta 0:22:55
epoch [24/50] batch [40/445] time 0.084 (0.099) data 0.000 (0.013) loss 2.1031 (2.0774) teacher_loss 0.8485 (0.8027) loss_zs_kd 1.4203 (1.4595) loss_oracle 0.8618 (0.8621) acc 71.8750 (70.0781) lr 1.1874e-03 eta 0:19:46
epoch [24/50] batch [60/445] time 0.083 (0.094) data 0.001 (0.009) loss 1.9161 (2.1265) teacher_loss 0.6685 (0.8504) loss_zs_kd 1.2873 (1.4436) loss_oracle 0.8761 (0.8711) acc 68.7500 (68.8021) lr 1.1874e-03 eta 0:18:48
epoch [24/50] batch [80/445] time 0.084 (0.092) data 0.000 (0.007) loss 2.0701 (2.1490) teacher_loss 0.8293 (0.8796) loss_zs_kd 1.2015 (1.4074) loss_oracle 0.9271 (0.8688) acc 62.5000 (68.0859) lr 1.1874e-03 eta 0:18:12
epoch [24/50] batch [100/445] time 0.086 (0.090) data 0.000 (0.005) loss 2.1847 (2.1577) teacher_loss 0.9095 (0.8897) loss_zs_kd 1.2331 (1.3976) loss_oracle 0.8881 (0.8686) acc 62.5000 (67.8125) lr 1.1874e-03 eta 0:17:47
epoch [24/50] batch [120/445] time 0.076 (0.088) data 0.000 (0.004) loss 2.2354 (2.1551) teacher_loss 0.9491 (0.8850) loss_zs_kd 1.2474 (1.3939) loss_oracle 0.8939 (0.8722) acc 65.6250 (68.1510) lr 1.1874e-03 eta 0:17:32
epoch [24/50] batch [140/445] time 0.075 (0.087) data 0.000 (0.004) loss 2.3598 (2.1463) teacher_loss 1.0661 (0.8765) loss_zs_kd 1.7683 (1.4174) loss_oracle 0.9400 (0.8750) acc 53.1250 (68.4375) lr 1.1874e-03 eta 0:17:15
epoch [24/50] batch [160/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.8984 (2.1271) teacher_loss 0.7060 (0.8586) loss_zs_kd 1.7918 (1.4198) loss_oracle 0.8477 (0.8736) acc 68.7500 (69.2188) lr 1.1874e-03 eta 0:17:09
epoch [24/50] batch [180/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.9242 (2.1235) teacher_loss 0.6135 (0.8537) loss_zs_kd 1.5308 (1.4318) loss_oracle 0.9024 (0.8755) acc 81.2500 (69.4792) lr 1.1874e-03 eta 0:17:07
epoch [24/50] batch [200/445] time 0.084 (0.086) data 0.000 (0.003) loss 1.9467 (2.1256) teacher_loss 0.6994 (0.8521) loss_zs_kd 1.5607 (1.4475) loss_oracle 0.8646 (0.8765) acc 78.1250 (69.7656) lr 1.1874e-03 eta 0:17:01
epoch [24/50] batch [220/445] time 0.085 (0.086) data 0.000 (0.003) loss 2.0859 (2.1268) teacher_loss 0.8488 (0.8513) loss_zs_kd 1.1801 (1.4561) loss_oracle 0.8590 (0.8789) acc 68.7500 (69.7869) lr 1.1874e-03 eta 0:16:53
epoch [24/50] batch [240/445] time 0.090 (0.086) data 0.000 (0.002) loss 2.3324 (2.1219) teacher_loss 1.0043 (0.8478) loss_zs_kd 1.2224 (1.4486) loss_oracle 0.8757 (0.8767) acc 68.7500 (69.9870) lr 1.1874e-03 eta 0:16:51
epoch [24/50] batch [260/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.0631 (2.1211) teacher_loss 0.8038 (0.8464) loss_zs_kd 1.7534 (1.4511) loss_oracle 0.8226 (0.8755) acc 78.1250 (70.1923) lr 1.1874e-03 eta 0:16:48
epoch [24/50] batch [280/445] time 0.081 (0.086) data 0.000 (0.002) loss 2.7253 (2.1220) teacher_loss 1.5043 (0.8473) loss_zs_kd 1.3896 (1.4525) loss_oracle 0.8864 (0.8737) acc 50.0000 (70.2455) lr 1.1874e-03 eta 0:16:46
epoch [24/50] batch [300/445] time 0.088 (0.086) data 0.000 (0.002) loss 2.1124 (2.1255) teacher_loss 0.8843 (0.8495) loss_zs_kd 1.4579 (1.4595) loss_oracle 0.8624 (0.8746) acc 68.7500 (70.2188) lr 1.1874e-03 eta 0:16:42
epoch [24/50] batch [320/445] time 0.090 (0.085) data 0.000 (0.002) loss 2.1246 (2.1273) teacher_loss 0.8444 (0.8488) loss_zs_kd 1.4136 (1.4612) loss_oracle 0.8865 (0.8755) acc 71.8750 (70.2246) lr 1.1874e-03 eta 0:16:39
epoch [24/50] batch [340/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.3700 (2.1321) teacher_loss 1.1222 (0.8509) loss_zs_kd 1.3300 (1.4598) loss_oracle 0.9049 (0.8774) acc 68.7500 (70.2390) lr 1.1874e-03 eta 0:16:47
epoch [24/50] batch [360/445] time 0.077 (0.086) data 0.000 (0.002) loss 2.1321 (2.1289) teacher_loss 0.7681 (0.8472) loss_zs_kd 1.5921 (1.4575) loss_oracle 0.9043 (0.8779) acc 71.8750 (70.4340) lr 1.1874e-03 eta 0:16:42
epoch [24/50] batch [380/445] time 0.086 (0.086) data 0.000 (0.002) loss 1.9525 (2.1299) teacher_loss 0.7113 (0.8473) loss_zs_kd 1.4792 (1.4564) loss_oracle 0.9054 (0.8793) acc 75.0000 (70.4276) lr 1.1874e-03 eta 0:16:39
epoch [24/50] batch [400/445] time 0.080 (0.086) data 0.000 (0.002) loss 2.0405 (2.1313) teacher_loss 0.6807 (0.8473) loss_zs_kd 1.5877 (1.4550) loss_oracle 0.9809 (0.8808) acc 71.8750 (70.4297) lr 1.1874e-03 eta 0:16:36
epoch [24/50] batch [420/445] time 0.082 (0.086) data 0.000 (0.001) loss 2.0903 (2.1330) teacher_loss 0.8015 (0.8469) loss_zs_kd 1.3166 (1.4548) loss_oracle 0.8593 (0.8826) acc 68.7500 (70.4762) lr 1.1874e-03 eta 0:16:34
epoch [24/50] batch [440/445] time 0.083 (0.086) data 0.000 (0.001) loss 2.0041 (2.1320) teacher_loss 0.7888 (0.8459) loss_zs_kd 1.6489 (1.4526) loss_oracle 0.7989 (0.8822) acc 71.8750 (70.5753) lr 1.1874e-03 eta 0:16:30
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,207
* accuracy: 68.9%
* error: 31.1%
* macro_f1: 54.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,958
* accuracy: 49.3%
* error: 50.7%
* macro_f1: 29.3%
******* Domain 3 best val acc:      69.3%, epoch: 22 *******
******* Domain 3 best val test acc: 50.9%, epoch: 22 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [25/50] batch [20/445] time 0.084 (0.112) data 0.000 (0.027) loss 2.0887 (2.1165) teacher_loss 0.7714 (0.8194) loss_zs_kd 1.4997 (1.4728) loss_oracle 0.9262 (0.8809) acc 65.6250 (71.4062) lr 1.1253e-03 eta 0:21:34
epoch [25/50] batch [40/445] time 0.081 (0.098) data 0.000 (0.013) loss 2.0833 (2.1376) teacher_loss 0.6487 (0.8342) loss_zs_kd 1.5116 (1.4656) loss_oracle 0.9213 (0.8849) acc 78.1250 (71.8750) lr 1.1253e-03 eta 0:18:55
epoch [25/50] batch [60/445] time 0.081 (0.094) data 0.001 (0.009) loss 2.4027 (2.1315) teacher_loss 1.0082 (0.8266) loss_zs_kd 1.4310 (1.4701) loss_oracle 0.9591 (0.8861) acc 62.5000 (71.8229) lr 1.1253e-03 eta 0:18:06
epoch [25/50] batch [80/445] time 0.089 (0.094) data 0.000 (0.007) loss 2.3083 (2.1383) teacher_loss 1.0022 (0.8371) loss_zs_kd 1.2192 (1.4676) loss_oracle 0.8230 (0.8863) acc 65.6250 (71.3281) lr 1.1253e-03 eta 0:17:59
epoch [25/50] batch [100/445] time 0.086 (0.092) data 0.000 (0.006) loss 1.8579 (2.1601) teacher_loss 0.6619 (0.8601) loss_zs_kd 1.5041 (1.4613) loss_oracle 0.8055 (0.8906) acc 81.2500 (70.5625) lr 1.1253e-03 eta 0:17:34
epoch [25/50] batch [120/445] time 0.083 (0.091) data 0.000 (0.005) loss 2.2482 (2.1636) teacher_loss 1.1179 (0.8660) loss_zs_kd 1.4606 (1.4734) loss_oracle 0.7416 (0.8905) acc 59.3750 (70.4688) lr 1.1253e-03 eta 0:17:17
epoch [25/50] batch [140/445] time 0.087 (0.090) data 0.000 (0.004) loss 2.4735 (2.1665) teacher_loss 1.1374 (0.8707) loss_zs_kd 1.4087 (1.4658) loss_oracle 0.9379 (0.8876) acc 62.5000 (70.2455) lr 1.1253e-03 eta 0:17:06
epoch [25/50] batch [160/445] time 0.078 (0.089) data 0.000 (0.004) loss 1.9179 (2.1619) teacher_loss 0.6501 (0.8649) loss_zs_kd 1.7476 (1.4682) loss_oracle 0.9185 (0.8880) acc 81.2500 (70.4883) lr 1.1253e-03 eta 0:16:51
epoch [25/50] batch [180/445] time 0.079 (0.088) data 0.000 (0.003) loss 2.0717 (2.1589) teacher_loss 0.7871 (0.8628) loss_zs_kd 1.6335 (1.4689) loss_oracle 0.8618 (0.8851) acc 78.1250 (70.5382) lr 1.1253e-03 eta 0:16:37
epoch [25/50] batch [200/445] time 0.080 (0.087) data 0.000 (0.003) loss 2.4505 (2.1602) teacher_loss 1.0645 (0.8628) loss_zs_kd 1.2127 (1.4728) loss_oracle 0.8778 (0.8843) acc 68.7500 (70.5625) lr 1.1253e-03 eta 0:16:30
epoch [25/50] batch [220/445] time 0.083 (0.087) data 0.000 (0.003) loss 1.9151 (2.1570) teacher_loss 0.7122 (0.8614) loss_zs_kd 1.4404 (1.4734) loss_oracle 0.8097 (0.8819) acc 68.7500 (70.5256) lr 1.1253e-03 eta 0:16:28
epoch [25/50] batch [240/445] time 0.084 (0.087) data 0.000 (0.003) loss 2.3577 (2.1535) teacher_loss 1.0337 (0.8614) loss_zs_kd 1.1580 (1.4663) loss_oracle 0.8832 (0.8797) acc 65.6250 (70.4818) lr 1.1253e-03 eta 0:16:26
epoch [25/50] batch [260/445] time 0.075 (0.087) data 0.000 (0.002) loss 2.1212 (2.1479) teacher_loss 0.7992 (0.8578) loss_zs_kd 1.4853 (1.4719) loss_oracle 0.8890 (0.8780) acc 65.6250 (70.6010) lr 1.1253e-03 eta 0:16:18
epoch [25/50] batch [280/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.0178 (2.1469) teacher_loss 0.7356 (0.8601) loss_zs_kd 1.5270 (1.4666) loss_oracle 0.8035 (0.8753) acc 78.1250 (70.5469) lr 1.1253e-03 eta 0:16:11
epoch [25/50] batch [300/445] time 0.093 (0.086) data 0.000 (0.002) loss 2.2305 (2.1430) teacher_loss 0.9432 (0.8579) loss_zs_kd 1.4665 (1.4664) loss_oracle 0.9133 (0.8741) acc 75.0000 (70.6354) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [320/445] time 0.079 (0.086) data 0.000 (0.002) loss 1.9585 (2.1408) teacher_loss 0.6956 (0.8560) loss_zs_kd 1.3967 (1.4679) loss_oracle 0.8750 (0.8731) acc 68.7500 (70.6543) lr 1.1253e-03 eta 0:16:04
epoch [25/50] batch [340/445] time 0.097 (0.086) data 0.000 (0.002) loss 2.1572 (2.1414) teacher_loss 0.8940 (0.8578) loss_zs_kd 1.1373 (1.4700) loss_oracle 0.8536 (0.8721) acc 65.6250 (70.6250) lr 1.1253e-03 eta 0:16:01
epoch [25/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.1201 (2.1370) teacher_loss 0.8140 (0.8551) loss_zs_kd 1.4395 (1.4654) loss_oracle 0.8774 (0.8712) acc 62.5000 (70.6250) lr 1.1253e-03 eta 0:15:58
epoch [25/50] batch [380/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.1679 (2.1345) teacher_loss 0.9321 (0.8534) loss_zs_kd 1.2363 (1.4684) loss_oracle 0.8607 (0.8710) acc 71.8750 (70.6908) lr 1.1253e-03 eta 0:15:59
epoch [25/50] batch [400/445] time 0.076 (0.086) data 0.000 (0.002) loss 1.8630 (2.1310) teacher_loss 0.6059 (0.8501) loss_zs_kd 1.8950 (1.4673) loss_oracle 0.8111 (0.8710) acc 68.7500 (70.8359) lr 1.1253e-03 eta 0:15:56
epoch [25/50] batch [420/445] time 0.081 (0.085) data 0.000 (0.002) loss 1.9048 (2.1292) teacher_loss 0.6586 (0.8484) loss_zs_kd 1.7928 (1.4691) loss_oracle 0.8264 (0.8714) acc 68.7500 (70.8557) lr 1.1253e-03 eta 0:15:53
epoch [25/50] batch [440/445] time 0.078 (0.086) data 0.000 (0.002) loss 2.2972 (2.1261) teacher_loss 0.9786 (0.8464) loss_zs_kd 1.3864 (1.4672) loss_oracle 0.9086 (0.8702) acc 68.7500 (70.9659) lr 1.1253e-03 eta 0:15:51
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,227
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 54.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,987
* accuracy: 50.1%
* error: 49.9%
* macro_f1: 29.6%
******* Domain 3 best val acc:      69.3%, epoch: 22 *******
******* Domain 3 best val test acc: 50.9%, epoch: 22 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [26/50] batch [20/445] time 0.090 (0.114) data 0.000 (0.028) loss 1.9623 (2.1011) teacher_loss 0.6766 (0.8329) loss_zs_kd 1.4144 (1.4475) loss_oracle 0.8154 (0.8486) acc 68.7500 (72.1875) lr 1.0628e-03 eta 0:21:06
epoch [26/50] batch [40/445] time 0.079 (0.098) data 0.000 (0.014) loss 1.7960 (2.0745) teacher_loss 0.5205 (0.8040) loss_zs_kd 1.7070 (1.4160) loss_oracle 0.8224 (0.8534) acc 78.1250 (73.2031) lr 1.0628e-03 eta 0:18:03
epoch [26/50] batch [60/445] time 0.081 (0.093) data 0.001 (0.009) loss 1.8844 (2.0712) teacher_loss 0.6085 (0.7953) loss_zs_kd 1.3271 (1.4194) loss_oracle 0.8396 (0.8598) acc 90.6250 (73.5417) lr 1.0628e-03 eta 0:17:08
epoch [26/50] batch [80/445] time 0.085 (0.090) data 0.000 (0.007) loss 2.3812 (2.0815) teacher_loss 0.9962 (0.8029) loss_zs_kd 1.5225 (1.4518) loss_oracle 0.8877 (0.8634) acc 68.7500 (73.0078) lr 1.0628e-03 eta 0:16:33
epoch [26/50] batch [100/445] time 0.084 (0.089) data 0.000 (0.006) loss 1.7349 (2.0823) teacher_loss 0.4500 (0.7997) loss_zs_kd 1.4923 (1.4413) loss_oracle 0.8706 (0.8609) acc 90.6250 (73.6250) lr 1.0628e-03 eta 0:16:19
epoch [26/50] batch [120/445] time 0.083 (0.088) data 0.000 (0.005) loss 2.2005 (2.0833) teacher_loss 0.7840 (0.7995) loss_zs_kd 1.3143 (1.4400) loss_oracle 0.8780 (0.8605) acc 71.8750 (73.8021) lr 1.0628e-03 eta 0:16:10
epoch [26/50] batch [140/445] time 0.074 (0.087) data 0.000 (0.004) loss 2.1686 (2.0941) teacher_loss 0.9562 (0.8093) loss_zs_kd 1.2478 (1.4379) loss_oracle 0.8848 (0.8614) acc 65.6250 (73.2143) lr 1.0628e-03 eta 0:15:58
epoch [26/50] batch [160/445] time 0.082 (0.087) data 0.000 (0.004) loss 1.8772 (2.1007) teacher_loss 0.6395 (0.8136) loss_zs_kd 1.5242 (1.4301) loss_oracle 0.8632 (0.8605) acc 81.2500 (73.0664) lr 1.0628e-03 eta 0:15:51
epoch [26/50] batch [180/445] time 0.089 (0.086) data 0.000 (0.003) loss 2.1097 (2.1081) teacher_loss 0.7575 (0.8208) loss_zs_kd 1.2376 (1.4330) loss_oracle 0.7864 (0.8590) acc 68.7500 (72.7431) lr 1.0628e-03 eta 0:15:45
epoch [26/50] batch [200/445] time 0.085 (0.088) data 0.000 (0.003) loss 2.1256 (2.1139) teacher_loss 0.8003 (0.8218) loss_zs_kd 2.1242 (1.4390) loss_oracle 0.8428 (0.8609) acc 68.7500 (72.6875) lr 1.0628e-03 eta 0:15:58
epoch [26/50] batch [220/445] time 0.087 (0.088) data 0.000 (0.003) loss 2.0894 (2.1256) teacher_loss 0.9237 (0.8300) loss_zs_kd 1.3365 (1.4406) loss_oracle 0.8106 (0.8620) acc 68.7500 (72.3295) lr 1.0628e-03 eta 0:15:54
epoch [26/50] batch [240/445] time 0.089 (0.087) data 0.000 (0.003) loss 2.0796 (2.1277) teacher_loss 0.9599 (0.8331) loss_zs_kd 1.2209 (1.4377) loss_oracle 0.7960 (0.8607) acc 68.7500 (72.2656) lr 1.0628e-03 eta 0:15:47
epoch [26/50] batch [260/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.0437 (2.1275) teacher_loss 0.8090 (0.8346) loss_zs_kd 1.7174 (1.4376) loss_oracle 0.8396 (0.8609) acc 68.7500 (72.2236) lr 1.0628e-03 eta 0:15:44
epoch [26/50] batch [280/445] time 0.074 (0.087) data 0.000 (0.002) loss 2.0908 (2.1239) teacher_loss 0.8490 (0.8317) loss_zs_kd 1.5543 (1.4472) loss_oracle 0.8384 (0.8629) acc 75.0000 (72.3103) lr 1.0628e-03 eta 0:15:40
epoch [26/50] batch [300/445] time 0.071 (0.086) data 0.000 (0.002) loss 2.3561 (2.1219) teacher_loss 1.1008 (0.8318) loss_zs_kd 1.4807 (1.4471) loss_oracle 0.9182 (0.8628) acc 62.5000 (72.3125) lr 1.0628e-03 eta 0:15:31
epoch [26/50] batch [320/445] time 0.080 (0.086) data 0.000 (0.002) loss 2.0829 (2.1161) teacher_loss 0.7999 (0.8280) loss_zs_kd 1.1044 (1.4484) loss_oracle 0.8365 (0.8624) acc 71.8750 (72.3828) lr 1.0628e-03 eta 0:15:26
epoch [26/50] batch [340/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.0754 (2.1146) teacher_loss 0.7226 (0.8272) loss_zs_kd 1.6214 (1.4452) loss_oracle 0.9191 (0.8622) acc 75.0000 (72.3438) lr 1.0628e-03 eta 0:15:22
epoch [26/50] batch [360/445] time 0.093 (0.086) data 0.000 (0.002) loss 1.8504 (2.1102) teacher_loss 0.5718 (0.8227) loss_zs_kd 1.8514 (1.4458) loss_oracle 0.8115 (0.8634) acc 84.3750 (72.5434) lr 1.0628e-03 eta 0:15:21
epoch [26/50] batch [380/445] time 0.085 (0.086) data 0.000 (0.002) loss 1.8901 (2.1112) teacher_loss 0.6771 (0.8237) loss_zs_kd 1.8025 (1.4516) loss_oracle 0.8341 (0.8636) acc 81.2500 (72.5822) lr 1.0628e-03 eta 0:15:19
epoch [26/50] batch [400/445] time 0.086 (0.086) data 0.000 (0.002) loss 1.9359 (2.1099) teacher_loss 0.6283 (0.8229) loss_zs_kd 1.8340 (1.4526) loss_oracle 0.8775 (0.8633) acc 81.2500 (72.6250) lr 1.0628e-03 eta 0:15:17
epoch [26/50] batch [420/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.0246 (2.1050) teacher_loss 0.6919 (0.8189) loss_zs_kd 1.4091 (1.4520) loss_oracle 0.8756 (0.8626) acc 81.2500 (72.6786) lr 1.0628e-03 eta 0:15:15
epoch [26/50] batch [440/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.3006 (2.1068) teacher_loss 1.0376 (0.8206) loss_zs_kd 1.3441 (1.4490) loss_oracle 0.8903 (0.8630) acc 75.0000 (72.5781) lr 1.0628e-03 eta 0:15:12
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,233
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 55.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,994
* accuracy: 50.2%
* error: 49.8%
* macro_f1: 29.0%
******* Domain 3 best val acc:      69.3%, epoch: 26 *******
******* Domain 3 best val test acc: 50.2%, epoch: 26 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [27/50] batch [20/445] time 0.086 (0.122) data 0.000 (0.028) loss 1.9157 (2.1377) teacher_loss 0.6381 (0.8465) loss_zs_kd 1.6673 (1.5135) loss_oracle 0.8754 (0.8820) acc 78.1250 (70.9375) lr 1.0000e-03 eta 0:21:38
epoch [27/50] batch [40/445] time 0.084 (0.104) data 0.000 (0.014) loss 2.2824 (2.1073) teacher_loss 0.9143 (0.8041) loss_zs_kd 1.7239 (1.4817) loss_oracle 0.9473 (0.8809) acc 62.5000 (72.1875) lr 1.0000e-03 eta 0:18:27
epoch [27/50] batch [60/445] time 0.079 (0.097) data 0.001 (0.009) loss 1.8429 (2.1071) teacher_loss 0.5975 (0.8056) loss_zs_kd 1.7537 (1.4884) loss_oracle 0.7487 (0.8732) acc 87.5000 (72.0312) lr 1.0000e-03 eta 0:17:15
epoch [27/50] batch [80/445] time 0.086 (0.094) data 0.000 (0.007) loss 2.1590 (2.1294) teacher_loss 0.8085 (0.8305) loss_zs_kd 1.5219 (1.4782) loss_oracle 0.8590 (0.8726) acc 71.8750 (70.9766) lr 1.0000e-03 eta 0:16:34
epoch [27/50] batch [100/445] time 0.082 (0.092) data 0.000 (0.006) loss 1.7190 (2.1279) teacher_loss 0.5660 (0.8375) loss_zs_kd 1.4451 (1.4610) loss_oracle 0.8695 (0.8674) acc 78.1250 (71.0938) lr 1.0000e-03 eta 0:16:12
epoch [27/50] batch [120/445] time 0.094 (0.090) data 0.000 (0.005) loss 2.3314 (2.1415) teacher_loss 1.0131 (0.8517) loss_zs_kd 1.2006 (1.4534) loss_oracle 0.8949 (0.8670) acc 65.6250 (70.9375) lr 1.0000e-03 eta 0:15:47
epoch [27/50] batch [140/445] time 0.077 (0.089) data 0.000 (0.004) loss 2.6312 (2.1298) teacher_loss 1.2967 (0.8437) loss_zs_kd 1.5549 (1.4416) loss_oracle 0.8610 (0.8665) acc 53.1250 (71.0938) lr 1.0000e-03 eta 0:15:37
epoch [27/50] batch [160/445] time 0.079 (0.088) data 0.000 (0.004) loss 2.3250 (2.1317) teacher_loss 0.9511 (0.8465) loss_zs_kd 1.5849 (1.4559) loss_oracle 0.8966 (0.8654) acc 62.5000 (71.0352) lr 1.0000e-03 eta 0:15:29
epoch [27/50] batch [180/445] time 0.083 (0.088) data 0.000 (0.003) loss 2.1542 (2.1251) teacher_loss 0.8745 (0.8428) loss_zs_kd 1.6658 (1.4638) loss_oracle 0.8664 (0.8615) acc 75.0000 (71.1979) lr 1.0000e-03 eta 0:15:25
epoch [27/50] batch [200/445] time 0.084 (0.088) data 0.000 (0.003) loss 2.4612 (2.1272) teacher_loss 1.0526 (0.8449) loss_zs_kd 1.4837 (1.4696) loss_oracle 0.8468 (0.8614) acc 68.7500 (71.0156) lr 1.0000e-03 eta 0:15:17
epoch [27/50] batch [220/445] time 0.080 (0.087) data 0.000 (0.003) loss 1.9102 (2.1286) teacher_loss 0.6251 (0.8461) loss_zs_kd 1.5470 (1.4712) loss_oracle 0.8949 (0.8619) acc 71.8750 (70.8665) lr 1.0000e-03 eta 0:15:08
epoch [27/50] batch [240/445] time 0.079 (0.087) data 0.000 (0.003) loss 2.5116 (2.1272) teacher_loss 1.2150 (0.8422) loss_zs_kd 1.8921 (1.4757) loss_oracle 0.8155 (0.8623) acc 56.2500 (71.0026) lr 1.0000e-03 eta 0:15:05
epoch [27/50] batch [260/445] time 0.079 (0.087) data 0.000 (0.002) loss 1.8962 (2.1280) teacher_loss 0.6394 (0.8443) loss_zs_kd 1.5349 (1.4770) loss_oracle 0.7663 (0.8615) acc 81.2500 (70.8894) lr 1.0000e-03 eta 0:15:02
epoch [27/50] batch [280/445] time 0.082 (0.087) data 0.000 (0.002) loss 2.3828 (2.1264) teacher_loss 1.0874 (0.8429) loss_zs_kd 1.5095 (1.4837) loss_oracle 0.8463 (0.8608) acc 59.3750 (70.8705) lr 1.0000e-03 eta 0:15:00
epoch [27/50] batch [300/445] time 0.088 (0.087) data 0.000 (0.002) loss 2.0986 (2.1249) teacher_loss 0.8349 (0.8422) loss_zs_kd 1.2926 (1.4831) loss_oracle 0.7994 (0.8603) acc 68.7500 (70.9479) lr 1.0000e-03 eta 0:14:58
epoch [27/50] batch [320/445] time 0.079 (0.088) data 0.000 (0.002) loss 1.8671 (2.1213) teacher_loss 0.6153 (0.8398) loss_zs_kd 1.2529 (1.4802) loss_oracle 0.8291 (0.8602) acc 81.2500 (70.9863) lr 1.0000e-03 eta 0:15:06
epoch [27/50] batch [340/445] time 0.074 (0.087) data 0.000 (0.002) loss 1.7381 (2.1205) teacher_loss 0.4649 (0.8385) loss_zs_kd 1.3230 (1.4729) loss_oracle 0.8634 (0.8597) acc 78.1250 (71.1213) lr 1.0000e-03 eta 0:14:59
epoch [27/50] batch [360/445] time 0.085 (0.087) data 0.000 (0.002) loss 2.3945 (2.1251) teacher_loss 1.1652 (0.8411) loss_zs_kd 1.6770 (1.4747) loss_oracle 0.8649 (0.8604) acc 65.6250 (71.0938) lr 1.0000e-03 eta 0:14:54
epoch [27/50] batch [380/445] time 0.079 (0.086) data 0.000 (0.002) loss 2.2611 (2.1266) teacher_loss 0.9124 (0.8413) loss_zs_kd 1.4545 (1.4706) loss_oracle 0.8828 (0.8603) acc 65.6250 (71.0938) lr 1.0000e-03 eta 0:14:50
epoch [27/50] batch [400/445] time 0.086 (0.086) data 0.000 (0.002) loss 2.3673 (2.1284) teacher_loss 0.9165 (0.8421) loss_zs_kd 1.7930 (1.4679) loss_oracle 0.8241 (0.8593) acc 62.5000 (71.0625) lr 1.0000e-03 eta 0:14:48
epoch [27/50] batch [420/445] time 0.077 (0.086) data 0.000 (0.002) loss 1.8722 (2.1250) teacher_loss 0.6838 (0.8387) loss_zs_kd 1.2966 (1.4698) loss_oracle 0.8000 (0.8586) acc 81.2500 (71.1607) lr 1.0000e-03 eta 0:14:42
epoch [27/50] batch [440/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.9410 (2.1262) teacher_loss 0.6382 (0.8400) loss_zs_kd 1.6726 (1.4701) loss_oracle 0.9012 (0.8576) acc 81.2500 (71.2145) lr 1.0000e-03 eta 0:14:38
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,221
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 55.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,949
* accuracy: 49.1%
* error: 50.9%
* macro_f1: 28.9%
******* Domain 3 best val acc:      69.3%, epoch: 26 *******
******* Domain 3 best val test acc: 50.2%, epoch: 26 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [28/50] batch [20/445] time 0.073 (0.099) data 0.000 (0.026) loss 1.8772 (2.1913) teacher_loss 0.6668 (0.9332) loss_zs_kd 1.2791 (1.3888) loss_oracle 0.7894 (0.8495) acc 78.1250 (67.3438) lr 9.3721e-04 eta 0:16:52
epoch [28/50] batch [40/445] time 0.078 (0.091) data 0.000 (0.013) loss 2.2216 (2.1958) teacher_loss 0.8293 (0.9202) loss_zs_kd 1.4327 (1.4245) loss_oracle 0.9854 (0.8498) acc 62.5000 (68.0469) lr 9.3721e-04 eta 0:15:27
epoch [28/50] batch [60/445] time 0.082 (0.093) data 0.001 (0.009) loss 1.8412 (2.1632) teacher_loss 0.7188 (0.8858) loss_zs_kd 1.4082 (1.4138) loss_oracle 0.7979 (0.8484) acc 71.8750 (69.3229) lr 9.3721e-04 eta 0:15:44
epoch [28/50] batch [80/445] time 0.078 (0.089) data 0.000 (0.007) loss 1.7207 (2.1530) teacher_loss 0.5259 (0.8787) loss_zs_kd 1.2559 (1.4325) loss_oracle 0.8063 (0.8491) acc 84.3750 (70.0391) lr 9.3721e-04 eta 0:15:06
epoch [28/50] batch [100/445] time 0.086 (0.088) data 0.000 (0.005) loss 2.2816 (2.1463) teacher_loss 1.0417 (0.8658) loss_zs_kd 1.4532 (1.4406) loss_oracle 0.8267 (0.8511) acc 62.5000 (70.1875) lr 9.3721e-04 eta 0:14:54
epoch [28/50] batch [120/445] time 0.080 (0.087) data 0.000 (0.005) loss 1.9618 (2.1256) teacher_loss 0.6614 (0.8470) loss_zs_kd 1.7161 (1.4534) loss_oracle 0.7734 (0.8486) acc 84.3750 (70.7552) lr 9.3721e-04 eta 0:14:42
epoch [28/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.004) loss 1.7599 (2.1114) teacher_loss 0.5354 (0.8363) loss_zs_kd 1.7036 (1.4725) loss_oracle 0.7873 (0.8479) acc 78.1250 (70.9821) lr 9.3721e-04 eta 0:14:37
epoch [28/50] batch [160/445] time 0.086 (0.087) data 0.000 (0.004) loss 1.9545 (2.1101) teacher_loss 0.6718 (0.8339) loss_zs_kd 1.5996 (1.4772) loss_oracle 0.8596 (0.8489) acc 78.1250 (71.2891) lr 9.3721e-04 eta 0:14:32
epoch [28/50] batch [180/445] time 0.088 (0.086) data 0.000 (0.003) loss 2.2710 (2.1038) teacher_loss 1.0768 (0.8299) loss_zs_kd 1.3327 (1.4744) loss_oracle 0.7882 (0.8486) acc 68.7500 (71.3715) lr 9.3721e-04 eta 0:14:28
epoch [28/50] batch [200/445] time 0.087 (0.086) data 0.000 (0.003) loss 1.8882 (2.1148) teacher_loss 0.6982 (0.8386) loss_zs_kd 1.5549 (1.4745) loss_oracle 0.8490 (0.8483) acc 78.1250 (71.1094) lr 9.3721e-04 eta 0:14:26
epoch [28/50] batch [220/445] time 0.088 (0.086) data 0.000 (0.003) loss 1.9757 (2.1160) teacher_loss 0.6184 (0.8386) loss_zs_kd 1.6832 (1.4764) loss_oracle 0.8330 (0.8497) acc 78.1250 (71.2074) lr 9.3721e-04 eta 0:14:20
epoch [28/50] batch [240/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.2539 (2.1212) teacher_loss 1.0068 (0.8441) loss_zs_kd 1.4312 (1.4786) loss_oracle 0.8669 (0.8504) acc 68.7500 (71.1198) lr 9.3721e-04 eta 0:14:17
epoch [28/50] batch [260/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.1064 (2.1266) teacher_loss 0.9224 (0.8501) loss_zs_kd 1.1400 (1.4748) loss_oracle 0.7641 (0.8496) acc 56.2500 (70.7692) lr 9.3721e-04 eta 0:14:14
epoch [28/50] batch [280/445] time 0.088 (0.085) data 0.000 (0.002) loss 2.5161 (2.1365) teacher_loss 1.1529 (0.8579) loss_zs_kd 1.6268 (1.4703) loss_oracle 0.8331 (0.8505) acc 59.3750 (70.5022) lr 9.3721e-04 eta 0:14:08
epoch [28/50] batch [300/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.0162 (2.1375) teacher_loss 0.7504 (0.8593) loss_zs_kd 1.1794 (1.4699) loss_oracle 0.8020 (0.8493) acc 71.8750 (70.6354) lr 9.3721e-04 eta 0:14:02
epoch [28/50] batch [320/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.4742 (2.1354) teacher_loss 1.1669 (0.8576) loss_zs_kd 1.3188 (1.4658) loss_oracle 0.8935 (0.8490) acc 68.7500 (70.7227) lr 9.3721e-04 eta 0:14:00
epoch [28/50] batch [340/445] time 0.089 (0.085) data 0.000 (0.002) loss 2.4395 (2.1340) teacher_loss 1.1760 (0.8564) loss_zs_kd 1.4903 (1.4696) loss_oracle 0.8037 (0.8483) acc 65.6250 (70.7537) lr 9.3721e-04 eta 0:13:58
epoch [28/50] batch [360/445] time 0.079 (0.085) data 0.000 (0.002) loss 2.2573 (2.1377) teacher_loss 0.9200 (0.8613) loss_zs_kd 1.8179 (1.4775) loss_oracle 0.8725 (0.8473) acc 59.3750 (70.5208) lr 9.3721e-04 eta 0:13:55
epoch [28/50] batch [380/445] time 0.076 (0.084) data 0.000 (0.002) loss 2.1467 (2.1345) teacher_loss 0.9471 (0.8600) loss_zs_kd 1.4199 (1.4776) loss_oracle 0.8275 (0.8466) acc 75.0000 (70.6250) lr 9.3721e-04 eta 0:13:50
epoch [28/50] batch [400/445] time 0.071 (0.084) data 0.000 (0.002) loss 2.0079 (2.1332) teacher_loss 0.6993 (0.8599) loss_zs_kd 1.4351 (1.4759) loss_oracle 0.8426 (0.8460) acc 75.0000 (70.5312) lr 9.3721e-04 eta 0:13:45
epoch [28/50] batch [420/445] time 0.082 (0.084) data 0.000 (0.002) loss 2.1476 (2.1331) teacher_loss 0.8527 (0.8591) loss_zs_kd 1.3391 (1.4799) loss_oracle 0.8197 (0.8457) acc 75.0000 (70.6324) lr 9.3721e-04 eta 0:13:44
epoch [28/50] batch [440/445] time 0.083 (0.084) data 0.000 (0.001) loss 1.6979 (2.1326) teacher_loss 0.5152 (0.8579) loss_zs_kd 1.3315 (1.4825) loss_oracle 0.7847 (0.8458) acc 84.3750 (70.5540) lr 9.3721e-04 eta 0:13:42
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,201
* accuracy: 68.8%
* error: 31.2%
* macro_f1: 55.4%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,895
* accuracy: 47.7%
* error: 52.3%
* macro_f1: 28.5%
******* Domain 3 best val acc:      69.3%, epoch: 26 *******
******* Domain 3 best val test acc: 50.2%, epoch: 26 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [29/50] batch [20/445] time 0.083 (0.113) data 0.000 (0.027) loss 2.0794 (2.0553) teacher_loss 0.9315 (0.7873) loss_zs_kd 1.5288 (1.5334) loss_oracle 0.9130 (0.8650) acc 71.8750 (72.0312) lr 8.7467e-04 eta 0:18:19
epoch [29/50] batch [40/445] time 0.082 (0.098) data 0.000 (0.014) loss 2.2252 (2.0982) teacher_loss 0.8652 (0.8251) loss_zs_kd 1.5510 (1.5480) loss_oracle 0.9210 (0.8620) acc 65.6250 (71.3281) lr 8.7467e-04 eta 0:15:52
epoch [29/50] batch [60/445] time 0.083 (0.093) data 0.001 (0.009) loss 1.9048 (2.1237) teacher_loss 0.5597 (0.8424) loss_zs_kd 1.6579 (1.5367) loss_oracle 0.8616 (0.8573) acc 84.3750 (71.6146) lr 8.7467e-04 eta 0:15:04
epoch [29/50] batch [80/445] time 0.082 (0.091) data 0.000 (0.007) loss 2.0413 (2.0881) teacher_loss 0.7589 (0.8165) loss_zs_kd 1.4834 (1.5348) loss_oracle 0.7809 (0.8513) acc 81.2500 (72.5000) lr 8.7467e-04 eta 0:14:46
epoch [29/50] batch [100/445] time 0.084 (0.090) data 0.000 (0.006) loss 2.1988 (2.0989) teacher_loss 0.9198 (0.8234) loss_zs_kd 1.7528 (1.5444) loss_oracle 0.8783 (0.8524) acc 68.7500 (72.3125) lr 8.7467e-04 eta 0:14:33
epoch [29/50] batch [120/445] time 0.084 (0.089) data 0.000 (0.005) loss 2.5100 (2.1055) teacher_loss 1.0644 (0.8270) loss_zs_kd 1.5091 (1.5288) loss_oracle 0.8530 (0.8540) acc 62.5000 (72.3958) lr 8.7467e-04 eta 0:14:21
epoch [29/50] batch [140/445] time 0.087 (0.088) data 0.000 (0.004) loss 1.9453 (2.1158) teacher_loss 0.6581 (0.8332) loss_zs_kd 1.4067 (1.5106) loss_oracle 0.8985 (0.8548) acc 78.1250 (71.8750) lr 8.7467e-04 eta 0:14:06
epoch [29/50] batch [160/445] time 0.081 (0.087) data 0.000 (0.004) loss 2.0275 (2.1209) teacher_loss 0.7280 (0.8360) loss_zs_kd 1.3415 (1.4934) loss_oracle 0.8297 (0.8558) acc 75.0000 (71.7773) lr 8.7467e-04 eta 0:14:01
epoch [29/50] batch [180/445] time 0.080 (0.086) data 0.000 (0.003) loss 2.2289 (2.1135) teacher_loss 1.0282 (0.8296) loss_zs_kd 1.5122 (1.4901) loss_oracle 0.8127 (0.8563) acc 68.7500 (72.0486) lr 8.7467e-04 eta 0:13:51
epoch [29/50] batch [200/445] time 0.089 (0.088) data 0.000 (0.003) loss 2.4176 (2.1230) teacher_loss 1.1929 (0.8394) loss_zs_kd 1.3782 (1.4800) loss_oracle 0.8275 (0.8555) acc 62.5000 (71.5156) lr 8.7467e-04 eta 0:14:04
epoch [29/50] batch [220/445] time 0.075 (0.087) data 0.000 (0.003) loss 2.3473 (2.1234) teacher_loss 0.9940 (0.8402) loss_zs_kd 2.0209 (1.4744) loss_oracle 0.8782 (0.8547) acc 62.5000 (71.4062) lr 8.7467e-04 eta 0:13:57
epoch [29/50] batch [240/445] time 0.086 (0.087) data 0.000 (0.003) loss 2.1386 (2.1253) teacher_loss 0.8817 (0.8445) loss_zs_kd 1.3459 (1.4761) loss_oracle 0.8827 (0.8544) acc 62.5000 (71.1849) lr 8.7467e-04 eta 0:13:53
epoch [29/50] batch [260/445] time 0.079 (0.087) data 0.000 (0.002) loss 2.2400 (2.1273) teacher_loss 0.9845 (0.8473) loss_zs_kd 1.3356 (1.4736) loss_oracle 0.8040 (0.8545) acc 65.6250 (71.0216) lr 8.7467e-04 eta 0:13:49
epoch [29/50] batch [280/445] time 0.084 (0.087) data 0.000 (0.002) loss 1.7827 (2.1205) teacher_loss 0.6089 (0.8429) loss_zs_kd 1.2957 (1.4639) loss_oracle 0.7835 (0.8535) acc 78.1250 (71.1607) lr 8.7467e-04 eta 0:13:46
epoch [29/50] batch [300/445] time 0.084 (0.087) data 0.000 (0.002) loss 1.9226 (2.1225) teacher_loss 0.6450 (0.8452) loss_zs_kd 1.4006 (1.4688) loss_oracle 0.8785 (0.8527) acc 81.2500 (71.0312) lr 8.7467e-04 eta 0:13:42
epoch [29/50] batch [320/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.0879 (2.1194) teacher_loss 0.8770 (0.8437) loss_zs_kd 1.5057 (1.4677) loss_oracle 0.8213 (0.8521) acc 71.8750 (71.0938) lr 8.7467e-04 eta 0:13:40
epoch [29/50] batch [340/445] time 0.075 (0.086) data 0.000 (0.002) loss 2.2025 (2.1191) teacher_loss 0.9072 (0.8444) loss_zs_kd 1.3968 (1.4609) loss_oracle 0.9058 (0.8523) acc 71.8750 (71.0294) lr 8.7467e-04 eta 0:13:36
epoch [29/50] batch [360/445] time 0.073 (0.086) data 0.000 (0.002) loss 2.1598 (2.1167) teacher_loss 0.9349 (0.8436) loss_zs_kd 1.6532 (1.4631) loss_oracle 0.8361 (0.8521) acc 56.2500 (71.0243) lr 8.7467e-04 eta 0:13:31
epoch [29/50] batch [380/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.7770 (2.1154) teacher_loss 0.5837 (0.8425) loss_zs_kd 1.5986 (1.4638) loss_oracle 0.8600 (0.8524) acc 84.3750 (71.1102) lr 8.7467e-04 eta 0:13:29
epoch [29/50] batch [400/445] time 0.081 (0.086) data 0.000 (0.002) loss 2.2880 (2.1176) teacher_loss 1.0198 (0.8430) loss_zs_kd 1.6598 (1.4636) loss_oracle 0.8121 (0.8528) acc 56.2500 (71.0312) lr 8.7467e-04 eta 0:13:27
epoch [29/50] batch [420/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.0540 (2.1195) teacher_loss 0.7363 (0.8446) loss_zs_kd 1.7189 (1.4659) loss_oracle 0.8707 (0.8524) acc 71.8750 (70.8854) lr 8.7467e-04 eta 0:13:24
epoch [29/50] batch [440/445] time 0.081 (0.086) data 0.000 (0.002) loss 2.0593 (2.1198) teacher_loss 0.8068 (0.8442) loss_zs_kd 1.3133 (1.4695) loss_oracle 0.8381 (0.8522) acc 75.0000 (70.8736) lr 8.7467e-04 eta 0:13:20
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,253
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 56.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,014
* accuracy: 50.7%
* error: 49.3%
* macro_f1: 30.1%
******* Domain 3 best val acc:      69.6%, epoch: 29 *******
******* Domain 3 best val test acc: 50.7%, epoch: 29 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [30/50] batch [20/445] time 0.091 (0.103) data 0.000 (0.027) loss 1.9136 (2.1450) teacher_loss 0.5845 (0.8368) loss_zs_kd 1.6576 (1.6270) loss_oracle 0.8466 (0.8731) acc 87.5000 (71.7188) lr 8.1262e-04 eta 0:16:02
epoch [30/50] batch [40/445] time 0.074 (0.093) data 0.000 (0.014) loss 2.0198 (2.1481) teacher_loss 0.7467 (0.8460) loss_zs_kd 1.6618 (1.5850) loss_oracle 0.8567 (0.8727) acc 78.1250 (71.2500) lr 8.1262e-04 eta 0:14:24
epoch [30/50] batch [60/445] time 0.082 (0.090) data 0.001 (0.009) loss 2.2425 (2.1526) teacher_loss 0.9288 (0.8529) loss_zs_kd 1.5226 (1.5584) loss_oracle 0.7983 (0.8669) acc 65.6250 (70.8854) lr 8.1262e-04 eta 0:13:51
epoch [30/50] batch [80/445] time 0.085 (0.088) data 0.000 (0.007) loss 1.8980 (2.1241) teacher_loss 0.6127 (0.8367) loss_zs_kd 1.5678 (1.5562) loss_oracle 0.9569 (0.8610) acc 81.2500 (72.1484) lr 8.1262e-04 eta 0:13:35
epoch [30/50] batch [100/445] time 0.077 (0.086) data 0.000 (0.006) loss 2.1254 (2.1106) teacher_loss 0.8700 (0.8282) loss_zs_kd 1.3955 (1.5545) loss_oracle 0.8924 (0.8603) acc 75.0000 (72.7188) lr 8.1262e-04 eta 0:13:19
epoch [30/50] batch [120/445] time 0.085 (0.085) data 0.000 (0.005) loss 2.1382 (2.1144) teacher_loss 0.8155 (0.8296) loss_zs_kd 1.7574 (1.5514) loss_oracle 0.8952 (0.8639) acc 65.6250 (72.2396) lr 8.1262e-04 eta 0:13:06
epoch [30/50] batch [140/445] time 0.083 (0.085) data 0.000 (0.004) loss 1.9976 (2.1183) teacher_loss 0.6546 (0.8335) loss_zs_kd 1.6384 (1.5447) loss_oracle 0.8807 (0.8661) acc 71.8750 (71.8973) lr 8.1262e-04 eta 0:13:03
epoch [30/50] batch [160/445] time 0.085 (0.084) data 0.000 (0.004) loss 2.2937 (2.1111) teacher_loss 1.0344 (0.8288) loss_zs_kd 1.3427 (1.5409) loss_oracle 0.8279 (0.8640) acc 71.8750 (72.4219) lr 8.1262e-04 eta 0:12:53
epoch [30/50] batch [180/445] time 0.090 (0.084) data 0.000 (0.003) loss 1.8705 (2.1159) teacher_loss 0.5943 (0.8344) loss_zs_kd 1.6145 (1.5423) loss_oracle 0.8749 (0.8648) acc 81.2500 (72.2396) lr 8.1262e-04 eta 0:12:52
epoch [30/50] batch [200/445] time 0.090 (0.084) data 0.000 (0.003) loss 2.0765 (2.1061) teacher_loss 0.8219 (0.8258) loss_zs_kd 1.4080 (1.5463) loss_oracle 0.8570 (0.8641) acc 68.7500 (72.3750) lr 8.1262e-04 eta 0:12:50
epoch [30/50] batch [220/445] time 0.082 (0.084) data 0.000 (0.003) loss 2.1610 (2.1047) teacher_loss 0.8227 (0.8252) loss_zs_kd 2.2651 (1.5570) loss_oracle 0.8358 (0.8621) acc 71.8750 (72.2443) lr 8.1262e-04 eta 0:12:49
epoch [30/50] batch [240/445] time 0.087 (0.085) data 0.000 (0.003) loss 1.7957 (2.1034) teacher_loss 0.5297 (0.8250) loss_zs_kd 1.2590 (1.5516) loss_oracle 0.8538 (0.8608) acc 84.3750 (72.3047) lr 8.1262e-04 eta 0:12:49
epoch [30/50] batch [260/445] time 0.092 (0.085) data 0.000 (0.002) loss 2.1260 (2.1029) teacher_loss 0.8451 (0.8255) loss_zs_kd 1.3765 (1.5468) loss_oracle 0.8516 (0.8602) acc 75.0000 (72.2837) lr 8.1262e-04 eta 0:12:50
epoch [30/50] batch [280/445] time 0.091 (0.085) data 0.000 (0.002) loss 1.9129 (2.0990) teacher_loss 0.6821 (0.8223) loss_zs_kd 1.6249 (1.5437) loss_oracle 0.8284 (0.8588) acc 81.2500 (72.3996) lr 8.1262e-04 eta 0:12:49
epoch [30/50] batch [300/445] time 0.158 (0.086) data 0.000 (0.002) loss 2.0059 (2.1021) teacher_loss 0.7246 (0.8262) loss_zs_kd 1.1064 (1.5395) loss_oracle 0.8996 (0.8579) acc 81.2500 (72.2812) lr 8.1262e-04 eta 0:12:54
epoch [30/50] batch [320/445] time 0.083 (0.085) data 0.000 (0.002) loss 2.5713 (2.1070) teacher_loss 1.1789 (0.8307) loss_zs_kd 1.9239 (1.5342) loss_oracle 0.8889 (0.8585) acc 53.1250 (72.0898) lr 8.1262e-04 eta 0:12:50
epoch [30/50] batch [340/445] time 0.087 (0.085) data 0.000 (0.002) loss 1.9563 (2.1046) teacher_loss 0.7544 (0.8278) loss_zs_kd 1.2289 (1.5272) loss_oracle 0.8508 (0.8588) acc 78.1250 (72.1783) lr 8.1262e-04 eta 0:12:49
epoch [30/50] batch [360/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.1093 (2.1011) teacher_loss 0.7735 (0.8247) loss_zs_kd 1.2791 (1.5206) loss_oracle 0.8838 (0.8585) acc 75.0000 (72.2396) lr 8.1262e-04 eta 0:12:47
epoch [30/50] batch [380/445] time 0.084 (0.085) data 0.000 (0.002) loss 1.9823 (2.1012) teacher_loss 0.7485 (0.8253) loss_zs_kd 1.6844 (1.5199) loss_oracle 0.8469 (0.8589) acc 75.0000 (72.2451) lr 8.1262e-04 eta 0:12:45
epoch [30/50] batch [400/445] time 0.079 (0.085) data 0.001 (0.002) loss 1.8558 (2.1024) teacher_loss 0.5877 (0.8269) loss_zs_kd 1.2963 (1.5170) loss_oracle 0.8388 (0.8584) acc 81.2500 (72.1875) lr 8.1262e-04 eta 0:12:42
epoch [30/50] batch [420/445] time 0.077 (0.085) data 0.000 (0.002) loss 2.4182 (2.1064) teacher_loss 1.1650 (0.8316) loss_zs_kd 1.5893 (1.5122) loss_oracle 0.9414 (0.8580) acc 56.2500 (71.9345) lr 8.1262e-04 eta 0:12:39
epoch [30/50] batch [440/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.2466 (2.1091) teacher_loss 0.9460 (0.8345) loss_zs_kd 1.3397 (1.5033) loss_oracle 0.8574 (0.8573) acc 68.7500 (71.7685) lr 8.1262e-04 eta 0:12:34
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,250
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 55.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,945
* accuracy: 49.0%
* error: 51.0%
* macro_f1: 31.0%
******* Domain 3 best val acc:      69.6%, epoch: 29 *******
******* Domain 3 best val test acc: 50.7%, epoch: 29 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [31/50] batch [20/445] time 0.074 (0.111) data 0.000 (0.029) loss 1.7923 (2.0698) teacher_loss 0.5706 (0.8119) loss_zs_kd 1.2840 (1.4403) loss_oracle 0.8127 (0.8322) acc 84.3750 (73.9062) lr 7.5131e-04 eta 0:16:23
epoch [31/50] batch [40/445] time 0.113 (0.096) data 0.001 (0.015) loss 2.0103 (2.0572) teacher_loss 0.7770 (0.7855) loss_zs_kd 1.4898 (1.4831) loss_oracle 0.8656 (0.8499) acc 71.8750 (73.6719) lr 7.5131e-04 eta 0:14:08
epoch [31/50] batch [60/445] time 0.075 (0.095) data 0.001 (0.010) loss 2.1776 (2.0673) teacher_loss 0.9147 (0.8004) loss_zs_kd 1.6841 (1.4716) loss_oracle 0.8032 (0.8456) acc 68.7500 (72.7083) lr 7.5131e-04 eta 0:13:58
epoch [31/50] batch [80/445] time 0.079 (0.091) data 0.000 (0.007) loss 2.2479 (2.0877) teacher_loss 0.8497 (0.8241) loss_zs_kd 1.3884 (1.4602) loss_oracle 0.8496 (0.8402) acc 78.1250 (71.8359) lr 7.5131e-04 eta 0:13:18
epoch [31/50] batch [100/445] time 0.085 (0.090) data 0.000 (0.006) loss 2.4877 (2.0873) teacher_loss 1.2706 (0.8249) loss_zs_kd 1.3208 (1.4479) loss_oracle 0.8601 (0.8401) acc 65.6250 (71.9062) lr 7.5131e-04 eta 0:13:09
epoch [31/50] batch [120/445] time 0.084 (0.089) data 0.000 (0.005) loss 2.5375 (2.0907) teacher_loss 1.1838 (0.8268) loss_zs_kd 1.6839 (1.4534) loss_oracle 0.8871 (0.8413) acc 68.7500 (71.7188) lr 7.5131e-04 eta 0:12:58
epoch [31/50] batch [140/445] time 0.082 (0.088) data 0.000 (0.004) loss 2.0082 (2.0908) teacher_loss 0.7624 (0.8261) loss_zs_kd 1.2926 (1.4601) loss_oracle 0.8317 (0.8442) acc 75.0000 (71.6741) lr 7.5131e-04 eta 0:12:52
epoch [31/50] batch [160/445] time 0.083 (0.088) data 0.000 (0.004) loss 2.0967 (2.0869) teacher_loss 0.9062 (0.8206) loss_zs_kd 1.2457 (1.4669) loss_oracle 0.8756 (0.8477) acc 65.6250 (72.0508) lr 7.5131e-04 eta 0:12:45
epoch [31/50] batch [180/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.2623 (2.0872) teacher_loss 1.1009 (0.8191) loss_zs_kd 1.4539 (1.4716) loss_oracle 0.8330 (0.8494) acc 59.3750 (71.9965) lr 7.5131e-04 eta 0:12:42
epoch [31/50] batch [200/445] time 0.093 (0.087) data 0.000 (0.003) loss 2.0892 (2.0895) teacher_loss 0.7435 (0.8177) loss_zs_kd 1.1726 (1.4674) loss_oracle 0.8817 (0.8503) acc 75.0000 (71.9375) lr 7.5131e-04 eta 0:12:39
epoch [31/50] batch [220/445] time 0.086 (0.087) data 0.000 (0.003) loss 2.1356 (2.0898) teacher_loss 0.6873 (0.8147) loss_zs_kd 1.7009 (1.4727) loss_oracle 0.9907 (0.8527) acc 75.0000 (72.0455) lr 7.5131e-04 eta 0:12:36
epoch [31/50] batch [240/445] time 0.087 (0.087) data 0.000 (0.003) loss 1.9064 (2.0915) teacher_loss 0.6914 (0.8158) loss_zs_kd 1.8864 (1.4782) loss_oracle 0.7543 (0.8525) acc 81.2500 (72.1354) lr 7.5131e-04 eta 0:12:33
epoch [31/50] batch [260/445] time 0.082 (0.087) data 0.000 (0.002) loss 1.9434 (2.0915) teacher_loss 0.6498 (0.8136) loss_zs_kd 1.5949 (1.4830) loss_oracle 0.8766 (0.8533) acc 75.0000 (72.1635) lr 7.5131e-04 eta 0:12:30
epoch [31/50] batch [280/445] time 0.077 (0.087) data 0.000 (0.002) loss 2.0445 (2.0963) teacher_loss 0.7716 (0.8171) loss_zs_kd 1.5890 (1.4896) loss_oracle 0.8289 (0.8551) acc 71.8750 (72.1094) lr 7.5131e-04 eta 0:12:26
epoch [31/50] batch [300/445] time 0.075 (0.086) data 0.000 (0.002) loss 2.0702 (2.0961) teacher_loss 0.7188 (0.8158) loss_zs_kd 1.6911 (1.4932) loss_oracle 0.8957 (0.8571) acc 68.7500 (72.1250) lr 7.5131e-04 eta 0:12:20
epoch [31/50] batch [320/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.1817 (2.0973) teacher_loss 0.8782 (0.8163) loss_zs_kd 1.5748 (1.4925) loss_oracle 0.7983 (0.8585) acc 65.6250 (72.1387) lr 7.5131e-04 eta 0:12:16
epoch [31/50] batch [340/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.6765 (2.1054) teacher_loss 1.1656 (0.8208) loss_zs_kd 1.8667 (1.4970) loss_oracle 0.9038 (0.8599) acc 56.2500 (71.9301) lr 7.5131e-04 eta 0:12:13
epoch [31/50] batch [360/445] time 0.076 (0.086) data 0.000 (0.002) loss 1.9354 (2.1085) teacher_loss 0.6226 (0.8185) loss_zs_kd 1.3574 (1.4952) loss_oracle 0.8665 (0.8601) acc 84.3750 (72.0486) lr 7.5131e-04 eta 0:12:10
epoch [31/50] batch [380/445] time 0.086 (0.085) data 0.000 (0.002) loss 2.2564 (2.1105) teacher_loss 0.7945 (0.8183) loss_zs_kd 1.1268 (1.4964) loss_oracle 0.9124 (0.8606) acc 68.7500 (72.0312) lr 7.5131e-04 eta 0:12:07
epoch [31/50] batch [400/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.1957 (2.1118) teacher_loss 0.9086 (0.8188) loss_zs_kd 1.2625 (1.4927) loss_oracle 0.8634 (0.8611) acc 62.5000 (71.9766) lr 7.5131e-04 eta 0:12:05
epoch [31/50] batch [420/445] time 0.090 (0.085) data 0.000 (0.002) loss 1.8316 (2.1143) teacher_loss 0.4836 (0.8185) loss_zs_kd 1.4861 (1.5010) loss_oracle 0.8228 (0.8628) acc 87.5000 (71.9866) lr 7.5131e-04 eta 0:12:04
epoch [31/50] batch [440/445] time 0.074 (0.086) data 0.000 (0.002) loss 2.0100 (2.1172) teacher_loss 0.7474 (0.8203) loss_zs_kd 1.9522 (1.5092) loss_oracle 0.8192 (0.8629) acc 78.1250 (71.9957) lr 7.5131e-04 eta 0:12:06
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,180
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 55.0%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,838
* accuracy: 46.3%
* error: 53.7%
* macro_f1: 29.0%
******* Domain 3 best val acc:      69.6%, epoch: 29 *******
******* Domain 3 best val test acc: 50.7%, epoch: 29 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [32/50] batch [20/445] time 0.073 (0.119) data 0.000 (0.027) loss 2.2501 (2.0964) teacher_loss 0.8603 (0.7922) loss_zs_kd 1.5405 (1.5225) loss_oracle 0.8558 (0.8872) acc 65.6250 (73.7500) lr 6.9098e-04 eta 0:16:43
epoch [32/50] batch [40/445] time 0.085 (0.101) data 0.000 (0.014) loss 2.1792 (2.1275) teacher_loss 0.9076 (0.8268) loss_zs_kd 1.3098 (1.5088) loss_oracle 0.8700 (0.8839) acc 71.8750 (71.9531) lr 6.9098e-04 eta 0:14:12
epoch [32/50] batch [60/445] time 0.088 (0.096) data 0.001 (0.009) loss 1.7853 (2.0966) teacher_loss 0.5160 (0.7963) loss_zs_kd 1.1114 (1.5235) loss_oracle 0.9100 (0.8875) acc 84.3750 (73.2812) lr 6.9098e-04 eta 0:13:29
epoch [32/50] batch [80/445] time 0.084 (0.094) data 0.000 (0.007) loss 2.0166 (2.0847) teacher_loss 0.7823 (0.7884) loss_zs_kd 1.6015 (1.5492) loss_oracle 0.9201 (0.8880) acc 78.1250 (73.8281) lr 6.9098e-04 eta 0:13:05
epoch [32/50] batch [100/445] time 0.084 (0.091) data 0.000 (0.006) loss 2.1985 (2.0859) teacher_loss 0.9552 (0.7896) loss_zs_kd 1.3702 (1.5363) loss_oracle 0.8257 (0.8856) acc 68.7500 (73.7812) lr 6.9098e-04 eta 0:12:41
epoch [32/50] batch [120/445] time 0.088 (0.090) data 0.000 (0.005) loss 1.8487 (2.0779) teacher_loss 0.5688 (0.7843) loss_zs_kd 1.4379 (1.5291) loss_oracle 0.9473 (0.8844) acc 78.1250 (73.6979) lr 6.9098e-04 eta 0:12:31
epoch [32/50] batch [140/445] time 0.086 (0.090) data 0.000 (0.004) loss 2.1488 (2.0843) teacher_loss 0.8642 (0.7921) loss_zs_kd 1.7534 (1.5295) loss_oracle 0.9011 (0.8851) acc 65.6250 (73.3705) lr 6.9098e-04 eta 0:12:24
epoch [32/50] batch [160/445] time 0.083 (0.089) data 0.000 (0.004) loss 2.0931 (2.0878) teacher_loss 0.7663 (0.7933) loss_zs_kd 1.5296 (1.5393) loss_oracle 0.8536 (0.8881) acc 71.8750 (73.3789) lr 6.9098e-04 eta 0:12:18
epoch [32/50] batch [180/445] time 0.080 (0.090) data 0.000 (0.003) loss 2.2430 (2.0925) teacher_loss 1.0019 (0.7965) loss_zs_kd 1.7418 (1.5533) loss_oracle 0.9244 (0.8906) acc 65.6250 (73.3681) lr 6.9098e-04 eta 0:12:25
epoch [32/50] batch [200/445] time 0.081 (0.089) data 0.000 (0.003) loss 1.8272 (2.0956) teacher_loss 0.5937 (0.7963) loss_zs_kd 1.8120 (1.5578) loss_oracle 0.8809 (0.8923) acc 81.2500 (73.2812) lr 6.9098e-04 eta 0:12:17
epoch [32/50] batch [220/445] time 0.093 (0.089) data 0.000 (0.003) loss 2.6664 (2.0963) teacher_loss 1.2758 (0.7949) loss_zs_kd 1.4851 (1.5602) loss_oracle 1.0065 (0.8964) acc 56.2500 (73.2528) lr 6.9098e-04 eta 0:12:13
epoch [32/50] batch [240/445] time 0.084 (0.088) data 0.000 (0.003) loss 1.9513 (2.0964) teacher_loss 0.6618 (0.7945) loss_zs_kd 1.7889 (1.5686) loss_oracle 0.8828 (0.8990) acc 75.0000 (73.3984) lr 6.9098e-04 eta 0:12:05
epoch [32/50] batch [260/445] time 0.082 (0.088) data 0.000 (0.002) loss 2.3937 (2.0958) teacher_loss 1.1162 (0.7954) loss_zs_kd 1.8292 (1.5722) loss_oracle 0.8145 (0.8975) acc 71.8750 (73.4255) lr 6.9098e-04 eta 0:11:58
epoch [32/50] batch [280/445] time 0.080 (0.087) data 0.000 (0.002) loss 1.9389 (2.0982) teacher_loss 0.7360 (0.7992) loss_zs_kd 1.6357 (1.5758) loss_oracle 0.8676 (0.8962) acc 81.2500 (73.1920) lr 6.9098e-04 eta 0:11:54
epoch [32/50] batch [300/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.3026 (2.1017) teacher_loss 1.0236 (0.8033) loss_zs_kd 1.7195 (1.5731) loss_oracle 0.8232 (0.8947) acc 65.6250 (72.8438) lr 6.9098e-04 eta 0:11:49
epoch [32/50] batch [320/445] time 0.084 (0.087) data 0.000 (0.002) loss 1.9910 (2.1049) teacher_loss 0.7199 (0.8067) loss_zs_kd 1.6395 (1.5667) loss_oracle 0.8575 (0.8932) acc 78.1250 (72.6855) lr 6.9098e-04 eta 0:11:44
epoch [32/50] batch [340/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.0807 (2.1049) teacher_loss 0.8394 (0.8071) loss_zs_kd 1.3150 (1.5730) loss_oracle 0.8881 (0.8929) acc 68.7500 (72.5827) lr 6.9098e-04 eta 0:11:40
epoch [32/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.3899 (2.1106) teacher_loss 1.0093 (0.8113) loss_zs_kd 1.4112 (1.5746) loss_oracle 0.8875 (0.8926) acc 59.3750 (72.4132) lr 6.9098e-04 eta 0:11:37
epoch [32/50] batch [380/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.0617 (2.1137) teacher_loss 0.7315 (0.8145) loss_zs_kd 1.8212 (1.5750) loss_oracle 0.9328 (0.8917) acc 75.0000 (72.3520) lr 6.9098e-04 eta 0:11:34
epoch [32/50] batch [400/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.3209 (2.1201) teacher_loss 1.0468 (0.8209) loss_zs_kd 1.4044 (1.5751) loss_oracle 0.8807 (0.8923) acc 62.5000 (72.0703) lr 6.9098e-04 eta 0:11:32
epoch [32/50] batch [420/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.0540 (2.1200) teacher_loss 0.7616 (0.8204) loss_zs_kd 1.7121 (1.5709) loss_oracle 0.9171 (0.8921) acc 84.3750 (72.0536) lr 6.9098e-04 eta 0:11:30
epoch [32/50] batch [440/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.8928 (2.1223) teacher_loss 0.6067 (0.8224) loss_zs_kd 1.3498 (1.5708) loss_oracle 0.8890 (0.8932) acc 81.2500 (71.9744) lr 6.9098e-04 eta 0:11:28
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,266
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 55.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,980
* accuracy: 49.9%
* error: 50.1%
* macro_f1: 29.4%
******* Domain 3 best val acc:      69.8%, epoch: 32 *******
******* Domain 3 best val test acc: 49.9%, epoch: 32 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [33/50] batch [20/445] time 0.090 (0.116) data 0.000 (0.033) loss 2.1558 (2.1027) teacher_loss 0.7681 (0.7789) loss_zs_kd 1.2791 (1.5173) loss_oracle 0.9127 (0.8926) acc 75.0000 (74.3750) lr 6.3188e-04 eta 0:15:25
epoch [33/50] batch [40/445] time 0.087 (0.099) data 0.000 (0.017) loss 1.8944 (2.1309) teacher_loss 0.6218 (0.8131) loss_zs_kd 1.6132 (1.5628) loss_oracle 0.8247 (0.8929) acc 78.1250 (72.4219) lr 6.3188e-04 eta 0:13:05
epoch [33/50] batch [60/445] time 0.083 (0.093) data 0.001 (0.011) loss 2.3628 (2.1498) teacher_loss 1.0296 (0.8366) loss_zs_kd 1.7293 (1.5904) loss_oracle 0.8889 (0.8937) acc 71.8750 (71.4062) lr 6.3188e-04 eta 0:12:18
epoch [33/50] batch [80/445] time 0.079 (0.090) data 0.000 (0.008) loss 2.0631 (2.1515) teacher_loss 0.7810 (0.8381) loss_zs_kd 1.9482 (1.5927) loss_oracle 0.8287 (0.8963) acc 68.7500 (70.8594) lr 6.3188e-04 eta 0:11:50
epoch [33/50] batch [100/445] time 0.079 (0.088) data 0.000 (0.007) loss 2.3745 (2.1475) teacher_loss 1.1330 (0.8347) loss_zs_kd 1.4906 (1.5835) loss_oracle 0.8190 (0.8951) acc 56.2500 (70.8125) lr 6.3188e-04 eta 0:11:39
epoch [33/50] batch [120/445] time 0.073 (0.088) data 0.000 (0.006) loss 1.7984 (2.1419) teacher_loss 0.5860 (0.8287) loss_zs_kd 1.6429 (1.5725) loss_oracle 0.7999 (0.8938) acc 84.3750 (71.0417) lr 6.3188e-04 eta 0:11:30
epoch [33/50] batch [140/445] time 0.076 (0.086) data 0.000 (0.005) loss 1.8422 (2.1355) teacher_loss 0.6314 (0.8247) loss_zs_kd 1.5134 (1.5817) loss_oracle 0.8358 (0.8925) acc 84.3750 (71.1830) lr 6.3188e-04 eta 0:11:18
epoch [33/50] batch [160/445] time 0.079 (0.085) data 0.000 (0.004) loss 1.9958 (2.1329) teacher_loss 0.7174 (0.8243) loss_zs_kd 1.8618 (1.5829) loss_oracle 0.8270 (0.8908) acc 78.1250 (71.3672) lr 6.3188e-04 eta 0:11:09
epoch [33/50] batch [180/445] time 0.073 (0.085) data 0.000 (0.004) loss 1.8035 (2.1249) teacher_loss 0.5373 (0.8161) loss_zs_kd 1.1595 (1.5741) loss_oracle 0.8725 (0.8902) acc 78.1250 (71.7014) lr 6.3188e-04 eta 0:11:02
epoch [33/50] batch [200/445] time 0.081 (0.084) data 0.000 (0.004) loss 1.7481 (2.1279) teacher_loss 0.4727 (0.8204) loss_zs_kd 1.5379 (1.5659) loss_oracle 0.8695 (0.8892) acc 81.2500 (71.5781) lr 6.3188e-04 eta 0:10:57
epoch [33/50] batch [220/445] time 0.082 (0.084) data 0.000 (0.003) loss 1.8390 (2.1288) teacher_loss 0.6093 (0.8243) loss_zs_kd 1.4033 (1.5677) loss_oracle 0.8165 (0.8883) acc 78.1250 (71.5909) lr 6.3188e-04 eta 0:10:56
epoch [33/50] batch [240/445] time 0.092 (0.084) data 0.000 (0.003) loss 2.0895 (2.1301) teacher_loss 0.7941 (0.8266) loss_zs_kd 1.3311 (1.5640) loss_oracle 0.8215 (0.8868) acc 75.0000 (71.5234) lr 6.3188e-04 eta 0:10:55
epoch [33/50] batch [260/445] time 0.079 (0.084) data 0.000 (0.003) loss 1.7082 (2.1253) teacher_loss 0.4571 (0.8236) loss_zs_kd 1.7097 (1.5651) loss_oracle 0.8697 (0.8845) acc 90.6250 (71.7788) lr 6.3188e-04 eta 0:10:50
epoch [33/50] batch [280/445] time 0.078 (0.084) data 0.000 (0.003) loss 1.9886 (2.1227) teacher_loss 0.7620 (0.8235) loss_zs_kd 1.3675 (1.5634) loss_oracle 0.8057 (0.8833) acc 68.7500 (71.8862) lr 6.3188e-04 eta 0:10:47
epoch [33/50] batch [300/445] time 0.083 (0.084) data 0.000 (0.002) loss 1.9040 (2.1221) teacher_loss 0.6022 (0.8236) loss_zs_kd 1.6143 (1.5642) loss_oracle 0.9237 (0.8823) acc 78.1250 (71.8854) lr 6.3188e-04 eta 0:10:46
epoch [33/50] batch [320/445] time 0.076 (0.084) data 0.000 (0.002) loss 2.0038 (2.1192) teacher_loss 0.6652 (0.8225) loss_zs_kd 1.5625 (1.5605) loss_oracle 0.9723 (0.8814) acc 75.0000 (71.9727) lr 6.3188e-04 eta 0:10:48
epoch [33/50] batch [340/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.1181 (2.1189) teacher_loss 0.9011 (0.8230) loss_zs_kd 1.3010 (1.5556) loss_oracle 0.8314 (0.8808) acc 62.5000 (71.9577) lr 6.3188e-04 eta 0:10:46
epoch [33/50] batch [360/445] time 0.079 (0.084) data 0.000 (0.002) loss 2.3280 (2.1180) teacher_loss 0.9519 (0.8227) loss_zs_kd 1.5267 (1.5508) loss_oracle 0.9262 (0.8799) acc 68.7500 (71.9705) lr 6.3188e-04 eta 0:10:44
epoch [33/50] batch [380/445] time 0.085 (0.084) data 0.000 (0.002) loss 1.9414 (2.1146) teacher_loss 0.7030 (0.8201) loss_zs_kd 1.5919 (1.5517) loss_oracle 0.8238 (0.8794) acc 81.2500 (72.0477) lr 6.3188e-04 eta 0:10:42
epoch [33/50] batch [400/445] time 0.089 (0.084) data 0.000 (0.002) loss 2.3358 (2.1155) teacher_loss 1.0418 (0.8218) loss_zs_kd 1.7469 (1.5543) loss_oracle 0.8262 (0.8780) acc 62.5000 (71.9609) lr 6.3188e-04 eta 0:10:40
epoch [33/50] batch [420/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.2455 (2.1148) teacher_loss 0.9544 (0.8215) loss_zs_kd 1.8809 (1.5603) loss_oracle 0.7995 (0.8770) acc 71.8750 (72.0164) lr 6.3188e-04 eta 0:10:38
epoch [33/50] batch [440/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.0603 (2.1134) teacher_loss 0.8989 (0.8209) loss_zs_kd 1.8014 (1.5648) loss_oracle 0.8254 (0.8768) acc 68.7500 (72.0455) lr 6.3188e-04 eta 0:10:37
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,264
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,019
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 30.9%
******* Domain 3 best val acc:      69.8%, epoch: 32 *******
******* Domain 3 best val test acc: 49.9%, epoch: 32 *******
******* Domain 3 best test acc:     50.9%, epoch: 22 *******
epoch [34/50] batch [20/445] time 0.076 (0.116) data 0.000 (0.028) loss 1.8875 (2.0894) teacher_loss 0.7277 (0.8295) loss_zs_kd 1.6358 (1.4916) loss_oracle 0.8383 (0.8830) acc 75.0000 (70.6250) lr 5.7422e-04 eta 0:14:34
epoch [34/50] batch [40/445] time 0.073 (0.097) data 0.000 (0.014) loss 2.3325 (2.0881) teacher_loss 0.9280 (0.8217) loss_zs_kd 1.7691 (1.5270) loss_oracle 0.9472 (0.8779) acc 71.8750 (72.2656) lr 5.7422e-04 eta 0:12:11
epoch [34/50] batch [60/445] time 0.076 (0.096) data 0.001 (0.009) loss 1.8185 (2.0903) teacher_loss 0.6116 (0.8252) loss_zs_kd 1.5338 (1.5169) loss_oracle 0.7900 (0.8719) acc 78.1250 (71.7708) lr 5.7422e-04 eta 0:11:56
epoch [34/50] batch [80/445] time 0.079 (0.092) data 0.000 (0.007) loss 2.2139 (2.0989) teacher_loss 0.7840 (0.8318) loss_zs_kd 1.6215 (1.5748) loss_oracle 0.8677 (0.8703) acc 75.0000 (72.1484) lr 5.7422e-04 eta 0:11:25
epoch [34/50] batch [100/445] time 0.081 (0.089) data 0.000 (0.006) loss 2.0163 (2.1124) teacher_loss 0.6699 (0.8358) loss_zs_kd 1.5875 (1.5944) loss_oracle 0.8239 (0.8735) acc 78.1250 (72.0312) lr 5.7422e-04 eta 0:11:05
epoch [34/50] batch [120/445] time 0.089 (0.088) data 0.000 (0.005) loss 2.5194 (2.1185) teacher_loss 1.1637 (0.8381) loss_zs_kd 1.8062 (1.6129) loss_oracle 0.9182 (0.8785) acc 62.5000 (71.9792) lr 5.7422e-04 eta 0:10:57
epoch [34/50] batch [140/445] time 0.080 (0.088) data 0.000 (0.004) loss 1.9643 (2.1213) teacher_loss 0.5583 (0.8377) loss_zs_kd 1.3459 (1.6051) loss_oracle 0.9806 (0.8804) acc 81.2500 (71.8750) lr 5.7422e-04 eta 0:10:51
epoch [34/50] batch [160/445] time 0.084 (0.087) data 0.000 (0.004) loss 2.1168 (2.1135) teacher_loss 0.7638 (0.8263) loss_zs_kd 1.3773 (1.6101) loss_oracle 0.8646 (0.8824) acc 78.1250 (72.2656) lr 5.7422e-04 eta 0:10:41
epoch [34/50] batch [180/445] time 0.093 (0.086) data 0.000 (0.003) loss 2.2509 (2.1090) teacher_loss 0.9302 (0.8200) loss_zs_kd 1.7824 (1.6118) loss_oracle 0.9101 (0.8813) acc 68.7500 (72.3264) lr 5.7422e-04 eta 0:10:36
epoch [34/50] batch [200/445] time 0.084 (0.086) data 0.000 (0.003) loss 2.2289 (2.1082) teacher_loss 0.9821 (0.8179) loss_zs_kd 1.6751 (1.6142) loss_oracle 0.9011 (0.8818) acc 62.5000 (72.4219) lr 5.7422e-04 eta 0:10:34
epoch [34/50] batch [220/445] time 0.079 (0.086) data 0.000 (0.003) loss 2.0196 (2.1048) teacher_loss 0.7942 (0.8142) loss_zs_kd 1.5114 (1.6141) loss_oracle 0.7849 (0.8805) acc 71.8750 (72.7841) lr 5.7422e-04 eta 0:10:32
epoch [34/50] batch [240/445] time 0.087 (0.086) data 0.000 (0.003) loss 1.8961 (2.1106) teacher_loss 0.7028 (0.8180) loss_zs_kd 1.4938 (1.6129) loss_oracle 0.8804 (0.8823) acc 75.0000 (72.6562) lr 5.7422e-04 eta 0:10:29
epoch [34/50] batch [260/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.2503 (2.1086) teacher_loss 0.8838 (0.8147) loss_zs_kd 1.5379 (1.6085) loss_oracle 0.8781 (0.8822) acc 75.0000 (72.7764) lr 5.7422e-04 eta 0:10:28
epoch [34/50] batch [280/445] time 0.086 (0.086) data 0.000 (0.002) loss 2.2468 (2.1101) teacher_loss 0.8966 (0.8137) loss_zs_kd 2.0489 (1.6169) loss_oracle 0.9538 (0.8842) acc 65.6250 (72.7232) lr 5.7422e-04 eta 0:10:25
epoch [34/50] batch [300/445] time 0.080 (0.086) data 0.000 (0.002) loss 2.5153 (2.1095) teacher_loss 1.1367 (0.8127) loss_zs_kd 1.4785 (1.6139) loss_oracle 0.9461 (0.8848) acc 59.3750 (72.8750) lr 5.7422e-04 eta 0:10:22
epoch [34/50] batch [320/445] time 0.090 (0.086) data 0.000 (0.002) loss 2.2216 (2.1148) teacher_loss 0.9551 (0.8185) loss_zs_kd 1.8665 (1.6170) loss_oracle 0.8224 (0.8836) acc 78.1250 (72.5879) lr 5.7422e-04 eta 0:10:21
epoch [34/50] batch [340/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.2056 (2.1167) teacher_loss 0.8562 (0.8193) loss_zs_kd 2.0406 (1.6176) loss_oracle 0.8823 (0.8838) acc 71.8750 (72.5276) lr 5.7422e-04 eta 0:10:19
epoch [34/50] batch [360/445] time 0.085 (0.086) data 0.000 (0.002) loss 2.0625 (2.1180) teacher_loss 0.7182 (0.8205) loss_zs_kd 1.4247 (1.6065) loss_oracle 0.8719 (0.8828) acc 78.1250 (72.4566) lr 5.7422e-04 eta 0:10:16
epoch [34/50] batch [380/445] time 0.088 (0.086) data 0.000 (0.002) loss 2.1831 (2.1157) teacher_loss 0.8400 (0.8174) loss_zs_kd 1.7709 (1.6037) loss_oracle 0.9386 (0.8834) acc 71.8750 (72.6398) lr 5.7422e-04 eta 0:10:14
epoch [34/50] batch [400/445] time 0.076 (0.085) data 0.000 (0.002) loss 2.3560 (2.1179) teacher_loss 1.0769 (0.8189) loss_zs_kd 2.1168 (1.6078) loss_oracle 0.8245 (0.8838) acc 65.6250 (72.6875) lr 5.7422e-04 eta 0:10:11
epoch [34/50] batch [420/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.2931 (2.1217) teacher_loss 1.0334 (0.8221) loss_zs_kd 1.4104 (1.6095) loss_oracle 0.9067 (0.8844) acc 59.3750 (72.5521) lr 5.7422e-04 eta 0:10:07
epoch [34/50] batch [440/445] time 0.103 (0.085) data 0.000 (0.002) loss 2.3513 (2.1234) teacher_loss 0.9882 (0.8246) loss_zs_kd 1.5129 (1.6065) loss_oracle 0.9118 (0.8844) acc 71.8750 (72.4787) lr 5.7422e-04 eta 0:10:05
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,212
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 55.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,024
* accuracy: 51.0%
* error: 49.0%
* macro_f1: 30.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      69.8%, epoch: 32 *******
******* Domain 3 best val test acc: 49.9%, epoch: 32 *******
******* Domain 3 best test acc:     51.0%, epoch: 34 *******
epoch [35/50] batch [20/445] time 0.078 (0.110) data 0.000 (0.025) loss 1.8329 (2.0208) teacher_loss 0.6048 (0.7422) loss_zs_kd 1.5735 (1.6017) loss_oracle 0.9040 (0.9059) acc 84.3750 (74.3750) lr 5.1825e-04 eta 0:12:58
epoch [35/50] batch [40/445] time 0.086 (0.097) data 0.000 (0.013) loss 2.1009 (2.0573) teacher_loss 0.9294 (0.7854) loss_zs_kd 1.1009 (1.5200) loss_oracle 0.8284 (0.8815) acc 68.7500 (73.6719) lr 5.1825e-04 eta 0:11:23
epoch [35/50] batch [60/445] time 0.084 (0.093) data 0.001 (0.009) loss 1.9013 (2.0635) teacher_loss 0.6162 (0.7859) loss_zs_kd 1.6357 (1.5114) loss_oracle 0.8857 (0.8891) acc 84.3750 (73.6979) lr 5.1825e-04 eta 0:10:54
epoch [35/50] batch [80/445] time 0.087 (0.091) data 0.000 (0.007) loss 2.1039 (2.0825) teacher_loss 0.8292 (0.7984) loss_zs_kd 1.5897 (1.5372) loss_oracle 0.9106 (0.8916) acc 75.0000 (73.1641) lr 5.1825e-04 eta 0:10:43
epoch [35/50] batch [100/445] time 0.069 (0.090) data 0.001 (0.005) loss 2.1879 (2.0979) teacher_loss 0.8968 (0.8108) loss_zs_kd 1.3036 (1.5220) loss_oracle 0.9223 (0.8916) acc 65.6250 (72.7500) lr 5.1825e-04 eta 0:10:30
epoch [35/50] batch [120/445] time 0.076 (0.088) data 0.000 (0.004) loss 1.9722 (2.0972) teacher_loss 0.6775 (0.8133) loss_zs_kd 1.5030 (1.5421) loss_oracle 0.9304 (0.8892) acc 81.2500 (72.5521) lr 5.1825e-04 eta 0:10:13
epoch [35/50] batch [140/445] time 0.079 (0.087) data 0.000 (0.004) loss 2.0113 (2.1003) teacher_loss 0.7454 (0.8147) loss_zs_kd 1.4925 (1.5492) loss_oracle 0.8852 (0.8886) acc 81.2500 (72.4777) lr 5.1825e-04 eta 0:10:05
epoch [35/50] batch [160/445] time 0.078 (0.087) data 0.000 (0.003) loss 2.4366 (2.1098) teacher_loss 1.1812 (0.8200) loss_zs_kd 1.7162 (1.5628) loss_oracle 0.9602 (0.8924) acc 50.0000 (72.3438) lr 5.1825e-04 eta 0:10:02
epoch [35/50] batch [180/445] time 0.083 (0.086) data 0.000 (0.003) loss 2.2048 (2.1129) teacher_loss 0.8832 (0.8199) loss_zs_kd 1.4371 (1.5643) loss_oracle 0.9117 (0.8940) acc 65.6250 (72.2396) lr 5.1825e-04 eta 0:09:59
epoch [35/50] batch [200/445] time 0.077 (0.087) data 0.000 (0.003) loss 2.3137 (2.1160) teacher_loss 0.9326 (0.8218) loss_zs_kd 1.3522 (1.5525) loss_oracle 0.9466 (0.8940) acc 65.6250 (72.1719) lr 5.1825e-04 eta 0:10:03
epoch [35/50] batch [220/445] time 0.080 (0.087) data 0.000 (0.003) loss 2.1039 (2.1156) teacher_loss 0.7875 (0.8210) loss_zs_kd 1.3159 (1.5535) loss_oracle 0.9070 (0.8933) acc 75.0000 (72.2301) lr 5.1825e-04 eta 0:09:59
epoch [35/50] batch [240/445] time 0.090 (0.087) data 0.000 (0.002) loss 2.0745 (2.1171) teacher_loss 0.7882 (0.8240) loss_zs_kd 1.4268 (1.5528) loss_oracle 0.8743 (0.8928) acc 78.1250 (72.2266) lr 5.1825e-04 eta 0:09:55
epoch [35/50] batch [260/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.9180 (2.1181) teacher_loss 0.6549 (0.8227) loss_zs_kd 1.4512 (1.5611) loss_oracle 0.8240 (0.8941) acc 84.3750 (72.3197) lr 5.1825e-04 eta 0:09:52
epoch [35/50] batch [280/445] time 0.077 (0.086) data 0.000 (0.002) loss 1.8400 (2.1161) teacher_loss 0.4791 (0.8197) loss_zs_kd 1.4878 (1.5630) loss_oracle 0.9011 (0.8949) acc 81.2500 (72.3661) lr 5.1825e-04 eta 0:09:46
epoch [35/50] batch [300/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.1704 (2.1150) teacher_loss 0.8018 (0.8187) loss_zs_kd 1.4458 (1.5615) loss_oracle 0.9292 (0.8942) acc 68.7500 (72.2917) lr 5.1825e-04 eta 0:09:43
epoch [35/50] batch [320/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.2169 (2.1154) teacher_loss 0.9853 (0.8195) loss_zs_kd 1.7330 (1.5679) loss_oracle 0.8730 (0.8940) acc 65.6250 (72.2266) lr 5.1825e-04 eta 0:09:41
epoch [35/50] batch [340/445] time 0.079 (0.085) data 0.000 (0.002) loss 2.3697 (2.1140) teacher_loss 0.9900 (0.8189) loss_zs_kd 1.5417 (1.5617) loss_oracle 0.8776 (0.8926) acc 68.7500 (72.3346) lr 5.1825e-04 eta 0:09:39
epoch [35/50] batch [360/445] time 0.080 (0.085) data 0.001 (0.002) loss 2.2033 (2.1148) teacher_loss 0.8917 (0.8199) loss_zs_kd 1.6311 (1.5639) loss_oracle 0.9283 (0.8924) acc 65.6250 (72.3264) lr 5.1825e-04 eta 0:09:36
epoch [35/50] batch [380/445] time 0.084 (0.085) data 0.000 (0.002) loss 2.1152 (2.1119) teacher_loss 0.8463 (0.8175) loss_zs_kd 1.5908 (1.5654) loss_oracle 0.8046 (0.8924) acc 62.5000 (72.4013) lr 5.1825e-04 eta 0:09:33
epoch [35/50] batch [400/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.1884 (2.1130) teacher_loss 0.9077 (0.8191) loss_zs_kd 1.5763 (1.5617) loss_oracle 0.8878 (0.8911) acc 59.3750 (72.3047) lr 5.1825e-04 eta 0:09:31
epoch [35/50] batch [420/445] time 0.085 (0.085) data 0.000 (0.001) loss 2.3612 (2.1132) teacher_loss 1.0345 (0.8206) loss_zs_kd 1.4895 (1.5616) loss_oracle 0.9424 (0.8907) acc 75.0000 (72.2768) lr 5.1825e-04 eta 0:09:28
epoch [35/50] batch [440/445] time 0.084 (0.085) data 0.000 (0.001) loss 2.2899 (2.1135) teacher_loss 1.0320 (0.8216) loss_zs_kd 1.6310 (1.5648) loss_oracle 0.8729 (0.8905) acc 62.5000 (72.3011) lr 5.1825e-04 eta 0:09:26
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,285
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 56.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,032
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 30.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      70.2%, epoch: 35 *******
******* Domain 3 best val test acc: 51.2%, epoch: 35 *******
******* Domain 3 best test acc:     51.2%, epoch: 35 *******
epoch [36/50] batch [20/445] time 0.080 (0.125) data 0.000 (0.038) loss 2.0631 (2.0760) teacher_loss 0.7865 (0.8009) loss_zs_kd 1.2218 (1.4965) loss_oracle 0.8880 (0.8681) acc 84.3750 (75.6250) lr 4.6417e-04 eta 0:13:55
epoch [36/50] batch [40/445] time 0.085 (0.103) data 0.000 (0.019) loss 2.4715 (2.0890) teacher_loss 1.1130 (0.8059) loss_zs_kd 1.7295 (1.5173) loss_oracle 0.9295 (0.8684) acc 59.3750 (74.3750) lr 4.6417e-04 eta 0:11:25
epoch [36/50] batch [60/445] time 0.085 (0.097) data 0.001 (0.013) loss 2.2125 (2.0883) teacher_loss 0.9550 (0.8130) loss_zs_kd 1.9434 (1.5372) loss_oracle 0.8534 (0.8624) acc 71.8750 (74.1667) lr 4.6417e-04 eta 0:10:44
epoch [36/50] batch [80/445] time 0.084 (0.095) data 0.000 (0.010) loss 2.1467 (2.0892) teacher_loss 0.8733 (0.8109) loss_zs_kd 1.8325 (1.5514) loss_oracle 0.8311 (0.8650) acc 71.8750 (73.7500) lr 4.6417e-04 eta 0:10:24
epoch [36/50] batch [100/445] time 0.094 (0.093) data 0.000 (0.008) loss 2.2048 (2.0837) teacher_loss 0.9065 (0.8022) loss_zs_kd 1.8725 (1.5583) loss_oracle 0.9272 (0.8659) acc 65.6250 (73.5938) lr 4.6417e-04 eta 0:10:12
epoch [36/50] batch [120/445] time 0.082 (0.092) data 0.000 (0.007) loss 1.8717 (2.0883) teacher_loss 0.6701 (0.8053) loss_zs_kd 1.4579 (1.5703) loss_oracle 0.8230 (0.8658) acc 75.0000 (73.3073) lr 4.6417e-04 eta 0:10:01
epoch [36/50] batch [140/445] time 0.076 (0.090) data 0.000 (0.006) loss 2.1292 (2.0951) teacher_loss 0.8385 (0.8142) loss_zs_kd 1.5617 (1.5676) loss_oracle 0.8267 (0.8631) acc 65.6250 (72.8125) lr 4.6417e-04 eta 0:09:48
epoch [36/50] batch [160/445] time 0.084 (0.089) data 0.000 (0.005) loss 2.1628 (2.0973) teacher_loss 0.8375 (0.8153) loss_zs_kd 1.2316 (1.5667) loss_oracle 0.8790 (0.8643) acc 71.8750 (72.9688) lr 4.6417e-04 eta 0:09:42
epoch [36/50] batch [180/445] time 0.095 (0.089) data 0.000 (0.005) loss 2.1015 (2.0973) teacher_loss 0.8664 (0.8158) loss_zs_kd 1.6262 (1.5697) loss_oracle 0.8593 (0.8674) acc 68.7500 (72.9514) lr 4.6417e-04 eta 0:09:36
epoch [36/50] batch [200/445] time 0.082 (0.089) data 0.000 (0.004) loss 2.1997 (2.1002) teacher_loss 0.9133 (0.8176) loss_zs_kd 1.5659 (1.5584) loss_oracle 0.8865 (0.8686) acc 68.7500 (72.8438) lr 4.6417e-04 eta 0:09:34
epoch [36/50] batch [220/445] time 0.087 (0.088) data 0.000 (0.004) loss 1.8114 (2.0992) teacher_loss 0.6031 (0.8153) loss_zs_kd 1.3703 (1.5607) loss_oracle 0.8595 (0.8698) acc 78.1250 (72.8693) lr 4.6417e-04 eta 0:09:30
epoch [36/50] batch [240/445] time 0.083 (0.088) data 0.000 (0.003) loss 2.0864 (2.0972) teacher_loss 1.0009 (0.8148) loss_zs_kd 1.1432 (1.5680) loss_oracle 0.8449 (0.8698) acc 71.8750 (72.9427) lr 4.6417e-04 eta 0:09:26
epoch [36/50] batch [260/445] time 0.082 (0.088) data 0.000 (0.003) loss 2.3487 (2.1017) teacher_loss 1.0172 (0.8197) loss_zs_kd 1.3500 (1.5612) loss_oracle 0.9547 (0.8689) acc 56.2500 (72.6082) lr 4.6417e-04 eta 0:09:23
epoch [36/50] batch [280/445] time 0.087 (0.088) data 0.000 (0.003) loss 2.0952 (2.1059) teacher_loss 0.8101 (0.8237) loss_zs_kd 1.8539 (1.5653) loss_oracle 0.8738 (0.8687) acc 68.7500 (72.4665) lr 4.6417e-04 eta 0:09:20
epoch [36/50] batch [300/445] time 0.163 (0.088) data 0.000 (0.003) loss 1.9452 (2.1031) teacher_loss 0.7468 (0.8216) loss_zs_kd 1.2283 (1.5646) loss_oracle 0.8188 (0.8683) acc 68.7500 (72.5208) lr 4.6417e-04 eta 0:09:19
epoch [36/50] batch [320/445] time 0.082 (0.088) data 0.000 (0.003) loss 1.8173 (2.0979) teacher_loss 0.4685 (0.8173) loss_zs_kd 1.6760 (1.5737) loss_oracle 0.9543 (0.8685) acc 84.3750 (72.6465) lr 4.6417e-04 eta 0:09:19
epoch [36/50] batch [340/445] time 0.095 (0.088) data 0.000 (0.003) loss 2.2970 (2.1009) teacher_loss 1.0290 (0.8203) loss_zs_kd 1.4305 (1.5753) loss_oracle 0.8590 (0.8678) acc 59.3750 (72.4908) lr 4.6417e-04 eta 0:09:16
epoch [36/50] batch [360/445] time 0.085 (0.088) data 0.000 (0.002) loss 2.4924 (2.1055) teacher_loss 1.1388 (0.8234) loss_zs_kd 1.6996 (1.5787) loss_oracle 0.9513 (0.8674) acc 59.3750 (72.3958) lr 4.6417e-04 eta 0:09:13
epoch [36/50] batch [380/445] time 0.083 (0.087) data 0.000 (0.002) loss 2.2076 (2.1048) teacher_loss 0.9900 (0.8232) loss_zs_kd 1.4789 (1.5771) loss_oracle 0.8338 (0.8670) acc 71.8750 (72.4836) lr 4.6417e-04 eta 0:09:10
epoch [36/50] batch [400/445] time 0.081 (0.087) data 0.000 (0.002) loss 2.0898 (2.1067) teacher_loss 0.8192 (0.8247) loss_zs_kd 1.3037 (1.5811) loss_oracle 0.8848 (0.8666) acc 68.7500 (72.4688) lr 4.6417e-04 eta 0:09:07
epoch [36/50] batch [420/445] time 0.077 (0.087) data 0.000 (0.002) loss 2.1219 (2.1019) teacher_loss 0.9001 (0.8198) loss_zs_kd 1.6767 (1.5813) loss_oracle 0.8834 (0.8671) acc 71.8750 (72.6265) lr 4.6417e-04 eta 0:09:04
epoch [36/50] batch [440/445] time 0.085 (0.087) data 0.001 (0.002) loss 1.9957 (2.1024) teacher_loss 0.8043 (0.8210) loss_zs_kd 1.3282 (1.5864) loss_oracle 0.7969 (0.8658) acc 71.8750 (72.5923) lr 4.6417e-04 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,299
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 56.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,021
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 30.7%
******* Domain 3 best val acc:      70.4%, epoch: 36 *******
******* Domain 3 best val test acc: 50.9%, epoch: 36 *******
******* Domain 3 best test acc:     51.2%, epoch: 35 *******
epoch [37/50] batch [20/445] time 0.142 (0.126) data 0.001 (0.035) loss 2.1684 (2.1178) teacher_loss 0.8232 (0.8250) loss_zs_kd 1.5570 (1.5746) loss_oracle 0.8300 (0.8597) acc 68.7500 (71.7188) lr 4.1221e-04 eta 0:13:03
epoch [37/50] batch [40/445] time 0.082 (0.109) data 0.000 (0.018) loss 1.8148 (2.1213) teacher_loss 0.4877 (0.8368) loss_zs_kd 1.5367 (1.5783) loss_oracle 0.8726 (0.8606) acc 84.3750 (71.9531) lr 4.1221e-04 eta 0:11:16
epoch [37/50] batch [60/445] time 0.091 (0.100) data 0.001 (0.012) loss 2.1159 (2.1234) teacher_loss 0.8797 (0.8490) loss_zs_kd 1.4222 (1.5910) loss_oracle 0.8784 (0.8546) acc 68.7500 (71.3021) lr 4.1221e-04 eta 0:10:19
epoch [37/50] batch [80/445] time 0.077 (0.096) data 0.000 (0.009) loss 2.1666 (2.1151) teacher_loss 0.9209 (0.8437) loss_zs_kd 1.6534 (1.5899) loss_oracle 0.8778 (0.8533) acc 59.3750 (71.2891) lr 4.1221e-04 eta 0:09:49
epoch [37/50] batch [100/445] time 0.077 (0.092) data 0.000 (0.007) loss 2.3826 (2.0974) teacher_loss 1.0730 (0.8244) loss_zs_kd 1.8150 (1.6015) loss_oracle 0.9469 (0.8547) acc 62.5000 (71.8750) lr 4.1221e-04 eta 0:09:25
epoch [37/50] batch [120/445] time 0.087 (0.091) data 0.000 (0.006) loss 2.2018 (2.1065) teacher_loss 0.8336 (0.8300) loss_zs_kd 1.8169 (1.5898) loss_oracle 0.8704 (0.8572) acc 71.8750 (71.6927) lr 4.1221e-04 eta 0:09:16
epoch [37/50] batch [140/445] time 0.080 (0.090) data 0.000 (0.005) loss 2.0174 (2.1011) teacher_loss 0.7276 (0.8254) loss_zs_kd 1.6452 (1.5793) loss_oracle 0.8398 (0.8574) acc 78.1250 (71.8527) lr 4.1221e-04 eta 0:09:10
epoch [37/50] batch [160/445] time 0.077 (0.089) data 0.000 (0.005) loss 1.9680 (2.1068) teacher_loss 0.6370 (0.8270) loss_zs_kd 1.7974 (1.5752) loss_oracle 0.8546 (0.8585) acc 75.0000 (71.9336) lr 4.1221e-04 eta 0:08:59
epoch [37/50] batch [180/445] time 0.070 (0.088) data 0.000 (0.004) loss 2.2881 (2.1109) teacher_loss 0.9418 (0.8290) loss_zs_kd 1.6452 (1.5815) loss_oracle 0.8790 (0.8575) acc 56.2500 (71.6493) lr 4.1221e-04 eta 0:08:53
epoch [37/50] batch [200/445] time 0.074 (0.087) data 0.000 (0.004) loss 2.0312 (2.1082) teacher_loss 0.7471 (0.8233) loss_zs_kd 1.4548 (1.5928) loss_oracle 0.8393 (0.8598) acc 84.3750 (71.8594) lr 4.1221e-04 eta 0:08:44
epoch [37/50] batch [220/445] time 0.084 (0.087) data 0.000 (0.003) loss 2.2668 (2.0972) teacher_loss 0.9509 (0.8116) loss_zs_kd 1.7089 (1.5944) loss_oracle 0.8376 (0.8615) acc 62.5000 (72.1733) lr 4.1221e-04 eta 0:08:40
epoch [37/50] batch [240/445] time 0.096 (0.087) data 0.000 (0.003) loss 2.0968 (2.0944) teacher_loss 0.7856 (0.8072) loss_zs_kd 1.6287 (1.5963) loss_oracle 0.8567 (0.8632) acc 71.8750 (72.3958) lr 4.1221e-04 eta 0:08:39
epoch [37/50] batch [260/445] time 0.087 (0.086) data 0.000 (0.003) loss 2.1794 (2.0959) teacher_loss 0.8781 (0.8090) loss_zs_kd 1.5393 (1.5994) loss_oracle 0.8550 (0.8627) acc 71.8750 (72.3317) lr 4.1221e-04 eta 0:08:36
epoch [37/50] batch [280/445] time 0.080 (0.086) data 0.000 (0.003) loss 2.2802 (2.1039) teacher_loss 0.9668 (0.8156) loss_zs_kd 2.2320 (1.6138) loss_oracle 0.8852 (0.8633) acc 68.7500 (72.0312) lr 4.1221e-04 eta 0:08:33
epoch [37/50] batch [300/445] time 0.079 (0.086) data 0.000 (0.003) loss 2.2059 (2.1029) teacher_loss 0.8987 (0.8145) loss_zs_kd 1.7585 (1.6100) loss_oracle 0.8460 (0.8642) acc 62.5000 (72.1979) lr 4.1221e-04 eta 0:08:28
epoch [37/50] batch [320/445] time 0.087 (0.085) data 0.000 (0.002) loss 2.1036 (2.1048) teacher_loss 0.8982 (0.8158) loss_zs_kd 1.7497 (1.6129) loss_oracle 0.9206 (0.8646) acc 68.7500 (72.1582) lr 4.1221e-04 eta 0:08:24
epoch [37/50] batch [340/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.1043 (2.1021) teacher_loss 0.8810 (0.8144) loss_zs_kd 1.6461 (1.6116) loss_oracle 0.8934 (0.8649) acc 81.2500 (72.2059) lr 4.1221e-04 eta 0:08:23
epoch [37/50] batch [360/445] time 0.075 (0.085) data 0.000 (0.002) loss 2.1469 (2.0982) teacher_loss 0.8845 (0.8122) loss_zs_kd 1.6515 (1.6121) loss_oracle 0.9253 (0.8651) acc 71.8750 (72.3264) lr 4.1221e-04 eta 0:08:20
epoch [37/50] batch [380/445] time 0.088 (0.085) data 0.000 (0.002) loss 1.9964 (2.0943) teacher_loss 0.6688 (0.8089) loss_zs_kd 1.6154 (1.6167) loss_oracle 0.9378 (0.8642) acc 81.2500 (72.5987) lr 4.1221e-04 eta 0:08:18
epoch [37/50] batch [400/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.0178 (2.0939) teacher_loss 0.8057 (0.8089) loss_zs_kd 1.6476 (1.6236) loss_oracle 0.8389 (0.8644) acc 78.1250 (72.6797) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [420/445] time 0.112 (0.086) data 0.001 (0.002) loss 2.1575 (2.0918) teacher_loss 0.8244 (0.8065) loss_zs_kd 2.0378 (1.6300) loss_oracle 0.8535 (0.8643) acc 65.6250 (72.7455) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [440/445] time 0.086 (0.086) data 0.001 (0.002) loss 2.2861 (2.0923) teacher_loss 0.9475 (0.8069) loss_zs_kd 1.5744 (1.6237) loss_oracle 0.9020 (0.8652) acc 71.8750 (72.7699) lr 4.1221e-04 eta 0:08:17
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,306
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,999
* accuracy: 50.4%
* error: 49.6%
* macro_f1: 30.1%
******* Domain 3 best val acc:      70.5%, epoch: 37 *******
******* Domain 3 best val test acc: 50.4%, epoch: 37 *******
******* Domain 3 best test acc:     51.2%, epoch: 35 *******
epoch [38/50] batch [20/445] time 0.085 (0.109) data 0.000 (0.025) loss 2.4381 (2.1362) teacher_loss 1.1258 (0.8636) loss_zs_kd 1.4724 (1.5641) loss_oracle 0.8096 (0.8479) acc 62.5000 (72.5000) lr 3.6258e-04 eta 0:10:27
epoch [38/50] batch [40/445] time 0.082 (0.097) data 0.000 (0.013) loss 1.8457 (2.0987) teacher_loss 0.5584 (0.8227) loss_zs_kd 1.5336 (1.6147) loss_oracle 0.8762 (0.8624) acc 84.3750 (72.8125) lr 3.6258e-04 eta 0:09:14
epoch [38/50] batch [60/445] time 0.097 (0.093) data 0.001 (0.009) loss 2.0102 (2.1145) teacher_loss 0.7444 (0.8330) loss_zs_kd 1.8806 (1.6237) loss_oracle 0.8087 (0.8712) acc 78.1250 (71.7188) lr 3.6258e-04 eta 0:08:50
epoch [38/50] batch [80/445] time 0.078 (0.090) data 0.000 (0.006) loss 1.8138 (2.1063) teacher_loss 0.5666 (0.8143) loss_zs_kd 2.1350 (1.6491) loss_oracle 0.8940 (0.8767) acc 87.5000 (72.2656) lr 3.6258e-04 eta 0:08:34
epoch [38/50] batch [100/445] time 0.079 (0.088) data 0.000 (0.005) loss 1.9732 (2.1032) teacher_loss 0.7590 (0.8058) loss_zs_kd 1.4644 (1.6552) loss_oracle 0.8726 (0.8787) acc 68.7500 (72.3125) lr 3.6258e-04 eta 0:08:22
epoch [38/50] batch [120/445] time 0.079 (0.087) data 0.000 (0.004) loss 2.3696 (2.1049) teacher_loss 0.9974 (0.8063) loss_zs_kd 1.6932 (1.6411) loss_oracle 0.8872 (0.8752) acc 62.5000 (72.5521) lr 3.6258e-04 eta 0:08:12
epoch [38/50] batch [140/445] time 0.078 (0.086) data 0.000 (0.004) loss 2.0812 (2.1068) teacher_loss 0.7649 (0.8054) loss_zs_kd 1.6480 (1.6308) loss_oracle 0.8873 (0.8732) acc 78.1250 (72.5000) lr 3.6258e-04 eta 0:08:06
epoch [38/50] batch [160/445] time 0.076 (0.087) data 0.000 (0.003) loss 2.0265 (2.1071) teacher_loss 0.6466 (0.8013) loss_zs_kd 1.8124 (1.6410) loss_oracle 0.8970 (0.8740) acc 81.2500 (72.5586) lr 3.6258e-04 eta 0:08:08
epoch [38/50] batch [180/445] time 0.089 (0.086) data 0.000 (0.003) loss 2.0930 (2.1083) teacher_loss 0.7621 (0.7977) loss_zs_kd 1.3627 (1.6338) loss_oracle 0.8982 (0.8753) acc 75.0000 (72.7951) lr 3.6258e-04 eta 0:08:02
epoch [38/50] batch [200/445] time 0.087 (0.086) data 0.000 (0.003) loss 2.7122 (2.1227) teacher_loss 1.2980 (0.8093) loss_zs_kd 1.9499 (1.6373) loss_oracle 0.9813 (0.8766) acc 56.2500 (72.3750) lr 3.6258e-04 eta 0:08:01
epoch [38/50] batch [220/445] time 0.083 (0.086) data 0.000 (0.003) loss 2.1507 (2.1286) teacher_loss 0.8379 (0.8149) loss_zs_kd 1.6504 (1.6421) loss_oracle 0.8897 (0.8776) acc 65.6250 (72.0170) lr 3.6258e-04 eta 0:07:59
epoch [38/50] batch [240/445] time 0.076 (0.086) data 0.000 (0.002) loss 2.3699 (2.1319) teacher_loss 0.9741 (0.8188) loss_zs_kd 1.8098 (1.6390) loss_oracle 0.8681 (0.8775) acc 56.2500 (71.8880) lr 3.6258e-04 eta 0:07:55
epoch [38/50] batch [260/445] time 0.087 (0.086) data 0.000 (0.002) loss 2.0103 (2.1290) teacher_loss 0.6606 (0.8169) loss_zs_kd 1.5019 (1.6364) loss_oracle 0.9423 (0.8776) acc 81.2500 (71.8630) lr 3.6258e-04 eta 0:07:52
epoch [38/50] batch [280/445] time 0.080 (0.085) data 0.000 (0.002) loss 1.8662 (2.1280) teacher_loss 0.6986 (0.8174) loss_zs_kd 1.6165 (1.6336) loss_oracle 0.7363 (0.8778) acc 65.6250 (71.8973) lr 3.6258e-04 eta 0:07:50
epoch [38/50] batch [300/445] time 0.076 (0.085) data 0.000 (0.002) loss 1.9495 (2.1289) teacher_loss 0.6648 (0.8202) loss_zs_kd 2.1299 (1.6353) loss_oracle 0.8808 (0.8776) acc 75.0000 (71.7708) lr 3.6258e-04 eta 0:07:47
epoch [38/50] batch [320/445] time 0.075 (0.085) data 0.000 (0.002) loss 2.0888 (2.1295) teacher_loss 0.9312 (0.8220) loss_zs_kd 1.3194 (1.6344) loss_oracle 0.7858 (0.8779) acc 68.7500 (71.7676) lr 3.6258e-04 eta 0:07:43
epoch [38/50] batch [340/445] time 0.083 (0.084) data 0.000 (0.002) loss 1.9876 (2.1278) teacher_loss 0.8125 (0.8214) loss_zs_kd 1.4110 (1.6299) loss_oracle 0.8522 (0.8786) acc 78.1250 (71.9393) lr 3.6258e-04 eta 0:07:39
epoch [38/50] batch [360/445] time 0.084 (0.084) data 0.000 (0.002) loss 1.8225 (2.1298) teacher_loss 0.6126 (0.8232) loss_zs_kd 1.5834 (1.6278) loss_oracle 0.8347 (0.8776) acc 90.6250 (71.8663) lr 3.6258e-04 eta 0:07:37
epoch [38/50] batch [380/445] time 0.080 (0.084) data 0.000 (0.002) loss 1.9431 (2.1290) teacher_loss 0.6524 (0.8220) loss_zs_kd 1.6419 (1.6331) loss_oracle 0.9431 (0.8783) acc 75.0000 (72.0230) lr 3.6258e-04 eta 0:07:35
epoch [38/50] batch [400/445] time 0.089 (0.084) data 0.000 (0.002) loss 2.1752 (2.1304) teacher_loss 0.8696 (0.8236) loss_zs_kd 1.9340 (1.6343) loss_oracle 0.8625 (0.8782) acc 68.7500 (72.0078) lr 3.6258e-04 eta 0:07:33
epoch [38/50] batch [420/445] time 0.083 (0.084) data 0.000 (0.001) loss 2.1827 (2.1297) teacher_loss 0.9446 (0.8220) loss_zs_kd 1.7208 (1.6364) loss_oracle 0.8515 (0.8783) acc 71.8750 (72.0164) lr 3.6258e-04 eta 0:07:32
epoch [38/50] batch [440/445] time 0.084 (0.084) data 0.000 (0.001) loss 1.8758 (2.1285) teacher_loss 0.5382 (0.8207) loss_zs_kd 1.7832 (1.6394) loss_oracle 0.8807 (0.8780) acc 84.3750 (72.0952) lr 3.6258e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,288
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 56.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,053
* accuracy: 51.7%
* error: 48.3%
* macro_f1: 31.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      70.5%, epoch: 37 *******
******* Domain 3 best val test acc: 50.4%, epoch: 37 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [39/50] batch [20/445] time 0.085 (0.112) data 0.000 (0.025) loss 1.8450 (2.1717) teacher_loss 0.5951 (0.8473) loss_zs_kd 1.2902 (1.7917) loss_oracle 0.8912 (0.9152) acc 75.0000 (71.2500) lr 3.1545e-04 eta 0:09:53
epoch [39/50] batch [40/445] time 0.074 (0.098) data 0.000 (0.013) loss 2.0842 (2.1523) teacher_loss 0.7743 (0.8330) loss_zs_kd 1.8894 (1.7345) loss_oracle 0.8767 (0.8954) acc 78.1250 (70.9375) lr 3.1545e-04 eta 0:08:39
epoch [39/50] batch [60/445] time 0.078 (0.091) data 0.001 (0.008) loss 1.9915 (2.1291) teacher_loss 0.6785 (0.8239) loss_zs_kd 1.7469 (1.7147) loss_oracle 0.8757 (0.8884) acc 81.2500 (71.8229) lr 3.1545e-04 eta 0:08:02
epoch [39/50] batch [80/445] time 0.088 (0.089) data 0.000 (0.006) loss 1.9298 (2.1268) teacher_loss 0.6197 (0.8174) loss_zs_kd 1.9157 (1.7254) loss_oracle 0.8562 (0.8887) acc 81.2500 (71.7969) lr 3.1545e-04 eta 0:07:47
epoch [39/50] batch [100/445] time 0.081 (0.087) data 0.000 (0.005) loss 2.1825 (2.1159) teacher_loss 0.6987 (0.8080) loss_zs_kd 1.5209 (1.7258) loss_oracle 0.9098 (0.8848) acc 75.0000 (71.9688) lr 3.1545e-04 eta 0:07:36
epoch [39/50] batch [120/445] time 0.082 (0.087) data 0.000 (0.004) loss 2.3236 (2.1132) teacher_loss 0.8489 (0.8038) loss_zs_kd 1.4170 (1.7186) loss_oracle 0.9694 (0.8884) acc 68.7500 (72.1615) lr 3.1545e-04 eta 0:07:32
epoch [39/50] batch [140/445] time 0.082 (0.086) data 0.000 (0.004) loss 2.2014 (2.1087) teacher_loss 0.9656 (0.8014) loss_zs_kd 1.7080 (1.7028) loss_oracle 0.8359 (0.8889) acc 68.7500 (72.3214) lr 3.1545e-04 eta 0:07:28
epoch [39/50] batch [160/445] time 0.079 (0.086) data 0.000 (0.003) loss 2.0162 (2.1027) teacher_loss 0.7268 (0.7969) loss_zs_kd 1.4772 (1.7110) loss_oracle 0.8732 (0.8888) acc 81.2500 (72.6562) lr 3.1545e-04 eta 0:07:24
epoch [39/50] batch [180/445] time 0.080 (0.085) data 0.000 (0.003) loss 2.1299 (2.1118) teacher_loss 0.8496 (0.8051) loss_zs_kd 1.7503 (1.7130) loss_oracle 0.8312 (0.8889) acc 68.7500 (72.4653) lr 3.1545e-04 eta 0:07:20
epoch [39/50] batch [200/445] time 0.077 (0.085) data 0.000 (0.003) loss 2.1744 (2.1120) teacher_loss 0.9025 (0.8053) loss_zs_kd 1.3441 (1.7071) loss_oracle 0.8644 (0.8889) acc 71.8750 (72.6562) lr 3.1545e-04 eta 0:07:17
epoch [39/50] batch [220/445] time 0.086 (0.084) data 0.000 (0.003) loss 2.6400 (2.1072) teacher_loss 1.2145 (0.8012) loss_zs_kd 1.6349 (1.6953) loss_oracle 0.9611 (0.8882) acc 56.2500 (72.9119) lr 3.1545e-04 eta 0:07:12
epoch [39/50] batch [240/445] time 0.083 (0.084) data 0.000 (0.002) loss 2.4537 (2.1138) teacher_loss 1.1186 (0.8057) loss_zs_kd 1.7139 (1.6930) loss_oracle 0.9357 (0.8880) acc 62.5000 (72.7865) lr 3.1545e-04 eta 0:07:10
epoch [39/50] batch [260/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.1894 (2.1107) teacher_loss 0.9501 (0.8032) loss_zs_kd 1.5235 (1.6852) loss_oracle 0.8444 (0.8886) acc 71.8750 (72.9207) lr 3.1545e-04 eta 0:07:09
epoch [39/50] batch [280/445] time 0.079 (0.084) data 0.000 (0.002) loss 1.8778 (2.1132) teacher_loss 0.6458 (0.8036) loss_zs_kd 1.8355 (1.6867) loss_oracle 0.9113 (0.8898) acc 81.2500 (72.9799) lr 3.1545e-04 eta 0:07:07
epoch [39/50] batch [300/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.0121 (2.1161) teacher_loss 0.7609 (0.8069) loss_zs_kd 1.9063 (1.6872) loss_oracle 0.8644 (0.8893) acc 78.1250 (72.8958) lr 3.1545e-04 eta 0:07:10
epoch [39/50] batch [320/445] time 0.075 (0.085) data 0.000 (0.002) loss 1.8162 (2.1154) teacher_loss 0.5212 (0.8075) loss_zs_kd 1.9546 (1.6844) loss_oracle 0.9216 (0.8883) acc 81.2500 (72.8711) lr 3.1545e-04 eta 0:07:08
epoch [39/50] batch [340/445] time 0.082 (0.085) data 0.000 (0.002) loss 2.2601 (2.1152) teacher_loss 0.9691 (0.8090) loss_zs_kd 1.8469 (1.6800) loss_oracle 0.8614 (0.8872) acc 68.7500 (72.7665) lr 3.1545e-04 eta 0:07:05
epoch [39/50] batch [360/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.1062 (2.1192) teacher_loss 0.8071 (0.8122) loss_zs_kd 2.0404 (1.6799) loss_oracle 0.9182 (0.8873) acc 75.0000 (72.6042) lr 3.1545e-04 eta 0:07:01
epoch [39/50] batch [380/445] time 0.081 (0.084) data 0.000 (0.002) loss 1.9755 (2.1227) teacher_loss 0.7226 (0.8164) loss_zs_kd 1.7633 (1.6831) loss_oracle 0.8928 (0.8870) acc 81.2500 (72.5329) lr 3.1545e-04 eta 0:06:59
epoch [39/50] batch [400/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.0661 (2.1176) teacher_loss 0.7899 (0.8130) loss_zs_kd 1.6777 (1.6852) loss_oracle 0.8951 (0.8862) acc 78.1250 (72.6250) lr 3.1545e-04 eta 0:06:57
epoch [39/50] batch [420/445] time 0.084 (0.084) data 0.000 (0.001) loss 2.3181 (2.1152) teacher_loss 1.0240 (0.8117) loss_zs_kd 1.3749 (1.6853) loss_oracle 0.9399 (0.8856) acc 71.8750 (72.7009) lr 3.1545e-04 eta 0:06:55
epoch [39/50] batch [440/445] time 0.082 (0.084) data 0.000 (0.001) loss 1.9108 (2.1153) teacher_loss 0.6478 (0.8122) loss_zs_kd 1.5270 (1.6848) loss_oracle 0.8810 (0.8853) acc 71.8750 (72.7060) lr 3.1545e-04 eta 0:06:53
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,316
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 57.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,016
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 31.6%
******* Domain 3 best val acc:      70.7%, epoch: 39 *******
******* Domain 3 best val test acc: 50.8%, epoch: 39 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [40/50] batch [20/445] time 0.086 (0.107) data 0.000 (0.026) loss 1.9070 (2.0851) teacher_loss 0.6504 (0.7715) loss_zs_kd 1.7292 (1.5960) loss_oracle 0.9139 (0.8846) acc 84.3750 (73.9062) lr 2.7103e-04 eta 0:08:39
epoch [40/50] batch [40/445] time 0.083 (0.103) data 0.000 (0.013) loss 2.2540 (2.1241) teacher_loss 0.9273 (0.8048) loss_zs_kd 1.3492 (1.6323) loss_oracle 0.8758 (0.8822) acc 71.8750 (73.8281) lr 2.7103e-04 eta 0:08:17
epoch [40/50] batch [60/445] time 0.091 (0.096) data 0.001 (0.009) loss 2.3135 (2.1057) teacher_loss 0.9738 (0.7906) loss_zs_kd 1.4464 (1.6080) loss_oracle 0.8875 (0.8833) acc 62.5000 (74.5833) lr 2.7103e-04 eta 0:07:42
epoch [40/50] batch [80/445] time 0.074 (0.092) data 0.000 (0.007) loss 2.5043 (2.1007) teacher_loss 1.0611 (0.7882) loss_zs_kd 1.5007 (1.6124) loss_oracle 0.9525 (0.8828) acc 65.6250 (74.0625) lr 2.7103e-04 eta 0:07:22
epoch [40/50] batch [100/445] time 0.083 (0.091) data 0.000 (0.005) loss 2.2286 (2.1203) teacher_loss 0.9410 (0.8080) loss_zs_kd 1.2914 (1.6121) loss_oracle 0.8088 (0.8844) acc 75.0000 (73.1562) lr 2.7103e-04 eta 0:07:14
epoch [40/50] batch [120/445] time 0.090 (0.090) data 0.000 (0.005) loss 2.1305 (2.1149) teacher_loss 0.7198 (0.8074) loss_zs_kd 1.6895 (1.6060) loss_oracle 0.9252 (0.8800) acc 81.2500 (73.4115) lr 2.7103e-04 eta 0:07:08
epoch [40/50] batch [140/445] time 0.073 (0.088) data 0.000 (0.004) loss 2.0735 (2.1050) teacher_loss 0.8221 (0.8023) loss_zs_kd 2.0472 (1.6197) loss_oracle 0.9209 (0.8776) acc 65.6250 (73.6830) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [160/445] time 0.079 (0.088) data 0.000 (0.004) loss 2.1679 (2.1111) teacher_loss 0.8022 (0.8074) loss_zs_kd 1.9220 (1.6223) loss_oracle 0.9199 (0.8805) acc 84.3750 (73.6328) lr 2.7103e-04 eta 0:06:55
epoch [40/50] batch [180/445] time 0.080 (0.087) data 0.000 (0.003) loss 2.0305 (2.1068) teacher_loss 0.6583 (0.8026) loss_zs_kd 1.7270 (1.6368) loss_oracle 0.8848 (0.8789) acc 81.2500 (73.8194) lr 2.7103e-04 eta 0:06:49
epoch [40/50] batch [200/445] time 0.085 (0.087) data 0.000 (0.003) loss 2.3466 (2.1126) teacher_loss 1.0201 (0.8081) loss_zs_kd 1.5519 (1.6363) loss_oracle 0.8972 (0.8770) acc 62.5000 (73.5156) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [220/445] time 0.074 (0.086) data 0.000 (0.003) loss 2.0488 (2.1178) teacher_loss 0.8340 (0.8112) loss_zs_kd 1.3626 (1.6356) loss_oracle 0.7957 (0.8774) acc 71.8750 (73.5653) lr 2.7103e-04 eta 0:06:43
epoch [40/50] batch [240/445] time 0.091 (0.086) data 0.000 (0.002) loss 2.0544 (2.1172) teacher_loss 0.8807 (0.8119) loss_zs_kd 1.2798 (1.6302) loss_oracle 0.7789 (0.8767) acc 59.3750 (73.2552) lr 2.7103e-04 eta 0:06:40
epoch [40/50] batch [260/445] time 0.081 (0.086) data 0.000 (0.002) loss 2.2180 (2.1212) teacher_loss 0.9569 (0.8144) loss_zs_kd 1.3263 (1.6306) loss_oracle 0.9283 (0.8796) acc 62.5000 (73.0649) lr 2.7103e-04 eta 0:06:38
epoch [40/50] batch [280/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.2296 (2.1163) teacher_loss 0.9026 (0.8106) loss_zs_kd 1.7370 (1.6342) loss_oracle 0.8955 (0.8794) acc 75.0000 (73.0022) lr 2.7103e-04 eta 0:06:34
epoch [40/50] batch [300/445] time 0.083 (0.085) data 0.000 (0.002) loss 2.3297 (2.1161) teacher_loss 1.0873 (0.8124) loss_zs_kd 1.3667 (1.6339) loss_oracle 0.8155 (0.8788) acc 71.8750 (72.8854) lr 2.7103e-04 eta 0:06:32
epoch [40/50] batch [320/445] time 0.078 (0.085) data 0.000 (0.002) loss 2.3941 (2.1196) teacher_loss 1.1673 (0.8162) loss_zs_kd 1.8022 (1.6344) loss_oracle 0.8556 (0.8789) acc 65.6250 (72.7734) lr 2.7103e-04 eta 0:06:29
epoch [40/50] batch [340/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.7105 (2.1221) teacher_loss 1.4221 (0.8185) loss_zs_kd 1.4735 (1.6320) loss_oracle 0.8393 (0.8789) acc 50.0000 (72.6103) lr 2.7103e-04 eta 0:06:27
epoch [40/50] batch [360/445] time 0.082 (0.085) data 0.000 (0.002) loss 1.8426 (2.1211) teacher_loss 0.5900 (0.8180) loss_zs_kd 1.7592 (1.6379) loss_oracle 0.8994 (0.8787) acc 75.0000 (72.6302) lr 2.7103e-04 eta 0:06:25
epoch [40/50] batch [380/445] time 0.087 (0.085) data 0.000 (0.002) loss 2.1529 (2.1216) teacher_loss 0.8890 (0.8186) loss_zs_kd 1.4842 (1.6387) loss_oracle 0.7852 (0.8781) acc 65.6250 (72.5329) lr 2.7103e-04 eta 0:06:23
epoch [40/50] batch [400/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.3272 (2.1249) teacher_loss 1.0062 (0.8217) loss_zs_kd 1.9547 (1.6434) loss_oracle 0.8468 (0.8773) acc 75.0000 (72.4375) lr 2.7103e-04 eta 0:06:22
epoch [40/50] batch [420/445] time 0.081 (0.085) data 0.000 (0.002) loss 2.7440 (2.1264) teacher_loss 1.3915 (0.8237) loss_zs_kd 1.8878 (1.6483) loss_oracle 0.8534 (0.8767) acc 50.0000 (72.2321) lr 2.7103e-04 eta 0:06:19
epoch [40/50] batch [440/445] time 0.083 (0.085) data 0.000 (0.001) loss 2.3239 (2.1242) teacher_loss 1.0355 (0.8219) loss_zs_kd 1.5327 (1.6494) loss_oracle 0.7806 (0.8764) acc 62.5000 (72.1946) lr 2.7103e-04 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,284
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,990
* accuracy: 50.1%
* error: 49.9%
* macro_f1: 30.9%
******* Domain 3 best val acc:      70.7%, epoch: 39 *******
******* Domain 3 best val test acc: 50.8%, epoch: 39 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [41/50] batch [20/445] time 0.083 (0.110) data 0.000 (0.026) loss 2.0910 (2.1940) teacher_loss 0.8423 (0.8742) loss_zs_kd 1.6374 (1.7219) loss_oracle 0.8214 (0.8753) acc 75.0000 (70.1562) lr 2.2949e-04 eta 0:08:05
epoch [41/50] batch [40/445] time 0.084 (0.096) data 0.000 (0.013) loss 2.1512 (2.1400) teacher_loss 0.8365 (0.8339) loss_zs_kd 1.6980 (1.6881) loss_oracle 0.8509 (0.8719) acc 71.8750 (71.2500) lr 2.2949e-04 eta 0:07:04
epoch [41/50] batch [60/445] time 0.087 (0.092) data 0.000 (0.009) loss 2.2775 (2.1459) teacher_loss 0.8984 (0.8352) loss_zs_kd 1.3231 (1.6506) loss_oracle 0.8518 (0.8750) acc 68.7500 (71.3021) lr 2.2949e-04 eta 0:06:46
epoch [41/50] batch [80/445] time 0.091 (0.091) data 0.000 (0.007) loss 1.9971 (2.1612) teacher_loss 0.7629 (0.8523) loss_zs_kd 1.5592 (1.6625) loss_oracle 0.8610 (0.8717) acc 71.8750 (70.8984) lr 2.2949e-04 eta 0:06:36
epoch [41/50] batch [100/445] time 0.081 (0.089) data 0.000 (0.005) loss 2.1918 (2.1563) teacher_loss 0.8707 (0.8508) loss_zs_kd 2.0528 (1.6528) loss_oracle 0.8447 (0.8702) acc 71.8750 (71.2188) lr 2.2949e-04 eta 0:06:28
epoch [41/50] batch [120/445] time 0.086 (0.088) data 0.000 (0.005) loss 2.3422 (2.1452) teacher_loss 1.0151 (0.8389) loss_zs_kd 1.4616 (1.6514) loss_oracle 0.8830 (0.8676) acc 65.6250 (71.7708) lr 2.2949e-04 eta 0:06:20
epoch [41/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.004) loss 2.2818 (2.1397) teacher_loss 0.9690 (0.8357) loss_zs_kd 1.6626 (1.6507) loss_oracle 0.8327 (0.8686) acc 65.6250 (71.8527) lr 2.2949e-04 eta 0:06:15
epoch [41/50] batch [160/445] time 0.163 (0.088) data 0.001 (0.004) loss 1.8661 (2.1407) teacher_loss 0.5471 (0.8350) loss_zs_kd 1.7264 (1.6633) loss_oracle 0.8928 (0.8710) acc 81.2500 (72.0117) lr 2.2949e-04 eta 0:06:19
epoch [41/50] batch [180/445] time 0.081 (0.088) data 0.000 (0.003) loss 2.2141 (2.1410) teacher_loss 0.8823 (0.8351) loss_zs_kd 1.5939 (1.6665) loss_oracle 0.8685 (0.8704) acc 65.6250 (71.8750) lr 2.2949e-04 eta 0:06:15
epoch [41/50] batch [200/445] time 0.075 (0.088) data 0.000 (0.003) loss 2.0574 (2.1357) teacher_loss 0.7334 (0.8287) loss_zs_kd 1.6649 (1.6689) loss_oracle 0.8155 (0.8695) acc 71.8750 (72.1719) lr 2.2949e-04 eta 0:06:12
epoch [41/50] batch [220/445] time 0.087 (0.087) data 0.000 (0.003) loss 2.3748 (2.1289) teacher_loss 0.9254 (0.8214) loss_zs_kd 1.6453 (1.6630) loss_oracle 0.9471 (0.8683) acc 75.0000 (72.5568) lr 2.2949e-04 eta 0:06:07
epoch [41/50] batch [240/445] time 0.086 (0.087) data 0.000 (0.002) loss 2.3266 (2.1312) teacher_loss 1.0042 (0.8242) loss_zs_kd 1.7432 (1.6599) loss_oracle 0.8829 (0.8677) acc 65.6250 (72.4349) lr 2.2949e-04 eta 0:06:04
epoch [41/50] batch [260/445] time 0.086 (0.087) data 0.000 (0.002) loss 2.2222 (2.1307) teacher_loss 0.9433 (0.8249) loss_zs_kd 1.5968 (1.6584) loss_oracle 0.8543 (0.8679) acc 62.5000 (72.3438) lr 2.2949e-04 eta 0:06:02
epoch [41/50] batch [280/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.2921 (2.1285) teacher_loss 1.0297 (0.8237) loss_zs_kd 1.4003 (1.6673) loss_oracle 0.8403 (0.8676) acc 68.7500 (72.4219) lr 2.2949e-04 eta 0:06:00
epoch [41/50] batch [300/445] time 0.074 (0.086) data 0.000 (0.002) loss 1.9050 (2.1263) teacher_loss 0.6804 (0.8226) loss_zs_kd 2.1066 (1.6701) loss_oracle 0.8093 (0.8675) acc 78.1250 (72.3750) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [320/445] time 0.091 (0.086) data 0.000 (0.002) loss 2.2314 (2.1253) teacher_loss 0.9657 (0.8216) loss_zs_kd 1.7464 (1.6714) loss_oracle 0.9093 (0.8689) acc 62.5000 (72.4512) lr 2.2949e-04 eta 0:05:54
epoch [41/50] batch [340/445] time 0.086 (0.086) data 0.000 (0.002) loss 1.7376 (2.1254) teacher_loss 0.5340 (0.8221) loss_zs_kd 1.7946 (1.6723) loss_oracle 0.8037 (0.8687) acc 81.2500 (72.5000) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.1104 (2.1255) teacher_loss 0.8094 (0.8232) loss_zs_kd 1.4160 (1.6717) loss_oracle 0.8329 (0.8677) acc 78.1250 (72.4392) lr 2.2949e-04 eta 0:05:50
epoch [41/50] batch [380/445] time 0.090 (0.086) data 0.000 (0.002) loss 2.0612 (2.1260) teacher_loss 0.6452 (0.8232) loss_zs_kd 1.5295 (1.6700) loss_oracle 0.9273 (0.8674) acc 78.1250 (72.5411) lr 2.2949e-04 eta 0:05:48
epoch [41/50] batch [400/445] time 0.092 (0.086) data 0.000 (0.002) loss 2.2273 (2.1251) teacher_loss 0.9051 (0.8221) loss_zs_kd 1.2636 (1.6687) loss_oracle 0.8291 (0.8685) acc 65.6250 (72.5859) lr 2.2949e-04 eta 0:05:46
epoch [41/50] batch [420/445] time 0.080 (0.085) data 0.000 (0.002) loss 2.2308 (2.1252) teacher_loss 0.9162 (0.8215) loss_zs_kd 1.6715 (1.6731) loss_oracle 0.8684 (0.8691) acc 62.5000 (72.5372) lr 2.2949e-04 eta 0:05:44
epoch [41/50] batch [440/445] time 0.081 (0.085) data 0.000 (0.001) loss 2.4464 (2.1264) teacher_loss 1.1954 (0.8226) loss_zs_kd 1.6399 (1.6737) loss_oracle 0.8426 (0.8691) acc 62.5000 (72.4077) lr 2.2949e-04 eta 0:05:42
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,295
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,957
* accuracy: 49.3%
* error: 50.7%
* macro_f1: 30.5%
******* Domain 3 best val acc:      70.7%, epoch: 39 *******
******* Domain 3 best val test acc: 50.8%, epoch: 39 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [42/50] batch [20/445] time 0.080 (0.122) data 0.000 (0.035) loss 2.4095 (2.1393) teacher_loss 1.1741 (0.8249) loss_zs_kd 1.7599 (1.7345) loss_oracle 0.9427 (0.8644) acc 50.0000 (70.6250) lr 1.9098e-04 eta 0:08:05
epoch [42/50] batch [40/445] time 0.086 (0.104) data 0.000 (0.018) loss 2.2559 (2.1481) teacher_loss 0.9050 (0.8300) loss_zs_kd 1.3552 (1.7465) loss_oracle 0.8773 (0.8715) acc 68.7500 (71.0156) lr 1.9098e-04 eta 0:06:50
epoch [42/50] batch [60/445] time 0.091 (0.098) data 0.001 (0.012) loss 2.4659 (2.1564) teacher_loss 1.1468 (0.8495) loss_zs_kd 1.7209 (1.6942) loss_oracle 0.9067 (0.8707) acc 62.5000 (70.5208) lr 1.9098e-04 eta 0:06:25
epoch [42/50] batch [80/445] time 0.086 (0.094) data 0.000 (0.009) loss 2.3554 (2.1215) teacher_loss 1.0424 (0.8159) loss_zs_kd 1.5160 (1.6921) loss_oracle 0.8176 (0.8728) acc 65.6250 (72.2266) lr 1.9098e-04 eta 0:06:10
epoch [42/50] batch [100/445] time 0.083 (0.092) data 0.000 (0.007) loss 1.9978 (2.1107) teacher_loss 0.7068 (0.8095) loss_zs_kd 1.9347 (1.6790) loss_oracle 0.8695 (0.8714) acc 71.8750 (72.6562) lr 1.9098e-04 eta 0:05:59
epoch [42/50] batch [120/445] time 0.081 (0.090) data 0.000 (0.006) loss 1.7948 (2.1052) teacher_loss 0.5015 (0.8009) loss_zs_kd 1.8262 (1.6969) loss_oracle 0.7816 (0.8720) acc 87.5000 (72.6302) lr 1.9098e-04 eta 0:05:51
epoch [42/50] batch [140/445] time 0.079 (0.089) data 0.000 (0.005) loss 1.9798 (2.1098) teacher_loss 0.6501 (0.8010) loss_zs_kd 1.8990 (1.6978) loss_oracle 0.9108 (0.8762) acc 78.1250 (72.5223) lr 1.9098e-04 eta 0:05:43
epoch [42/50] batch [160/445] time 0.085 (0.088) data 0.000 (0.005) loss 2.1869 (2.1085) teacher_loss 0.8853 (0.8035) loss_zs_kd 1.5213 (1.7008) loss_oracle 0.9486 (0.8758) acc 68.7500 (72.5195) lr 1.9098e-04 eta 0:05:39
epoch [42/50] batch [180/445] time 0.083 (0.088) data 0.000 (0.004) loss 2.3340 (2.1061) teacher_loss 1.0423 (0.8026) loss_zs_kd 1.7978 (1.7068) loss_oracle 0.7812 (0.8742) acc 59.3750 (72.5174) lr 1.9098e-04 eta 0:05:35
epoch [42/50] batch [200/445] time 0.082 (0.087) data 0.000 (0.004) loss 1.9403 (2.1090) teacher_loss 0.6386 (0.8038) loss_zs_kd 1.6488 (1.7076) loss_oracle 0.8139 (0.8738) acc 81.2500 (72.6094) lr 1.9098e-04 eta 0:05:32
epoch [42/50] batch [220/445] time 0.089 (0.087) data 0.000 (0.003) loss 2.3157 (2.1123) teacher_loss 0.9520 (0.8065) loss_zs_kd 2.0884 (1.7080) loss_oracle 0.8127 (0.8750) acc 68.7500 (72.6420) lr 1.9098e-04 eta 0:05:30
epoch [42/50] batch [240/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.2404 (2.1130) teacher_loss 0.9611 (0.8096) loss_zs_kd 1.2199 (1.7034) loss_oracle 0.8339 (0.8747) acc 65.6250 (72.5781) lr 1.9098e-04 eta 0:05:27
epoch [42/50] batch [260/445] time 0.084 (0.087) data 0.000 (0.003) loss 1.9606 (2.1113) teacher_loss 0.5909 (0.8089) loss_zs_kd 1.3846 (1.7093) loss_oracle 0.9331 (0.8743) acc 81.2500 (72.4880) lr 1.9098e-04 eta 0:05:24
epoch [42/50] batch [280/445] time 0.073 (0.088) data 0.000 (0.003) loss 2.0198 (2.1139) teacher_loss 0.7886 (0.8100) loss_zs_kd 1.5233 (1.7115) loss_oracle 0.8321 (0.8747) acc 75.0000 (72.3214) lr 1.9098e-04 eta 0:05:26
epoch [42/50] batch [300/445] time 0.086 (0.087) data 0.000 (0.003) loss 1.8357 (2.1119) teacher_loss 0.5481 (0.8078) loss_zs_kd 1.4851 (1.7094) loss_oracle 0.8207 (0.8739) acc 81.2500 (72.3438) lr 1.9098e-04 eta 0:05:23
epoch [42/50] batch [320/445] time 0.079 (0.087) data 0.000 (0.002) loss 2.3166 (2.1183) teacher_loss 1.0371 (0.8128) loss_zs_kd 1.6489 (1.7058) loss_oracle 0.8593 (0.8741) acc 62.5000 (72.2168) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [340/445] time 0.086 (0.087) data 0.000 (0.002) loss 1.9304 (2.1191) teacher_loss 0.6469 (0.8128) loss_zs_kd 1.7812 (1.7058) loss_oracle 0.8008 (0.8755) acc 71.8750 (72.2335) lr 1.9098e-04 eta 0:05:17
epoch [42/50] batch [360/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.1363 (2.1195) teacher_loss 0.8534 (0.8117) loss_zs_kd 1.5175 (1.7090) loss_oracle 0.7949 (0.8761) acc 75.0000 (72.2309) lr 1.9098e-04 eta 0:05:15
epoch [42/50] batch [380/445] time 0.078 (0.086) data 0.000 (0.002) loss 2.1647 (2.1222) teacher_loss 0.8449 (0.8130) loss_zs_kd 1.5416 (1.7094) loss_oracle 0.8682 (0.8776) acc 71.8750 (72.1546) lr 1.9098e-04 eta 0:05:13
epoch [42/50] batch [400/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.0479 (2.1220) teacher_loss 0.8779 (0.8130) loss_zs_kd 1.2518 (1.7091) loss_oracle 0.8769 (0.8777) acc 81.2500 (72.2188) lr 1.9098e-04 eta 0:05:11
epoch [42/50] batch [420/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.5022 (2.1207) teacher_loss 1.2453 (0.8127) loss_zs_kd 1.4733 (1.7074) loss_oracle 0.8443 (0.8780) acc 59.3750 (72.2321) lr 1.9098e-04 eta 0:05:09
epoch [42/50] batch [440/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.1008 (2.1234) teacher_loss 0.7297 (0.8151) loss_zs_kd 1.6460 (1.7083) loss_oracle 0.8860 (0.8779) acc 75.0000 (72.1023) lr 1.9098e-04 eta 0:05:07
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,322
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 57.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,952
* accuracy: 49.2%
* error: 50.8%
* macro_f1: 30.4%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [43/50] batch [20/445] time 0.086 (0.135) data 0.000 (0.028) loss 2.4768 (2.0901) teacher_loss 1.1139 (0.7718) loss_zs_kd 2.0151 (1.6695) loss_oracle 0.8663 (0.8763) acc 62.5000 (73.7500) lr 1.5567e-04 eta 0:07:56
epoch [43/50] batch [40/445] time 0.081 (0.108) data 0.000 (0.014) loss 2.2165 (2.1326) teacher_loss 1.0054 (0.8176) loss_zs_kd 1.6173 (1.6613) loss_oracle 0.8384 (0.8831) acc 71.8750 (72.5000) lr 1.5567e-04 eta 0:06:18
epoch [43/50] batch [60/445] time 0.078 (0.099) data 0.001 (0.009) loss 2.0119 (2.1410) teacher_loss 0.7945 (0.8228) loss_zs_kd 1.7153 (1.7042) loss_oracle 0.8268 (0.8827) acc 71.8750 (72.8125) lr 1.5567e-04 eta 0:05:46
epoch [43/50] batch [80/445] time 0.086 (0.094) data 0.000 (0.007) loss 2.2600 (2.1391) teacher_loss 0.8602 (0.8231) loss_zs_kd 1.7662 (1.7250) loss_oracle 0.8741 (0.8854) acc 78.1250 (72.8125) lr 1.5567e-04 eta 0:05:28
epoch [43/50] batch [100/445] time 0.082 (0.091) data 0.000 (0.006) loss 2.5032 (2.1251) teacher_loss 1.2412 (0.8164) loss_zs_kd 1.6502 (1.7261) loss_oracle 0.8286 (0.8782) acc 50.0000 (73.1562) lr 1.5567e-04 eta 0:05:15
epoch [43/50] batch [120/445] time 0.084 (0.090) data 0.000 (0.005) loss 2.1136 (2.1287) teacher_loss 0.6995 (0.8187) loss_zs_kd 2.0307 (1.7255) loss_oracle 0.9656 (0.8776) acc 78.1250 (72.7865) lr 1.5567e-04 eta 0:05:08
epoch [43/50] batch [140/445] time 0.081 (0.089) data 0.000 (0.004) loss 2.0867 (2.1198) teacher_loss 0.7906 (0.8122) loss_zs_kd 1.3018 (1.7257) loss_oracle 0.8802 (0.8768) acc 71.8750 (73.0357) lr 1.5567e-04 eta 0:05:02
epoch [43/50] batch [160/445] time 0.085 (0.088) data 0.000 (0.004) loss 2.2790 (2.1105) teacher_loss 0.7619 (0.8019) loss_zs_kd 1.8759 (1.7404) loss_oracle 1.0324 (0.8786) acc 78.1250 (73.5156) lr 1.5567e-04 eta 0:04:58
epoch [43/50] batch [180/445] time 0.088 (0.088) data 0.000 (0.003) loss 1.9429 (2.1144) teacher_loss 0.6844 (0.8054) loss_zs_kd 1.8760 (1.7295) loss_oracle 0.8752 (0.8791) acc 81.2500 (73.5417) lr 1.5567e-04 eta 0:04:56
epoch [43/50] batch [200/445] time 0.078 (0.087) data 0.000 (0.003) loss 2.0604 (2.1179) teacher_loss 0.7655 (0.8066) loss_zs_kd 1.9858 (1.7311) loss_oracle 0.8949 (0.8796) acc 81.2500 (73.5469) lr 1.5567e-04 eta 0:04:53
epoch [43/50] batch [220/445] time 0.082 (0.087) data 0.000 (0.003) loss 2.4161 (2.1221) teacher_loss 1.0887 (0.8082) loss_zs_kd 1.7292 (1.7344) loss_oracle 0.8927 (0.8802) acc 50.0000 (73.3381) lr 1.5567e-04 eta 0:04:49
epoch [43/50] batch [240/445] time 0.081 (0.086) data 0.000 (0.003) loss 2.1333 (2.1232) teacher_loss 0.8653 (0.8091) loss_zs_kd 1.4024 (1.7443) loss_oracle 0.8229 (0.8799) acc 71.8750 (73.3203) lr 1.5567e-04 eta 0:04:45
epoch [43/50] batch [260/445] time 0.089 (0.086) data 0.000 (0.002) loss 1.7867 (2.1213) teacher_loss 0.4859 (0.8061) loss_zs_kd 1.6273 (1.7450) loss_oracle 0.8331 (0.8819) acc 87.5000 (73.4014) lr 1.5567e-04 eta 0:04:43
epoch [43/50] batch [280/445] time 0.086 (0.086) data 0.001 (0.002) loss 2.0595 (2.1211) teacher_loss 0.8023 (0.8047) loss_zs_kd 1.6049 (1.7488) loss_oracle 0.9375 (0.8827) acc 71.8750 (73.4152) lr 1.5567e-04 eta 0:04:41
epoch [43/50] batch [300/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.7274 (2.1202) teacher_loss 1.2983 (0.8014) loss_zs_kd 1.8544 (1.7510) loss_oracle 0.9369 (0.8846) acc 62.5000 (73.5104) lr 1.5567e-04 eta 0:04:39
epoch [43/50] batch [320/445] time 0.081 (0.086) data 0.000 (0.002) loss 2.7469 (2.1231) teacher_loss 1.3008 (0.8028) loss_zs_kd 2.0897 (1.7471) loss_oracle 0.9247 (0.8856) acc 68.7500 (73.4180) lr 1.5567e-04 eta 0:04:37
epoch [43/50] batch [340/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.2389 (2.1280) teacher_loss 0.8631 (0.8066) loss_zs_kd 1.9751 (1.7459) loss_oracle 0.9042 (0.8850) acc 78.1250 (73.3640) lr 1.5567e-04 eta 0:04:34
epoch [43/50] batch [360/445] time 0.079 (0.085) data 0.000 (0.002) loss 2.0776 (2.1288) teacher_loss 0.6924 (0.8060) loss_zs_kd 1.8602 (1.7487) loss_oracle 0.9558 (0.8856) acc 71.8750 (73.3507) lr 1.5567e-04 eta 0:04:31
epoch [43/50] batch [380/445] time 0.073 (0.084) data 0.000 (0.002) loss 2.1148 (2.1294) teacher_loss 0.6959 (0.8062) loss_zs_kd 2.1123 (1.7437) loss_oracle 0.9646 (0.8862) acc 78.1250 (73.3470) lr 1.5567e-04 eta 0:04:28
epoch [43/50] batch [400/445] time 0.075 (0.084) data 0.000 (0.002) loss 2.2681 (2.1293) teacher_loss 0.9861 (0.8049) loss_zs_kd 1.6743 (1.7478) loss_oracle 0.9636 (0.8873) acc 71.8750 (73.3906) lr 1.5567e-04 eta 0:04:25
epoch [43/50] batch [420/445] time 0.075 (0.085) data 0.000 (0.002) loss 2.1581 (2.1309) teacher_loss 0.8266 (0.8055) loss_zs_kd 1.9890 (1.7505) loss_oracle 0.8442 (0.8880) acc 71.8750 (73.3929) lr 1.5567e-04 eta 0:04:25
epoch [43/50] batch [440/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.1925 (2.1301) teacher_loss 0.7769 (0.8045) loss_zs_kd 1.4269 (1.7498) loss_oracle 0.8466 (0.8873) acc 75.0000 (73.4588) lr 1.5567e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,283
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 57.0%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,913
* accuracy: 48.2%
* error: 51.8%
* macro_f1: 30.2%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [44/50] batch [20/445] time 0.087 (0.104) data 0.000 (0.024) loss 2.1402 (2.1800) teacher_loss 0.8288 (0.7763) loss_zs_kd 1.5704 (1.6212) loss_oracle 0.8826 (0.8943) acc 71.8750 (73.2812) lr 1.2369e-04 eta 0:05:22
epoch [44/50] batch [40/445] time 0.075 (0.092) data 0.000 (0.012) loss 2.2204 (2.2013) teacher_loss 0.7964 (0.8040) loss_zs_kd 1.9518 (1.6595) loss_oracle 0.9482 (0.8911) acc 71.8750 (72.9688) lr 1.2369e-04 eta 0:04:43
epoch [44/50] batch [60/445] time 0.078 (0.089) data 0.000 (0.008) loss 2.0252 (2.1880) teacher_loss 0.7133 (0.7944) loss_zs_kd 2.0884 (1.7003) loss_oracle 0.7985 (0.8889) acc 84.3750 (73.2292) lr 1.2369e-04 eta 0:04:31
epoch [44/50] batch [80/445] time 0.075 (0.086) data 0.000 (0.006) loss 2.3220 (2.1893) teacher_loss 0.9678 (0.8023) loss_zs_kd 1.2934 (1.7127) loss_oracle 0.8467 (0.8854) acc 62.5000 (73.3203) lr 1.2369e-04 eta 0:04:21
epoch [44/50] batch [100/445] time 0.081 (0.086) data 0.000 (0.005) loss 2.4696 (2.1842) teacher_loss 1.0019 (0.8033) loss_zs_kd 1.8855 (1.7181) loss_oracle 1.0053 (0.8858) acc 62.5000 (73.2812) lr 1.2369e-04 eta 0:04:18
epoch [44/50] batch [120/445] time 0.078 (0.085) data 0.000 (0.004) loss 2.1670 (2.1870) teacher_loss 0.7786 (0.8096) loss_zs_kd 1.8240 (1.7056) loss_oracle 0.8988 (0.8857) acc 71.8750 (72.7344) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [140/445] time 0.086 (0.085) data 0.000 (0.004) loss 2.2327 (2.1732) teacher_loss 0.8647 (0.8019) loss_zs_kd 1.6184 (1.7122) loss_oracle 0.9541 (0.8853) acc 75.0000 (73.1696) lr 1.2369e-04 eta 0:04:12
epoch [44/50] batch [160/445] time 0.116 (0.086) data 0.001 (0.003) loss 2.2909 (2.1743) teacher_loss 0.8087 (0.8019) loss_zs_kd 1.6014 (1.7120) loss_oracle 1.0171 (0.8845) acc 75.0000 (73.3594) lr 1.2369e-04 eta 0:04:13
epoch [44/50] batch [180/445] time 0.083 (0.085) data 0.000 (0.003) loss 2.1255 (2.1785) teacher_loss 0.7774 (0.8082) loss_zs_kd 1.8240 (1.7195) loss_oracle 0.9408 (0.8842) acc 71.8750 (73.0903) lr 1.2369e-04 eta 0:04:10
epoch [44/50] batch [200/445] time 0.088 (0.085) data 0.000 (0.003) loss 2.4486 (2.1803) teacher_loss 1.1906 (0.8095) loss_zs_kd 2.1374 (1.7330) loss_oracle 0.8767 (0.8873) acc 62.5000 (73.0469) lr 1.2369e-04 eta 0:04:08
epoch [44/50] batch [220/445] time 0.071 (0.085) data 0.000 (0.002) loss 2.2891 (2.1757) teacher_loss 0.8624 (0.8068) loss_zs_kd 1.3825 (1.7427) loss_oracle 0.8784 (0.8863) acc 68.7500 (73.0398) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [240/445] time 0.086 (0.085) data 0.000 (0.002) loss 1.9916 (2.1750) teacher_loss 0.5962 (0.8063) loss_zs_kd 1.5903 (1.7409) loss_oracle 0.9531 (0.8872) acc 81.2500 (73.0859) lr 1.2369e-04 eta 0:04:03
epoch [44/50] batch [260/445] time 0.085 (0.084) data 0.000 (0.002) loss 2.2869 (2.1772) teacher_loss 0.8721 (0.8069) loss_zs_kd 1.3256 (1.7400) loss_oracle 0.8781 (0.8867) acc 71.8750 (73.0168) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [280/445] time 0.080 (0.084) data 0.000 (0.002) loss 2.1859 (2.1770) teacher_loss 0.7487 (0.8076) loss_zs_kd 1.9658 (1.7425) loss_oracle 0.8348 (0.8867) acc 75.0000 (73.1138) lr 1.2369e-04 eta 0:03:59
epoch [44/50] batch [300/445] time 0.081 (0.084) data 0.000 (0.002) loss 2.3248 (2.1776) teacher_loss 0.7372 (0.8069) loss_zs_kd 1.4228 (1.7376) loss_oracle 0.8921 (0.8879) acc 71.8750 (73.0833) lr 1.2369e-04 eta 0:03:57
epoch [44/50] batch [320/445] time 0.084 (0.084) data 0.000 (0.002) loss 2.2262 (2.1789) teacher_loss 0.8486 (0.8071) loss_zs_kd 1.7848 (1.7369) loss_oracle 0.9374 (0.8881) acc 68.7500 (73.1348) lr 1.2369e-04 eta 0:03:56
epoch [44/50] batch [340/445] time 0.086 (0.085) data 0.000 (0.002) loss 2.1954 (2.1843) teacher_loss 0.7810 (0.8133) loss_zs_kd 1.6078 (1.7358) loss_oracle 0.8967 (0.8889) acc 65.6250 (72.9504) lr 1.2369e-04 eta 0:03:54
epoch [44/50] batch [360/445] time 0.080 (0.085) data 0.000 (0.002) loss 2.0846 (2.1830) teacher_loss 0.8119 (0.8135) loss_zs_kd 1.8945 (1.7361) loss_oracle 0.8149 (0.8877) acc 71.8750 (73.0122) lr 1.2369e-04 eta 0:03:53
epoch [44/50] batch [380/445] time 0.086 (0.085) data 0.000 (0.002) loss 2.1752 (2.1804) teacher_loss 0.7961 (0.8122) loss_zs_kd 2.2338 (1.7358) loss_oracle 0.8902 (0.8874) acc 78.1250 (72.9852) lr 1.2369e-04 eta 0:03:51
epoch [44/50] batch [400/445] time 0.083 (0.085) data 0.000 (0.001) loss 2.3928 (2.1755) teacher_loss 1.0756 (0.8084) loss_zs_kd 1.7374 (1.7394) loss_oracle 0.8837 (0.8879) acc 53.1250 (73.0859) lr 1.2369e-04 eta 0:03:49
epoch [44/50] batch [420/445] time 0.086 (0.085) data 0.000 (0.001) loss 1.7816 (2.1717) teacher_loss 0.5290 (0.8049) loss_zs_kd 1.4517 (1.7375) loss_oracle 0.8484 (0.8886) acc 81.2500 (73.2366) lr 1.2369e-04 eta 0:03:47
epoch [44/50] batch [440/445] time 0.077 (0.084) data 0.000 (0.001) loss 2.4838 (2.1739) teacher_loss 0.9287 (0.8056) loss_zs_kd 1.9200 (1.7407) loss_oracle 0.9603 (0.8888) acc 62.5000 (73.1818) lr 1.2369e-04 eta 0:03:45
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,276
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,914
* accuracy: 48.2%
* error: 51.8%
* macro_f1: 30.1%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [45/50] batch [20/445] time 0.078 (0.116) data 0.000 (0.027) loss 2.1307 (2.1836) teacher_loss 0.7036 (0.8250) loss_zs_kd 1.5821 (1.8067) loss_oracle 0.8967 (0.8967) acc 81.2500 (71.5625) lr 9.5173e-05 eta 0:05:06
epoch [45/50] batch [40/445] time 0.074 (0.096) data 0.000 (0.014) loss 2.4081 (2.1941) teacher_loss 1.0942 (0.8294) loss_zs_kd 1.8850 (1.8005) loss_oracle 0.8349 (0.8932) acc 65.6250 (72.8125) lr 9.5173e-05 eta 0:04:13
epoch [45/50] batch [60/445] time 0.087 (0.092) data 0.001 (0.009) loss 2.1348 (2.1835) teacher_loss 0.9008 (0.8153) loss_zs_kd 1.9141 (1.7935) loss_oracle 0.8604 (0.8903) acc 78.1250 (72.8125) lr 9.5173e-05 eta 0:04:00
epoch [45/50] batch [80/445] time 0.100 (0.089) data 0.000 (0.007) loss 2.0388 (2.1795) teacher_loss 0.6806 (0.8082) loss_zs_kd 1.5039 (1.7669) loss_oracle 0.9267 (0.8944) acc 75.0000 (72.9688) lr 9.5173e-05 eta 0:03:50
epoch [45/50] batch [100/445] time 0.085 (0.089) data 0.000 (0.006) loss 2.5788 (2.1714) teacher_loss 1.0850 (0.8051) loss_zs_kd 1.5496 (1.7542) loss_oracle 1.0338 (0.8958) acc 75.0000 (73.2188) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [120/445] time 0.084 (0.088) data 0.000 (0.005) loss 2.0727 (2.1821) teacher_loss 0.7012 (0.8126) loss_zs_kd 1.7307 (1.7458) loss_oracle 0.8231 (0.8944) acc 75.0000 (72.8906) lr 9.5173e-05 eta 0:03:44
epoch [45/50] batch [140/445] time 0.083 (0.088) data 0.000 (0.004) loss 1.9603 (2.1821) teacher_loss 0.5606 (0.8107) loss_zs_kd 1.8476 (1.7525) loss_oracle 0.8856 (0.8961) acc 78.1250 (72.6786) lr 9.5173e-05 eta 0:03:41
epoch [45/50] batch [160/445] time 0.083 (0.087) data 0.000 (0.004) loss 2.0570 (2.1787) teacher_loss 0.7169 (0.8098) loss_zs_kd 1.8253 (1.7559) loss_oracle 0.8307 (0.8952) acc 81.2500 (72.7344) lr 9.5173e-05 eta 0:03:39
epoch [45/50] batch [180/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.2008 (2.1788) teacher_loss 0.7117 (0.8064) loss_zs_kd 1.8628 (1.7560) loss_oracle 0.9071 (0.8949) acc 75.0000 (73.0382) lr 9.5173e-05 eta 0:03:36
epoch [45/50] batch [200/445] time 0.091 (0.086) data 0.000 (0.003) loss 2.2051 (2.1701) teacher_loss 0.8310 (0.7974) loss_zs_kd 2.1028 (1.7525) loss_oracle 0.9294 (0.8947) acc 75.0000 (73.3438) lr 9.5173e-05 eta 0:03:33
epoch [45/50] batch [220/445] time 0.079 (0.086) data 0.000 (0.003) loss 2.3461 (2.1715) teacher_loss 0.9928 (0.7996) loss_zs_kd 1.4767 (1.7561) loss_oracle 0.8682 (0.8943) acc 75.0000 (73.3807) lr 9.5173e-05 eta 0:03:31
epoch [45/50] batch [240/445] time 0.088 (0.086) data 0.000 (0.003) loss 2.2107 (2.1746) teacher_loss 0.8602 (0.8022) loss_zs_kd 1.6531 (1.7618) loss_oracle 0.8186 (0.8941) acc 68.7500 (73.2422) lr 9.5173e-05 eta 0:03:29
epoch [45/50] batch [260/445] time 0.088 (0.086) data 0.000 (0.002) loss 2.4610 (2.1742) teacher_loss 1.0833 (0.8034) loss_zs_kd 1.8837 (1.7632) loss_oracle 0.8348 (0.8948) acc 65.6250 (73.2212) lr 9.5173e-05 eta 0:03:27
epoch [45/50] batch [280/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.2299 (2.1688) teacher_loss 0.8081 (0.8005) loss_zs_kd 1.8314 (1.7652) loss_oracle 0.9741 (0.8940) acc 75.0000 (73.2254) lr 9.5173e-05 eta 0:03:25
epoch [45/50] batch [300/445] time 0.083 (0.087) data 0.000 (0.002) loss 2.2162 (2.1692) teacher_loss 0.8924 (0.8034) loss_zs_kd 1.6612 (1.7623) loss_oracle 0.8245 (0.8937) acc 71.8750 (73.0833) lr 9.5173e-05 eta 0:03:25
epoch [45/50] batch [320/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.1731 (2.1734) teacher_loss 0.8515 (0.8103) loss_zs_kd 1.6781 (1.7666) loss_oracle 0.8228 (0.8922) acc 71.8750 (72.7344) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [340/445] time 0.072 (0.086) data 0.000 (0.002) loss 2.1532 (2.1696) teacher_loss 0.6940 (0.8076) loss_zs_kd 1.9784 (1.7667) loss_oracle 0.9883 (0.8927) acc 84.3750 (72.9688) lr 9.5173e-05 eta 0:03:21
epoch [45/50] batch [360/445] time 0.077 (0.086) data 0.000 (0.002) loss 2.0239 (2.1644) teacher_loss 0.7365 (0.8050) loss_zs_kd 2.0891 (1.7639) loss_oracle 0.8781 (0.8923) acc 75.0000 (73.0382) lr 9.5173e-05 eta 0:03:18
epoch [45/50] batch [380/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.2002 (2.1626) teacher_loss 0.7844 (0.8047) loss_zs_kd 1.6787 (1.7636) loss_oracle 0.9402 (0.8921) acc 71.8750 (73.0263) lr 9.5173e-05 eta 0:03:16
epoch [45/50] batch [400/445] time 0.074 (0.085) data 0.000 (0.002) loss 2.0718 (2.1616) teacher_loss 0.6912 (0.8045) loss_zs_kd 1.7905 (1.7625) loss_oracle 0.9305 (0.8924) acc 78.1250 (72.9766) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [420/445] time 0.085 (0.085) data 0.000 (0.002) loss 2.2317 (2.1627) teacher_loss 0.9717 (0.8068) loss_zs_kd 1.9536 (1.7625) loss_oracle 0.8300 (0.8925) acc 62.5000 (72.8943) lr 9.5173e-05 eta 0:03:12
epoch [45/50] batch [440/445] time 0.076 (0.085) data 0.000 (0.001) loss 2.5590 (2.1625) teacher_loss 1.1645 (0.8087) loss_zs_kd 1.9767 (1.7667) loss_oracle 0.9489 (0.8922) acc 59.3750 (72.7912) lr 9.5173e-05 eta 0:03:09
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,296
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,938
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 30.4%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [46/50] batch [20/445] time 0.085 (0.117) data 0.000 (0.026) loss 2.0748 (2.1501) teacher_loss 0.7576 (0.8236) loss_zs_kd 2.1632 (1.7894) loss_oracle 0.8997 (0.8923) acc 75.0000 (73.4375) lr 7.0224e-05 eta 0:04:17
epoch [46/50] batch [40/445] time 0.087 (0.105) data 0.001 (0.013) loss 2.0403 (2.1295) teacher_loss 0.7789 (0.8122) loss_zs_kd 1.6126 (1.7401) loss_oracle 0.8672 (0.8901) acc 78.1250 (73.4375) lr 7.0224e-05 eta 0:03:50
epoch [46/50] batch [60/445] time 0.060 (0.095) data 0.000 (0.009) loss 2.0279 (2.1189) teacher_loss 0.6747 (0.8035) loss_zs_kd 1.7869 (1.7709) loss_oracle 0.9656 (0.8900) acc 71.8750 (73.2812) lr 7.0224e-05 eta 0:03:26
epoch [46/50] batch [80/445] time 0.071 (0.088) data 0.000 (0.007) loss 2.0854 (2.1024) teacher_loss 0.8231 (0.7861) loss_zs_kd 1.8077 (1.7486) loss_oracle 0.8611 (0.8871) acc 71.8750 (73.9453) lr 7.0224e-05 eta 0:03:08
epoch [46/50] batch [100/445] time 0.079 (0.084) data 0.000 (0.005) loss 2.0064 (2.1127) teacher_loss 0.7011 (0.7938) loss_zs_kd 1.8570 (1.7410) loss_oracle 0.8796 (0.8864) acc 75.0000 (73.7812) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [120/445] time 0.076 (0.083) data 0.000 (0.005) loss 2.4250 (2.1232) teacher_loss 1.1148 (0.8024) loss_zs_kd 1.8184 (1.7429) loss_oracle 0.9485 (0.8881) acc 59.3750 (73.2292) lr 7.0224e-05 eta 0:02:55
epoch [46/50] batch [140/445] time 0.084 (0.083) data 0.000 (0.004) loss 2.3391 (2.1209) teacher_loss 0.9826 (0.8041) loss_zs_kd 1.8533 (1.7284) loss_oracle 0.8089 (0.8842) acc 59.3750 (73.1920) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [160/445] time 0.084 (0.084) data 0.000 (0.003) loss 2.7027 (2.1316) teacher_loss 1.2640 (0.8119) loss_zs_kd 1.6741 (1.7253) loss_oracle 0.9860 (0.8871) acc 59.3750 (72.6953) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [180/445] time 0.081 (0.084) data 0.000 (0.003) loss 2.3604 (2.1390) teacher_loss 1.1035 (0.8189) loss_zs_kd 1.4819 (1.7213) loss_oracle 0.8104 (0.8862) acc 56.2500 (72.4132) lr 7.0224e-05 eta 0:02:51
epoch [46/50] batch [200/445] time 0.084 (0.083) data 0.000 (0.003) loss 1.9221 (2.1406) teacher_loss 0.6213 (0.8193) loss_zs_kd 1.5848 (1.7151) loss_oracle 0.8506 (0.8869) acc 90.6250 (72.4844) lr 7.0224e-05 eta 0:02:48
epoch [46/50] batch [220/445] time 0.077 (0.083) data 0.000 (0.003) loss 2.3353 (2.1473) teacher_loss 1.0019 (0.8243) loss_zs_kd 1.7847 (1.7241) loss_oracle 0.9153 (0.8885) acc 65.6250 (72.4148) lr 7.0224e-05 eta 0:02:46
epoch [46/50] batch [240/445] time 0.082 (0.083) data 0.000 (0.002) loss 2.1954 (2.1428) teacher_loss 0.7880 (0.8200) loss_zs_kd 1.7401 (1.7271) loss_oracle 0.9875 (0.8885) acc 71.8750 (72.6172) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [260/445] time 0.074 (0.083) data 0.000 (0.002) loss 2.2844 (2.1421) teacher_loss 0.9046 (0.8197) loss_zs_kd 1.7288 (1.7314) loss_oracle 0.8943 (0.8880) acc 68.7500 (72.5601) lr 7.0224e-05 eta 0:02:42
epoch [46/50] batch [280/445] time 0.083 (0.083) data 0.000 (0.002) loss 2.0185 (2.1371) teacher_loss 0.7153 (0.8150) loss_zs_kd 1.7684 (1.7305) loss_oracle 0.8132 (0.8870) acc 71.8750 (72.5781) lr 7.0224e-05 eta 0:02:40
epoch [46/50] batch [300/445] time 0.080 (0.082) data 0.000 (0.002) loss 2.1826 (2.1368) teacher_loss 0.8520 (0.8156) loss_zs_kd 1.6706 (1.7304) loss_oracle 0.8379 (0.8861) acc 65.6250 (72.5000) lr 7.0224e-05 eta 0:02:38
epoch [46/50] batch [320/445] time 0.090 (0.082) data 0.000 (0.002) loss 1.9083 (2.1327) teacher_loss 0.6495 (0.8113) loss_zs_kd 1.7796 (1.7289) loss_oracle 0.9414 (0.8862) acc 71.8750 (72.6465) lr 7.0224e-05 eta 0:02:36
epoch [46/50] batch [340/445] time 0.075 (0.082) data 0.000 (0.002) loss 2.1954 (2.1313) teacher_loss 0.8670 (0.8093) loss_zs_kd 1.6781 (1.7247) loss_oracle 0.8909 (0.8873) acc 71.8750 (72.8125) lr 7.0224e-05 eta 0:02:35
epoch [46/50] batch [360/445] time 0.084 (0.083) data 0.000 (0.002) loss 2.0033 (2.1336) teacher_loss 0.6599 (0.8116) loss_zs_kd 1.8971 (1.7240) loss_oracle 0.9055 (0.8872) acc 81.2500 (72.7257) lr 7.0224e-05 eta 0:02:33
epoch [46/50] batch [380/445] time 0.074 (0.082) data 0.000 (0.002) loss 2.1144 (2.1387) teacher_loss 0.7436 (0.8143) loss_zs_kd 1.7499 (1.7262) loss_oracle 0.8239 (0.8887) acc 78.1250 (72.6562) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [400/445] time 0.087 (0.083) data 0.000 (0.002) loss 2.0741 (2.1403) teacher_loss 0.6854 (0.8148) loss_zs_kd 2.0387 (1.7268) loss_oracle 0.9225 (0.8896) acc 78.1250 (72.5625) lr 7.0224e-05 eta 0:02:30
epoch [46/50] batch [420/445] time 0.083 (0.083) data 0.000 (0.002) loss 2.0914 (2.1394) teacher_loss 0.7574 (0.8145) loss_zs_kd 1.8378 (1.7240) loss_oracle 0.8744 (0.8898) acc 78.1250 (72.5149) lr 7.0224e-05 eta 0:02:29
epoch [46/50] batch [440/445] time 0.065 (0.083) data 0.000 (0.001) loss 2.1129 (2.1422) teacher_loss 0.8543 (0.8174) loss_zs_kd 1.6231 (1.7221) loss_oracle 0.9115 (0.8906) acc 71.8750 (72.4574) lr 7.0224e-05 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,304
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,967
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 30.8%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [47/50] batch [20/445] time 0.080 (0.125) data 0.001 (0.034) loss 2.3685 (2.0942) teacher_loss 1.0998 (0.7818) loss_zs_kd 2.0010 (1.7531) loss_oracle 0.8825 (0.8790) acc 65.6250 (74.0625) lr 4.8943e-05 eta 0:03:40
epoch [47/50] batch [40/445] time 0.086 (0.103) data 0.000 (0.017) loss 1.8235 (2.1121) teacher_loss 0.5717 (0.7943) loss_zs_kd 1.6961 (1.7160) loss_oracle 0.8408 (0.8860) acc 84.3750 (73.9844) lr 4.8943e-05 eta 0:02:59
epoch [47/50] batch [60/445] time 0.078 (0.096) data 0.001 (0.012) loss 2.1993 (2.1414) teacher_loss 0.8826 (0.8219) loss_zs_kd 1.5900 (1.7248) loss_oracle 0.8358 (0.8954) acc 62.5000 (72.8125) lr 4.8943e-05 eta 0:02:45
epoch [47/50] batch [80/445] time 0.083 (0.092) data 0.000 (0.009) loss 2.1290 (2.1068) teacher_loss 0.7463 (0.7874) loss_zs_kd 1.7894 (1.7304) loss_oracle 0.9753 (0.8908) acc 75.0000 (73.9844) lr 4.8943e-05 eta 0:02:36
epoch [47/50] batch [100/445] time 0.076 (0.090) data 0.000 (0.007) loss 2.0722 (2.1074) teacher_loss 0.8107 (0.7887) loss_zs_kd 1.3313 (1.7213) loss_oracle 0.8873 (0.8898) acc 68.7500 (74.0000) lr 4.8943e-05 eta 0:02:30
epoch [47/50] batch [120/445] time 0.080 (0.088) data 0.000 (0.006) loss 2.0576 (2.1250) teacher_loss 0.7698 (0.8064) loss_zs_kd 1.7190 (1.7139) loss_oracle 0.9098 (0.8921) acc 78.1250 (73.3594) lr 4.8943e-05 eta 0:02:25
epoch [47/50] batch [140/445] time 0.084 (0.087) data 0.000 (0.005) loss 2.2349 (2.1311) teacher_loss 0.8687 (0.8094) loss_zs_kd 1.7080 (1.7207) loss_oracle 0.8379 (0.8939) acc 75.0000 (73.1473) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [160/445] time 0.079 (0.087) data 0.000 (0.005) loss 2.2526 (2.1348) teacher_loss 0.9352 (0.8118) loss_zs_kd 1.4868 (1.7222) loss_oracle 0.9643 (0.8956) acc 65.6250 (73.1250) lr 4.8943e-05 eta 0:02:20
epoch [47/50] batch [180/445] time 0.065 (0.087) data 0.000 (0.004) loss 1.8577 (2.1307) teacher_loss 0.6182 (0.8093) loss_zs_kd 1.8253 (1.7137) loss_oracle 0.8593 (0.8939) acc 84.3750 (73.2465) lr 4.8943e-05 eta 0:02:18
epoch [47/50] batch [200/445] time 0.079 (0.086) data 0.000 (0.004) loss 2.5465 (2.1371) teacher_loss 1.1347 (0.8133) loss_zs_kd 1.6705 (1.7101) loss_oracle 0.9389 (0.8951) acc 59.3750 (73.0625) lr 4.8943e-05 eta 0:02:15
epoch [47/50] batch [220/445] time 0.079 (0.086) data 0.000 (0.003) loss 2.0876 (2.1337) teacher_loss 0.8837 (0.8103) loss_zs_kd 1.3523 (1.7101) loss_oracle 0.7900 (0.8945) acc 71.8750 (73.1960) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [240/445] time 0.063 (0.085) data 0.000 (0.003) loss 2.2449 (2.1342) teacher_loss 0.8954 (0.8133) loss_zs_kd 1.6303 (1.7082) loss_oracle 0.9141 (0.8947) acc 68.7500 (73.0339) lr 4.8943e-05 eta 0:02:10
epoch [47/50] batch [260/445] time 0.062 (0.083) data 0.000 (0.003) loss 2.2282 (2.1381) teacher_loss 0.8761 (0.8158) loss_zs_kd 1.9597 (1.7083) loss_oracle 0.8611 (0.8941) acc 62.5000 (72.9207) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [280/445] time 0.070 (0.082) data 0.000 (0.003) loss 1.9557 (2.1360) teacher_loss 0.6557 (0.8131) loss_zs_kd 1.6279 (1.7101) loss_oracle 0.8810 (0.8938) acc 84.3750 (72.9576) lr 4.8943e-05 eta 0:02:02
epoch [47/50] batch [300/445] time 0.065 (0.080) data 0.000 (0.003) loss 2.5501 (2.1409) teacher_loss 1.2736 (0.8178) loss_zs_kd 1.7765 (1.7122) loss_oracle 0.9204 (0.8942) acc 65.6250 (72.8125) lr 4.8943e-05 eta 0:01:58
epoch [47/50] batch [320/445] time 0.067 (0.079) data 0.000 (0.002) loss 2.1654 (2.1397) teacher_loss 0.8225 (0.8161) loss_zs_kd 1.5595 (1.7117) loss_oracle 0.9619 (0.8940) acc 75.0000 (72.8320) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [340/445] time 0.066 (0.078) data 0.000 (0.002) loss 2.5244 (2.1387) teacher_loss 1.0950 (0.8153) loss_zs_kd 1.8722 (1.7054) loss_oracle 0.9154 (0.8940) acc 68.7500 (72.7665) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [360/445] time 0.088 (0.079) data 0.000 (0.002) loss 1.9195 (2.1387) teacher_loss 0.7219 (0.8161) loss_zs_kd 1.7552 (1.7045) loss_oracle 0.8021 (0.8933) acc 84.3750 (72.7083) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [380/445] time 0.083 (0.079) data 0.000 (0.002) loss 2.1209 (2.1396) teacher_loss 0.7536 (0.8186) loss_zs_kd 1.7828 (1.7019) loss_oracle 0.9309 (0.8933) acc 75.0000 (72.6727) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [400/445] time 0.083 (0.079) data 0.000 (0.002) loss 2.1248 (2.1376) teacher_loss 0.8600 (0.8169) loss_zs_kd 1.8465 (1.7081) loss_oracle 0.9486 (0.8928) acc 78.1250 (72.7031) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [420/445] time 0.085 (0.080) data 0.000 (0.002) loss 2.1268 (2.1362) teacher_loss 0.8475 (0.8161) loss_zs_kd 2.2079 (1.7104) loss_oracle 0.8485 (0.8927) acc 65.6250 (72.6935) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [440/445] time 0.078 (0.080) data 0.000 (0.002) loss 1.7992 (2.1370) teacher_loss 0.6403 (0.8162) loss_zs_kd 1.9502 (1.7138) loss_oracle 0.8177 (0.8927) acc 78.1250 (72.5639) lr 4.8943e-05 eta 0:01:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,308
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,966
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 30.8%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [48/50] batch [20/445] time 0.089 (0.122) data 0.000 (0.031) loss 2.3076 (2.0723) teacher_loss 1.0101 (0.7667) loss_zs_kd 1.5553 (1.7139) loss_oracle 0.8400 (0.8775) acc 62.5000 (74.0625) lr 3.1417e-05 eta 0:02:39
epoch [48/50] batch [40/445] time 0.077 (0.102) data 0.000 (0.016) loss 2.5733 (2.1035) teacher_loss 1.1072 (0.7778) loss_zs_kd 2.1338 (1.7680) loss_oracle 0.9858 (0.8960) acc 59.3750 (73.2812) lr 3.1417e-05 eta 0:02:12
epoch [48/50] batch [60/445] time 0.082 (0.094) data 0.000 (0.010) loss 2.5746 (2.1163) teacher_loss 1.3845 (0.7953) loss_zs_kd 1.4501 (1.7389) loss_oracle 0.9273 (0.8929) acc 59.3750 (73.2812) lr 3.1417e-05 eta 0:02:00
epoch [48/50] batch [80/445] time 0.076 (0.092) data 0.000 (0.008) loss 1.9963 (2.1189) teacher_loss 0.8182 (0.8089) loss_zs_kd 1.9709 (1.7138) loss_oracle 0.8160 (0.8858) acc 68.7500 (72.6172) lr 3.1417e-05 eta 0:01:55
epoch [48/50] batch [100/445] time 0.080 (0.089) data 0.000 (0.006) loss 2.2173 (2.1225) teacher_loss 0.8369 (0.8131) loss_zs_kd 1.8279 (1.7149) loss_oracle 0.9215 (0.8856) acc 68.7500 (72.6875) lr 3.1417e-05 eta 0:01:50
epoch [48/50] batch [120/445] time 0.076 (0.088) data 0.000 (0.005) loss 2.2204 (2.1263) teacher_loss 0.8981 (0.8137) loss_zs_kd 1.5186 (1.7255) loss_oracle 0.9366 (0.8875) acc 56.2500 (72.5781) lr 3.1417e-05 eta 0:01:46
epoch [48/50] batch [140/445] time 0.087 (0.087) data 0.000 (0.005) loss 1.9110 (2.1294) teacher_loss 0.5600 (0.8132) loss_zs_kd 1.7632 (1.7239) loss_oracle 0.8615 (0.8872) acc 78.1250 (72.7455) lr 3.1417e-05 eta 0:01:44
epoch [48/50] batch [160/445] time 0.093 (0.087) data 0.000 (0.004) loss 2.3614 (2.1299) teacher_loss 1.0272 (0.8128) loss_zs_kd 1.7685 (1.7144) loss_oracle 0.8764 (0.8877) acc 62.5000 (72.5977) lr 3.1417e-05 eta 0:01:42
epoch [48/50] batch [180/445] time 0.090 (0.087) data 0.001 (0.004) loss 2.1219 (2.1336) teacher_loss 0.8734 (0.8183) loss_zs_kd 1.5871 (1.7132) loss_oracle 0.8893 (0.8873) acc 59.3750 (72.5868) lr 3.1417e-05 eta 0:01:40
epoch [48/50] batch [200/445] time 0.083 (0.086) data 0.000 (0.003) loss 2.1773 (2.1328) teacher_loss 0.7772 (0.8169) loss_zs_kd 1.7627 (1.7146) loss_oracle 0.9286 (0.8872) acc 75.0000 (72.6250) lr 3.1417e-05 eta 0:01:37
epoch [48/50] batch [220/445] time 0.082 (0.086) data 0.000 (0.003) loss 2.0772 (2.1282) teacher_loss 0.8020 (0.8143) loss_zs_kd 1.2557 (1.7145) loss_oracle 0.8105 (0.8866) acc 71.8750 (72.6420) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [240/445] time 0.085 (0.086) data 0.000 (0.003) loss 2.0356 (2.1280) teacher_loss 0.7267 (0.8134) loss_zs_kd 1.7659 (1.7125) loss_oracle 0.9127 (0.8865) acc 81.2500 (72.7344) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [260/445] time 0.080 (0.086) data 0.000 (0.003) loss 1.8841 (2.1228) teacher_loss 0.7075 (0.8094) loss_zs_kd 1.6308 (1.7112) loss_oracle 0.7946 (0.8854) acc 78.1250 (72.6562) lr 3.1417e-05 eta 0:01:32
epoch [48/50] batch [280/445] time 0.088 (0.086) data 0.000 (0.002) loss 2.6313 (2.1282) teacher_loss 1.2975 (0.8133) loss_zs_kd 1.7135 (1.7138) loss_oracle 0.8378 (0.8853) acc 56.2500 (72.5223) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [300/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.4647 (2.1298) teacher_loss 1.0891 (0.8147) loss_zs_kd 1.5428 (1.7125) loss_oracle 0.8942 (0.8847) acc 59.3750 (72.3438) lr 3.1417e-05 eta 0:01:28
epoch [48/50] batch [320/445] time 0.075 (0.085) data 0.000 (0.002) loss 2.0031 (2.1309) teacher_loss 0.7335 (0.8163) loss_zs_kd 1.6472 (1.7100) loss_oracle 0.8284 (0.8838) acc 71.8750 (72.2266) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [340/445] time 0.085 (0.087) data 0.000 (0.002) loss 1.9832 (2.1315) teacher_loss 0.8142 (0.8182) loss_zs_kd 1.1143 (1.7056) loss_oracle 0.8001 (0.8829) acc 78.1250 (72.1507) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [360/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.8874 (2.1351) teacher_loss 0.6967 (0.8201) loss_zs_kd 1.4230 (1.7053) loss_oracle 0.8609 (0.8837) acc 78.1250 (72.1875) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [380/445] time 0.081 (0.086) data 0.000 (0.002) loss 1.9614 (2.1358) teacher_loss 0.6358 (0.8208) loss_zs_kd 1.5821 (1.7033) loss_oracle 0.8755 (0.8849) acc 81.2500 (72.1628) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [400/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.0939 (2.1329) teacher_loss 0.7859 (0.8194) loss_zs_kd 1.8612 (1.7039) loss_oracle 0.9053 (0.8842) acc 65.6250 (72.2578) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [420/445] time 0.070 (0.086) data 0.000 (0.002) loss 1.8103 (2.1311) teacher_loss 0.5353 (0.8179) loss_zs_kd 1.9355 (1.7068) loss_oracle 0.8186 (0.8841) acc 81.2500 (72.2991) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [440/445] time 0.084 (0.086) data 0.000 (0.002) loss 2.1065 (2.1309) teacher_loss 0.7856 (0.8187) loss_zs_kd 2.2226 (1.7050) loss_oracle 0.9487 (0.8838) acc 78.1250 (72.3366) lr 3.1417e-05 eta 0:01:16
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,312
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 56.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,978
* accuracy: 49.8%
* error: 50.2%
* macro_f1: 30.8%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [49/50] batch [20/445] time 0.086 (0.122) data 0.000 (0.035) loss 2.5010 (2.1230) teacher_loss 1.1637 (0.7907) loss_zs_kd 1.8831 (1.6743) loss_oracle 0.8919 (0.8920) acc 62.5000 (73.7500) lr 1.7713e-05 eta 0:01:46
epoch [49/50] batch [40/445] time 0.083 (0.101) data 0.000 (0.017) loss 2.2065 (2.1496) teacher_loss 0.9026 (0.8331) loss_zs_kd 2.0075 (1.6964) loss_oracle 0.8615 (0.8902) acc 71.8750 (72.2656) lr 1.7713e-05 eta 0:01:26
epoch [49/50] batch [60/445] time 0.087 (0.096) data 0.001 (0.012) loss 2.1799 (2.1429) teacher_loss 0.8919 (0.8298) loss_zs_kd 1.6911 (1.6877) loss_oracle 0.8427 (0.8855) acc 71.8750 (71.6146) lr 1.7713e-05 eta 0:01:19
epoch [49/50] batch [80/445] time 0.080 (0.098) data 0.000 (0.009) loss 2.3736 (2.1495) teacher_loss 1.1264 (0.8324) loss_zs_kd 1.7051 (1.6842) loss_oracle 0.8055 (0.8874) acc 62.5000 (70.9766) lr 1.7713e-05 eta 0:01:19
epoch [49/50] batch [100/445] time 0.086 (0.095) data 0.000 (0.007) loss 2.0003 (2.1540) teacher_loss 0.6553 (0.8355) loss_zs_kd 1.6258 (1.6908) loss_oracle 0.9296 (0.8901) acc 78.1250 (70.8438) lr 1.7713e-05 eta 0:01:15
epoch [49/50] batch [120/445] time 0.074 (0.093) data 0.000 (0.006) loss 2.3392 (2.1560) teacher_loss 1.1129 (0.8426) loss_zs_kd 1.7657 (1.7020) loss_oracle 0.7839 (0.8843) acc 65.6250 (71.0938) lr 1.7713e-05 eta 0:01:11
epoch [49/50] batch [140/445] time 0.085 (0.091) data 0.000 (0.005) loss 2.1459 (2.1566) teacher_loss 0.7634 (0.8446) loss_zs_kd 1.5892 (1.7157) loss_oracle 0.9158 (0.8860) acc 81.2500 (71.2277) lr 1.7713e-05 eta 0:01:08
epoch [49/50] batch [160/445] time 0.093 (0.091) data 0.000 (0.005) loss 1.8052 (2.1516) teacher_loss 0.5661 (0.8397) loss_zs_kd 1.3942 (1.7134) loss_oracle 0.8060 (0.8867) acc 81.2500 (71.3867) lr 1.7713e-05 eta 0:01:06
epoch [49/50] batch [180/445] time 0.076 (0.090) data 0.000 (0.004) loss 1.9789 (2.1542) teacher_loss 0.6522 (0.8414) loss_zs_kd 1.6478 (1.7147) loss_oracle 0.8584 (0.8856) acc 75.0000 (71.4757) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [200/445] time 0.073 (0.089) data 0.000 (0.004) loss 2.0492 (2.1437) teacher_loss 0.7599 (0.8328) loss_zs_kd 1.4551 (1.7154) loss_oracle 0.8372 (0.8837) acc 65.6250 (71.6406) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [220/445] time 0.080 (0.089) data 0.000 (0.003) loss 1.9903 (2.1422) teacher_loss 0.7647 (0.8308) loss_zs_kd 1.8634 (1.7203) loss_oracle 0.8241 (0.8827) acc 81.2500 (71.7188) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [240/445] time 0.085 (0.088) data 0.000 (0.003) loss 2.1417 (2.1407) teacher_loss 0.8092 (0.8301) loss_zs_kd 1.6530 (1.7284) loss_oracle 0.8596 (0.8824) acc 65.6250 (71.8229) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [260/445] time 0.088 (0.088) data 0.000 (0.003) loss 1.9329 (2.1382) teacher_loss 0.7063 (0.8264) loss_zs_kd 1.8642 (1.7263) loss_oracle 0.7568 (0.8833) acc 81.2500 (72.0913) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [280/445] time 0.082 (0.088) data 0.000 (0.003) loss 2.0581 (2.1356) teacher_loss 0.7428 (0.8247) loss_zs_kd 1.3486 (1.7191) loss_oracle 0.9387 (0.8833) acc 75.0000 (72.1652) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [300/445] time 0.078 (0.087) data 0.000 (0.003) loss 1.8575 (2.1363) teacher_loss 0.6737 (0.8260) loss_zs_kd 1.7001 (1.7137) loss_oracle 0.8231 (0.8836) acc 75.0000 (72.0833) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [320/445] time 0.084 (0.087) data 0.000 (0.002) loss 2.1429 (2.1388) teacher_loss 0.8249 (0.8279) loss_zs_kd 1.7822 (1.7126) loss_oracle 0.9032 (0.8835) acc 65.6250 (71.9922) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [340/445] time 0.078 (0.086) data 0.000 (0.002) loss 1.9258 (2.1416) teacher_loss 0.7240 (0.8291) loss_zs_kd 2.1448 (1.7178) loss_oracle 0.8653 (0.8846) acc 75.0000 (71.9577) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [360/445] time 0.083 (0.086) data 0.000 (0.002) loss 1.7833 (2.1444) teacher_loss 0.4300 (0.8302) loss_zs_kd 1.8510 (1.7153) loss_oracle 0.9263 (0.8852) acc 87.5000 (71.9531) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [380/445] time 0.085 (0.086) data 0.000 (0.002) loss 1.7945 (2.1410) teacher_loss 0.4247 (0.8260) loss_zs_kd 1.8279 (1.7145) loss_oracle 0.9203 (0.8854) acc 93.7500 (72.0395) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [400/445] time 0.095 (0.086) data 0.000 (0.002) loss 2.3470 (2.1381) teacher_loss 1.1284 (0.8241) loss_zs_kd 1.7736 (1.7105) loss_oracle 0.8173 (0.8850) acc 62.5000 (72.0938) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [420/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.1506 (2.1352) teacher_loss 0.8299 (0.8218) loss_zs_kd 1.5452 (1.7111) loss_oracle 0.8734 (0.8845) acc 78.1250 (72.1949) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [440/445] time 0.085 (0.086) data 0.000 (0.002) loss 1.9948 (2.1325) teacher_loss 0.7013 (0.8193) loss_zs_kd 1.7904 (1.7117) loss_oracle 0.8802 (0.8852) acc 71.8750 (72.3153) lr 1.7713e-05 eta 0:00:38
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,320
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 56.9%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,976
* accuracy: 49.8%
* error: 50.2%
* macro_f1: 30.7%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
epoch [50/50] batch [20/445] time 0.084 (0.120) data 0.000 (0.035) loss 2.2494 (2.1061) teacher_loss 0.9186 (0.7923) loss_zs_kd 1.3794 (1.6487) loss_oracle 0.8186 (0.8761) acc 65.6250 (71.4062) lr 7.8853e-06 eta 0:00:50
epoch [50/50] batch [40/445] time 0.085 (0.100) data 0.000 (0.017) loss 2.3843 (2.1232) teacher_loss 1.1225 (0.8155) loss_zs_kd 1.4103 (1.6743) loss_oracle 0.8297 (0.8706) acc 53.1250 (71.6406) lr 7.8853e-06 eta 0:00:40
epoch [50/50] batch [60/445] time 0.081 (0.093) data 0.001 (0.012) loss 2.1952 (2.1377) teacher_loss 0.8614 (0.8209) loss_zs_kd 1.5925 (1.6945) loss_oracle 0.8580 (0.8769) acc 75.0000 (71.4583) lr 7.8853e-06 eta 0:00:35
epoch [50/50] batch [80/445] time 0.073 (0.091) data 0.000 (0.009) loss 2.2237 (2.1484) teacher_loss 0.8561 (0.8258) loss_zs_kd 1.8976 (1.6854) loss_oracle 0.9511 (0.8825) acc 75.0000 (71.4453) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [100/445] time 0.083 (0.090) data 0.000 (0.007) loss 2.2762 (2.1432) teacher_loss 0.8407 (0.8266) loss_zs_kd 1.8222 (1.6815) loss_oracle 0.9273 (0.8860) acc 65.6250 (71.7812) lr 7.8853e-06 eta 0:00:30
epoch [50/50] batch [120/445] time 0.081 (0.089) data 0.000 (0.006) loss 2.1202 (2.1472) teacher_loss 0.7450 (0.8325) loss_zs_kd 1.6820 (1.6817) loss_oracle 0.8734 (0.8827) acc 71.8750 (71.4323) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [140/445] time 0.081 (0.088) data 0.000 (0.005) loss 1.9085 (2.1455) teacher_loss 0.6200 (0.8279) loss_zs_kd 1.5105 (1.6765) loss_oracle 0.8697 (0.8832) acc 81.2500 (71.8973) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [160/445] time 0.088 (0.088) data 0.000 (0.005) loss 2.1422 (2.1414) teacher_loss 0.8153 (0.8271) loss_zs_kd 1.3821 (1.6920) loss_oracle 0.9028 (0.8823) acc 81.2500 (72.0508) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [180/445] time 0.075 (0.087) data 0.001 (0.004) loss 2.2817 (2.1407) teacher_loss 0.8620 (0.8249) loss_zs_kd 1.6234 (1.7017) loss_oracle 0.9534 (0.8818) acc 68.7500 (72.0660) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [200/445] time 0.086 (0.088) data 0.000 (0.004) loss 2.1988 (2.1395) teacher_loss 0.8797 (0.8243) loss_zs_kd 1.7690 (1.6888) loss_oracle 0.9346 (0.8825) acc 68.7500 (72.1406) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [220/445] time 0.077 (0.088) data 0.000 (0.003) loss 1.9800 (2.1387) teacher_loss 0.6616 (0.8242) loss_zs_kd 2.0489 (1.6972) loss_oracle 0.8992 (0.8836) acc 71.8750 (72.0597) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [240/445] time 0.083 (0.087) data 0.000 (0.003) loss 2.0969 (2.1376) teacher_loss 0.7811 (0.8211) loss_zs_kd 1.6763 (1.7025) loss_oracle 0.8953 (0.8840) acc 75.0000 (72.3177) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [260/445] time 0.085 (0.087) data 0.000 (0.003) loss 2.2317 (2.1406) teacher_loss 0.8634 (0.8248) loss_zs_kd 1.7237 (1.7012) loss_oracle 0.9046 (0.8846) acc 75.0000 (72.1274) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [280/445] time 0.083 (0.086) data 0.000 (0.003) loss 2.0125 (2.1371) teacher_loss 0.5719 (0.8208) loss_zs_kd 1.9383 (1.7060) loss_oracle 0.8614 (0.8846) acc 78.1250 (72.3996) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [300/445] time 0.082 (0.086) data 0.000 (0.003) loss 1.9955 (2.1388) teacher_loss 0.7204 (0.8221) loss_zs_kd 1.5949 (1.7104) loss_oracle 0.9070 (0.8836) acc 81.2500 (72.3021) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [320/445] time 0.082 (0.086) data 0.000 (0.002) loss 2.1444 (2.1370) teacher_loss 0.8260 (0.8204) loss_zs_kd 1.2453 (1.7079) loss_oracle 0.8943 (0.8836) acc 71.8750 (72.3145) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [340/445] time 0.081 (0.086) data 0.000 (0.002) loss 1.9897 (2.1374) teacher_loss 0.6897 (0.8202) loss_zs_kd 1.8285 (1.7084) loss_oracle 0.8375 (0.8842) acc 78.1250 (72.4540) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [360/445] time 0.089 (0.086) data 0.000 (0.002) loss 2.3160 (2.1409) teacher_loss 1.1207 (0.8242) loss_zs_kd 1.5387 (1.7093) loss_oracle 0.9311 (0.8851) acc 65.6250 (72.4306) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [380/445] time 0.088 (0.086) data 0.000 (0.002) loss 2.2012 (2.1463) teacher_loss 0.8998 (0.8302) loss_zs_kd 2.0439 (1.7131) loss_oracle 0.8472 (0.8851) acc 78.1250 (72.2862) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [400/445] time 0.087 (0.086) data 0.000 (0.002) loss 2.0674 (2.1473) teacher_loss 0.6852 (0.8305) loss_zs_kd 1.8046 (1.7190) loss_oracle 0.9319 (0.8860) acc 84.3750 (72.1797) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [420/445] time 0.083 (0.086) data 0.000 (0.002) loss 2.1523 (2.1430) teacher_loss 0.7886 (0.8269) loss_zs_kd 1.6173 (1.7185) loss_oracle 0.9674 (0.8854) acc 71.8750 (72.2917) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [440/445] time 0.068 (0.085) data 0.000 (0.002) loss 1.7230 (2.1387) teacher_loss 0.5234 (0.8223) loss_zs_kd 1.5425 (1.7167) loss_oracle 0.8855 (0.8849) acc 78.1250 (72.4716) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,311
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 56.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,978
* accuracy: 49.8%
* error: 50.2%
* macro_f1: 30.8%
******* Domain 3 best val acc:      70.8%, epoch: 42 *******
******* Domain 3 best val test acc: 49.2%, epoch: 42 *******
******* Domain 3 best test acc:     51.7%, epoch: 38 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:45:49

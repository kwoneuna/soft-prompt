Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_38', 'location_43']
Target     ['location_46']
# classes  10
# train_x  12,912
# val      5,535
# test     5,883
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/403] time 0.081 (0.139) data 0.000 (0.034) loss 3.1180 (3.0899) teacher_loss 2.2064 (2.1821) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0058 (0.0030) acc 34.3750 (32.1875) lr 1.0000e-05 eta 0:46:38
epoch [1/50] batch [40/403] time 0.078 (0.108) data 0.000 (0.017) loss 3.2448 (3.1319) teacher_loss 2.4283 (2.2298) loss_zs_kd 0.0027 (0.0007) loss_oracle 0.0218 (0.0081) acc 31.2500 (31.7969) lr 1.0000e-05 eta 0:36:02
epoch [1/50] batch [60/403] time 0.082 (0.099) data 0.000 (0.011) loss 3.1640 (3.1136) teacher_loss 2.3251 (2.2063) loss_zs_kd 0.0083 (0.0021) loss_oracle 0.0183 (0.0130) acc 18.7500 (32.7083) lr 1.0000e-05 eta 0:33:03
epoch [1/50] batch [80/403] time 0.092 (0.093) data 0.000 (0.009) loss 3.4363 (3.0848) teacher_loss 2.4683 (2.1758) loss_zs_kd 0.0179 (0.0044) loss_oracle 0.0121 (0.0134) acc 31.2500 (33.2812) lr 1.0000e-05 eta 0:31:14
epoch [1/50] batch [100/403] time 0.070 (0.090) data 0.000 (0.007) loss 3.4732 (3.0829) teacher_loss 2.4934 (2.1698) loss_zs_kd 0.0316 (0.0081) loss_oracle 0.0224 (0.0137) acc 25.0000 (33.2500) lr 1.0000e-05 eta 0:30:11
epoch [1/50] batch [120/403] time 0.087 (0.089) data 0.000 (0.006) loss 3.3425 (3.0658) teacher_loss 2.3225 (2.1514) loss_zs_kd 0.0571 (0.0140) loss_oracle 0.1828 (0.0205) acc 28.1250 (33.5417) lr 1.0000e-05 eta 0:29:40
epoch [1/50] batch [140/403] time 0.084 (0.088) data 0.000 (0.005) loss 2.9088 (3.0636) teacher_loss 1.5717 (2.1099) loss_zs_kd 0.1094 (0.0260) loss_oracle 0.6868 (0.0941) acc 56.2500 (34.4196) lr 1.0000e-05 eta 0:29:11
epoch [1/50] batch [160/403] time 0.094 (0.087) data 0.000 (0.004) loss 3.3588 (3.0452) teacher_loss 2.1212 (2.0676) loss_zs_kd 0.4260 (0.0538) loss_oracle 0.4985 (0.1369) acc 31.2500 (35.3906) lr 1.0000e-05 eta 0:28:53
epoch [1/50] batch [180/403] time 0.091 (0.086) data 0.000 (0.004) loss 3.1533 (3.0422) teacher_loss 1.6189 (2.0306) loss_zs_kd 0.6865 (0.0949) loss_oracle 0.9962 (0.1980) acc 46.8750 (36.1458) lr 1.0000e-05 eta 0:28:47
epoch [1/50] batch [200/403] time 0.076 (0.086) data 0.000 (0.004) loss 2.9575 (3.0518) teacher_loss 1.7221 (1.9972) loss_zs_kd 0.5586 (0.1396) loss_oracle 0.9023 (0.2735) acc 37.5000 (36.7188) lr 1.0000e-05 eta 0:28:36
epoch [1/50] batch [220/403] time 0.076 (0.086) data 0.001 (0.003) loss 2.8762 (3.0389) teacher_loss 1.5322 (1.9628) loss_zs_kd 0.6259 (0.1739) loss_oracle 0.8437 (0.3140) acc 43.7500 (37.3438) lr 1.0000e-05 eta 0:28:25
epoch [1/50] batch [240/403] time 0.079 (0.086) data 0.000 (0.003) loss 2.9570 (3.0390) teacher_loss 1.4947 (1.9369) loss_zs_kd 0.7889 (0.2083) loss_oracle 0.9272 (0.3605) acc 34.3750 (37.7865) lr 1.0000e-05 eta 0:28:25
epoch [1/50] batch [260/403] time 0.084 (0.085) data 0.000 (0.003) loss 3.5265 (3.0455) teacher_loss 2.0637 (1.9113) loss_zs_kd 0.7987 (0.2465) loss_oracle 0.9872 (0.4101) acc 34.3750 (38.1490) lr 1.0000e-05 eta 0:28:15
epoch [1/50] batch [280/403] time 0.077 (0.085) data 0.000 (0.003) loss 3.1771 (3.0544) teacher_loss 1.6492 (1.8952) loss_zs_kd 0.7888 (0.2798) loss_oracle 1.0503 (0.4498) acc 46.8750 (38.5826) lr 1.0000e-05 eta 0:28:04
epoch [1/50] batch [300/403] time 0.089 (0.084) data 0.001 (0.003) loss 3.3257 (3.0601) teacher_loss 1.8072 (1.8761) loss_zs_kd 0.4809 (0.3017) loss_oracle 0.9304 (0.4899) acc 37.5000 (39.0208) lr 1.0000e-05 eta 0:27:55
epoch [1/50] batch [320/403] time 0.084 (0.084) data 0.000 (0.002) loss 3.1112 (3.0688) teacher_loss 1.7901 (1.8703) loss_zs_kd 0.5391 (0.3093) loss_oracle 0.7150 (0.5112) acc 34.3750 (39.0918) lr 1.0000e-05 eta 0:27:53
epoch [1/50] batch [340/403] time 0.095 (0.084) data 0.000 (0.002) loss 2.9810 (3.0672) teacher_loss 1.3568 (1.8533) loss_zs_kd 0.7474 (0.3214) loss_oracle 1.0943 (0.5334) acc 53.1250 (39.4026) lr 1.0000e-05 eta 0:27:47
epoch [1/50] batch [360/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.7570 (3.0762) teacher_loss 1.5233 (1.8475) loss_zs_kd 0.5092 (0.3332) loss_oracle 0.6315 (0.5558) acc 43.7500 (39.5226) lr 1.0000e-05 eta 0:27:46
epoch [1/50] batch [380/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.7460 (3.0775) teacher_loss 1.3912 (1.8386) loss_zs_kd 0.4454 (0.3391) loss_oracle 0.8404 (0.5724) acc 46.8750 (39.6217) lr 1.0000e-05 eta 0:27:39
epoch [1/50] batch [400/403] time 0.072 (0.084) data 0.000 (0.002) loss 3.4060 (3.0806) teacher_loss 1.9040 (1.8281) loss_zs_kd 0.6594 (0.3488) loss_oracle 1.0053 (0.5931) acc 34.3750 (39.8203) lr 1.0000e-05 eta 0:27:29
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 2,539
* accuracy: 45.9%
* error: 54.1%
* macro_f1: 32.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,919
* accuracy: 32.6%
* error: 67.4%
* macro_f1: 23.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      45.9%, epoch: 1 *******
******* Domain 4 best val test acc: 32.6%, epoch: 1 *******
******* Domain 4 best test acc:     32.6%, epoch: 1 *******
epoch [2/50] batch [20/403] time 0.088 (0.120) data 0.000 (0.027) loss 2.7426 (3.0087) teacher_loss 1.1315 (1.4653) loss_zs_kd 1.4862 (0.9160) loss_oracle 1.0795 (1.0163) acc 65.6250 (50.0000) lr 2.0000e-03 eta 0:39:18
epoch [2/50] batch [40/403] time 0.080 (0.101) data 0.000 (0.014) loss 3.0064 (3.0008) teacher_loss 1.4212 (1.4409) loss_zs_kd 0.8127 (0.9696) loss_oracle 1.0695 (1.0364) acc 37.5000 (51.7188) lr 2.0000e-03 eta 0:33:14
epoch [2/50] batch [60/403] time 0.086 (0.095) data 0.000 (0.009) loss 2.7810 (2.9657) teacher_loss 1.2469 (1.4054) loss_zs_kd 0.5978 (0.8901) loss_oracle 1.0432 (1.0411) acc 59.3750 (52.2917) lr 2.0000e-03 eta 0:31:16
epoch [2/50] batch [80/403] time 0.075 (0.092) data 0.000 (0.007) loss 2.9256 (2.9607) teacher_loss 1.4041 (1.4068) loss_zs_kd 0.5722 (0.8203) loss_oracle 1.0147 (1.0382) acc 34.3750 (52.0312) lr 2.0000e-03 eta 0:30:08
epoch [2/50] batch [100/403] time 0.086 (0.091) data 0.000 (0.006) loss 3.6045 (2.9307) teacher_loss 2.1256 (1.3900) loss_zs_kd 0.6425 (0.8104) loss_oracle 0.9876 (1.0302) acc 28.1250 (52.4062) lr 2.0000e-03 eta 0:29:43
epoch [2/50] batch [120/403] time 0.080 (0.090) data 0.000 (0.005) loss 2.8037 (2.8798) teacher_loss 1.3545 (1.3558) loss_zs_kd 0.6699 (0.7786) loss_oracle 0.9628 (1.0204) acc 46.8750 (53.2552) lr 2.0000e-03 eta 0:29:18
epoch [2/50] batch [140/403] time 0.081 (0.089) data 0.000 (0.004) loss 2.5600 (2.8417) teacher_loss 1.1611 (1.3338) loss_zs_kd 0.5390 (0.7559) loss_oracle 0.9364 (1.0098) acc 53.1250 (54.0179) lr 2.0000e-03 eta 0:29:04
epoch [2/50] batch [160/403] time 0.090 (0.089) data 0.000 (0.004) loss 2.3266 (2.8045) teacher_loss 0.9431 (1.3126) loss_zs_kd 0.7141 (0.7353) loss_oracle 0.9117 (0.9989) acc 68.7500 (54.6094) lr 2.0000e-03 eta 0:28:53
epoch [2/50] batch [180/403] time 0.084 (0.088) data 0.000 (0.003) loss 2.3997 (2.7716) teacher_loss 1.0644 (1.2959) loss_zs_kd 0.5435 (0.7210) loss_oracle 0.8984 (0.9879) acc 53.1250 (55.2951) lr 2.0000e-03 eta 0:28:47
epoch [2/50] batch [200/403] time 0.087 (0.088) data 0.001 (0.003) loss 2.5484 (2.7410) teacher_loss 1.2560 (1.2817) loss_zs_kd 0.9197 (0.7126) loss_oracle 0.8643 (0.9767) acc 53.1250 (55.7812) lr 2.0000e-03 eta 0:28:39
epoch [2/50] batch [220/403] time 0.088 (0.088) data 0.000 (0.003) loss 2.5165 (2.7099) teacher_loss 1.2576 (1.2677) loss_zs_kd 0.6494 (0.7051) loss_oracle 0.8361 (0.9656) acc 62.5000 (56.2642) lr 2.0000e-03 eta 0:28:30
epoch [2/50] batch [240/403] time 0.083 (0.087) data 0.000 (0.003) loss 2.3215 (2.6819) teacher_loss 1.0822 (1.2564) loss_zs_kd 0.5244 (0.6957) loss_oracle 0.8349 (0.9549) acc 56.2500 (56.4453) lr 2.0000e-03 eta 0:28:23
epoch [2/50] batch [260/403] time 0.088 (0.087) data 0.000 (0.002) loss 2.3454 (2.6597) teacher_loss 1.1355 (1.2505) loss_zs_kd 0.6431 (0.6893) loss_oracle 0.8169 (0.9439) acc 62.5000 (56.6707) lr 2.0000e-03 eta 0:28:17
epoch [2/50] batch [280/403] time 0.080 (0.087) data 0.000 (0.002) loss 2.2114 (2.6378) teacher_loss 1.0295 (1.2449) loss_zs_kd 0.5915 (0.6837) loss_oracle 0.7815 (0.9331) acc 62.5000 (56.7969) lr 2.0000e-03 eta 0:28:13
epoch [2/50] batch [300/403] time 0.085 (0.087) data 0.001 (0.002) loss 2.0872 (2.6103) teacher_loss 0.9680 (1.2329) loss_zs_kd 0.8305 (0.6886) loss_oracle 0.7648 (0.9228) acc 68.7500 (57.1667) lr 2.0000e-03 eta 0:28:09
epoch [2/50] batch [320/403] time 0.088 (0.087) data 0.000 (0.002) loss 2.7407 (2.5891) teacher_loss 1.6562 (1.2267) loss_zs_kd 0.8287 (0.7017) loss_oracle 0.7479 (0.9133) acc 46.8750 (57.4316) lr 2.0000e-03 eta 0:28:06
epoch [2/50] batch [340/403] time 0.084 (0.087) data 0.000 (0.002) loss 2.4933 (2.5687) teacher_loss 1.3931 (1.2208) loss_zs_kd 0.4661 (0.6980) loss_oracle 0.7485 (0.9032) acc 53.1250 (57.5551) lr 2.0000e-03 eta 0:28:02
epoch [2/50] batch [360/403] time 0.086 (0.087) data 0.000 (0.002) loss 2.0646 (2.5510) teacher_loss 0.9944 (1.2175) loss_zs_kd 0.4323 (0.6915) loss_oracle 0.7179 (0.8932) acc 62.5000 (57.7083) lr 2.0000e-03 eta 0:28:02
epoch [2/50] batch [380/403] time 0.086 (0.088) data 0.000 (0.002) loss 2.0103 (2.5306) teacher_loss 0.9568 (1.2110) loss_zs_kd 0.6616 (0.6853) loss_oracle 0.7031 (0.8836) acc 62.5000 (57.9030) lr 2.0000e-03 eta 0:28:17
epoch [2/50] batch [400/403] time 0.084 (0.087) data 0.000 (0.002) loss 2.2338 (2.5106) teacher_loss 1.2143 (1.2047) loss_zs_kd 0.5163 (0.6809) loss_oracle 0.6901 (0.8742) acc 56.2500 (58.0938) lr 2.0000e-03 eta 0:28:10
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,306
* accuracy: 59.7%
* error: 40.3%
* macro_f1: 44.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,924
* accuracy: 32.7%
* error: 67.3%
* macro_f1: 25.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      59.7%, epoch: 2 *******
******* Domain 4 best val test acc: 32.7%, epoch: 2 *******
******* Domain 4 best test acc:     32.7%, epoch: 2 *******
epoch [3/50] batch [20/403] time 0.076 (0.121) data 0.000 (0.030) loss 2.1747 (2.0676) teacher_loss 1.1594 (1.0376) loss_zs_kd 0.7770 (0.6513) loss_oracle 0.6774 (0.6833) acc 62.5000 (63.4375) lr 1.9980e-03 eta 0:39:05
epoch [3/50] batch [40/403] time 0.076 (0.101) data 0.000 (0.015) loss 2.1189 (2.0814) teacher_loss 1.0960 (1.0560) loss_zs_kd 0.7027 (0.6297) loss_oracle 0.6670 (0.6778) acc 56.2500 (62.0312) lr 1.9980e-03 eta 0:32:36
epoch [3/50] batch [60/403] time 0.089 (0.096) data 0.001 (0.010) loss 1.7720 (2.0532) teacher_loss 0.7685 (1.0333) loss_zs_kd 0.4978 (0.6413) loss_oracle 0.6575 (0.6724) acc 68.7500 (62.7083) lr 1.9980e-03 eta 0:30:56
epoch [3/50] batch [80/403] time 0.088 (0.094) data 0.000 (0.008) loss 2.2241 (2.0446) teacher_loss 1.1797 (1.0294) loss_zs_kd 0.5451 (0.6465) loss_oracle 0.6481 (0.6677) acc 62.5000 (63.1641) lr 1.9980e-03 eta 0:30:07
epoch [3/50] batch [100/403] time 0.073 (0.092) data 0.000 (0.006) loss 1.8598 (2.0475) teacher_loss 0.8804 (1.0409) loss_zs_kd 0.5051 (0.6472) loss_oracle 0.6410 (0.6631) acc 75.0000 (63.2812) lr 1.9980e-03 eta 0:29:32
epoch [3/50] batch [120/403] time 0.086 (0.093) data 0.000 (0.005) loss 1.9904 (2.0493) teacher_loss 1.0023 (1.0495) loss_zs_kd 0.6677 (0.6430) loss_oracle 0.6334 (0.6587) acc 59.3750 (62.6823) lr 1.9980e-03 eta 0:29:39
epoch [3/50] batch [140/403] time 0.080 (0.091) data 0.000 (0.005) loss 1.6210 (2.0368) teacher_loss 0.6721 (1.0443) loss_zs_kd 0.7146 (0.6439) loss_oracle 0.6268 (0.6547) acc 71.8750 (62.9464) lr 1.9980e-03 eta 0:29:16
epoch [3/50] batch [160/403] time 0.076 (0.090) data 0.000 (0.004) loss 2.1232 (2.0355) teacher_loss 1.1775 (1.0479) loss_zs_kd 0.7171 (0.6428) loss_oracle 0.6224 (0.6510) acc 65.6250 (62.8516) lr 1.9980e-03 eta 0:28:52
epoch [3/50] batch [180/403] time 0.084 (0.089) data 0.000 (0.004) loss 2.0389 (2.0244) teacher_loss 1.1187 (1.0433) loss_zs_kd 0.7192 (0.6485) loss_oracle 0.6160 (0.6475) acc 59.3750 (62.9167) lr 1.9980e-03 eta 0:28:34
epoch [3/50] batch [200/403] time 0.089 (0.089) data 0.000 (0.003) loss 2.2126 (2.0256) teacher_loss 1.2967 (1.0489) loss_zs_kd 0.6546 (0.6496) loss_oracle 0.6112 (0.6443) acc 62.5000 (62.9844) lr 1.9980e-03 eta 0:28:26
epoch [3/50] batch [220/403] time 0.080 (0.089) data 0.000 (0.003) loss 1.8157 (2.0273) teacher_loss 0.9061 (1.0555) loss_zs_kd 0.6453 (0.6465) loss_oracle 0.6073 (0.6411) acc 62.5000 (62.5142) lr 1.9980e-03 eta 0:28:16
epoch [3/50] batch [240/403] time 0.079 (0.088) data 0.000 (0.003) loss 2.0216 (2.0255) teacher_loss 1.1271 (1.0583) loss_zs_kd 0.6362 (0.6453) loss_oracle 0.6036 (0.6381) acc 62.5000 (62.3047) lr 1.9980e-03 eta 0:28:02
epoch [3/50] batch [260/403] time 0.085 (0.088) data 0.000 (0.003) loss 2.2411 (2.0206) teacher_loss 1.3138 (1.0575) loss_zs_kd 0.5293 (0.6398) loss_oracle 0.6002 (0.6353) acc 46.8750 (62.2596) lr 1.9980e-03 eta 0:27:51
epoch [3/50] batch [280/403] time 0.090 (0.087) data 0.000 (0.002) loss 1.5041 (2.0079) teacher_loss 0.5472 (1.0484) loss_zs_kd 0.6097 (0.6385) loss_oracle 0.6237 (0.6327) acc 81.2500 (62.5558) lr 1.9980e-03 eta 0:27:46
epoch [3/50] batch [300/403] time 0.092 (0.087) data 0.000 (0.002) loss 2.0015 (2.0017) teacher_loss 1.0877 (1.0461) loss_zs_kd 0.7895 (0.6447) loss_oracle 0.5884 (0.6302) acc 65.6250 (62.5833) lr 1.9980e-03 eta 0:27:41
epoch [3/50] batch [320/403] time 0.085 (0.087) data 0.000 (0.002) loss 1.8061 (2.0008) teacher_loss 0.8926 (1.0485) loss_zs_kd 0.5511 (0.6489) loss_oracle 0.5908 (0.6280) acc 68.7500 (62.5684) lr 1.9980e-03 eta 0:27:31
epoch [3/50] batch [340/403] time 0.081 (0.087) data 0.000 (0.002) loss 1.8736 (1.9969) teacher_loss 0.9914 (1.0469) loss_zs_kd 0.7832 (0.6543) loss_oracle 0.5886 (0.6260) acc 62.5000 (62.6287) lr 1.9980e-03 eta 0:27:23
epoch [3/50] batch [360/403] time 0.080 (0.086) data 0.000 (0.002) loss 2.0130 (1.9934) teacher_loss 1.1218 (1.0461) loss_zs_kd 0.7436 (0.6564) loss_oracle 0.5870 (0.6239) acc 65.6250 (62.8733) lr 1.9980e-03 eta 0:27:19
epoch [3/50] batch [380/403] time 0.094 (0.086) data 0.000 (0.002) loss 1.9649 (1.9880) teacher_loss 1.1068 (1.0436) loss_zs_kd 0.6437 (0.6536) loss_oracle 0.5696 (0.6219) acc 56.2500 (62.9852) lr 1.9980e-03 eta 0:27:17
epoch [3/50] batch [400/403] time 0.078 (0.086) data 0.001 (0.002) loss 2.1270 (1.9828) teacher_loss 1.2346 (1.0409) loss_zs_kd 0.7954 (0.6563) loss_oracle 0.5826 (0.6206) acc 53.1250 (63.0703) lr 1.9980e-03 eta 0:27:07
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,351
* accuracy: 60.5%
* error: 39.5%
* macro_f1: 46.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,841
* accuracy: 31.3%
* error: 68.7%
* macro_f1: 23.2%
******* Domain 4 best val acc:      60.5%, epoch: 3 *******
******* Domain 4 best val test acc: 31.3%, epoch: 3 *******
******* Domain 4 best test acc:     32.7%, epoch: 2 *******
epoch [4/50] batch [20/403] time 0.084 (0.107) data 0.000 (0.025) loss 1.8492 (1.8688) teacher_loss 0.9089 (0.9576) loss_zs_kd 0.6080 (0.6907) loss_oracle 0.6102 (0.5994) acc 65.6250 (66.4062) lr 1.9921e-03 eta 0:33:38
epoch [4/50] batch [40/403] time 0.079 (0.094) data 0.000 (0.013) loss 1.9845 (1.9020) teacher_loss 1.0923 (0.9890) loss_zs_kd 0.7677 (0.7420) loss_oracle 0.5666 (0.5907) acc 59.3750 (65.3906) lr 1.9921e-03 eta 0:29:39
epoch [4/50] batch [60/403] time 0.082 (0.092) data 0.000 (0.009) loss 2.0131 (1.9255) teacher_loss 1.1448 (1.0155) loss_zs_kd 0.9814 (0.8041) loss_oracle 0.5781 (0.5877) acc 59.3750 (64.8958) lr 1.9921e-03 eta 0:28:49
epoch [4/50] batch [80/403] time 0.081 (0.089) data 0.000 (0.007) loss 1.5366 (1.9205) teacher_loss 0.6540 (1.0112) loss_zs_kd 0.9794 (0.8439) loss_oracle 0.5772 (0.5859) acc 81.2500 (65.1172) lr 1.9921e-03 eta 0:28:01
epoch [4/50] batch [100/403] time 0.087 (0.088) data 0.000 (0.005) loss 2.2238 (1.9415) teacher_loss 1.3457 (1.0302) loss_zs_kd 0.7296 (0.8307) loss_oracle 0.5759 (0.5846) acc 53.1250 (64.5000) lr 1.9921e-03 eta 0:27:36
epoch [4/50] batch [120/403] time 0.077 (0.087) data 0.000 (0.004) loss 2.0326 (1.9373) teacher_loss 1.1160 (1.0263) loss_zs_kd 0.7148 (0.8197) loss_oracle 0.5752 (0.5839) acc 68.7500 (64.7917) lr 1.9921e-03 eta 0:27:16
epoch [4/50] batch [140/403] time 0.072 (0.086) data 0.000 (0.004) loss 1.9625 (1.9360) teacher_loss 1.0187 (1.0283) loss_zs_kd 0.7544 (0.8147) loss_oracle 0.5741 (0.5840) acc 75.0000 (64.8438) lr 1.9921e-03 eta 0:26:55
epoch [4/50] batch [160/403] time 0.081 (0.085) data 0.000 (0.003) loss 2.0082 (1.9353) teacher_loss 1.1278 (1.0302) loss_zs_kd 0.5581 (0.7999) loss_oracle 0.5853 (0.5839) acc 65.6250 (64.8047) lr 1.9921e-03 eta 0:26:34
epoch [4/50] batch [180/403] time 0.082 (0.084) data 0.000 (0.003) loss 1.6852 (1.9358) teacher_loss 0.8359 (1.0325) loss_zs_kd 0.8796 (0.8023) loss_oracle 0.5723 (0.5828) acc 71.8750 (64.4792) lr 1.9921e-03 eta 0:26:20
epoch [4/50] batch [200/403] time 0.095 (0.084) data 0.000 (0.003) loss 1.8761 (1.9331) teacher_loss 1.0369 (1.0320) loss_zs_kd 0.6378 (0.7977) loss_oracle 0.5714 (0.5818) acc 62.5000 (64.3281) lr 1.9921e-03 eta 0:26:20
epoch [4/50] batch [220/403] time 0.086 (0.084) data 0.000 (0.003) loss 1.6666 (1.9245) teacher_loss 0.7706 (1.0236) loss_zs_kd 0.9291 (0.7949) loss_oracle 0.5557 (0.5811) acc 75.0000 (64.4176) lr 1.9921e-03 eta 0:26:19
epoch [4/50] batch [240/403] time 0.071 (0.084) data 0.000 (0.002) loss 1.8762 (1.9255) teacher_loss 1.0218 (1.0238) loss_zs_kd 0.9025 (0.7990) loss_oracle 0.5697 (0.5811) acc 65.6250 (64.3490) lr 1.9921e-03 eta 0:26:04
epoch [4/50] batch [260/403] time 0.084 (0.083) data 0.000 (0.002) loss 1.7551 (1.9180) teacher_loss 0.8251 (1.0164) loss_zs_kd 0.9752 (0.8095) loss_oracle 0.5691 (0.5807) acc 71.8750 (64.6394) lr 1.9921e-03 eta 0:25:59
epoch [4/50] batch [280/403] time 0.074 (0.085) data 0.000 (0.002) loss 2.2363 (1.9123) teacher_loss 1.2696 (1.0091) loss_zs_kd 1.0718 (0.8156) loss_oracle 0.5985 (0.5824) acc 62.5000 (64.9442) lr 1.9921e-03 eta 0:26:17
epoch [4/50] batch [300/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.3002 (1.9127) teacher_loss 1.3478 (1.0082) loss_zs_kd 0.8371 (0.8200) loss_oracle 0.6206 (0.5845) acc 37.5000 (64.8438) lr 1.9921e-03 eta 0:26:11
epoch [4/50] batch [320/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.7305 (1.9142) teacher_loss 0.8537 (1.0087) loss_zs_kd 0.6779 (0.8248) loss_oracle 0.5943 (0.5865) acc 75.0000 (64.7949) lr 1.9921e-03 eta 0:26:03
epoch [4/50] batch [340/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.2247 (1.9166) teacher_loss 1.2609 (1.0102) loss_zs_kd 0.9727 (0.8283) loss_oracle 0.6570 (0.5874) acc 68.7500 (64.6875) lr 1.9921e-03 eta 0:25:57
epoch [4/50] batch [360/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.1638 (1.9128) teacher_loss 1.1861 (1.0047) loss_zs_kd 1.0459 (0.8336) loss_oracle 0.6528 (0.5890) acc 62.5000 (64.9306) lr 1.9921e-03 eta 0:25:49
epoch [4/50] batch [380/403] time 0.089 (0.083) data 0.000 (0.002) loss 2.1270 (1.9168) teacher_loss 1.1309 (1.0063) loss_zs_kd 1.1983 (0.8428) loss_oracle 0.7306 (0.5923) acc 56.2500 (64.8931) lr 1.9921e-03 eta 0:25:47
epoch [4/50] batch [400/403] time 0.076 (0.083) data 0.000 (0.002) loss 2.4884 (1.9204) teacher_loss 1.5106 (1.0051) loss_zs_kd 0.7212 (0.8448) loss_oracle 0.7314 (0.5994) acc 46.8750 (65.0391) lr 1.9921e-03 eta 0:25:42
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,513
* accuracy: 63.5%
* error: 36.5%
* macro_f1: 50.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,011
* accuracy: 34.2%
* error: 65.8%
* macro_f1: 24.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      63.5%, epoch: 4 *******
******* Domain 4 best val test acc: 34.2%, epoch: 4 *******
******* Domain 4 best test acc:     34.2%, epoch: 4 *******
epoch [5/50] batch [20/403] time 0.080 (0.111) data 0.000 (0.030) loss 2.2296 (2.0547) teacher_loss 1.0297 (1.0229) loss_zs_kd 0.9702 (0.8212) loss_oracle 0.8326 (0.7570) acc 68.7500 (65.0000) lr 1.9823e-03 eta 0:34:22
epoch [5/50] batch [40/403] time 0.077 (0.102) data 0.000 (0.015) loss 2.3181 (2.0451) teacher_loss 1.1614 (0.9994) loss_zs_kd 0.9332 (0.8898) loss_oracle 0.8511 (0.7745) acc 46.8750 (64.9219) lr 1.9823e-03 eta 0:31:34
epoch [5/50] batch [60/403] time 0.081 (0.097) data 0.001 (0.010) loss 2.0106 (2.0314) teacher_loss 0.9083 (0.9813) loss_zs_kd 0.9218 (0.9286) loss_oracle 0.7779 (0.7808) acc 71.8750 (66.2500) lr 1.9823e-03 eta 0:29:44
epoch [5/50] batch [80/403] time 0.076 (0.093) data 0.000 (0.008) loss 1.9008 (2.0100) teacher_loss 0.8855 (0.9705) loss_zs_kd 1.1467 (0.9441) loss_oracle 0.6540 (0.7666) acc 65.6250 (66.9141) lr 1.9823e-03 eta 0:28:28
epoch [5/50] batch [100/403] time 0.082 (0.090) data 0.000 (0.006) loss 1.6770 (1.9930) teacher_loss 0.7959 (0.9670) loss_zs_kd 1.0822 (0.9730) loss_oracle 0.5845 (0.7481) acc 71.8750 (66.4688) lr 1.9823e-03 eta 0:27:48
epoch [5/50] batch [120/403] time 0.084 (0.089) data 0.001 (0.005) loss 2.0481 (1.9770) teacher_loss 1.1154 (0.9676) loss_zs_kd 0.8573 (0.9716) loss_oracle 0.6442 (0.7296) acc 62.5000 (66.3281) lr 1.9823e-03 eta 0:27:20
epoch [5/50] batch [140/403] time 0.080 (0.088) data 0.000 (0.005) loss 2.2071 (1.9769) teacher_loss 1.1789 (0.9756) loss_zs_kd 1.1269 (0.9686) loss_oracle 0.6396 (0.7155) acc 56.2500 (66.0938) lr 1.9823e-03 eta 0:27:07
epoch [5/50] batch [160/403] time 0.080 (0.088) data 0.000 (0.004) loss 2.2107 (1.9749) teacher_loss 1.2868 (0.9815) loss_zs_kd 0.9629 (0.9700) loss_oracle 0.6755 (0.7047) acc 53.1250 (65.9180) lr 1.9823e-03 eta 0:26:53
epoch [5/50] batch [180/403] time 0.085 (0.087) data 0.000 (0.004) loss 1.5964 (1.9626) teacher_loss 0.6592 (0.9775) loss_zs_kd 0.7934 (0.9616) loss_oracle 0.6312 (0.6977) acc 81.2500 (65.9722) lr 1.9823e-03 eta 0:26:44
epoch [5/50] batch [200/403] time 0.074 (0.087) data 0.000 (0.003) loss 2.0446 (1.9667) teacher_loss 1.0063 (0.9800) loss_zs_kd 0.7103 (0.9567) loss_oracle 0.6830 (0.6984) acc 75.0000 (65.5312) lr 1.9823e-03 eta 0:26:39
epoch [5/50] batch [220/403] time 0.086 (0.087) data 0.000 (0.003) loss 1.9519 (1.9615) teacher_loss 0.9126 (0.9760) loss_zs_kd 0.9457 (0.9586) loss_oracle 0.6685 (0.6954) acc 65.6250 (65.6676) lr 1.9823e-03 eta 0:26:29
epoch [5/50] batch [240/403] time 0.081 (0.086) data 0.000 (0.003) loss 1.9294 (1.9653) teacher_loss 0.8249 (0.9759) loss_zs_kd 1.1142 (0.9663) loss_oracle 0.6944 (0.6947) acc 71.8750 (65.5208) lr 1.9823e-03 eta 0:26:22
epoch [5/50] batch [260/403] time 0.076 (0.086) data 0.000 (0.003) loss 1.8637 (1.9669) teacher_loss 0.7650 (0.9696) loss_zs_kd 1.0532 (0.9725) loss_oracle 0.6554 (0.6936) acc 68.7500 (65.9495) lr 1.9823e-03 eta 0:26:08
epoch [5/50] batch [280/403] time 0.086 (0.086) data 0.000 (0.002) loss 1.8968 (1.9697) teacher_loss 0.7595 (0.9652) loss_zs_kd 1.2250 (0.9839) loss_oracle 0.7427 (0.6945) acc 71.8750 (66.1384) lr 1.9823e-03 eta 0:26:04
epoch [5/50] batch [300/403] time 0.078 (0.086) data 0.000 (0.002) loss 1.8552 (1.9678) teacher_loss 0.8353 (0.9579) loss_zs_kd 1.1097 (0.9905) loss_oracle 0.6931 (0.6954) acc 68.7500 (66.5417) lr 1.9823e-03 eta 0:26:01
epoch [5/50] batch [320/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.2001 (1.9668) teacher_loss 1.0933 (0.9573) loss_zs_kd 1.1928 (0.9987) loss_oracle 0.7242 (0.6943) acc 71.8750 (66.6309) lr 1.9823e-03 eta 0:25:56
epoch [5/50] batch [340/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.6099 (1.9671) teacher_loss 0.6404 (0.9576) loss_zs_kd 0.9026 (1.0064) loss_oracle 0.6896 (0.6954) acc 87.5000 (66.7463) lr 1.9823e-03 eta 0:25:55
epoch [5/50] batch [360/403] time 0.088 (0.085) data 0.000 (0.002) loss 2.2628 (1.9636) teacher_loss 1.1593 (0.9537) loss_zs_kd 0.8593 (1.0046) loss_oracle 0.6824 (0.6974) acc 59.3750 (66.9184) lr 1.9823e-03 eta 0:25:52
epoch [5/50] batch [380/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.9201 (1.9686) teacher_loss 0.7481 (0.9527) loss_zs_kd 1.1739 (1.0074) loss_oracle 0.7940 (0.7008) acc 75.0000 (66.9079) lr 1.9823e-03 eta 0:25:49
epoch [5/50] batch [400/403] time 0.077 (0.085) data 0.000 (0.002) loss 2.0031 (1.9752) teacher_loss 1.0406 (0.9523) loss_zs_kd 1.3166 (1.0166) loss_oracle 0.7053 (0.7017) acc 65.6250 (66.9844) lr 1.9823e-03 eta 0:25:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,620
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 51.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,926
* accuracy: 32.7%
* error: 67.3%
* macro_f1: 24.7%
******* Domain 4 best val acc:      65.4%, epoch: 5 *******
******* Domain 4 best val test acc: 32.7%, epoch: 5 *******
******* Domain 4 best test acc:     34.2%, epoch: 4 *******
epoch [6/50] batch [20/403] time 0.078 (0.111) data 0.000 (0.026) loss 1.8280 (2.0576) teacher_loss 0.6884 (0.8647) loss_zs_kd 1.1739 (1.2316) loss_oracle 0.8184 (0.8330) acc 71.8750 (69.2188) lr 1.9686e-03 eta 0:33:22
epoch [6/50] batch [40/403] time 0.080 (0.096) data 0.000 (0.013) loss 2.0019 (2.1092) teacher_loss 0.9325 (0.9065) loss_zs_kd 1.2051 (1.2379) loss_oracle 0.8080 (0.8248) acc 65.6250 (67.9688) lr 1.9686e-03 eta 0:28:50
epoch [6/50] batch [60/403] time 0.081 (0.089) data 0.001 (0.009) loss 2.8661 (2.2014) teacher_loss 1.2065 (0.9580) loss_zs_kd 1.0078 (1.1836) loss_oracle 1.1576 (0.8302) acc 59.3750 (65.8333) lr 1.9686e-03 eta 0:26:56
epoch [6/50] batch [80/403] time 0.070 (0.087) data 0.000 (0.007) loss 2.3163 (2.2687) teacher_loss 0.9765 (0.9589) loss_zs_kd 1.1039 (1.1839) loss_oracle 1.0025 (0.8654) acc 75.0000 (66.4062) lr 1.9686e-03 eta 0:26:02
epoch [6/50] batch [100/403] time 0.060 (0.083) data 0.000 (0.006) loss 1.9776 (2.2608) teacher_loss 0.8281 (0.9609) loss_zs_kd 1.2072 (1.1959) loss_oracle 0.7893 (0.8687) acc 75.0000 (66.5000) lr 1.9686e-03 eta 0:24:51
epoch [6/50] batch [120/403] time 0.085 (0.082) data 0.000 (0.005) loss 1.9659 (2.2491) teacher_loss 0.8216 (0.9716) loss_zs_kd 1.1983 (1.2042) loss_oracle 0.8543 (0.8553) acc 78.1250 (66.0156) lr 1.9686e-03 eta 0:24:42
epoch [6/50] batch [140/403] time 0.078 (0.082) data 0.000 (0.004) loss 2.4124 (2.2640) teacher_loss 0.9227 (0.9650) loss_zs_kd 1.1539 (1.1818) loss_oracle 0.9393 (0.8676) acc 62.5000 (66.2277) lr 1.9686e-03 eta 0:24:30
epoch [6/50] batch [160/403] time 0.079 (0.081) data 0.000 (0.004) loss 2.3797 (2.2654) teacher_loss 1.1189 (0.9663) loss_zs_kd 1.2005 (1.1712) loss_oracle 0.8256 (0.8655) acc 56.2500 (66.1523) lr 1.9686e-03 eta 0:24:17
epoch [6/50] batch [180/403] time 0.081 (0.081) data 0.000 (0.003) loss 2.5750 (2.2573) teacher_loss 1.2446 (0.9637) loss_zs_kd 1.1608 (1.1706) loss_oracle 1.0348 (0.8674) acc 59.3750 (66.3542) lr 1.9686e-03 eta 0:24:19
epoch [6/50] batch [200/403] time 0.083 (0.084) data 0.000 (0.003) loss 2.0845 (2.2390) teacher_loss 0.9879 (0.9557) loss_zs_kd 1.2584 (1.1611) loss_oracle 0.7892 (0.8647) acc 65.6250 (66.5156) lr 1.9686e-03 eta 0:25:00
epoch [6/50] batch [220/403] time 0.080 (0.084) data 0.000 (0.003) loss 2.2545 (2.2382) teacher_loss 0.7376 (0.9558) loss_zs_kd 1.1459 (1.1596) loss_oracle 1.1415 (0.8700) acc 71.8750 (66.5483) lr 1.9686e-03 eta 0:24:59
epoch [6/50] batch [240/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.3891 (2.2447) teacher_loss 1.0290 (0.9579) loss_zs_kd 1.0576 (1.1585) loss_oracle 0.8683 (0.8768) acc 59.3750 (66.3021) lr 1.9686e-03 eta 0:24:58
epoch [6/50] batch [260/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.2783 (2.2500) teacher_loss 1.1160 (0.9626) loss_zs_kd 0.9990 (1.1480) loss_oracle 0.8162 (0.8810) acc 62.5000 (65.9615) lr 1.9686e-03 eta 0:24:55
epoch [6/50] batch [280/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.4418 (2.2550) teacher_loss 1.0024 (0.9591) loss_zs_kd 1.2129 (1.1488) loss_oracle 1.0086 (0.8886) acc 53.1250 (65.9710) lr 1.9686e-03 eta 0:24:43
epoch [6/50] batch [300/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.1504 (2.2549) teacher_loss 0.8755 (0.9538) loss_zs_kd 1.1560 (1.1459) loss_oracle 0.9755 (0.8963) acc 62.5000 (66.3125) lr 1.9686e-03 eta 0:24:39
epoch [6/50] batch [320/403] time 0.085 (0.083) data 0.000 (0.002) loss 2.3184 (2.2524) teacher_loss 0.9155 (0.9546) loss_zs_kd 0.8999 (1.1353) loss_oracle 0.8759 (0.8939) acc 68.7500 (66.2207) lr 1.9686e-03 eta 0:24:40
epoch [6/50] batch [340/403] time 0.075 (0.083) data 0.000 (0.002) loss 1.6664 (2.2496) teacher_loss 0.5679 (0.9522) loss_zs_kd 1.4954 (1.1477) loss_oracle 0.7197 (0.8921) acc 81.2500 (66.3603) lr 1.9686e-03 eta 0:24:38
epoch [6/50] batch [360/403] time 0.077 (0.083) data 0.000 (0.002) loss 2.9835 (2.2550) teacher_loss 1.4711 (0.9558) loss_zs_kd 1.4419 (1.1565) loss_oracle 1.2197 (0.8952) acc 50.0000 (66.2674) lr 1.9686e-03 eta 0:24:31
epoch [6/50] batch [380/403] time 0.087 (0.083) data 0.000 (0.002) loss 2.3438 (2.2529) teacher_loss 1.0468 (0.9536) loss_zs_kd 1.1700 (1.1539) loss_oracle 0.9429 (0.9014) acc 75.0000 (66.4556) lr 1.9686e-03 eta 0:24:30
epoch [6/50] batch [400/403] time 0.068 (0.083) data 0.000 (0.002) loss 1.9333 (2.2501) teacher_loss 0.5591 (0.9530) loss_zs_kd 1.3585 (1.1575) loss_oracle 0.9713 (0.9029) acc 87.5000 (66.5625) lr 1.9686e-03 eta 0:24:24
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,443
* accuracy: 62.2%
* error: 37.8%
* macro_f1: 48.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,738
* accuracy: 29.5%
* error: 70.5%
* macro_f1: 21.6%
******* Domain 4 best val acc:      65.4%, epoch: 5 *******
******* Domain 4 best val test acc: 32.7%, epoch: 5 *******
******* Domain 4 best test acc:     34.2%, epoch: 4 *******
epoch [7/50] batch [20/403] time 0.082 (0.106) data 0.000 (0.027) loss 2.0876 (2.2977) teacher_loss 0.6760 (0.8865) loss_zs_kd 1.3688 (1.3316) loss_oracle 1.0680 (0.9920) acc 71.8750 (70.6250) lr 1.9511e-03 eta 0:31:23
epoch [7/50] batch [40/403] time 0.087 (0.093) data 0.000 (0.014) loss 2.1067 (2.2618) teacher_loss 0.8934 (0.8716) loss_zs_kd 1.1416 (1.2811) loss_oracle 0.8391 (0.9793) acc 68.7500 (71.4844) lr 1.9511e-03 eta 0:27:29
epoch [7/50] batch [60/403] time 0.085 (0.090) data 0.001 (0.009) loss 2.0365 (2.2455) teacher_loss 0.9157 (0.8986) loss_zs_kd 0.9725 (1.2479) loss_oracle 0.8172 (0.9595) acc 62.5000 (69.5312) lr 1.9511e-03 eta 0:26:33
epoch [7/50] batch [80/403] time 0.077 (0.086) data 0.000 (0.007) loss 2.0183 (2.2354) teacher_loss 0.8045 (0.9059) loss_zs_kd 1.1416 (1.2311) loss_oracle 0.9723 (0.9626) acc 75.0000 (68.8281) lr 1.9511e-03 eta 0:25:26
epoch [7/50] batch [100/403] time 0.074 (0.085) data 0.000 (0.006) loss 2.3886 (2.1982) teacher_loss 1.2477 (0.9082) loss_zs_kd 1.2941 (1.1972) loss_oracle 0.9750 (0.9389) acc 59.3750 (69.0000) lr 1.9511e-03 eta 0:24:58
epoch [7/50] batch [120/403] time 0.075 (0.085) data 0.000 (0.005) loss 2.3226 (2.1809) teacher_loss 1.1509 (0.9147) loss_zs_kd 1.2140 (1.1845) loss_oracle 1.0620 (0.9312) acc 65.6250 (68.7240) lr 1.9511e-03 eta 0:24:54
epoch [7/50] batch [140/403] time 0.086 (0.085) data 0.000 (0.004) loss 2.0426 (2.1618) teacher_loss 0.8746 (0.9195) loss_zs_kd 1.4110 (1.1911) loss_oracle 0.8797 (0.9221) acc 68.7500 (68.7277) lr 1.9511e-03 eta 0:24:56
epoch [7/50] batch [160/403] time 0.077 (0.085) data 0.000 (0.004) loss 1.8886 (2.1474) teacher_loss 0.6534 (0.9057) loss_zs_kd 1.2248 (1.1916) loss_oracle 0.7933 (0.9146) acc 75.0000 (69.0820) lr 1.9511e-03 eta 0:24:50
epoch [7/50] batch [180/403] time 0.079 (0.084) data 0.000 (0.003) loss 2.1790 (2.1427) teacher_loss 0.9048 (0.9035) loss_zs_kd 1.4090 (1.1951) loss_oracle 0.8533 (0.9085) acc 71.8750 (68.9236) lr 1.9511e-03 eta 0:24:37
epoch [7/50] batch [200/403] time 0.076 (0.084) data 0.000 (0.003) loss 1.6161 (2.1419) teacher_loss 0.4548 (0.9050) loss_zs_kd 1.0437 (1.1911) loss_oracle 0.9404 (0.9075) acc 90.6250 (68.9219) lr 1.9511e-03 eta 0:24:32
epoch [7/50] batch [220/403] time 0.082 (0.084) data 0.000 (0.003) loss 2.2473 (2.1459) teacher_loss 0.8662 (0.9043) loss_zs_kd 1.3554 (1.1977) loss_oracle 1.0567 (0.9164) acc 71.8750 (68.7784) lr 1.9511e-03 eta 0:24:28
epoch [7/50] batch [240/403] time 0.089 (0.084) data 0.000 (0.002) loss 2.1181 (2.1518) teacher_loss 0.8385 (0.9065) loss_zs_kd 1.5055 (1.1977) loss_oracle 1.0411 (0.9229) acc 56.2500 (68.5286) lr 1.9511e-03 eta 0:24:26
epoch [7/50] batch [260/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.2874 (2.1557) teacher_loss 0.9401 (0.9052) loss_zs_kd 1.2448 (1.1977) loss_oracle 1.0054 (0.9308) acc 65.6250 (68.5938) lr 1.9511e-03 eta 0:24:27
epoch [7/50] batch [280/403] time 0.088 (0.084) data 0.000 (0.002) loss 2.0956 (2.1578) teacher_loss 0.7580 (0.9004) loss_zs_kd 1.2231 (1.2062) loss_oracle 1.0761 (0.9400) acc 78.1250 (68.7054) lr 1.9511e-03 eta 0:24:26
epoch [7/50] batch [300/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.0147 (2.1605) teacher_loss 0.6933 (0.9025) loss_zs_kd 1.1235 (1.2081) loss_oracle 1.1520 (0.9447) acc 75.0000 (68.5625) lr 1.9511e-03 eta 0:24:27
epoch [7/50] batch [320/403] time 0.086 (0.084) data 0.000 (0.002) loss 2.1615 (2.1576) teacher_loss 0.8010 (0.8994) loss_zs_kd 1.2781 (1.2166) loss_oracle 0.9813 (0.9478) acc 75.0000 (68.6621) lr 1.9511e-03 eta 0:24:26
epoch [7/50] batch [340/403] time 0.086 (0.084) data 0.000 (0.002) loss 2.0959 (2.1548) teacher_loss 0.7684 (0.8967) loss_zs_kd 1.2064 (1.2191) loss_oracle 0.9992 (0.9477) acc 68.7500 (68.7684) lr 1.9511e-03 eta 0:24:26
epoch [7/50] batch [360/403] time 0.082 (0.085) data 0.000 (0.002) loss 2.4344 (2.1575) teacher_loss 1.2293 (0.8991) loss_zs_kd 1.1817 (1.2269) loss_oracle 0.8937 (0.9480) acc 65.6250 (68.6111) lr 1.9511e-03 eta 0:24:39
epoch [7/50] batch [380/403] time 0.103 (0.085) data 0.000 (0.002) loss 2.2018 (2.1569) teacher_loss 1.0449 (0.9001) loss_zs_kd 1.0683 (1.2281) loss_oracle 0.8037 (0.9475) acc 68.7500 (68.5033) lr 1.9511e-03 eta 0:24:36
epoch [7/50] batch [400/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.2501 (2.1556) teacher_loss 1.1550 (0.9039) loss_zs_kd 1.1245 (1.2280) loss_oracle 0.8983 (0.9453) acc 53.1250 (68.3516) lr 1.9511e-03 eta 0:24:31
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,738
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 51.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,155
* accuracy: 36.6%
* error: 63.4%
* macro_f1: 27.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      67.5%, epoch: 7 *******
******* Domain 4 best val test acc: 36.6%, epoch: 7 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [8/50] batch [20/403] time 0.090 (0.114) data 0.000 (0.026) loss 2.2856 (2.1173) teacher_loss 1.0736 (0.9714) loss_zs_kd 1.2469 (1.1752) loss_oracle 0.9511 (0.8993) acc 68.7500 (65.7812) lr 1.9298e-03 eta 0:32:56
epoch [8/50] batch [40/403] time 0.082 (0.097) data 0.000 (0.013) loss 1.9615 (2.1396) teacher_loss 0.8002 (0.9976) loss_zs_kd 1.0845 (1.1650) loss_oracle 0.9786 (0.8689) acc 71.8750 (65.4688) lr 1.9298e-03 eta 0:27:58
epoch [8/50] batch [60/403] time 0.079 (0.091) data 0.001 (0.009) loss 2.4085 (2.1199) teacher_loss 1.0980 (0.9621) loss_zs_kd 1.0146 (1.1212) loss_oracle 0.9659 (0.8845) acc 56.2500 (66.3542) lr 1.9298e-03 eta 0:26:18
epoch [8/50] batch [80/403] time 0.073 (0.089) data 0.000 (0.007) loss 2.4163 (2.1314) teacher_loss 1.0116 (0.9548) loss_zs_kd 1.3502 (1.1238) loss_oracle 0.9853 (0.9019) acc 65.6250 (66.7188) lr 1.9298e-03 eta 0:25:28
epoch [8/50] batch [100/403] time 0.118 (0.090) data 0.001 (0.005) loss 2.5228 (2.1347) teacher_loss 1.1359 (0.9455) loss_zs_kd 1.4419 (1.1436) loss_oracle 1.0632 (0.9130) acc 59.3750 (66.9688) lr 1.9298e-03 eta 0:25:53
epoch [8/50] batch [120/403] time 0.077 (0.089) data 0.000 (0.005) loss 2.1795 (2.1315) teacher_loss 0.9296 (0.9343) loss_zs_kd 1.2244 (1.1543) loss_oracle 0.9574 (0.9191) acc 68.7500 (67.6302) lr 1.9298e-03 eta 0:25:30
epoch [8/50] batch [140/403] time 0.076 (0.087) data 0.000 (0.004) loss 1.8520 (2.1277) teacher_loss 0.6667 (0.9246) loss_zs_kd 1.0206 (1.1589) loss_oracle 1.0182 (0.9228) acc 75.0000 (67.8795) lr 1.9298e-03 eta 0:25:00
epoch [8/50] batch [160/403] time 0.078 (0.086) data 0.000 (0.003) loss 2.0826 (2.1341) teacher_loss 0.8387 (0.9167) loss_zs_kd 1.3884 (1.1794) loss_oracle 0.9737 (0.9386) acc 71.8750 (68.0469) lr 1.9298e-03 eta 0:24:44
epoch [8/50] batch [180/403] time 0.070 (0.086) data 0.000 (0.003) loss 1.9649 (2.1404) teacher_loss 0.7139 (0.9151) loss_zs_kd 1.1154 (1.1857) loss_oracle 0.8960 (0.9483) acc 75.0000 (68.1250) lr 1.9298e-03 eta 0:24:29
epoch [8/50] batch [200/403] time 0.084 (0.086) data 0.000 (0.003) loss 2.3687 (2.1354) teacher_loss 0.9675 (0.9091) loss_zs_kd 0.9808 (1.1900) loss_oracle 1.0107 (0.9456) acc 62.5000 (68.3750) lr 1.9298e-03 eta 0:24:28
epoch [8/50] batch [220/403] time 0.078 (0.085) data 0.000 (0.003) loss 2.2277 (2.1322) teacher_loss 1.0088 (0.9055) loss_zs_kd 1.3631 (1.1957) loss_oracle 0.8740 (0.9404) acc 62.5000 (68.6506) lr 1.9298e-03 eta 0:24:18
epoch [8/50] batch [240/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.1763 (2.1370) teacher_loss 0.8564 (0.9029) loss_zs_kd 1.2955 (1.2116) loss_oracle 1.0047 (0.9447) acc 71.8750 (68.9453) lr 1.9298e-03 eta 0:24:15
epoch [8/50] batch [260/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.2213 (2.1372) teacher_loss 1.0202 (0.9080) loss_zs_kd 1.3668 (1.2073) loss_oracle 0.9844 (0.9441) acc 68.7500 (68.7380) lr 1.9298e-03 eta 0:24:14
epoch [8/50] batch [280/403] time 0.083 (0.085) data 0.000 (0.002) loss 1.9103 (2.1344) teacher_loss 0.7121 (0.9073) loss_zs_kd 1.4562 (1.2111) loss_oracle 0.9697 (0.9495) acc 71.8750 (68.6607) lr 1.9298e-03 eta 0:24:09
epoch [8/50] batch [300/403] time 0.087 (0.085) data 0.000 (0.002) loss 2.2555 (2.1344) teacher_loss 1.1449 (0.9084) loss_zs_kd 1.1274 (1.2237) loss_oracle 0.9709 (0.9555) acc 65.6250 (68.4583) lr 1.9298e-03 eta 0:24:08
epoch [8/50] batch [320/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.3196 (2.1324) teacher_loss 1.0988 (0.9077) loss_zs_kd 1.1349 (1.2170) loss_oracle 0.9794 (0.9542) acc 62.5000 (68.3887) lr 1.9298e-03 eta 0:24:06
epoch [8/50] batch [340/403] time 0.072 (0.085) data 0.000 (0.002) loss 2.2245 (2.1434) teacher_loss 0.7906 (0.9116) loss_zs_kd 1.2768 (1.2193) loss_oracle 0.9381 (0.9544) acc 68.7500 (68.1526) lr 1.9298e-03 eta 0:23:56
epoch [8/50] batch [360/403] time 0.079 (0.084) data 0.000 (0.002) loss 2.2985 (2.1552) teacher_loss 0.8727 (0.9133) loss_zs_kd 1.5135 (1.2206) loss_oracle 1.0647 (0.9570) acc 65.6250 (67.9688) lr 1.9298e-03 eta 0:23:48
epoch [8/50] batch [380/403] time 0.079 (0.084) data 0.000 (0.002) loss 2.3330 (2.1604) teacher_loss 0.9075 (0.9119) loss_zs_kd 1.3157 (1.2221) loss_oracle 1.0767 (0.9634) acc 62.5000 (67.9276) lr 1.9298e-03 eta 0:23:45
epoch [8/50] batch [400/403] time 0.069 (0.084) data 0.000 (0.002) loss 2.4070 (2.1637) teacher_loss 0.9494 (0.9081) loss_zs_kd 1.2317 (1.2305) loss_oracle 1.1440 (0.9682) acc 71.8750 (68.1719) lr 1.9298e-03 eta 0:23:38
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,800
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 54.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,082
* accuracy: 35.4%
* error: 64.6%
* macro_f1: 26.3%
******* Domain 4 best val acc:      68.7%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [9/50] batch [20/403] time 0.085 (0.122) data 0.000 (0.033) loss 2.1923 (2.2834) teacher_loss 0.6493 (0.7884) loss_zs_kd 1.2068 (1.5065) loss_oracle 1.0610 (1.1220) acc 81.2500 (75.3125) lr 1.9048e-03 eta 0:34:22
epoch [9/50] batch [40/403] time 0.082 (0.103) data 0.000 (0.017) loss 2.5765 (2.3578) teacher_loss 0.9553 (0.8554) loss_zs_kd 1.3855 (1.4567) loss_oracle 1.2651 (1.1369) acc 65.6250 (72.5000) lr 1.9048e-03 eta 0:28:54
epoch [9/50] batch [60/403] time 0.089 (0.096) data 0.000 (0.011) loss 2.3654 (2.3685) teacher_loss 0.8615 (0.8588) loss_zs_kd 1.4902 (1.4366) loss_oracle 1.1182 (1.1442) acc 65.6250 (71.4062) lr 1.9048e-03 eta 0:27:05
epoch [9/50] batch [80/403] time 0.069 (0.092) data 0.000 (0.008) loss 2.2184 (2.3679) teacher_loss 0.7811 (0.8625) loss_zs_kd 1.4619 (1.4261) loss_oracle 1.0605 (1.1388) acc 71.8750 (70.9766) lr 1.9048e-03 eta 0:25:55
epoch [9/50] batch [100/403] time 0.086 (0.089) data 0.000 (0.007) loss 2.5910 (2.3873) teacher_loss 0.8301 (0.8762) loss_zs_kd 1.8319 (1.4273) loss_oracle 1.2079 (1.1437) acc 59.3750 (69.9062) lr 1.9048e-03 eta 0:25:04
epoch [9/50] batch [120/403] time 0.091 (0.089) data 0.000 (0.006) loss 2.4181 (2.4245) teacher_loss 0.8334 (0.8971) loss_zs_kd 1.4477 (1.4321) loss_oracle 1.0653 (1.1446) acc 75.0000 (69.1667) lr 1.9048e-03 eta 0:24:50
epoch [9/50] batch [140/403] time 0.083 (0.088) data 0.000 (0.005) loss 2.0717 (2.4200) teacher_loss 0.6664 (0.8947) loss_zs_kd 1.5914 (1.4503) loss_oracle 1.0560 (1.1427) acc 81.2500 (69.2857) lr 1.9048e-03 eta 0:24:29
epoch [9/50] batch [160/403] time 0.080 (0.087) data 0.000 (0.004) loss 2.0838 (2.4149) teacher_loss 0.8198 (0.9009) loss_zs_kd 1.5923 (1.4668) loss_oracle 1.0298 (1.1362) acc 71.8750 (68.9844) lr 1.9048e-03 eta 0:24:16
epoch [9/50] batch [180/403] time 0.094 (0.087) data 0.000 (0.004) loss 2.2105 (2.3862) teacher_loss 0.8339 (0.8944) loss_zs_kd 1.2094 (1.4672) loss_oracle 1.0042 (1.1228) acc 59.3750 (69.3056) lr 1.9048e-03 eta 0:24:11
epoch [9/50] batch [200/403] time 0.069 (0.086) data 0.000 (0.004) loss 2.2821 (2.3717) teacher_loss 0.9490 (0.8918) loss_zs_kd 1.4217 (1.4570) loss_oracle 0.9656 (1.1148) acc 62.5000 (69.2812) lr 1.9048e-03 eta 0:23:59
epoch [9/50] batch [220/403] time 0.086 (0.086) data 0.000 (0.003) loss 2.4244 (2.3579) teacher_loss 0.9039 (0.8878) loss_zs_kd 1.5399 (1.4677) loss_oracle 1.0392 (1.1045) acc 65.6250 (69.4602) lr 1.9048e-03 eta 0:23:55
epoch [9/50] batch [240/403] time 0.057 (0.086) data 0.000 (0.003) loss 2.2066 (2.3534) teacher_loss 0.6702 (0.8842) loss_zs_kd 1.2421 (1.4774) loss_oracle 1.1388 (1.1020) acc 71.8750 (69.5573) lr 1.9048e-03 eta 0:23:47
epoch [9/50] batch [260/403] time 0.078 (0.086) data 0.000 (0.003) loss 2.3826 (2.3428) teacher_loss 1.0963 (0.8790) loss_zs_kd 1.6090 (1.4787) loss_oracle 1.0184 (1.0992) acc 62.5000 (69.8197) lr 1.9048e-03 eta 0:23:49
epoch [9/50] batch [280/403] time 0.074 (0.085) data 0.000 (0.003) loss 1.7098 (2.3355) teacher_loss 0.4978 (0.8785) loss_zs_kd 1.3397 (1.4783) loss_oracle 0.9265 (1.0936) acc 84.3750 (69.9107) lr 1.9048e-03 eta 0:23:36
epoch [9/50] batch [300/403] time 0.067 (0.084) data 0.000 (0.002) loss 2.1226 (2.3214) teacher_loss 0.7961 (0.8721) loss_zs_kd 1.5635 (1.4807) loss_oracle 0.9478 (1.0876) acc 65.6250 (70.1875) lr 1.9048e-03 eta 0:23:20
epoch [9/50] batch [320/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.0347 (2.3101) teacher_loss 0.7517 (0.8678) loss_zs_kd 1.5891 (1.4821) loss_oracle 1.0049 (1.0830) acc 75.0000 (70.3809) lr 1.9048e-03 eta 0:23:13
epoch [9/50] batch [340/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.2431 (2.3028) teacher_loss 0.7996 (0.8625) loss_zs_kd 1.5776 (1.4844) loss_oracle 1.0670 (1.0820) acc 68.7500 (70.4779) lr 1.9048e-03 eta 0:23:12
epoch [9/50] batch [360/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.0861 (2.2976) teacher_loss 0.6258 (0.8596) loss_zs_kd 1.1769 (1.4846) loss_oracle 0.9790 (1.0797) acc 71.8750 (70.6076) lr 1.9048e-03 eta 0:23:12
epoch [9/50] batch [380/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.0227 (2.2902) teacher_loss 0.6191 (0.8566) loss_zs_kd 1.4471 (1.4878) loss_oracle 1.0971 (1.0767) acc 78.1250 (70.7648) lr 1.9048e-03 eta 0:23:11
epoch [9/50] batch [400/403] time 0.078 (0.084) data 0.000 (0.002) loss 2.0350 (2.2836) teacher_loss 0.8676 (0.8547) loss_zs_kd 1.4754 (1.4873) loss_oracle 0.9138 (1.0718) acc 62.5000 (70.7891) lr 1.9048e-03 eta 0:23:05
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,730
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 51.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,953
* accuracy: 33.2%
* error: 66.8%
* macro_f1: 24.9%
******* Domain 4 best val acc:      68.7%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [10/50] batch [20/403] time 0.120 (0.120) data 0.000 (0.032) loss 2.1696 (2.1878) teacher_loss 0.7667 (0.8410) loss_zs_kd 1.6044 (1.4943) loss_oracle 1.0649 (1.0042) acc 75.0000 (71.4062) lr 1.8763e-03 eta 0:33:01
epoch [10/50] batch [40/403] time 0.083 (0.108) data 0.000 (0.016) loss 2.3110 (2.1761) teacher_loss 0.8324 (0.8291) loss_zs_kd 1.5307 (1.4910) loss_oracle 1.2090 (1.0195) acc 65.6250 (71.7188) lr 1.8763e-03 eta 0:29:43
epoch [10/50] batch [60/403] time 0.079 (0.100) data 0.000 (0.011) loss 2.0095 (2.1780) teacher_loss 0.5032 (0.8016) loss_zs_kd 1.6928 (1.5096) loss_oracle 1.1659 (1.0385) acc 84.3750 (72.6042) lr 1.8763e-03 eta 0:27:20
epoch [10/50] batch [80/403] time 0.083 (0.095) data 0.000 (0.008) loss 2.6056 (2.2013) teacher_loss 1.1120 (0.8167) loss_zs_kd 1.3126 (1.5313) loss_oracle 1.0894 (1.0361) acc 59.3750 (72.2266) lr 1.8763e-03 eta 0:26:04
epoch [10/50] batch [100/403] time 0.085 (0.093) data 0.000 (0.007) loss 2.2298 (2.2127) teacher_loss 0.7496 (0.8140) loss_zs_kd 1.5905 (1.5279) loss_oracle 0.9915 (1.0358) acc 78.1250 (72.0625) lr 1.8763e-03 eta 0:25:32
epoch [10/50] batch [120/403] time 0.078 (0.092) data 0.000 (0.006) loss 2.2426 (2.2659) teacher_loss 0.6392 (0.8352) loss_zs_kd 1.8060 (1.5285) loss_oracle 1.0885 (1.0487) acc 78.1250 (71.5104) lr 1.8763e-03 eta 0:25:02
epoch [10/50] batch [140/403] time 0.074 (0.090) data 0.000 (0.005) loss 2.4509 (2.3074) teacher_loss 0.8999 (0.8511) loss_zs_kd 1.5037 (1.5343) loss_oracle 1.0394 (1.0571) acc 62.5000 (70.7143) lr 1.8763e-03 eta 0:24:32
epoch [10/50] batch [160/403] time 0.083 (0.088) data 0.000 (0.004) loss 2.4404 (2.3098) teacher_loss 0.8543 (0.8498) loss_zs_kd 1.8381 (1.5279) loss_oracle 1.1069 (1.0592) acc 68.7500 (70.7617) lr 1.8763e-03 eta 0:24:06
epoch [10/50] batch [180/403] time 0.085 (0.088) data 0.000 (0.004) loss 2.8213 (2.3201) teacher_loss 1.2700 (0.8525) loss_zs_kd 2.0107 (1.5296) loss_oracle 1.2334 (1.0677) acc 65.6250 (70.7812) lr 1.8763e-03 eta 0:24:00
epoch [10/50] batch [200/403] time 0.083 (0.088) data 0.000 (0.003) loss 2.2152 (2.3240) teacher_loss 0.7574 (0.8524) loss_zs_kd 1.2011 (1.5263) loss_oracle 1.1547 (1.0786) acc 71.8750 (70.8594) lr 1.8763e-03 eta 0:23:51
epoch [10/50] batch [220/403] time 0.077 (0.087) data 0.000 (0.003) loss 2.3756 (2.3174) teacher_loss 0.8885 (0.8478) loss_zs_kd 1.2201 (1.5206) loss_oracle 1.1477 (1.0836) acc 68.7500 (71.0511) lr 1.8763e-03 eta 0:23:35
epoch [10/50] batch [240/403] time 0.070 (0.086) data 0.000 (0.003) loss 2.5440 (2.3065) teacher_loss 1.1932 (0.8467) loss_zs_kd 1.4982 (1.5144) loss_oracle 1.0417 (1.0812) acc 56.2500 (71.0156) lr 1.8763e-03 eta 0:23:18
epoch [10/50] batch [260/403] time 0.069 (0.085) data 0.000 (0.003) loss 2.2733 (2.2985) teacher_loss 0.7807 (0.8459) loss_zs_kd 1.2860 (1.5005) loss_oracle 1.1152 (1.0780) acc 78.1250 (71.0337) lr 1.8763e-03 eta 0:22:55
epoch [10/50] batch [280/403] time 0.080 (0.084) data 0.000 (0.003) loss 2.4962 (2.2985) teacher_loss 0.8302 (0.8441) loss_zs_kd 2.0357 (1.5035) loss_oracle 1.2501 (1.0807) acc 75.0000 (70.9933) lr 1.8763e-03 eta 0:22:49
epoch [10/50] batch [300/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.3245 (2.2995) teacher_loss 0.8938 (0.8487) loss_zs_kd 1.3123 (1.5049) loss_oracle 0.9849 (1.0794) acc 65.6250 (70.8125) lr 1.8763e-03 eta 0:22:47
epoch [10/50] batch [320/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.2345 (2.2991) teacher_loss 0.7461 (0.8515) loss_zs_kd 1.4646 (1.5022) loss_oracle 1.0564 (1.0765) acc 75.0000 (70.8887) lr 1.8763e-03 eta 0:22:48
epoch [10/50] batch [340/403] time 0.081 (0.085) data 0.000 (0.002) loss 2.5837 (2.2951) teacher_loss 0.9809 (0.8503) loss_zs_kd 1.3161 (1.4953) loss_oracle 1.2403 (1.0739) acc 62.5000 (70.8732) lr 1.8763e-03 eta 0:22:48
epoch [10/50] batch [360/403] time 0.091 (0.085) data 0.000 (0.002) loss 2.8915 (2.2938) teacher_loss 1.4698 (0.8472) loss_zs_kd 2.1252 (1.4962) loss_oracle 1.0509 (1.0742) acc 62.5000 (71.0851) lr 1.8763e-03 eta 0:22:46
epoch [10/50] batch [380/403] time 0.083 (0.085) data 0.000 (0.002) loss 2.1662 (2.3009) teacher_loss 0.8026 (0.8485) loss_zs_kd 1.6216 (1.4983) loss_oracle 1.1339 (1.0785) acc 78.1250 (71.1431) lr 1.8763e-03 eta 0:22:45
epoch [10/50] batch [400/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.2500 (2.3048) teacher_loss 1.0082 (0.8495) loss_zs_kd 1.5977 (1.5031) loss_oracle 1.0207 (1.0818) acc 56.2500 (71.1016) lr 1.8763e-03 eta 0:22:44
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,757
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 52.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,039
* accuracy: 34.7%
* error: 65.3%
* macro_f1: 26.3%
******* Domain 4 best val acc:      68.7%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [11/50] batch [20/403] time 0.078 (0.123) data 0.000 (0.032) loss 2.6334 (2.2847) teacher_loss 1.1609 (0.8459) loss_zs_kd 1.6938 (1.5966) loss_oracle 1.1521 (1.1255) acc 65.6250 (69.2188) lr 1.8443e-03 eta 0:32:54
epoch [11/50] batch [40/403] time 0.080 (0.101) data 0.000 (0.016) loss 2.0386 (2.2895) teacher_loss 0.6430 (0.8474) loss_zs_kd 1.5136 (1.6107) loss_oracle 1.0372 (1.1336) acc 75.0000 (70.9375) lr 1.8443e-03 eta 0:27:05
epoch [11/50] batch [60/403] time 0.084 (0.096) data 0.001 (0.011) loss 2.3346 (2.2790) teacher_loss 0.6983 (0.8299) loss_zs_kd 1.2991 (1.5080) loss_oracle 1.1359 (1.1286) acc 78.1250 (71.2500) lr 1.8443e-03 eta 0:25:46
epoch [11/50] batch [80/403] time 0.082 (0.094) data 0.000 (0.008) loss 2.2016 (2.2645) teacher_loss 0.8507 (0.8178) loss_zs_kd 1.5923 (1.4683) loss_oracle 1.0616 (1.1194) acc 71.8750 (71.6016) lr 1.8443e-03 eta 0:25:03
epoch [11/50] batch [100/403] time 0.086 (0.091) data 0.000 (0.007) loss 2.3926 (2.2823) teacher_loss 0.8617 (0.8252) loss_zs_kd 1.4108 (1.4914) loss_oracle 1.2144 (1.1257) acc 75.0000 (71.6250) lr 1.8443e-03 eta 0:24:20
epoch [11/50] batch [120/403] time 0.082 (0.090) data 0.000 (0.005) loss 2.1684 (2.2683) teacher_loss 0.8595 (0.8140) loss_zs_kd 1.6012 (1.5020) loss_oracle 0.9603 (1.1184) acc 75.0000 (72.1354) lr 1.8443e-03 eta 0:24:05
epoch [11/50] batch [140/403] time 0.083 (0.090) data 0.000 (0.005) loss 1.9236 (2.2637) teacher_loss 0.4784 (0.8093) loss_zs_kd 1.7594 (1.5071) loss_oracle 1.0408 (1.1171) acc 84.3750 (72.2321) lr 1.8443e-03 eta 0:23:55
epoch [11/50] batch [160/403] time 0.092 (0.090) data 0.000 (0.004) loss 2.2734 (2.2778) teacher_loss 0.7684 (0.8130) loss_zs_kd 2.1206 (1.5179) loss_oracle 1.1299 (1.1237) acc 68.7500 (71.8359) lr 1.8443e-03 eta 0:23:50
epoch [11/50] batch [180/403] time 0.079 (0.089) data 0.000 (0.004) loss 2.1692 (2.2786) teacher_loss 0.7260 (0.8121) loss_zs_kd 1.5539 (1.5205) loss_oracle 1.0148 (1.1237) acc 68.7500 (71.7188) lr 1.8443e-03 eta 0:23:36
epoch [11/50] batch [200/403] time 0.087 (0.089) data 0.000 (0.003) loss 2.2734 (2.2732) teacher_loss 0.9671 (0.8118) loss_zs_kd 1.7829 (1.5197) loss_oracle 1.0832 (1.1188) acc 68.7500 (71.7031) lr 1.8443e-03 eta 0:23:30
epoch [11/50] batch [220/403] time 0.084 (0.088) data 0.000 (0.003) loss 2.3417 (2.2807) teacher_loss 0.8957 (0.8196) loss_zs_kd 1.1972 (1.5159) loss_oracle 1.0123 (1.1165) acc 59.3750 (71.3778) lr 1.8443e-03 eta 0:23:21
epoch [11/50] batch [240/403] time 0.079 (0.088) data 0.000 (0.003) loss 2.7333 (2.2866) teacher_loss 1.2622 (0.8257) loss_zs_kd 1.4620 (1.4983) loss_oracle 1.1052 (1.1163) acc 53.1250 (71.1719) lr 1.8443e-03 eta 0:23:11
epoch [11/50] batch [260/403] time 0.074 (0.087) data 0.000 (0.003) loss 2.1997 (2.2871) teacher_loss 0.6614 (0.8237) loss_zs_kd 1.6726 (1.4963) loss_oracle 1.1369 (1.1168) acc 75.0000 (71.4543) lr 1.8443e-03 eta 0:22:58
epoch [11/50] batch [280/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.7597 (2.2820) teacher_loss 0.3870 (0.8219) loss_zs_kd 2.0103 (1.5071) loss_oracle 0.9879 (1.1124) acc 90.6250 (71.5179) lr 1.8443e-03 eta 0:22:49
epoch [11/50] batch [300/403] time 0.080 (0.086) data 0.000 (0.002) loss 2.3069 (2.2814) teacher_loss 0.8035 (0.8231) loss_zs_kd 1.0644 (1.5148) loss_oracle 1.0872 (1.1098) acc 71.8750 (71.6354) lr 1.8443e-03 eta 0:22:41
epoch [11/50] batch [320/403] time 0.080 (0.086) data 0.000 (0.002) loss 2.5355 (2.2763) teacher_loss 1.1761 (0.8238) loss_zs_kd 1.5139 (1.5115) loss_oracle 1.1348 (1.1051) acc 62.5000 (71.6113) lr 1.8443e-03 eta 0:22:32
epoch [11/50] batch [340/403] time 0.089 (0.085) data 0.000 (0.002) loss 2.2766 (2.2739) teacher_loss 0.9699 (0.8252) loss_zs_kd 1.8221 (1.5091) loss_oracle 1.0142 (1.1009) acc 65.6250 (71.7096) lr 1.8443e-03 eta 0:22:28
epoch [11/50] batch [360/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.0611 (2.2660) teacher_loss 0.7079 (0.8217) loss_zs_kd 1.5763 (1.5092) loss_oracle 1.0518 (1.0973) acc 78.1250 (71.8490) lr 1.8443e-03 eta 0:22:25
epoch [11/50] batch [380/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.5188 (2.2622) teacher_loss 1.0976 (0.8245) loss_zs_kd 1.5224 (1.5018) loss_oracle 1.0114 (1.0925) acc 59.3750 (71.7352) lr 1.8443e-03 eta 0:22:20
epoch [11/50] batch [400/403] time 0.077 (0.085) data 0.000 (0.002) loss 2.1102 (2.2595) teacher_loss 0.8374 (0.8271) loss_zs_kd 1.4678 (1.5015) loss_oracle 0.9322 (1.0872) acc 68.7500 (71.6875) lr 1.8443e-03 eta 0:22:14
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,792
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 52.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,101
* accuracy: 35.7%
* error: 64.3%
* macro_f1: 25.8%
******* Domain 4 best val acc:      68.7%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [12/50] batch [20/403] time 0.084 (0.120) data 0.000 (0.034) loss 2.3291 (2.1923) teacher_loss 0.9639 (0.8673) loss_zs_kd 1.4244 (1.3730) loss_oracle 0.9831 (0.9625) acc 59.3750 (69.8438) lr 1.8090e-03 eta 0:31:20
epoch [12/50] batch [40/403] time 0.086 (0.100) data 0.000 (0.017) loss 2.7366 (2.1988) teacher_loss 1.3348 (0.8739) loss_zs_kd 1.6182 (1.4125) loss_oracle 1.0424 (0.9663) acc 43.7500 (70.3125) lr 1.8090e-03 eta 0:26:11
epoch [12/50] batch [60/403] time 0.089 (0.095) data 0.001 (0.012) loss 2.2201 (2.1791) teacher_loss 0.8364 (0.8556) loss_zs_kd 1.3509 (1.4064) loss_oracle 1.0225 (0.9712) acc 75.0000 (70.9896) lr 1.8090e-03 eta 0:24:49
epoch [12/50] batch [80/403] time 0.090 (0.092) data 0.000 (0.009) loss 2.5723 (2.1874) teacher_loss 1.1707 (0.8467) loss_zs_kd 1.3964 (1.4068) loss_oracle 0.9425 (0.9833) acc 65.6250 (70.9766) lr 1.8090e-03 eta 0:23:51
epoch [12/50] batch [100/403] time 0.086 (0.092) data 0.000 (0.007) loss 2.0838 (2.1915) teacher_loss 0.6861 (0.8500) loss_zs_kd 1.1831 (1.3868) loss_oracle 1.0051 (0.9820) acc 78.1250 (70.4688) lr 1.8090e-03 eta 0:23:49
epoch [12/50] batch [120/403] time 0.078 (0.090) data 0.000 (0.006) loss 2.5809 (2.1948) teacher_loss 1.2069 (0.8531) loss_zs_kd 1.5175 (1.3858) loss_oracle 1.0402 (0.9854) acc 53.1250 (70.2604) lr 1.8090e-03 eta 0:23:20
epoch [12/50] batch [140/403] time 0.080 (0.088) data 0.000 (0.005) loss 2.4464 (2.2057) teacher_loss 0.9877 (0.8599) loss_zs_kd 1.4666 (1.3898) loss_oracle 0.9971 (0.9871) acc 65.6250 (70.1786) lr 1.8090e-03 eta 0:22:49
epoch [12/50] batch [160/403] time 0.079 (0.087) data 0.000 (0.005) loss 2.1896 (2.2183) teacher_loss 0.8081 (0.8702) loss_zs_kd 1.4428 (1.3860) loss_oracle 0.9581 (0.9844) acc 75.0000 (70.0977) lr 1.8090e-03 eta 0:22:27
epoch [12/50] batch [180/403] time 0.085 (0.086) data 0.000 (0.004) loss 2.4019 (2.2340) teacher_loss 0.9425 (0.8786) loss_zs_kd 2.1555 (1.3878) loss_oracle 1.1268 (0.9872) acc 59.3750 (69.7222) lr 1.8090e-03 eta 0:22:13
epoch [12/50] batch [200/403] time 0.091 (0.086) data 0.000 (0.004) loss 2.6282 (2.2408) teacher_loss 0.9785 (0.8788) loss_zs_kd 1.6313 (1.3919) loss_oracle 1.0320 (0.9905) acc 65.6250 (69.6562) lr 1.8090e-03 eta 0:22:10
epoch [12/50] batch [220/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.9468 (2.2356) teacher_loss 0.6811 (0.8703) loss_zs_kd 1.4887 (1.4098) loss_oracle 0.9126 (0.9907) acc 81.2500 (70.0284) lr 1.8090e-03 eta 0:22:08
epoch [12/50] batch [240/403] time 0.085 (0.086) data 0.000 (0.003) loss 2.4963 (2.2442) teacher_loss 1.0352 (0.8751) loss_zs_kd 1.6641 (1.4220) loss_oracle 1.0806 (0.9887) acc 56.2500 (69.7266) lr 1.8090e-03 eta 0:22:04
epoch [12/50] batch [260/403] time 0.099 (0.086) data 0.000 (0.003) loss 2.5446 (2.2544) teacher_loss 1.0529 (0.8798) loss_zs_kd 1.1938 (1.4251) loss_oracle 0.9877 (0.9904) acc 62.5000 (69.6514) lr 1.8090e-03 eta 0:22:03
epoch [12/50] batch [280/403] time 0.086 (0.085) data 0.000 (0.003) loss 2.1141 (2.2543) teacher_loss 0.7720 (0.8773) loss_zs_kd 1.6369 (1.4261) loss_oracle 0.8833 (0.9883) acc 71.8750 (69.7321) lr 1.8090e-03 eta 0:21:57
epoch [12/50] batch [300/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.2279 (2.2559) teacher_loss 0.7950 (0.8787) loss_zs_kd 1.4486 (1.4284) loss_oracle 0.9675 (0.9845) acc 68.7500 (69.6875) lr 1.8090e-03 eta 0:21:56
epoch [12/50] batch [320/403] time 0.081 (0.085) data 0.000 (0.002) loss 2.1437 (2.2516) teacher_loss 0.7944 (0.8756) loss_zs_kd 1.8540 (1.4318) loss_oracle 0.9182 (0.9818) acc 75.0000 (69.8047) lr 1.8090e-03 eta 0:21:49
epoch [12/50] batch [340/403] time 0.092 (0.086) data 0.000 (0.002) loss 2.1126 (2.2528) teacher_loss 0.8201 (0.8749) loss_zs_kd 1.7973 (1.4418) loss_oracle 0.9993 (0.9799) acc 68.7500 (70.0000) lr 1.8090e-03 eta 0:22:00
epoch [12/50] batch [360/403] time 0.072 (0.086) data 0.000 (0.002) loss 2.2363 (2.2544) teacher_loss 0.9349 (0.8723) loss_zs_kd 1.2033 (1.4516) loss_oracle 0.9185 (0.9803) acc 75.0000 (70.0781) lr 1.8090e-03 eta 0:21:57
epoch [12/50] batch [380/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.2166 (2.2527) teacher_loss 0.8021 (0.8704) loss_zs_kd 1.8502 (1.4553) loss_oracle 1.0104 (0.9793) acc 78.1250 (70.2220) lr 1.8090e-03 eta 0:21:51
epoch [12/50] batch [400/403] time 0.075 (0.085) data 0.000 (0.002) loss 2.7613 (2.2556) teacher_loss 1.2702 (0.8689) loss_zs_kd 1.3949 (1.4564) loss_oracle 1.0008 (0.9792) acc 50.0000 (70.3359) lr 1.8090e-03 eta 0:21:43
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,812
* accuracy: 68.9%
* error: 31.1%
* macro_f1: 53.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,236
* accuracy: 38.0%
* error: 62.0%
* macro_f1: 27.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      68.9%, epoch: 12 *******
******* Domain 4 best val test acc: 38.0%, epoch: 12 *******
******* Domain 4 best test acc:     38.0%, epoch: 12 *******
epoch [13/50] batch [20/403] time 0.090 (0.111) data 0.000 (0.030) loss 1.9580 (2.2040) teacher_loss 0.7115 (0.8092) loss_zs_kd 1.5648 (1.4280) loss_oracle 0.8554 (0.9353) acc 75.0000 (71.2500) lr 1.7705e-03 eta 0:28:21
epoch [13/50] batch [40/403] time 0.078 (0.095) data 0.000 (0.015) loss 2.1281 (2.1936) teacher_loss 0.7775 (0.8116) loss_zs_kd 1.5537 (1.4960) loss_oracle 0.8400 (0.9141) acc 78.1250 (73.1250) lr 1.7705e-03 eta 0:24:03
epoch [13/50] batch [60/403] time 0.088 (0.091) data 0.001 (0.010) loss 2.7173 (2.1888) teacher_loss 1.4570 (0.8228) loss_zs_kd 1.6723 (1.4787) loss_oracle 0.8427 (0.9034) acc 56.2500 (72.7083) lr 1.7705e-03 eta 0:23:06
epoch [13/50] batch [80/403] time 0.077 (0.091) data 0.000 (0.008) loss 2.2242 (2.1795) teacher_loss 0.9173 (0.8227) loss_zs_kd 1.3874 (1.4575) loss_oracle 0.9116 (0.9029) acc 65.6250 (71.9141) lr 1.7705e-03 eta 0:23:13
epoch [13/50] batch [100/403] time 0.086 (0.090) data 0.000 (0.006) loss 2.1007 (2.1849) teacher_loss 0.7648 (0.8333) loss_zs_kd 1.2205 (1.4691) loss_oracle 0.8966 (0.9022) acc 78.1250 (71.8750) lr 1.7705e-03 eta 0:22:45
epoch [13/50] batch [120/403] time 0.087 (0.089) data 0.000 (0.005) loss 2.2933 (2.1787) teacher_loss 0.8776 (0.8287) loss_zs_kd 1.5918 (1.4800) loss_oracle 0.8836 (0.8992) acc 71.8750 (72.0052) lr 1.7705e-03 eta 0:22:34
epoch [13/50] batch [140/403] time 0.058 (0.088) data 0.000 (0.004) loss 2.0253 (2.1691) teacher_loss 0.6474 (0.8188) loss_zs_kd 1.3037 (1.5033) loss_oracle 0.8336 (0.8995) acc 75.0000 (72.4554) lr 1.7705e-03 eta 0:22:11
epoch [13/50] batch [160/403] time 0.080 (0.087) data 0.000 (0.004) loss 1.9827 (2.1684) teacher_loss 0.5342 (0.8157) loss_zs_kd 1.5659 (1.4894) loss_oracle 0.8931 (0.9014) acc 87.5000 (72.6367) lr 1.7705e-03 eta 0:21:59
epoch [13/50] batch [180/403] time 0.089 (0.087) data 0.000 (0.004) loss 2.1200 (2.1623) teacher_loss 0.6677 (0.8117) loss_zs_kd 1.3875 (1.4704) loss_oracle 0.9965 (0.9030) acc 81.2500 (72.9340) lr 1.7705e-03 eta 0:21:55
epoch [13/50] batch [200/403] time 0.070 (0.086) data 0.000 (0.003) loss 2.1821 (2.1673) teacher_loss 0.7917 (0.8143) loss_zs_kd 1.4588 (1.4573) loss_oracle 0.9553 (0.9071) acc 71.8750 (72.6406) lr 1.7705e-03 eta 0:21:41
epoch [13/50] batch [220/403] time 0.089 (0.086) data 0.000 (0.003) loss 2.1495 (2.1709) teacher_loss 0.8780 (0.8169) loss_zs_kd 1.1799 (1.4554) loss_oracle 0.8952 (0.9092) acc 71.8750 (72.2727) lr 1.7705e-03 eta 0:21:32
epoch [13/50] batch [240/403] time 0.080 (0.086) data 0.000 (0.003) loss 1.9550 (2.1750) teacher_loss 0.5928 (0.8217) loss_zs_kd 1.4060 (1.4588) loss_oracle 0.9520 (0.9089) acc 81.2500 (72.2786) lr 1.7705e-03 eta 0:21:30
epoch [13/50] batch [260/403] time 0.081 (0.085) data 0.000 (0.003) loss 1.8108 (2.1728) teacher_loss 0.5905 (0.8201) loss_zs_kd 1.2139 (1.4506) loss_oracle 0.8606 (0.9108) acc 71.8750 (72.1274) lr 1.7705e-03 eta 0:21:20
epoch [13/50] batch [280/403] time 0.079 (0.085) data 0.000 (0.002) loss 2.2035 (2.1747) teacher_loss 0.9029 (0.8225) loss_zs_kd 1.5594 (1.4442) loss_oracle 0.9198 (0.9131) acc 71.8750 (71.9866) lr 1.7705e-03 eta 0:21:17
epoch [13/50] batch [300/403] time 0.088 (0.085) data 0.000 (0.002) loss 1.8779 (2.1714) teacher_loss 0.6314 (0.8218) loss_zs_kd 1.0162 (1.4395) loss_oracle 0.8469 (0.9125) acc 78.1250 (72.0417) lr 1.7705e-03 eta 0:21:17
epoch [13/50] batch [320/403] time 0.079 (0.085) data 0.000 (0.002) loss 2.1269 (2.1765) teacher_loss 0.8639 (0.8283) loss_zs_kd 1.1252 (1.4324) loss_oracle 0.8183 (0.9114) acc 59.3750 (71.8066) lr 1.7705e-03 eta 0:21:13
epoch [13/50] batch [340/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.9709 (2.1680) teacher_loss 0.5956 (0.8216) loss_zs_kd 1.4503 (1.4325) loss_oracle 0.8912 (0.9097) acc 71.8750 (72.0221) lr 1.7705e-03 eta 0:21:05
epoch [13/50] batch [360/403] time 0.078 (0.084) data 0.000 (0.002) loss 2.5153 (2.1681) teacher_loss 1.2015 (0.8229) loss_zs_kd 1.3273 (1.4405) loss_oracle 0.8814 (0.9087) acc 56.2500 (71.9965) lr 1.7705e-03 eta 0:20:58
epoch [13/50] batch [380/403] time 0.084 (0.084) data 0.000 (0.002) loss 2.2247 (2.1653) teacher_loss 0.8621 (0.8225) loss_zs_kd 1.5493 (1.4468) loss_oracle 0.8932 (0.9073) acc 71.8750 (71.9901) lr 1.7705e-03 eta 0:20:53
epoch [13/50] batch [400/403] time 0.076 (0.084) data 0.000 (0.002) loss 2.1104 (2.1657) teacher_loss 0.8519 (0.8235) loss_zs_kd 1.5623 (1.4452) loss_oracle 0.8409 (0.9057) acc 71.8750 (71.9375) lr 1.7705e-03 eta 0:20:48
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,679
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 52.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,100
* accuracy: 35.7%
* error: 64.3%
* macro_f1: 27.6%
******* Domain 4 best val acc:      68.9%, epoch: 12 *******
******* Domain 4 best val test acc: 38.0%, epoch: 12 *******
******* Domain 4 best test acc:     38.0%, epoch: 12 *******
epoch [14/50] batch [20/403] time 0.081 (0.115) data 0.000 (0.028) loss 2.1779 (2.1680) teacher_loss 0.8244 (0.8693) loss_zs_kd 1.1507 (1.5346) loss_oracle 0.8716 (0.8483) acc 71.8750 (68.7500) lr 1.7290e-03 eta 0:28:38
epoch [14/50] batch [40/403] time 0.077 (0.098) data 0.000 (0.014) loss 1.8467 (2.1975) teacher_loss 0.5553 (0.8965) loss_zs_kd 1.6259 (1.5143) loss_oracle 0.8223 (0.8569) acc 84.3750 (67.8125) lr 1.7290e-03 eta 0:24:20
epoch [14/50] batch [60/403] time 0.081 (0.092) data 0.000 (0.009) loss 2.1287 (2.1808) teacher_loss 0.8046 (0.8772) loss_zs_kd 1.6119 (1.5005) loss_oracle 0.9046 (0.8626) acc 75.0000 (69.5312) lr 1.7290e-03 eta 0:22:51
epoch [14/50] batch [80/403] time 0.089 (0.090) data 0.000 (0.007) loss 1.9633 (2.1666) teacher_loss 0.6951 (0.8675) loss_zs_kd 1.6182 (1.5070) loss_oracle 0.8931 (0.8639) acc 78.1250 (69.6875) lr 1.7290e-03 eta 0:22:18
epoch [14/50] batch [100/403] time 0.086 (0.089) data 0.000 (0.006) loss 2.0903 (2.1552) teacher_loss 0.9087 (0.8595) loss_zs_kd 1.5675 (1.5025) loss_oracle 0.8245 (0.8652) acc 65.6250 (70.0938) lr 1.7290e-03 eta 0:22:03
epoch [14/50] batch [120/403] time 0.083 (0.089) data 0.001 (0.005) loss 2.0894 (2.1451) teacher_loss 0.8353 (0.8520) loss_zs_kd 1.2824 (1.5061) loss_oracle 0.8780 (0.8667) acc 68.7500 (70.4427) lr 1.7290e-03 eta 0:21:51
epoch [14/50] batch [140/403] time 0.090 (0.088) data 0.000 (0.004) loss 1.9891 (2.1363) teacher_loss 0.6565 (0.8426) loss_zs_kd 1.7947 (1.5152) loss_oracle 0.8772 (0.8676) acc 75.0000 (70.7812) lr 1.7290e-03 eta 0:21:42
epoch [14/50] batch [160/403] time 0.085 (0.088) data 0.000 (0.004) loss 2.3356 (2.1410) teacher_loss 0.9877 (0.8498) loss_zs_kd 1.3909 (1.4975) loss_oracle 0.8534 (0.8663) acc 59.3750 (70.5469) lr 1.7290e-03 eta 0:21:30
epoch [14/50] batch [180/403] time 0.083 (0.087) data 0.000 (0.003) loss 2.2049 (2.1431) teacher_loss 0.9337 (0.8499) loss_zs_kd 1.1393 (1.4934) loss_oracle 0.8627 (0.8684) acc 71.8750 (70.5903) lr 1.7290e-03 eta 0:21:25
epoch [14/50] batch [200/403] time 0.080 (0.087) data 0.000 (0.003) loss 2.2650 (2.1497) teacher_loss 0.8896 (0.8537) loss_zs_kd 1.3693 (1.4879) loss_oracle 0.9102 (0.8698) acc 71.8750 (70.6406) lr 1.7290e-03 eta 0:21:17
epoch [14/50] batch [220/403] time 0.135 (0.087) data 0.001 (0.003) loss 2.4555 (2.1525) teacher_loss 1.1311 (0.8565) loss_zs_kd 1.6275 (1.4914) loss_oracle 0.9537 (0.8720) acc 59.3750 (70.8239) lr 1.7290e-03 eta 0:21:24
epoch [14/50] batch [240/403] time 0.086 (0.088) data 0.000 (0.003) loss 2.5974 (2.1540) teacher_loss 1.1956 (0.8544) loss_zs_kd 1.2092 (1.4973) loss_oracle 0.8283 (0.8733) acc 59.3750 (70.8984) lr 1.7290e-03 eta 0:21:26
epoch [14/50] batch [260/403] time 0.086 (0.087) data 0.000 (0.002) loss 2.5295 (2.1568) teacher_loss 1.2473 (0.8548) loss_zs_kd 1.6620 (1.4917) loss_oracle 0.8361 (0.8744) acc 56.2500 (70.8173) lr 1.7290e-03 eta 0:21:21
epoch [14/50] batch [280/403] time 0.079 (0.087) data 0.000 (0.002) loss 1.9712 (2.1533) teacher_loss 0.6378 (0.8495) loss_zs_kd 1.6111 (1.4904) loss_oracle 0.8779 (0.8744) acc 78.1250 (71.1384) lr 1.7290e-03 eta 0:21:14
epoch [14/50] batch [300/403] time 0.083 (0.087) data 0.000 (0.002) loss 2.3080 (2.1589) teacher_loss 0.8299 (0.8485) loss_zs_kd 1.2944 (1.4885) loss_oracle 0.9984 (0.8784) acc 62.5000 (71.1042) lr 1.7290e-03 eta 0:21:12
epoch [14/50] batch [320/403] time 0.085 (0.087) data 0.000 (0.002) loss 2.5096 (2.1603) teacher_loss 1.0248 (0.8441) loss_zs_kd 2.1714 (1.4865) loss_oracle 1.0145 (0.8825) acc 65.6250 (71.2891) lr 1.7290e-03 eta 0:21:09
epoch [14/50] batch [340/403] time 0.083 (0.087) data 0.000 (0.002) loss 1.9175 (2.1621) teacher_loss 0.6844 (0.8420) loss_zs_kd 2.0193 (1.4931) loss_oracle 0.8296 (0.8846) acc 78.1250 (71.3787) lr 1.7290e-03 eta 0:21:06
epoch [14/50] batch [360/403] time 0.082 (0.087) data 0.000 (0.002) loss 2.6132 (2.1671) teacher_loss 1.2101 (0.8445) loss_zs_kd 1.6298 (1.4928) loss_oracle 0.9651 (0.8857) acc 53.1250 (71.2587) lr 1.7290e-03 eta 0:21:02
epoch [14/50] batch [380/403] time 0.071 (0.086) data 0.000 (0.002) loss 2.2897 (2.1646) teacher_loss 0.7632 (0.8404) loss_zs_kd 1.2590 (1.4934) loss_oracle 0.8669 (0.8848) acc 75.0000 (71.3487) lr 1.7290e-03 eta 0:20:53
epoch [14/50] batch [400/403] time 0.083 (0.086) data 0.000 (0.002) loss 2.0788 (2.1632) teacher_loss 0.7583 (0.8359) loss_zs_kd 1.4520 (1.4966) loss_oracle 0.8010 (0.8836) acc 84.3750 (71.5625) lr 1.7290e-03 eta 0:20:46
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,876
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 56.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,246
* accuracy: 38.2%
* error: 61.8%
* macro_f1: 27.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.0%, epoch: 14 *******
******* Domain 4 best val test acc: 38.2%, epoch: 14 *******
******* Domain 4 best test acc:     38.2%, epoch: 14 *******
epoch [15/50] batch [20/403] time 0.080 (0.099) data 0.000 (0.024) loss 2.2844 (2.2166) teacher_loss 0.9585 (0.8457) loss_zs_kd 1.8202 (1.6525) loss_oracle 0.8635 (0.8694) acc 59.3750 (71.5625) lr 1.6845e-03 eta 0:23:50
epoch [15/50] batch [40/403] time 0.089 (0.092) data 0.000 (0.012) loss 2.0957 (2.1854) teacher_loss 0.6840 (0.8095) loss_zs_kd 1.9880 (1.6847) loss_oracle 1.0523 (0.8903) acc 81.2500 (73.9844) lr 1.6845e-03 eta 0:22:13
epoch [15/50] batch [60/403] time 0.086 (0.090) data 0.000 (0.008) loss 2.2096 (2.1942) teacher_loss 0.8346 (0.8028) loss_zs_kd 1.4446 (1.6475) loss_oracle 0.8529 (0.9052) acc 75.0000 (73.8021) lr 1.6845e-03 eta 0:21:39
epoch [15/50] batch [80/403] time 0.094 (0.088) data 0.001 (0.006) loss 2.0620 (2.2149) teacher_loss 0.7947 (0.8162) loss_zs_kd 1.3460 (1.6316) loss_oracle 0.8825 (0.9164) acc 78.1250 (72.8516) lr 1.6845e-03 eta 0:21:16
epoch [15/50] batch [100/403] time 0.083 (0.088) data 0.001 (0.005) loss 2.4744 (2.2277) teacher_loss 1.0483 (0.8320) loss_zs_kd 1.5745 (1.6121) loss_oracle 0.9099 (0.9148) acc 62.5000 (72.0938) lr 1.6845e-03 eta 0:21:03
epoch [15/50] batch [120/403] time 0.067 (0.086) data 0.000 (0.004) loss 2.3573 (2.2178) teacher_loss 0.8318 (0.8215) loss_zs_kd 1.3474 (1.5948) loss_oracle 0.9838 (0.9182) acc 65.6250 (72.4479) lr 1.6845e-03 eta 0:20:40
epoch [15/50] batch [140/403] time 0.082 (0.084) data 0.000 (0.004) loss 2.4225 (2.2268) teacher_loss 1.0606 (0.8282) loss_zs_kd 1.4807 (1.5924) loss_oracle 0.9261 (0.9206) acc 56.2500 (72.2321) lr 1.6845e-03 eta 0:20:13
epoch [15/50] batch [160/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.0104 (2.2255) teacher_loss 0.5897 (0.8256) loss_zs_kd 1.3411 (1.5995) loss_oracle 0.8831 (0.9234) acc 84.3750 (72.1484) lr 1.6845e-03 eta 0:20:03
epoch [15/50] batch [180/403] time 0.068 (0.083) data 0.000 (0.003) loss 2.1947 (2.2249) teacher_loss 0.7273 (0.8262) loss_zs_kd 1.9484 (1.6190) loss_oracle 0.8946 (0.9225) acc 75.0000 (71.9792) lr 1.6845e-03 eta 0:19:50
epoch [15/50] batch [200/403] time 0.078 (0.082) data 0.000 (0.003) loss 2.1506 (2.2220) teacher_loss 0.6622 (0.8235) loss_zs_kd 1.8739 (1.6156) loss_oracle 0.8395 (0.9206) acc 78.1250 (72.1406) lr 1.6845e-03 eta 0:19:39
epoch [15/50] batch [220/403] time 0.080 (0.082) data 0.000 (0.002) loss 2.3335 (2.2217) teacher_loss 0.8989 (0.8235) loss_zs_kd 1.6652 (1.6165) loss_oracle 0.9167 (0.9194) acc 59.3750 (72.1307) lr 1.6845e-03 eta 0:19:36
epoch [15/50] batch [240/403] time 0.077 (0.082) data 0.000 (0.002) loss 2.1713 (2.2150) teacher_loss 0.7825 (0.8180) loss_zs_kd 1.2723 (1.6162) loss_oracle 0.8795 (0.9177) acc 78.1250 (72.3047) lr 1.6845e-03 eta 0:19:31
epoch [15/50] batch [260/403] time 0.053 (0.082) data 0.000 (0.002) loss 2.5054 (2.2087) teacher_loss 1.0723 (0.8136) loss_zs_kd 1.8926 (1.6079) loss_oracle 0.9159 (0.9143) acc 50.0000 (72.4519) lr 1.6845e-03 eta 0:19:28
epoch [15/50] batch [280/403] time 0.061 (0.081) data 0.000 (0.002) loss 1.9853 (2.1992) teacher_loss 0.6350 (0.8071) loss_zs_kd 1.5703 (1.6139) loss_oracle 0.8237 (0.9116) acc 78.1250 (72.7121) lr 1.6845e-03 eta 0:19:05
epoch [15/50] batch [300/403] time 0.075 (0.081) data 0.000 (0.002) loss 2.3265 (2.2060) teacher_loss 0.9930 (0.8130) loss_zs_kd 1.5682 (1.6219) loss_oracle 0.9535 (0.9101) acc 68.7500 (72.6042) lr 1.6845e-03 eta 0:19:04
epoch [15/50] batch [320/403] time 0.080 (0.080) data 0.000 (0.002) loss 2.3826 (2.2102) teacher_loss 1.0048 (0.8138) loss_zs_kd 1.3753 (1.6217) loss_oracle 0.8667 (0.9079) acc 53.1250 (72.4219) lr 1.6845e-03 eta 0:19:00
epoch [15/50] batch [340/403] time 0.091 (0.080) data 0.000 (0.002) loss 2.2889 (2.2215) teacher_loss 0.8392 (0.8190) loss_zs_kd 1.5483 (1.6194) loss_oracle 0.8569 (0.9076) acc 65.6250 (72.2610) lr 1.6845e-03 eta 0:18:56
epoch [15/50] batch [360/403] time 0.078 (0.080) data 0.000 (0.002) loss 1.8195 (2.2177) teacher_loss 0.4605 (0.8140) loss_zs_kd 1.2194 (1.6173) loss_oracle 0.8514 (0.9045) acc 87.5000 (72.5087) lr 1.6845e-03 eta 0:18:53
epoch [15/50] batch [380/403] time 0.144 (0.081) data 0.001 (0.002) loss 2.3836 (2.2202) teacher_loss 1.0244 (0.8165) loss_zs_kd 1.4870 (1.6172) loss_oracle 0.8509 (0.9024) acc 59.3750 (72.4013) lr 1.6845e-03 eta 0:19:08
epoch [15/50] batch [400/403] time 0.081 (0.081) data 0.000 (0.001) loss 2.0024 (2.2158) teacher_loss 0.6374 (0.8140) loss_zs_kd 1.4065 (1.6145) loss_oracle 0.8688 (0.9019) acc 78.1250 (72.4688) lr 1.6845e-03 eta 0:19:06
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,804
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 55.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,281
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 25.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.0%, epoch: 14 *******
******* Domain 4 best val test acc: 38.2%, epoch: 14 *******
******* Domain 4 best test acc:     38.8%, epoch: 15 *******
epoch [16/50] batch [20/403] time 0.079 (0.113) data 0.000 (0.025) loss 2.1369 (2.2994) teacher_loss 0.7095 (0.8427) loss_zs_kd 1.4431 (1.4906) loss_oracle 0.8873 (0.9091) acc 75.0000 (72.5000) lr 1.6374e-03 eta 0:26:27
epoch [16/50] batch [40/403] time 0.084 (0.098) data 0.000 (0.012) loss 1.9193 (2.2811) teacher_loss 0.5057 (0.8596) loss_zs_kd 1.5831 (1.5650) loss_oracle 0.8826 (0.8969) acc 81.2500 (72.7344) lr 1.6374e-03 eta 0:22:56
epoch [16/50] batch [60/403] time 0.083 (0.093) data 0.000 (0.008) loss 2.2249 (2.2230) teacher_loss 0.8277 (0.8112) loss_zs_kd 1.9150 (1.6309) loss_oracle 0.8787 (0.8984) acc 65.6250 (73.6979) lr 1.6374e-03 eta 0:21:43
epoch [16/50] batch [80/403] time 0.081 (0.091) data 0.000 (0.006) loss 1.8970 (2.2139) teacher_loss 0.6487 (0.8071) loss_zs_kd 1.3153 (1.6017) loss_oracle 0.8120 (0.8982) acc 84.3750 (73.5547) lr 1.6374e-03 eta 0:21:14
epoch [16/50] batch [100/403] time 0.073 (0.088) data 0.000 (0.005) loss 2.1922 (2.2010) teacher_loss 0.8485 (0.8001) loss_zs_kd 1.7350 (1.6008) loss_oracle 0.8601 (0.8946) acc 68.7500 (73.3750) lr 1.6374e-03 eta 0:20:38
epoch [16/50] batch [120/403] time 0.089 (0.087) data 0.000 (0.004) loss 1.9073 (2.2006) teacher_loss 0.5249 (0.7989) loss_zs_kd 1.4038 (1.6089) loss_oracle 0.8590 (0.8956) acc 78.1250 (73.1250) lr 1.6374e-03 eta 0:20:16
epoch [16/50] batch [140/403] time 0.086 (0.089) data 0.000 (0.004) loss 2.4103 (2.2055) teacher_loss 0.9428 (0.7987) loss_zs_kd 1.4537 (1.6093) loss_oracle 0.8856 (0.8934) acc 71.8750 (73.0357) lr 1.6374e-03 eta 0:20:41
epoch [16/50] batch [160/403] time 0.083 (0.089) data 0.000 (0.003) loss 2.6208 (2.2144) teacher_loss 1.1947 (0.8062) loss_zs_kd 1.4406 (1.5920) loss_oracle 0.9698 (0.8964) acc 62.5000 (72.7734) lr 1.6374e-03 eta 0:20:35
epoch [16/50] batch [180/403] time 0.089 (0.088) data 0.000 (0.003) loss 2.1985 (2.2224) teacher_loss 0.7936 (0.8107) loss_zs_kd 1.5960 (1.5786) loss_oracle 0.8893 (0.8948) acc 75.0000 (72.5868) lr 1.6374e-03 eta 0:20:28
epoch [16/50] batch [200/403] time 0.095 (0.088) data 0.000 (0.003) loss 2.3890 (2.2269) teacher_loss 1.0531 (0.8132) loss_zs_kd 1.9064 (1.5829) loss_oracle 0.8588 (0.8967) acc 59.3750 (72.4375) lr 1.6374e-03 eta 0:20:24
epoch [16/50] batch [220/403] time 0.080 (0.088) data 0.000 (0.002) loss 2.1074 (2.2240) teacher_loss 0.6915 (0.8138) loss_zs_kd 1.2956 (1.5780) loss_oracle 0.9183 (0.8954) acc 71.8750 (72.5142) lr 1.6374e-03 eta 0:20:15
epoch [16/50] batch [240/403] time 0.081 (0.087) data 0.000 (0.002) loss 1.9314 (2.2186) teacher_loss 0.4859 (0.8074) loss_zs_kd 1.5993 (1.5880) loss_oracle 0.8882 (0.8947) acc 81.2500 (72.7083) lr 1.6374e-03 eta 0:20:09
epoch [16/50] batch [260/403] time 0.088 (0.087) data 0.000 (0.002) loss 2.1842 (2.2206) teacher_loss 0.7850 (0.8117) loss_zs_kd 1.3684 (1.5936) loss_oracle 0.8424 (0.8917) acc 75.0000 (72.5481) lr 1.6374e-03 eta 0:20:06
epoch [16/50] batch [280/403] time 0.080 (0.087) data 0.000 (0.002) loss 2.4320 (2.2190) teacher_loss 0.9822 (0.8128) loss_zs_kd 1.9818 (1.5954) loss_oracle 0.9148 (0.8892) acc 71.8750 (72.4554) lr 1.6374e-03 eta 0:19:59
epoch [16/50] batch [300/403] time 0.084 (0.087) data 0.000 (0.002) loss 2.3166 (2.2133) teacher_loss 0.8871 (0.8099) loss_zs_kd 1.5498 (1.5902) loss_oracle 0.8438 (0.8869) acc 75.0000 (72.4375) lr 1.6374e-03 eta 0:19:55
epoch [16/50] batch [320/403] time 0.090 (0.087) data 0.000 (0.002) loss 2.2201 (2.2125) teacher_loss 0.6737 (0.8083) loss_zs_kd 1.4936 (1.5825) loss_oracle 0.8630 (0.8851) acc 81.2500 (72.3828) lr 1.6374e-03 eta 0:19:52
epoch [16/50] batch [340/403] time 0.089 (0.086) data 0.000 (0.002) loss 2.0114 (2.2100) teacher_loss 0.6924 (0.8050) loss_zs_kd 1.6924 (1.5894) loss_oracle 0.8404 (0.8846) acc 75.0000 (72.4449) lr 1.6374e-03 eta 0:19:50
epoch [16/50] batch [360/403] time 0.084 (0.086) data 0.000 (0.002) loss 2.3927 (2.2092) teacher_loss 1.0589 (0.8048) loss_zs_kd 1.4670 (1.5923) loss_oracle 0.8658 (0.8840) acc 59.3750 (72.4392) lr 1.6374e-03 eta 0:19:47
epoch [16/50] batch [380/403] time 0.083 (0.086) data 0.000 (0.002) loss 2.1568 (2.2102) teacher_loss 0.6855 (0.8057) loss_zs_kd 1.6044 (1.5959) loss_oracle 0.8721 (0.8838) acc 71.8750 (72.3355) lr 1.6374e-03 eta 0:19:45
epoch [16/50] batch [400/403] time 0.078 (0.086) data 0.000 (0.002) loss 2.0922 (2.2090) teacher_loss 0.6651 (0.8050) loss_zs_kd 1.7207 (1.6033) loss_oracle 0.9350 (0.8836) acc 78.1250 (72.4609) lr 1.6374e-03 eta 0:19:41
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,891
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,220
* accuracy: 37.7%
* error: 62.3%
* macro_f1: 27.4%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     38.8%, epoch: 15 *******
epoch [17/50] batch [20/403] time 0.077 (0.114) data 0.000 (0.027) loss 2.0488 (2.1392) teacher_loss 0.5882 (0.7211) loss_zs_kd 1.5870 (1.6335) loss_oracle 0.9043 (0.8893) acc 78.1250 (73.7500) lr 1.5878e-03 eta 0:26:01
epoch [17/50] batch [40/403] time 0.084 (0.099) data 0.000 (0.014) loss 2.8060 (2.1996) teacher_loss 1.3717 (0.7809) loss_zs_kd 2.0103 (1.6149) loss_oracle 0.9768 (0.8951) acc 59.3750 (73.2812) lr 1.5878e-03 eta 0:22:30
epoch [17/50] batch [60/403] time 0.080 (0.094) data 0.000 (0.009) loss 2.0370 (2.1717) teacher_loss 0.6251 (0.7582) loss_zs_kd 1.6070 (1.6488) loss_oracle 0.8267 (0.8867) acc 78.1250 (74.0625) lr 1.5878e-03 eta 0:21:17
epoch [17/50] batch [80/403] time 0.082 (0.091) data 0.000 (0.007) loss 2.6223 (2.1723) teacher_loss 1.3166 (0.7723) loss_zs_kd 1.5384 (1.6404) loss_oracle 0.8765 (0.8807) acc 59.3750 (73.6328) lr 1.5878e-03 eta 0:20:45
epoch [17/50] batch [100/403] time 0.083 (0.090) data 0.000 (0.006) loss 2.2488 (2.1780) teacher_loss 0.8182 (0.7775) loss_zs_kd 1.6396 (1.6544) loss_oracle 0.9618 (0.8778) acc 75.0000 (73.4688) lr 1.5878e-03 eta 0:20:23
epoch [17/50] batch [120/403] time 0.084 (0.089) data 0.000 (0.005) loss 2.0687 (2.1745) teacher_loss 0.7031 (0.7791) loss_zs_kd 1.2757 (1.6643) loss_oracle 0.9022 (0.8819) acc 78.1250 (73.3073) lr 1.5878e-03 eta 0:20:10
epoch [17/50] batch [140/403] time 0.080 (0.088) data 0.000 (0.004) loss 2.1851 (2.1738) teacher_loss 0.7872 (0.7856) loss_zs_kd 1.3245 (1.6722) loss_oracle 0.8678 (0.8787) acc 68.7500 (72.9911) lr 1.5878e-03 eta 0:19:53
epoch [17/50] batch [160/403] time 0.079 (0.088) data 0.000 (0.004) loss 2.2302 (2.1715) teacher_loss 0.7323 (0.7850) loss_zs_kd 1.6243 (1.6571) loss_oracle 0.9387 (0.8797) acc 78.1250 (73.3008) lr 1.5878e-03 eta 0:19:44
epoch [17/50] batch [180/403] time 0.085 (0.087) data 0.000 (0.003) loss 2.5472 (2.1717) teacher_loss 0.9663 (0.7837) loss_zs_kd 1.4046 (1.6338) loss_oracle 0.9913 (0.8853) acc 68.7500 (73.4375) lr 1.5878e-03 eta 0:19:37
epoch [17/50] batch [200/403] time 0.080 (0.087) data 0.000 (0.003) loss 1.8985 (2.1762) teacher_loss 0.5739 (0.7844) loss_zs_kd 1.4113 (1.6103) loss_oracle 0.9169 (0.8904) acc 78.1250 (73.3750) lr 1.5878e-03 eta 0:19:31
epoch [17/50] batch [220/403] time 0.093 (0.087) data 0.001 (0.003) loss 2.0724 (2.1844) teacher_loss 0.6879 (0.7870) loss_zs_kd 1.7147 (1.6125) loss_oracle 0.9353 (0.8977) acc 68.7500 (73.2386) lr 1.5878e-03 eta 0:19:29
epoch [17/50] batch [240/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.8668 (2.1834) teacher_loss 0.5589 (0.7859) loss_zs_kd 1.4035 (1.6065) loss_oracle 0.9108 (0.9001) acc 78.1250 (73.2812) lr 1.5878e-03 eta 0:19:24
epoch [17/50] batch [260/403] time 0.087 (0.086) data 0.000 (0.002) loss 1.9916 (2.1890) teacher_loss 0.6344 (0.7893) loss_zs_kd 1.5192 (1.6048) loss_oracle 0.9028 (0.9017) acc 81.2500 (73.2572) lr 1.5878e-03 eta 0:19:20
epoch [17/50] batch [280/403] time 0.079 (0.088) data 0.001 (0.002) loss 2.1012 (2.1892) teacher_loss 0.7676 (0.7903) loss_zs_kd 1.5752 (1.6046) loss_oracle 0.8843 (0.9014) acc 71.8750 (73.2701) lr 1.5878e-03 eta 0:19:35
epoch [17/50] batch [300/403] time 0.081 (0.087) data 0.000 (0.002) loss 2.1641 (2.1925) teacher_loss 0.7512 (0.7936) loss_zs_kd 1.5272 (1.5990) loss_oracle 0.9157 (0.9023) acc 68.7500 (73.0625) lr 1.5878e-03 eta 0:19:21
epoch [17/50] batch [320/403] time 0.084 (0.086) data 0.000 (0.002) loss 2.1438 (2.1901) teacher_loss 0.7311 (0.7914) loss_zs_kd 1.5100 (1.5987) loss_oracle 0.9615 (0.9035) acc 71.8750 (73.1934) lr 1.5878e-03 eta 0:19:16
epoch [17/50] batch [340/403] time 0.081 (0.086) data 0.000 (0.002) loss 2.1961 (2.1905) teacher_loss 0.7413 (0.7916) loss_zs_kd 1.4210 (1.5963) loss_oracle 0.9003 (0.9030) acc 71.8750 (73.2077) lr 1.5878e-03 eta 0:19:11
epoch [17/50] batch [360/403] time 0.092 (0.086) data 0.000 (0.002) loss 2.1484 (2.1909) teacher_loss 0.6547 (0.7915) loss_zs_kd 1.6320 (1.6010) loss_oracle 0.8542 (0.9024) acc 75.0000 (73.2639) lr 1.5878e-03 eta 0:19:07
epoch [17/50] batch [380/403] time 0.082 (0.086) data 0.000 (0.002) loss 2.3969 (2.1896) teacher_loss 0.9280 (0.7920) loss_zs_kd 1.4222 (1.5984) loss_oracle 0.8510 (0.8995) acc 75.0000 (73.2812) lr 1.5878e-03 eta 0:19:03
epoch [17/50] batch [400/403] time 0.082 (0.085) data 0.000 (0.002) loss 2.3033 (2.1933) teacher_loss 0.8750 (0.7960) loss_zs_kd 1.8219 (1.6004) loss_oracle 0.9314 (0.8989) acc 68.7500 (73.0078) lr 1.5878e-03 eta 0:18:56
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,886
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 57.0%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,292
* accuracy: 39.0%
* error: 61.0%
* macro_f1: 27.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     39.0%, epoch: 17 *******
epoch [18/50] batch [20/403] time 0.078 (0.114) data 0.000 (0.032) loss 2.1633 (2.1648) teacher_loss 0.8498 (0.8120) loss_zs_kd 1.3287 (1.5542) loss_oracle 0.8906 (0.8829) acc 71.8750 (72.3438) lr 1.5358e-03 eta 0:25:15
epoch [18/50] batch [40/403] time 0.086 (0.106) data 0.000 (0.016) loss 2.1490 (2.2083) teacher_loss 0.7585 (0.8290) loss_zs_kd 1.6641 (1.5979) loss_oracle 0.8960 (0.9026) acc 71.8750 (71.4062) lr 1.5358e-03 eta 0:23:26
epoch [18/50] batch [60/403] time 0.092 (0.099) data 0.001 (0.011) loss 2.1708 (2.2037) teacher_loss 0.8024 (0.8249) loss_zs_kd 1.4361 (1.5777) loss_oracle 0.8747 (0.8975) acc 78.1250 (72.1354) lr 1.5358e-03 eta 0:21:44
epoch [18/50] batch [80/403] time 0.084 (0.095) data 0.000 (0.008) loss 2.3976 (2.2308) teacher_loss 0.8907 (0.8251) loss_zs_kd 1.5989 (1.5858) loss_oracle 0.9823 (0.9199) acc 71.8750 (71.6016) lr 1.5358e-03 eta 0:21:00
epoch [18/50] batch [100/403] time 0.086 (0.093) data 0.000 (0.007) loss 2.1260 (2.2290) teacher_loss 0.7890 (0.8282) loss_zs_kd 1.7509 (1.5945) loss_oracle 0.8225 (0.9155) acc 78.1250 (71.4062) lr 1.5358e-03 eta 0:20:32
epoch [18/50] batch [120/403] time 0.077 (0.091) data 0.000 (0.006) loss 2.0565 (2.2175) teacher_loss 0.5866 (0.8205) loss_zs_kd 1.7793 (1.6212) loss_oracle 0.8569 (0.9118) acc 90.6250 (72.0052) lr 1.5358e-03 eta 0:20:03
epoch [18/50] batch [140/403] time 0.083 (0.090) data 0.000 (0.005) loss 2.2189 (2.2171) teacher_loss 0.7258 (0.8194) loss_zs_kd 1.4680 (1.6200) loss_oracle 0.9995 (0.9083) acc 78.1250 (71.9866) lr 1.5358e-03 eta 0:19:43
epoch [18/50] batch [160/403] time 0.080 (0.089) data 0.000 (0.004) loss 2.3908 (2.2188) teacher_loss 0.9886 (0.8199) loss_zs_kd 1.8495 (1.6473) loss_oracle 0.8833 (0.9081) acc 62.5000 (71.8359) lr 1.5358e-03 eta 0:19:34
epoch [18/50] batch [180/403] time 0.068 (0.088) data 0.000 (0.004) loss 2.3021 (2.2175) teacher_loss 0.9331 (0.8196) loss_zs_kd 1.6554 (1.6517) loss_oracle 0.9054 (0.9056) acc 71.8750 (71.8576) lr 1.5358e-03 eta 0:19:20
epoch [18/50] batch [200/403] time 0.072 (0.087) data 0.000 (0.003) loss 2.0711 (2.2238) teacher_loss 0.5097 (0.8216) loss_zs_kd 1.5656 (1.6516) loss_oracle 1.0104 (0.9057) acc 78.1250 (71.7656) lr 1.5358e-03 eta 0:19:04
epoch [18/50] batch [220/403] time 0.083 (0.086) data 0.000 (0.003) loss 2.0524 (2.2244) teacher_loss 0.6586 (0.8182) loss_zs_kd 1.5878 (1.6446) loss_oracle 0.9458 (0.9050) acc 68.7500 (72.0312) lr 1.5358e-03 eta 0:18:49
epoch [18/50] batch [240/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.7474 (2.2191) teacher_loss 0.5408 (0.8115) loss_zs_kd 1.3990 (1.6402) loss_oracle 0.8262 (0.9057) acc 81.2500 (72.3698) lr 1.5358e-03 eta 0:18:42
epoch [18/50] batch [260/403] time 0.085 (0.086) data 0.000 (0.003) loss 2.1815 (2.2282) teacher_loss 0.8172 (0.8176) loss_zs_kd 1.6440 (1.6380) loss_oracle 0.8704 (0.9076) acc 78.1250 (72.3438) lr 1.5358e-03 eta 0:18:40
epoch [18/50] batch [280/403] time 0.083 (0.086) data 0.000 (0.003) loss 2.1150 (2.2225) teacher_loss 0.7784 (0.8118) loss_zs_kd 1.1536 (1.6292) loss_oracle 0.8572 (0.9059) acc 71.8750 (72.5446) lr 1.5358e-03 eta 0:18:35
epoch [18/50] batch [300/403] time 0.088 (0.085) data 0.000 (0.002) loss 2.2689 (2.2179) teacher_loss 0.8299 (0.8101) loss_zs_kd 1.5903 (1.6239) loss_oracle 0.9292 (0.9029) acc 65.6250 (72.5729) lr 1.5358e-03 eta 0:18:28
epoch [18/50] batch [320/403] time 0.064 (0.084) data 0.000 (0.002) loss 2.2768 (2.2193) teacher_loss 0.9584 (0.8128) loss_zs_kd 1.5341 (1.6212) loss_oracle 0.8713 (0.9025) acc 75.0000 (72.4414) lr 1.5358e-03 eta 0:18:13
epoch [18/50] batch [340/403] time 0.079 (0.083) data 0.000 (0.002) loss 2.6514 (2.2180) teacher_loss 1.2598 (0.8126) loss_zs_kd 1.8723 (1.6236) loss_oracle 0.8542 (0.9029) acc 62.5000 (72.4173) lr 1.5358e-03 eta 0:18:00
epoch [18/50] batch [360/403] time 0.093 (0.083) data 0.000 (0.002) loss 2.2669 (2.2133) teacher_loss 0.8416 (0.8085) loss_zs_kd 1.8253 (1.6246) loss_oracle 0.9305 (0.9035) acc 65.6250 (72.5174) lr 1.5358e-03 eta 0:17:57
epoch [18/50] batch [380/403] time 0.080 (0.083) data 0.000 (0.002) loss 2.2163 (2.2139) teacher_loss 0.8559 (0.8094) loss_zs_kd 1.6892 (1.6306) loss_oracle 0.8071 (0.9035) acc 62.5000 (72.5000) lr 1.5358e-03 eta 0:17:55
epoch [18/50] batch [400/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.1217 (2.2118) teacher_loss 0.7484 (0.8066) loss_zs_kd 1.6318 (1.6351) loss_oracle 0.8878 (0.9036) acc 81.2500 (72.5469) lr 1.5358e-03 eta 0:17:51
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,845
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 54.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,262
* accuracy: 38.4%
* error: 61.6%
* macro_f1: 27.5%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     39.0%, epoch: 17 *******
epoch [19/50] batch [20/403] time 0.083 (0.119) data 0.000 (0.030) loss 2.1581 (2.2397) teacher_loss 0.8058 (0.8634) loss_zs_kd 1.4911 (1.6411) loss_oracle 0.8863 (0.8909) acc 81.2500 (70.7812) lr 1.4818e-03 eta 0:25:29
epoch [19/50] batch [40/403] time 0.085 (0.102) data 0.000 (0.015) loss 2.0338 (2.2223) teacher_loss 0.7119 (0.8550) loss_zs_kd 1.6531 (1.6483) loss_oracle 0.8911 (0.8890) acc 71.8750 (71.2500) lr 1.4818e-03 eta 0:21:54
epoch [19/50] batch [60/403] time 0.082 (0.094) data 0.000 (0.010) loss 1.9500 (2.1791) teacher_loss 0.6995 (0.8139) loss_zs_kd 1.7165 (1.6435) loss_oracle 0.8930 (0.8983) acc 75.0000 (72.4479) lr 1.4818e-03 eta 0:20:12
epoch [19/50] batch [80/403] time 0.075 (0.091) data 0.000 (0.008) loss 1.9792 (2.1568) teacher_loss 0.6221 (0.7946) loss_zs_kd 1.2801 (1.6306) loss_oracle 0.9149 (0.9013) acc 81.2500 (72.7344) lr 1.4818e-03 eta 0:19:27
epoch [19/50] batch [100/403] time 0.078 (0.089) data 0.001 (0.006) loss 1.9963 (2.1720) teacher_loss 0.6130 (0.8036) loss_zs_kd 2.2723 (1.6207) loss_oracle 0.9703 (0.9055) acc 84.3750 (72.4375) lr 1.4818e-03 eta 0:18:57
epoch [19/50] batch [120/403] time 0.070 (0.087) data 0.000 (0.005) loss 2.2218 (2.1832) teacher_loss 0.7530 (0.8074) loss_zs_kd 2.0379 (1.6363) loss_oracle 0.9252 (0.9093) acc 78.1250 (72.2396) lr 1.4818e-03 eta 0:18:32
epoch [19/50] batch [140/403] time 0.080 (0.086) data 0.000 (0.005) loss 2.2561 (2.1805) teacher_loss 0.9323 (0.8022) loss_zs_kd 2.2020 (1.6357) loss_oracle 0.8187 (0.9094) acc 59.3750 (72.1429) lr 1.4818e-03 eta 0:18:15
epoch [19/50] batch [160/403] time 0.070 (0.085) data 0.000 (0.004) loss 2.2533 (2.1726) teacher_loss 0.9258 (0.7954) loss_zs_kd 1.1779 (1.6185) loss_oracle 0.8796 (0.9069) acc 68.7500 (72.7344) lr 1.4818e-03 eta 0:17:58
epoch [19/50] batch [180/403] time 0.086 (0.085) data 0.000 (0.004) loss 2.3270 (2.1626) teacher_loss 0.8638 (0.7889) loss_zs_kd 1.3116 (1.6114) loss_oracle 0.8676 (0.9061) acc 78.1250 (73.0035) lr 1.4818e-03 eta 0:17:56
epoch [19/50] batch [200/403] time 0.082 (0.086) data 0.000 (0.003) loss 2.2910 (2.1609) teacher_loss 0.9430 (0.7900) loss_zs_kd 1.5773 (1.6003) loss_oracle 0.8614 (0.9026) acc 62.5000 (72.8125) lr 1.4818e-03 eta 0:18:17
epoch [19/50] batch [220/403] time 0.079 (0.086) data 0.000 (0.003) loss 2.0249 (2.1546) teacher_loss 0.7237 (0.7861) loss_zs_kd 1.4956 (1.5983) loss_oracle 0.8818 (0.9004) acc 78.1250 (72.9545) lr 1.4818e-03 eta 0:18:09
epoch [19/50] batch [240/403] time 0.076 (0.085) data 0.000 (0.003) loss 2.1870 (2.1687) teacher_loss 0.8733 (0.7992) loss_zs_kd 1.7148 (1.5931) loss_oracle 0.9012 (0.9019) acc 68.7500 (72.4740) lr 1.4818e-03 eta 0:18:01
epoch [19/50] batch [260/403] time 0.086 (0.085) data 0.000 (0.003) loss 2.1323 (2.1765) teacher_loss 0.7895 (0.8079) loss_zs_kd 2.0369 (1.5947) loss_oracle 0.8571 (0.9006) acc 71.8750 (72.1154) lr 1.4818e-03 eta 0:17:52
epoch [19/50] batch [280/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.1389 (2.1761) teacher_loss 0.8027 (0.8093) loss_zs_kd 1.0352 (1.5885) loss_oracle 0.8846 (0.8995) acc 78.1250 (72.2433) lr 1.4818e-03 eta 0:17:48
epoch [19/50] batch [300/403] time 0.074 (0.084) data 0.000 (0.002) loss 1.8700 (2.1700) teacher_loss 0.5388 (0.8049) loss_zs_kd 1.7569 (1.5883) loss_oracle 0.8672 (0.8973) acc 78.1250 (72.3854) lr 1.4818e-03 eta 0:17:43
epoch [19/50] batch [320/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.2658 (2.1718) teacher_loss 0.8252 (0.8066) loss_zs_kd 1.6401 (1.5838) loss_oracle 0.8997 (0.8971) acc 68.7500 (72.3047) lr 1.4818e-03 eta 0:17:37
epoch [19/50] batch [340/403] time 0.076 (0.084) data 0.000 (0.002) loss 2.1249 (2.1718) teacher_loss 0.8103 (0.8088) loss_zs_kd 1.3644 (1.5743) loss_oracle 0.7993 (0.8964) acc 68.7500 (72.1599) lr 1.4818e-03 eta 0:17:34
epoch [19/50] batch [360/403] time 0.071 (0.084) data 0.000 (0.002) loss 2.1827 (2.1722) teacher_loss 0.7388 (0.8103) loss_zs_kd 1.5063 (1.5617) loss_oracle 0.9787 (0.8966) acc 71.8750 (72.0833) lr 1.4818e-03 eta 0:17:27
epoch [19/50] batch [380/403] time 0.073 (0.083) data 0.000 (0.002) loss 2.1707 (2.1748) teacher_loss 0.8163 (0.8115) loss_zs_kd 1.5363 (1.5486) loss_oracle 0.8649 (0.8975) acc 75.0000 (72.1135) lr 1.4818e-03 eta 0:17:22
epoch [19/50] batch [400/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.3177 (2.1764) teacher_loss 0.9772 (0.8132) loss_zs_kd 1.7795 (1.5477) loss_oracle 0.9426 (0.8973) acc 68.7500 (72.0234) lr 1.4818e-03 eta 0:17:18
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,792
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 53.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,209
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 26.5%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     39.0%, epoch: 17 *******
epoch [20/50] batch [20/403] time 0.070 (0.111) data 0.000 (0.031) loss 2.2107 (2.2506) teacher_loss 0.9276 (0.8835) loss_zs_kd 1.8385 (1.6301) loss_oracle 0.8267 (0.8606) acc 71.8750 (68.5938) lr 1.4258e-03 eta 0:22:59
epoch [20/50] batch [40/403] time 0.073 (0.096) data 0.000 (0.015) loss 1.9455 (2.1814) teacher_loss 0.5909 (0.8168) loss_zs_kd 1.1331 (1.6225) loss_oracle 0.8772 (0.8627) acc 75.0000 (71.5625) lr 1.4258e-03 eta 0:19:55
epoch [20/50] batch [60/403] time 0.078 (0.090) data 0.000 (0.010) loss 2.0633 (2.1815) teacher_loss 0.7619 (0.8161) loss_zs_kd 1.6088 (1.6521) loss_oracle 0.8438 (0.8735) acc 68.7500 (72.1354) lr 1.4258e-03 eta 0:18:38
epoch [20/50] batch [80/403] time 0.079 (0.088) data 0.000 (0.008) loss 2.0863 (2.1665) teacher_loss 0.8192 (0.8032) loss_zs_kd 1.5293 (1.6360) loss_oracle 0.8399 (0.8738) acc 68.7500 (72.7344) lr 1.4258e-03 eta 0:18:17
epoch [20/50] batch [100/403] time 0.081 (0.087) data 0.000 (0.006) loss 2.3462 (2.1882) teacher_loss 0.9952 (0.8231) loss_zs_kd 1.8933 (1.6277) loss_oracle 0.8908 (0.8780) acc 53.1250 (72.1250) lr 1.4258e-03 eta 0:17:59
epoch [20/50] batch [120/403] time 0.085 (0.085) data 0.000 (0.005) loss 2.0425 (2.1826) teacher_loss 0.9043 (0.8206) loss_zs_kd 1.4026 (1.6067) loss_oracle 0.7370 (0.8781) acc 75.0000 (72.5260) lr 1.4258e-03 eta 0:17:34
epoch [20/50] batch [140/403] time 0.070 (0.085) data 0.000 (0.005) loss 2.4792 (2.1829) teacher_loss 1.0845 (0.8227) loss_zs_kd 2.4415 (1.6148) loss_oracle 0.8784 (0.8790) acc 65.6250 (72.5223) lr 1.4258e-03 eta 0:17:24
epoch [20/50] batch [160/403] time 0.086 (0.084) data 0.000 (0.004) loss 2.5775 (2.1807) teacher_loss 1.1787 (0.8232) loss_zs_kd 1.9539 (1.6281) loss_oracle 0.8779 (0.8820) acc 50.0000 (72.1680) lr 1.4258e-03 eta 0:17:16
epoch [20/50] batch [180/403] time 0.078 (0.083) data 0.000 (0.004) loss 1.9122 (2.1849) teacher_loss 0.5998 (0.8260) loss_zs_kd 1.4943 (1.6323) loss_oracle 0.8313 (0.8850) acc 87.5000 (72.2569) lr 1.4258e-03 eta 0:17:07
epoch [20/50] batch [200/403] time 0.078 (0.083) data 0.000 (0.003) loss 1.9292 (2.1816) teacher_loss 0.6729 (0.8249) loss_zs_kd 2.0335 (1.6414) loss_oracle 0.8984 (0.8870) acc 75.0000 (72.1406) lr 1.4258e-03 eta 0:17:04
epoch [20/50] batch [220/403] time 0.080 (0.083) data 0.000 (0.003) loss 2.4050 (2.1795) teacher_loss 1.0759 (0.8242) loss_zs_kd 1.6309 (1.6319) loss_oracle 0.8793 (0.8875) acc 65.6250 (72.1165) lr 1.4258e-03 eta 0:16:59
epoch [20/50] batch [240/403] time 0.079 (0.083) data 0.000 (0.003) loss 2.1794 (2.1773) teacher_loss 0.8451 (0.8211) loss_zs_kd 1.9053 (1.6312) loss_oracle 0.8525 (0.8886) acc 71.8750 (72.2005) lr 1.4258e-03 eta 0:16:58
epoch [20/50] batch [260/403] time 0.081 (0.083) data 0.000 (0.003) loss 2.2196 (2.1789) teacher_loss 0.8608 (0.8205) loss_zs_kd 1.1648 (1.6297) loss_oracle 0.8771 (0.8900) acc 65.6250 (72.1514) lr 1.4258e-03 eta 0:16:52
epoch [20/50] batch [280/403] time 0.080 (0.083) data 0.000 (0.002) loss 2.0671 (2.1793) teacher_loss 0.7998 (0.8195) loss_zs_kd 1.8436 (1.6277) loss_oracle 0.8824 (0.8925) acc 71.8750 (72.2321) lr 1.4258e-03 eta 0:16:48
epoch [20/50] batch [300/403] time 0.082 (0.083) data 0.000 (0.002) loss 1.8185 (2.1760) teacher_loss 0.5144 (0.8174) loss_zs_kd 2.0359 (1.6375) loss_oracle 0.8734 (0.8931) acc 81.2500 (72.2708) lr 1.4258e-03 eta 0:16:46
epoch [20/50] batch [320/403] time 0.073 (0.082) data 0.000 (0.002) loss 1.9467 (2.1712) teacher_loss 0.5863 (0.8129) loss_zs_kd 1.3980 (1.6448) loss_oracle 0.9235 (0.8946) acc 81.2500 (72.4805) lr 1.4258e-03 eta 0:16:42
epoch [20/50] batch [340/403] time 0.080 (0.082) data 0.000 (0.002) loss 2.1741 (2.1682) teacher_loss 0.7848 (0.8104) loss_zs_kd 1.6966 (1.6525) loss_oracle 0.9774 (0.8954) acc 68.7500 (72.5368) lr 1.4258e-03 eta 0:16:40
epoch [20/50] batch [360/403] time 0.089 (0.083) data 0.000 (0.002) loss 2.1108 (2.1656) teacher_loss 0.6740 (0.8071) loss_zs_kd 1.6185 (1.6509) loss_oracle 1.0530 (0.8962) acc 78.1250 (72.6128) lr 1.4258e-03 eta 0:16:41
epoch [20/50] batch [380/403] time 0.079 (0.083) data 0.000 (0.002) loss 2.2451 (2.1635) teacher_loss 0.9398 (0.8037) loss_zs_kd 1.1337 (1.6486) loss_oracle 0.8835 (0.8958) acc 71.8750 (72.7056) lr 1.4258e-03 eta 0:16:48
epoch [20/50] batch [400/403] time 0.083 (0.083) data 0.000 (0.002) loss 2.2995 (2.1659) teacher_loss 0.8696 (0.8061) loss_zs_kd 1.7774 (1.6490) loss_oracle 0.9353 (0.8953) acc 78.1250 (72.4688) lr 1.4258e-03 eta 0:16:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,773
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 55.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,275
* accuracy: 38.7%
* error: 61.3%
* macro_f1: 27.4%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     39.0%, epoch: 17 *******
epoch [21/50] batch [20/403] time 0.066 (0.109) data 0.001 (0.031) loss 2.1423 (2.1583) teacher_loss 0.8185 (0.7995) loss_zs_kd 1.8011 (1.6967) loss_oracle 0.8953 (0.8864) acc 78.1250 (72.5000) lr 1.3681e-03 eta 0:21:52
epoch [21/50] batch [40/403] time 0.065 (0.090) data 0.000 (0.016) loss 2.5268 (2.2144) teacher_loss 1.1428 (0.8510) loss_zs_kd 1.5523 (1.6897) loss_oracle 1.0019 (0.9073) acc 62.5000 (70.8594) lr 1.3681e-03 eta 0:17:59
epoch [21/50] batch [60/403] time 0.084 (0.085) data 0.000 (0.011) loss 2.1820 (2.2200) teacher_loss 0.7930 (0.8552) loss_zs_kd 1.6011 (1.6735) loss_oracle 0.9032 (0.9116) acc 68.7500 (70.1042) lr 1.3681e-03 eta 0:17:04
epoch [21/50] batch [80/403] time 0.086 (0.085) data 0.000 (0.008) loss 2.0129 (2.1945) teacher_loss 0.6808 (0.8287) loss_zs_kd 1.8196 (1.6633) loss_oracle 0.8620 (0.9115) acc 75.0000 (71.3672) lr 1.3681e-03 eta 0:17:02
epoch [21/50] batch [100/403] time 0.083 (0.084) data 0.000 (0.006) loss 1.8808 (2.1985) teacher_loss 0.5269 (0.8291) loss_zs_kd 1.3408 (1.6575) loss_oracle 0.8017 (0.9118) acc 81.2500 (71.5938) lr 1.3681e-03 eta 0:16:48
epoch [21/50] batch [120/403] time 0.081 (0.084) data 0.000 (0.005) loss 2.2385 (2.1908) teacher_loss 0.9716 (0.8281) loss_zs_kd 1.5170 (1.6533) loss_oracle 0.8401 (0.9051) acc 56.2500 (71.5885) lr 1.3681e-03 eta 0:16:50
epoch [21/50] batch [140/403] time 0.086 (0.086) data 0.000 (0.005) loss 2.1971 (2.2074) teacher_loss 0.8421 (0.8504) loss_zs_kd 1.1835 (1.6474) loss_oracle 0.8953 (0.8997) acc 65.6250 (70.8482) lr 1.3681e-03 eta 0:17:08
epoch [21/50] batch [160/403] time 0.083 (0.086) data 0.000 (0.004) loss 2.3502 (2.1984) teacher_loss 0.8595 (0.8451) loss_zs_kd 1.6352 (1.6354) loss_oracle 1.0153 (0.8989) acc 75.0000 (71.0938) lr 1.3681e-03 eta 0:17:06
epoch [21/50] batch [180/403] time 0.083 (0.085) data 0.000 (0.004) loss 2.2627 (2.1937) teacher_loss 0.8270 (0.8416) loss_zs_kd 1.5609 (1.6354) loss_oracle 0.8353 (0.8961) acc 65.6250 (71.2153) lr 1.3681e-03 eta 0:16:56
epoch [21/50] batch [200/403] time 0.091 (0.085) data 0.001 (0.003) loss 1.9892 (2.1733) teacher_loss 0.6430 (0.8293) loss_zs_kd 1.1533 (1.6273) loss_oracle 0.9009 (0.8917) acc 68.7500 (71.5781) lr 1.3681e-03 eta 0:16:55
epoch [21/50] batch [220/403] time 0.080 (0.085) data 0.000 (0.003) loss 1.9378 (2.1637) teacher_loss 0.7052 (0.8228) loss_zs_kd 1.4166 (1.6262) loss_oracle 0.8266 (0.8892) acc 75.0000 (71.9318) lr 1.3681e-03 eta 0:16:51
epoch [21/50] batch [240/403] time 0.083 (0.085) data 0.000 (0.003) loss 2.3428 (2.1671) teacher_loss 0.9083 (0.8265) loss_zs_kd 1.6215 (1.6192) loss_oracle 0.8892 (0.8872) acc 68.7500 (71.8620) lr 1.3681e-03 eta 0:16:50
epoch [21/50] batch [260/403] time 0.086 (0.085) data 0.000 (0.003) loss 1.9114 (2.1663) teacher_loss 0.5790 (0.8278) loss_zs_kd 1.5682 (1.6124) loss_oracle 0.8855 (0.8863) acc 71.8750 (71.8389) lr 1.3681e-03 eta 0:16:46
epoch [21/50] batch [280/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.3105 (2.1654) teacher_loss 0.8932 (0.8275) loss_zs_kd 1.2822 (1.6022) loss_oracle 0.9483 (0.8858) acc 59.3750 (71.7522) lr 1.3681e-03 eta 0:16:42
epoch [21/50] batch [300/403] time 0.090 (0.085) data 0.000 (0.002) loss 2.2592 (2.1593) teacher_loss 0.9748 (0.8249) loss_zs_kd 1.7689 (1.6013) loss_oracle 0.8862 (0.8845) acc 62.5000 (71.7083) lr 1.3681e-03 eta 0:16:37
epoch [21/50] batch [320/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.0245 (2.1591) teacher_loss 0.7586 (0.8284) loss_zs_kd 1.6102 (1.5941) loss_oracle 0.8525 (0.8834) acc 71.8750 (71.6797) lr 1.3681e-03 eta 0:16:33
epoch [21/50] batch [340/403] time 0.076 (0.084) data 0.000 (0.002) loss 2.1651 (2.1600) teacher_loss 0.8623 (0.8305) loss_zs_kd 1.9629 (1.5910) loss_oracle 0.8459 (0.8825) acc 71.8750 (71.4338) lr 1.3681e-03 eta 0:16:27
epoch [21/50] batch [360/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.2032 (2.1597) teacher_loss 0.9669 (0.8315) loss_zs_kd 1.4234 (1.5909) loss_oracle 0.8573 (0.8822) acc 75.0000 (71.3628) lr 1.3681e-03 eta 0:16:23
epoch [21/50] batch [380/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.4732 (2.1665) teacher_loss 1.1250 (0.8368) loss_zs_kd 1.8326 (1.6008) loss_oracle 0.9064 (0.8832) acc 68.7500 (71.2582) lr 1.3681e-03 eta 0:16:18
epoch [21/50] batch [400/403] time 0.068 (0.083) data 0.000 (0.002) loss 2.1351 (2.1690) teacher_loss 0.7072 (0.8376) loss_zs_kd 2.1000 (1.6027) loss_oracle 0.8528 (0.8837) acc 75.0000 (71.2500) lr 1.3681e-03 eta 0:16:12
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,865
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 55.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,308
* accuracy: 39.2%
* error: 60.8%
* macro_f1: 28.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 37.7%, epoch: 16 *******
******* Domain 4 best test acc:     39.2%, epoch: 21 *******
epoch [22/50] batch [20/403] time 0.084 (0.109) data 0.000 (0.024) loss 2.1865 (2.2149) teacher_loss 0.8761 (0.8668) loss_zs_kd 1.7091 (1.6136) loss_oracle 0.8078 (0.8913) acc 68.7500 (67.9688) lr 1.3090e-03 eta 0:21:11
epoch [22/50] batch [40/403] time 0.079 (0.096) data 0.000 (0.012) loss 2.5373 (2.1916) teacher_loss 1.2385 (0.8563) loss_zs_kd 1.8366 (1.6227) loss_oracle 0.8334 (0.8774) acc 59.3750 (68.6719) lr 1.3090e-03 eta 0:18:33
epoch [22/50] batch [60/403] time 0.086 (0.092) data 0.000 (0.008) loss 2.1991 (2.2102) teacher_loss 0.7418 (0.8599) loss_zs_kd 2.0041 (1.6240) loss_oracle 0.8660 (0.8770) acc 78.1250 (68.7500) lr 1.3090e-03 eta 0:17:48
epoch [22/50] batch [80/403] time 0.090 (0.091) data 0.000 (0.006) loss 2.2975 (2.2194) teacher_loss 0.8686 (0.8571) loss_zs_kd 1.4340 (1.6188) loss_oracle 0.9564 (0.8882) acc 65.6250 (69.2188) lr 1.3090e-03 eta 0:17:36
epoch [22/50] batch [100/403] time 0.076 (0.088) data 0.000 (0.005) loss 2.0536 (2.2127) teacher_loss 0.7013 (0.8415) loss_zs_kd 1.5827 (1.5925) loss_oracle 0.8666 (0.8920) acc 75.0000 (69.7188) lr 1.3090e-03 eta 0:17:02
epoch [22/50] batch [120/403] time 0.078 (0.087) data 0.000 (0.004) loss 2.0915 (2.1937) teacher_loss 0.7714 (0.8254) loss_zs_kd 1.6285 (1.5945) loss_oracle 0.9301 (0.8943) acc 65.6250 (70.2604) lr 1.3090e-03 eta 0:16:43
epoch [22/50] batch [140/403] time 0.080 (0.086) data 0.000 (0.004) loss 2.3553 (2.1955) teacher_loss 0.9564 (0.8258) loss_zs_kd 1.5206 (1.6056) loss_oracle 0.8911 (0.8955) acc 71.8750 (70.3348) lr 1.3090e-03 eta 0:16:30
epoch [22/50] batch [160/403] time 0.076 (0.086) data 0.000 (0.003) loss 1.9175 (2.1905) teacher_loss 0.5333 (0.8239) loss_zs_kd 1.6714 (1.6072) loss_oracle 0.9238 (0.8950) acc 81.2500 (70.4883) lr 1.3090e-03 eta 0:16:27
epoch [22/50] batch [180/403] time 0.082 (0.085) data 0.000 (0.003) loss 2.3219 (2.1887) teacher_loss 0.9705 (0.8257) loss_zs_kd 1.2964 (1.6082) loss_oracle 0.8239 (0.8940) acc 71.8750 (70.5729) lr 1.3090e-03 eta 0:16:12
epoch [22/50] batch [200/403] time 0.074 (0.084) data 0.000 (0.003) loss 2.7463 (2.1942) teacher_loss 1.1701 (0.8281) loss_zs_kd 1.9191 (1.6186) loss_oracle 1.0075 (0.8947) acc 56.2500 (70.5938) lr 1.3090e-03 eta 0:16:07
epoch [22/50] batch [220/403] time 0.071 (0.083) data 0.000 (0.002) loss 2.1095 (2.1956) teacher_loss 0.7483 (0.8271) loss_zs_kd 1.3197 (1.6252) loss_oracle 0.8825 (0.8937) acc 78.1250 (70.6534) lr 1.3090e-03 eta 0:15:55
epoch [22/50] batch [240/403] time 0.057 (0.081) data 0.000 (0.002) loss 2.0833 (2.1960) teacher_loss 0.7041 (0.8267) loss_zs_kd 1.7578 (1.6248) loss_oracle 0.9180 (0.8946) acc 78.1250 (70.6901) lr 1.3090e-03 eta 0:15:32
epoch [22/50] batch [260/403] time 0.058 (0.080) data 0.000 (0.002) loss 1.7423 (2.1891) teacher_loss 0.4788 (0.8238) loss_zs_kd 1.6999 (1.6289) loss_oracle 0.8498 (0.8933) acc 87.5000 (70.9014) lr 1.3090e-03 eta 0:15:13
epoch [22/50] batch [280/403] time 0.064 (0.079) data 0.000 (0.002) loss 2.1662 (2.1871) teacher_loss 0.9146 (0.8263) loss_zs_kd 1.7224 (1.6267) loss_oracle 0.8366 (0.8931) acc 59.3750 (70.8036) lr 1.3090e-03 eta 0:14:59
epoch [22/50] batch [300/403] time 0.173 (0.080) data 0.001 (0.002) loss 1.6651 (2.1836) teacher_loss 0.3848 (0.8258) loss_zs_kd 1.6757 (1.6248) loss_oracle 0.8503 (0.8918) acc 84.3750 (70.9583) lr 1.3090e-03 eta 0:15:06
epoch [22/50] batch [320/403] time 0.073 (0.080) data 0.000 (0.002) loss 2.1213 (2.1806) teacher_loss 0.8142 (0.8258) loss_zs_kd 1.6342 (1.6182) loss_oracle 0.8816 (0.8921) acc 75.0000 (71.0645) lr 1.3090e-03 eta 0:15:08
epoch [22/50] batch [340/403] time 0.084 (0.080) data 0.000 (0.002) loss 2.2534 (2.1805) teacher_loss 0.9164 (0.8267) loss_zs_kd 1.6052 (1.6208) loss_oracle 0.8579 (0.8916) acc 71.8750 (71.0570) lr 1.3090e-03 eta 0:15:06
epoch [22/50] batch [360/403] time 0.072 (0.080) data 0.000 (0.002) loss 2.0952 (2.1836) teacher_loss 0.7434 (0.8317) loss_zs_kd 2.0233 (1.6247) loss_oracle 0.9625 (0.8911) acc 78.1250 (70.8420) lr 1.3090e-03 eta 0:15:00
epoch [22/50] batch [380/403] time 0.060 (0.079) data 0.000 (0.002) loss 1.7745 (2.1843) teacher_loss 0.4578 (0.8328) loss_zs_kd 1.4833 (1.6255) loss_oracle 0.8926 (0.8914) acc 84.3750 (70.8717) lr 1.3090e-03 eta 0:14:57
epoch [22/50] batch [400/403] time 0.083 (0.079) data 0.000 (0.001) loss 1.7579 (2.1831) teacher_loss 0.4458 (0.8311) loss_zs_kd 1.6244 (1.6229) loss_oracle 0.9268 (0.8923) acc 84.3750 (70.9688) lr 1.3090e-03 eta 0:14:56
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,931
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 57.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,376
* accuracy: 40.4%
* error: 59.6%
* macro_f1: 29.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.0%, epoch: 22 *******
******* Domain 4 best val test acc: 40.4%, epoch: 22 *******
******* Domain 4 best test acc:     40.4%, epoch: 22 *******
epoch [23/50] batch [20/403] time 0.073 (0.118) data 0.000 (0.031) loss 1.7902 (2.1632) teacher_loss 0.4762 (0.7965) loss_zs_kd 1.6955 (1.7008) loss_oracle 0.9364 (0.9104) acc 87.5000 (72.0312) lr 1.2487e-03 eta 0:22:04
epoch [23/50] batch [40/403] time 0.088 (0.100) data 0.000 (0.016) loss 1.7674 (2.1728) teacher_loss 0.5317 (0.8136) loss_zs_kd 1.6879 (1.7401) loss_oracle 0.8362 (0.8971) acc 87.5000 (71.6406) lr 1.2487e-03 eta 0:18:43
epoch [23/50] batch [60/403] time 0.077 (0.099) data 0.000 (0.011) loss 2.1148 (2.1739) teacher_loss 0.8841 (0.8155) loss_zs_kd 1.3896 (1.7235) loss_oracle 0.8754 (0.9000) acc 75.0000 (71.6146) lr 1.2487e-03 eta 0:18:31
epoch [23/50] batch [80/403] time 0.083 (0.095) data 0.000 (0.008) loss 2.2345 (2.1611) teacher_loss 0.8335 (0.8057) loss_zs_kd 1.6626 (1.7158) loss_oracle 0.8976 (0.8970) acc 71.8750 (71.6406) lr 1.2487e-03 eta 0:17:39
epoch [23/50] batch [100/403] time 0.077 (0.092) data 0.000 (0.006) loss 1.8924 (2.1589) teacher_loss 0.6069 (0.8000) loss_zs_kd 1.5154 (1.7148) loss_oracle 0.8196 (0.8994) acc 81.2500 (72.2188) lr 1.2487e-03 eta 0:17:13
epoch [23/50] batch [120/403] time 0.077 (0.090) data 0.000 (0.005) loss 2.2334 (2.1661) teacher_loss 0.9049 (0.8074) loss_zs_kd 1.7090 (1.7203) loss_oracle 0.8470 (0.8990) acc 71.8750 (71.7448) lr 1.2487e-03 eta 0:16:49
epoch [23/50] batch [140/403] time 0.080 (0.089) data 0.000 (0.005) loss 2.1136 (2.1755) teacher_loss 0.7643 (0.8139) loss_zs_kd 1.8758 (1.7068) loss_oracle 0.9336 (0.8992) acc 75.0000 (71.8750) lr 1.2487e-03 eta 0:16:35
epoch [23/50] batch [160/403] time 0.073 (0.088) data 0.000 (0.004) loss 2.0588 (2.1724) teacher_loss 0.6187 (0.8128) loss_zs_kd 1.6691 (1.7027) loss_oracle 0.8812 (0.8968) acc 81.2500 (72.0117) lr 1.2487e-03 eta 0:16:13
epoch [23/50] batch [180/403] time 0.079 (0.087) data 0.000 (0.004) loss 1.9939 (2.1778) teacher_loss 0.7153 (0.8192) loss_zs_kd 1.9586 (1.6849) loss_oracle 0.8982 (0.8965) acc 68.7500 (71.7535) lr 1.2487e-03 eta 0:16:06
epoch [23/50] batch [200/403] time 0.089 (0.087) data 0.000 (0.003) loss 2.1721 (2.1784) teacher_loss 0.6968 (0.8184) loss_zs_kd 2.0018 (1.6740) loss_oracle 0.9103 (0.8961) acc 75.0000 (71.7969) lr 1.2487e-03 eta 0:16:01
epoch [23/50] batch [220/403] time 0.087 (0.086) data 0.000 (0.003) loss 1.9675 (2.1770) teacher_loss 0.6794 (0.8187) loss_zs_kd 1.7467 (1.6644) loss_oracle 0.9048 (0.8966) acc 87.5000 (71.8750) lr 1.2487e-03 eta 0:15:55
epoch [23/50] batch [240/403] time 0.080 (0.086) data 0.000 (0.003) loss 1.8426 (2.1657) teacher_loss 0.5429 (0.8104) loss_zs_kd 1.5153 (1.6576) loss_oracle 0.8904 (0.8933) acc 75.0000 (72.1094) lr 1.2487e-03 eta 0:15:48
epoch [23/50] batch [260/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.9941 (2.1619) teacher_loss 0.7500 (0.8085) loss_zs_kd 1.4499 (1.6633) loss_oracle 0.8780 (0.8921) acc 71.8750 (72.0913) lr 1.2487e-03 eta 0:15:39
epoch [23/50] batch [280/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.0491 (2.1618) teacher_loss 0.7250 (0.8106) loss_zs_kd 1.6393 (1.6572) loss_oracle 0.9183 (0.8900) acc 78.1250 (72.0759) lr 1.2487e-03 eta 0:15:33
epoch [23/50] batch [300/403] time 0.087 (0.085) data 0.000 (0.002) loss 1.8113 (2.1610) teacher_loss 0.5137 (0.8111) loss_zs_kd 2.0228 (1.6581) loss_oracle 0.8332 (0.8895) acc 87.5000 (71.9271) lr 1.2487e-03 eta 0:15:33
epoch [23/50] batch [320/403] time 0.083 (0.085) data 0.000 (0.002) loss 2.5074 (2.1592) teacher_loss 1.1081 (0.8084) loss_zs_kd 1.4289 (1.6567) loss_oracle 0.9341 (0.8906) acc 50.0000 (71.9434) lr 1.2487e-03 eta 0:15:30
epoch [23/50] batch [340/403] time 0.073 (0.085) data 0.000 (0.002) loss 1.9431 (2.1609) teacher_loss 0.6420 (0.8114) loss_zs_kd 1.7658 (1.6618) loss_oracle 0.9052 (0.8907) acc 81.2500 (71.9577) lr 1.2487e-03 eta 0:15:25
epoch [23/50] batch [360/403] time 0.071 (0.084) data 0.000 (0.002) loss 1.8594 (2.1612) teacher_loss 0.5741 (0.8111) loss_zs_kd 1.6561 (1.6596) loss_oracle 0.9123 (0.8906) acc 78.1250 (71.9878) lr 1.2487e-03 eta 0:15:21
epoch [23/50] batch [380/403] time 0.078 (0.084) data 0.000 (0.002) loss 2.1760 (2.1602) teacher_loss 0.7224 (0.8100) loss_zs_kd 1.4057 (1.6544) loss_oracle 0.9180 (0.8910) acc 71.8750 (72.1382) lr 1.2487e-03 eta 0:15:17
epoch [23/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.002) loss 2.1999 (2.1619) teacher_loss 0.8219 (0.8118) loss_zs_kd 1.6853 (1.6457) loss_oracle 0.8546 (0.8902) acc 71.8750 (72.0625) lr 1.2487e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,934
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 57.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,422
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 30.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.1%, epoch: 23 *******
******* Domain 4 best val test acc: 41.2%, epoch: 23 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [24/50] batch [20/403] time 0.074 (0.112) data 0.000 (0.028) loss 2.1058 (2.1548) teacher_loss 0.7739 (0.8171) loss_zs_kd 1.8247 (1.5269) loss_oracle 0.8453 (0.8787) acc 75.0000 (70.1562) lr 1.1874e-03 eta 0:20:19
epoch [24/50] batch [40/403] time 0.072 (0.095) data 0.000 (0.014) loss 1.8745 (2.1409) teacher_loss 0.5760 (0.8002) loss_zs_kd 1.2868 (1.4949) loss_oracle 0.8148 (0.8748) acc 75.0000 (71.0156) lr 1.1874e-03 eta 0:17:13
epoch [24/50] batch [60/403] time 0.078 (0.091) data 0.000 (0.009) loss 2.2365 (2.1347) teacher_loss 0.8507 (0.7953) loss_zs_kd 1.2999 (1.5385) loss_oracle 0.8697 (0.8732) acc 75.0000 (71.9792) lr 1.1874e-03 eta 0:16:21
epoch [24/50] batch [80/403] time 0.087 (0.088) data 0.000 (0.007) loss 2.5425 (2.1408) teacher_loss 1.2263 (0.8060) loss_zs_kd 1.8049 (1.5449) loss_oracle 0.8689 (0.8704) acc 53.1250 (71.2500) lr 1.1874e-03 eta 0:15:51
epoch [24/50] batch [100/403] time 0.086 (0.088) data 0.000 (0.006) loss 2.2279 (2.1378) teacher_loss 0.7620 (0.7984) loss_zs_kd 1.2959 (1.5298) loss_oracle 0.8797 (0.8692) acc 78.1250 (71.7812) lr 1.1874e-03 eta 0:15:44
epoch [24/50] batch [120/403] time 0.082 (0.087) data 0.000 (0.005) loss 1.9975 (2.1375) teacher_loss 0.6205 (0.7956) loss_zs_kd 1.7437 (1.5224) loss_oracle 0.8810 (0.8680) acc 81.2500 (71.6667) lr 1.1874e-03 eta 0:15:32
epoch [24/50] batch [140/403] time 0.071 (0.086) data 0.000 (0.004) loss 2.1807 (2.1297) teacher_loss 0.8287 (0.7895) loss_zs_kd 2.0272 (1.5466) loss_oracle 0.8647 (0.8673) acc 68.7500 (71.7857) lr 1.1874e-03 eta 0:15:19
epoch [24/50] batch [160/403] time 0.080 (0.084) data 0.000 (0.004) loss 2.0888 (2.1221) teacher_loss 0.7889 (0.7857) loss_zs_kd 1.7208 (1.5624) loss_oracle 0.9293 (0.8684) acc 71.8750 (72.2266) lr 1.1874e-03 eta 0:15:05
epoch [24/50] batch [180/403] time 0.083 (0.084) data 0.000 (0.003) loss 2.2652 (2.1303) teacher_loss 0.9166 (0.7919) loss_zs_kd 1.8352 (1.5721) loss_oracle 0.8223 (0.8707) acc 68.7500 (71.8403) lr 1.1874e-03 eta 0:15:03
epoch [24/50] batch [200/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.1512 (2.1251) teacher_loss 0.8277 (0.7861) loss_zs_kd 1.9526 (1.5814) loss_oracle 0.8550 (0.8714) acc 71.8750 (72.0625) lr 1.1874e-03 eta 0:14:59
epoch [24/50] batch [220/403] time 0.078 (0.085) data 0.000 (0.003) loss 2.0899 (2.1355) teacher_loss 0.7975 (0.7944) loss_zs_kd 1.7226 (1.5930) loss_oracle 0.8741 (0.8726) acc 71.8750 (71.7898) lr 1.1874e-03 eta 0:15:06
epoch [24/50] batch [240/403] time 0.086 (0.085) data 0.001 (0.003) loss 1.7740 (2.1293) teacher_loss 0.4745 (0.7886) loss_zs_kd 1.3283 (1.6063) loss_oracle 0.8772 (0.8737) acc 84.3750 (72.0573) lr 1.1874e-03 eta 0:15:00
epoch [24/50] batch [260/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.4482 (2.1289) teacher_loss 1.0497 (0.7895) loss_zs_kd 1.8254 (1.6126) loss_oracle 0.8674 (0.8748) acc 59.3750 (72.0553) lr 1.1874e-03 eta 0:14:58
epoch [24/50] batch [280/403] time 0.087 (0.085) data 0.000 (0.002) loss 2.3086 (2.1304) teacher_loss 0.8649 (0.7891) loss_zs_kd 1.8840 (1.6199) loss_oracle 1.0582 (0.8775) acc 65.6250 (72.1763) lr 1.1874e-03 eta 0:14:56
epoch [24/50] batch [300/403] time 0.083 (0.085) data 0.000 (0.002) loss 2.0884 (2.1369) teacher_loss 0.6885 (0.7929) loss_zs_kd 1.6812 (1.6329) loss_oracle 0.9458 (0.8805) acc 68.7500 (72.0729) lr 1.1874e-03 eta 0:14:55
epoch [24/50] batch [320/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.4881 (2.1387) teacher_loss 1.1894 (0.7951) loss_zs_kd 1.7895 (1.6455) loss_oracle 0.8045 (0.8788) acc 65.6250 (72.0605) lr 1.1874e-03 eta 0:14:55
epoch [24/50] batch [340/403] time 0.082 (0.085) data 0.000 (0.002) loss 2.1150 (2.1386) teacher_loss 0.6921 (0.7947) loss_zs_kd 2.0284 (1.6594) loss_oracle 0.9579 (0.8789) acc 75.0000 (72.0864) lr 1.1874e-03 eta 0:14:53
epoch [24/50] batch [360/403] time 0.089 (0.085) data 0.000 (0.002) loss 2.0406 (2.1413) teacher_loss 0.7445 (0.7972) loss_zs_kd 1.5967 (1.6625) loss_oracle 0.9006 (0.8800) acc 81.2500 (71.9705) lr 1.1874e-03 eta 0:14:50
epoch [24/50] batch [380/403] time 0.090 (0.085) data 0.000 (0.002) loss 2.1281 (2.1413) teacher_loss 0.8434 (0.7977) loss_zs_kd 1.7050 (1.6610) loss_oracle 0.7999 (0.8794) acc 71.8750 (71.9490) lr 1.1874e-03 eta 0:14:48
epoch [24/50] batch [400/403] time 0.077 (0.084) data 0.001 (0.002) loss 2.1934 (2.1458) teacher_loss 0.8057 (0.8016) loss_zs_kd 1.2385 (1.6638) loss_oracle 0.9097 (0.8810) acc 68.7500 (71.8359) lr 1.1874e-03 eta 0:14:43
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,829
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 55.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,258
* accuracy: 38.4%
* error: 61.6%
* macro_f1: 28.4%
******* Domain 4 best val acc:      71.1%, epoch: 23 *******
******* Domain 4 best val test acc: 41.2%, epoch: 23 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [25/50] batch [20/403] time 0.079 (0.113) data 0.000 (0.033) loss 2.0232 (2.1862) teacher_loss 0.6726 (0.8304) loss_zs_kd 1.6493 (1.6227) loss_oracle 0.8868 (0.8743) acc 81.2500 (71.4062) lr 1.1253e-03 eta 0:19:40
epoch [25/50] batch [40/403] time 0.078 (0.095) data 0.000 (0.016) loss 1.9967 (2.2158) teacher_loss 0.6556 (0.8575) loss_zs_kd 1.4496 (1.6254) loss_oracle 0.8635 (0.8790) acc 75.0000 (70.2344) lr 1.1253e-03 eta 0:16:32
epoch [25/50] batch [60/403] time 0.085 (0.089) data 0.000 (0.011) loss 2.3808 (2.1960) teacher_loss 1.0435 (0.8444) loss_zs_kd 1.6630 (1.6304) loss_oracle 0.8629 (0.8825) acc 71.8750 (70.6250) lr 1.1253e-03 eta 0:15:28
epoch [25/50] batch [80/403] time 0.086 (0.088) data 0.000 (0.008) loss 2.3098 (2.1900) teacher_loss 0.9387 (0.8411) loss_zs_kd 1.1751 (1.6433) loss_oracle 0.8331 (0.8832) acc 65.6250 (70.3906) lr 1.1253e-03 eta 0:15:16
epoch [25/50] batch [100/403] time 0.070 (0.086) data 0.000 (0.007) loss 1.8878 (2.1824) teacher_loss 0.6535 (0.8350) loss_zs_kd 1.5509 (1.6604) loss_oracle 0.9015 (0.8859) acc 81.2500 (70.5938) lr 1.1253e-03 eta 0:14:55
epoch [25/50] batch [120/403] time 0.073 (0.085) data 0.000 (0.006) loss 2.1150 (2.1658) teacher_loss 0.7545 (0.8202) loss_zs_kd 1.9372 (1.6733) loss_oracle 0.8825 (0.8835) acc 75.0000 (71.5365) lr 1.1253e-03 eta 0:14:44
epoch [25/50] batch [140/403] time 0.090 (0.085) data 0.000 (0.005) loss 1.9951 (2.1641) teacher_loss 0.6428 (0.8184) loss_zs_kd 1.8481 (1.6951) loss_oracle 0.8287 (0.8824) acc 81.2500 (71.3839) lr 1.1253e-03 eta 0:14:34
epoch [25/50] batch [160/403] time 0.097 (0.084) data 0.000 (0.004) loss 2.3857 (2.1622) teacher_loss 1.0726 (0.8174) loss_zs_kd 1.2843 (1.6881) loss_oracle 0.8629 (0.8820) acc 71.8750 (71.5234) lr 1.1253e-03 eta 0:14:30
epoch [25/50] batch [180/403] time 0.087 (0.085) data 0.000 (0.004) loss 2.1642 (2.1642) teacher_loss 0.9106 (0.8162) loss_zs_kd 1.6636 (1.6801) loss_oracle 0.8816 (0.8851) acc 62.5000 (71.6840) lr 1.1253e-03 eta 0:14:30
epoch [25/50] batch [200/403] time 0.074 (0.084) data 0.000 (0.003) loss 1.7618 (2.1727) teacher_loss 0.4790 (0.8195) loss_zs_kd 1.4807 (1.6764) loss_oracle 0.8601 (0.8900) acc 90.6250 (71.6094) lr 1.1253e-03 eta 0:14:26
epoch [25/50] batch [220/403] time 0.080 (0.084) data 0.000 (0.003) loss 2.8748 (2.1794) teacher_loss 1.5336 (0.8216) loss_zs_kd 1.4418 (1.6705) loss_oracle 0.8574 (0.8950) acc 40.6250 (71.7330) lr 1.1253e-03 eta 0:14:22
epoch [25/50] batch [240/403] time 0.087 (0.084) data 0.000 (0.003) loss 2.0282 (2.1787) teacher_loss 0.6337 (0.8187) loss_zs_kd 1.4446 (1.6723) loss_oracle 0.9294 (0.8975) acc 81.2500 (71.8750) lr 1.1253e-03 eta 0:14:19
epoch [25/50] batch [260/403] time 0.089 (0.084) data 0.000 (0.003) loss 2.1786 (2.1737) teacher_loss 0.7783 (0.8137) loss_zs_kd 1.8683 (1.6727) loss_oracle 0.9418 (0.8981) acc 78.1250 (72.2476) lr 1.1253e-03 eta 0:14:19
epoch [25/50] batch [280/403] time 0.074 (0.084) data 0.000 (0.003) loss 2.2428 (2.1701) teacher_loss 0.9175 (0.8118) loss_zs_kd 1.6875 (1.6775) loss_oracle 0.8287 (0.8969) acc 62.5000 (72.2545) lr 1.1253e-03 eta 0:14:13
epoch [25/50] batch [300/403] time 0.071 (0.083) data 0.000 (0.002) loss 2.1917 (2.1693) teacher_loss 0.9283 (0.8121) loss_zs_kd 1.8034 (1.6825) loss_oracle 0.8087 (0.8968) acc 65.6250 (72.1667) lr 1.1253e-03 eta 0:14:09
epoch [25/50] batch [320/403] time 0.087 (0.083) data 0.000 (0.002) loss 1.8520 (2.1675) teacher_loss 0.4676 (0.8119) loss_zs_kd 1.3405 (1.6829) loss_oracle 0.8629 (0.8956) acc 84.3750 (72.1191) lr 1.1253e-03 eta 0:14:07
epoch [25/50] batch [340/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.2072 (2.1670) teacher_loss 0.8762 (0.8115) loss_zs_kd 1.9307 (1.6807) loss_oracle 0.8972 (0.8960) acc 65.6250 (72.0772) lr 1.1253e-03 eta 0:14:07
epoch [25/50] batch [360/403] time 0.173 (0.084) data 0.000 (0.002) loss 2.1577 (2.1641) teacher_loss 0.7425 (0.8092) loss_zs_kd 2.2178 (1.6801) loss_oracle 0.8885 (0.8961) acc 71.8750 (72.0486) lr 1.1253e-03 eta 0:14:11
epoch [25/50] batch [380/403] time 0.076 (0.084) data 0.000 (0.002) loss 2.2445 (2.1644) teacher_loss 0.8997 (0.8086) loss_zs_kd 1.6377 (1.6756) loss_oracle 0.8666 (0.8967) acc 62.5000 (72.0559) lr 1.1253e-03 eta 0:14:12
epoch [25/50] batch [400/403] time 0.071 (0.084) data 0.000 (0.002) loss 2.1628 (2.1643) teacher_loss 0.8238 (0.8085) loss_zs_kd 1.7027 (1.6744) loss_oracle 0.9145 (0.8967) acc 78.1250 (72.0078) lr 1.1253e-03 eta 0:14:06
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,936
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 58.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,336
* accuracy: 39.7%
* error: 60.3%
* macro_f1: 29.3%
******* Domain 4 best val acc:      71.1%, epoch: 25 *******
******* Domain 4 best val test acc: 39.7%, epoch: 25 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [26/50] batch [20/403] time 0.077 (0.117) data 0.000 (0.031) loss 2.0312 (2.2246) teacher_loss 0.7158 (0.8522) loss_zs_kd 1.9720 (1.6788) loss_oracle 0.8713 (0.9285) acc 71.8750 (73.1250) lr 1.0628e-03 eta 0:19:41
epoch [26/50] batch [40/403] time 0.089 (0.101) data 0.000 (0.016) loss 1.8108 (2.2012) teacher_loss 0.5064 (0.8309) loss_zs_kd 1.5903 (1.6222) loss_oracle 0.8354 (0.9143) acc 81.2500 (72.1094) lr 1.0628e-03 eta 0:16:58
epoch [26/50] batch [60/403] time 0.093 (0.097) data 0.001 (0.010) loss 2.1243 (2.1941) teacher_loss 0.7272 (0.8180) loss_zs_kd 1.8067 (1.6666) loss_oracle 0.9171 (0.9167) acc 75.0000 (72.1875) lr 1.0628e-03 eta 0:16:07
epoch [26/50] batch [80/403] time 0.092 (0.094) data 0.000 (0.008) loss 2.1347 (2.1852) teacher_loss 0.7609 (0.8222) loss_zs_kd 1.9789 (1.6867) loss_oracle 0.8976 (0.9114) acc 75.0000 (72.1875) lr 1.0628e-03 eta 0:15:40
epoch [26/50] batch [100/403] time 0.137 (0.094) data 0.000 (0.006) loss 2.2019 (2.1801) teacher_loss 0.9008 (0.8182) loss_zs_kd 1.3438 (1.7185) loss_oracle 0.8707 (0.9064) acc 62.5000 (72.5938) lr 1.0628e-03 eta 0:15:39
epoch [26/50] batch [120/403] time 0.085 (0.093) data 0.000 (0.005) loss 2.3889 (2.1773) teacher_loss 1.0503 (0.8176) loss_zs_kd 1.9529 (1.7464) loss_oracle 0.8659 (0.9038) acc 62.5000 (72.2135) lr 1.0628e-03 eta 0:15:26
epoch [26/50] batch [140/403] time 0.080 (0.092) data 0.000 (0.005) loss 1.8836 (2.1710) teacher_loss 0.6191 (0.8169) loss_zs_kd 2.0054 (1.7420) loss_oracle 0.8698 (0.8978) acc 87.5000 (72.1652) lr 1.0628e-03 eta 0:15:14
epoch [26/50] batch [160/403] time 0.100 (0.092) data 0.000 (0.004) loss 2.0580 (2.1633) teacher_loss 0.7659 (0.8139) loss_zs_kd 1.8629 (1.7538) loss_oracle 0.8999 (0.8943) acc 62.5000 (72.3047) lr 1.0628e-03 eta 0:15:09
epoch [26/50] batch [180/403] time 0.086 (0.091) data 0.000 (0.004) loss 2.1693 (2.1546) teacher_loss 0.8001 (0.8068) loss_zs_kd 1.5927 (1.7493) loss_oracle 0.8396 (0.8921) acc 68.7500 (72.5521) lr 1.0628e-03 eta 0:14:57
epoch [26/50] batch [200/403] time 0.079 (0.090) data 0.000 (0.003) loss 1.8437 (2.1449) teacher_loss 0.5343 (0.8000) loss_zs_kd 1.3301 (1.7381) loss_oracle 0.9510 (0.8910) acc 81.2500 (72.8594) lr 1.0628e-03 eta 0:14:44
epoch [26/50] batch [220/403] time 0.079 (0.089) data 0.000 (0.003) loss 1.8771 (2.1421) teacher_loss 0.5884 (0.7959) loss_zs_kd 1.8736 (1.7394) loss_oracle 0.8559 (0.8899) acc 84.3750 (72.8977) lr 1.0628e-03 eta 0:14:36
epoch [26/50] batch [240/403] time 0.088 (0.088) data 0.000 (0.003) loss 1.9650 (2.1370) teacher_loss 0.5761 (0.7915) loss_zs_kd 1.7276 (1.7404) loss_oracle 0.9442 (0.8894) acc 87.5000 (73.1250) lr 1.0628e-03 eta 0:14:27
epoch [26/50] batch [260/403] time 0.081 (0.088) data 0.000 (0.003) loss 2.1909 (2.1406) teacher_loss 0.7898 (0.7923) loss_zs_kd 1.4586 (1.7362) loss_oracle 0.9223 (0.8895) acc 75.0000 (73.1851) lr 1.0628e-03 eta 0:14:20
epoch [26/50] batch [280/403] time 0.083 (0.087) data 0.000 (0.002) loss 1.9453 (2.1372) teacher_loss 0.6289 (0.7897) loss_zs_kd 1.6777 (1.7300) loss_oracle 0.8190 (0.8885) acc 75.0000 (73.2143) lr 1.0628e-03 eta 0:14:16
epoch [26/50] batch [300/403] time 0.081 (0.087) data 0.000 (0.002) loss 2.1834 (2.1419) teacher_loss 0.7290 (0.7926) loss_zs_kd 1.5816 (1.7290) loss_oracle 0.9144 (0.8887) acc 71.8750 (73.1562) lr 1.0628e-03 eta 0:14:12
epoch [26/50] batch [320/403] time 0.087 (0.087) data 0.000 (0.002) loss 2.4123 (2.1386) teacher_loss 1.0369 (0.7918) loss_zs_kd 1.6167 (1.7243) loss_oracle 0.8786 (0.8877) acc 65.6250 (73.2520) lr 1.0628e-03 eta 0:14:09
epoch [26/50] batch [340/403] time 0.081 (0.087) data 0.000 (0.002) loss 1.8082 (2.1400) teacher_loss 0.4991 (0.7924) loss_zs_kd 1.6413 (1.7228) loss_oracle 0.8928 (0.8869) acc 78.1250 (73.1158) lr 1.0628e-03 eta 0:14:06
epoch [26/50] batch [360/403] time 0.076 (0.087) data 0.000 (0.002) loss 2.2799 (2.1460) teacher_loss 0.9337 (0.7965) loss_zs_kd 2.0121 (1.7249) loss_oracle 0.8640 (0.8870) acc 53.1250 (72.9601) lr 1.0628e-03 eta 0:14:00
epoch [26/50] batch [380/403] time 0.083 (0.086) data 0.000 (0.002) loss 2.2644 (2.1454) teacher_loss 0.9085 (0.7962) loss_zs_kd 1.4945 (1.7234) loss_oracle 0.9150 (0.8874) acc 71.8750 (73.0345) lr 1.0628e-03 eta 0:13:55
epoch [26/50] batch [400/403] time 0.081 (0.086) data 0.001 (0.002) loss 2.1895 (2.1477) teacher_loss 0.8109 (0.7977) loss_zs_kd 1.9591 (1.7234) loss_oracle 0.9982 (0.8880) acc 81.2500 (72.9844) lr 1.0628e-03 eta 0:13:51
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,903
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,384
* accuracy: 40.5%
* error: 59.5%
* macro_f1: 30.0%
******* Domain 4 best val acc:      71.1%, epoch: 25 *******
******* Domain 4 best val test acc: 39.7%, epoch: 25 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [27/50] batch [20/403] time 0.073 (0.108) data 0.000 (0.025) loss 2.2599 (2.1396) teacher_loss 0.9401 (0.7891) loss_zs_kd 1.5873 (1.7532) loss_oracle 0.8737 (0.8941) acc 62.5000 (71.8750) lr 1.0000e-03 eta 0:17:25
epoch [27/50] batch [40/403] time 0.069 (0.090) data 0.000 (0.013) loss 2.0262 (2.1028) teacher_loss 0.6706 (0.7680) loss_zs_kd 1.9859 (1.7214) loss_oracle 0.8817 (0.8810) acc 78.1250 (74.0625) lr 1.0000e-03 eta 0:14:29
epoch [27/50] batch [60/403] time 0.084 (0.087) data 0.000 (0.009) loss 2.0930 (2.1008) teacher_loss 0.8260 (0.7696) loss_zs_kd 1.6735 (1.7668) loss_oracle 0.8396 (0.8775) acc 68.7500 (73.9062) lr 1.0000e-03 eta 0:13:52
epoch [27/50] batch [80/403] time 0.099 (0.087) data 0.000 (0.007) loss 2.2364 (2.0977) teacher_loss 0.9721 (0.7713) loss_zs_kd 2.0935 (1.7456) loss_oracle 0.8197 (0.8756) acc 62.5000 (73.9453) lr 1.0000e-03 eta 0:13:51
epoch [27/50] batch [100/403] time 0.078 (0.085) data 0.000 (0.005) loss 2.3080 (2.0933) teacher_loss 0.9061 (0.7650) loss_zs_kd 1.7489 (1.7505) loss_oracle 0.8997 (0.8747) acc 62.5000 (73.8125) lr 1.0000e-03 eta 0:13:37
epoch [27/50] batch [120/403] time 0.087 (0.085) data 0.001 (0.004) loss 2.5355 (2.0964) teacher_loss 1.1188 (0.7674) loss_zs_kd 1.8795 (1.7675) loss_oracle 0.9128 (0.8727) acc 65.6250 (73.8281) lr 1.0000e-03 eta 0:13:27
epoch [27/50] batch [140/403] time 0.081 (0.085) data 0.000 (0.004) loss 2.3650 (2.1091) teacher_loss 0.9756 (0.7791) loss_zs_kd 1.6162 (1.7809) loss_oracle 0.8365 (0.8732) acc 65.6250 (73.1920) lr 1.0000e-03 eta 0:13:26
epoch [27/50] batch [160/403] time 0.084 (0.084) data 0.000 (0.003) loss 2.2558 (2.1083) teacher_loss 0.9513 (0.7807) loss_zs_kd 1.4547 (1.7717) loss_oracle 0.9037 (0.8726) acc 78.1250 (73.2812) lr 1.0000e-03 eta 0:13:20
epoch [27/50] batch [180/403] time 0.074 (0.084) data 0.000 (0.003) loss 2.4953 (2.1052) teacher_loss 1.0851 (0.7792) loss_zs_kd 1.7164 (1.7698) loss_oracle 0.8617 (0.8715) acc 68.7500 (73.4375) lr 1.0000e-03 eta 0:13:14
epoch [27/50] batch [200/403] time 0.082 (0.083) data 0.000 (0.003) loss 2.1283 (2.1067) teacher_loss 0.7707 (0.7808) loss_zs_kd 1.8851 (1.7796) loss_oracle 0.8698 (0.8707) acc 68.7500 (73.2969) lr 1.0000e-03 eta 0:13:06
epoch [27/50] batch [220/403] time 0.090 (0.083) data 0.000 (0.003) loss 2.1022 (2.1192) teacher_loss 0.7470 (0.7900) loss_zs_kd 1.3142 (1.7844) loss_oracle 0.8420 (0.8697) acc 78.1250 (72.7273) lr 1.0000e-03 eta 0:13:02
epoch [27/50] batch [240/403] time 0.083 (0.083) data 0.000 (0.002) loss 2.4670 (2.1207) teacher_loss 1.0823 (0.7920) loss_zs_kd 1.4411 (1.7737) loss_oracle 0.9021 (0.8696) acc 65.6250 (72.6042) lr 1.0000e-03 eta 0:13:00
epoch [27/50] batch [260/403] time 0.093 (0.082) data 0.000 (0.002) loss 2.2452 (2.1236) teacher_loss 0.9316 (0.7947) loss_zs_kd 1.4781 (1.7712) loss_oracle 0.8391 (0.8699) acc 71.8750 (72.4639) lr 1.0000e-03 eta 0:12:56
epoch [27/50] batch [280/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.0980 (2.1228) teacher_loss 0.7934 (0.7931) loss_zs_kd 1.9558 (1.7729) loss_oracle 0.9079 (0.8702) acc 81.2500 (72.6674) lr 1.0000e-03 eta 0:13:04
epoch [27/50] batch [300/403] time 0.072 (0.083) data 0.000 (0.002) loss 2.1082 (2.1234) teacher_loss 0.8391 (0.7918) loss_zs_kd 1.6558 (1.7723) loss_oracle 0.8393 (0.8701) acc 78.1250 (72.6042) lr 1.0000e-03 eta 0:13:00
epoch [27/50] batch [320/403] time 0.078 (0.083) data 0.000 (0.002) loss 1.8013 (2.1200) teacher_loss 0.5488 (0.7887) loss_zs_kd 1.8258 (1.7685) loss_oracle 0.8519 (0.8690) acc 81.2500 (72.7441) lr 1.0000e-03 eta 0:12:56
epoch [27/50] batch [340/403] time 0.085 (0.083) data 0.000 (0.002) loss 2.3648 (2.1255) teacher_loss 0.9592 (0.7942) loss_zs_kd 1.5670 (1.7626) loss_oracle 0.9177 (0.8688) acc 81.2500 (72.6471) lr 1.0000e-03 eta 0:12:54
epoch [27/50] batch [360/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.3993 (2.1210) teacher_loss 1.0482 (0.7914) loss_zs_kd 2.0469 (1.7587) loss_oracle 0.9207 (0.8683) acc 65.6250 (72.8906) lr 1.0000e-03 eta 0:12:54
epoch [27/50] batch [380/403] time 0.071 (0.083) data 0.000 (0.002) loss 2.1316 (2.1199) teacher_loss 0.7293 (0.7909) loss_zs_kd 1.8215 (1.7572) loss_oracle 0.8184 (0.8674) acc 78.1250 (72.9194) lr 1.0000e-03 eta 0:12:53
epoch [27/50] batch [400/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.0846 (2.1200) teacher_loss 0.8704 (0.7917) loss_zs_kd 2.0503 (1.7523) loss_oracle 0.8492 (0.8667) acc 71.8750 (72.9297) lr 1.0000e-03 eta 0:12:47
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,877
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 56.0%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,341
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 28.7%
******* Domain 4 best val acc:      71.1%, epoch: 25 *******
******* Domain 4 best val test acc: 39.7%, epoch: 25 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [28/50] batch [20/403] time 0.173 (0.124) data 0.000 (0.032) loss 2.0644 (2.0988) teacher_loss 0.7090 (0.7792) loss_zs_kd 2.2106 (1.7387) loss_oracle 0.8685 (0.8645) acc 75.0000 (73.5938) lr 9.3721e-04 eta 0:19:08
epoch [28/50] batch [40/403] time 0.073 (0.107) data 0.000 (0.016) loss 2.5433 (2.1397) teacher_loss 1.1532 (0.8041) loss_zs_kd 1.6505 (1.7717) loss_oracle 0.8764 (0.8657) acc 65.6250 (72.6562) lr 9.3721e-04 eta 0:16:31
epoch [28/50] batch [60/403] time 0.080 (0.100) data 0.000 (0.011) loss 2.1867 (2.1716) teacher_loss 0.8226 (0.8304) loss_zs_kd 1.8345 (1.7731) loss_oracle 0.8752 (0.8697) acc 62.5000 (71.5625) lr 9.3721e-04 eta 0:15:21
epoch [28/50] batch [80/403] time 0.082 (0.096) data 0.000 (0.008) loss 2.4536 (2.1515) teacher_loss 1.0304 (0.8050) loss_zs_kd 1.8889 (1.7622) loss_oracle 0.9098 (0.8770) acc 53.1250 (72.2656) lr 9.3721e-04 eta 0:14:38
epoch [28/50] batch [100/403] time 0.087 (0.093) data 0.000 (0.007) loss 2.2358 (2.1662) teacher_loss 0.8554 (0.8157) loss_zs_kd 1.4514 (1.7617) loss_oracle 0.9161 (0.8862) acc 75.0000 (71.9062) lr 9.3721e-04 eta 0:14:14
epoch [28/50] batch [120/403] time 0.075 (0.091) data 0.000 (0.006) loss 2.4878 (2.1621) teacher_loss 1.0658 (0.8101) loss_zs_kd 1.6304 (1.7534) loss_oracle 0.9367 (0.8870) acc 59.3750 (72.2135) lr 9.3721e-04 eta 0:13:48
epoch [28/50] batch [140/403] time 0.073 (0.089) data 0.000 (0.005) loss 2.0034 (2.1551) teacher_loss 0.6600 (0.8053) loss_zs_kd 1.7012 (1.7424) loss_oracle 0.8851 (0.8866) acc 71.8750 (72.3214) lr 9.3721e-04 eta 0:13:31
epoch [28/50] batch [160/403] time 0.085 (0.088) data 0.000 (0.004) loss 1.9214 (2.1599) teacher_loss 0.5276 (0.8107) loss_zs_kd 1.6508 (1.7433) loss_oracle 0.8638 (0.8859) acc 78.1250 (71.8555) lr 9.3721e-04 eta 0:13:20
epoch [28/50] batch [180/403] time 0.083 (0.088) data 0.000 (0.004) loss 2.3589 (2.1591) teacher_loss 0.9533 (0.8095) loss_zs_kd 1.7237 (1.7497) loss_oracle 0.8760 (0.8859) acc 65.6250 (71.8576) lr 9.3721e-04 eta 0:13:17
epoch [28/50] batch [200/403] time 0.077 (0.087) data 0.000 (0.003) loss 2.1516 (2.1570) teacher_loss 0.7932 (0.8048) loss_zs_kd 1.8647 (1.7534) loss_oracle 0.9152 (0.8858) acc 62.5000 (71.8594) lr 9.3721e-04 eta 0:13:08
epoch [28/50] batch [220/403] time 0.079 (0.087) data 0.000 (0.003) loss 2.3395 (2.1620) teacher_loss 0.9737 (0.8084) loss_zs_kd 2.1527 (1.7594) loss_oracle 0.8474 (0.8838) acc 65.6250 (71.7472) lr 9.3721e-04 eta 0:13:02
epoch [28/50] batch [240/403] time 0.083 (0.086) data 0.000 (0.003) loss 2.0493 (2.1669) teacher_loss 0.6228 (0.8146) loss_zs_kd 1.8480 (1.7573) loss_oracle 0.9118 (0.8823) acc 81.2500 (71.4844) lr 9.3721e-04 eta 0:13:00
epoch [28/50] batch [260/403] time 0.089 (0.086) data 0.000 (0.003) loss 2.1116 (2.1647) teacher_loss 0.7212 (0.8140) loss_zs_kd 1.5743 (1.7503) loss_oracle 0.8686 (0.8804) acc 75.0000 (71.6587) lr 9.3721e-04 eta 0:12:58
epoch [28/50] batch [280/403] time 0.088 (0.086) data 0.000 (0.003) loss 1.8286 (2.1633) teacher_loss 0.5351 (0.8136) loss_zs_kd 1.7612 (1.7442) loss_oracle 0.8682 (0.8799) acc 87.5000 (71.6295) lr 9.3721e-04 eta 0:12:56
epoch [28/50] batch [300/403] time 0.080 (0.086) data 0.000 (0.002) loss 2.1164 (2.1597) teacher_loss 0.8186 (0.8119) loss_zs_kd 1.8984 (1.7419) loss_oracle 0.8269 (0.8792) acc 68.7500 (71.6146) lr 9.3721e-04 eta 0:12:52
epoch [28/50] batch [320/403] time 0.086 (0.086) data 0.000 (0.002) loss 2.0107 (2.1587) teacher_loss 0.7324 (0.8133) loss_zs_kd 1.2949 (1.7413) loss_oracle 0.8723 (0.8775) acc 71.8750 (71.5820) lr 9.3721e-04 eta 0:12:47
epoch [28/50] batch [340/403] time 0.082 (0.086) data 0.000 (0.002) loss 2.0571 (2.1578) teacher_loss 0.6817 (0.8129) loss_zs_kd 1.5111 (1.7428) loss_oracle 0.8899 (0.8768) acc 71.8750 (71.7371) lr 9.3721e-04 eta 0:12:45
epoch [28/50] batch [360/403] time 0.076 (0.085) data 0.000 (0.002) loss 2.1803 (2.1600) teacher_loss 0.8038 (0.8144) loss_zs_kd 1.3955 (1.7423) loss_oracle 0.8850 (0.8769) acc 71.8750 (71.7014) lr 9.3721e-04 eta 0:12:40
epoch [28/50] batch [380/403] time 0.081 (0.085) data 0.000 (0.002) loss 2.2381 (2.1622) teacher_loss 0.8255 (0.8168) loss_zs_kd 1.6675 (1.7365) loss_oracle 0.8846 (0.8765) acc 71.8750 (71.7188) lr 9.3721e-04 eta 0:12:35
epoch [28/50] batch [400/403] time 0.083 (0.085) data 0.000 (0.002) loss 2.3291 (2.1620) teacher_loss 0.9267 (0.8165) loss_zs_kd 1.8286 (1.7414) loss_oracle 0.8521 (0.8769) acc 75.0000 (71.5938) lr 9.3721e-04 eta 0:12:32
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,930
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,282
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 27.6%
******* Domain 4 best val acc:      71.1%, epoch: 25 *******
******* Domain 4 best val test acc: 39.7%, epoch: 25 *******
******* Domain 4 best test acc:     41.2%, epoch: 23 *******
epoch [29/50] batch [20/403] time 0.078 (0.119) data 0.000 (0.027) loss 1.9886 (2.1357) teacher_loss 0.6041 (0.7956) loss_zs_kd 1.6159 (2.0151) loss_oracle 0.8849 (0.8921) acc 84.3750 (75.6250) lr 8.7467e-04 eta 0:17:29
epoch [29/50] batch [40/403] time 0.083 (0.098) data 0.000 (0.014) loss 2.1281 (2.1515) teacher_loss 0.8109 (0.7999) loss_zs_kd 1.4307 (1.9638) loss_oracle 0.8523 (0.8860) acc 71.8750 (74.2969) lr 8.7467e-04 eta 0:14:28
epoch [29/50] batch [60/403] time 0.088 (0.093) data 0.001 (0.009) loss 2.1199 (2.1497) teacher_loss 0.7701 (0.7982) loss_zs_kd 1.8958 (1.8704) loss_oracle 0.8935 (0.8871) acc 78.1250 (73.4896) lr 8.7467e-04 eta 0:13:40
epoch [29/50] batch [80/403] time 0.085 (0.090) data 0.000 (0.007) loss 2.4606 (2.1452) teacher_loss 1.0691 (0.7941) loss_zs_kd 2.0025 (1.8624) loss_oracle 0.8918 (0.8867) acc 59.3750 (73.5938) lr 8.7467e-04 eta 0:13:12
epoch [29/50] batch [100/403] time 0.086 (0.089) data 0.000 (0.006) loss 2.1747 (2.1466) teacher_loss 0.8763 (0.7908) loss_zs_kd 1.6835 (1.8210) loss_oracle 0.8315 (0.8819) acc 59.3750 (73.7812) lr 8.7467e-04 eta 0:12:57
epoch [29/50] batch [120/403] time 0.080 (0.087) data 0.000 (0.005) loss 2.0599 (2.1697) teacher_loss 0.7501 (0.8043) loss_zs_kd 1.5030 (1.8182) loss_oracle 0.8985 (0.8812) acc 68.7500 (73.0729) lr 8.7467e-04 eta 0:12:44
epoch [29/50] batch [140/403] time 0.080 (0.087) data 0.000 (0.004) loss 2.1327 (2.1593) teacher_loss 0.7700 (0.7949) loss_zs_kd 2.0309 (1.8128) loss_oracle 0.8925 (0.8811) acc 81.2500 (73.7500) lr 8.7467e-04 eta 0:12:35
epoch [29/50] batch [160/403] time 0.085 (0.086) data 0.000 (0.004) loss 1.8750 (2.1565) teacher_loss 0.5273 (0.7916) loss_zs_kd 2.1301 (1.8131) loss_oracle 0.8586 (0.8779) acc 84.3750 (73.6914) lr 8.7467e-04 eta 0:12:26
epoch [29/50] batch [180/403] time 0.075 (0.086) data 0.000 (0.003) loss 1.8114 (2.1575) teacher_loss 0.4102 (0.7902) loss_zs_kd 2.1856 (1.8237) loss_oracle 0.8446 (0.8785) acc 81.2500 (73.5243) lr 8.7467e-04 eta 0:12:24
epoch [29/50] batch [200/403] time 0.072 (0.087) data 0.000 (0.003) loss 1.7906 (2.1550) teacher_loss 0.4489 (0.7881) loss_zs_kd 2.4924 (1.8453) loss_oracle 0.9070 (0.8785) acc 90.6250 (73.7344) lr 8.7467e-04 eta 0:12:33
epoch [29/50] batch [220/403] time 0.085 (0.086) data 0.000 (0.003) loss 2.0778 (2.1577) teacher_loss 0.8044 (0.7915) loss_zs_kd 1.7985 (1.8442) loss_oracle 0.9014 (0.8799) acc 75.0000 (73.4659) lr 8.7467e-04 eta 0:12:25
epoch [29/50] batch [240/403] time 0.090 (0.086) data 0.000 (0.003) loss 2.3457 (2.1617) teacher_loss 0.9116 (0.7926) loss_zs_kd 2.2098 (1.8428) loss_oracle 0.8295 (0.8791) acc 65.6250 (73.1771) lr 8.7467e-04 eta 0:12:21
epoch [29/50] batch [260/403] time 0.091 (0.086) data 0.000 (0.002) loss 2.1196 (2.1659) teacher_loss 0.6641 (0.7935) loss_zs_kd 1.7903 (1.8466) loss_oracle 0.9356 (0.8819) acc 78.1250 (72.9928) lr 8.7467e-04 eta 0:12:20
epoch [29/50] batch [280/403] time 0.087 (0.086) data 0.000 (0.002) loss 1.9909 (2.1671) teacher_loss 0.5736 (0.7931) loss_zs_kd 2.1368 (1.8467) loss_oracle 0.9286 (0.8823) acc 84.3750 (72.9129) lr 8.7467e-04 eta 0:12:17
epoch [29/50] batch [300/403] time 0.082 (0.086) data 0.000 (0.002) loss 2.3351 (2.1684) teacher_loss 1.0083 (0.7949) loss_zs_kd 2.1089 (1.8490) loss_oracle 0.8154 (0.8818) acc 68.7500 (72.9062) lr 8.7467e-04 eta 0:12:16
epoch [29/50] batch [320/403] time 0.092 (0.086) data 0.000 (0.002) loss 2.4291 (2.1697) teacher_loss 0.9603 (0.7974) loss_zs_kd 1.6094 (1.8495) loss_oracle 0.8996 (0.8812) acc 62.5000 (72.7539) lr 8.7467e-04 eta 0:12:14
epoch [29/50] batch [340/403] time 0.087 (0.086) data 0.000 (0.002) loss 2.1504 (2.1742) teacher_loss 0.8278 (0.8026) loss_zs_kd 1.9071 (1.8467) loss_oracle 0.8137 (0.8811) acc 68.7500 (72.5643) lr 8.7467e-04 eta 0:12:12
epoch [29/50] batch [360/403] time 0.081 (0.086) data 0.000 (0.002) loss 2.7024 (2.1741) teacher_loss 1.3313 (0.8032) loss_zs_kd 1.6664 (1.8413) loss_oracle 0.8609 (0.8813) acc 56.2500 (72.5174) lr 8.7467e-04 eta 0:12:10
epoch [29/50] batch [380/403] time 0.077 (0.086) data 0.000 (0.002) loss 2.1016 (2.1805) teacher_loss 0.7137 (0.8089) loss_zs_kd 1.9210 (1.8380) loss_oracle 0.9036 (0.8818) acc 68.7500 (72.2615) lr 8.7467e-04 eta 0:12:05
epoch [29/50] batch [400/403] time 0.083 (0.085) data 0.000 (0.002) loss 2.2913 (2.1796) teacher_loss 0.9600 (0.8095) loss_zs_kd 1.6109 (1.8280) loss_oracle 0.8295 (0.8814) acc 62.5000 (72.2422) lr 8.7467e-04 eta 0:12:01
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,972
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 58.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,470
* accuracy: 42.0%
* error: 58.0%
* macro_f1: 30.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.8%, epoch: 29 *******
******* Domain 4 best val test acc: 42.0%, epoch: 29 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [30/50] batch [20/403] time 0.064 (0.100) data 0.000 (0.029) loss 2.2276 (2.2059) teacher_loss 0.7669 (0.8306) loss_zs_kd 1.4012 (1.7086) loss_oracle 0.9232 (0.8743) acc 75.0000 (70.6250) lr 8.1262e-04 eta 0:14:01
epoch [30/50] batch [40/403] time 0.078 (0.083) data 0.000 (0.015) loss 1.7489 (2.1930) teacher_loss 0.5450 (0.8420) loss_zs_kd 1.6076 (1.6985) loss_oracle 0.8024 (0.8737) acc 84.3750 (70.6250) lr 8.1262e-04 eta 0:11:42
epoch [30/50] batch [60/403] time 0.080 (0.082) data 0.002 (0.010) loss 2.0470 (2.1812) teacher_loss 0.8032 (0.8314) loss_zs_kd 1.6288 (1.7047) loss_oracle 0.8929 (0.8760) acc 68.7500 (71.5625) lr 8.1262e-04 eta 0:11:28
epoch [30/50] batch [80/403] time 0.086 (0.082) data 0.001 (0.008) loss 2.0140 (2.1634) teacher_loss 0.7005 (0.8072) loss_zs_kd 1.5931 (1.7167) loss_oracle 0.8128 (0.8778) acc 75.0000 (72.4219) lr 8.1262e-04 eta 0:11:29
epoch [30/50] batch [100/403] time 0.074 (0.082) data 0.000 (0.006) loss 2.0939 (2.1528) teacher_loss 0.7792 (0.7931) loss_zs_kd 2.0141 (1.7308) loss_oracle 0.8355 (0.8776) acc 75.0000 (72.6562) lr 8.1262e-04 eta 0:11:23
epoch [30/50] batch [120/403] time 0.089 (0.082) data 0.000 (0.005) loss 2.4951 (2.1478) teacher_loss 1.0541 (0.7854) loss_zs_kd 1.6952 (1.7578) loss_oracle 0.8818 (0.8781) acc 56.2500 (72.8646) lr 8.1262e-04 eta 0:11:26
epoch [30/50] batch [140/403] time 0.087 (0.082) data 0.000 (0.004) loss 2.0187 (2.1448) teacher_loss 0.7335 (0.7854) loss_zs_kd 1.5588 (1.7676) loss_oracle 0.8623 (0.8770) acc 71.8750 (72.6786) lr 8.1262e-04 eta 0:11:22
epoch [30/50] batch [160/403] time 0.087 (0.082) data 0.000 (0.004) loss 2.4104 (2.1474) teacher_loss 0.9523 (0.7874) loss_zs_kd 2.0099 (1.7794) loss_oracle 0.8985 (0.8749) acc 65.6250 (72.6758) lr 8.1262e-04 eta 0:11:23
epoch [30/50] batch [180/403] time 0.098 (0.083) data 0.000 (0.003) loss 2.0858 (2.1518) teacher_loss 0.6614 (0.7906) loss_zs_kd 1.9641 (1.7939) loss_oracle 0.9538 (0.8751) acc 75.0000 (72.6389) lr 8.1262e-04 eta 0:11:26
epoch [30/50] batch [200/403] time 0.085 (0.083) data 0.000 (0.003) loss 2.2234 (2.1524) teacher_loss 0.8273 (0.7901) loss_zs_kd 1.5059 (1.7943) loss_oracle 0.9042 (0.8755) acc 56.2500 (72.3750) lr 8.1262e-04 eta 0:11:27
epoch [30/50] batch [220/403] time 0.076 (0.083) data 0.000 (0.003) loss 2.2093 (2.1562) teacher_loss 0.9027 (0.7935) loss_zs_kd 2.0176 (1.8035) loss_oracle 0.8711 (0.8770) acc 71.8750 (72.1165) lr 8.1262e-04 eta 0:11:25
epoch [30/50] batch [240/403] time 0.083 (0.083) data 0.000 (0.003) loss 2.2736 (2.1638) teacher_loss 0.8709 (0.8014) loss_zs_kd 1.6333 (1.7948) loss_oracle 0.8601 (0.8787) acc 75.0000 (72.0703) lr 8.1262e-04 eta 0:11:23
epoch [30/50] batch [260/403] time 0.080 (0.083) data 0.001 (0.003) loss 1.9535 (2.1625) teacher_loss 0.6704 (0.8019) loss_zs_kd 1.7266 (1.7950) loss_oracle 0.8423 (0.8784) acc 81.2500 (72.0553) lr 8.1262e-04 eta 0:11:21
epoch [30/50] batch [280/403] time 0.076 (0.083) data 0.000 (0.002) loss 2.3179 (2.1685) teacher_loss 0.9778 (0.8072) loss_zs_kd 1.7641 (1.7934) loss_oracle 0.8756 (0.8789) acc 62.5000 (71.9643) lr 8.1262e-04 eta 0:11:18
epoch [30/50] batch [300/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.2242 (2.1719) teacher_loss 0.9389 (0.8114) loss_zs_kd 1.9127 (1.7953) loss_oracle 0.9337 (0.8799) acc 65.6250 (71.8021) lr 8.1262e-04 eta 0:11:16
epoch [30/50] batch [320/403] time 0.067 (0.082) data 0.000 (0.002) loss 2.4543 (2.1724) teacher_loss 1.0265 (0.8107) loss_zs_kd 1.8621 (1.7830) loss_oracle 0.8858 (0.8816) acc 62.5000 (71.7969) lr 8.1262e-04 eta 0:11:06
epoch [30/50] batch [340/403] time 0.064 (0.081) data 0.000 (0.002) loss 2.0351 (2.1751) teacher_loss 0.6948 (0.8117) loss_zs_kd 1.6962 (1.7758) loss_oracle 0.8534 (0.8842) acc 78.1250 (71.7923) lr 8.1262e-04 eta 0:10:56
epoch [30/50] batch [360/403] time 0.086 (0.082) data 0.000 (0.002) loss 2.1574 (2.1744) teacher_loss 0.7389 (0.8097) loss_zs_kd 1.5823 (1.7755) loss_oracle 0.8758 (0.8874) acc 78.1250 (71.9010) lr 8.1262e-04 eta 0:11:00
epoch [30/50] batch [380/403] time 0.084 (0.082) data 0.000 (0.002) loss 2.0495 (2.1746) teacher_loss 0.6176 (0.8102) loss_zs_kd 1.6506 (1.7764) loss_oracle 0.9349 (0.8883) acc 78.1250 (71.9161) lr 8.1262e-04 eta 0:11:00
epoch [30/50] batch [400/403] time 0.083 (0.082) data 0.000 (0.002) loss 2.2110 (2.1728) teacher_loss 0.8026 (0.8080) loss_zs_kd 2.0832 (1.7781) loss_oracle 0.8709 (0.8895) acc 62.5000 (71.8984) lr 8.1262e-04 eta 0:10:58
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,955
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 58.2%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,441
* accuracy: 41.5%
* error: 58.5%
* macro_f1: 30.0%
******* Domain 4 best val acc:      71.8%, epoch: 29 *******
******* Domain 4 best val test acc: 42.0%, epoch: 29 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [31/50] batch [20/403] time 0.063 (0.090) data 0.000 (0.025) loss 2.1792 (2.1548) teacher_loss 0.8572 (0.7975) loss_zs_kd 1.4194 (1.8069) loss_oracle 0.8845 (0.8931) acc 68.7500 (71.0938) lr 7.5131e-04 eta 0:12:02
epoch [31/50] batch [40/403] time 0.062 (0.075) data 0.000 (0.013) loss 2.1388 (2.1675) teacher_loss 0.8064 (0.8106) loss_zs_kd 1.7052 (1.8340) loss_oracle 0.9717 (0.8923) acc 68.7500 (71.6406) lr 7.5131e-04 eta 0:09:58
epoch [31/50] batch [60/403] time 0.062 (0.070) data 0.001 (0.008) loss 1.9674 (2.1934) teacher_loss 0.6466 (0.8233) loss_zs_kd 1.6406 (1.8212) loss_oracle 0.9073 (0.8914) acc 78.1250 (70.8854) lr 7.5131e-04 eta 0:09:16
epoch [31/50] batch [80/403] time 0.065 (0.068) data 0.000 (0.006) loss 2.4424 (2.1874) teacher_loss 0.9484 (0.8216) loss_zs_kd 1.6425 (1.7812) loss_oracle 0.9221 (0.8946) acc 68.7500 (71.0938) lr 7.5131e-04 eta 0:09:00
epoch [31/50] batch [100/403] time 0.061 (0.067) data 0.000 (0.005) loss 2.0662 (2.1943) teacher_loss 0.6270 (0.8261) loss_zs_kd 1.6250 (1.7633) loss_oracle 0.9400 (0.8918) acc 81.2500 (71.1250) lr 7.5131e-04 eta 0:08:50
epoch [31/50] batch [120/403] time 0.088 (0.068) data 0.000 (0.004) loss 2.1890 (2.1890) teacher_loss 0.7100 (0.8213) loss_zs_kd 1.7289 (1.7566) loss_oracle 0.9000 (0.8903) acc 78.1250 (71.4583) lr 7.5131e-04 eta 0:08:58
epoch [31/50] batch [140/403] time 0.085 (0.072) data 0.000 (0.004) loss 2.3839 (2.1870) teacher_loss 1.0477 (0.8270) loss_zs_kd 1.4983 (1.7490) loss_oracle 0.8452 (0.8878) acc 65.6250 (71.3393) lr 7.5131e-04 eta 0:09:33
epoch [31/50] batch [160/403] time 0.084 (0.074) data 0.000 (0.003) loss 2.1946 (2.1877) teacher_loss 0.7693 (0.8289) loss_zs_kd 1.5445 (1.7641) loss_oracle 0.8755 (0.8887) acc 68.7500 (71.4258) lr 7.5131e-04 eta 0:09:43
epoch [31/50] batch [180/403] time 0.073 (0.074) data 0.000 (0.003) loss 2.2514 (2.1838) teacher_loss 0.8957 (0.8270) loss_zs_kd 1.9753 (1.7567) loss_oracle 0.8808 (0.8885) acc 62.5000 (71.3542) lr 7.5131e-04 eta 0:09:42
epoch [31/50] batch [200/403] time 0.072 (0.074) data 0.000 (0.003) loss 2.3140 (2.1810) teacher_loss 0.8918 (0.8245) loss_zs_kd 1.5533 (1.7636) loss_oracle 0.8798 (0.8877) acc 65.6250 (71.6250) lr 7.5131e-04 eta 0:09:43
epoch [31/50] batch [220/403] time 0.083 (0.075) data 0.000 (0.003) loss 2.1351 (2.1759) teacher_loss 0.7950 (0.8194) loss_zs_kd 1.7915 (1.7640) loss_oracle 0.9674 (0.8887) acc 71.8750 (71.7898) lr 7.5131e-04 eta 0:09:44
epoch [31/50] batch [240/403] time 0.083 (0.075) data 0.000 (0.002) loss 1.9115 (2.1756) teacher_loss 0.5561 (0.8192) loss_zs_kd 1.8804 (1.7619) loss_oracle 0.8892 (0.8894) acc 81.2500 (71.7318) lr 7.5131e-04 eta 0:09:50
epoch [31/50] batch [260/403] time 0.076 (0.076) data 0.000 (0.002) loss 2.0895 (2.1793) teacher_loss 0.7061 (0.8227) loss_zs_kd 1.9107 (1.7597) loss_oracle 0.9432 (0.8893) acc 78.1250 (71.6827) lr 7.5131e-04 eta 0:09:53
epoch [31/50] batch [280/403] time 0.091 (0.077) data 0.000 (0.002) loss 2.0910 (2.1825) teacher_loss 0.6921 (0.8250) loss_zs_kd 1.6863 (1.7566) loss_oracle 0.9239 (0.8904) acc 75.0000 (71.5067) lr 7.5131e-04 eta 0:09:57
epoch [31/50] batch [300/403] time 0.082 (0.077) data 0.000 (0.002) loss 2.2449 (2.1849) teacher_loss 0.9037 (0.8257) loss_zs_kd 1.7985 (1.7581) loss_oracle 0.9095 (0.8896) acc 65.6250 (71.5417) lr 7.5131e-04 eta 0:10:00
epoch [31/50] batch [320/403] time 0.081 (0.078) data 0.000 (0.002) loss 2.0365 (2.1846) teacher_loss 0.7335 (0.8246) loss_zs_kd 1.6393 (1.7490) loss_oracle 0.8643 (0.8900) acc 75.0000 (71.5430) lr 7.5131e-04 eta 0:10:01
epoch [31/50] batch [340/403] time 0.080 (0.078) data 0.000 (0.002) loss 2.0764 (2.1840) teacher_loss 0.6748 (0.8239) loss_zs_kd 1.8362 (1.7435) loss_oracle 0.8938 (0.8892) acc 75.0000 (71.5257) lr 7.5131e-04 eta 0:10:03
epoch [31/50] batch [360/403] time 0.089 (0.078) data 0.000 (0.002) loss 2.3334 (2.1873) teacher_loss 0.8872 (0.8258) loss_zs_kd 2.2521 (1.7490) loss_oracle 0.9194 (0.8892) acc 56.2500 (71.3889) lr 7.5131e-04 eta 0:10:04
epoch [31/50] batch [380/403] time 0.079 (0.079) data 0.000 (0.002) loss 2.4834 (2.1887) teacher_loss 1.0447 (0.8269) loss_zs_kd 1.6484 (1.7496) loss_oracle 0.9382 (0.8899) acc 59.3750 (71.3651) lr 7.5131e-04 eta 0:10:04
epoch [31/50] batch [400/403] time 0.075 (0.079) data 0.000 (0.002) loss 2.3648 (2.1884) teacher_loss 0.9487 (0.8264) loss_zs_kd 1.6638 (1.7519) loss_oracle 0.9253 (0.8907) acc 65.6250 (71.4062) lr 7.5131e-04 eta 0:10:02
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,946
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 58.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,433
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 29.7%
******* Domain 4 best val acc:      71.8%, epoch: 29 *******
******* Domain 4 best val test acc: 42.0%, epoch: 29 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [32/50] batch [20/403] time 0.092 (0.113) data 0.000 (0.027) loss 1.9531 (2.1901) teacher_loss 0.7177 (0.7965) loss_zs_kd 1.8312 (1.7703) loss_oracle 0.8683 (0.9267) acc 75.0000 (71.5625) lr 6.9098e-04 eta 0:14:19
epoch [32/50] batch [40/403] time 0.093 (0.098) data 0.000 (0.014) loss 2.1861 (2.1595) teacher_loss 0.8005 (0.7739) loss_zs_kd 2.0252 (1.7464) loss_oracle 0.8868 (0.9166) acc 75.0000 (71.8750) lr 6.9098e-04 eta 0:12:26
epoch [32/50] batch [60/403] time 0.076 (0.091) data 0.000 (0.009) loss 2.0524 (2.1755) teacher_loss 0.6343 (0.7851) loss_zs_kd 2.1039 (1.8079) loss_oracle 0.9059 (0.9132) acc 78.1250 (71.3021) lr 6.9098e-04 eta 0:11:30
epoch [32/50] batch [80/403] time 0.089 (0.090) data 0.000 (0.007) loss 2.1451 (2.1744) teacher_loss 0.6428 (0.7800) loss_zs_kd 1.7554 (1.7987) loss_oracle 0.9436 (0.9149) acc 81.2500 (71.9531) lr 6.9098e-04 eta 0:11:19
epoch [32/50] batch [100/403] time 0.078 (0.088) data 0.000 (0.006) loss 2.0014 (2.1691) teacher_loss 0.6204 (0.7762) loss_zs_kd 1.5841 (1.8293) loss_oracle 0.8791 (0.9123) acc 81.2500 (72.3750) lr 6.9098e-04 eta 0:11:02
epoch [32/50] batch [120/403] time 0.082 (0.087) data 0.000 (0.005) loss 2.2083 (2.1731) teacher_loss 0.7901 (0.7768) loss_zs_kd 2.0203 (1.8295) loss_oracle 0.8746 (0.9093) acc 68.7500 (72.6823) lr 6.9098e-04 eta 0:10:56
epoch [32/50] batch [140/403] time 0.083 (0.087) data 0.000 (0.004) loss 2.1977 (2.1620) teacher_loss 0.8961 (0.7710) loss_zs_kd 1.8561 (1.8465) loss_oracle 0.8444 (0.9057) acc 75.0000 (73.1920) lr 6.9098e-04 eta 0:10:52
epoch [32/50] batch [160/403] time 0.083 (0.085) data 0.000 (0.004) loss 2.1972 (2.1599) teacher_loss 0.8326 (0.7741) loss_zs_kd 1.9600 (1.8447) loss_oracle 0.8547 (0.9020) acc 84.3750 (73.2422) lr 6.9098e-04 eta 0:10:38
epoch [32/50] batch [180/403] time 0.074 (0.084) data 0.000 (0.003) loss 1.9982 (2.1583) teacher_loss 0.6369 (0.7763) loss_zs_kd 1.4921 (1.8368) loss_oracle 0.9112 (0.8998) acc 84.3750 (73.1076) lr 6.9098e-04 eta 0:10:30
epoch [32/50] batch [200/403] time 0.079 (0.084) data 0.000 (0.003) loss 1.8722 (2.1585) teacher_loss 0.5459 (0.7780) loss_zs_kd 1.8405 (1.8449) loss_oracle 0.8918 (0.8980) acc 84.3750 (72.9375) lr 6.9098e-04 eta 0:10:24
epoch [32/50] batch [220/403] time 0.079 (0.084) data 0.000 (0.003) loss 2.0609 (2.1523) teacher_loss 0.7258 (0.7727) loss_zs_kd 1.9767 (1.8493) loss_oracle 0.9269 (0.8977) acc 78.1250 (73.1960) lr 6.9098e-04 eta 0:10:21
epoch [32/50] batch [240/403] time 0.081 (0.083) data 0.000 (0.002) loss 1.9150 (2.1541) teacher_loss 0.6860 (0.7758) loss_zs_kd 1.7461 (1.8509) loss_oracle 0.8524 (0.8954) acc 75.0000 (73.1771) lr 6.9098e-04 eta 0:10:17
epoch [32/50] batch [260/403] time 0.077 (0.083) data 0.000 (0.002) loss 2.2520 (2.1596) teacher_loss 0.8034 (0.7799) loss_zs_kd 1.8357 (1.8605) loss_oracle 0.9632 (0.8946) acc 65.6250 (72.9688) lr 6.9098e-04 eta 0:10:15
epoch [32/50] batch [280/403] time 0.113 (0.083) data 0.000 (0.002) loss 2.3725 (2.1556) teacher_loss 0.9978 (0.7766) loss_zs_kd 1.9241 (1.8634) loss_oracle 0.8704 (0.8943) acc 75.0000 (73.0915) lr 6.9098e-04 eta 0:10:14
epoch [32/50] batch [300/403] time 0.076 (0.084) data 0.000 (0.002) loss 2.3679 (2.1474) teacher_loss 0.8626 (0.7708) loss_zs_kd 2.0531 (1.8679) loss_oracle 0.8568 (0.8932) acc 68.7500 (73.2708) lr 6.9098e-04 eta 0:10:15
epoch [32/50] batch [320/403] time 0.073 (0.083) data 0.000 (0.002) loss 2.3836 (2.1466) teacher_loss 1.0733 (0.7708) loss_zs_kd 1.6306 (1.8670) loss_oracle 0.9136 (0.8924) acc 62.5000 (73.2031) lr 6.9098e-04 eta 0:10:11
epoch [32/50] batch [340/403] time 0.081 (0.083) data 0.000 (0.002) loss 2.2093 (2.1465) teacher_loss 0.8459 (0.7709) loss_zs_kd 1.5658 (1.8645) loss_oracle 0.8547 (0.8926) acc 78.1250 (73.3088) lr 6.9098e-04 eta 0:10:09
epoch [32/50] batch [360/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.1721 (2.1447) teacher_loss 0.6840 (0.7704) loss_zs_kd 1.9227 (1.8640) loss_oracle 0.9400 (0.8917) acc 81.2500 (73.4549) lr 6.9098e-04 eta 0:10:07
epoch [32/50] batch [380/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.2323 (2.1483) teacher_loss 0.8445 (0.7743) loss_zs_kd 1.6239 (1.8653) loss_oracle 0.9474 (0.8912) acc 71.8750 (73.3553) lr 6.9098e-04 eta 0:10:04
epoch [32/50] batch [400/403] time 0.074 (0.083) data 0.000 (0.002) loss 2.2275 (2.1442) teacher_loss 0.8469 (0.7722) loss_zs_kd 2.2379 (1.8678) loss_oracle 0.9151 (0.8906) acc 81.2500 (73.5469) lr 6.9098e-04 eta 0:10:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,978
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 58.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,357
* accuracy: 40.1%
* error: 59.9%
* macro_f1: 30.6%
******* Domain 4 best val acc:      71.9%, epoch: 32 *******
******* Domain 4 best val test acc: 40.1%, epoch: 32 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [33/50] batch [20/403] time 0.100 (0.117) data 0.000 (0.034) loss 2.3386 (2.1556) teacher_loss 1.0078 (0.8252) loss_zs_kd 1.8231 (1.8277) loss_oracle 0.8363 (0.8890) acc 78.1250 (73.2812) lr 6.3188e-04 eta 0:14:09
epoch [33/50] batch [40/403] time 0.160 (0.102) data 0.000 (0.017) loss 2.0808 (2.1342) teacher_loss 0.6605 (0.7838) loss_zs_kd 2.2057 (1.8887) loss_oracle 0.8700 (0.8941) acc 71.8750 (73.6719) lr 6.3188e-04 eta 0:12:14
epoch [33/50] batch [60/403] time 0.086 (0.098) data 0.000 (0.012) loss 1.8246 (2.1104) teacher_loss 0.6265 (0.7714) loss_zs_kd 1.5491 (1.8877) loss_oracle 0.8675 (0.8840) acc 81.2500 (73.5417) lr 6.3188e-04 eta 0:11:44
epoch [33/50] batch [80/403] time 0.083 (0.094) data 0.000 (0.009) loss 2.0316 (2.1190) teacher_loss 0.6741 (0.7782) loss_zs_kd 2.1555 (1.8854) loss_oracle 0.8832 (0.8805) acc 68.7500 (73.5938) lr 6.3188e-04 eta 0:11:13
epoch [33/50] batch [100/403] time 0.080 (0.092) data 0.000 (0.007) loss 2.4949 (2.1198) teacher_loss 1.1878 (0.7767) loss_zs_kd 2.3329 (1.8824) loss_oracle 0.8359 (0.8792) acc 62.5000 (73.3750) lr 6.3188e-04 eta 0:10:54
epoch [33/50] batch [120/403] time 0.078 (0.089) data 0.000 (0.006) loss 2.1721 (2.1192) teacher_loss 0.7598 (0.7755) loss_zs_kd 1.8902 (1.8688) loss_oracle 0.8367 (0.8809) acc 68.7500 (73.4115) lr 6.3188e-04 eta 0:10:36
epoch [33/50] batch [140/403] time 0.084 (0.088) data 0.000 (0.005) loss 1.6745 (2.1054) teacher_loss 0.3625 (0.7649) loss_zs_kd 1.4962 (1.8637) loss_oracle 0.8745 (0.8809) acc 93.7500 (73.7277) lr 6.3188e-04 eta 0:10:29
epoch [33/50] batch [160/403] time 0.082 (0.088) data 0.000 (0.005) loss 2.0482 (2.1208) teacher_loss 0.7624 (0.7795) loss_zs_kd 1.6683 (1.8517) loss_oracle 0.9355 (0.8809) acc 75.0000 (73.1445) lr 6.3188e-04 eta 0:10:25
epoch [33/50] batch [180/403] time 0.079 (0.087) data 0.000 (0.004) loss 2.2905 (2.1241) teacher_loss 0.9056 (0.7799) loss_zs_kd 2.2029 (1.8498) loss_oracle 0.8875 (0.8826) acc 68.7500 (73.1771) lr 6.3188e-04 eta 0:10:17
epoch [33/50] batch [200/403] time 0.089 (0.087) data 0.000 (0.004) loss 1.9640 (2.1265) teacher_loss 0.6941 (0.7789) loss_zs_kd 1.8847 (1.8390) loss_oracle 0.8470 (0.8857) acc 78.1250 (73.1094) lr 6.3188e-04 eta 0:10:14
epoch [33/50] batch [220/403] time 0.085 (0.087) data 0.000 (0.003) loss 2.3058 (2.1328) teacher_loss 0.8802 (0.7837) loss_zs_kd 1.7585 (1.8370) loss_oracle 0.9536 (0.8876) acc 71.8750 (72.9261) lr 6.3188e-04 eta 0:10:11
epoch [33/50] batch [240/403] time 0.085 (0.087) data 0.000 (0.003) loss 2.1679 (2.1311) teacher_loss 0.6508 (0.7811) loss_zs_kd 1.7940 (1.8293) loss_oracle 0.9411 (0.8886) acc 81.2500 (72.9948) lr 6.3188e-04 eta 0:10:06
epoch [33/50] batch [260/403] time 0.080 (0.086) data 0.000 (0.003) loss 2.0397 (2.1306) teacher_loss 0.6326 (0.7807) loss_zs_kd 1.4373 (1.8265) loss_oracle 0.9196 (0.8905) acc 84.3750 (73.1851) lr 6.3188e-04 eta 0:10:03
epoch [33/50] batch [280/403] time 0.086 (0.086) data 0.000 (0.003) loss 2.2605 (2.1333) teacher_loss 0.9567 (0.7851) loss_zs_kd 1.9044 (1.8288) loss_oracle 0.8395 (0.8892) acc 65.6250 (73.0469) lr 6.3188e-04 eta 0:10:01
epoch [33/50] batch [300/403] time 0.082 (0.086) data 0.000 (0.003) loss 1.7848 (2.1342) teacher_loss 0.4682 (0.7868) loss_zs_kd 2.1211 (1.8290) loss_oracle 0.8914 (0.8892) acc 81.2500 (72.8125) lr 6.3188e-04 eta 0:09:58
epoch [33/50] batch [320/403] time 0.078 (0.086) data 0.000 (0.002) loss 2.2887 (2.1337) teacher_loss 0.8504 (0.7855) loss_zs_kd 1.5971 (1.8206) loss_oracle 0.9395 (0.8892) acc 68.7500 (72.7051) lr 6.3188e-04 eta 0:09:54
epoch [33/50] batch [340/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.7911 (2.1344) teacher_loss 0.4825 (0.7854) loss_zs_kd 1.7304 (1.8163) loss_oracle 0.8388 (0.8898) acc 84.3750 (72.7206) lr 6.3188e-04 eta 0:09:49
epoch [33/50] batch [360/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.2301 (2.1382) teacher_loss 0.8118 (0.7889) loss_zs_kd 1.7471 (1.8124) loss_oracle 0.8643 (0.8909) acc 75.0000 (72.6128) lr 6.3188e-04 eta 0:09:47
epoch [33/50] batch [380/403] time 0.096 (0.085) data 0.000 (0.002) loss 1.8449 (2.1395) teacher_loss 0.4755 (0.7896) loss_zs_kd 2.0847 (1.8162) loss_oracle 0.9413 (0.8913) acc 84.3750 (72.7385) lr 6.3188e-04 eta 0:09:45
epoch [33/50] batch [400/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.9299 (2.1376) teacher_loss 0.6002 (0.7865) loss_zs_kd 1.5997 (1.8162) loss_oracle 0.8909 (0.8925) acc 75.0000 (72.8281) lr 6.3188e-04 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,965
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 57.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,412
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 31.2%
******* Domain 4 best val acc:      71.9%, epoch: 32 *******
******* Domain 4 best val test acc: 40.1%, epoch: 32 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [34/50] batch [20/403] time 0.093 (0.118) data 0.000 (0.028) loss 2.0187 (2.1604) teacher_loss 0.6537 (0.7841) loss_zs_kd 1.7632 (1.9197) loss_oracle 0.8814 (0.9031) acc 75.0000 (71.8750) lr 5.7422e-04 eta 0:13:24
epoch [34/50] batch [40/403] time 0.077 (0.098) data 0.000 (0.014) loss 2.2618 (2.1527) teacher_loss 0.8271 (0.7827) loss_zs_kd 2.2630 (1.9580) loss_oracle 0.9684 (0.9120) acc 75.0000 (72.9688) lr 5.7422e-04 eta 0:11:09
epoch [34/50] batch [60/403] time 0.078 (0.093) data 0.000 (0.010) loss 2.0533 (2.1333) teacher_loss 0.6960 (0.7655) loss_zs_kd 1.4691 (1.9070) loss_oracle 0.8595 (0.9089) acc 71.8750 (73.4375) lr 5.7422e-04 eta 0:10:32
epoch [34/50] batch [80/403] time 0.084 (0.090) data 0.000 (0.007) loss 2.3627 (2.1387) teacher_loss 1.0194 (0.7726) loss_zs_kd 1.9275 (1.9190) loss_oracle 0.8581 (0.9070) acc 75.0000 (73.6328) lr 5.7422e-04 eta 0:10:09
epoch [34/50] batch [100/403] time 0.079 (0.089) data 0.000 (0.006) loss 1.9518 (2.1443) teacher_loss 0.6279 (0.7748) loss_zs_kd 1.5402 (1.9087) loss_oracle 0.9105 (0.9062) acc 84.3750 (73.4375) lr 5.7422e-04 eta 0:10:03
epoch [34/50] batch [120/403] time 0.078 (0.088) data 0.000 (0.005) loss 2.3602 (2.1538) teacher_loss 0.8664 (0.7800) loss_zs_kd 2.2609 (1.8833) loss_oracle 0.9958 (0.9098) acc 71.8750 (73.2552) lr 5.7422e-04 eta 0:09:50
epoch [34/50] batch [140/403] time 0.073 (0.086) data 0.000 (0.004) loss 2.0168 (2.1486) teacher_loss 0.6595 (0.7738) loss_zs_kd 1.7983 (1.8879) loss_oracle 0.8980 (0.9108) acc 75.0000 (73.3929) lr 5.7422e-04 eta 0:09:35
epoch [34/50] batch [160/403] time 0.080 (0.085) data 0.000 (0.004) loss 2.2407 (2.1505) teacher_loss 0.8380 (0.7743) loss_zs_kd 1.7295 (1.8957) loss_oracle 0.9019 (0.9098) acc 71.8750 (73.3789) lr 5.7422e-04 eta 0:09:27
epoch [34/50] batch [180/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.4390 (2.1454) teacher_loss 1.0151 (0.7706) loss_zs_kd 2.2533 (1.8977) loss_oracle 0.9766 (0.9077) acc 65.6250 (73.4375) lr 5.7422e-04 eta 0:09:26
epoch [34/50] batch [200/403] time 0.168 (0.086) data 0.000 (0.003) loss 1.7646 (2.1386) teacher_loss 0.5402 (0.7649) loss_zs_kd 1.6477 (1.9000) loss_oracle 0.8540 (0.9069) acc 75.0000 (73.8281) lr 5.7422e-04 eta 0:09:30
epoch [34/50] batch [220/403] time 0.087 (0.086) data 0.000 (0.003) loss 2.2475 (2.1458) teacher_loss 0.8169 (0.7709) loss_zs_kd 2.1629 (1.8974) loss_oracle 0.9837 (0.9071) acc 65.6250 (73.5938) lr 5.7422e-04 eta 0:09:31
epoch [34/50] batch [240/403] time 0.085 (0.086) data 0.000 (0.003) loss 2.4335 (2.1466) teacher_loss 1.1268 (0.7721) loss_zs_kd 1.8687 (1.8894) loss_oracle 0.8724 (0.9051) acc 50.0000 (73.4766) lr 5.7422e-04 eta 0:09:29
epoch [34/50] batch [260/403] time 0.083 (0.086) data 0.000 (0.002) loss 2.1116 (2.1502) teacher_loss 0.7400 (0.7761) loss_zs_kd 1.7276 (1.8813) loss_oracle 0.9113 (0.9058) acc 78.1250 (73.3293) lr 5.7422e-04 eta 0:09:24
epoch [34/50] batch [280/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.0974 (2.1476) teacher_loss 0.7645 (0.7739) loss_zs_kd 1.7523 (1.8710) loss_oracle 0.9426 (0.9059) acc 71.8750 (73.5379) lr 5.7422e-04 eta 0:09:19
epoch [34/50] batch [300/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.2042 (2.1473) teacher_loss 0.8915 (0.7755) loss_zs_kd 1.5682 (1.8670) loss_oracle 0.9027 (0.9053) acc 68.7500 (73.5104) lr 5.7422e-04 eta 0:09:15
epoch [34/50] batch [320/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.1004 (2.1443) teacher_loss 0.6480 (0.7728) loss_zs_kd 1.7606 (1.8611) loss_oracle 0.9377 (0.9050) acc 75.0000 (73.6230) lr 5.7422e-04 eta 0:09:12
epoch [34/50] batch [340/403] time 0.091 (0.085) data 0.000 (0.002) loss 2.3859 (2.1484) teacher_loss 1.0709 (0.7769) loss_zs_kd 1.6683 (1.8544) loss_oracle 0.8320 (0.9051) acc 65.6250 (73.4926) lr 5.7422e-04 eta 0:09:11
epoch [34/50] batch [360/403] time 0.080 (0.084) data 0.001 (0.002) loss 2.0087 (2.1466) teacher_loss 0.5626 (0.7735) loss_zs_kd 1.9734 (1.8578) loss_oracle 0.9619 (0.9052) acc 84.3750 (73.5851) lr 5.7422e-04 eta 0:09:08
epoch [34/50] batch [380/403] time 0.089 (0.084) data 0.000 (0.002) loss 2.2395 (2.1473) teacher_loss 0.9384 (0.7726) loss_zs_kd 1.6658 (1.8567) loss_oracle 0.9141 (0.9050) acc 68.7500 (73.6678) lr 5.7422e-04 eta 0:09:05
epoch [34/50] batch [400/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.9769 (2.1448) teacher_loss 0.5618 (0.7707) loss_zs_kd 1.8157 (1.8580) loss_oracle 0.8851 (0.9037) acc 78.1250 (73.7109) lr 5.7422e-04 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,988
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 58.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,394
* accuracy: 40.7%
* error: 59.3%
* macro_f1: 30.0%
******* Domain 4 best val acc:      72.1%, epoch: 34 *******
******* Domain 4 best val test acc: 40.7%, epoch: 34 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [35/50] batch [20/403] time 0.078 (0.121) data 0.000 (0.034) loss 2.0612 (2.1419) teacher_loss 0.6534 (0.7449) loss_zs_kd 2.0468 (1.9230) loss_oracle 0.8638 (0.8920) acc 75.0000 (71.4062) lr 5.1825e-04 eta 0:12:58
epoch [35/50] batch [40/403] time 0.081 (0.099) data 0.000 (0.017) loss 1.6767 (2.1496) teacher_loss 0.4743 (0.7641) loss_zs_kd 1.4381 (1.8778) loss_oracle 0.8208 (0.8891) acc 87.5000 (72.6562) lr 5.1825e-04 eta 0:10:36
epoch [35/50] batch [60/403] time 0.083 (0.095) data 0.000 (0.012) loss 1.9139 (2.1601) teacher_loss 0.5500 (0.7743) loss_zs_kd 1.4392 (1.8674) loss_oracle 0.8793 (0.8896) acc 81.2500 (72.5000) lr 5.1825e-04 eta 0:10:03
epoch [35/50] batch [80/403] time 0.085 (0.092) data 0.000 (0.009) loss 2.5904 (2.1478) teacher_loss 1.2966 (0.7668) loss_zs_kd 1.8863 (1.8798) loss_oracle 0.8950 (0.8923) acc 59.3750 (73.3594) lr 5.1825e-04 eta 0:09:42
epoch [35/50] batch [100/403] time 0.079 (0.089) data 0.000 (0.007) loss 2.2445 (2.1599) teacher_loss 0.8758 (0.7846) loss_zs_kd 1.8633 (1.8789) loss_oracle 0.8369 (0.8886) acc 75.0000 (72.9688) lr 5.1825e-04 eta 0:09:26
epoch [35/50] batch [120/403] time 0.087 (0.088) data 0.000 (0.006) loss 2.5870 (2.1577) teacher_loss 1.1289 (0.7887) loss_zs_kd 2.1823 (1.8989) loss_oracle 0.9312 (0.8882) acc 68.7500 (72.9427) lr 5.1825e-04 eta 0:09:18
epoch [35/50] batch [140/403] time 0.089 (0.088) data 0.000 (0.005) loss 1.9818 (2.1564) teacher_loss 0.7518 (0.7897) loss_zs_kd 1.6833 (1.8756) loss_oracle 0.8843 (0.8890) acc 75.0000 (73.0134) lr 5.1825e-04 eta 0:09:12
epoch [35/50] batch [160/403] time 0.090 (0.087) data 0.000 (0.004) loss 2.2489 (2.1520) teacher_loss 0.9698 (0.7871) loss_zs_kd 1.8676 (1.8688) loss_oracle 0.7948 (0.8886) acc 71.8750 (72.9492) lr 5.1825e-04 eta 0:09:05
epoch [35/50] batch [180/403] time 0.065 (0.086) data 0.000 (0.004) loss 2.0708 (2.1433) teacher_loss 0.6734 (0.7800) loss_zs_kd 2.1132 (1.8714) loss_oracle 0.8824 (0.8875) acc 78.1250 (73.1076) lr 5.1825e-04 eta 0:09:00
epoch [35/50] batch [200/403] time 0.083 (0.085) data 0.000 (0.004) loss 2.3345 (2.1365) teacher_loss 0.9845 (0.7741) loss_zs_kd 1.8711 (1.8798) loss_oracle 0.8999 (0.8865) acc 62.5000 (73.1406) lr 5.1825e-04 eta 0:08:52
epoch [35/50] batch [220/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.8527 (2.1370) teacher_loss 0.5645 (0.7731) loss_zs_kd 1.5392 (1.8861) loss_oracle 0.8627 (0.8869) acc 75.0000 (73.1818) lr 5.1825e-04 eta 0:08:48
epoch [35/50] batch [240/403] time 0.080 (0.085) data 0.000 (0.003) loss 2.3449 (2.1369) teacher_loss 1.0046 (0.7735) loss_zs_kd 1.9300 (1.8750) loss_oracle 0.9666 (0.8870) acc 62.5000 (73.0729) lr 5.1825e-04 eta 0:08:44
epoch [35/50] batch [260/403] time 0.084 (0.085) data 0.000 (0.003) loss 1.8916 (2.1449) teacher_loss 0.5580 (0.7807) loss_zs_kd 1.7046 (1.8711) loss_oracle 0.9339 (0.8882) acc 81.2500 (72.8005) lr 5.1825e-04 eta 0:08:43
epoch [35/50] batch [280/403] time 0.087 (0.085) data 0.000 (0.003) loss 2.0110 (2.1489) teacher_loss 0.6962 (0.7843) loss_zs_kd 1.7284 (1.8689) loss_oracle 0.8391 (0.8895) acc 75.0000 (72.6228) lr 5.1825e-04 eta 0:08:41
epoch [35/50] batch [300/403] time 0.084 (0.085) data 0.000 (0.003) loss 2.2374 (2.1483) teacher_loss 0.8414 (0.7837) loss_zs_kd 1.9220 (1.8693) loss_oracle 0.9038 (0.8896) acc 71.8750 (72.6979) lr 5.1825e-04 eta 0:08:39
epoch [35/50] batch [320/403] time 0.083 (0.084) data 0.000 (0.002) loss 2.1127 (2.1491) teacher_loss 0.7492 (0.7839) loss_zs_kd 1.9447 (1.8692) loss_oracle 0.9146 (0.8902) acc 78.1250 (72.7930) lr 5.1825e-04 eta 0:08:35
epoch [35/50] batch [340/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.9768 (2.1484) teacher_loss 0.6843 (0.7830) loss_zs_kd 2.1067 (1.8675) loss_oracle 0.8435 (0.8912) acc 78.1250 (72.8676) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [360/403] time 0.081 (0.085) data 0.000 (0.002) loss 2.1300 (2.1507) teacher_loss 0.8015 (0.7849) loss_zs_kd 1.6310 (1.8743) loss_oracle 0.9313 (0.8916) acc 68.7500 (72.8212) lr 5.1825e-04 eta 0:08:35
epoch [35/50] batch [380/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.5488 (2.1551) teacher_loss 1.0338 (0.7880) loss_zs_kd 2.2454 (1.8786) loss_oracle 0.9213 (0.8930) acc 65.6250 (72.7467) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.002) loss 2.2040 (2.1601) teacher_loss 0.8070 (0.7921) loss_zs_kd 1.4342 (1.8700) loss_oracle 0.8756 (0.8939) acc 71.8750 (72.6250) lr 5.1825e-04 eta 0:08:29
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,022
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 60.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,440
* accuracy: 41.5%
* error: 58.5%
* macro_f1: 30.9%
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     42.0%, epoch: 29 *******
epoch [36/50] batch [20/403] time 0.073 (0.110) data 0.000 (0.029) loss 1.9301 (2.2202) teacher_loss 0.6328 (0.8462) loss_zs_kd 2.0877 (1.7324) loss_oracle 0.8806 (0.9156) acc 81.2500 (69.2188) lr 4.6417e-04 eta 0:11:04
epoch [36/50] batch [40/403] time 0.083 (0.097) data 0.000 (0.015) loss 2.7181 (2.2206) teacher_loss 1.3387 (0.8423) loss_zs_kd 1.9879 (1.7969) loss_oracle 0.9462 (0.9145) acc 53.1250 (69.3750) lr 4.6417e-04 eta 0:09:43
epoch [36/50] batch [60/403] time 0.084 (0.092) data 0.001 (0.010) loss 2.2461 (2.1947) teacher_loss 0.8605 (0.8189) loss_zs_kd 1.8744 (1.8006) loss_oracle 0.8210 (0.9105) acc 71.8750 (69.9479) lr 4.6417e-04 eta 0:09:12
epoch [36/50] batch [80/403] time 0.073 (0.090) data 0.000 (0.008) loss 2.0784 (2.1728) teacher_loss 0.7380 (0.8023) loss_zs_kd 2.1879 (1.8009) loss_oracle 0.8759 (0.9067) acc 68.7500 (70.7812) lr 4.6417e-04 eta 0:08:56
epoch [36/50] batch [100/403] time 0.085 (0.088) data 0.000 (0.006) loss 1.9757 (2.1727) teacher_loss 0.6768 (0.8039) loss_zs_kd 1.8541 (1.8136) loss_oracle 0.8585 (0.9050) acc 75.0000 (70.7500) lr 4.6417e-04 eta 0:08:44
epoch [36/50] batch [120/403] time 0.077 (0.090) data 0.000 (0.005) loss 1.6134 (2.1777) teacher_loss 0.2860 (0.8134) loss_zs_kd 1.5944 (1.8273) loss_oracle 0.8569 (0.9034) acc 90.6250 (70.9635) lr 4.6417e-04 eta 0:08:53
epoch [36/50] batch [140/403] time 0.086 (0.089) data 0.000 (0.004) loss 1.9645 (2.1687) teacher_loss 0.6020 (0.8034) loss_zs_kd 2.1853 (1.8404) loss_oracle 0.9334 (0.9028) acc 81.2500 (71.3170) lr 4.6417e-04 eta 0:08:45
epoch [36/50] batch [160/403] time 0.061 (0.087) data 0.000 (0.004) loss 2.0498 (2.1650) teacher_loss 0.6674 (0.8034) loss_zs_kd 1.6638 (1.8340) loss_oracle 0.8777 (0.8999) acc 71.8750 (71.6016) lr 4.6417e-04 eta 0:08:32
epoch [36/50] batch [180/403] time 0.082 (0.085) data 0.000 (0.004) loss 2.1377 (2.1662) teacher_loss 0.7991 (0.8028) loss_zs_kd 1.5731 (1.8410) loss_oracle 0.8866 (0.9014) acc 75.0000 (71.6840) lr 4.6417e-04 eta 0:08:19
epoch [36/50] batch [200/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.0585 (2.1632) teacher_loss 0.7767 (0.7964) loss_zs_kd 1.6170 (1.8529) loss_oracle 0.9432 (0.9014) acc 62.5000 (71.8750) lr 4.6417e-04 eta 0:08:13
epoch [36/50] batch [220/403] time 0.083 (0.084) data 0.000 (0.003) loss 1.8849 (2.1571) teacher_loss 0.5329 (0.7884) loss_zs_kd 1.9396 (1.8642) loss_oracle 0.8904 (0.9018) acc 75.0000 (72.1449) lr 4.6417e-04 eta 0:08:10
epoch [36/50] batch [240/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.0038 (2.1553) teacher_loss 0.7756 (0.7867) loss_zs_kd 1.9894 (1.8758) loss_oracle 0.8381 (0.9015) acc 81.2500 (72.2396) lr 4.6417e-04 eta 0:08:09
epoch [36/50] batch [260/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.0496 (2.1517) teacher_loss 0.6576 (0.7835) loss_zs_kd 1.7679 (1.8678) loss_oracle 0.8808 (0.9010) acc 71.8750 (72.2476) lr 4.6417e-04 eta 0:08:07
epoch [36/50] batch [280/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.3135 (2.1532) teacher_loss 0.9277 (0.7843) loss_zs_kd 2.2059 (1.8686) loss_oracle 0.9337 (0.9013) acc 71.8750 (72.2545) lr 4.6417e-04 eta 0:08:04
epoch [36/50] batch [300/403] time 0.084 (0.084) data 0.000 (0.002) loss 2.0457 (2.1516) teacher_loss 0.6565 (0.7835) loss_zs_kd 1.5806 (1.8629) loss_oracle 0.9479 (0.9005) acc 81.2500 (72.2917) lr 4.6417e-04 eta 0:08:00
epoch [36/50] batch [320/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.1558 (2.1545) teacher_loss 0.6463 (0.7858) loss_zs_kd 1.6751 (1.8617) loss_oracle 0.9217 (0.9002) acc 75.0000 (72.2559) lr 4.6417e-04 eta 0:07:58
epoch [36/50] batch [340/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.0175 (2.1516) teacher_loss 0.7320 (0.7857) loss_zs_kd 1.5000 (1.8604) loss_oracle 0.8466 (0.8988) acc 78.1250 (72.4908) lr 4.6417e-04 eta 0:07:57
epoch [36/50] batch [360/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.9559 (2.1483) teacher_loss 0.6349 (0.7844) loss_zs_kd 2.1604 (1.8608) loss_oracle 0.8833 (0.8982) acc 75.0000 (72.5000) lr 4.6417e-04 eta 0:07:56
epoch [36/50] batch [380/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.9471 (2.1451) teacher_loss 0.5743 (0.7828) loss_zs_kd 2.2343 (1.8625) loss_oracle 0.9811 (0.8974) acc 81.2500 (72.5329) lr 4.6417e-04 eta 0:07:53
epoch [36/50] batch [400/403] time 0.079 (0.083) data 0.000 (0.002) loss 1.7181 (2.1443) teacher_loss 0.4419 (0.7819) loss_zs_kd 1.9322 (1.8638) loss_oracle 0.8673 (0.8968) acc 84.3750 (72.6250) lr 4.6417e-04 eta 0:07:49
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,985
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 58.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,507
* accuracy: 42.6%
* error: 57.4%
* macro_f1: 31.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     42.6%, epoch: 36 *******
epoch [37/50] batch [20/403] time 0.082 (0.117) data 0.000 (0.028) loss 1.9620 (2.1626) teacher_loss 0.7285 (0.8062) loss_zs_kd 1.8794 (1.9016) loss_oracle 0.8242 (0.9007) acc 75.0000 (72.1875) lr 4.1221e-04 eta 0:10:56
epoch [37/50] batch [40/403] time 0.073 (0.096) data 0.000 (0.014) loss 2.1888 (2.1546) teacher_loss 0.9369 (0.7949) loss_zs_kd 1.6370 (1.8999) loss_oracle 0.9186 (0.9005) acc 71.8750 (72.3438) lr 4.1221e-04 eta 0:09:00
epoch [37/50] batch [60/403] time 0.083 (0.091) data 0.000 (0.009) loss 1.8531 (2.1484) teacher_loss 0.5838 (0.7942) loss_zs_kd 2.3825 (1.9317) loss_oracle 0.8131 (0.8910) acc 75.0000 (72.6042) lr 4.1221e-04 eta 0:08:28
epoch [37/50] batch [80/403] time 0.089 (0.089) data 0.000 (0.007) loss 2.1540 (2.1525) teacher_loss 0.8682 (0.7972) loss_zs_kd 1.7313 (1.9408) loss_oracle 0.8210 (0.8906) acc 65.6250 (72.3438) lr 4.1221e-04 eta 0:08:14
epoch [37/50] batch [100/403] time 0.084 (0.088) data 0.000 (0.006) loss 2.3751 (2.1526) teacher_loss 0.9820 (0.7970) loss_zs_kd 2.1850 (1.9179) loss_oracle 0.8908 (0.8865) acc 65.6250 (72.4375) lr 4.1221e-04 eta 0:08:07
epoch [37/50] batch [120/403] time 0.084 (0.087) data 0.000 (0.005) loss 2.0681 (2.1442) teacher_loss 0.6337 (0.7863) loss_zs_kd 1.6910 (1.9001) loss_oracle 0.9208 (0.8874) acc 75.0000 (73.1510) lr 4.1221e-04 eta 0:07:58
epoch [37/50] batch [140/403] time 0.085 (0.086) data 0.000 (0.004) loss 2.7429 (2.1367) teacher_loss 1.3420 (0.7794) loss_zs_kd 1.6715 (1.9062) loss_oracle 0.8135 (0.8880) acc 43.7500 (73.2366) lr 4.1221e-04 eta 0:07:55
epoch [37/50] batch [160/403] time 0.086 (0.086) data 0.000 (0.004) loss 2.1680 (2.1374) teacher_loss 0.8552 (0.7786) loss_zs_kd 1.5886 (1.8929) loss_oracle 0.8924 (0.8873) acc 68.7500 (73.3398) lr 4.1221e-04 eta 0:07:53
epoch [37/50] batch [180/403] time 0.091 (0.086) data 0.000 (0.003) loss 2.1284 (2.1418) teacher_loss 0.7550 (0.7816) loss_zs_kd 1.7283 (1.8825) loss_oracle 0.9063 (0.8882) acc 71.8750 (73.1944) lr 4.1221e-04 eta 0:07:51
epoch [37/50] batch [200/403] time 0.076 (0.086) data 0.000 (0.003) loss 2.0656 (2.1413) teacher_loss 0.6413 (0.7810) loss_zs_kd 1.8724 (1.8759) loss_oracle 0.9210 (0.8877) acc 81.2500 (73.4531) lr 4.1221e-04 eta 0:07:46
epoch [37/50] batch [220/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.0857 (2.1421) teacher_loss 0.7614 (0.7824) loss_zs_kd 1.9597 (1.8719) loss_oracle 0.8900 (0.8888) acc 65.6250 (73.2528) lr 4.1221e-04 eta 0:07:40
epoch [37/50] batch [240/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.9226 (2.1364) teacher_loss 0.5727 (0.7776) loss_zs_kd 1.7957 (1.8722) loss_oracle 0.9253 (0.8902) acc 81.2500 (73.3984) lr 4.1221e-04 eta 0:07:36
epoch [37/50] batch [260/403] time 0.081 (0.086) data 0.000 (0.002) loss 2.2341 (2.1350) teacher_loss 0.8607 (0.7772) loss_zs_kd 1.6891 (1.8694) loss_oracle 0.9058 (0.8907) acc 65.6250 (73.3894) lr 4.1221e-04 eta 0:07:42
epoch [37/50] batch [280/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.5290 (2.1316) teacher_loss 1.2091 (0.7749) loss_zs_kd 1.7105 (1.8693) loss_oracle 0.8934 (0.8905) acc 59.3750 (73.3817) lr 4.1221e-04 eta 0:07:38
epoch [37/50] batch [300/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.2111 (2.1319) teacher_loss 0.8772 (0.7728) loss_zs_kd 1.5602 (1.8639) loss_oracle 0.9396 (0.8914) acc 65.6250 (73.4271) lr 4.1221e-04 eta 0:07:35
epoch [37/50] batch [320/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.0982 (2.1323) teacher_loss 0.7323 (0.7751) loss_zs_kd 2.2138 (1.8562) loss_oracle 0.9930 (0.8910) acc 71.8750 (73.2520) lr 4.1221e-04 eta 0:07:31
epoch [37/50] batch [340/403] time 0.083 (0.085) data 0.000 (0.002) loss 1.9766 (2.1308) teacher_loss 0.6959 (0.7735) loss_zs_kd 1.5177 (1.8537) loss_oracle 0.8794 (0.8915) acc 78.1250 (73.1893) lr 4.1221e-04 eta 0:07:29
epoch [37/50] batch [360/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.3212 (2.1310) teacher_loss 0.8307 (0.7715) loss_zs_kd 1.9247 (1.8541) loss_oracle 0.9096 (0.8926) acc 71.8750 (73.2205) lr 4.1221e-04 eta 0:07:27
epoch [37/50] batch [380/403] time 0.081 (0.084) data 0.000 (0.002) loss 2.2332 (2.1343) teacher_loss 0.7931 (0.7729) loss_zs_kd 2.2407 (1.8605) loss_oracle 0.8607 (0.8921) acc 71.8750 (73.0592) lr 4.1221e-04 eta 0:07:24
epoch [37/50] batch [400/403] time 0.082 (0.084) data 0.000 (0.002) loss 2.2034 (2.1358) teacher_loss 0.7080 (0.7741) loss_zs_kd 2.0200 (1.8614) loss_oracle 0.9211 (0.8927) acc 68.7500 (73.0234) lr 4.1221e-04 eta 0:07:22
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,987
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 59.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,466
* accuracy: 41.9%
* error: 58.1%
* macro_f1: 31.2%
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     42.6%, epoch: 36 *******
epoch [38/50] batch [20/403] time 0.082 (0.128) data 0.000 (0.027) loss 2.2020 (2.2181) teacher_loss 0.8303 (0.8197) loss_zs_kd 1.7807 (1.8828) loss_oracle 0.8378 (0.9146) acc 78.1250 (72.1875) lr 3.6258e-04 eta 0:11:08
epoch [38/50] batch [40/403] time 0.094 (0.107) data 0.000 (0.014) loss 2.4610 (2.2193) teacher_loss 0.9801 (0.8149) loss_zs_kd 2.0364 (1.9056) loss_oracle 0.8899 (0.9153) acc 62.5000 (71.8750) lr 3.6258e-04 eta 0:09:17
epoch [38/50] batch [60/403] time 0.088 (0.100) data 0.001 (0.009) loss 1.8752 (2.1969) teacher_loss 0.4863 (0.7997) loss_zs_kd 1.8715 (1.9010) loss_oracle 0.8516 (0.9017) acc 81.2500 (71.5625) lr 3.6258e-04 eta 0:08:39
epoch [38/50] batch [80/403] time 0.078 (0.097) data 0.000 (0.007) loss 2.1203 (2.1911) teacher_loss 0.7616 (0.7902) loss_zs_kd 1.5921 (1.9305) loss_oracle 0.8689 (0.9052) acc 78.1250 (72.3047) lr 3.6258e-04 eta 0:08:19
epoch [38/50] batch [100/403] time 0.086 (0.094) data 0.000 (0.006) loss 2.0578 (2.1807) teacher_loss 0.7988 (0.7865) loss_zs_kd 1.8187 (1.8934) loss_oracle 0.8964 (0.9051) acc 78.1250 (72.7500) lr 3.6258e-04 eta 0:08:05
epoch [38/50] batch [120/403] time 0.062 (0.091) data 0.000 (0.005) loss 2.2274 (2.1805) teacher_loss 0.9103 (0.7879) loss_zs_kd 1.6107 (1.8816) loss_oracle 0.8771 (0.9020) acc 65.6250 (72.4740) lr 3.6258e-04 eta 0:07:45
epoch [38/50] batch [140/403] time 0.079 (0.088) data 0.000 (0.004) loss 2.0626 (2.1660) teacher_loss 0.7417 (0.7806) loss_zs_kd 1.7648 (1.8602) loss_oracle 0.8649 (0.8993) acc 65.6250 (72.9241) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [160/403] time 0.084 (0.087) data 0.000 (0.004) loss 1.6284 (2.1673) teacher_loss 0.4312 (0.7845) loss_zs_kd 2.0777 (1.8536) loss_oracle 0.8291 (0.8993) acc 81.2500 (72.8516) lr 3.6258e-04 eta 0:07:21
epoch [38/50] batch [180/403] time 0.074 (0.085) data 0.000 (0.003) loss 1.7702 (2.1562) teacher_loss 0.4472 (0.7783) loss_zs_kd 1.7074 (1.8438) loss_oracle 0.9196 (0.8964) acc 93.7500 (73.1076) lr 3.6258e-04 eta 0:07:11
epoch [38/50] batch [200/403] time 0.078 (0.085) data 0.000 (0.003) loss 2.2873 (2.1531) teacher_loss 0.9293 (0.7770) loss_zs_kd 1.6700 (1.8409) loss_oracle 0.9800 (0.8970) acc 68.7500 (73.1250) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [220/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.3608 (2.1507) teacher_loss 1.0067 (0.7761) loss_zs_kd 1.6079 (1.8400) loss_oracle 0.8830 (0.8968) acc 71.8750 (73.3949) lr 3.6258e-04 eta 0:07:01
epoch [38/50] batch [240/403] time 0.076 (0.083) data 0.000 (0.003) loss 2.2324 (2.1537) teacher_loss 0.8898 (0.7797) loss_zs_kd 1.9998 (1.8376) loss_oracle 0.8467 (0.8957) acc 62.5000 (73.3203) lr 3.6258e-04 eta 0:06:57
epoch [38/50] batch [260/403] time 0.075 (0.083) data 0.000 (0.002) loss 2.1120 (2.1533) teacher_loss 0.7329 (0.7799) loss_zs_kd 2.0967 (1.8403) loss_oracle 0.9340 (0.8956) acc 71.8750 (73.2692) lr 3.6258e-04 eta 0:06:54
epoch [38/50] batch [280/403] time 0.083 (0.083) data 0.000 (0.002) loss 1.9442 (2.1527) teacher_loss 0.5391 (0.7802) loss_zs_kd 1.7700 (1.8346) loss_oracle 0.9409 (0.8963) acc 81.2500 (73.3594) lr 3.6258e-04 eta 0:06:52
epoch [38/50] batch [300/403] time 0.083 (0.083) data 0.000 (0.002) loss 2.0482 (2.1528) teacher_loss 0.6320 (0.7788) loss_zs_kd 1.6256 (1.8382) loss_oracle 0.9160 (0.8978) acc 75.0000 (73.4583) lr 3.6258e-04 eta 0:06:51
epoch [38/50] batch [320/403] time 0.071 (0.083) data 0.000 (0.002) loss 2.2372 (2.1572) teacher_loss 0.8989 (0.7829) loss_zs_kd 1.6899 (1.8257) loss_oracle 0.9069 (0.8979) acc 62.5000 (73.1934) lr 3.6258e-04 eta 0:06:49
epoch [38/50] batch [340/403] time 0.074 (0.083) data 0.000 (0.002) loss 2.3536 (2.1640) teacher_loss 1.0500 (0.7891) loss_zs_kd 1.2519 (1.8206) loss_oracle 0.8748 (0.8991) acc 68.7500 (72.9228) lr 3.6258e-04 eta 0:06:46
epoch [38/50] batch [360/403] time 0.079 (0.083) data 0.000 (0.002) loss 2.0830 (2.1693) teacher_loss 0.7745 (0.7937) loss_zs_kd 2.0111 (1.8199) loss_oracle 0.9499 (0.8990) acc 71.8750 (72.7257) lr 3.6258e-04 eta 0:06:43
epoch [38/50] batch [380/403] time 0.083 (0.083) data 0.000 (0.002) loss 2.4130 (2.1670) teacher_loss 1.0808 (0.7928) loss_zs_kd 2.0869 (1.8199) loss_oracle 0.8907 (0.8985) acc 62.5000 (72.7632) lr 3.6258e-04 eta 0:06:41
epoch [38/50] batch [400/403] time 0.075 (0.082) data 0.001 (0.002) loss 2.1312 (2.1665) teacher_loss 0.7337 (0.7933) loss_zs_kd 1.8003 (1.8192) loss_oracle 0.9290 (0.8979) acc 75.0000 (72.6953) lr 3.6258e-04 eta 0:06:39
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,008
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 58.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,523
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 31.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     42.9%, epoch: 38 *******
epoch [39/50] batch [20/403] time 0.089 (0.119) data 0.000 (0.032) loss 2.6653 (2.1744) teacher_loss 1.1298 (0.8097) loss_zs_kd 1.6456 (1.7715) loss_oracle 1.0178 (0.8940) acc 59.3750 (73.2812) lr 3.1545e-04 eta 0:09:33
epoch [39/50] batch [40/403] time 0.087 (0.100) data 0.000 (0.016) loss 2.0102 (2.1967) teacher_loss 0.6511 (0.8251) loss_zs_kd 1.6019 (1.7873) loss_oracle 0.9866 (0.8950) acc 75.0000 (72.5781) lr 3.1545e-04 eta 0:07:59
epoch [39/50] batch [60/403] time 0.082 (0.093) data 0.001 (0.011) loss 1.9860 (2.1770) teacher_loss 0.5975 (0.8049) loss_zs_kd 2.0026 (1.7949) loss_oracle 0.8923 (0.8942) acc 87.5000 (73.2812) lr 3.1545e-04 eta 0:07:22
epoch [39/50] batch [80/403] time 0.081 (0.089) data 0.000 (0.008) loss 2.0952 (2.1825) teacher_loss 0.6607 (0.8072) loss_zs_kd 2.0969 (1.8202) loss_oracle 0.9778 (0.8961) acc 78.1250 (72.8906) lr 3.1545e-04 eta 0:07:02
epoch [39/50] batch [100/403] time 0.083 (0.087) data 0.000 (0.007) loss 2.4567 (2.1724) teacher_loss 0.9519 (0.7992) loss_zs_kd 1.8333 (1.8142) loss_oracle 0.9890 (0.8957) acc 68.7500 (73.0312) lr 3.1545e-04 eta 0:06:53
epoch [39/50] batch [120/403] time 0.085 (0.087) data 0.000 (0.006) loss 2.4778 (2.1584) teacher_loss 1.0712 (0.7888) loss_zs_kd 2.1013 (1.8207) loss_oracle 0.9239 (0.8936) acc 53.1250 (73.5677) lr 3.1545e-04 eta 0:06:49
epoch [39/50] batch [140/403] time 0.083 (0.086) data 0.001 (0.005) loss 2.2266 (2.1589) teacher_loss 0.8183 (0.7909) loss_zs_kd 1.8675 (1.8164) loss_oracle 0.8382 (0.8908) acc 71.8750 (73.1027) lr 3.1545e-04 eta 0:06:41
epoch [39/50] batch [160/403] time 0.086 (0.085) data 0.000 (0.004) loss 1.8324 (2.1549) teacher_loss 0.5326 (0.7900) loss_zs_kd 1.6529 (1.8014) loss_oracle 0.9100 (0.8913) acc 75.0000 (72.9102) lr 3.1545e-04 eta 0:06:39
epoch [39/50] batch [180/403] time 0.075 (0.087) data 0.000 (0.004) loss 2.2218 (2.1591) teacher_loss 0.7383 (0.7923) loss_zs_kd 1.7659 (1.7995) loss_oracle 0.8831 (0.8914) acc 81.2500 (72.7778) lr 3.1545e-04 eta 0:06:44
epoch [39/50] batch [200/403] time 0.073 (0.086) data 0.000 (0.003) loss 2.1431 (2.1563) teacher_loss 0.8645 (0.7905) loss_zs_kd 1.7930 (1.7988) loss_oracle 0.8703 (0.8907) acc 68.7500 (72.7969) lr 3.1545e-04 eta 0:06:39
epoch [39/50] batch [220/403] time 0.090 (0.086) data 0.000 (0.003) loss 2.0957 (2.1541) teacher_loss 0.7066 (0.7868) loss_zs_kd 1.6514 (1.8048) loss_oracle 0.8796 (0.8906) acc 68.7500 (72.9972) lr 3.1545e-04 eta 0:06:36
epoch [39/50] batch [240/403] time 0.081 (0.086) data 0.000 (0.003) loss 2.3621 (2.1546) teacher_loss 0.9581 (0.7858) loss_zs_kd 1.7632 (1.8035) loss_oracle 0.8467 (0.8912) acc 68.7500 (73.0339) lr 3.1545e-04 eta 0:06:33
epoch [39/50] batch [260/403] time 0.076 (0.085) data 0.000 (0.003) loss 2.3004 (2.1512) teacher_loss 0.9089 (0.7837) loss_zs_kd 1.7578 (1.8067) loss_oracle 0.9479 (0.8907) acc 75.0000 (73.0529) lr 3.1545e-04 eta 0:06:29
epoch [39/50] batch [280/403] time 0.085 (0.085) data 0.000 (0.003) loss 2.1001 (2.1523) teacher_loss 0.7644 (0.7837) loss_zs_kd 1.7399 (1.8111) loss_oracle 0.9340 (0.8917) acc 71.8750 (72.9576) lr 3.1545e-04 eta 0:06:25
epoch [39/50] batch [300/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.3169 (2.1514) teacher_loss 0.8371 (0.7818) loss_zs_kd 1.7492 (1.8124) loss_oracle 0.8973 (0.8926) acc 71.8750 (72.8646) lr 3.1545e-04 eta 0:06:22
epoch [39/50] batch [320/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.0882 (2.1553) teacher_loss 0.5934 (0.7845) loss_zs_kd 1.7885 (1.8125) loss_oracle 0.8566 (0.8926) acc 78.1250 (72.7246) lr 3.1545e-04 eta 0:06:21
epoch [39/50] batch [340/403] time 0.088 (0.084) data 0.000 (0.002) loss 2.5575 (2.1559) teacher_loss 1.1256 (0.7840) loss_zs_kd 1.6073 (1.8141) loss_oracle 0.8947 (0.8935) acc 62.5000 (72.7941) lr 3.1545e-04 eta 0:06:19
epoch [39/50] batch [360/403] time 0.075 (0.084) data 0.000 (0.002) loss 2.1333 (2.1508) teacher_loss 0.7007 (0.7806) loss_zs_kd 1.7083 (1.8099) loss_oracle 0.9247 (0.8936) acc 75.0000 (72.7865) lr 3.1545e-04 eta 0:06:17
epoch [39/50] batch [380/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.2476 (2.1480) teacher_loss 0.6899 (0.7774) loss_zs_kd 2.0417 (1.8127) loss_oracle 0.9900 (0.8940) acc 75.0000 (72.8783) lr 3.1545e-04 eta 0:06:14
epoch [39/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.002) loss 2.0828 (2.1475) teacher_loss 0.6682 (0.7769) loss_zs_kd 1.9224 (1.8184) loss_oracle 0.9062 (0.8935) acc 81.2500 (72.8672) lr 3.1545e-04 eta 0:06:10
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,973
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,565
* accuracy: 43.6%
* error: 56.4%
* macro_f1: 32.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [40/50] batch [20/403] time 0.078 (0.118) data 0.000 (0.033) loss 2.3071 (2.1420) teacher_loss 0.7717 (0.7554) loss_zs_kd 2.2401 (1.9118) loss_oracle 1.0274 (0.8979) acc 68.7500 (72.6562) lr 2.7103e-04 eta 0:08:39
epoch [40/50] batch [40/403] time 0.083 (0.099) data 0.000 (0.017) loss 2.5373 (2.1824) teacher_loss 0.9247 (0.7758) loss_zs_kd 2.2677 (1.9510) loss_oracle 0.9334 (0.8923) acc 56.2500 (72.1094) lr 2.7103e-04 eta 0:07:16
epoch [40/50] batch [60/403] time 0.082 (0.092) data 0.000 (0.011) loss 1.9787 (2.1794) teacher_loss 0.5998 (0.7804) loss_zs_kd 2.1569 (1.9824) loss_oracle 0.8473 (0.8908) acc 78.1250 (71.7188) lr 2.7103e-04 eta 0:06:44
epoch [40/50] batch [80/403] time 0.080 (0.091) data 0.000 (0.008) loss 2.0415 (2.1760) teacher_loss 0.6490 (0.7787) loss_zs_kd 1.7798 (1.9490) loss_oracle 0.9034 (0.8915) acc 84.3750 (71.7578) lr 2.7103e-04 eta 0:06:34
epoch [40/50] batch [100/403] time 0.084 (0.090) data 0.000 (0.007) loss 1.9594 (2.1664) teacher_loss 0.5503 (0.7722) loss_zs_kd 2.2544 (1.9527) loss_oracle 0.8968 (0.8921) acc 81.2500 (72.2188) lr 2.7103e-04 eta 0:06:27
epoch [40/50] batch [120/403] time 0.084 (0.089) data 0.000 (0.006) loss 2.2153 (2.1693) teacher_loss 0.8482 (0.7797) loss_zs_kd 1.7688 (1.9548) loss_oracle 0.9172 (0.8915) acc 78.1250 (72.1615) lr 2.7103e-04 eta 0:06:23
epoch [40/50] batch [140/403] time 0.081 (0.088) data 0.000 (0.005) loss 2.6090 (2.1837) teacher_loss 1.1741 (0.7961) loss_zs_kd 2.2092 (1.9466) loss_oracle 0.8368 (0.8906) acc 59.3750 (71.8527) lr 2.7103e-04 eta 0:06:16
epoch [40/50] batch [160/403] time 0.084 (0.087) data 0.000 (0.004) loss 2.0697 (2.1704) teacher_loss 0.7115 (0.7862) loss_zs_kd 2.0204 (1.9335) loss_oracle 0.9171 (0.8903) acc 78.1250 (72.3438) lr 2.7103e-04 eta 0:06:11
epoch [40/50] batch [180/403] time 0.083 (0.087) data 0.000 (0.004) loss 1.8104 (2.1623) teacher_loss 0.4407 (0.7789) loss_zs_kd 1.4863 (1.9187) loss_oracle 0.8144 (0.8891) acc 81.2500 (72.7431) lr 2.7103e-04 eta 0:06:09
epoch [40/50] batch [200/403] time 0.081 (0.087) data 0.000 (0.004) loss 2.0620 (2.1680) teacher_loss 0.7167 (0.7839) loss_zs_kd 1.6455 (1.9200) loss_oracle 0.8897 (0.8895) acc 65.6250 (72.6875) lr 2.7103e-04 eta 0:06:06
epoch [40/50] batch [220/403] time 0.091 (0.087) data 0.000 (0.003) loss 2.1501 (2.1713) teacher_loss 0.7134 (0.7889) loss_zs_kd 1.9678 (1.9131) loss_oracle 0.8415 (0.8882) acc 68.7500 (72.6562) lr 2.7103e-04 eta 0:06:04
epoch [40/50] batch [240/403] time 0.084 (0.087) data 0.000 (0.003) loss 2.2685 (2.1687) teacher_loss 0.9835 (0.7896) loss_zs_kd 1.6868 (1.8938) loss_oracle 0.8669 (0.8889) acc 62.5000 (72.5391) lr 2.7103e-04 eta 0:06:02
epoch [40/50] batch [260/403] time 0.082 (0.086) data 0.000 (0.003) loss 2.0445 (2.1660) teacher_loss 0.6530 (0.7880) loss_zs_kd 1.5063 (1.8922) loss_oracle 0.8620 (0.8878) acc 78.1250 (72.6322) lr 2.7103e-04 eta 0:05:58
epoch [40/50] batch [280/403] time 0.084 (0.086) data 0.000 (0.003) loss 2.1465 (2.1669) teacher_loss 0.7438 (0.7898) loss_zs_kd 2.5050 (1.8879) loss_oracle 0.8797 (0.8870) acc 65.6250 (72.6562) lr 2.7103e-04 eta 0:05:56
epoch [40/50] batch [300/403] time 0.079 (0.086) data 0.000 (0.002) loss 1.8970 (2.1661) teacher_loss 0.5978 (0.7888) loss_zs_kd 1.8829 (1.8868) loss_oracle 0.9200 (0.8881) acc 81.2500 (72.7188) lr 2.7103e-04 eta 0:05:54
epoch [40/50] batch [320/403] time 0.153 (0.086) data 0.000 (0.002) loss 2.0821 (2.1626) teacher_loss 0.6909 (0.7867) loss_zs_kd 1.9853 (1.8858) loss_oracle 0.8609 (0.8878) acc 68.7500 (72.6855) lr 2.7103e-04 eta 0:05:53
epoch [40/50] batch [340/403] time 0.082 (0.086) data 0.000 (0.002) loss 1.9599 (2.1608) teacher_loss 0.6612 (0.7856) loss_zs_kd 1.4274 (1.8863) loss_oracle 0.8115 (0.8864) acc 81.2500 (72.7941) lr 2.7103e-04 eta 0:05:53
epoch [40/50] batch [360/403] time 0.092 (0.086) data 0.000 (0.002) loss 2.4031 (2.1573) teacher_loss 0.9643 (0.7830) loss_zs_kd 1.9840 (1.8839) loss_oracle 0.9015 (0.8862) acc 65.6250 (72.9514) lr 2.7103e-04 eta 0:05:50
epoch [40/50] batch [380/403] time 0.079 (0.086) data 0.000 (0.002) loss 1.9768 (2.1565) teacher_loss 0.6692 (0.7821) loss_zs_kd 2.0759 (1.8858) loss_oracle 0.8941 (0.8870) acc 84.3750 (72.9770) lr 2.7103e-04 eta 0:05:47
epoch [40/50] batch [400/403] time 0.077 (0.085) data 0.000 (0.002) loss 2.1665 (2.1570) teacher_loss 0.7871 (0.7822) loss_zs_kd 2.1100 (1.8861) loss_oracle 0.9124 (0.8866) acc 71.8750 (73.0234) lr 2.7103e-04 eta 0:05:43
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,013
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,495
* accuracy: 42.4%
* error: 57.6%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [41/50] batch [20/403] time 0.084 (0.113) data 0.000 (0.028) loss 2.1500 (2.2074) teacher_loss 0.7811 (0.8465) loss_zs_kd 1.9794 (1.8430) loss_oracle 0.8837 (0.8880) acc 78.1250 (70.9375) lr 2.2949e-04 eta 0:07:34
epoch [41/50] batch [40/403] time 0.083 (0.096) data 0.000 (0.014) loss 1.7621 (2.1715) teacher_loss 0.4768 (0.8145) loss_zs_kd 1.7637 (1.8417) loss_oracle 0.9176 (0.8864) acc 87.5000 (71.9531) lr 2.2949e-04 eta 0:06:23
epoch [41/50] batch [60/403] time 0.080 (0.092) data 0.000 (0.010) loss 2.1621 (2.1839) teacher_loss 0.7002 (0.8170) loss_zs_kd 1.7206 (1.8557) loss_oracle 0.9422 (0.8921) acc 78.1250 (71.5104) lr 2.2949e-04 eta 0:06:05
epoch [41/50] batch [80/403] time 0.092 (0.090) data 0.000 (0.007) loss 2.2502 (2.1760) teacher_loss 0.9567 (0.8114) loss_zs_kd 1.9799 (1.8696) loss_oracle 0.8433 (0.8869) acc 65.6250 (71.6797) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [100/403] time 0.086 (0.093) data 0.000 (0.006) loss 2.5595 (2.1880) teacher_loss 1.1644 (0.8184) loss_zs_kd 2.2136 (1.8636) loss_oracle 0.8866 (0.8916) acc 56.2500 (71.3125) lr 2.2949e-04 eta 0:06:06
epoch [41/50] batch [120/403] time 0.080 (0.092) data 0.000 (0.005) loss 1.9480 (2.1805) teacher_loss 0.5876 (0.8134) loss_zs_kd 1.8848 (1.8614) loss_oracle 0.8681 (0.8931) acc 71.8750 (71.4844) lr 2.2949e-04 eta 0:05:59
epoch [41/50] batch [140/403] time 0.085 (0.091) data 0.000 (0.004) loss 2.2288 (2.1745) teacher_loss 0.9161 (0.8070) loss_zs_kd 1.7900 (1.8517) loss_oracle 0.8253 (0.8941) acc 59.3750 (71.5179) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [160/403] time 0.082 (0.090) data 0.000 (0.004) loss 1.7281 (2.1688) teacher_loss 0.4129 (0.8027) loss_zs_kd 1.5751 (1.8450) loss_oracle 0.8443 (0.8940) acc 87.5000 (71.6797) lr 2.2949e-04 eta 0:05:47
epoch [41/50] batch [180/403] time 0.088 (0.089) data 0.000 (0.003) loss 1.9559 (2.1617) teacher_loss 0.5804 (0.7972) loss_zs_kd 2.2332 (1.8531) loss_oracle 0.8870 (0.8947) acc 75.0000 (71.8229) lr 2.2949e-04 eta 0:05:42
epoch [41/50] batch [200/403] time 0.079 (0.088) data 0.000 (0.003) loss 2.0772 (2.1608) teacher_loss 0.7606 (0.7944) loss_zs_kd 1.5533 (1.8615) loss_oracle 0.8552 (0.8936) acc 68.7500 (71.8281) lr 2.2949e-04 eta 0:05:38
epoch [41/50] batch [220/403] time 0.081 (0.088) data 0.000 (0.003) loss 2.2259 (2.1633) teacher_loss 0.9682 (0.7966) loss_zs_kd 1.9992 (1.8533) loss_oracle 0.9012 (0.8934) acc 59.3750 (71.6193) lr 2.2949e-04 eta 0:05:33
epoch [41/50] batch [240/403] time 0.084 (0.088) data 0.000 (0.003) loss 1.9508 (2.1610) teacher_loss 0.6244 (0.7934) loss_zs_kd 1.7486 (1.8501) loss_oracle 0.8767 (0.8931) acc 84.3750 (71.7188) lr 2.2949e-04 eta 0:05:31
epoch [41/50] batch [260/403] time 0.082 (0.087) data 0.000 (0.002) loss 2.2308 (2.1583) teacher_loss 0.8403 (0.7908) loss_zs_kd 1.9072 (1.8509) loss_oracle 0.9113 (0.8927) acc 81.2500 (71.7909) lr 2.2949e-04 eta 0:05:27
epoch [41/50] batch [280/403] time 0.097 (0.086) data 0.000 (0.002) loss 2.1392 (2.1588) teacher_loss 0.7489 (0.7904) loss_zs_kd 1.5809 (1.8558) loss_oracle 0.8391 (0.8914) acc 68.7500 (71.7857) lr 2.2949e-04 eta 0:05:23
epoch [41/50] batch [300/403] time 0.078 (0.086) data 0.000 (0.002) loss 2.3873 (2.1578) teacher_loss 0.8696 (0.7887) loss_zs_kd 1.5972 (1.8493) loss_oracle 0.8795 (0.8913) acc 65.6250 (71.8542) lr 2.2949e-04 eta 0:05:19
epoch [41/50] batch [320/403] time 0.085 (0.086) data 0.000 (0.002) loss 2.2762 (2.1571) teacher_loss 0.8190 (0.7868) loss_zs_kd 2.1984 (1.8501) loss_oracle 0.9314 (0.8917) acc 68.7500 (71.9434) lr 2.2949e-04 eta 0:05:17
epoch [41/50] batch [340/403] time 0.090 (0.085) data 0.000 (0.002) loss 1.9438 (2.1552) teacher_loss 0.5585 (0.7852) loss_zs_kd 1.7559 (1.8543) loss_oracle 0.8601 (0.8908) acc 75.0000 (71.9945) lr 2.2949e-04 eta 0:05:14
epoch [41/50] batch [360/403] time 0.065 (0.085) data 0.000 (0.002) loss 1.9039 (2.1534) teacher_loss 0.6331 (0.7835) loss_zs_kd 1.3884 (1.8548) loss_oracle 0.8793 (0.8911) acc 71.8750 (72.0312) lr 2.2949e-04 eta 0:05:11
epoch [41/50] batch [380/403] time 0.084 (0.085) data 0.001 (0.002) loss 1.9506 (2.1531) teacher_loss 0.6470 (0.7838) loss_zs_kd 2.0826 (1.8556) loss_oracle 0.8910 (0.8910) acc 81.2500 (72.0970) lr 2.2949e-04 eta 0:05:08
epoch [41/50] batch [400/403] time 0.084 (0.084) data 0.000 (0.002) loss 2.1079 (2.1560) teacher_loss 0.8254 (0.7857) loss_zs_kd 2.0827 (1.8575) loss_oracle 0.8780 (0.8910) acc 78.1250 (72.1719) lr 2.2949e-04 eta 0:05:06
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,011
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 60.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,520
* accuracy: 42.8%
* error: 57.2%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.7%, epoch: 35 *******
******* Domain 4 best val test acc: 41.5%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [42/50] batch [20/403] time 0.089 (0.104) data 0.000 (0.026) loss 2.3771 (2.1282) teacher_loss 0.9495 (0.7743) loss_zs_kd 1.7459 (1.8859) loss_oracle 0.8353 (0.8870) acc 65.6250 (75.1562) lr 1.9098e-04 eta 0:06:16
epoch [42/50] batch [40/403] time 0.071 (0.094) data 0.000 (0.013) loss 2.1486 (2.1359) teacher_loss 0.7615 (0.7793) loss_zs_kd 1.9770 (1.8777) loss_oracle 0.8625 (0.9010) acc 78.1250 (73.9844) lr 1.9098e-04 eta 0:05:36
epoch [42/50] batch [60/403] time 0.090 (0.090) data 0.000 (0.009) loss 2.2314 (2.1623) teacher_loss 0.8568 (0.8014) loss_zs_kd 1.9025 (1.9088) loss_oracle 0.8564 (0.9046) acc 62.5000 (72.7604) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [80/403] time 0.086 (0.089) data 0.000 (0.007) loss 2.7361 (2.1790) teacher_loss 1.3241 (0.8212) loss_zs_kd 2.0041 (1.9010) loss_oracle 0.9238 (0.9015) acc 46.8750 (71.9141) lr 1.9098e-04 eta 0:05:13
epoch [42/50] batch [100/403] time 0.078 (0.087) data 0.000 (0.005) loss 1.9810 (2.1751) teacher_loss 0.6491 (0.8157) loss_zs_kd 1.9111 (1.9101) loss_oracle 0.8710 (0.9000) acc 81.2500 (71.8438) lr 1.9098e-04 eta 0:05:05
epoch [42/50] batch [120/403] time 0.078 (0.086) data 0.000 (0.005) loss 2.2379 (2.1618) teacher_loss 0.9089 (0.8017) loss_zs_kd 1.6041 (1.8982) loss_oracle 0.8762 (0.8975) acc 78.1250 (72.2917) lr 1.9098e-04 eta 0:05:02
epoch [42/50] batch [140/403] time 0.077 (0.085) data 0.000 (0.004) loss 2.1759 (2.1621) teacher_loss 0.7708 (0.7953) loss_zs_kd 1.8436 (1.8938) loss_oracle 0.8910 (0.8967) acc 75.0000 (72.3214) lr 1.9098e-04 eta 0:04:56
epoch [42/50] batch [160/403] time 0.088 (0.085) data 0.000 (0.003) loss 2.5323 (2.1670) teacher_loss 1.0462 (0.7973) loss_zs_kd 1.6369 (1.8970) loss_oracle 0.9144 (0.8974) acc 59.3750 (72.3242) lr 1.9098e-04 eta 0:04:53
epoch [42/50] batch [180/403] time 0.081 (0.085) data 0.000 (0.003) loss 1.8817 (2.1717) teacher_loss 0.6289 (0.8029) loss_zs_kd 1.3343 (1.9000) loss_oracle 0.8320 (0.8959) acc 81.2500 (72.2917) lr 1.9098e-04 eta 0:04:51
epoch [42/50] batch [200/403] time 0.083 (0.084) data 0.000 (0.003) loss 2.1995 (2.1696) teacher_loss 0.7481 (0.7974) loss_zs_kd 2.1178 (1.8966) loss_oracle 1.0271 (0.8947) acc 75.0000 (72.5000) lr 1.9098e-04 eta 0:04:46
epoch [42/50] batch [220/403] time 0.081 (0.083) data 0.000 (0.003) loss 1.9146 (2.1602) teacher_loss 0.5960 (0.7905) loss_zs_kd 2.3218 (1.8836) loss_oracle 0.9150 (0.8930) acc 87.5000 (72.8409) lr 1.9098e-04 eta 0:04:43
epoch [42/50] batch [240/403] time 0.161 (0.084) data 0.000 (0.002) loss 2.5991 (2.1549) teacher_loss 1.1762 (0.7845) loss_zs_kd 1.9041 (1.8844) loss_oracle 0.9425 (0.8925) acc 62.5000 (72.9557) lr 1.9098e-04 eta 0:04:45
epoch [42/50] batch [260/403] time 0.083 (0.084) data 0.000 (0.002) loss 1.9512 (2.1515) teacher_loss 0.6076 (0.7816) loss_zs_kd 1.9274 (1.8846) loss_oracle 0.8482 (0.8917) acc 71.8750 (73.1010) lr 1.9098e-04 eta 0:04:44
epoch [42/50] batch [280/403] time 0.089 (0.084) data 0.000 (0.002) loss 2.1628 (2.1517) teacher_loss 0.6530 (0.7786) loss_zs_kd 2.0696 (1.8859) loss_oracle 0.9688 (0.8925) acc 71.8750 (73.1027) lr 1.9098e-04 eta 0:04:42
epoch [42/50] batch [300/403] time 0.073 (0.084) data 0.000 (0.002) loss 1.7875 (2.1411) teacher_loss 0.4295 (0.7693) loss_zs_kd 1.6918 (1.8848) loss_oracle 0.8725 (0.8916) acc 93.7500 (73.4062) lr 1.9098e-04 eta 0:04:40
epoch [42/50] batch [320/403] time 0.079 (0.084) data 0.000 (0.002) loss 2.5985 (2.1474) teacher_loss 1.1536 (0.7739) loss_zs_kd 2.3549 (1.8857) loss_oracle 0.9341 (0.8913) acc 62.5000 (73.3789) lr 1.9098e-04 eta 0:04:37
epoch [42/50] batch [340/403] time 0.084 (0.084) data 0.000 (0.002) loss 2.2298 (2.1479) teacher_loss 0.8760 (0.7741) loss_zs_kd 2.2273 (1.8879) loss_oracle 0.8297 (0.8899) acc 78.1250 (73.3732) lr 1.9098e-04 eta 0:04:35
epoch [42/50] batch [360/403] time 0.072 (0.083) data 0.000 (0.002) loss 2.0256 (2.1522) teacher_loss 0.6300 (0.7781) loss_zs_kd 1.4588 (1.8863) loss_oracle 0.8821 (0.8899) acc 81.2500 (73.2639) lr 1.9098e-04 eta 0:04:32
epoch [42/50] batch [380/403] time 0.074 (0.083) data 0.000 (0.002) loss 2.0269 (2.1512) teacher_loss 0.6055 (0.7775) loss_zs_kd 1.6542 (1.8855) loss_oracle 0.8336 (0.8900) acc 84.3750 (73.3388) lr 1.9098e-04 eta 0:04:30
epoch [42/50] batch [400/403] time 0.076 (0.083) data 0.000 (0.002) loss 2.0804 (2.1554) teacher_loss 0.7584 (0.7807) loss_zs_kd 1.6549 (1.8871) loss_oracle 0.9201 (0.8899) acc 75.0000 (73.1016) lr 1.9098e-04 eta 0:04:27
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,030
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 61.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,543
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 33.0%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [43/50] batch [20/403] time 0.084 (0.130) data 0.000 (0.031) loss 2.6512 (2.1473) teacher_loss 1.1090 (0.7680) loss_zs_kd 2.1222 (1.8278) loss_oracle 0.9414 (0.8866) acc 59.3750 (75.0000) lr 1.5567e-04 eta 0:06:55
epoch [43/50] batch [40/403] time 0.095 (0.106) data 0.000 (0.016) loss 2.1667 (2.1604) teacher_loss 0.9003 (0.7811) loss_zs_kd 1.4998 (1.8040) loss_oracle 0.8584 (0.8831) acc 65.6250 (72.5781) lr 1.5567e-04 eta 0:05:37
epoch [43/50] batch [60/403] time 0.093 (0.095) data 0.002 (0.011) loss 2.3671 (2.1366) teacher_loss 1.0171 (0.7593) loss_zs_kd 1.8001 (1.8280) loss_oracle 0.9117 (0.8842) acc 71.8750 (73.6979) lr 1.5567e-04 eta 0:05:01
epoch [43/50] batch [80/403] time 0.072 (0.091) data 0.000 (0.008) loss 2.1139 (2.1404) teacher_loss 0.7063 (0.7648) loss_zs_kd 1.5456 (1.8052) loss_oracle 0.8816 (0.8859) acc 78.1250 (73.2031) lr 1.5567e-04 eta 0:04:44
epoch [43/50] batch [100/403] time 0.080 (0.089) data 0.000 (0.007) loss 1.9573 (2.1586) teacher_loss 0.6749 (0.7755) loss_zs_kd 1.9490 (1.8270) loss_oracle 0.8747 (0.8858) acc 81.2500 (72.7188) lr 1.5567e-04 eta 0:04:38
epoch [43/50] batch [120/403] time 0.073 (0.086) data 0.000 (0.005) loss 2.5413 (2.1630) teacher_loss 1.1124 (0.7826) loss_zs_kd 1.7862 (1.8293) loss_oracle 0.8927 (0.8852) acc 53.1250 (72.1094) lr 1.5567e-04 eta 0:04:27
epoch [43/50] batch [140/403] time 0.079 (0.085) data 0.000 (0.005) loss 2.3243 (2.1634) teacher_loss 0.8633 (0.7842) loss_zs_kd 1.9397 (1.8277) loss_oracle 0.9418 (0.8859) acc 59.3750 (71.8527) lr 1.5567e-04 eta 0:04:23
epoch [43/50] batch [160/403] time 0.069 (0.084) data 0.000 (0.004) loss 2.1229 (2.1596) teacher_loss 0.7435 (0.7849) loss_zs_kd 2.1771 (1.8376) loss_oracle 0.8759 (0.8854) acc 75.0000 (71.8164) lr 1.5567e-04 eta 0:04:18
epoch [43/50] batch [180/403] time 0.077 (0.083) data 0.000 (0.004) loss 2.1729 (2.1587) teacher_loss 0.8138 (0.7851) loss_zs_kd 2.1161 (1.8413) loss_oracle 0.9243 (0.8840) acc 71.8750 (71.6493) lr 1.5567e-04 eta 0:04:13
epoch [43/50] batch [200/403] time 0.059 (0.082) data 0.000 (0.003) loss 2.2187 (2.1622) teacher_loss 0.8420 (0.7859) loss_zs_kd 1.6434 (1.8311) loss_oracle 0.8643 (0.8842) acc 68.7500 (71.7656) lr 1.5567e-04 eta 0:04:08
epoch [43/50] batch [220/403] time 0.061 (0.080) data 0.000 (0.003) loss 1.8481 (2.1636) teacher_loss 0.4628 (0.7855) loss_zs_kd 1.9872 (1.8344) loss_oracle 0.9199 (0.8850) acc 81.2500 (71.8892) lr 1.5567e-04 eta 0:04:01
epoch [43/50] batch [240/403] time 0.081 (0.080) data 0.000 (0.003) loss 2.2387 (2.1673) teacher_loss 0.9658 (0.7906) loss_zs_kd 1.9557 (1.8412) loss_oracle 0.8400 (0.8851) acc 56.2500 (71.7839) lr 1.5567e-04 eta 0:03:58
epoch [43/50] batch [260/403] time 0.082 (0.080) data 0.000 (0.003) loss 2.3827 (2.1652) teacher_loss 0.9577 (0.7899) loss_zs_kd 2.1398 (1.8419) loss_oracle 0.9213 (0.8845) acc 65.6250 (71.8149) lr 1.5567e-04 eta 0:03:56
epoch [43/50] batch [280/403] time 0.078 (0.080) data 0.000 (0.002) loss 2.3897 (2.1615) teacher_loss 1.0899 (0.7871) loss_zs_kd 1.9085 (1.8440) loss_oracle 0.8604 (0.8842) acc 62.5000 (71.9196) lr 1.5567e-04 eta 0:03:54
epoch [43/50] batch [300/403] time 0.074 (0.080) data 0.000 (0.002) loss 2.1085 (2.1614) teacher_loss 0.6464 (0.7880) loss_zs_kd 1.9178 (1.8418) loss_oracle 0.9327 (0.8840) acc 78.1250 (72.0312) lr 1.5567e-04 eta 0:03:52
epoch [43/50] batch [320/403] time 0.072 (0.080) data 0.000 (0.002) loss 2.1541 (2.1673) teacher_loss 0.7746 (0.7925) loss_zs_kd 2.2022 (1.8470) loss_oracle 0.8686 (0.8852) acc 71.8750 (71.9531) lr 1.5567e-04 eta 0:03:50
epoch [43/50] batch [340/403] time 0.073 (0.080) data 0.001 (0.002) loss 2.0747 (2.1697) teacher_loss 0.8767 (0.7955) loss_zs_kd 1.9594 (1.8436) loss_oracle 0.8678 (0.8853) acc 71.8750 (71.8474) lr 1.5567e-04 eta 0:03:49
epoch [43/50] batch [360/403] time 0.070 (0.079) data 0.000 (0.002) loss 2.0757 (2.1685) teacher_loss 0.7040 (0.7949) loss_zs_kd 2.3680 (1.8440) loss_oracle 0.8795 (0.8851) acc 75.0000 (71.8490) lr 1.5567e-04 eta 0:03:47
epoch [43/50] batch [380/403] time 0.087 (0.080) data 0.000 (0.002) loss 2.3052 (2.1702) teacher_loss 0.8334 (0.7965) loss_zs_kd 2.3644 (1.8443) loss_oracle 0.9359 (0.8853) acc 65.6250 (71.7845) lr 1.5567e-04 eta 0:03:46
epoch [43/50] batch [400/403] time 0.076 (0.080) data 0.000 (0.002) loss 2.2551 (2.1717) teacher_loss 0.8372 (0.7975) loss_zs_kd 1.7348 (1.8393) loss_oracle 0.8881 (0.8849) acc 75.0000 (71.7500) lr 1.5567e-04 eta 0:03:44
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,019
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 60.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,554
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [44/50] batch [20/403] time 0.079 (0.112) data 0.000 (0.027) loss 1.9082 (2.1594) teacher_loss 0.6079 (0.7936) loss_zs_kd 1.6302 (1.7260) loss_oracle 0.8325 (0.8903) acc 78.1250 (72.0312) lr 1.2369e-04 eta 0:05:13
epoch [44/50] batch [40/403] time 0.080 (0.098) data 0.000 (0.014) loss 2.0219 (2.1716) teacher_loss 0.6445 (0.8007) loss_zs_kd 1.6511 (1.7558) loss_oracle 0.9141 (0.8846) acc 78.1250 (71.7188) lr 1.2369e-04 eta 0:04:33
epoch [44/50] batch [60/403] time 0.080 (0.093) data 0.000 (0.009) loss 2.1215 (2.1560) teacher_loss 0.6681 (0.7865) loss_zs_kd 1.7022 (1.7299) loss_oracle 0.9148 (0.8819) acc 84.3750 (72.0833) lr 1.2369e-04 eta 0:04:17
epoch [44/50] batch [80/403] time 0.082 (0.091) data 0.000 (0.007) loss 2.2605 (2.1656) teacher_loss 0.9140 (0.7918) loss_zs_kd 1.5435 (1.7490) loss_oracle 0.8987 (0.8842) acc 62.5000 (72.6562) lr 1.2369e-04 eta 0:04:08
epoch [44/50] batch [100/403] time 0.074 (0.088) data 0.000 (0.006) loss 2.2502 (2.1511) teacher_loss 0.8627 (0.7823) loss_zs_kd 2.0123 (1.7655) loss_oracle 0.8854 (0.8829) acc 65.6250 (72.7500) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [120/403] time 0.084 (0.088) data 0.000 (0.005) loss 2.1914 (2.1526) teacher_loss 0.7911 (0.7850) loss_zs_kd 2.3397 (1.7901) loss_oracle 0.8912 (0.8830) acc 71.8750 (72.4219) lr 1.2369e-04 eta 0:03:56
epoch [44/50] batch [140/403] time 0.081 (0.087) data 0.000 (0.004) loss 1.7479 (2.1582) teacher_loss 0.5110 (0.7899) loss_zs_kd 1.7170 (1.7955) loss_oracle 0.8531 (0.8811) acc 87.5000 (72.4107) lr 1.2369e-04 eta 0:03:51
epoch [44/50] batch [160/403] time 0.083 (0.086) data 0.000 (0.004) loss 2.0584 (2.1486) teacher_loss 0.6282 (0.7825) loss_zs_kd 1.6098 (1.8098) loss_oracle 0.9535 (0.8810) acc 75.0000 (72.5586) lr 1.2369e-04 eta 0:03:48
epoch [44/50] batch [180/403] time 0.081 (0.085) data 0.000 (0.003) loss 2.1803 (2.1501) teacher_loss 0.6649 (0.7827) loss_zs_kd 1.8553 (1.8110) loss_oracle 0.9861 (0.8814) acc 71.8750 (72.5000) lr 1.2369e-04 eta 0:03:45
epoch [44/50] batch [200/403] time 0.079 (0.086) data 0.000 (0.003) loss 2.3404 (2.1528) teacher_loss 1.0460 (0.7817) loss_zs_kd 1.7642 (1.8097) loss_oracle 0.8348 (0.8815) acc 75.0000 (72.4688) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [220/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.9960 (2.1536) teacher_loss 0.6083 (0.7841) loss_zs_kd 2.0266 (1.8120) loss_oracle 0.9539 (0.8811) acc 78.1250 (72.3438) lr 1.2369e-04 eta 0:03:43
epoch [44/50] batch [240/403] time 0.077 (0.086) data 0.000 (0.003) loss 2.0756 (2.1549) teacher_loss 0.7375 (0.7857) loss_zs_kd 1.7479 (1.8143) loss_oracle 0.9293 (0.8819) acc 62.5000 (72.2656) lr 1.2369e-04 eta 0:03:40
epoch [44/50] batch [260/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.9706 (2.1563) teacher_loss 0.7219 (0.7861) loss_zs_kd 1.9701 (1.8259) loss_oracle 0.8339 (0.8830) acc 75.0000 (72.2837) lr 1.2369e-04 eta 0:03:37
epoch [44/50] batch [280/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.0652 (2.1586) teacher_loss 0.7551 (0.7886) loss_zs_kd 1.6786 (1.8245) loss_oracle 0.8484 (0.8826) acc 65.6250 (72.1429) lr 1.2369e-04 eta 0:03:35
epoch [44/50] batch [300/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.0901 (2.1540) teacher_loss 0.6904 (0.7852) loss_zs_kd 2.0859 (1.8209) loss_oracle 0.8849 (0.8827) acc 75.0000 (72.5000) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [320/403] time 0.087 (0.085) data 0.000 (0.002) loss 2.0168 (2.1541) teacher_loss 0.7297 (0.7863) loss_zs_kd 1.6060 (1.8245) loss_oracle 0.8357 (0.8826) acc 78.1250 (72.5391) lr 1.2369e-04 eta 0:03:31
epoch [44/50] batch [340/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.8997 (2.1530) teacher_loss 0.5787 (0.7874) loss_zs_kd 1.6525 (1.8264) loss_oracle 0.8916 (0.8821) acc 81.2500 (72.5643) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [360/403] time 0.089 (0.085) data 0.000 (0.002) loss 2.1448 (2.1533) teacher_loss 0.7246 (0.7876) loss_zs_kd 1.9812 (1.8295) loss_oracle 0.8607 (0.8824) acc 62.5000 (72.4826) lr 1.2369e-04 eta 0:03:28
epoch [44/50] batch [380/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.0913 (2.1523) teacher_loss 0.6475 (0.7862) loss_zs_kd 1.5882 (1.8275) loss_oracle 0.8835 (0.8825) acc 71.8750 (72.5164) lr 1.2369e-04 eta 0:03:27
epoch [44/50] batch [400/403] time 0.079 (0.085) data 0.000 (0.002) loss 2.0567 (2.1524) teacher_loss 0.6308 (0.7862) loss_zs_kd 1.7319 (1.8269) loss_oracle 0.8726 (0.8826) acc 78.1250 (72.4688) lr 1.2369e-04 eta 0:03:25
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,002
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,509
* accuracy: 42.6%
* error: 57.4%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [45/50] batch [20/403] time 0.090 (0.118) data 0.000 (0.033) loss 2.1376 (2.1401) teacher_loss 0.8292 (0.7991) loss_zs_kd 2.0179 (1.8859) loss_oracle 0.8513 (0.8804) acc 65.6250 (72.5000) lr 9.5173e-05 eta 0:04:43
epoch [45/50] batch [40/403] time 0.084 (0.100) data 0.000 (0.017) loss 2.0873 (2.1253) teacher_loss 0.6942 (0.7764) loss_zs_kd 1.7904 (1.8352) loss_oracle 0.8690 (0.8777) acc 78.1250 (73.3594) lr 9.5173e-05 eta 0:03:57
epoch [45/50] batch [60/403] time 0.087 (0.096) data 0.000 (0.011) loss 2.0446 (2.1376) teacher_loss 0.7506 (0.7859) loss_zs_kd 2.0632 (1.8454) loss_oracle 0.8145 (0.8802) acc 78.1250 (73.3333) lr 9.5173e-05 eta 0:03:45
epoch [45/50] batch [80/403] time 0.081 (0.092) data 0.000 (0.008) loss 2.3336 (2.1514) teacher_loss 0.7622 (0.7987) loss_zs_kd 1.7177 (1.8499) loss_oracle 0.9533 (0.8828) acc 78.1250 (72.8906) lr 9.5173e-05 eta 0:03:34
epoch [45/50] batch [100/403] time 0.079 (0.089) data 0.000 (0.007) loss 2.1914 (2.1437) teacher_loss 0.8477 (0.7873) loss_zs_kd 1.8189 (1.8458) loss_oracle 0.8867 (0.8821) acc 71.8750 (73.2812) lr 9.5173e-05 eta 0:03:27
epoch [45/50] batch [120/403] time 0.091 (0.088) data 0.000 (0.006) loss 2.1505 (2.1407) teacher_loss 0.7701 (0.7829) loss_zs_kd 2.2377 (1.8472) loss_oracle 0.8896 (0.8840) acc 75.0000 (73.5156) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [140/403] time 0.078 (0.087) data 0.000 (0.005) loss 2.1479 (2.1409) teacher_loss 0.6919 (0.7800) loss_zs_kd 1.8706 (1.8410) loss_oracle 0.8773 (0.8832) acc 78.1250 (73.3705) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [160/403] time 0.074 (0.087) data 0.000 (0.004) loss 2.3155 (2.1530) teacher_loss 0.8748 (0.7908) loss_zs_kd 2.0806 (1.8514) loss_oracle 0.8650 (0.8840) acc 65.6250 (72.7734) lr 9.5173e-05 eta 0:03:15
epoch [45/50] batch [180/403] time 0.086 (0.087) data 0.000 (0.004) loss 2.0420 (2.1523) teacher_loss 0.7290 (0.7908) loss_zs_kd 1.7364 (1.8546) loss_oracle 0.9681 (0.8839) acc 75.0000 (72.7951) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [200/403] time 0.088 (0.086) data 0.000 (0.004) loss 2.5276 (2.1481) teacher_loss 0.9985 (0.7848) loss_zs_kd 1.4739 (1.8643) loss_oracle 0.9516 (0.8852) acc 53.1250 (72.8438) lr 9.5173e-05 eta 0:03:10
epoch [45/50] batch [220/403] time 0.080 (0.086) data 0.000 (0.003) loss 1.8558 (2.1512) teacher_loss 0.5345 (0.7867) loss_zs_kd 2.0397 (1.8671) loss_oracle 0.9049 (0.8850) acc 87.5000 (72.9119) lr 9.5173e-05 eta 0:03:08
epoch [45/50] batch [240/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.1711 (2.1528) teacher_loss 0.7177 (0.7880) loss_zs_kd 1.7596 (1.8656) loss_oracle 0.9204 (0.8849) acc 71.8750 (72.8255) lr 9.5173e-05 eta 0:03:05
epoch [45/50] batch [260/403] time 0.088 (0.085) data 0.000 (0.003) loss 2.1539 (2.1530) teacher_loss 0.8644 (0.7882) loss_zs_kd 1.8500 (1.8716) loss_oracle 0.8467 (0.8836) acc 75.0000 (72.8486) lr 9.5173e-05 eta 0:03:03
epoch [45/50] batch [280/403] time 0.077 (0.085) data 0.000 (0.003) loss 2.3350 (2.1582) teacher_loss 0.9689 (0.7916) loss_zs_kd 1.9964 (1.8720) loss_oracle 0.9429 (0.8847) acc 59.3750 (72.7344) lr 9.5173e-05 eta 0:03:01
epoch [45/50] batch [300/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.2662 (2.1583) teacher_loss 0.7417 (0.7920) loss_zs_kd 1.9671 (1.8733) loss_oracle 0.8851 (0.8841) acc 78.1250 (72.8229) lr 9.5173e-05 eta 0:02:59
epoch [45/50] batch [320/403] time 0.087 (0.085) data 0.000 (0.002) loss 2.2486 (2.1571) teacher_loss 0.8570 (0.7905) loss_zs_kd 2.0038 (1.8660) loss_oracle 0.9518 (0.8840) acc 71.8750 (72.8320) lr 9.5173e-05 eta 0:02:57
epoch [45/50] batch [340/403] time 0.156 (0.085) data 0.001 (0.002) loss 2.2626 (2.1559) teacher_loss 0.8485 (0.7879) loss_zs_kd 2.2308 (1.8683) loss_oracle 0.8735 (0.8854) acc 65.6250 (72.8768) lr 9.5173e-05 eta 0:02:57
epoch [45/50] batch [360/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.0335 (2.1526) teacher_loss 0.7172 (0.7850) loss_zs_kd 1.4336 (1.8703) loss_oracle 0.8739 (0.8853) acc 75.0000 (72.9948) lr 9.5173e-05 eta 0:02:55
epoch [45/50] batch [380/403] time 0.087 (0.085) data 0.000 (0.002) loss 2.1337 (2.1534) teacher_loss 0.6915 (0.7846) loss_zs_kd 1.9893 (1.8678) loss_oracle 0.8934 (0.8855) acc 71.8750 (72.8783) lr 9.5173e-05 eta 0:02:54
epoch [45/50] batch [400/403] time 0.086 (0.085) data 0.001 (0.002) loss 2.1740 (2.1518) teacher_loss 0.8516 (0.7831) loss_zs_kd 1.8866 (1.8610) loss_oracle 0.8255 (0.8855) acc 68.7500 (72.8984) lr 9.5173e-05 eta 0:02:51
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,002
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,538
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.9%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [46/50] batch [20/403] time 0.091 (0.124) data 0.000 (0.034) loss 1.9485 (2.1497) teacher_loss 0.5971 (0.7742) loss_zs_kd 1.6452 (1.7724) loss_oracle 0.8519 (0.8703) acc 75.0000 (71.7188) lr 7.0224e-05 eta 0:04:06
epoch [46/50] batch [40/403] time 0.086 (0.103) data 0.000 (0.017) loss 1.8669 (2.1234) teacher_loss 0.4900 (0.7569) loss_zs_kd 1.9567 (1.8484) loss_oracle 0.8775 (0.8766) acc 84.3750 (72.5781) lr 7.0224e-05 eta 0:03:23
epoch [46/50] batch [60/403] time 0.084 (0.097) data 0.001 (0.012) loss 1.9910 (2.1161) teacher_loss 0.6436 (0.7520) loss_zs_kd 1.8990 (1.8276) loss_oracle 0.9092 (0.8808) acc 78.1250 (72.6042) lr 7.0224e-05 eta 0:03:10
epoch [46/50] batch [80/403] time 0.086 (0.094) data 0.000 (0.009) loss 2.2755 (2.1304) teacher_loss 0.8340 (0.7657) loss_zs_kd 1.8590 (1.8576) loss_oracle 0.9160 (0.8826) acc 65.6250 (72.1875) lr 7.0224e-05 eta 0:03:01
epoch [46/50] batch [100/403] time 0.168 (0.096) data 0.001 (0.007) loss 1.9654 (2.1296) teacher_loss 0.5979 (0.7617) loss_zs_kd 2.2701 (1.8677) loss_oracle 0.9420 (0.8808) acc 84.3750 (72.8438) lr 7.0224e-05 eta 0:03:03
epoch [46/50] batch [120/403] time 0.076 (0.094) data 0.000 (0.006) loss 2.1027 (2.1338) teacher_loss 0.6527 (0.7674) loss_zs_kd 1.7673 (1.8657) loss_oracle 0.8917 (0.8798) acc 75.0000 (72.9167) lr 7.0224e-05 eta 0:02:57
epoch [46/50] batch [140/403] time 0.083 (0.093) data 0.000 (0.005) loss 2.1129 (2.1340) teacher_loss 0.6839 (0.7686) loss_zs_kd 1.9831 (1.8601) loss_oracle 0.9002 (0.8808) acc 78.1250 (72.9241) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [160/403] time 0.082 (0.092) data 0.000 (0.005) loss 2.2909 (2.1358) teacher_loss 0.8320 (0.7701) loss_zs_kd 1.7302 (1.8623) loss_oracle 0.9491 (0.8813) acc 62.5000 (72.8125) lr 7.0224e-05 eta 0:02:49
epoch [46/50] batch [180/403] time 0.087 (0.091) data 0.000 (0.004) loss 2.1250 (2.1376) teacher_loss 0.6970 (0.7704) loss_zs_kd 1.5283 (1.8601) loss_oracle 0.8674 (0.8808) acc 78.1250 (72.9167) lr 7.0224e-05 eta 0:02:46
epoch [46/50] batch [200/403] time 0.084 (0.090) data 0.000 (0.004) loss 2.1188 (2.1286) teacher_loss 0.7112 (0.7631) loss_zs_kd 1.8889 (1.8538) loss_oracle 0.9111 (0.8804) acc 71.8750 (73.3438) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [220/403] time 0.079 (0.089) data 0.000 (0.003) loss 2.2286 (2.1358) teacher_loss 0.7885 (0.7674) loss_zs_kd 2.1227 (1.8538) loss_oracle 0.8501 (0.8808) acc 65.6250 (73.1818) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [240/403] time 0.088 (0.089) data 0.000 (0.003) loss 2.0428 (2.1340) teacher_loss 0.6651 (0.7663) loss_zs_kd 2.2168 (1.8596) loss_oracle 0.8352 (0.8804) acc 71.8750 (73.2292) lr 7.0224e-05 eta 0:02:37
epoch [46/50] batch [260/403] time 0.089 (0.088) data 0.000 (0.003) loss 2.1392 (2.1418) teacher_loss 0.7504 (0.7731) loss_zs_kd 1.9302 (1.8569) loss_oracle 0.8399 (0.8804) acc 71.8750 (72.9447) lr 7.0224e-05 eta 0:02:35
epoch [46/50] batch [280/403] time 0.089 (0.088) data 0.000 (0.003) loss 2.3154 (2.1411) teacher_loss 0.8673 (0.7739) loss_zs_kd 1.7370 (1.8499) loss_oracle 0.9266 (0.8805) acc 71.8750 (72.9799) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [300/403] time 0.073 (0.088) data 0.000 (0.003) loss 2.1921 (2.1408) teacher_loss 0.8304 (0.7737) loss_zs_kd 1.9284 (1.8545) loss_oracle 0.8976 (0.8802) acc 78.1250 (73.0104) lr 7.0224e-05 eta 0:02:30
epoch [46/50] batch [320/403] time 0.085 (0.087) data 0.000 (0.002) loss 2.6103 (2.1440) teacher_loss 1.3168 (0.7769) loss_zs_kd 1.7339 (1.8536) loss_oracle 0.8909 (0.8801) acc 53.1250 (72.8418) lr 7.0224e-05 eta 0:02:28
epoch [46/50] batch [340/403] time 0.082 (0.087) data 0.000 (0.002) loss 2.0255 (2.1430) teacher_loss 0.5658 (0.7733) loss_zs_kd 2.2662 (1.8533) loss_oracle 0.9109 (0.8812) acc 84.3750 (73.0515) lr 7.0224e-05 eta 0:02:26
epoch [46/50] batch [360/403] time 0.075 (0.087) data 0.000 (0.002) loss 2.1787 (2.1424) teacher_loss 0.7665 (0.7737) loss_zs_kd 1.9783 (1.8546) loss_oracle 0.9019 (0.8812) acc 68.7500 (73.1250) lr 7.0224e-05 eta 0:02:24
epoch [46/50] batch [380/403] time 0.089 (0.087) data 0.000 (0.002) loss 2.0979 (2.1469) teacher_loss 0.7040 (0.7786) loss_zs_kd 1.8436 (1.8536) loss_oracle 0.8903 (0.8818) acc 75.0000 (72.8947) lr 7.0224e-05 eta 0:02:22
epoch [46/50] batch [400/403] time 0.085 (0.087) data 0.000 (0.002) loss 2.2377 (2.1485) teacher_loss 0.8613 (0.7793) loss_zs_kd 1.9845 (1.8541) loss_oracle 0.8820 (0.8826) acc 65.6250 (72.8672) lr 7.0224e-05 eta 0:02:20
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,000
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,546
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [47/50] batch [20/403] time 0.083 (0.121) data 0.000 (0.029) loss 2.4159 (2.1460) teacher_loss 1.0860 (0.7519) loss_zs_kd 2.2520 (2.0435) loss_oracle 0.8593 (0.8831) acc 65.6250 (73.9062) lr 4.8943e-05 eta 0:03:12
epoch [47/50] batch [40/403] time 0.086 (0.102) data 0.000 (0.014) loss 1.8653 (2.1370) teacher_loss 0.5568 (0.7565) loss_zs_kd 1.5604 (1.9347) loss_oracle 0.8340 (0.8922) acc 81.2500 (73.6719) lr 4.8943e-05 eta 0:02:39
epoch [47/50] batch [60/403] time 0.088 (0.097) data 0.001 (0.010) loss 1.9841 (2.1476) teacher_loss 0.7044 (0.7713) loss_zs_kd 1.8924 (1.9099) loss_oracle 0.9216 (0.8872) acc 75.0000 (73.1771) lr 4.8943e-05 eta 0:02:30
epoch [47/50] batch [80/403] time 0.086 (0.094) data 0.000 (0.007) loss 2.3265 (2.1442) teacher_loss 0.9935 (0.7718) loss_zs_kd 1.5034 (1.8899) loss_oracle 0.8819 (0.8858) acc 71.8750 (73.1641) lr 4.8943e-05 eta 0:02:23
epoch [47/50] batch [100/403] time 0.091 (0.092) data 0.000 (0.006) loss 2.2133 (2.1480) teacher_loss 0.8306 (0.7752) loss_zs_kd 1.5779 (1.8795) loss_oracle 0.8243 (0.8864) acc 65.6250 (73.0625) lr 4.8943e-05 eta 0:02:19
epoch [47/50] batch [120/403] time 0.101 (0.092) data 0.001 (0.005) loss 2.1902 (2.1373) teacher_loss 0.7264 (0.7615) loss_zs_kd 2.6074 (1.8928) loss_oracle 0.9012 (0.8883) acc 75.0000 (73.7500) lr 4.8943e-05 eta 0:02:16
epoch [47/50] batch [140/403] time 0.081 (0.090) data 0.000 (0.004) loss 2.3446 (2.1500) teacher_loss 0.9487 (0.7731) loss_zs_kd 2.2028 (1.8936) loss_oracle 0.8583 (0.8909) acc 65.6250 (73.1473) lr 4.8943e-05 eta 0:02:12
epoch [47/50] batch [160/403] time 0.076 (0.089) data 0.000 (0.004) loss 2.1055 (2.1651) teacher_loss 0.6257 (0.7831) loss_zs_kd 2.0061 (1.9002) loss_oracle 0.8606 (0.8926) acc 75.0000 (72.9688) lr 4.8943e-05 eta 0:02:09
epoch [47/50] batch [180/403] time 0.082 (0.088) data 0.000 (0.003) loss 1.9147 (2.1685) teacher_loss 0.5994 (0.7859) loss_zs_kd 2.0783 (1.8968) loss_oracle 0.8713 (0.8915) acc 75.0000 (72.5174) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [200/403] time 0.079 (0.089) data 0.000 (0.003) loss 2.3464 (2.1665) teacher_loss 0.9653 (0.7848) loss_zs_kd 2.0503 (1.8920) loss_oracle 0.8759 (0.8912) acc 71.8750 (72.4375) lr 4.8943e-05 eta 0:02:05
epoch [47/50] batch [220/403] time 0.080 (0.088) data 0.000 (0.003) loss 2.1119 (2.1605) teacher_loss 0.7896 (0.7810) loss_zs_kd 2.0057 (1.8864) loss_oracle 0.8900 (0.8894) acc 68.7500 (72.5426) lr 4.8943e-05 eta 0:02:02
epoch [47/50] batch [240/403] time 0.084 (0.089) data 0.000 (0.003) loss 1.7677 (2.1601) teacher_loss 0.5024 (0.7813) loss_zs_kd 1.9232 (1.8919) loss_oracle 0.8257 (0.8884) acc 75.0000 (72.5130) lr 4.8943e-05 eta 0:02:01
epoch [47/50] batch [260/403] time 0.083 (0.088) data 0.000 (0.002) loss 2.1328 (2.1608) teacher_loss 0.7784 (0.7821) loss_zs_kd 2.0818 (1.8896) loss_oracle 0.8849 (0.8879) acc 71.8750 (72.4399) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [280/403] time 0.089 (0.088) data 0.000 (0.002) loss 2.1766 (2.1584) teacher_loss 0.9014 (0.7818) loss_zs_kd 1.9430 (1.8943) loss_oracle 0.8360 (0.8875) acc 68.7500 (72.5670) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [300/403] time 0.089 (0.088) data 0.000 (0.002) loss 2.3243 (2.1605) teacher_loss 0.9236 (0.7830) loss_zs_kd 2.0745 (1.8985) loss_oracle 0.9610 (0.8880) acc 68.7500 (72.5000) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [320/403] time 0.084 (0.088) data 0.000 (0.002) loss 2.2044 (2.1636) teacher_loss 0.7481 (0.7859) loss_zs_kd 2.4124 (1.8941) loss_oracle 0.9224 (0.8877) acc 68.7500 (72.4902) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [340/403] time 0.085 (0.088) data 0.001 (0.002) loss 1.7947 (2.1584) teacher_loss 0.5158 (0.7815) loss_zs_kd 1.9061 (1.8888) loss_oracle 0.8656 (0.8880) acc 84.3750 (72.6471) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [360/403] time 0.079 (0.088) data 0.000 (0.002) loss 2.3101 (2.1561) teacher_loss 0.9542 (0.7792) loss_zs_kd 2.2280 (1.8811) loss_oracle 0.8495 (0.8885) acc 56.2500 (72.6910) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [380/403] time 0.085 (0.087) data 0.000 (0.002) loss 1.9400 (2.1551) teacher_loss 0.5650 (0.7776) loss_zs_kd 1.6560 (1.8808) loss_oracle 0.8924 (0.8883) acc 84.3750 (72.6727) lr 4.8943e-05 eta 0:01:47
epoch [47/50] batch [400/403] time 0.065 (0.087) data 0.000 (0.002) loss 2.0180 (2.1528) teacher_loss 0.6970 (0.7760) loss_zs_kd 2.0071 (1.8792) loss_oracle 0.8171 (0.8876) acc 75.0000 (72.7422) lr 4.8943e-05 eta 0:01:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,995
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,533
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.3%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [48/50] batch [20/403] time 0.091 (0.117) data 0.000 (0.026) loss 1.9402 (2.1329) teacher_loss 0.6101 (0.7849) loss_zs_kd 1.6154 (1.8602) loss_oracle 0.8484 (0.8727) acc 81.2500 (74.2188) lr 3.1417e-05 eta 0:02:19
epoch [48/50] batch [40/403] time 0.093 (0.101) data 0.000 (0.013) loss 2.1886 (2.1515) teacher_loss 0.7684 (0.7872) loss_zs_kd 2.0163 (1.8611) loss_oracle 0.9019 (0.8839) acc 78.1250 (73.2031) lr 3.1417e-05 eta 0:01:57
epoch [48/50] batch [60/403] time 0.088 (0.095) data 0.000 (0.009) loss 1.8346 (2.1398) teacher_loss 0.4139 (0.7755) loss_zs_kd 1.6865 (1.8470) loss_oracle 0.9289 (0.8845) acc 90.6250 (72.9688) lr 3.1417e-05 eta 0:01:48
epoch [48/50] batch [80/403] time 0.084 (0.092) data 0.000 (0.007) loss 2.0389 (2.1537) teacher_loss 0.6446 (0.7894) loss_zs_kd 2.4114 (1.8654) loss_oracle 0.9027 (0.8843) acc 81.2500 (72.6953) lr 3.1417e-05 eta 0:01:44
epoch [48/50] batch [100/403] time 0.086 (0.091) data 0.000 (0.006) loss 2.1039 (2.1429) teacher_loss 0.6635 (0.7766) loss_zs_kd 2.0144 (1.8702) loss_oracle 0.8960 (0.8838) acc 81.2500 (73.1875) lr 3.1417e-05 eta 0:01:40
epoch [48/50] batch [120/403] time 0.087 (0.090) data 0.000 (0.005) loss 2.2253 (2.1313) teacher_loss 0.8804 (0.7686) loss_zs_kd 1.8854 (1.8733) loss_oracle 0.9466 (0.8826) acc 71.8750 (73.2812) lr 3.1417e-05 eta 0:01:37
epoch [48/50] batch [140/403] time 0.087 (0.090) data 0.000 (0.004) loss 1.9629 (2.1310) teacher_loss 0.6274 (0.7663) loss_zs_kd 1.9967 (1.8670) loss_oracle 0.8568 (0.8824) acc 75.0000 (73.3929) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [160/403] time 0.087 (0.089) data 0.000 (0.004) loss 1.9234 (2.1373) teacher_loss 0.5360 (0.7677) loss_zs_kd 1.9554 (1.8756) loss_oracle 0.8952 (0.8835) acc 84.3750 (73.3398) lr 3.1417e-05 eta 0:01:33
epoch [48/50] batch [180/403] time 0.085 (0.089) data 0.000 (0.003) loss 2.1558 (2.1395) teacher_loss 0.7237 (0.7688) loss_zs_kd 2.3721 (1.8781) loss_oracle 0.9835 (0.8865) acc 81.2500 (73.4375) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [200/403] time 0.082 (0.088) data 0.000 (0.003) loss 2.4028 (2.1435) teacher_loss 0.9568 (0.7700) loss_zs_kd 1.8212 (1.8715) loss_oracle 0.9218 (0.8885) acc 65.6250 (73.4531) lr 3.1417e-05 eta 0:01:29
epoch [48/50] batch [220/403] time 0.090 (0.088) data 0.000 (0.003) loss 2.2280 (2.1444) teacher_loss 0.9097 (0.7721) loss_zs_kd 1.7915 (1.8662) loss_oracle 0.9695 (0.8887) acc 68.7500 (73.2955) lr 3.1417e-05 eta 0:01:27
epoch [48/50] batch [240/403] time 0.106 (0.089) data 0.001 (0.003) loss 2.0410 (2.1484) teacher_loss 0.7134 (0.7750) loss_zs_kd 2.1341 (1.8626) loss_oracle 0.8967 (0.8885) acc 78.1250 (73.1771) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [260/403] time 0.082 (0.089) data 0.000 (0.002) loss 2.2303 (2.1501) teacher_loss 0.8485 (0.7768) loss_zs_kd 1.7321 (1.8597) loss_oracle 0.9234 (0.8887) acc 75.0000 (73.0529) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [280/403] time 0.082 (0.089) data 0.000 (0.002) loss 2.3658 (2.1500) teacher_loss 0.9662 (0.7769) loss_zs_kd 1.9724 (1.8652) loss_oracle 0.8849 (0.8882) acc 65.6250 (73.0469) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [300/403] time 0.077 (0.089) data 0.000 (0.002) loss 1.9185 (2.1483) teacher_loss 0.6999 (0.7757) loss_zs_kd 2.0077 (1.8699) loss_oracle 0.8209 (0.8881) acc 71.8750 (72.9688) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [320/403] time 0.084 (0.088) data 0.000 (0.002) loss 2.2592 (2.1449) teacher_loss 0.9241 (0.7741) loss_zs_kd 2.0711 (1.8716) loss_oracle 0.8646 (0.8873) acc 68.7500 (73.0664) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [340/403] time 0.099 (0.088) data 0.000 (0.002) loss 1.7829 (2.1441) teacher_loss 0.5202 (0.7743) loss_zs_kd 1.7502 (1.8642) loss_oracle 0.8106 (0.8866) acc 75.0000 (73.1710) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [360/403] time 0.091 (0.088) data 0.001 (0.002) loss 2.1221 (2.1448) teacher_loss 0.7595 (0.7744) loss_zs_kd 2.0416 (1.8682) loss_oracle 0.8970 (0.8865) acc 71.8750 (73.1597) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [380/403] time 0.080 (0.088) data 0.000 (0.002) loss 2.1372 (2.1477) teacher_loss 0.7677 (0.7776) loss_zs_kd 1.5889 (1.8710) loss_oracle 0.8849 (0.8865) acc 71.8750 (73.0345) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [400/403] time 0.075 (0.088) data 0.000 (0.002) loss 2.2005 (2.1471) teacher_loss 0.7720 (0.7763) loss_zs_kd 2.1080 (1.8739) loss_oracle 0.9237 (0.8869) acc 65.6250 (73.0312) lr 3.1417e-05 eta 0:01:11
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,002
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,542
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [49/50] batch [20/403] time 0.073 (0.113) data 0.000 (0.035) loss 2.3206 (2.1432) teacher_loss 1.0193 (0.7493) loss_zs_kd 1.9950 (1.8931) loss_oracle 0.8656 (0.8887) acc 65.6250 (73.7500) lr 1.7713e-05 eta 0:01:28
epoch [49/50] batch [40/403] time 0.071 (0.096) data 0.000 (0.018) loss 2.1120 (2.1749) teacher_loss 0.7591 (0.7795) loss_zs_kd 2.4177 (1.9166) loss_oracle 0.8889 (0.8927) acc 78.1250 (73.5156) lr 1.7713e-05 eta 0:01:13
epoch [49/50] batch [60/403] time 0.080 (0.090) data 0.001 (0.012) loss 1.7715 (2.1523) teacher_loss 0.4386 (0.7637) loss_zs_kd 1.6140 (1.9044) loss_oracle 0.8813 (0.8914) acc 84.3750 (74.3229) lr 1.7713e-05 eta 0:01:07
epoch [49/50] batch [80/403] time 0.088 (0.089) data 0.000 (0.009) loss 1.7447 (2.1433) teacher_loss 0.4304 (0.7609) loss_zs_kd 1.9055 (1.9028) loss_oracle 0.8894 (0.8872) acc 84.3750 (74.3359) lr 1.7713e-05 eta 0:01:04
epoch [49/50] batch [100/403] time 0.091 (0.088) data 0.000 (0.007) loss 2.2957 (2.1408) teacher_loss 0.9202 (0.7602) loss_zs_kd 1.9613 (1.8874) loss_oracle 0.8283 (0.8917) acc 71.8750 (74.5938) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [120/403] time 0.091 (0.086) data 0.000 (0.006) loss 2.5947 (2.1427) teacher_loss 0.9877 (0.7625) loss_zs_kd 1.8751 (1.8726) loss_oracle 0.9837 (0.8905) acc 68.7500 (74.1406) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [140/403] time 0.080 (0.086) data 0.000 (0.005) loss 2.1657 (2.1509) teacher_loss 0.8459 (0.7684) loss_zs_kd 1.6124 (1.8621) loss_oracle 0.8735 (0.8908) acc 71.8750 (73.8170) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [160/403] time 0.086 (0.086) data 0.000 (0.005) loss 1.9984 (2.1531) teacher_loss 0.6588 (0.7719) loss_zs_kd 1.7241 (1.8568) loss_oracle 0.9224 (0.8916) acc 75.0000 (73.8477) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [180/403] time 0.081 (0.086) data 0.000 (0.004) loss 2.3387 (2.1565) teacher_loss 0.9752 (0.7765) loss_zs_kd 1.8842 (1.8630) loss_oracle 0.8356 (0.8901) acc 62.5000 (73.7674) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [200/403] time 0.086 (0.086) data 0.000 (0.004) loss 2.1798 (2.1531) teacher_loss 0.8074 (0.7717) loss_zs_kd 1.8297 (1.8635) loss_oracle 0.8877 (0.8906) acc 65.6250 (73.8281) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [220/403] time 0.084 (0.086) data 0.000 (0.003) loss 2.3169 (2.1487) teacher_loss 0.9432 (0.7711) loss_zs_kd 1.3027 (1.8583) loss_oracle 0.8663 (0.8898) acc 62.5000 (73.7784) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [240/403] time 0.085 (0.086) data 0.000 (0.003) loss 2.0914 (2.1498) teacher_loss 0.6884 (0.7734) loss_zs_kd 1.7880 (1.8543) loss_oracle 0.8387 (0.8879) acc 81.2500 (73.5547) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [260/403] time 0.095 (0.086) data 0.001 (0.003) loss 2.5696 (2.1546) teacher_loss 1.1641 (0.7764) loss_zs_kd 1.9688 (1.8631) loss_oracle 0.8457 (0.8884) acc 53.1250 (73.3413) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [280/403] time 0.080 (0.086) data 0.000 (0.003) loss 2.1240 (2.1520) teacher_loss 0.7988 (0.7750) loss_zs_kd 2.2253 (1.8674) loss_oracle 0.8420 (0.8881) acc 71.8750 (73.2924) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [300/403] time 0.086 (0.085) data 0.000 (0.003) loss 2.3023 (2.1541) teacher_loss 0.8268 (0.7768) loss_zs_kd 1.9169 (1.8705) loss_oracle 0.9449 (0.8886) acc 75.0000 (73.2812) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [320/403] time 0.076 (0.085) data 0.000 (0.002) loss 2.1803 (2.1541) teacher_loss 0.6612 (0.7764) loss_zs_kd 1.9245 (1.8665) loss_oracle 0.9475 (0.8891) acc 78.1250 (73.3398) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [340/403] time 0.093 (0.085) data 0.000 (0.002) loss 1.8199 (2.1528) teacher_loss 0.5002 (0.7748) loss_zs_kd 2.2804 (1.8653) loss_oracle 0.8617 (0.8895) acc 87.5000 (73.4099) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [360/403] time 0.103 (0.086) data 0.000 (0.002) loss 2.3386 (2.1511) teacher_loss 0.8036 (0.7738) loss_zs_kd 1.6343 (1.8676) loss_oracle 0.9783 (0.8901) acc 71.8750 (73.4028) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [380/403] time 0.104 (0.087) data 0.000 (0.002) loss 2.3217 (2.1538) teacher_loss 0.9446 (0.7768) loss_zs_kd 1.5139 (1.8683) loss_oracle 0.7931 (0.8896) acc 65.6250 (73.1579) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [400/403] time 0.102 (0.088) data 0.000 (0.002) loss 2.2232 (2.1578) teacher_loss 0.8833 (0.7798) loss_zs_kd 1.6036 (1.8670) loss_oracle 0.8925 (0.8898) acc 78.1250 (73.0938) lr 1.7713e-05 eta 0:00:35
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,006
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,545
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [50/50] batch [20/403] time 0.091 (0.127) data 0.000 (0.031) loss 1.9207 (2.0775) teacher_loss 0.4859 (0.7219) loss_zs_kd 1.7837 (1.8455) loss_oracle 0.9332 (0.8727) acc 84.3750 (75.6250) lr 7.8853e-06 eta 0:00:48
epoch [50/50] batch [40/403] time 0.101 (0.115) data 0.000 (0.015) loss 2.0659 (2.1398) teacher_loss 0.6231 (0.7635) loss_zs_kd 1.6988 (1.8436) loss_oracle 0.8877 (0.8813) acc 78.1250 (73.3594) lr 7.8853e-06 eta 0:00:41
epoch [50/50] batch [60/403] time 0.111 (0.111) data 0.001 (0.010) loss 2.1232 (2.1547) teacher_loss 0.7934 (0.7842) loss_zs_kd 1.8528 (1.8569) loss_oracle 0.8983 (0.8827) acc 75.0000 (72.6562) lr 7.8853e-06 eta 0:00:38
epoch [50/50] batch [80/403] time 0.099 (0.109) data 0.000 (0.008) loss 1.9440 (2.1435) teacher_loss 0.6193 (0.7753) loss_zs_kd 1.7376 (1.8434) loss_oracle 0.8868 (0.8875) acc 78.1250 (72.8906) lr 7.8853e-06 eta 0:00:35
epoch [50/50] batch [100/403] time 0.116 (0.108) data 0.000 (0.006) loss 2.1924 (2.1369) teacher_loss 0.8893 (0.7669) loss_zs_kd 1.8787 (1.8422) loss_oracle 0.8893 (0.8883) acc 65.6250 (73.3438) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [120/403] time 0.097 (0.107) data 0.000 (0.005) loss 1.8777 (2.1388) teacher_loss 0.4813 (0.7619) loss_zs_kd 1.6604 (1.8526) loss_oracle 0.8890 (0.8901) acc 81.2500 (73.3854) lr 7.8853e-06 eta 0:00:30
epoch [50/50] batch [140/403] time 0.106 (0.107) data 0.000 (0.005) loss 2.0268 (2.1303) teacher_loss 0.6980 (0.7570) loss_zs_kd 1.8212 (1.8412) loss_oracle 0.8691 (0.8885) acc 68.7500 (73.4598) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [160/403] time 0.096 (0.107) data 0.000 (0.004) loss 2.4206 (2.1425) teacher_loss 0.9171 (0.7668) loss_zs_kd 1.4726 (1.8471) loss_oracle 0.8557 (0.8886) acc 65.6250 (73.1836) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [180/403] time 0.073 (0.105) data 0.000 (0.004) loss 2.3016 (2.1521) teacher_loss 0.8783 (0.7760) loss_zs_kd 1.9878 (1.8452) loss_oracle 0.9201 (0.8891) acc 65.6250 (72.7604) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [200/403] time 0.167 (0.103) data 0.000 (0.003) loss 2.2057 (2.1463) teacher_loss 0.8728 (0.7727) loss_zs_kd 2.2207 (1.8478) loss_oracle 0.9412 (0.8880) acc 75.0000 (73.0469) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [220/403] time 0.068 (0.106) data 0.000 (0.003) loss 2.0717 (2.1498) teacher_loss 0.6855 (0.7759) loss_zs_kd 2.1671 (1.8544) loss_oracle 0.9435 (0.8881) acc 78.1250 (72.9403) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [240/403] time 0.073 (0.106) data 0.000 (0.003) loss 1.9859 (2.1524) teacher_loss 0.6799 (0.7805) loss_zs_kd 1.4734 (1.8549) loss_oracle 0.8213 (0.8869) acc 78.1250 (72.8516) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [260/403] time 0.166 (0.106) data 0.000 (0.003) loss 2.2938 (2.1584) teacher_loss 0.8530 (0.7845) loss_zs_kd 2.1459 (1.8627) loss_oracle 0.9155 (0.8884) acc 71.8750 (72.7404) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [280/403] time 0.133 (0.106) data 0.000 (0.002) loss 2.0033 (2.1593) teacher_loss 0.6241 (0.7843) loss_zs_kd 1.7356 (1.8613) loss_oracle 0.8829 (0.8878) acc 68.7500 (72.7344) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [300/403] time 0.084 (0.105) data 0.000 (0.002) loss 1.8647 (2.1559) teacher_loss 0.6074 (0.7813) loss_zs_kd 1.7909 (1.8648) loss_oracle 0.8857 (0.8880) acc 78.1250 (72.9271) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [320/403] time 0.075 (0.104) data 0.000 (0.002) loss 2.6158 (2.1557) teacher_loss 1.1775 (0.7832) loss_zs_kd 2.2807 (1.8650) loss_oracle 0.9103 (0.8873) acc 75.0000 (72.9004) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [340/403] time 0.076 (0.105) data 0.000 (0.002) loss 2.0986 (2.1533) teacher_loss 0.7760 (0.7813) loss_zs_kd 2.4604 (1.8693) loss_oracle 0.8512 (0.8875) acc 71.8750 (72.9504) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [360/403] time 0.168 (0.105) data 0.000 (0.002) loss 2.0361 (2.1524) teacher_loss 0.7387 (0.7792) loss_zs_kd 1.7612 (1.8735) loss_oracle 0.9192 (0.8881) acc 84.3750 (73.0122) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [380/403] time 0.082 (0.104) data 0.000 (0.002) loss 1.9865 (2.1511) teacher_loss 0.7475 (0.7790) loss_zs_kd 1.9130 (1.8691) loss_oracle 0.8875 (0.8875) acc 71.8750 (73.0510) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [400/403] time 0.096 (0.104) data 0.000 (0.002) loss 2.1167 (2.1512) teacher_loss 0.7983 (0.7795) loss_zs_kd 1.5146 (1.8683) loss_oracle 0.8465 (0.8875) acc 71.8750 (73.0000) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,006
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,542
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.2%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:44:33

Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'product', 'real_world']
Target     ['clipart']
# classes  65
# train_x  7,870
# val      3,353
# test     4,365
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/245] time 0.146 (0.193) data 0.000 (0.017) loss 0.8688 (0.9944) teacher_loss 0.8486 (0.9444) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) kd_loss 0.0202 (0.0500) acc 75.0000 (76.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3360 (0.3362) gate/usage_min 0.3293 (0.3294) gate/usage_std 0.0029 (0.0029) teacher/entropy 1.0783 (1.0486) teacher/usage_max 0.3451 (0.3533) teacher/usage_min 0.3222 (0.3163) teacher/usage_std 0.0093 (0.0158) nleep/row_max_mean 1154.2449 (1172.4350) nleep/row_max_std 60.7999 (88.6396) nleep/row_min_mean 1153.9824 (1171.9085) lr 1.0000e-05 eta 0:39:15
epoch [1/50] batch [40/245] time 0.142 (0.166) data 0.000 (0.009) loss 0.9013 (0.9829) teacher_loss 0.8582 (0.9404) loss_zs_kd 0.0002 (0.0001) loss_oracle -0.0000 (-0.0001) kd_loss 0.0430 (0.0425) acc 75.0000 (75.3906) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3361 (0.3362) gate/usage_min 0.3295 (0.3294) gate/usage_std 0.0028 (0.0029) teacher/entropy 1.0558 (1.0561) teacher/usage_max 0.3449 (0.3533) teacher/usage_min 0.3263 (0.3166) teacher/usage_std 0.0083 (0.0157) nleep/row_max_mean 1180.5999 (1173.2570) nleep/row_max_std 87.5904 (84.6397) nleep/row_min_mean 1180.1987 (1172.8256) lr 1.0000e-05 eta 0:33:46
epoch [1/50] batch [60/245] time 0.142 (0.158) data 0.000 (0.006) loss 0.9796 (0.9878) teacher_loss 0.9570 (0.9519) loss_zs_kd 0.0003 (0.0001) loss_oracle -0.0001 (-0.0001) kd_loss 0.0224 (0.0358) acc 75.0000 (75.2083) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3361 (0.3362) gate/usage_min 0.3296 (0.3294) gate/usage_std 0.0027 (0.0029) teacher/entropy 1.0762 (1.0628) teacher/usage_max 0.3485 (0.3516) teacher/usage_min 0.3242 (0.3182) teacher/usage_std 0.0108 (0.0143) nleep/row_max_mean 1187.4456 (1173.0291) nleep/row_max_std 85.1748 (79.2535) nleep/row_min_mean 1187.2087 (1172.6607) lr 1.0000e-05 eta 0:32:06
epoch [1/50] batch [80/245] time 0.144 (0.154) data 0.000 (0.004) loss 1.1803 (0.9992) teacher_loss 1.1421 (0.9671) loss_zs_kd 0.0003 (0.0001) loss_oracle -0.0001 (-0.0001) kd_loss 0.0381 (0.0320) acc 71.8750 (74.9609) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3363 (0.3362) gate/usage_min 0.3295 (0.3294) gate/usage_std 0.0028 (0.0029) teacher/entropy 1.0607 (1.0666) teacher/usage_max 0.3587 (0.3506) teacher/usage_min 0.3118 (0.3191) teacher/usage_std 0.0193 (0.0135) nleep/row_max_mean 1188.5814 (1173.8416) nleep/row_max_std 76.8060 (74.8347) nleep/row_min_mean 1188.2246 (1173.5065) lr 1.0000e-05 eta 0:31:08
epoch [1/50] batch [100/245] time 0.150 (0.151) data 0.000 (0.004) loss 0.7967 (0.9667) teacher_loss 0.7704 (0.9381) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0001 (-0.0000) kd_loss 0.0258 (0.0285) acc 81.2500 (75.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3360 (0.3362) gate/usage_min 0.3294 (0.3294) gate/usage_std 0.0028 (0.0029) teacher/entropy 1.0730 (1.0702) teacher/usage_max 0.3480 (0.3492) teacher/usage_min 0.3164 (0.3201) teacher/usage_std 0.0130 (0.0124) nleep/row_max_mean 1196.0576 (1174.5045) nleep/row_max_std 79.3408 (70.8498) nleep/row_min_mean 1195.7778 (1174.1977) lr 1.0000e-05 eta 0:30:36
epoch [1/50] batch [120/245] time 0.139 (0.149) data 0.000 (0.003) loss 0.8179 (0.9506) teacher_loss 0.8099 (0.9249) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0000 (-0.0000) kd_loss 0.0077 (0.0255) acc 75.0000 (75.6250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3363 (0.3362) gate/usage_min 0.3293 (0.3294) gate/usage_std 0.0029 (0.0029) teacher/entropy 1.0910 (1.0731) teacher/usage_max 0.3441 (0.3483) teacher/usage_min 0.3243 (0.3210) teacher/usage_std 0.0082 (0.0117) nleep/row_max_mean 1175.4878 (1175.0701) nleep/row_max_std 31.8085 (66.6678) nleep/row_min_mean 1175.3560 (1174.7854) lr 1.0000e-05 eta 0:30:05
epoch [1/50] batch [140/245] time 0.139 (0.148) data 0.000 (0.003) loss 0.3407 (0.9387) teacher_loss 0.3277 (0.9154) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0000 (-0.0000) kd_loss 0.0126 (0.0231) acc 93.7500 (75.6920) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3359 (0.3362) gate/usage_min 0.3295 (0.3294) gate/usage_std 0.0028 (0.0029) teacher/entropy 1.0860 (1.0755) teacher/usage_max 0.3450 (0.3473) teacher/usage_min 0.3273 (0.3215) teacher/usage_std 0.0082 (0.0110) nleep/row_max_mean 1190.3281 (1175.7045) nleep/row_max_std 54.6079 (62.7430) nleep/row_min_mean 1190.1429 (1175.4373) lr 1.0000e-05 eta 0:29:46
epoch [1/50] batch [160/245] time 0.138 (0.146) data 0.000 (0.002) loss 0.9990 (0.9341) teacher_loss 0.9909 (0.9125) loss_zs_kd 0.0016 (0.0006) loss_oracle -0.0001 (-0.0000) kd_loss 0.0074 (0.0213) acc 71.8750 (75.6836) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3360 (0.3362) gate/usage_min 0.3295 (0.3294) gate/usage_std 0.0028 (0.0029) teacher/entropy 1.0915 (1.0773) teacher/usage_max 0.3461 (0.3468) teacher/usage_min 0.3199 (0.3218) teacher/usage_std 0.0107 (0.0107) nleep/row_max_mean 1181.6718 (1176.8088) nleep/row_max_std 39.5297 (60.3590) nleep/row_min_mean 1181.5300 (1176.5542) lr 1.0000e-05 eta 0:29:30
epoch [1/50] batch [180/245] time 0.136 (0.146) data 0.000 (0.002) loss 0.5660 (0.9275) teacher_loss 0.5473 (0.9073) loss_zs_kd 0.0018 (0.0007) loss_oracle 0.0001 (-0.0000) kd_loss 0.0178 (0.0199) acc 84.3750 (75.5556) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3359 (0.3361) gate/usage_min 0.3293 (0.3294) gate/usage_std 0.0029 (0.0029) teacher/entropy 1.0808 (1.0788) teacher/usage_max 0.3477 (0.3463) teacher/usage_min 0.3259 (0.3222) teacher/usage_std 0.0101 (0.0103) nleep/row_max_mean 1201.7689 (1177.8691) nleep/row_max_std 57.3086 (58.3290) nleep/row_min_mean 1201.5170 (1177.6246) lr 1.0000e-05 eta 0:29:21
epoch [1/50] batch [200/245] time 0.144 (0.145) data 0.000 (0.002) loss 0.5861 (0.9315) teacher_loss 0.5838 (0.9127) loss_zs_kd 0.0008 (0.0008) loss_oracle 0.0001 (0.0000) kd_loss 0.0018 (0.0184) acc 84.3750 (75.4062) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3358 (0.3362) gate/usage_min 0.3296 (0.3294) gate/usage_std 0.0027 (0.0029) teacher/entropy 1.0969 (1.0803) teacher/usage_max 0.3362 (0.3456) teacher/usage_min 0.3291 (0.3227) teacher/usage_std 0.0030 (0.0098) nleep/row_max_mean 1177.7865 (1178.5018) nleep/row_max_std 20.5415 (55.7660) nleep/row_min_mean 1177.6902 (1178.2683) lr 1.0000e-05 eta 0:29:12
epoch [1/50] batch [220/245] time 0.136 (0.145) data 0.000 (0.002) loss 1.4227 (0.9226) teacher_loss 1.4171 (0.9049) loss_zs_kd 0.0038 (0.0009) loss_oracle 0.0001 (0.0000) kd_loss 0.0037 (0.0172) acc 56.2500 (75.6108) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3363 (0.3362) gate/usage_min 0.3292 (0.3294) gate/usage_std 0.0030 (0.0029) teacher/entropy 1.0949 (1.0815) teacher/usage_max 0.3351 (0.3450) teacher/usage_min 0.3322 (0.3232) teacher/usage_std 0.0012 (0.0093) nleep/row_max_mean 1184.0002 (1179.2053) nleep/row_max_std 27.1956 (53.7174) nleep/row_min_mean 1183.8833 (1178.9802) lr 1.0000e-05 eta 0:29:07
epoch [1/50] batch [240/245] time 0.138 (0.145) data 0.000 (0.002) loss 0.8984 (0.9227) teacher_loss 0.8926 (0.9061) loss_zs_kd 0.0014 (0.0011) loss_oracle 0.0001 (0.0000) kd_loss 0.0051 (0.0161) acc 75.0000 (75.5208) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3360 (0.3362) gate/usage_min 0.3294 (0.3294) gate/usage_std 0.0029 (0.0029) teacher/entropy 1.0936 (1.0825) teacher/usage_max 0.3367 (0.3445) teacher/usage_min 0.3297 (0.3235) teacher/usage_std 0.0029 (0.0090) nleep/row_max_mean 1191.6941 (1179.8287) nleep/row_max_std 35.0748 (51.7885) nleep/row_min_mean 1191.5435 (1179.6111) lr 1.0000e-05 eta 0:29:01
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 2,923
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,075
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.0%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      87.2%, epoch: 1 *******
******* Domain c best val test acc: 70.4%, epoch: 1 *******
******* Domain c best test acc:     70.4%, epoch: 1 *******
epoch [2/50] batch [20/245] time 0.259 (0.174) data 0.000 (0.014) loss 0.9774 (0.9454) teacher_loss 0.9171 (0.9005) loss_zs_kd 0.1042 (0.0788) loss_oracle 0.0097 (0.0042) kd_loss 0.0033 (0.0034) acc 75.0000 (75.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3356 (0.3359) gate/usage_min 0.3298 (0.3296) gate/usage_std 0.0025 (0.0027) teacher/entropy 1.0954 (1.0953) teacher/usage_max 0.3422 (0.3388) teacher/usage_min 0.3260 (0.3269) teacher/usage_std 0.0067 (0.0051) nleep/row_max_mean 1194.4213 (1187.9447) nleep/row_max_std 32.5413 (27.7930) nleep/row_min_mean 1194.2996 (1187.8219) lr 2.0000e-03 eta 0:34:41
epoch [2/50] batch [40/245] time 0.187 (0.169) data 0.000 (0.007) loss 1.0951 (0.9272) teacher_loss 1.0655 (0.8791) loss_zs_kd 0.0476 (0.0838) loss_oracle 0.0082 (0.0062) kd_loss 0.0017 (0.0031) acc 68.7500 (75.8594) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3352 (0.3357) gate/usage_min 0.3300 (0.3299) gate/usage_std 0.0024 (0.0025) teacher/entropy 1.0970 (1.0956) teacher/usage_max 0.3363 (0.3393) teacher/usage_min 0.3313 (0.3265) teacher/usage_std 0.0021 (0.0055) nleep/row_max_mean 1183.6748 (1188.0510) nleep/row_max_std 19.4682 (26.7013) nleep/row_min_mean 1183.5801 (1187.9290) lr 2.0000e-03 eta 0:33:43
epoch [2/50] batch [60/245] time 0.143 (0.161) data 0.000 (0.005) loss 0.7511 (0.9067) teacher_loss 0.6980 (0.8589) loss_zs_kd 0.0840 (0.0801) loss_oracle 0.0163 (0.0091) kd_loss 0.0030 (0.0032) acc 84.3750 (76.9271) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3354) gate/usage_min 0.3307 (0.3300) gate/usage_std 0.0018 (0.0024) teacher/entropy 1.0956 (1.0955) teacher/usage_max 0.3388 (0.3397) teacher/usage_min 0.3288 (0.3259) teacher/usage_std 0.0041 (0.0059) nleep/row_max_mean 1190.0471 (1188.8780) nleep/row_max_std 24.1153 (26.1775) nleep/row_min_mean 1189.9187 (1188.7532) lr 2.0000e-03 eta 0:32:03
epoch [2/50] batch [80/245] time 0.138 (0.158) data 0.000 (0.004) loss 0.6493 (0.8999) teacher_loss 0.6100 (0.8517) loss_zs_kd 0.0659 (0.0806) loss_oracle 0.0088 (0.0095) kd_loss 0.0020 (0.0031) acc 81.2500 (77.0703) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3353) gate/usage_min 0.3304 (0.3302) gate/usage_std 0.0021 (0.0022) teacher/entropy 1.0967 (1.0956) teacher/usage_max 0.3384 (0.3396) teacher/usage_min 0.3251 (0.3263) teacher/usage_std 0.0059 (0.0057) nleep/row_max_mean 1189.6194 (1189.4034) nleep/row_max_std 21.4577 (25.3276) nleep/row_min_mean 1189.5139 (1189.2799) lr 2.0000e-03 eta 0:31:22
epoch [2/50] batch [100/245] time 0.140 (0.155) data 0.000 (0.003) loss 0.6080 (0.8700) teacher_loss 0.5401 (0.8226) loss_zs_kd 0.1202 (0.0797) loss_oracle 0.0084 (0.0090) kd_loss 0.0036 (0.0031) acc 84.3750 (77.7188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3352) gate/usage_min 0.3308 (0.3303) gate/usage_std 0.0018 (0.0022) teacher/entropy 1.0950 (1.0956) teacher/usage_max 0.3408 (0.3394) teacher/usage_min 0.3292 (0.3265) teacher/usage_std 0.0053 (0.0055) nleep/row_max_mean 1192.2546 (1189.6816) nleep/row_max_std 22.2620 (24.4230) nleep/row_min_mean 1192.1167 (1189.5576) lr 2.0000e-03 eta 0:30:48
epoch [2/50] batch [120/245] time 0.138 (0.154) data 0.000 (0.003) loss 0.8603 (0.8794) teacher_loss 0.8161 (0.8331) loss_zs_kd 0.0674 (0.0773) loss_oracle 0.0135 (0.0094) kd_loss 0.0037 (0.0030) acc 71.8750 (77.6302) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3351) gate/usage_min 0.3309 (0.3304) gate/usage_std 0.0018 (0.0021) teacher/entropy 1.0948 (1.0957) teacher/usage_max 0.3387 (0.3392) teacher/usage_min 0.3266 (0.3267) teacher/usage_std 0.0051 (0.0053) nleep/row_max_mean 1191.9800 (1190.2137) nleep/row_max_std 19.4564 (23.6379) nleep/row_min_mean 1191.8354 (1190.0885) lr 2.0000e-03 eta 0:30:30
epoch [2/50] batch [140/245] time 0.138 (0.153) data 0.000 (0.002) loss 1.0500 (0.8650) teacher_loss 0.9722 (0.8171) loss_zs_kd 0.0886 (0.0763) loss_oracle 0.0616 (0.0136) kd_loss 0.0027 (0.0030) acc 68.7500 (77.7902) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3353 (0.3351) gate/usage_min 0.3308 (0.3304) gate/usage_std 0.0019 (0.0021) teacher/entropy 1.0958 (1.0957) teacher/usage_max 0.3476 (0.3397) teacher/usage_min 0.3261 (0.3267) teacher/usage_std 0.0101 (0.0056) nleep/row_max_mean 1195.5110 (1190.5816) nleep/row_max_std 17.0808 (23.0891) nleep/row_min_mean 1195.3645 (1190.4544) lr 2.0000e-03 eta 0:30:15
epoch [2/50] batch [160/245] time 0.138 (0.152) data 0.000 (0.002) loss 1.3678 (0.8683) teacher_loss 1.3134 (0.8196) loss_zs_kd 0.0643 (0.0743) loss_oracle 0.0387 (0.0170) kd_loss 0.0029 (0.0030) acc 68.7500 (77.8320) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3362 (0.3352) gate/usage_min 0.3306 (0.3304) gate/usage_std 0.0023 (0.0021) teacher/entropy 1.0957 (1.0957) teacher/usage_max 0.3387 (0.3400) teacher/usage_min 0.3285 (0.3265) teacher/usage_std 0.0042 (0.0058) nleep/row_max_mean 1190.2295 (1190.8124) nleep/row_max_std 15.0573 (22.4703) nleep/row_min_mean 1190.0857 (1190.6825) lr 2.0000e-03 eta 0:30:03
epoch [2/50] batch [180/245] time 0.142 (0.151) data 0.000 (0.002) loss 1.2637 (0.8712) teacher_loss 1.1838 (0.8200) loss_zs_kd 0.0752 (0.0759) loss_oracle 0.0711 (0.0204) kd_loss 0.0067 (0.0031) acc 75.0000 (77.9861) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3358 (0.3353) gate/usage_min 0.3306 (0.3305) gate/usage_std 0.0021 (0.0021) teacher/entropy 1.0917 (1.0956) teacher/usage_max 0.3601 (0.3405) teacher/usage_min 0.3088 (0.3260) teacher/usage_std 0.0210 (0.0062) nleep/row_max_mean 1201.8521 (1191.1771) nleep/row_max_std 22.7101 (22.0905) nleep/row_min_mean 1201.6327 (1191.0428) lr 2.0000e-03 eta 0:29:51
epoch [2/50] batch [200/245] time 0.142 (0.151) data 0.000 (0.002) loss 0.9499 (0.8742) teacher_loss 0.8817 (0.8196) loss_zs_kd 0.0730 (0.0771) loss_oracle 0.0463 (0.0254) kd_loss 0.0085 (0.0034) acc 78.1250 (77.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3351 (0.3353) gate/usage_min 0.3298 (0.3304) gate/usage_std 0.0025 (0.0021) teacher/entropy 1.0897 (1.0952) teacher/usage_max 0.3510 (0.3419) teacher/usage_min 0.2994 (0.3245) teacher/usage_std 0.0240 (0.0074) nleep/row_max_mean 1194.7795 (1191.5418) nleep/row_max_std 16.4986 (21.6996) nleep/row_min_mean 1194.5186 (1191.3984) lr 2.0000e-03 eta 0:29:41
epoch [2/50] batch [220/245] time 0.135 (0.150) data 0.000 (0.001) loss 0.8215 (0.8766) teacher_loss 0.6984 (0.8204) loss_zs_kd 0.1989 (0.0784) loss_oracle 0.0359 (0.0268) kd_loss 0.0057 (0.0036) acc 75.0000 (77.9545) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3366 (0.3354) gate/usage_min 0.3289 (0.3303) gate/usage_std 0.0033 (0.0022) teacher/entropy 1.0924 (1.0949) teacher/usage_max 0.3588 (0.3432) teacher/usage_min 0.3102 (0.3230) teacher/usage_std 0.0199 (0.0085) nleep/row_max_mean 1193.8947 (1191.8895) nleep/row_max_std 11.5698 (21.2790) nleep/row_min_mean 1193.6699 (1191.7376) lr 2.0000e-03 eta 0:29:31
epoch [2/50] batch [240/245] time 0.137 (0.150) data 0.000 (0.001) loss 0.7137 (0.8681) teacher_loss 0.6360 (0.8113) loss_zs_kd 0.1102 (0.0787) loss_oracle 0.0259 (0.0270) kd_loss 0.0096 (0.0039) acc 84.3750 (78.1120) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3368 (0.3355) gate/usage_min 0.3283 (0.3302) gate/usage_std 0.0037 (0.0023) teacher/entropy 1.0884 (1.0947) teacher/usage_max 0.3613 (0.3439) teacher/usage_min 0.3078 (0.3221) teacher/usage_std 0.0219 (0.0092) nleep/row_max_mean 1198.0479 (1192.3088) nleep/row_max_std 15.2844 (20.9031) nleep/row_min_mean 1197.7739 (1192.1500) lr 2.0000e-03 eta 0:29:20
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,017
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.0%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,196
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 72.0%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.0%, epoch: 2 *******
******* Domain c best val test acc: 73.2%, epoch: 2 *******
******* Domain c best test acc:     73.2%, epoch: 2 *******
epoch [3/50] batch [20/245] time 0.139 (0.161) data 0.000 (0.011) loss 0.5971 (0.7802) teacher_loss 0.5390 (0.7050) loss_zs_kd 0.0855 (0.0946) loss_oracle 0.0203 (0.0429) kd_loss 0.0052 (0.0064) acc 90.6250 (80.6250) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3384 (0.3375) gate/usage_min 0.3274 (0.3279) gate/usage_std 0.0045 (0.0040) teacher/entropy 1.0933 (1.0919) teacher/usage_max 0.3416 (0.3466) teacher/usage_min 0.3240 (0.3185) teacher/usage_std 0.0072 (0.0118) nleep/row_max_mean 1201.3431 (1197.2928) nleep/row_max_std 17.4753 (16.3308) nleep/row_min_mean 1201.1294 (1197.0599) lr 1.9980e-03 eta 0:31:28
epoch [3/50] batch [40/245] time 0.148 (0.154) data 0.000 (0.006) loss 0.6446 (0.8137) teacher_loss 0.6063 (0.7523) loss_zs_kd 0.0432 (0.0804) loss_oracle 0.0196 (0.0293) kd_loss 0.0069 (0.0065) acc 84.3750 (79.6875) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3387 (0.3380) gate/usage_min 0.3261 (0.3272) gate/usage_std 0.0053 (0.0045) teacher/entropy 1.0917 (1.0918) teacher/usage_max 0.3392 (0.3460) teacher/usage_min 0.3275 (0.3190) teacher/usage_std 0.0048 (0.0114) nleep/row_max_mean 1196.5601 (1197.4564) nleep/row_max_std 19.3369 (16.4322) nleep/row_min_mean 1196.3081 (1197.2215) lr 1.9980e-03 eta 0:30:04
epoch [3/50] batch [60/245] time 0.135 (0.151) data 0.000 (0.004) loss 1.0920 (0.8154) teacher_loss 1.0340 (0.7561) loss_zs_kd 0.0622 (0.0783) loss_oracle 0.0340 (0.0264) kd_loss 0.0098 (0.0069) acc 71.8750 (79.1146) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3381 (0.3381) gate/usage_min 0.3259 (0.3268) gate/usage_std 0.0053 (0.0048) teacher/entropy 1.0891 (1.0915) teacher/usage_max 0.3516 (0.3467) teacher/usage_min 0.3157 (0.3194) teacher/usage_std 0.0147 (0.0116) nleep/row_max_mean 1202.7220 (1197.7541) nleep/row_max_std 17.7417 (16.2036) nleep/row_min_mean 1202.4402 (1197.5131) lr 1.9980e-03 eta 0:29:23
epoch [3/50] batch [80/245] time 0.097 (0.150) data 0.000 (0.003) loss 0.7360 (0.8171) teacher_loss 0.6361 (0.7570) loss_zs_kd 0.1599 (0.0793) loss_oracle 0.0265 (0.0270) kd_loss 0.0067 (0.0070) acc 84.3750 (79.0625) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3375 (0.3379) gate/usage_min 0.3262 (0.3266) gate/usage_std 0.0051 (0.0049) teacher/entropy 1.0919 (1.0915) teacher/usage_max 0.3432 (0.3471) teacher/usage_min 0.3269 (0.3194) teacher/usage_std 0.0071 (0.0117) nleep/row_max_mean 1199.1702 (1198.1415) nleep/row_max_std 14.9389 (16.2739) nleep/row_min_mean 1198.9333 (1197.9005) lr 1.9980e-03 eta 0:29:12
epoch [3/50] batch [100/245] time 0.114 (0.145) data 0.000 (0.002) loss 1.0222 (0.8301) teacher_loss 0.9357 (0.7649) loss_zs_kd 0.1017 (0.0862) loss_oracle 0.0552 (0.0294) kd_loss 0.0081 (0.0074) acc 78.1250 (78.6562) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3391 (0.3380) gate/usage_min 0.3265 (0.3265) gate/usage_std 0.0052 (0.0050) teacher/entropy 1.0905 (1.0911) teacher/usage_max 0.3473 (0.3482) teacher/usage_min 0.3156 (0.3176) teacher/usage_std 0.0132 (0.0130) nleep/row_max_mean 1193.8159 (1198.3686) nleep/row_max_std 19.9261 (16.4342) nleep/row_min_mean 1193.5605 (1198.1208) lr 1.9980e-03 eta 0:28:16
epoch [3/50] batch [120/245] time 0.086 (0.146) data 0.000 (0.002) loss 0.3443 (0.8227) teacher_loss 0.2719 (0.7552) loss_zs_kd 0.0708 (0.0863) loss_oracle 0.0490 (0.0327) kd_loss 0.0126 (0.0080) acc 93.7500 (78.9323) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3405 (0.3383) gate/usage_min 0.3279 (0.3266) gate/usage_std 0.0053 (0.0050) teacher/entropy 1.0864 (1.0905) teacher/usage_max 0.3593 (0.3497) teacher/usage_min 0.3019 (0.3151) teacher/usage_std 0.0237 (0.0147) nleep/row_max_mean 1202.7712 (1198.7359) nleep/row_max_std 17.8519 (16.5087) nleep/row_min_mean 1202.4447 (1198.4791) lr 1.9980e-03 eta 0:28:13
epoch [3/50] batch [140/245] time 0.292 (0.148) data 0.000 (0.002) loss 0.6858 (0.8328) teacher_loss 0.6127 (0.7635) loss_zs_kd 0.0762 (0.0872) loss_oracle 0.0475 (0.0343) kd_loss 0.0112 (0.0085) acc 78.1250 (78.7500) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3417 (0.3387) gate/usage_min 0.3290 (0.3269) gate/usage_std 0.0060 (0.0051) teacher/entropy 1.0868 (1.0899) teacher/usage_max 0.3532 (0.3506) teacher/usage_min 0.3017 (0.3127) teacher/usage_std 0.0226 (0.0162) nleep/row_max_mean 1201.2107 (1198.9239) nleep/row_max_std 18.0332 (16.6131) nleep/row_min_mean 1200.8811 (1198.6570) lr 1.9980e-03 eta 0:28:40
epoch [3/50] batch [160/245] time 0.106 (0.145) data 0.000 (0.002) loss 0.6524 (0.8285) teacher_loss 0.5853 (0.7588) loss_zs_kd 0.0781 (0.0849) loss_oracle 0.0314 (0.0362) kd_loss 0.0123 (0.0092) acc 81.2500 (78.8867) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3423 (0.3391) gate/usage_min 0.3272 (0.3271) gate/usage_std 0.0065 (0.0052) teacher/entropy 1.0849 (1.0892) teacher/usage_max 0.3638 (0.3517) teacher/usage_min 0.2787 (0.3100) teacher/usage_std 0.0387 (0.0180) nleep/row_max_mean 1198.3135 (1199.0537) nleep/row_max_std 17.0589 (16.6952) nleep/row_min_mean 1197.9668 (1198.7761) lr 1.9980e-03 eta 0:28:03
epoch [3/50] batch [180/245] time 0.342 (0.146) data 0.000 (0.001) loss 0.6784 (0.8321) teacher_loss 0.6297 (0.7621) loss_zs_kd 0.0364 (0.0833) loss_oracle 0.0303 (0.0366) kd_loss 0.0153 (0.0100) acc 81.2500 (78.8194) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3434 (0.3395) gate/usage_min 0.3239 (0.3269) gate/usage_std 0.0080 (0.0054) teacher/entropy 1.0815 (1.0882) teacher/usage_max 0.3583 (0.3535) teacher/usage_min 0.2845 (0.3064) teacher/usage_std 0.0345 (0.0204) nleep/row_max_mean 1200.0532 (1199.2069) nleep/row_max_std 13.7849 (16.6405) nleep/row_min_mean 1199.6665 (1198.9151) lr 1.9980e-03 eta 0:28:06
epoch [3/50] batch [200/245] time 0.101 (0.144) data 0.000 (0.001) loss 0.9412 (0.8374) teacher_loss 0.8424 (0.7670) loss_zs_kd 0.1252 (0.0832) loss_oracle 0.0369 (0.0362) kd_loss 0.0177 (0.0107) acc 75.0000 (78.6719) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3442 (0.3400) gate/usage_min 0.3213 (0.3265) gate/usage_std 0.0094 (0.0058) teacher/entropy 1.0784 (1.0874) teacher/usage_max 0.3622 (0.3554) teacher/usage_min 0.2786 (0.3032) teacher/usage_std 0.0387 (0.0226) nleep/row_max_mean 1198.1213 (1199.2657) nleep/row_max_std 15.2048 (16.5661) nleep/row_min_mean 1197.6921 (1198.9612) lr 1.9980e-03 eta 0:27:47
epoch [3/50] batch [220/245] time 0.090 (0.146) data 0.000 (0.001) loss 1.0693 (0.8435) teacher_loss 0.9696 (0.7712) loss_zs_kd 0.1235 (0.0857) loss_oracle 0.0318 (0.0362) kd_loss 0.0221 (0.0113) acc 78.1250 (78.5795) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3449 (0.3404) gate/usage_min 0.3195 (0.3259) gate/usage_std 0.0105 (0.0061) teacher/entropy 1.0728 (1.0866) teacher/usage_max 0.3735 (0.3568) teacher/usage_min 0.2639 (0.3006) teacher/usage_std 0.0493 (0.0244) nleep/row_max_mean 1199.7123 (1199.3438) nleep/row_max_std 14.8236 (16.3975) nleep/row_min_mean 1199.2360 (1199.0282) lr 1.9980e-03 eta 0:28:09
epoch [3/50] batch [240/245] time 0.137 (0.145) data 0.000 (0.001) loss 0.3545 (0.8446) teacher_loss 0.2454 (0.7703) loss_zs_kd 0.1411 (0.0878) loss_oracle 0.0412 (0.0370) kd_loss 0.0180 (0.0119) acc 93.7500 (78.6458) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3453 (0.3407) gate/usage_min 0.3180 (0.3253) gate/usage_std 0.0114 (0.0065) teacher/entropy 1.0768 (1.0857) teacher/usage_max 0.3764 (0.3584) teacher/usage_min 0.2669 (0.2980) teacher/usage_std 0.0476 (0.0263) nleep/row_max_mean 1200.6868 (1199.4221) nleep/row_max_std 15.6595 (16.2718) nleep/row_min_mean 1200.2251 (1199.0946) lr 1.9980e-03 eta 0:27:52
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,015
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,191
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 71.6%
******* Domain c best val acc:      90.0%, epoch: 2 *******
******* Domain c best val test acc: 73.2%, epoch: 2 *******
******* Domain c best test acc:     73.2%, epoch: 2 *******
epoch [4/50] batch [20/245] time 0.130 (0.157) data 0.000 (0.015) loss 1.0685 (0.8984) teacher_loss 0.9455 (0.8059) loss_zs_kd 0.1648 (0.0960) loss_oracle 0.0382 (0.0451) kd_loss 0.0215 (0.0219) acc 68.7500 (77.8125) gate/entropy 1.0979 (1.0979) gate/usage_max 0.3449 (0.3449) gate/usage_min 0.3157 (0.3166) gate/usage_std 0.0127 (0.0121) teacher/entropy 1.0726 (1.0724) teacher/usage_max 0.3853 (0.3819) teacher/usage_min 0.2660 (0.2651) teacher/usage_std 0.0499 (0.0500) nleep/row_max_mean 1200.7812 (1200.9545) nleep/row_max_std 14.4234 (14.7895) nleep/row_min_mean 1200.3021 (1200.4603) lr 1.9921e-03 eta 0:30:02
epoch [4/50] batch [40/245] time 0.136 (0.148) data 0.000 (0.008) loss 0.9956 (0.8833) teacher_loss 0.9159 (0.7940) loss_zs_kd 0.0967 (0.0966) loss_oracle 0.0282 (0.0388) kd_loss 0.0172 (0.0216) acc 75.0000 (77.2656) gate/entropy 1.0977 (1.0979) gate/usage_max 0.3454 (0.3449) gate/usage_min 0.3140 (0.3157) gate/usage_std 0.0138 (0.0127) teacher/entropy 1.0771 (1.0723) teacher/usage_max 0.3631 (0.3814) teacher/usage_min 0.2745 (0.2639) teacher/usage_std 0.0416 (0.0506) nleep/row_max_mean 1202.3236 (1201.2356) nleep/row_max_std 12.5882 (14.3884) nleep/row_min_mean 1201.8716 (1200.7381) lr 1.9921e-03 eta 0:28:15
epoch [4/50] batch [60/245] time 0.141 (0.144) data 0.000 (0.005) loss 0.6216 (0.8617) teacher_loss 0.5269 (0.7772) loss_zs_kd 0.1132 (0.0906) loss_oracle 0.0352 (0.0360) kd_loss 0.0205 (0.0212) acc 87.5000 (77.8646) gate/entropy 1.0976 (1.0978) gate/usage_max 0.3459 (0.3451) gate/usage_min 0.3121 (0.3148) gate/usage_std 0.0151 (0.0133) teacher/entropy 1.0720 (1.0725) teacher/usage_max 0.3859 (0.3808) teacher/usage_min 0.2577 (0.2636) teacher/usage_std 0.0548 (0.0507) nleep/row_max_mean 1199.6138 (1201.2195) nleep/row_max_std 13.5899 (14.3805) nleep/row_min_mean 1199.1023 (1200.7237) lr 1.9921e-03 eta 0:27:33
epoch [4/50] batch [80/245] time 0.137 (0.142) data 0.000 (0.004) loss 0.7581 (0.8728) teacher_loss 0.6788 (0.7884) loss_zs_kd 0.0745 (0.0896) loss_oracle 0.0334 (0.0366) kd_loss 0.0254 (0.0213) acc 81.2500 (77.6172) gate/entropy 1.0974 (1.0977) gate/usage_max 0.3461 (0.3453) gate/usage_min 0.3103 (0.3139) gate/usage_std 0.0163 (0.0139) teacher/entropy 1.0656 (1.0720) teacher/usage_max 0.3889 (0.3818) teacher/usage_min 0.2498 (0.2622) teacher/usage_std 0.0601 (0.0517) nleep/row_max_mean 1202.9335 (1201.2771) nleep/row_max_std 15.2634 (14.4977) nleep/row_min_mean 1202.3715 (1200.7750) lr 1.9921e-03 eta 0:27:07
epoch [4/50] batch [100/245] time 0.136 (0.142) data 0.000 (0.003) loss 0.8237 (0.8637) teacher_loss 0.7138 (0.7768) loss_zs_kd 0.1208 (0.0910) loss_oracle 0.0473 (0.0391) kd_loss 0.0258 (0.0218) acc 87.5000 (78.4062) gate/entropy 1.0972 (1.0976) gate/usage_max 0.3473 (0.3456) gate/usage_min 0.3084 (0.3129) gate/usage_std 0.0177 (0.0145) teacher/entropy 1.0639 (1.0710) teacher/usage_max 0.3813 (0.3833) teacher/usage_min 0.2425 (0.2598) teacher/usage_std 0.0642 (0.0535) nleep/row_max_mean 1200.7712 (1201.3486) nleep/row_max_std 17.4644 (14.4368) nleep/row_min_mean 1200.1868 (1200.8345) lr 1.9921e-03 eta 0:27:05
epoch [4/50] batch [120/245] time 0.135 (0.141) data 0.000 (0.003) loss 1.1681 (0.8726) teacher_loss 1.0805 (0.7845) loss_zs_kd 0.0773 (0.0918) loss_oracle 0.0410 (0.0394) kd_loss 0.0285 (0.0224) acc 75.0000 (78.1510) gate/entropy 1.0969 (1.0975) gate/usage_max 0.3482 (0.3460) gate/usage_min 0.3064 (0.3120) gate/usage_std 0.0191 (0.0152) teacher/entropy 1.0613 (1.0699) teacher/usage_max 0.3815 (0.3843) teacher/usage_min 0.2479 (0.2575) teacher/usage_std 0.0606 (0.0550) nleep/row_max_mean 1200.3523 (1201.1706) nleep/row_max_std 13.2662 (14.4635) nleep/row_min_mean 1199.7548 (1200.6449) lr 1.9921e-03 eta 0:26:49
epoch [4/50] batch [140/245] time 0.133 (0.140) data 0.000 (0.002) loss 0.7958 (0.8715) teacher_loss 0.7105 (0.7826) loss_zs_kd 0.0876 (0.0914) loss_oracle 0.0315 (0.0404) kd_loss 0.0257 (0.0230) acc 81.2500 (78.4821) gate/entropy 1.0968 (1.0974) gate/usage_max 0.3480 (0.3463) gate/usage_min 0.3052 (0.3111) gate/usage_std 0.0199 (0.0158) teacher/entropy 1.0617 (1.0689) teacher/usage_max 0.3981 (0.3851) teacher/usage_min 0.2323 (0.2560) teacher/usage_std 0.0724 (0.0561) nleep/row_max_mean 1199.0859 (1201.1474) nleep/row_max_std 13.5094 (14.4908) nleep/row_min_mean 1198.4661 (1200.6122) lr 1.9921e-03 eta 0:26:37
epoch [4/50] batch [160/245] time 0.135 (0.140) data 0.000 (0.002) loss 0.5034 (0.8699) teacher_loss 0.4193 (0.7798) loss_zs_kd 0.0744 (0.0907) loss_oracle 0.0385 (0.0420) kd_loss 0.0276 (0.0237) acc 90.6250 (78.7695) gate/entropy 1.0966 (1.0973) gate/usage_max 0.3487 (0.3465) gate/usage_min 0.3035 (0.3102) gate/usage_std 0.0211 (0.0164) teacher/entropy 1.0592 (1.0677) teacher/usage_max 0.4060 (0.3865) teacher/usage_min 0.2325 (0.2542) teacher/usage_std 0.0736 (0.0574) nleep/row_max_mean 1207.5063 (1201.3504) nleep/row_max_std 14.9034 (14.4558) nleep/row_min_mean 1206.8611 (1200.8039) lr 1.9921e-03 eta 0:26:27
epoch [4/50] batch [180/245] time 0.135 (0.139) data 0.000 (0.002) loss 0.4349 (0.8610) teacher_loss 0.3378 (0.7689) loss_zs_kd 0.0700 (0.0907) loss_oracle 0.0612 (0.0444) kd_loss 0.0316 (0.0245) acc 93.7500 (79.0799) gate/entropy 1.0964 (1.0972) gate/usage_max 0.3513 (0.3469) gate/usage_min 0.3022 (0.3094) gate/usage_std 0.0221 (0.0170) teacher/entropy 1.0553 (1.0666) teacher/usage_max 0.4017 (0.3887) teacher/usage_min 0.2381 (0.2528) teacher/usage_std 0.0695 (0.0586) nleep/row_max_mean 1202.8608 (1201.3978) nleep/row_max_std 14.4610 (14.4054) nleep/row_min_mean 1202.2012 (1200.8407) lr 1.9921e-03 eta 0:26:20
epoch [4/50] batch [200/245] time 0.142 (0.139) data 0.000 (0.002) loss 0.6667 (0.8587) teacher_loss 0.5568 (0.7644) loss_zs_kd 0.1081 (0.0927) loss_oracle 0.0549 (0.0460) kd_loss 0.0284 (0.0249) acc 78.1250 (79.1094) gate/entropy 1.0961 (1.0971) gate/usage_max 0.3533 (0.3475) gate/usage_min 0.3004 (0.3086) gate/usage_std 0.0235 (0.0176) teacher/entropy 1.0588 (1.0658) teacher/usage_max 0.4156 (0.3908) teacher/usage_min 0.2473 (0.2522) teacher/usage_std 0.0688 (0.0595) nleep/row_max_mean 1203.4561 (1201.4128) nleep/row_max_std 16.3337 (14.4388) nleep/row_min_mean 1202.8285 (1200.8487) lr 1.9921e-03 eta 0:26:15
epoch [4/50] batch [220/245] time 0.133 (0.139) data 0.000 (0.002) loss 0.7114 (0.8629) teacher_loss 0.5796 (0.7676) loss_zs_kd 0.1297 (0.0932) loss_oracle 0.0690 (0.0470) kd_loss 0.0325 (0.0253) acc 84.3750 (79.1619) gate/entropy 1.0959 (1.0970) gate/usage_max 0.3543 (0.3481) gate/usage_min 0.2992 (0.3078) gate/usage_std 0.0244 (0.0182) teacher/entropy 1.0536 (1.0650) teacher/usage_max 0.4091 (0.3922) teacher/usage_min 0.2409 (0.2514) teacher/usage_std 0.0696 (0.0603) nleep/row_max_mean 1201.8828 (1201.4595) nleep/row_max_std 14.1072 (14.4261) nleep/row_min_mean 1201.2579 (1200.8886) lr 1.9921e-03 eta 0:26:15
epoch [4/50] batch [240/245] time 0.135 (0.139) data 0.000 (0.001) loss 1.0345 (0.8676) teacher_loss 0.9418 (0.7707) loss_zs_kd 0.0792 (0.0939) loss_oracle 0.0380 (0.0479) kd_loss 0.0340 (0.0260) acc 68.7500 (79.0104) gate/entropy 1.0956 (1.0969) gate/usage_max 0.3565 (0.3487) gate/usage_min 0.2974 (0.3070) gate/usage_std 0.0258 (0.0188) teacher/entropy 1.0490 (1.0638) teacher/usage_max 0.4161 (0.3942) teacher/usage_min 0.2270 (0.2500) teacher/usage_std 0.0790 (0.0615) nleep/row_max_mean 1198.8025 (1201.5474) nleep/row_max_std 13.7222 (14.3888) nleep/row_min_mean 1198.0791 (1200.9664) lr 1.9921e-03 eta 0:26:08
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,027
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,197
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 72.0%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.3%, epoch: 4 *******
******* Domain c best val test acc: 73.2%, epoch: 4 *******
******* Domain c best test acc:     73.2%, epoch: 4 *******
epoch [5/50] batch [20/245] time 0.330 (0.152) data 0.000 (0.014) loss 1.2496 (0.9618) teacher_loss 1.1258 (0.8523) loss_zs_kd 0.1528 (0.1026) loss_oracle 0.0450 (0.0533) kd_loss 0.0249 (0.0316) acc 75.0000 (77.3438) gate/entropy 1.0950 (1.0952) gate/usage_max 0.3597 (0.3586) gate/usage_min 0.2945 (0.2954) gate/usage_std 0.0281 (0.0273) teacher/entropy 1.0586 (1.0519) teacher/usage_max 0.4059 (0.4157) teacher/usage_min 0.2342 (0.2346) teacher/usage_std 0.0726 (0.0751) nleep/row_max_mean 1202.9987 (1200.9232) nleep/row_max_std 16.4316 (14.0562) nleep/row_min_mean 1202.3486 (1200.2373) lr 1.9823e-03 eta 0:28:30
epoch [5/50] batch [40/245] time 0.089 (0.136) data 0.000 (0.007) loss 1.0113 (0.9301) teacher_loss 0.8954 (0.8224) loss_zs_kd 0.1041 (0.1032) loss_oracle 0.0468 (0.0508) kd_loss 0.0404 (0.0308) acc 78.1250 (77.2656) gate/entropy 1.0948 (1.0951) gate/usage_max 0.3610 (0.3594) gate/usage_min 0.2938 (0.2948) gate/usage_std 0.0287 (0.0278) teacher/entropy 1.0383 (1.0527) teacher/usage_max 0.4384 (0.4128) teacher/usage_min 0.2160 (0.2357) teacher/usage_std 0.0912 (0.0738) nleep/row_max_mean 1206.6926 (1201.7967) nleep/row_max_std 11.2875 (13.9312) nleep/row_min_mean 1205.8898 (1201.1196) lr 1.9823e-03 eta 0:25:27
epoch [5/50] batch [60/245] time 0.093 (0.137) data 0.001 (0.005) loss 0.9131 (0.9031) teacher_loss 0.8332 (0.7987) loss_zs_kd 0.0640 (0.0985) loss_oracle 0.0324 (0.0483) kd_loss 0.0316 (0.0310) acc 71.8750 (78.0729) gate/entropy 1.0945 (1.0949) gate/usage_max 0.3624 (0.3602) gate/usage_min 0.2922 (0.2942) gate/usage_std 0.0299 (0.0283) teacher/entropy 1.0484 (1.0524) teacher/usage_max 0.4298 (0.4121) teacher/usage_min 0.2256 (0.2362) teacher/usage_std 0.0837 (0.0734) nleep/row_max_mean 1202.2667 (1202.0189) nleep/row_max_std 13.6213 (14.1686) nleep/row_min_mean 1201.5533 (1201.3398) lr 1.9823e-03 eta 0:25:35
epoch [5/50] batch [80/245] time 0.081 (0.143) data 0.000 (0.004) loss 0.7407 (0.8927) teacher_loss 0.6119 (0.7869) loss_zs_kd 0.1345 (0.1009) loss_oracle 0.0529 (0.0483) kd_loss 0.0351 (0.0312) acc 84.3750 (78.5547) gate/entropy 1.0940 (1.0948) gate/usage_max 0.3650 (0.3612) gate/usage_min 0.2902 (0.2934) gate/usage_std 0.0316 (0.0289) teacher/entropy 1.0461 (1.0518) teacher/usage_max 0.4196 (0.4121) teacher/usage_min 0.2331 (0.2360) teacher/usage_std 0.0768 (0.0735) nleep/row_max_mean 1203.0437 (1202.6425) nleep/row_max_std 12.2535 (14.3315) nleep/row_min_mean 1202.3259 (1201.9598) lr 1.9823e-03 eta 0:26:36
epoch [5/50] batch [100/245] time 0.079 (0.140) data 0.000 (0.003) loss 0.4118 (0.8692) teacher_loss 0.3227 (0.7650) loss_zs_kd 0.0762 (0.0987) loss_oracle 0.0404 (0.0472) kd_loss 0.0308 (0.0312) acc 87.5000 (79.0625) gate/entropy 1.0936 (1.0946) gate/usage_max 0.3676 (0.3622) gate/usage_min 0.2883 (0.2926) gate/usage_std 0.0332 (0.0296) teacher/entropy 1.0512 (1.0515) teacher/usage_max 0.3950 (0.4123) teacher/usage_min 0.2333 (0.2357) teacher/usage_std 0.0714 (0.0737) nleep/row_max_mean 1204.3806 (1202.9921) nleep/row_max_std 16.9555 (14.6830) nleep/row_min_mean 1203.6807 (1202.3067) lr 1.9823e-03 eta 0:26:00
epoch [5/50] batch [120/245] time 0.078 (0.143) data 0.000 (0.002) loss 0.7644 (0.8638) teacher_loss 0.6460 (0.7591) loss_zs_kd 0.1042 (0.0973) loss_oracle 0.0572 (0.0497) kd_loss 0.0377 (0.0312) acc 75.0000 (79.1667) gate/entropy 1.0932 (1.0944) gate/usage_max 0.3693 (0.3632) gate/usage_min 0.2868 (0.2918) gate/usage_std 0.0345 (0.0303) teacher/entropy 1.0366 (1.0513) teacher/usage_max 0.4431 (0.4117) teacher/usage_min 0.2118 (0.2359) teacher/usage_std 0.0948 (0.0735) nleep/row_max_mean 1200.2175 (1203.0536) nleep/row_max_std 11.8440 (14.6744) nleep/row_min_mean 1199.4127 (1202.3669) lr 1.9823e-03 eta 0:26:37
epoch [5/50] batch [140/245] time 0.137 (0.143) data 0.000 (0.002) loss 0.6343 (0.8550) teacher_loss 0.5200 (0.7500) loss_zs_kd 0.1116 (0.0955) loss_oracle 0.0533 (0.0515) kd_loss 0.0319 (0.0314) acc 84.3750 (79.4643) gate/entropy 1.0932 (1.0942) gate/usage_max 0.3696 (0.3641) gate/usage_min 0.2869 (0.2911) gate/usage_std 0.0345 (0.0309) teacher/entropy 1.0496 (1.0508) teacher/usage_max 0.4075 (0.4121) teacher/usage_min 0.2377 (0.2357) teacher/usage_std 0.0710 (0.0737) nleep/row_max_mean 1199.7046 (1203.1767) nleep/row_max_std 11.6705 (14.7093) nleep/row_min_mean 1199.0392 (1202.4864) lr 1.9823e-03 eta 0:26:31
epoch [5/50] batch [160/245] time 0.138 (0.143) data 0.000 (0.002) loss 0.7461 (0.8562) teacher_loss 0.6381 (0.7493) loss_zs_kd 0.1063 (0.0965) loss_oracle 0.0579 (0.0535) kd_loss 0.0260 (0.0318) acc 84.3750 (79.6094) gate/entropy 1.0928 (1.0940) gate/usage_max 0.3713 (0.3649) gate/usage_min 0.2855 (0.2905) gate/usage_std 0.0357 (0.0315) teacher/entropy 1.0584 (1.0503) teacher/usage_max 0.3979 (0.4108) teacher/usage_min 0.2520 (0.2362) teacher/usage_std 0.0607 (0.0731) nleep/row_max_mean 1202.0363 (1203.3411) nleep/row_max_std 15.3950 (14.5482) nleep/row_min_mean 1201.4233 (1202.6489) lr 1.9823e-03 eta 0:26:24
epoch [5/50] batch [180/245] time 0.134 (0.142) data 0.000 (0.002) loss 0.9928 (0.8659) teacher_loss 0.8019 (0.7571) loss_zs_kd 0.1825 (0.0982) loss_oracle 0.1009 (0.0558) kd_loss 0.0492 (0.0318) acc 84.3750 (79.2882) gate/entropy 1.0926 (1.0939) gate/usage_max 0.3724 (0.3656) gate/usage_min 0.2852 (0.2899) gate/usage_std 0.0362 (0.0319) teacher/entropy 1.0231 (1.0504) teacher/usage_max 0.4589 (0.4099) teacher/usage_min 0.2144 (0.2370) teacher/usage_std 0.0999 (0.0725) nleep/row_max_mean 1200.7731 (1203.1878) nleep/row_max_std 14.3684 (14.4503) nleep/row_min_mean 1199.9261 (1202.4964) lr 1.9823e-03 eta 0:26:16
epoch [5/50] batch [200/245] time 0.138 (0.142) data 0.000 (0.002) loss 0.8328 (0.8673) teacher_loss 0.7278 (0.7574) loss_zs_kd 0.1008 (0.0993) loss_oracle 0.0469 (0.0563) kd_loss 0.0312 (0.0321) acc 75.0000 (79.1875) gate/entropy 1.0927 (1.0938) gate/usage_max 0.3723 (0.3663) gate/usage_min 0.2857 (0.2895) gate/usage_std 0.0359 (0.0323) teacher/entropy 1.0536 (1.0501) teacher/usage_max 0.3926 (0.4093) teacher/usage_min 0.2521 (0.2376) teacher/usage_std 0.0594 (0.0720) nleep/row_max_mean 1200.3420 (1203.1614) nleep/row_max_std 13.1111 (14.4835) nleep/row_min_mean 1199.6586 (1202.4690) lr 1.9823e-03 eta 0:26:14
epoch [5/50] batch [220/245] time 0.162 (0.142) data 0.000 (0.001) loss 1.2622 (0.8695) teacher_loss 1.1711 (0.7604) loss_zs_kd 0.0798 (0.0984) loss_oracle 0.0326 (0.0554) kd_loss 0.0350 (0.0322) acc 68.7500 (79.1903) gate/entropy 1.0925 (1.0937) gate/usage_max 0.3731 (0.3668) gate/usage_min 0.2849 (0.2891) gate/usage_std 0.0365 (0.0327) teacher/entropy 1.0440 (1.0502) teacher/usage_max 0.4343 (0.4082) teacher/usage_min 0.2415 (0.2387) teacher/usage_std 0.0790 (0.0712) nleep/row_max_mean 1195.3524 (1203.0677) nleep/row_max_std 11.5930 (14.4437) nleep/row_min_mean 1194.6183 (1202.3772) lr 1.9823e-03 eta 0:26:12
epoch [5/50] batch [240/245] time 0.135 (0.142) data 0.000 (0.001) loss 1.1723 (0.8721) teacher_loss 1.0649 (0.7634) loss_zs_kd 0.1076 (0.0989) loss_oracle 0.0410 (0.0544) kd_loss 0.0331 (0.0320) acc 65.6250 (78.9062) gate/entropy 1.0924 (1.0936) gate/usage_max 0.3728 (0.3673) gate/usage_min 0.2844 (0.2887) gate/usage_std 0.0367 (0.0330) teacher/entropy 1.0493 (1.0506) teacher/usage_max 0.3927 (0.4067) teacher/usage_min 0.2390 (0.2397) teacher/usage_std 0.0675 (0.0703) nleep/row_max_mean 1202.1077 (1203.0839) nleep/row_max_std 18.3842 (14.4352) nleep/row_min_mean 1201.3984 (1202.3970) lr 1.9823e-03 eta 0:26:03
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,026
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.4%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,173
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.4%
******* Domain c best val acc:      90.3%, epoch: 4 *******
******* Domain c best val test acc: 73.2%, epoch: 4 *******
******* Domain c best test acc:     73.2%, epoch: 4 *******
epoch [6/50] batch [20/245] time 0.155 (0.176) data 0.000 (0.014) loss 0.8747 (0.7992) teacher_loss 0.7919 (0.6931) loss_zs_kd 0.0748 (0.0917) loss_oracle 0.0456 (0.0506) kd_loss 0.0226 (0.0350) acc 81.2500 (81.8750) gate/entropy 1.0919 (1.0922) gate/usage_max 0.3751 (0.3740) gate/usage_min 0.2828 (0.2836) gate/usage_std 0.0382 (0.0375) teacher/entropy 1.0598 (1.0473) teacher/usage_max 0.4008 (0.3958) teacher/usage_min 0.2463 (0.2417) teacher/usage_std 0.0646 (0.0667) nleep/row_max_mean 1202.1630 (1204.1490) nleep/row_max_std 15.4369 (14.8317) nleep/row_min_mean 1201.5620 (1203.4403) lr 1.9686e-03 eta 0:32:15
epoch [6/50] batch [40/245] time 0.164 (0.168) data 0.000 (0.007) loss 1.1199 (0.8237) teacher_loss 1.0290 (0.7194) loss_zs_kd 0.1013 (0.0909) loss_oracle 0.0350 (0.0514) kd_loss 0.0228 (0.0332) acc 65.6250 (79.8438) gate/entropy 1.0917 (1.0920) gate/usage_max 0.3760 (0.3747) gate/usage_min 0.2818 (0.2830) gate/usage_std 0.0389 (0.0379) teacher/entropy 1.0606 (1.0493) teacher/usage_max 0.4021 (0.3981) teacher/usage_min 0.2521 (0.2444) teacher/usage_std 0.0619 (0.0656) nleep/row_max_mean 1204.0603 (1203.9823) nleep/row_max_std 11.7518 (14.4739) nleep/row_min_mean 1203.4562 (1203.2941) lr 1.9686e-03 eta 0:30:45
epoch [6/50] batch [60/245] time 0.137 (0.164) data 0.001 (0.005) loss 0.9336 (0.8344) teacher_loss 0.8083 (0.7253) loss_zs_kd 0.0976 (0.0943) loss_oracle 0.0638 (0.0550) kd_loss 0.0447 (0.0345) acc 71.8750 (79.6354) gate/entropy 1.0914 (1.0919) gate/usage_max 0.3773 (0.3753) gate/usage_min 0.2810 (0.2826) gate/usage_std 0.0397 (0.0384) teacher/entropy 1.0329 (1.0478) teacher/usage_max 0.4149 (0.4009) teacher/usage_min 0.2307 (0.2452) teacher/usage_std 0.0767 (0.0659) nleep/row_max_mean 1209.0725 (1203.8691) nleep/row_max_std 13.2103 (14.2488) nleep/row_min_mean 1208.3047 (1203.1771) lr 1.9686e-03 eta 0:29:54
epoch [6/50] batch [80/245] time 0.136 (0.157) data 0.000 (0.004) loss 0.7841 (0.8348) teacher_loss 0.6645 (0.7242) loss_zs_kd 0.0926 (0.0960) loss_oracle 0.0545 (0.0548) kd_loss 0.0461 (0.0353) acc 78.1250 (79.8438) gate/entropy 1.0912 (1.0917) gate/usage_max 0.3786 (0.3759) gate/usage_min 0.2808 (0.2822) gate/usage_std 0.0403 (0.0387) teacher/entropy 1.0298 (1.0470) teacher/usage_max 0.4279 (0.4017) teacher/usage_min 0.2297 (0.2463) teacher/usage_std 0.0812 (0.0656) nleep/row_max_mean 1204.1672 (1203.7307) nleep/row_max_std 16.0342 (14.1581) nleep/row_min_mean 1203.3533 (1203.0330) lr 1.9686e-03 eta 0:28:35
epoch [6/50] batch [100/245] time 0.140 (0.153) data 0.000 (0.003) loss 1.4009 (0.8260) teacher_loss 1.2726 (0.7145) loss_zs_kd 0.1091 (0.0955) loss_oracle 0.0743 (0.0561) kd_loss 0.0366 (0.0356) acc 68.7500 (80.4062) gate/entropy 1.0909 (1.0916) gate/usage_max 0.3799 (0.3766) gate/usage_min 0.2799 (0.2819) gate/usage_std 0.0411 (0.0391) teacher/entropy 1.0473 (1.0469) teacher/usage_max 0.4044 (0.4002) teacher/usage_min 0.2591 (0.2468) teacher/usage_std 0.0594 (0.0649) nleep/row_max_mean 1200.7542 (1203.7103) nleep/row_max_std 16.3642 (14.2010) nleep/row_min_mean 1200.0935 (1203.0143) lr 1.9686e-03 eta 0:27:56
epoch [6/50] batch [120/245] time 0.133 (0.151) data 0.000 (0.002) loss 1.0895 (0.8215) teacher_loss 0.9482 (0.7078) loss_zs_kd 0.1327 (0.0964) loss_oracle 0.0748 (0.0583) kd_loss 0.0376 (0.0364) acc 75.0000 (80.6250) gate/entropy 1.0904 (1.0915) gate/usage_max 0.3817 (0.3773) gate/usage_min 0.2784 (0.2815) gate/usage_std 0.0424 (0.0395) teacher/entropy 1.0450 (1.0461) teacher/usage_max 0.3978 (0.4001) teacher/usage_min 0.2499 (0.2473) teacher/usage_std 0.0618 (0.0646) nleep/row_max_mean 1205.6638 (1203.7722) nleep/row_max_std 20.9823 (14.2573) nleep/row_min_mean 1204.9513 (1203.0709) lr 1.9686e-03 eta 0:27:24
epoch [6/50] batch [140/245] time 0.149 (0.149) data 0.000 (0.002) loss 1.0372 (0.8293) teacher_loss 0.9086 (0.7150) loss_zs_kd 0.1136 (0.0977) loss_oracle 0.0595 (0.0582) kd_loss 0.0420 (0.0364) acc 78.1250 (80.5580) gate/entropy 1.0902 (1.0913) gate/usage_max 0.3817 (0.3779) gate/usage_min 0.2775 (0.2810) gate/usage_std 0.0429 (0.0400) teacher/entropy 1.0411 (1.0461) teacher/usage_max 0.3804 (0.3989) teacher/usage_min 0.2436 (0.2472) teacher/usage_std 0.0635 (0.0644) nleep/row_max_mean 1204.0845 (1203.6908) nleep/row_max_std 15.2069 (14.3753) nleep/row_min_mean 1203.3309 (1202.9879) lr 1.9686e-03 eta 0:27:01
epoch [6/50] batch [160/245] time 0.133 (0.148) data 0.000 (0.002) loss 0.6953 (0.8322) teacher_loss 0.5753 (0.7157) loss_zs_kd 0.0772 (0.0991) loss_oracle 0.0807 (0.0609) kd_loss 0.0410 (0.0365) acc 84.3750 (80.3711) gate/entropy 1.0901 (1.0911) gate/usage_max 0.3822 (0.3785) gate/usage_min 0.2775 (0.2805) gate/usage_std 0.0430 (0.0404) teacher/entropy 1.0507 (1.0462) teacher/usage_max 0.3833 (0.3986) teacher/usage_min 0.2674 (0.2479) teacher/usage_std 0.0487 (0.0640) nleep/row_max_mean 1204.5048 (1203.5717) nleep/row_max_std 17.6795 (14.4394) nleep/row_min_mean 1203.8962 (1202.8686) lr 1.9686e-03 eta 0:26:43
epoch [6/50] batch [180/245] time 0.151 (0.147) data 0.000 (0.002) loss 0.7431 (0.8312) teacher_loss 0.5886 (0.7129) loss_zs_kd 0.0926 (0.0992) loss_oracle 0.1247 (0.0631) kd_loss 0.0459 (0.0371) acc 87.5000 (80.4340) gate/entropy 1.0900 (1.0910) gate/usage_max 0.3838 (0.3790) gate/usage_min 0.2774 (0.2801) gate/usage_std 0.0436 (0.0407) teacher/entropy 1.0337 (1.0453) teacher/usage_max 0.4193 (0.3992) teacher/usage_min 0.2496 (0.2475) teacher/usage_std 0.0693 (0.0644) nleep/row_max_mean 1205.1042 (1203.6125) nleep/row_max_std 17.1908 (14.4754) nleep/row_min_mean 1204.3379 (1202.9040) lr 1.9686e-03 eta 0:26:39
epoch [6/50] batch [200/245] time 0.099 (0.145) data 0.000 (0.002) loss 0.5427 (0.8356) teacher_loss 0.4168 (0.7163) loss_zs_kd 0.1286 (0.0999) loss_oracle 0.0509 (0.0641) kd_loss 0.0361 (0.0373) acc 87.5000 (80.3125) gate/entropy 1.0893 (1.0909) gate/usage_max 0.3866 (0.3796) gate/usage_min 0.2762 (0.2798) gate/usage_std 0.0452 (0.0411) teacher/entropy 1.0428 (1.0449) teacher/usage_max 0.4266 (0.3996) teacher/usage_min 0.2523 (0.2470) teacher/usage_std 0.0717 (0.0648) nleep/row_max_mean 1201.9590 (1203.6695) nleep/row_max_std 15.4441 (14.4014) nleep/row_min_mean 1201.2711 (1202.9588) lr 1.9686e-03 eta 0:26:12
epoch [6/50] batch [220/245] time 0.087 (0.145) data 0.000 (0.001) loss 0.7961 (0.8469) teacher_loss 0.7145 (0.7274) loss_zs_kd 0.0674 (0.1008) loss_oracle 0.0529 (0.0629) kd_loss 0.0215 (0.0376) acc 84.3750 (80.0852) gate/entropy 1.0890 (1.0907) gate/usage_max 0.3878 (0.3803) gate/usage_min 0.2752 (0.2794) gate/usage_std 0.0461 (0.0415) teacher/entropy 1.0723 (1.0446) teacher/usage_max 0.3676 (0.3992) teacher/usage_min 0.2861 (0.2470) teacher/usage_std 0.0345 (0.0646) nleep/row_max_mean 1202.8927 (1203.7142) nleep/row_max_std 13.3178 (14.4512) nleep/row_min_mean 1202.3981 (1203.0009) lr 1.9686e-03 eta 0:26:07
epoch [6/50] batch [240/245] time 0.117 (0.143) data 0.000 (0.001) loss 0.8135 (0.8410) teacher_loss 0.6821 (0.7196) loss_zs_kd 0.0823 (0.0998) loss_oracle 0.1009 (0.0670) kd_loss 0.0398 (0.0380) acc 78.1250 (80.1953) gate/entropy 1.0883 (1.0905) gate/usage_max 0.3906 (0.3811) gate/usage_min 0.2738 (0.2790) gate/usage_std 0.0477 (0.0420) teacher/entropy 1.0395 (1.0442) teacher/usage_max 0.4100 (0.3996) teacher/usage_min 0.2448 (0.2473) teacher/usage_std 0.0679 (0.0646) nleep/row_max_mean 1200.7001 (1203.7041) nleep/row_max_std 14.2053 (14.4213) nleep/row_min_mean 1199.9788 (1202.9887) lr 1.9686e-03 eta 0:25:43
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,029
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,185
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.7%
******* Domain c best val acc:      90.3%, epoch: 6 *******
******* Domain c best val test acc: 73.0%, epoch: 6 *******
******* Domain c best test acc:     73.2%, epoch: 4 *******
epoch [7/50] batch [20/245] time 0.136 (0.152) data 0.000 (0.013) loss 1.3519 (0.9548) teacher_loss 1.2405 (0.8283) loss_zs_kd 0.0937 (0.0963) loss_oracle 0.0435 (0.0728) kd_loss 0.0428 (0.0420) acc 68.7500 (78.2812) gate/entropy 1.0874 (1.0877) gate/usage_max 0.3943 (0.3930) gate/usage_min 0.2724 (0.2729) gate/usage_std 0.0498 (0.0490) teacher/entropy 1.0353 (1.0383) teacher/usage_max 0.4129 (0.4074) teacher/usage_min 0.2420 (0.2484) teacher/usage_std 0.0703 (0.0667) nleep/row_max_mean 1206.4797 (1203.7513) nleep/row_max_std 14.3154 (13.3422) nleep/row_min_mean 1205.6736 (1203.0068) lr 1.9511e-03 eta 0:27:16
epoch [7/50] batch [40/245] time 0.135 (0.145) data 0.000 (0.007) loss 0.6441 (0.9234) teacher_loss 0.5200 (0.7900) loss_zs_kd 0.0829 (0.1080) loss_oracle 0.0574 (0.0720) kd_loss 0.0539 (0.0434) acc 87.5000 (78.4375) gate/entropy 1.0875 (1.0876) gate/usage_max 0.3938 (0.3935) gate/usage_min 0.2723 (0.2726) gate/usage_std 0.0496 (0.0493) teacher/entropy 1.0263 (1.0369) teacher/usage_max 0.3986 (0.4069) teacher/usage_min 0.2422 (0.2481) teacher/usage_std 0.0664 (0.0664) nleep/row_max_mean 1205.4152 (1203.3111) nleep/row_max_std 11.9792 (13.3472) nleep/row_min_mean 1204.5892 (1202.5586) lr 1.9511e-03 eta 0:25:58
epoch [7/50] batch [60/245] time 0.137 (0.142) data 0.000 (0.005) loss 1.0194 (0.8898) teacher_loss 0.9038 (0.7597) loss_zs_kd 0.1040 (0.1041) loss_oracle 0.0578 (0.0704) kd_loss 0.0346 (0.0429) acc 71.8750 (80.0000) gate/entropy 1.0873 (1.0875) gate/usage_max 0.3937 (0.3936) gate/usage_min 0.2716 (0.2724) gate/usage_std 0.0498 (0.0495) teacher/entropy 1.0466 (1.0371) teacher/usage_max 0.3929 (0.4072) teacher/usage_min 0.2424 (0.2475) teacher/usage_std 0.0653 (0.0669) nleep/row_max_mean 1202.3602 (1203.0505) nleep/row_max_std 11.8776 (13.2849) nleep/row_min_mean 1201.6744 (1202.2948) lr 1.9511e-03 eta 0:25:27
epoch [7/50] batch [80/245] time 0.133 (0.142) data 0.000 (0.003) loss 0.9441 (0.8715) teacher_loss 0.8373 (0.7423) loss_zs_kd 0.0597 (0.1011) loss_oracle 0.0735 (0.0713) kd_loss 0.0401 (0.0431) acc 78.1250 (80.2344) gate/entropy 1.0867 (1.0874) gate/usage_max 0.3951 (0.3938) gate/usage_min 0.2697 (0.2720) gate/usage_std 0.0512 (0.0497) teacher/entropy 1.0386 (1.0364) teacher/usage_max 0.3960 (0.4076) teacher/usage_min 0.2347 (0.2454) teacher/usage_std 0.0706 (0.0680) nleep/row_max_mean 1204.3716 (1203.1851) nleep/row_max_std 15.2240 (13.2956) nleep/row_min_mean 1203.5801 (1202.4223) lr 1.9511e-03 eta 0:25:14
epoch [7/50] batch [100/245] time 0.160 (0.143) data 0.000 (0.003) loss 0.7577 (0.8746) teacher_loss 0.6668 (0.7451) loss_zs_kd 0.0593 (0.1018) loss_oracle 0.0451 (0.0701) kd_loss 0.0387 (0.0436) acc 81.2500 (80.2188) gate/entropy 1.0862 (1.0872) gate/usage_max 0.3959 (0.3942) gate/usage_min 0.2679 (0.2713) gate/usage_std 0.0523 (0.0502) teacher/entropy 1.0420 (1.0354) teacher/usage_max 0.3873 (0.4075) teacher/usage_min 0.2395 (0.2432) teacher/usage_std 0.0666 (0.0692) nleep/row_max_mean 1203.1094 (1203.1687) nleep/row_max_std 14.6048 (13.4284) nleep/row_min_mean 1202.3632 (1202.3964) lr 1.9511e-03 eta 0:25:27
epoch [7/50] batch [120/245] time 0.139 (0.143) data 0.000 (0.002) loss 0.8741 (0.8742) teacher_loss 0.7695 (0.7440) loss_zs_kd 0.0744 (0.1017) loss_oracle 0.0402 (0.0702) kd_loss 0.0473 (0.0443) acc 81.2500 (80.2344) gate/entropy 1.0855 (1.0870) gate/usage_max 0.3974 (0.3946) gate/usage_min 0.2661 (0.2706) gate/usage_std 0.0536 (0.0507) teacher/entropy 1.0233 (1.0340) teacher/usage_max 0.4112 (0.4085) teacher/usage_min 0.2126 (0.2412) teacher/usage_std 0.0865 (0.0705) nleep/row_max_mean 1204.6951 (1203.2511) nleep/row_max_std 12.4778 (13.4486) nleep/row_min_mean 1203.8289 (1202.4678) lr 1.9511e-03 eta 0:25:27
epoch [7/50] batch [140/245] time 0.143 (0.144) data 0.000 (0.002) loss 0.9695 (0.8806) teacher_loss 0.8143 (0.7483) loss_zs_kd 0.0707 (0.1025) loss_oracle 0.0717 (0.0704) kd_loss 0.0840 (0.0458) acc 84.3750 (80.0670) gate/entropy 1.0849 (1.0867) gate/usage_max 0.3989 (0.3951) gate/usage_min 0.2647 (0.2698) gate/usage_std 0.0548 (0.0512) teacher/entropy 0.9752 (1.0314) teacher/usage_max 0.4377 (0.4102) teacher/usage_min 0.1861 (0.2388) teacher/usage_std 0.1071 (0.0724) nleep/row_max_mean 1208.7736 (1203.3706) nleep/row_max_std 12.4132 (13.5215) nleep/row_min_mean 1207.6023 (1202.5720) lr 1.9511e-03 eta 0:25:29
epoch [7/50] batch [160/245] time 0.136 (0.143) data 0.000 (0.002) loss 0.9142 (0.8899) teacher_loss 0.7835 (0.7563) loss_zs_kd 0.0909 (0.1035) loss_oracle 0.0712 (0.0709) kd_loss 0.0496 (0.0464) acc 81.2500 (79.8828) gate/entropy 1.0845 (1.0865) gate/usage_max 0.4002 (0.3956) gate/usage_min 0.2638 (0.2691) gate/usage_std 0.0557 (0.0517) teacher/entropy 1.0138 (1.0299) teacher/usage_max 0.4429 (0.4121) teacher/usage_min 0.2080 (0.2368) teacher/usage_std 0.0966 (0.0739) nleep/row_max_mean 1203.9812 (1203.3967) nleep/row_max_std 15.7156 (13.5688) nleep/row_min_mean 1203.0212 (1202.5867) lr 1.9511e-03 eta 0:25:23
epoch [7/50] batch [180/245] time 0.138 (0.143) data 0.000 (0.002) loss 0.7242 (0.8885) teacher_loss 0.5327 (0.7523) loss_zs_kd 0.1534 (0.1039) loss_oracle 0.1333 (0.0753) kd_loss 0.0482 (0.0465) acc 84.3750 (80.0000) gate/entropy 1.0840 (1.0862) gate/usage_max 0.4017 (0.3962) gate/usage_min 0.2631 (0.2685) gate/usage_std 0.0566 (0.0522) teacher/entropy 1.0203 (1.0291) teacher/usage_max 0.4514 (0.4138) teacher/usage_min 0.2372 (0.2355) teacher/usage_std 0.0888 (0.0750) nleep/row_max_mean 1198.6442 (1203.4251) nleep/row_max_std 12.5832 (13.5452) nleep/row_min_mean 1197.7668 (1202.6070) lr 1.9511e-03 eta 0:25:17
epoch [7/50] batch [200/245] time 0.137 (0.143) data 0.000 (0.001) loss 1.0036 (0.8803) teacher_loss 0.8700 (0.7424) loss_zs_kd 0.0627 (0.1032) loss_oracle 0.1054 (0.0787) kd_loss 0.0495 (0.0470) acc 78.1250 (80.2812) gate/entropy 1.0832 (1.0860) gate/usage_max 0.4048 (0.3969) gate/usage_min 0.2621 (0.2679) gate/usage_std 0.0583 (0.0527) teacher/entropy 1.0289 (1.0280) teacher/usage_max 0.4056 (0.4158) teacher/usage_min 0.2433 (0.2343) teacher/usage_std 0.0674 (0.0762) nleep/row_max_mean 1202.0017 (1203.5290) nleep/row_max_std 13.5497 (13.5664) nleep/row_min_mean 1201.1860 (1202.7034) lr 1.9511e-03 eta 0:25:12
epoch [7/50] batch [220/245] time 0.159 (0.143) data 0.000 (0.001) loss 0.7436 (0.8759) teacher_loss 0.5897 (0.7371) loss_zs_kd 0.1239 (0.1036) loss_oracle 0.0906 (0.0800) kd_loss 0.0467 (0.0470) acc 81.2500 (80.3693) gate/entropy 1.0826 (1.0857) gate/usage_max 0.4077 (0.3978) gate/usage_min 0.2619 (0.2674) gate/usage_std 0.0596 (0.0533) teacher/entropy 1.0194 (1.0273) teacher/usage_max 0.4410 (0.4179) teacher/usage_min 0.2231 (0.2336) teacher/usage_std 0.0890 (0.0772) nleep/row_max_mean 1203.3452 (1203.6300) nleep/row_max_std 15.2840 (13.6167) nleep/row_min_mean 1202.4323 (1202.7997) lr 1.9511e-03 eta 0:25:08
epoch [7/50] batch [240/245] time 0.136 (0.142) data 0.000 (0.001) loss 0.4636 (0.8671) teacher_loss 0.3009 (0.7279) loss_zs_kd 0.0730 (0.1027) loss_oracle 0.1094 (0.0808) kd_loss 0.0715 (0.0475) acc 93.7500 (80.6771) gate/entropy 1.0823 (1.0854) gate/usage_max 0.4092 (0.3987) gate/usage_min 0.2618 (0.2669) gate/usage_std 0.0602 (0.0538) teacher/entropy 0.9863 (1.0260) teacher/usage_max 0.4605 (0.4202) teacher/usage_min 0.2055 (0.2325) teacher/usage_std 0.1041 (0.0785) nleep/row_max_mean 1206.9060 (1203.8465) nleep/row_max_std 12.2730 (13.7431) nleep/row_min_mean 1205.8325 (1203.0081) lr 1.9511e-03 eta 0:25:00
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,035
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,189
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 71.8%
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 73.1%, epoch: 7 *******
******* Domain c best test acc:     73.2%, epoch: 4 *******
epoch [8/50] batch [20/245] time 0.139 (0.160) data 0.000 (0.015) loss 1.1619 (0.9375) teacher_loss 1.0294 (0.7793) loss_zs_kd 0.0818 (0.1066) loss_oracle 0.0936 (0.1034) kd_loss 0.0448 (0.0531) acc 68.7500 (79.8438) gate/entropy 1.0813 (1.0816) gate/usage_max 0.4123 (0.4112) gate/usage_min 0.2610 (0.2611) gate/usage_std 0.0620 (0.0614) teacher/entropy 1.0316 (1.0112) teacher/usage_max 0.4207 (0.4504) teacher/usage_min 0.2491 (0.2253) teacher/usage_std 0.0701 (0.0930) nleep/row_max_mean 1206.9109 (1204.8065) nleep/row_max_std 16.4986 (14.2854) nleep/row_min_mean 1206.1267 (1203.8912) lr 1.9298e-03 eta 0:28:01
epoch [8/50] batch [40/245] time 0.133 (0.148) data 0.000 (0.008) loss 0.6142 (0.9007) teacher_loss 0.4819 (0.7360) loss_zs_kd 0.0564 (0.0998) loss_oracle 0.1266 (0.1204) kd_loss 0.0408 (0.0547) acc 78.1250 (80.3125) gate/entropy 1.0803 (1.0813) gate/usage_max 0.4156 (0.4125) gate/usage_min 0.2600 (0.2608) gate/usage_std 0.0638 (0.0621) teacher/entropy 1.0286 (1.0084) teacher/usage_max 0.4371 (0.4527) teacher/usage_min 0.2364 (0.2231) teacher/usage_std 0.0821 (0.0949) nleep/row_max_mean 1201.8749 (1204.4764) nleep/row_max_std 15.4588 (13.9185) nleep/row_min_mean 1201.0698 (1203.5421) lr 1.9298e-03 eta 0:25:55
epoch [8/50] batch [60/245] time 0.134 (0.144) data 0.000 (0.005) loss 0.9888 (0.8819) teacher_loss 0.8543 (0.7204) loss_zs_kd 0.0777 (0.0980) loss_oracle 0.0899 (0.1166) kd_loss 0.0508 (0.0541) acc 78.1250 (80.9896) gate/entropy 1.0791 (1.0808) gate/usage_max 0.4195 (0.4142) gate/usage_min 0.2590 (0.2604) gate/usage_std 0.0661 (0.0630) teacher/entropy 1.0135 (1.0092) teacher/usage_max 0.4418 (0.4522) teacher/usage_min 0.2186 (0.2251) teacher/usage_std 0.0912 (0.0939) nleep/row_max_mean 1207.5387 (1204.9978) nleep/row_max_std 16.9285 (14.0011) nleep/row_min_mean 1206.6082 (1204.0697) lr 1.9298e-03 eta 0:25:06
epoch [8/50] batch [80/245] time 0.138 (0.142) data 0.000 (0.004) loss 0.5290 (0.8921) teacher_loss 0.4081 (0.7341) loss_zs_kd 0.0729 (0.0973) loss_oracle 0.0789 (0.1095) kd_loss 0.0450 (0.0546) acc 90.6250 (80.2344) gate/entropy 1.0783 (1.0802) gate/usage_max 0.4222 (0.4159) gate/usage_min 0.2587 (0.2600) gate/usage_std 0.0675 (0.0640) teacher/entropy 1.0308 (1.0077) teacher/usage_max 0.4234 (0.4556) teacher/usage_min 0.2503 (0.2251) teacher/usage_std 0.0708 (0.0955) nleep/row_max_mean 1203.7036 (1204.6128) nleep/row_max_std 12.8740 (13.9978) nleep/row_min_mean 1202.9119 (1203.6771) lr 1.9298e-03 eta 0:24:44
epoch [8/50] batch [100/245] time 0.098 (0.134) data 0.000 (0.003) loss 0.9452 (0.8989) teacher_loss 0.7604 (0.7419) loss_zs_kd 0.1493 (0.0967) loss_oracle 0.0818 (0.1062) kd_loss 0.0693 (0.0556) acc 78.1250 (80.0625) gate/entropy 1.0768 (1.0797) gate/usage_max 0.4263 (0.4176) gate/usage_min 0.2571 (0.2595) gate/usage_std 0.0701 (0.0650) teacher/entropy 0.9637 (1.0053) teacher/usage_max 0.5260 (0.4587) teacher/usage_min 0.1903 (0.2239) teacher/usage_std 0.1415 (0.0974) nleep/row_max_mean 1206.8308 (1204.5544) nleep/row_max_std 15.3534 (13.7972) nleep/row_min_mean 1205.6631 (1203.6080) lr 1.9298e-03 eta 0:23:22
epoch [8/50] batch [120/245] time 0.088 (0.139) data 0.000 (0.003) loss 0.8428 (0.8814) teacher_loss 0.6190 (0.7252) loss_zs_kd 0.1584 (0.0972) loss_oracle 0.1240 (0.1033) kd_loss 0.0826 (0.0560) acc 71.8750 (80.1302) gate/entropy 1.0762 (1.0791) gate/usage_max 0.4282 (0.4192) gate/usage_min 0.2567 (0.2591) gate/usage_std 0.0712 (0.0660) teacher/entropy 0.9677 (1.0046) teacher/usage_max 0.4830 (0.4597) teacher/usage_min 0.2170 (0.2247) teacher/usage_std 0.1111 (0.0976) nleep/row_max_mean 1206.0591 (1204.5671) nleep/row_max_std 14.2370 (13.7175) nleep/row_min_mean 1204.9751 (1203.6211) lr 1.9298e-03 eta 0:24:12
epoch [8/50] batch [140/245] time 0.079 (0.143) data 0.000 (0.002) loss 0.5853 (0.8744) teacher_loss 0.4779 (0.7195) loss_zs_kd 0.0736 (0.0969) loss_oracle 0.0533 (0.1007) kd_loss 0.0439 (0.0562) acc 87.5000 (80.2679) gate/entropy 1.0754 (1.0786) gate/usage_max 0.4306 (0.4208) gate/usage_min 0.2565 (0.2587) gate/usage_std 0.0725 (0.0669) teacher/entropy 1.0087 (1.0040) teacher/usage_max 0.4710 (0.4605) teacher/usage_min 0.2080 (0.2248) teacher/usage_std 0.1077 (0.0979) nleep/row_max_mean 1203.7913 (1204.4586) nleep/row_max_std 13.3690 (13.8003) nleep/row_min_mean 1202.8077 (1203.5091) lr 1.9298e-03 eta 0:24:41
epoch [8/50] batch [160/245] time 0.096 (0.140) data 0.000 (0.002) loss 1.0957 (0.8816) teacher_loss 1.0034 (0.7276) loss_zs_kd 0.0708 (0.0993) loss_oracle 0.0427 (0.0976) kd_loss 0.0356 (0.0555) acc 78.1250 (80.2344) gate/entropy 1.0744 (1.0781) gate/usage_max 0.4331 (0.4222) gate/usage_min 0.2557 (0.2583) gate/usage_std 0.0741 (0.0677) teacher/entropy 1.0227 (1.0050) teacher/usage_max 0.4644 (0.4596) teacher/usage_min 0.2267 (0.2259) teacher/usage_std 0.0986 (0.0971) nleep/row_max_mean 1205.6121 (1204.3968) nleep/row_max_std 16.0892 (13.7363) nleep/row_min_mean 1204.7596 (1203.4527) lr 1.9298e-03 eta 0:24:15
epoch [8/50] batch [180/245] time 0.361 (0.141) data 0.000 (0.002) loss 0.6789 (0.8757) teacher_loss 0.5505 (0.7216) loss_zs_kd 0.0838 (0.1003) loss_oracle 0.0543 (0.0956) kd_loss 0.0594 (0.0562) acc 84.3750 (80.3819) gate/entropy 1.0745 (1.0777) gate/usage_max 0.4330 (0.4234) gate/usage_min 0.2559 (0.2581) gate/usage_std 0.0740 (0.0684) teacher/entropy 1.0018 (1.0041) teacher/usage_max 0.4448 (0.4602) teacher/usage_min 0.2107 (0.2260) teacher/usage_std 0.0959 (0.0973) nleep/row_max_mean 1208.5955 (1204.3341) nleep/row_max_std 14.7845 (13.7388) nleep/row_min_mean 1207.5725 (1203.3855) lr 1.9298e-03 eta 0:24:16
epoch [8/50] batch [200/245] time 0.098 (0.140) data 0.000 (0.002) loss 1.2504 (0.8771) teacher_loss 1.0843 (0.7229) loss_zs_kd 0.0898 (0.1006) loss_oracle 0.1225 (0.0953) kd_loss 0.0600 (0.0563) acc 68.7500 (80.3906) gate/entropy 1.0732 (1.0773) gate/usage_max 0.4357 (0.4245) gate/usage_min 0.2540 (0.2578) gate/usage_std 0.0760 (0.0690) teacher/entropy 0.9871 (1.0037) teacher/usage_max 0.4898 (0.4602) teacher/usage_min 0.2171 (0.2257) teacher/usage_std 0.1149 (0.0975) nleep/row_max_mean 1204.2727 (1204.3206) nleep/row_max_std 15.0422 (13.8349) nleep/row_min_mean 1203.2158 (1203.3704) lr 1.9298e-03 eta 0:24:10
epoch [8/50] batch [220/245] time 0.138 (0.140) data 0.000 (0.002) loss 0.8681 (0.8751) teacher_loss 0.6269 (0.7187) loss_zs_kd 0.1472 (0.1017) loss_oracle 0.1517 (0.0979) kd_loss 0.0917 (0.0566) acc 87.5000 (80.4261) gate/entropy 1.0718 (1.0769) gate/usage_max 0.4390 (0.4256) gate/usage_min 0.2526 (0.2574) gate/usage_std 0.0781 (0.0697) teacher/entropy 0.9472 (1.0029) teacher/usage_max 0.5021 (0.4614) teacher/usage_min 0.2017 (0.2256) teacher/usage_std 0.1254 (0.0981) nleep/row_max_mean 1201.1494 (1204.3329) nleep/row_max_std 14.3129 (13.8825) nleep/row_min_mean 1199.9213 (1203.3791) lr 1.9298e-03 eta 0:24:08
epoch [8/50] batch [240/245] time 0.138 (0.140) data 0.000 (0.001) loss 0.7854 (0.8787) teacher_loss 0.6153 (0.7223) loss_zs_kd 0.1018 (0.1012) loss_oracle 0.0865 (0.0977) kd_loss 0.0759 (0.0569) acc 84.3750 (80.3776) gate/entropy 1.0701 (1.0765) gate/usage_max 0.4428 (0.4268) gate/usage_min 0.2513 (0.2570) gate/usage_std 0.0805 (0.0705) teacher/entropy 0.9681 (1.0022) teacher/usage_max 0.4756 (0.4621) teacher/usage_min 0.1817 (0.2257) teacher/usage_std 0.1202 (0.0985) nleep/row_max_mean 1210.7494 (1204.2818) nleep/row_max_std 15.1169 (13.8674) nleep/row_min_mean 1209.5605 (1203.3243) lr 1.9298e-03 eta 0:24:03
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,028
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.4%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,186
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.6%
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 73.1%, epoch: 7 *******
******* Domain c best test acc:     73.2%, epoch: 4 *******
epoch [9/50] batch [20/245] time 0.131 (0.154) data 0.000 (0.014) loss 0.9962 (0.8519) teacher_loss 0.8184 (0.6736) loss_zs_kd 0.1200 (0.1065) loss_oracle 0.1186 (0.1275) kd_loss 0.0585 (0.0613) acc 81.2500 (81.2500) gate/entropy 1.0690 (1.0694) gate/usage_max 0.4457 (0.4448) gate/usage_min 0.2512 (0.2511) gate/usage_std 0.0822 (0.0817) teacher/entropy 0.9956 (0.9882) teacher/usage_max 0.4616 (0.4810) teacher/usage_min 0.2061 (0.2216) teacher/usage_std 0.1043 (0.1094) nleep/row_max_mean 1204.4760 (1203.8659) nleep/row_max_std 17.5835 (14.6534) nleep/row_min_mean 1203.4778 (1202.8375) lr 1.9048e-03 eta 0:26:20
epoch [9/50] batch [40/245] time 0.134 (0.145) data 0.000 (0.007) loss 0.6862 (0.8453) teacher_loss 0.4717 (0.6640) loss_zs_kd 0.1507 (0.1089) loss_oracle 0.1403 (0.1309) kd_loss 0.0689 (0.0614) acc 84.3750 (81.0938) gate/entropy 1.0675 (1.0687) gate/usage_max 0.4491 (0.4464) gate/usage_min 0.2504 (0.2508) gate/usage_std 0.0844 (0.0827) teacher/entropy 0.9778 (0.9865) teacher/usage_max 0.4893 (0.4838) teacher/usage_min 0.2289 (0.2197) teacher/usage_std 0.1124 (0.1114) nleep/row_max_mean 1203.3179 (1203.8313) nleep/row_max_std 14.8220 (14.8139) nleep/row_min_mean 1202.2502 (1202.7871) lr 1.9048e-03 eta 0:24:45
epoch [9/50] batch [60/245] time 0.134 (0.142) data 0.000 (0.005) loss 1.4214 (0.8981) teacher_loss 1.2951 (0.7179) loss_zs_kd 0.1043 (0.1124) loss_oracle 0.0814 (0.1232) kd_loss 0.0335 (0.0624) acc 62.5000 (79.4792) gate/entropy 1.0666 (1.0681) gate/usage_max 0.4512 (0.4477) gate/usage_min 0.2501 (0.2506) gate/usage_std 0.0857 (0.0835) teacher/entropy 1.0233 (0.9840) teacher/usage_max 0.4660 (0.4860) teacher/usage_min 0.2303 (0.2174) teacher/usage_std 0.0985 (0.1133) nleep/row_max_mean 1203.0627 (1203.7717) nleep/row_max_std 16.3071 (14.6602) nleep/row_min_mean 1202.2302 (1202.7184) lr 1.9048e-03 eta 0:24:12
epoch [9/50] batch [80/245] time 0.132 (0.141) data 0.000 (0.004) loss 0.9669 (0.9158) teacher_loss 0.8435 (0.7390) loss_zs_kd 0.0812 (0.1115) loss_oracle 0.0750 (0.1170) kd_loss 0.0453 (0.0626) acc 75.0000 (79.6484) gate/entropy 1.0660 (1.0677) gate/usage_max 0.4525 (0.4487) gate/usage_min 0.2498 (0.2504) gate/usage_std 0.0865 (0.0842) teacher/entropy 1.0039 (0.9858) teacher/usage_max 0.4756 (0.4819) teacher/usage_min 0.2105 (0.2199) teacher/usage_std 0.1091 (0.1105) nleep/row_max_mean 1201.1904 (1203.9905) nleep/row_max_std 12.5952 (14.3919) nleep/row_min_mean 1200.2710 (1202.9487) lr 1.9048e-03 eta 0:23:54
epoch [9/50] batch [100/245] time 0.139 (0.140) data 0.000 (0.003) loss 0.2848 (0.9145) teacher_loss 0.1200 (0.7369) loss_zs_kd 0.0965 (0.1106) loss_oracle 0.1102 (0.1162) kd_loss 0.0615 (0.0642) acc 100.0000 (79.9375) gate/entropy 1.0656 (1.0673) gate/usage_max 0.4535 (0.4495) gate/usage_min 0.2499 (0.2503) gate/usage_std 0.0871 (0.0846) teacher/entropy 0.9732 (0.9847) teacher/usage_max 0.5051 (0.4805) teacher/usage_min 0.2002 (0.2199) teacher/usage_std 0.1274 (0.1098) nleep/row_max_mean 1206.4144 (1204.1857) nleep/row_max_std 14.0736 (14.4615) nleep/row_min_mean 1205.2822 (1203.1376) lr 1.9048e-03 eta 0:23:42
epoch [9/50] batch [120/245] time 0.132 (0.139) data 0.000 (0.002) loss 0.6888 (0.9122) teacher_loss 0.5249 (0.7354) loss_zs_kd 0.0987 (0.1083) loss_oracle 0.1087 (0.1165) kd_loss 0.0602 (0.0644) acc 84.3750 (80.0000) gate/entropy 1.0642 (1.0669) gate/usage_max 0.4563 (0.4504) gate/usage_min 0.2485 (0.2501) gate/usage_std 0.0890 (0.0852) teacher/entropy 0.9935 (0.9843) teacher/usage_max 0.4633 (0.4803) teacher/usage_min 0.2090 (0.2190) teacher/usage_std 0.1039 (0.1099) nleep/row_max_mean 1209.5984 (1204.4964) nleep/row_max_std 16.5455 (14.5361) nleep/row_min_mean 1208.5979 (1203.4459) lr 1.9048e-03 eta 0:23:32
epoch [9/50] batch [140/245] time 0.135 (0.138) data 0.000 (0.002) loss 0.4621 (0.9227) teacher_loss 0.3263 (0.7432) loss_zs_kd 0.0615 (0.1080) loss_oracle 0.1006 (0.1206) kd_loss 0.0547 (0.0653) acc 87.5000 (79.9107) gate/entropy 1.0622 (1.0664) gate/usage_max 0.4601 (0.4516) gate/usage_min 0.2468 (0.2498) gate/usage_std 0.0916 (0.0860) teacher/entropy 1.0032 (0.9833) teacher/usage_max 0.4610 (0.4805) teacher/usage_min 0.2264 (0.2194) teacher/usage_std 0.0969 (0.1099) nleep/row_max_mean 1210.8240 (1204.5915) nleep/row_max_std 15.5996 (14.5449) nleep/row_min_mean 1209.9043 (1203.5382) lr 1.9048e-03 eta 0:23:25
epoch [9/50] batch [160/245] time 0.134 (0.138) data 0.000 (0.002) loss 0.7656 (0.9200) teacher_loss 0.5881 (0.7403) loss_zs_kd 0.1336 (0.1090) loss_oracle 0.0978 (0.1188) kd_loss 0.0618 (0.0659) acc 81.2500 (79.9609) gate/entropy 1.0614 (1.0658) gate/usage_max 0.4617 (0.4527) gate/usage_min 0.2464 (0.2494) gate/usage_std 0.0927 (0.0867) teacher/entropy 0.9982 (0.9829) teacher/usage_max 0.4562 (0.4799) teacher/usage_min 0.2279 (0.2197) teacher/usage_std 0.0941 (0.1095) nleep/row_max_mean 1208.9180 (1204.7652) nleep/row_max_std 17.8782 (14.6089) nleep/row_min_mean 1207.9219 (1203.7110) lr 1.9048e-03 eta 0:23:19
epoch [9/50] batch [180/245] time 0.136 (0.138) data 0.000 (0.002) loss 1.3407 (0.9152) teacher_loss 1.1849 (0.7364) loss_zs_kd 0.1509 (0.1096) loss_oracle 0.0435 (0.1155) kd_loss 0.0586 (0.0662) acc 62.5000 (79.9306) gate/entropy 1.0602 (1.0652) gate/usage_max 0.4639 (0.4539) gate/usage_min 0.2452 (0.2489) gate/usage_std 0.0942 (0.0875) teacher/entropy 1.0096 (0.9829) teacher/usage_max 0.4367 (0.4791) teacher/usage_min 0.2201 (0.2202) teacher/usage_std 0.0887 (0.1089) nleep/row_max_mean 1208.5564 (1204.9236) nleep/row_max_std 15.6611 (14.7538) nleep/row_min_mean 1207.6191 (1203.8718) lr 1.9048e-03 eta 0:23:14
epoch [9/50] batch [200/245] time 0.137 (0.138) data 0.000 (0.002) loss 0.8458 (0.9125) teacher_loss 0.7503 (0.7352) loss_zs_kd 0.0494 (0.1091) loss_oracle 0.0624 (0.1126) kd_loss 0.0396 (0.0665) acc 78.1250 (80.0625) gate/entropy 1.0592 (1.0647) gate/usage_max 0.4657 (0.4550) gate/usage_min 0.2448 (0.2486) gate/usage_std 0.0954 (0.0882) teacher/entropy 1.0219 (0.9831) teacher/usage_max 0.4518 (0.4782) teacher/usage_min 0.2211 (0.2209) teacher/usage_std 0.0943 (0.1082) nleep/row_max_mean 1206.3794 (1205.0166) nleep/row_max_std 13.0347 (14.7609) nleep/row_min_mean 1205.5153 (1203.9670) lr 1.9048e-03 eta 0:23:12
epoch [9/50] batch [220/245] time 0.137 (0.138) data 0.000 (0.001) loss 1.1201 (0.9105) teacher_loss 0.9755 (0.7347) loss_zs_kd 0.1056 (0.1077) loss_oracle 0.0768 (0.1112) kd_loss 0.0534 (0.0663) acc 75.0000 (80.0426) gate/entropy 1.0588 (1.0641) gate/usage_max 0.4666 (0.4560) gate/usage_min 0.2444 (0.2482) gate/usage_std 0.0960 (0.0889) teacher/entropy 1.0046 (0.9842) teacher/usage_max 0.4580 (0.4764) teacher/usage_min 0.2178 (0.2218) teacher/usage_std 0.0983 (0.1071) nleep/row_max_mean 1205.7893 (1204.9890) nleep/row_max_std 13.8174 (14.7812) nleep/row_min_mean 1204.7991 (1203.9442) lr 1.9048e-03 eta 0:23:12
epoch [9/50] batch [240/245] time 0.149 (0.138) data 0.000 (0.001) loss 1.0464 (0.9087) teacher_loss 0.8697 (0.7326) loss_zs_kd 0.1327 (0.1085) loss_oracle 0.0853 (0.1107) kd_loss 0.0677 (0.0664) acc 75.0000 (80.1172) gate/entropy 1.0578 (1.0637) gate/usage_max 0.4682 (0.4570) gate/usage_min 0.2435 (0.2479) gate/usage_std 0.0971 (0.0896) teacher/entropy 0.9888 (0.9845) teacher/usage_max 0.4660 (0.4757) teacher/usage_min 0.2327 (0.2224) teacher/usage_std 0.0979 (0.1065) nleep/row_max_mean 1207.6218 (1204.9500) nleep/row_max_std 13.2075 (14.8129) nleep/row_min_mean 1206.6194 (1203.9065) lr 1.9048e-03 eta 0:23:08
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,034
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,199
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.0%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 73.1%, epoch: 7 *******
******* Domain c best test acc:     73.3%, epoch: 9 *******
epoch [10/50] batch [20/245] time 0.162 (0.169) data 0.000 (0.016) loss 0.8474 (0.9132) teacher_loss 0.6364 (0.7194) loss_zs_kd 0.1191 (0.1163) loss_oracle 0.1297 (0.1231) kd_loss 0.0866 (0.0741) acc 78.1250 (81.5625) gate/entropy 1.0562 (1.0568) gate/usage_max 0.4711 (0.4701) gate/usage_min 0.2421 (0.2427) gate/usage_std 0.0991 (0.0984) teacher/entropy 0.9910 (0.9814) teacher/usage_max 0.4281 (0.4643) teacher/usage_min 0.2480 (0.2221) teacher/usage_std 0.0738 (0.1005) nleep/row_max_mean 1206.2047 (1206.0817) nleep/row_max_std 14.1223 (14.9740) nleep/row_min_mean 1205.2437 (1205.0244) lr 1.8763e-03 eta 0:28:17
epoch [10/50] batch [40/245] time 0.330 (0.142) data 0.000 (0.008) loss 0.5048 (0.8921) teacher_loss 0.2988 (0.7002) loss_zs_kd 0.0855 (0.1063) loss_oracle 0.1568 (0.1302) kd_loss 0.0848 (0.0736) acc 96.8750 (81.6406) gate/entropy 1.0549 (1.0561) gate/usage_max 0.4735 (0.4713) gate/usage_min 0.2416 (0.2422) gate/usage_std 0.1007 (0.0992) teacher/entropy 0.9595 (0.9786) teacher/usage_max 0.4867 (0.4724) teacher/usage_min 0.2244 (0.2264) teacher/usage_std 0.1116 (0.1039) nleep/row_max_mean 1207.9846 (1205.8415) nleep/row_max_std 14.3825 (14.8163) nleep/row_min_mean 1206.9219 (1204.7830) lr 1.8763e-03 eta 0:23:43
epoch [10/50] batch [60/245] time 0.113 (0.148) data 0.001 (0.005) loss 1.0772 (0.8771) teacher_loss 0.9095 (0.6850) loss_zs_kd 0.1000 (0.1082) loss_oracle 0.1159 (0.1303) kd_loss 0.0598 (0.0728) acc 81.2500 (81.9792) gate/entropy 1.0530 (1.0555) gate/usage_max 0.4769 (0.4725) gate/usage_min 0.2408 (0.2420) gate/usage_std 0.1029 (0.1000) teacher/entropy 0.9767 (0.9782) teacher/usage_max 0.5015 (0.4751) teacher/usage_min 0.2177 (0.2273) teacher/usage_std 0.1217 (0.1052) nleep/row_max_mean 1207.8234 (1205.7229) nleep/row_max_std 13.8905 (14.7273) nleep/row_min_mean 1206.6779 (1204.6623) lr 1.8763e-03 eta 0:24:34
epoch [10/50] batch [80/245] time 0.112 (0.152) data 0.000 (0.004) loss 0.7843 (0.8801) teacher_loss 0.5983 (0.6881) loss_zs_kd 0.1171 (0.1083) loss_oracle 0.1273 (0.1288) kd_loss 0.0638 (0.0735) acc 81.2500 (81.7188) gate/entropy 1.0520 (1.0548) gate/usage_max 0.4789 (0.4737) gate/usage_min 0.2408 (0.2418) gate/usage_std 0.1042 (0.1008) teacher/entropy 0.9852 (0.9755) teacher/usage_max 0.4859 (0.4790) teacher/usage_min 0.2515 (0.2277) teacher/usage_std 0.1080 (0.1073) nleep/row_max_mean 1205.4989 (1205.4399) nleep/row_max_std 12.7784 (14.5809) nleep/row_min_mean 1204.4437 (1204.3684) lr 1.8763e-03 eta 0:25:14
epoch [10/50] batch [100/245] time 0.105 (0.146) data 0.000 (0.003) loss 1.0542 (0.9061) teacher_loss 0.8564 (0.7168) loss_zs_kd 0.1296 (0.1067) loss_oracle 0.0999 (0.1242) kd_loss 0.0831 (0.0739) acc 78.1250 (80.9688) gate/entropy 1.0501 (1.0541) gate/usage_max 0.4819 (0.4750) gate/usage_min 0.2396 (0.2415) gate/usage_std 0.1063 (0.1017) teacher/entropy 0.9701 (0.9742) teacher/usage_max 0.4698 (0.4805) teacher/usage_min 0.2193 (0.2260) teacher/usage_std 0.1035 (0.1084) nleep/row_max_mean 1206.0078 (1205.2868) nleep/row_max_std 16.0198 (14.6567) nleep/row_min_mean 1204.8468 (1204.2083) lr 1.8763e-03 eta 0:24:14
epoch [10/50] batch [120/245] time 0.331 (0.149) data 0.000 (0.003) loss 0.8470 (0.9018) teacher_loss 0.6633 (0.7167) loss_zs_kd 0.0933 (0.1043) loss_oracle 0.1055 (0.1192) kd_loss 0.0844 (0.0733) acc 81.2500 (80.9896) gate/entropy 1.0497 (1.0534) gate/usage_max 0.4827 (0.4762) gate/usage_min 0.2398 (0.2412) gate/usage_std 0.1067 (0.1025) teacher/entropy 0.9867 (0.9748) teacher/usage_max 0.4461 (0.4805) teacher/usage_min 0.2525 (0.2263) teacher/usage_std 0.0822 (0.1083) nleep/row_max_mean 1207.0580 (1205.2712) nleep/row_max_std 11.9497 (14.5836) nleep/row_min_mean 1206.0537 (1204.1986) lr 1.8763e-03 eta 0:24:39
epoch [10/50] batch [140/245] time 0.326 (0.152) data 0.000 (0.002) loss 1.0525 (0.9032) teacher_loss 0.8342 (0.7187) loss_zs_kd 0.1508 (0.1047) loss_oracle 0.1300 (0.1185) kd_loss 0.0779 (0.0729) acc 71.8750 (80.8259) gate/entropy 1.0498 (1.0528) gate/usage_max 0.4827 (0.4772) gate/usage_min 0.2406 (0.2411) gate/usage_std 0.1067 (0.1031) teacher/entropy 1.0140 (0.9765) teacher/usage_max 0.4157 (0.4787) teacher/usage_min 0.2824 (0.2281) teacher/usage_std 0.0588 (0.1069) nleep/row_max_mean 1202.9441 (1205.1718) nleep/row_max_std 15.8905 (14.5417) nleep/row_min_mean 1202.0627 (1204.1092) lr 1.8763e-03 eta 0:25:06
epoch [10/50] batch [160/245] time 0.139 (0.150) data 0.000 (0.002) loss 1.1037 (0.9053) teacher_loss 0.9150 (0.7211) loss_zs_kd 0.1186 (0.1046) loss_oracle 0.1220 (0.1176) kd_loss 0.0684 (0.0731) acc 65.6250 (80.6055) gate/entropy 1.0501 (1.0525) gate/usage_max 0.4826 (0.4778) gate/usage_min 0.2419 (0.2411) gate/usage_std 0.1064 (0.1035) teacher/entropy 0.9567 (0.9786) teacher/usage_max 0.5190 (0.4753) teacher/usage_min 0.2104 (0.2308) teacher/usage_std 0.1336 (0.1043) nleep/row_max_mean 1203.5359 (1205.2996) nleep/row_max_std 12.8820 (14.5096) nleep/row_min_mean 1202.3992 (1204.2484) lr 1.8763e-03 eta 0:24:42
epoch [10/50] batch [180/245] time 0.139 (0.149) data 0.000 (0.002) loss 0.9421 (0.9060) teacher_loss 0.7478 (0.7216) loss_zs_kd 0.1506 (0.1069) loss_oracle 0.0916 (0.1154) kd_loss 0.0732 (0.0732) acc 84.3750 (80.6597) gate/entropy 1.0512 (1.0523) gate/usage_max 0.4809 (0.4783) gate/usage_min 0.2429 (0.2413) gate/usage_std 0.1052 (0.1037) teacher/entropy 0.9819 (0.9801) teacher/usage_max 0.4722 (0.4730) teacher/usage_min 0.2436 (0.2326) teacher/usage_std 0.0996 (0.1026) nleep/row_max_mean 1202.3453 (1205.2151) nleep/row_max_std 14.1595 (14.4172) nleep/row_min_mean 1201.3613 (1204.1728) lr 1.8763e-03 eta 0:24:26
epoch [10/50] batch [200/245] time 0.133 (0.147) data 0.000 (0.002) loss 0.7388 (0.9057) teacher_loss 0.5695 (0.7202) loss_zs_kd 0.0932 (0.1083) loss_oracle 0.0995 (0.1148) kd_loss 0.0730 (0.0739) acc 84.3750 (80.6875) gate/entropy 1.0514 (1.0522) gate/usage_max 0.4806 (0.4785) gate/usage_min 0.2435 (0.2415) gate/usage_std 0.1050 (0.1039) teacher/entropy 0.9357 (0.9800) teacher/usage_max 0.5450 (0.4720) teacher/usage_min 0.1913 (0.2335) teacher/usage_std 0.1526 (0.1019) nleep/row_max_mean 1207.3108 (1205.0905) nleep/row_max_std 17.3051 (14.3701) nleep/row_min_mean 1206.0448 (1204.0494) lr 1.8763e-03 eta 0:24:11
epoch [10/50] batch [220/245] time 0.133 (0.146) data 0.000 (0.002) loss 0.7084 (0.8979) teacher_loss 0.4847 (0.7120) loss_zs_kd 0.1109 (0.1095) loss_oracle 0.1275 (0.1139) kd_loss 0.1045 (0.0742) acc 90.6250 (80.9659) gate/entropy 1.0528 (1.0522) gate/usage_max 0.4783 (0.4786) gate/usage_min 0.2449 (0.2417) gate/usage_std 0.1033 (0.1039) teacher/entropy 0.9974 (0.9804) teacher/usage_max 0.3927 (0.4711) teacher/usage_min 0.2703 (0.2343) teacher/usage_std 0.0500 (0.1012) nleep/row_max_mean 1209.5569 (1205.0799) nleep/row_max_std 19.1605 (14.2796) nleep/row_min_mean 1208.5397 (1204.0404) lr 1.8763e-03 eta 0:23:57
epoch [10/50] batch [240/245] time 0.137 (0.145) data 0.000 (0.001) loss 0.8649 (0.8985) teacher_loss 0.6868 (0.7114) loss_zs_kd 0.1213 (0.1106) loss_oracle 0.1047 (0.1146) kd_loss 0.0651 (0.0745) acc 87.5000 (80.9896) gate/entropy 1.0520 (1.0522) gate/usage_max 0.4798 (0.4787) gate/usage_min 0.2448 (0.2419) gate/usage_std 0.1043 (0.1039) teacher/entropy 1.0161 (0.9811) teacher/usage_max 0.4340 (0.4695) teacher/usage_min 0.2793 (0.2355) teacher/usage_std 0.0713 (0.1000) nleep/row_max_mean 1202.8809 (1204.9724) nleep/row_max_std 14.0629 (14.2415) nleep/row_min_mean 1202.0503 (1203.9372) lr 1.8763e-03 eta 0:23:44
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,038
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,211
* accuracy: 73.6%
* error: 26.4%
* macro_f1: 72.4%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.6%, epoch: 10 *******
******* Domain c best val test acc: 73.6%, epoch: 10 *******
******* Domain c best test acc:     73.6%, epoch: 10 *******
epoch [11/50] batch [20/245] time 0.137 (0.155) data 0.000 (0.016) loss 1.2016 (0.8596) teacher_loss 0.9499 (0.6567) loss_zs_kd 0.1426 (0.1195) loss_oracle 0.1500 (0.1249) kd_loss 0.1054 (0.0807) acc 81.2500 (82.6562) gate/entropy 1.0517 (1.0521) gate/usage_max 0.4804 (0.4796) gate/usage_min 0.2453 (0.2453) gate/usage_std 0.1046 (0.1042) teacher/entropy 0.9593 (0.9880) teacher/usage_max 0.4561 (0.4493) teacher/usage_min 0.2441 (0.2486) teacher/usage_std 0.0897 (0.0855) nleep/row_max_mean 1200.8840 (1203.9979) nleep/row_max_std 11.6601 (14.1291) nleep/row_min_mean 1199.7224 (1202.9971) lr 1.8443e-03 eta 0:25:11
epoch [11/50] batch [40/245] time 0.133 (0.149) data 0.000 (0.008) loss 1.0618 (0.8896) teacher_loss 0.8959 (0.6933) loss_zs_kd 0.1172 (0.1105) loss_oracle 0.0717 (0.1130) kd_loss 0.0715 (0.0846) acc 71.8750 (80.7031) gate/entropy 1.0516 (1.0521) gate/usage_max 0.4805 (0.4798) gate/usage_min 0.2452 (0.2454) gate/usage_std 0.1048 (0.1043) teacher/entropy 0.9975 (0.9817) teacher/usage_max 0.4481 (0.4527) teacher/usage_min 0.2403 (0.2434) teacher/usage_std 0.0862 (0.0891) nleep/row_max_mean 1205.2295 (1203.9426) nleep/row_max_std 10.4399 (13.7518) nleep/row_min_mean 1204.2661 (1202.9128) lr 1.8443e-03 eta 0:24:16
epoch [11/50] batch [60/245] time 0.137 (0.146) data 0.000 (0.006) loss 0.8405 (0.8564) teacher_loss 0.6952 (0.6670) loss_zs_kd 0.0725 (0.1087) loss_oracle 0.0790 (0.1028) kd_loss 0.0695 (0.0837) acc 78.1250 (81.9792) gate/entropy 1.0516 (1.0520) gate/usage_max 0.4806 (0.4799) gate/usage_min 0.2451 (0.2454) gate/usage_std 0.1048 (0.1044) teacher/entropy 0.9850 (0.9819) teacher/usage_max 0.4702 (0.4532) teacher/usage_min 0.2234 (0.2400) teacher/usage_std 0.1025 (0.0902) nleep/row_max_mean 1205.4771 (1203.8179) nleep/row_max_std 12.3071 (13.4973) nleep/row_min_mean 1204.4413 (1202.7876) lr 1.8443e-03 eta 0:23:39
epoch [11/50] batch [80/245] time 0.145 (0.144) data 0.000 (0.004) loss 1.1199 (0.8758) teacher_loss 0.8889 (0.6863) loss_zs_kd 0.1336 (0.1093) loss_oracle 0.1229 (0.1011) kd_loss 0.1027 (0.0843) acc 78.1250 (81.2500) gate/entropy 1.0517 (1.0519) gate/usage_max 0.4804 (0.4800) gate/usage_min 0.2446 (0.2453) gate/usage_std 0.1047 (0.1044) teacher/entropy 0.9659 (0.9810) teacher/usage_max 0.4427 (0.4532) teacher/usage_min 0.2131 (0.2378) teacher/usage_std 0.0940 (0.0908) nleep/row_max_mean 1203.0183 (1203.7176) nleep/row_max_std 15.7929 (13.4244) nleep/row_min_mean 1201.9435 (1202.6834) lr 1.8443e-03 eta 0:23:18
epoch [11/50] batch [100/245] time 0.135 (0.143) data 0.000 (0.003) loss 1.0897 (0.8780) teacher_loss 0.9566 (0.6875) loss_zs_kd 0.0975 (0.1105) loss_oracle 0.0578 (0.0996) kd_loss 0.0555 (0.0853) acc 68.7500 (81.3750) gate/entropy 1.0517 (1.0519) gate/usage_max 0.4802 (0.4800) gate/usage_min 0.2443 (0.2452) gate/usage_std 0.1046 (0.1044) teacher/entropy 1.0318 (0.9825) teacher/usage_max 0.4149 (0.4488) teacher/usage_min 0.2429 (0.2383) teacher/usage_std 0.0705 (0.0886) nleep/row_max_mean 1200.7438 (1203.4087) nleep/row_max_std 12.7096 (13.4889) nleep/row_min_mean 1199.9073 (1202.3785) lr 1.8443e-03 eta 0:23:05
epoch [11/50] batch [120/245] time 0.132 (0.142) data 0.000 (0.003) loss 0.9205 (0.8648) teacher_loss 0.7350 (0.6763) loss_zs_kd 0.0978 (0.1100) loss_oracle 0.0907 (0.0977) kd_loss 0.0913 (0.0847) acc 71.8750 (81.5625) gate/entropy 1.0529 (1.0520) gate/usage_max 0.4782 (0.4798) gate/usage_min 0.2449 (0.2451) gate/usage_std 0.1033 (0.1043) teacher/entropy 0.9705 (0.9843) teacher/usage_max 0.4576 (0.4467) teacher/usage_min 0.2267 (0.2389) teacher/usage_std 0.0951 (0.0872) nleep/row_max_mean 1202.2285 (1203.3489) nleep/row_max_std 12.5761 (13.4771) nleep/row_min_mean 1201.1106 (1202.3236) lr 1.8443e-03 eta 0:22:57
epoch [11/50] batch [140/245] time 0.136 (0.142) data 0.000 (0.002) loss 0.6455 (0.8750) teacher_loss 0.4689 (0.6870) loss_zs_kd 0.0852 (0.1095) loss_oracle 0.0909 (0.0975) kd_loss 0.0886 (0.0844) acc 81.2500 (81.2723) gate/entropy 1.0537 (1.0522) gate/usage_max 0.4768 (0.4795) gate/usage_min 0.2452 (0.2450) gate/usage_std 0.1023 (0.1041) teacher/entropy 0.9975 (0.9850) teacher/usage_max 0.4162 (0.4459) teacher/usage_min 0.2472 (0.2390) teacher/usage_std 0.0690 (0.0867) nleep/row_max_mean 1204.9346 (1203.3798) nleep/row_max_std 13.8194 (13.4672) nleep/row_min_mean 1203.9362 (1202.3589) lr 1.8443e-03 eta 0:22:49
epoch [11/50] batch [160/245] time 0.132 (0.141) data 0.000 (0.002) loss 0.9291 (0.8886) teacher_loss 0.7698 (0.6984) loss_zs_kd 0.1085 (0.1116) loss_oracle 0.1123 (0.0996) kd_loss 0.0490 (0.0845) acc 75.0000 (81.0156) gate/entropy 1.0531 (1.0523) gate/usage_max 0.4777 (0.4793) gate/usage_min 0.2447 (0.2450) gate/usage_std 0.1030 (0.1040) teacher/entropy 0.9828 (0.9839) teacher/usage_max 0.5132 (0.4475) teacher/usage_min 0.2324 (0.2389) teacher/usage_std 0.1275 (0.0876) nleep/row_max_mean 1203.2588 (1203.2768) nleep/row_max_std 12.4472 (13.3592) nleep/row_min_mean 1202.2314 (1202.2509) lr 1.8443e-03 eta 0:22:40
epoch [11/50] batch [180/245] time 0.122 (0.140) data 0.000 (0.002) loss 1.0419 (0.8909) teacher_loss 0.8243 (0.6999) loss_zs_kd 0.0852 (0.1106) loss_oracle 0.1186 (0.1018) kd_loss 0.1158 (0.0848) acc 75.0000 (81.0417) gate/entropy 1.0529 (1.0524) gate/usage_max 0.4781 (0.4791) gate/usage_min 0.2449 (0.2449) gate/usage_std 0.1032 (0.1039) teacher/entropy 0.9712 (0.9846) teacher/usage_max 0.4139 (0.4461) teacher/usage_min 0.2455 (0.2404) teacher/usage_std 0.0690 (0.0864) nleep/row_max_mean 1203.4077 (1203.2955) nleep/row_max_std 11.7314 (13.3474) nleep/row_min_mean 1202.3079 (1202.2720) lr 1.8443e-03 eta 0:22:30
epoch [11/50] batch [200/245] time 0.133 (0.140) data 0.000 (0.002) loss 0.7111 (0.8880) teacher_loss 0.5355 (0.6959) loss_zs_kd 0.0787 (0.1098) loss_oracle 0.1126 (0.1036) kd_loss 0.0799 (0.0854) acc 87.5000 (81.2188) gate/entropy 1.0521 (1.0524) gate/usage_max 0.4796 (0.4791) gate/usage_min 0.2447 (0.2449) gate/usage_std 0.1042 (0.1039) teacher/entropy 1.0012 (0.9843) teacher/usage_max 0.4307 (0.4459) teacher/usage_min 0.2664 (0.2419) teacher/usage_std 0.0705 (0.0859) nleep/row_max_mean 1201.4443 (1203.2809) nleep/row_max_std 13.0891 (13.2852) nleep/row_min_mean 1200.5098 (1202.2564) lr 1.8443e-03 eta 0:22:24
epoch [11/50] batch [220/245] time 0.133 (0.140) data 0.000 (0.002) loss 0.6805 (0.8885) teacher_loss 0.4799 (0.6952) loss_zs_kd 0.1111 (0.1090) loss_oracle 0.1162 (0.1049) kd_loss 0.0870 (0.0863) acc 84.3750 (81.1080) gate/entropy 1.0519 (1.0524) gate/usage_max 0.4800 (0.4791) gate/usage_min 0.2449 (0.2449) gate/usage_std 0.1044 (0.1039) teacher/entropy 1.0120 (0.9841) teacher/usage_max 0.4021 (0.4448) teacher/usage_min 0.2824 (0.2430) teacher/usage_std 0.0505 (0.0851) nleep/row_max_mean 1204.3121 (1203.3084) nleep/row_max_std 13.5393 (13.2394) nleep/row_min_mean 1203.3826 (1202.2842) lr 1.8443e-03 eta 0:22:17
epoch [11/50] batch [240/245] time 0.136 (0.139) data 0.000 (0.001) loss 0.5388 (0.8899) teacher_loss 0.3985 (0.6977) loss_zs_kd 0.0458 (0.1081) loss_oracle 0.0758 (0.1039) kd_loss 0.0795 (0.0862) acc 90.6250 (81.1458) gate/entropy 1.0524 (1.0524) gate/usage_max 0.4793 (0.4792) gate/usage_min 0.2457 (0.2450) gate/usage_std 0.1039 (0.1039) teacher/entropy 0.9741 (0.9848) teacher/usage_max 0.4758 (0.4440) teacher/usage_min 0.2471 (0.2440) teacher/usage_std 0.1015 (0.0845) nleep/row_max_mean 1205.1931 (1203.3359) nleep/row_max_std 11.0188 (13.1790) nleep/row_min_mean 1204.1129 (1202.3140) lr 1.8443e-03 eta 0:22:12
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,035
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,186
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.7%
******* Domain c best val acc:      90.6%, epoch: 10 *******
******* Domain c best val test acc: 73.6%, epoch: 10 *******
******* Domain c best test acc:     73.6%, epoch: 10 *******
epoch [12/50] batch [20/245] time 0.105 (0.145) data 0.000 (0.016) loss 1.1823 (0.9317) teacher_loss 0.9807 (0.7543) loss_zs_kd 0.0964 (0.0954) loss_oracle 0.1219 (0.0884) kd_loss 0.0924 (0.0856) acc 75.0000 (80.0000) gate/entropy 1.0526 (1.0525) gate/usage_max 0.4789 (0.4790) gate/usage_min 0.2457 (0.2458) gate/usage_std 0.1036 (0.1037) teacher/entropy 0.9935 (0.9885) teacher/usage_max 0.4271 (0.4407) teacher/usage_min 0.2806 (0.2543) teacher/usage_std 0.0665 (0.0801) nleep/row_max_mean 1207.2047 (1204.8894) nleep/row_max_std 12.0800 (11.9887) nleep/row_min_mean 1206.2128 (1203.8970) lr 1.8090e-03 eta 0:23:05
epoch [12/50] batch [40/245] time 0.299 (0.149) data 0.000 (0.008) loss 0.9606 (0.9163) teacher_loss 0.7949 (0.7300) loss_zs_kd 0.1403 (0.1081) loss_oracle 0.0711 (0.0918) kd_loss 0.0599 (0.0864) acc 87.5000 (80.8594) gate/entropy 1.0523 (1.0527) gate/usage_max 0.4795 (0.4788) gate/usage_min 0.2460 (0.2461) gate/usage_std 0.1040 (0.1036) teacher/entropy 1.0000 (0.9830) teacher/usage_max 0.4604 (0.4486) teacher/usage_min 0.2241 (0.2518) teacher/usage_std 0.0973 (0.0852) nleep/row_max_mean 1203.3579 (1204.0996) nleep/row_max_std 10.7249 (12.3205) nleep/row_min_mean 1202.4362 (1203.0833) lr 1.8090e-03 eta 0:23:33
epoch [12/50] batch [60/245] time 0.366 (0.155) data 0.000 (0.005) loss 0.7856 (0.9098) teacher_loss 0.6009 (0.7200) loss_zs_kd 0.0815 (0.1061) loss_oracle 0.1355 (0.0997) kd_loss 0.0762 (0.0869) acc 84.3750 (81.0417) gate/entropy 1.0527 (1.0527) gate/usage_max 0.4788 (0.4788) gate/usage_min 0.2468 (0.2463) gate/usage_std 0.1035 (0.1035) teacher/entropy 0.9925 (0.9812) teacher/usage_max 0.4490 (0.4506) teacher/usage_min 0.2498 (0.2502) teacher/usage_std 0.0844 (0.0867) nleep/row_max_mean 1204.2819 (1204.2375) nleep/row_max_std 11.9899 (12.3984) nleep/row_min_mean 1203.2592 (1203.2086) lr 1.8090e-03 eta 0:24:28
epoch [12/50] batch [80/245] time 0.149 (0.148) data 0.000 (0.004) loss 1.1206 (0.9266) teacher_loss 0.9152 (0.7295) loss_zs_kd 0.1352 (0.1113) loss_oracle 0.1172 (0.1098) kd_loss 0.0792 (0.0865) acc 68.7500 (80.7031) gate/entropy 1.0513 (1.0525) gate/usage_max 0.4813 (0.4791) gate/usage_min 0.2461 (0.2463) gate/usage_std 0.1052 (0.1037) teacher/entropy 1.0012 (0.9812) teacher/usage_max 0.4306 (0.4515) teacher/usage_min 0.2559 (0.2497) teacher/usage_std 0.0727 (0.0872) nleep/row_max_mean 1205.4363 (1204.2511) nleep/row_max_std 13.5916 (12.4391) nleep/row_min_mean 1204.4429 (1203.2202) lr 1.8090e-03 eta 0:23:20
epoch [12/50] batch [100/245] time 0.137 (0.147) data 0.000 (0.003) loss 1.1515 (0.9274) teacher_loss 0.9456 (0.7265) loss_zs_kd 0.1093 (0.1137) loss_oracle 0.1276 (0.1139) kd_loss 0.0875 (0.0871) acc 68.7500 (80.7188) gate/entropy 1.0509 (1.0523) gate/usage_max 0.4822 (0.4795) gate/usage_min 0.2467 (0.2463) gate/usage_std 0.1057 (0.1040) teacher/entropy 0.9781 (0.9833) teacher/usage_max 0.4557 (0.4471) teacher/usage_min 0.2477 (0.2512) teacher/usage_std 0.0888 (0.0845) nleep/row_max_mean 1203.3762 (1204.2784) nleep/row_max_std 14.3299 (12.5364) nleep/row_min_mean 1202.3392 (1203.2554) lr 1.8090e-03 eta 0:23:07
epoch [12/50] batch [120/245] time 0.138 (0.145) data 0.000 (0.003) loss 0.7252 (0.9248) teacher_loss 0.5249 (0.7227) loss_zs_kd 0.0914 (0.1143) loss_oracle 0.1050 (0.1118) kd_loss 0.1021 (0.0891) acc 87.5000 (80.6771) gate/entropy 1.0521 (1.0522) gate/usage_max 0.4802 (0.4797) gate/usage_min 0.2477 (0.2465) gate/usage_std 0.1043 (0.1041) teacher/entropy 0.9838 (0.9841) teacher/usage_max 0.4204 (0.4424) teacher/usage_min 0.2483 (0.2527) teacher/usage_std 0.0703 (0.0816) nleep/row_max_mean 1204.9094 (1204.4189) nleep/row_max_std 13.9794 (12.7203) nleep/row_min_mean 1203.8352 (1203.3941) lr 1.8090e-03 eta 0:22:51
epoch [12/50] batch [140/245] time 0.133 (0.145) data 0.000 (0.002) loss 1.2729 (0.9209) teacher_loss 1.1298 (0.7210) loss_zs_kd 0.0655 (0.1136) loss_oracle 0.0746 (0.1087) kd_loss 0.0731 (0.0888) acc 75.0000 (80.6473) gate/entropy 1.0522 (1.0522) gate/usage_max 0.4800 (0.4797) gate/usage_min 0.2479 (0.2467) gate/usage_std 0.1042 (0.1041) teacher/entropy 1.0061 (0.9850) teacher/usage_max 0.4359 (0.4415) teacher/usage_min 0.2721 (0.2533) teacher/usage_std 0.0730 (0.0808) nleep/row_max_mean 1205.2264 (1204.4314) nleep/row_max_std 12.0405 (12.6945) nleep/row_min_mean 1204.3289 (1203.4106) lr 1.8090e-03 eta 0:22:40
epoch [12/50] batch [160/245] time 0.142 (0.144) data 0.000 (0.002) loss 0.6314 (0.9139) teacher_loss 0.4786 (0.7156) loss_zs_kd 0.0840 (0.1123) loss_oracle 0.0946 (0.1072) kd_loss 0.0635 (0.0885) acc 87.5000 (80.8789) gate/entropy 1.0530 (1.0523) gate/usage_max 0.4785 (0.4797) gate/usage_min 0.2481 (0.2468) gate/usage_std 0.1032 (0.1040) teacher/entropy 0.9849 (0.9852) teacher/usage_max 0.4835 (0.4415) teacher/usage_min 0.2373 (0.2525) teacher/usage_std 0.1076 (0.0810) nleep/row_max_mean 1201.9353 (1204.3649) nleep/row_max_std 11.0933 (12.6825) nleep/row_min_mean 1200.9751 (1203.3447) lr 1.8090e-03 eta 0:22:31
epoch [12/50] batch [180/245] time 0.157 (0.144) data 0.000 (0.002) loss 0.6739 (0.9169) teacher_loss 0.5114 (0.7193) loss_zs_kd 0.0907 (0.1121) loss_oracle 0.0762 (0.1057) kd_loss 0.0791 (0.0886) acc 87.5000 (80.7639) gate/entropy 1.0537 (1.0524) gate/usage_max 0.4774 (0.4796) gate/usage_min 0.2485 (0.2470) gate/usage_std 0.1024 (0.1040) teacher/entropy 0.9789 (0.9856) teacher/usage_max 0.4686 (0.4406) teacher/usage_min 0.2496 (0.2522) teacher/usage_std 0.0965 (0.0806) nleep/row_max_mean 1203.6561 (1204.2702) nleep/row_max_std 12.8925 (12.6736) nleep/row_min_mean 1202.6753 (1203.2510) lr 1.8090e-03 eta 0:22:28
epoch [12/50] batch [200/245] time 0.135 (0.145) data 0.000 (0.002) loss 1.0737 (0.9197) teacher_loss 0.8745 (0.7219) loss_zs_kd 0.1272 (0.1127) loss_oracle 0.0984 (0.1047) kd_loss 0.0864 (0.0891) acc 78.1250 (80.5469) gate/entropy 1.0545 (1.0525) gate/usage_max 0.4760 (0.4794) gate/usage_min 0.2491 (0.2471) gate/usage_std 0.1015 (0.1038) teacher/entropy 1.0021 (0.9851) teacher/usage_max 0.4143 (0.4405) teacher/usage_min 0.2606 (0.2522) teacher/usage_std 0.0630 (0.0806) nleep/row_max_mean 1201.7261 (1204.2149) nleep/row_max_std 12.8891 (12.6913) nleep/row_min_mean 1200.7864 (1203.1956) lr 1.8090e-03 eta 0:22:35
epoch [12/50] batch [220/245] time 0.143 (0.145) data 0.000 (0.002) loss 0.8556 (0.9221) teacher_loss 0.6137 (0.7240) loss_zs_kd 0.1425 (0.1135) loss_oracle 0.1075 (0.1043) kd_loss 0.1169 (0.0892) acc 84.3750 (80.4830) gate/entropy 1.0554 (1.0527) gate/usage_max 0.4746 (0.4790) gate/usage_min 0.2496 (0.2473) gate/usage_std 0.1005 (0.1036) teacher/entropy 0.9727 (0.9856) teacher/usage_max 0.4156 (0.4394) teacher/usage_min 0.2832 (0.2528) teacher/usage_std 0.0586 (0.0798) nleep/row_max_mean 1201.1011 (1204.1451) nleep/row_max_std 15.1029 (12.7733) nleep/row_min_mean 1200.1067 (1203.1280) lr 1.8090e-03 eta 0:22:30
epoch [12/50] batch [240/245] time 0.133 (0.144) data 0.000 (0.001) loss 0.8963 (0.9194) teacher_loss 0.7291 (0.7206) loss_zs_kd 0.1027 (0.1141) loss_oracle 0.0756 (0.1049) kd_loss 0.0780 (0.0893) acc 84.3750 (80.6250) gate/entropy 1.0556 (1.0529) gate/usage_max 0.4742 (0.4786) gate/usage_min 0.2501 (0.2475) gate/usage_std 0.1001 (0.1033) teacher/entropy 1.0084 (0.9847) teacher/usage_max 0.4213 (0.4406) teacher/usage_min 0.2766 (0.2522) teacher/usage_std 0.0630 (0.0806) nleep/row_max_mean 1202.6799 (1204.0456) nleep/row_max_std 13.8182 (12.8409) nleep/row_min_mean 1201.8040 (1203.0254) lr 1.8090e-03 eta 0:22:25
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,036
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,206
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 72.0%
******* Domain c best val acc:      90.6%, epoch: 10 *******
******* Domain c best val test acc: 73.6%, epoch: 10 *******
******* Domain c best test acc:     73.6%, epoch: 10 *******
epoch [13/50] batch [20/245] time 0.130 (0.155) data 0.000 (0.014) loss 1.0779 (1.0062) teacher_loss 0.8041 (0.7984) loss_zs_kd 0.1661 (0.1186) loss_oracle 0.1528 (0.1127) kd_loss 0.1144 (0.0922) acc 78.1250 (77.8125) gate/entropy 1.0552 (1.0554) gate/usage_max 0.4749 (0.4746) gate/usage_min 0.2498 (0.2499) gate/usage_std 0.1006 (0.1004) teacher/entropy 0.9339 (0.9714) teacher/usage_max 0.4857 (0.4578) teacher/usage_min 0.2485 (0.2466) teacher/usage_std 0.1080 (0.0910) nleep/row_max_mean 1196.7738 (1202.8262) nleep/row_max_std 14.2728 (13.8798) nleep/row_min_mean 1195.6409 (1201.7518) lr 1.7705e-03 eta 0:24:02
epoch [13/50] batch [40/245] time 0.134 (0.146) data 0.000 (0.007) loss 0.7768 (0.9642) teacher_loss 0.5718 (0.7587) loss_zs_kd 0.1105 (0.1170) loss_oracle 0.1132 (0.1156) kd_loss 0.0931 (0.0892) acc 93.7500 (79.4531) gate/entropy 1.0551 (1.0554) gate/usage_max 0.4753 (0.4747) gate/usage_min 0.2503 (0.2500) gate/usage_std 0.1009 (0.1005) teacher/entropy 0.9955 (0.9731) teacher/usage_max 0.4154 (0.4599) teacher/usage_min 0.2678 (0.2457) teacher/usage_std 0.0614 (0.0923) nleep/row_max_mean 1200.7063 (1203.0754) nleep/row_max_std 13.1608 (13.3743) nleep/row_min_mean 1199.7383 (1202.0150) lr 1.7705e-03 eta 0:22:34
epoch [13/50] batch [60/245] time 0.136 (0.143) data 0.000 (0.005) loss 1.1311 (0.9447) teacher_loss 0.9226 (0.7395) loss_zs_kd 0.1330 (0.1182) loss_oracle 0.1172 (0.1134) kd_loss 0.0834 (0.0894) acc 71.8750 (80.1042) gate/entropy 1.0550 (1.0552) gate/usage_max 0.4755 (0.4750) gate/usage_min 0.2504 (0.2501) gate/usage_std 0.1010 (0.1007) teacher/entropy 1.0080 (0.9736) teacher/usage_max 0.4103 (0.4587) teacher/usage_min 0.2684 (0.2460) teacher/usage_std 0.0586 (0.0917) nleep/row_max_mean 1201.2231 (1203.2398) nleep/row_max_std 12.3637 (13.2091) nleep/row_min_mean 1200.3684 (1202.1766) lr 1.7705e-03 eta 0:21:59
epoch [13/50] batch [80/245] time 0.131 (0.141) data 0.000 (0.004) loss 1.0798 (0.9364) teacher_loss 0.8675 (0.7319) loss_zs_kd 0.1035 (0.1171) loss_oracle 0.1448 (0.1129) kd_loss 0.0882 (0.0895) acc 81.2500 (80.4688) gate/entropy 1.0540 (1.0550) gate/usage_max 0.4770 (0.4752) gate/usage_min 0.2491 (0.2500) gate/usage_std 0.1021 (0.1009) teacher/entropy 0.9765 (0.9724) teacher/usage_max 0.4518 (0.4605) teacher/usage_min 0.2287 (0.2449) teacher/usage_std 0.0916 (0.0930) nleep/row_max_mean 1206.8596 (1203.4703) nleep/row_max_std 14.2368 (13.3198) nleep/row_min_mean 1205.7544 (1202.3946) lr 1.7705e-03 eta 0:21:38
epoch [13/50] batch [100/245] time 0.140 (0.140) data 0.000 (0.003) loss 0.7059 (0.9292) teacher_loss 0.5102 (0.7238) loss_zs_kd 0.0823 (0.1162) loss_oracle 0.1324 (0.1154) kd_loss 0.0883 (0.0896) acc 81.2500 (80.6875) gate/entropy 1.0532 (1.0548) gate/usage_max 0.4783 (0.4757) gate/usage_min 0.2485 (0.2498) gate/usage_std 0.1030 (0.1012) teacher/entropy 0.9548 (0.9721) teacher/usage_max 0.4941 (0.4609) teacher/usage_min 0.2428 (0.2443) teacher/usage_std 0.1140 (0.0934) nleep/row_max_mean 1207.5337 (1203.6232) nleep/row_max_std 11.6210 (13.1990) nleep/row_min_mean 1206.3870 (1202.5470) lr 1.7705e-03 eta 0:21:29
epoch [13/50] batch [120/245] time 0.147 (0.141) data 0.000 (0.002) loss 0.7433 (0.9206) teacher_loss 0.5122 (0.7146) loss_zs_kd 0.1292 (0.1165) loss_oracle 0.1248 (0.1152) kd_loss 0.1041 (0.0901) acc 81.2500 (80.8594) gate/entropy 1.0523 (1.0544) gate/usage_max 0.4798 (0.4763) gate/usage_min 0.2478 (0.2495) gate/usage_std 0.1041 (0.1016) teacher/entropy 0.9347 (0.9719) teacher/usage_max 0.4984 (0.4604) teacher/usage_min 0.2235 (0.2451) teacher/usage_std 0.1188 (0.0930) nleep/row_max_mean 1204.8635 (1203.5728) nleep/row_max_std 15.6359 (13.1134) nleep/row_min_mean 1203.7168 (1202.4980) lr 1.7705e-03 eta 0:21:33
epoch [13/50] batch [140/245] time 0.151 (0.142) data 0.000 (0.002) loss 1.1163 (0.9167) teacher_loss 0.9099 (0.7111) loss_zs_kd 0.1284 (0.1160) loss_oracle 0.0998 (0.1141) kd_loss 0.0923 (0.0905) acc 71.8750 (80.7812) gate/entropy 1.0524 (1.0542) gate/usage_max 0.4796 (0.4767) gate/usage_min 0.2481 (0.2493) gate/usage_std 0.1039 (0.1019) teacher/entropy 0.9876 (0.9720) teacher/usage_max 0.4344 (0.4598) teacher/usage_min 0.2776 (0.2463) teacher/usage_std 0.0716 (0.0924) nleep/row_max_mean 1205.0049 (1203.5873) nleep/row_max_std 11.2579 (12.9667) nleep/row_min_mean 1204.0460 (1202.5143) lr 1.7705e-03 eta 0:21:41
epoch [13/50] batch [160/245] time 0.092 (0.142) data 0.000 (0.002) loss 1.1083 (0.9210) teacher_loss 0.7602 (0.7141) loss_zs_kd 0.1298 (0.1161) loss_oracle 0.2103 (0.1159) kd_loss 0.1781 (0.0909) acc 84.3750 (80.6641) gate/entropy 1.0529 (1.0540) gate/usage_max 0.4790 (0.4770) gate/usage_min 0.2491 (0.2492) gate/usage_std 0.1034 (0.1021) teacher/entropy 0.8927 (0.9721) teacher/usage_max 0.4442 (0.4594) teacher/usage_min 0.2349 (0.2476) teacher/usage_std 0.0859 (0.0918) nleep/row_max_mean 1203.4110 (1203.6567) nleep/row_max_std 12.3734 (12.9894) nleep/row_min_mean 1201.9661 (1202.5839) lr 1.7705e-03 eta 0:21:35
epoch [13/50] batch [180/245] time 0.337 (0.140) data 0.000 (0.002) loss 1.3286 (0.9260) teacher_loss 1.0864 (0.7189) loss_zs_kd 0.1523 (0.1160) loss_oracle 0.1692 (0.1170) kd_loss 0.0815 (0.0905) acc 75.0000 (80.5382) gate/entropy 1.0531 (1.0538) gate/usage_max 0.4787 (0.4773) gate/usage_min 0.2498 (0.2492) gate/usage_std 0.1032 (0.1023) teacher/entropy 1.0047 (0.9716) teacher/usage_max 0.4231 (0.4607) teacher/usage_min 0.2777 (0.2466) teacher/usage_std 0.0641 (0.0928) nleep/row_max_mean 1203.2241 (1203.5684) nleep/row_max_std 13.9413 (12.9432) nleep/row_min_mean 1202.2742 (1202.4934) lr 1.7705e-03 eta 0:21:14
epoch [13/50] batch [200/245] time 0.327 (0.140) data 0.000 (0.002) loss 0.8597 (0.9205) teacher_loss 0.6226 (0.7132) loss_zs_kd 0.1127 (0.1152) loss_oracle 0.1241 (0.1183) kd_loss 0.1187 (0.0905) acc 87.5000 (80.7344) gate/entropy 1.0537 (1.0538) gate/usage_max 0.4779 (0.4774) gate/usage_min 0.2510 (0.2493) gate/usage_std 0.1025 (0.1023) teacher/entropy 0.9726 (0.9717) teacher/usage_max 0.4111 (0.4607) teacher/usage_min 0.2630 (0.2470) teacher/usage_std 0.0607 (0.0928) nleep/row_max_mean 1204.6008 (1203.5230) nleep/row_max_std 13.3804 (12.9180) nleep/row_min_mean 1203.4871 (1202.4478) lr 1.7705e-03 eta 0:21:19
epoch [13/50] batch [220/245] time 0.144 (0.141) data 0.000 (0.001) loss 0.9832 (0.9225) teacher_loss 0.7719 (0.7151) loss_zs_kd 0.1100 (0.1145) loss_oracle 0.1094 (0.1176) kd_loss 0.1017 (0.0913) acc 75.0000 (80.6108) gate/entropy 1.0549 (1.0538) gate/usage_max 0.4760 (0.4773) gate/usage_min 0.2525 (0.2496) gate/usage_std 0.1012 (0.1023) teacher/entropy 0.9637 (0.9706) teacher/usage_max 0.4557 (0.4612) teacher/usage_min 0.2503 (0.2472) teacher/usage_std 0.0884 (0.0930) nleep/row_max_mean 1204.4174 (1203.4711) nleep/row_max_std 13.9367 (12.9096) nleep/row_min_mean 1203.3894 (1202.3914) lr 1.7705e-03 eta 0:21:19
epoch [13/50] batch [240/245] time 0.087 (0.141) data 0.000 (0.001) loss 1.1756 (0.9208) teacher_loss 0.9736 (0.7135) loss_zs_kd 0.1229 (0.1136) loss_oracle 0.0973 (0.1177) kd_loss 0.0919 (0.0916) acc 68.7500 (80.6901) gate/entropy 1.0544 (1.0539) gate/usage_max 0.4768 (0.4773) gate/usage_min 0.2525 (0.2498) gate/usage_std 0.1017 (0.1022) teacher/entropy 0.9944 (0.9694) teacher/usage_max 0.4181 (0.4626) teacher/usage_min 0.2384 (0.2460) teacher/usage_std 0.0737 (0.0941) nleep/row_max_mean 1203.9064 (1203.4937) nleep/row_max_std 12.2371 (12.8557) nleep/row_min_mean 1202.8887 (1202.4079) lr 1.7705e-03 eta 0:21:16
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,039
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/tuning/20_ema_teacherupdate_for_office/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,205
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 72.2%
******* Domain c best val acc:      90.6%, epoch: 13 *******
******* Domain c best val test acc: 73.4%, epoch: 13 *******
******* Domain c best test acc:     73.6%, epoch: 10 *******
epoch [14/50] batch [20/245] time 0.137 (0.163) data 0.000 (0.013) loss 0.9865 (0.9321) teacher_loss 0.7479 (0.7082) loss_zs_kd 0.1101 (0.1193) loss_oracle 0.1506 (0.1291) kd_loss 0.1082 (0.0998) acc 81.2500 (80.9375) gate/entropy 1.0532 (1.0537) gate/usage_max 0.4788 (0.4781) gate/usage_min 0.2520 (0.2523) gate/usage_std 0.1031 (0.1026) teacher/entropy 0.9080 (0.9505) teacher/usage_max 0.5345 (0.4799) teacher/usage_min 0.2027 (0.2312) teacher/usage_std 0.1443 (0.1075) nleep/row_max_mean 1199.8630 (1202.7167) nleep/row_max_std 12.5518 (12.5086) nleep/row_min_mean 1198.5549 (1201.5463) lr 1.7290e-03 eta 0:24:33

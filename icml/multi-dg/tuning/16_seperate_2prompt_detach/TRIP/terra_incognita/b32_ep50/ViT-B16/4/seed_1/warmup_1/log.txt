Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_38', 'location_43']
Target     ['location_46']
# classes  10
# train_x  12,912
# val      5,535
# test     5,883
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  256
gate.mlp.2.bias                                    2
Total trainable params: 70,019
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/403] time 0.073 (0.122) data 0.000 (0.032) loss 3.2104 (2.7790) teacher_loss 2.5811 (2.2112) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.0075 (0.0029) acc 12.5000 (33.7500) lr 1.0000e-05 eta 0:40:54
epoch [1/50] batch [40/403] time 0.072 (0.098) data 0.000 (0.016) loss 2.6848 (2.8195) teacher_loss 2.1311 (2.2512) loss_zs_kd 0.0065 (0.0014) loss_oracle 0.0058 (0.0078) acc 28.1250 (31.0938) lr 1.0000e-05 eta 0:32:49
epoch [1/50] batch [60/403] time 0.082 (0.090) data 0.000 (0.011) loss 2.8331 (2.7789) teacher_loss 2.2903 (2.2062) loss_zs_kd 0.0210 (0.0047) loss_oracle 0.0030 (0.0070) acc 25.0000 (32.3438) lr 1.0000e-05 eta 0:30:13
epoch [1/50] batch [80/403] time 0.068 (0.084) data 0.000 (0.008) loss 2.6927 (2.7505) teacher_loss 2.1247 (2.1745) loss_zs_kd 0.0545 (0.0119) loss_oracle 0.0605 (0.0085) acc 31.2500 (32.8516) lr 1.0000e-05 eta 0:28:08
epoch [1/50] batch [100/403] time 0.073 (0.082) data 0.000 (0.007) loss 3.1929 (2.7387) teacher_loss 2.3590 (2.1291) loss_zs_kd 0.1340 (0.0282) loss_oracle 0.5081 (0.0696) acc 31.2500 (34.0938) lr 1.0000e-05 eta 0:27:18
epoch [1/50] batch [120/403] time 0.066 (0.080) data 0.000 (0.006) loss 2.0823 (2.7322) teacher_loss 1.2897 (2.0843) loss_zs_kd 0.3072 (0.0802) loss_oracle 0.3227 (0.1433) acc 53.1250 (35.1302) lr 1.0000e-05 eta 0:26:43
epoch [1/50] batch [140/403] time 0.078 (0.079) data 0.000 (0.005) loss 2.8281 (2.7074) teacher_loss 1.8822 (2.0317) loss_zs_kd 0.5786 (0.1382) loss_oracle 0.6228 (0.1909) acc 43.7500 (36.1830) lr 1.0000e-05 eta 0:26:14
epoch [1/50] batch [160/403] time 0.064 (0.077) data 0.000 (0.004) loss 2.8260 (2.6914) teacher_loss 1.8870 (1.9921) loss_zs_kd 0.5754 (0.1905) loss_oracle 0.6563 (0.2324) acc 25.0000 (36.6992) lr 1.0000e-05 eta 0:25:34
epoch [1/50] batch [180/403] time 0.073 (0.076) data 0.000 (0.004) loss 2.6591 (2.6793) teacher_loss 1.7211 (1.9556) loss_zs_kd 0.4447 (0.2244) loss_oracle 0.5898 (0.2748) acc 43.7500 (37.4653) lr 1.0000e-05 eta 0:25:17
epoch [1/50] batch [200/403] time 0.073 (0.076) data 0.000 (0.003) loss 2.7287 (2.6686) teacher_loss 1.8842 (1.9326) loss_zs_kd 0.6332 (0.2520) loss_oracle 0.4617 (0.2979) acc 43.7500 (38.0938) lr 1.0000e-05 eta 0:25:11
epoch [1/50] batch [220/403] time 0.086 (0.076) data 0.000 (0.003) loss 2.2667 (2.6502) teacher_loss 1.4798 (1.9027) loss_zs_kd 0.6979 (0.2788) loss_oracle 0.4027 (0.3168) acc 53.1250 (38.6932) lr 1.0000e-05 eta 0:25:09
epoch [1/50] batch [240/403] time 0.075 (0.076) data 0.000 (0.003) loss 2.0678 (2.6390) teacher_loss 1.2810 (1.8826) loss_zs_kd 0.5175 (0.3013) loss_oracle 0.4418 (0.3309) acc 46.8750 (39.2188) lr 1.0000e-05 eta 0:25:04
epoch [1/50] batch [260/403] time 0.071 (0.075) data 0.000 (0.003) loss 2.4362 (2.6275) teacher_loss 1.5530 (1.8649) loss_zs_kd 0.5029 (0.3145) loss_oracle 0.4596 (0.3404) acc 50.0000 (39.5673) lr 1.0000e-05 eta 0:24:58
epoch [1/50] batch [280/403] time 0.075 (0.075) data 0.000 (0.003) loss 2.4511 (2.6184) teacher_loss 1.5021 (1.8408) loss_zs_kd 0.5579 (0.3357) loss_oracle 0.5488 (0.3628) acc 37.5000 (40.0781) lr 1.0000e-05 eta 0:24:51
epoch [1/50] batch [300/403] time 0.073 (0.075) data 0.000 (0.002) loss 2.6350 (2.6081) teacher_loss 1.6430 (1.8195) loss_zs_kd 0.8772 (0.3564) loss_oracle 0.6213 (0.3780) acc 34.3750 (40.5729) lr 1.0000e-05 eta 0:24:47
epoch [1/50] batch [320/403] time 0.071 (0.075) data 0.000 (0.002) loss 2.4753 (2.6019) teacher_loss 1.4807 (1.8013) loss_zs_kd 0.7518 (0.3913) loss_oracle 0.6811 (0.3948) acc 53.1250 (41.0547) lr 1.0000e-05 eta 0:24:39
epoch [1/50] batch [340/403] time 0.070 (0.074) data 0.000 (0.002) loss 2.4581 (2.5974) teacher_loss 1.5465 (1.7871) loss_zs_kd 0.5278 (0.4077) loss_oracle 0.5966 (0.4092) acc 50.0000 (41.4246) lr 1.0000e-05 eta 0:24:32
epoch [1/50] batch [360/403] time 0.071 (0.074) data 0.000 (0.002) loss 2.8842 (2.5932) teacher_loss 1.8677 (1.7754) loss_zs_kd 0.9837 (0.4185) loss_oracle 0.6863 (0.4220) acc 25.0000 (41.6927) lr 1.0000e-05 eta 0:24:27
epoch [1/50] batch [380/403] time 0.080 (0.075) data 0.000 (0.002) loss 2.4799 (2.5924) teacher_loss 1.5706 (1.7674) loss_zs_kd 0.6086 (0.4350) loss_oracle 0.6650 (0.4348) acc 50.0000 (41.7434) lr 1.0000e-05 eta 0:24:37
epoch [1/50] batch [400/403] time 0.065 (0.074) data 0.000 (0.002) loss 2.4134 (2.5829) teacher_loss 1.4439 (1.7532) loss_zs_kd 0.5667 (0.4401) loss_oracle 0.6309 (0.4436) acc 37.5000 (42.1172) lr 1.0000e-05 eta 0:24:30
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 2,817
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 37.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,987
* accuracy: 33.8%
* error: 66.2%
* macro_f1: 25.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      50.9%, epoch: 1 *******
******* Domain 4 best val test acc: 33.8%, epoch: 1 *******
******* Domain 4 best test acc:     33.8%, epoch: 1 *******
epoch [2/50] batch [20/403] time 0.067 (0.100) data 0.000 (0.023) loss 3.1346 (2.7653) teacher_loss 2.0981 (1.7719) loss_zs_kd 0.6344 (0.6584) loss_oracle 0.6938 (0.6675) acc 31.2500 (42.1875) lr 2.0000e-03 eta 0:32:51
epoch [2/50] batch [40/403] time 0.074 (0.086) data 0.000 (0.012) loss 2.4173 (2.6198) teacher_loss 1.4639 (1.6229) loss_zs_kd 0.7169 (0.6828) loss_oracle 0.6887 (0.6776) acc 43.7500 (45.1562) lr 2.0000e-03 eta 0:28:07
epoch [2/50] batch [60/403] time 0.071 (0.080) data 0.001 (0.008) loss 2.3222 (2.5008) teacher_loss 1.3794 (1.5035) loss_zs_kd 0.8847 (0.7518) loss_oracle 0.6571 (0.6792) acc 46.8750 (48.1250) lr 2.0000e-03 eta 0:26:11
epoch [2/50] batch [80/403] time 0.072 (0.076) data 0.000 (0.006) loss 2.3260 (2.4378) teacher_loss 1.3334 (1.4437) loss_zs_kd 0.6783 (0.7868) loss_oracle 0.6747 (0.6779) acc 46.8750 (50.7031) lr 2.0000e-03 eta 0:25:04
epoch [2/50] batch [100/403] time 0.074 (0.075) data 0.000 (0.005) loss 2.0002 (2.3979) teacher_loss 0.9950 (1.4077) loss_zs_kd 1.0123 (0.8092) loss_oracle 0.6611 (0.6738) acc 59.3750 (52.3750) lr 2.0000e-03 eta 0:24:35
epoch [2/50] batch [120/403] time 0.073 (0.074) data 0.001 (0.004) loss 1.8095 (2.3518) teacher_loss 0.8612 (1.3645) loss_zs_kd 0.9745 (0.8644) loss_oracle 0.6509 (0.6697) acc 75.0000 (53.8802) lr 2.0000e-03 eta 0:24:21
epoch [2/50] batch [140/403] time 0.073 (0.074) data 0.000 (0.004) loss 2.3107 (2.3336) teacher_loss 1.3682 (1.3504) loss_zs_kd 0.8091 (0.8657) loss_oracle 0.5851 (0.6647) acc 56.2500 (54.3527) lr 2.0000e-03 eta 0:24:07
epoch [2/50] batch [160/403] time 0.073 (0.076) data 0.000 (0.003) loss 1.7448 (2.3059) teacher_loss 0.8103 (1.3241) loss_zs_kd 1.4493 (0.8944) loss_oracle 0.5897 (0.6595) acc 71.8750 (55.1367) lr 2.0000e-03 eta 0:24:52
epoch [2/50] batch [180/403] time 0.068 (0.075) data 0.000 (0.003) loss 2.1657 (2.2943) teacher_loss 1.2186 (1.3165) loss_zs_kd 0.9285 (0.9084) loss_oracle 0.6254 (0.6548) acc 53.1250 (55.1562) lr 2.0000e-03 eta 0:24:36
epoch [2/50] batch [200/403] time 0.067 (0.075) data 0.000 (0.003) loss 2.1306 (2.2770) teacher_loss 1.1984 (1.3043) loss_zs_kd 0.8998 (0.9198) loss_oracle 0.6185 (0.6504) acc 56.2500 (55.5000) lr 2.0000e-03 eta 0:24:26
epoch [2/50] batch [220/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.9979 (2.2576) teacher_loss 1.0954 (1.2906) loss_zs_kd 1.0491 (0.9255) loss_oracle 0.5815 (0.6459) acc 71.8750 (55.8807) lr 2.0000e-03 eta 0:24:25
epoch [2/50] batch [240/403] time 0.077 (0.075) data 0.000 (0.002) loss 2.2667 (2.2387) teacher_loss 1.3286 (1.2770) loss_zs_kd 1.2020 (0.9319) loss_oracle 0.5836 (0.6410) acc 43.7500 (56.2109) lr 2.0000e-03 eta 0:24:20
epoch [2/50] batch [260/403] time 0.071 (0.075) data 0.000 (0.002) loss 2.1182 (2.2232) teacher_loss 1.2293 (1.2665) loss_zs_kd 0.9283 (0.9295) loss_oracle 0.5717 (0.6358) acc 53.1250 (56.5865) lr 2.0000e-03 eta 0:24:15
epoch [2/50] batch [280/403] time 0.067 (0.074) data 0.001 (0.002) loss 2.1097 (2.2013) teacher_loss 1.2335 (1.2503) loss_zs_kd 0.8176 (0.9398) loss_oracle 0.5783 (0.6306) acc 53.1250 (57.1094) lr 2.0000e-03 eta 0:24:09
epoch [2/50] batch [300/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.5856 (2.1860) teacher_loss 0.6956 (1.2391) loss_zs_kd 1.0061 (0.9436) loss_oracle 0.5501 (0.6255) acc 78.1250 (57.3958) lr 2.0000e-03 eta 0:24:02
epoch [2/50] batch [320/403] time 0.067 (0.074) data 0.000 (0.002) loss 2.0986 (2.1779) teacher_loss 1.2288 (1.2350) loss_zs_kd 1.2159 (0.9609) loss_oracle 0.5445 (0.6205) acc 65.6250 (57.5781) lr 2.0000e-03 eta 0:23:56
epoch [2/50] batch [340/403] time 0.072 (0.074) data 0.000 (0.002) loss 2.1811 (2.1703) teacher_loss 1.2419 (1.2304) loss_zs_kd 1.2244 (0.9734) loss_oracle 0.5263 (0.6156) acc 62.5000 (57.7114) lr 2.0000e-03 eta 0:23:49
epoch [2/50] batch [360/403] time 0.065 (0.074) data 0.000 (0.002) loss 1.8865 (2.1593) teacher_loss 0.9934 (1.2220) loss_zs_kd 0.9987 (0.9797) loss_oracle 0.5324 (0.6108) acc 59.3750 (57.8559) lr 2.0000e-03 eta 0:23:45
epoch [2/50] batch [380/403] time 0.068 (0.073) data 0.000 (0.002) loss 2.2319 (2.1545) teacher_loss 1.3043 (1.2177) loss_zs_kd 1.1751 (0.9907) loss_oracle 0.5287 (0.6065) acc 50.0000 (57.9852) lr 2.0000e-03 eta 0:23:37
epoch [2/50] batch [400/403] time 0.066 (0.073) data 0.000 (0.001) loss 1.7120 (2.1452) teacher_loss 0.8664 (1.2110) loss_zs_kd 1.0635 (0.9984) loss_oracle 0.5252 (0.6026) acc 65.6250 (58.2500) lr 2.0000e-03 eta 0:23:30
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,535
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 48.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,112
* accuracy: 35.9%
* error: 64.1%
* macro_f1: 24.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      63.9%, epoch: 2 *******
******* Domain 4 best val test acc: 35.9%, epoch: 2 *******
******* Domain 4 best test acc:     35.9%, epoch: 2 *******
epoch [3/50] batch [20/403] time 0.047 (0.095) data 0.000 (0.033) loss 1.7954 (1.9468) teacher_loss 0.7993 (1.0316) loss_zs_kd 1.3626 (1.2080) loss_oracle 0.5349 (0.5197) acc 78.1250 (62.9688) lr 1.9980e-03 eta 0:30:26
epoch [3/50] batch [40/403] time 0.047 (0.072) data 0.000 (0.017) loss 2.1274 (2.0451) teacher_loss 1.1563 (1.0950) loss_zs_kd 1.4139 (1.1983) loss_oracle 0.4972 (0.5176) acc 65.6250 (60.4688) lr 1.9980e-03 eta 0:23:04
epoch [3/50] batch [60/403] time 0.071 (0.068) data 0.000 (0.011) loss 1.9670 (2.0311) teacher_loss 0.9952 (1.0856) loss_zs_kd 1.4876 (1.2870) loss_oracle 0.5065 (0.5221) acc 56.2500 (61.1979) lr 1.9980e-03 eta 0:21:50
epoch [3/50] batch [80/403] time 0.071 (0.069) data 0.000 (0.009) loss 1.9711 (2.0011) teacher_loss 0.9787 (1.0569) loss_zs_kd 1.2289 (1.3236) loss_oracle 0.5396 (0.5242) acc 62.5000 (62.4219) lr 1.9980e-03 eta 0:22:02
epoch [3/50] batch [100/403] time 0.070 (0.069) data 0.000 (0.007) loss 1.5844 (1.9788) teacher_loss 0.7766 (1.0400) loss_zs_kd 1.2410 (1.2988) loss_oracle 0.5255 (0.5251) acc 81.2500 (63.6250) lr 1.9980e-03 eta 0:22:08
epoch [3/50] batch [120/403] time 0.068 (0.069) data 0.000 (0.006) loss 1.8272 (1.9592) teacher_loss 1.0106 (1.0329) loss_zs_kd 1.2003 (1.3006) loss_oracle 0.5006 (0.5237) acc 68.7500 (63.7760) lr 1.9980e-03 eta 0:22:06
epoch [3/50] batch [140/403] time 0.049 (0.069) data 0.000 (0.005) loss 1.8269 (1.9287) teacher_loss 0.9956 (1.0133) loss_zs_kd 1.3822 (1.2870) loss_oracle 0.5073 (0.5231) acc 59.3750 (64.3527) lr 1.9980e-03 eta 0:22:08
epoch [3/50] batch [160/403] time 0.073 (0.069) data 0.000 (0.004) loss 1.9748 (1.9151) teacher_loss 1.1062 (1.0066) loss_zs_kd 1.0835 (1.2712) loss_oracle 0.5398 (0.5221) acc 65.6250 (64.8047) lr 1.9980e-03 eta 0:21:55
epoch [3/50] batch [180/403] time 0.070 (0.069) data 0.000 (0.004) loss 1.8542 (1.9048) teacher_loss 0.9831 (1.0015) loss_zs_kd 1.5422 (1.2781) loss_oracle 0.5854 (0.5215) acc 62.5000 (64.8090) lr 1.9980e-03 eta 0:21:59
epoch [3/50] batch [200/403] time 0.078 (0.070) data 0.000 (0.004) loss 1.4694 (1.8928) teacher_loss 0.6193 (0.9923) loss_zs_kd 1.1804 (1.2855) loss_oracle 0.5346 (0.5214) acc 81.2500 (65.0469) lr 1.9980e-03 eta 0:22:11
epoch [3/50] batch [220/403] time 0.070 (0.070) data 0.000 (0.003) loss 1.7768 (1.8922) teacher_loss 1.0258 (0.9940) loss_zs_kd 1.2846 (1.2902) loss_oracle 0.4761 (0.5192) acc 59.3750 (64.8295) lr 1.9980e-03 eta 0:22:12
epoch [3/50] batch [240/403] time 0.078 (0.070) data 0.000 (0.003) loss 2.0671 (1.8878) teacher_loss 1.0698 (0.9929) loss_zs_kd 1.4041 (1.2993) loss_oracle 0.5406 (0.5179) acc 65.6250 (64.7786) lr 1.9980e-03 eta 0:22:13
epoch [3/50] batch [260/403] time 0.068 (0.070) data 0.000 (0.003) loss 1.7965 (1.8781) teacher_loss 0.8855 (0.9859) loss_zs_kd 1.1627 (1.2948) loss_oracle 0.5258 (0.5168) acc 68.7500 (65.1082) lr 1.9980e-03 eta 0:22:16
epoch [3/50] batch [280/403] time 0.083 (0.070) data 0.000 (0.003) loss 1.7821 (1.8799) teacher_loss 0.9770 (0.9881) loss_zs_kd 1.1702 (1.2936) loss_oracle 0.4974 (0.5162) acc 68.7500 (65.1339) lr 1.9980e-03 eta 0:22:21
epoch [3/50] batch [300/403] time 0.072 (0.070) data 0.000 (0.003) loss 1.8052 (1.8739) teacher_loss 0.8620 (0.9849) loss_zs_kd 1.1448 (1.2853) loss_oracle 0.4879 (0.5158) acc 56.2500 (65.2812) lr 1.9980e-03 eta 0:22:21
epoch [3/50] batch [320/403] time 0.069 (0.071) data 0.000 (0.002) loss 1.8644 (1.8751) teacher_loss 0.9703 (0.9863) loss_zs_kd 1.2065 (1.2854) loss_oracle 0.5695 (0.5155) acc 71.8750 (65.2930) lr 1.9980e-03 eta 0:22:23
epoch [3/50] batch [340/403] time 0.058 (0.071) data 0.000 (0.002) loss 1.4609 (1.8727) teacher_loss 0.5283 (0.9844) loss_zs_kd 1.7683 (1.2911) loss_oracle 0.5739 (0.5165) acc 84.3750 (65.3493) lr 1.9980e-03 eta 0:22:21
epoch [3/50] batch [360/403] time 0.077 (0.071) data 0.001 (0.002) loss 1.8462 (1.8784) teacher_loss 0.8131 (0.9847) loss_zs_kd 1.5311 (1.3000) loss_oracle 0.6359 (0.5189) acc 68.7500 (65.3472) lr 1.9980e-03 eta 0:22:20
epoch [3/50] batch [380/403] time 0.046 (0.072) data 0.000 (0.002) loss 1.9460 (1.8813) teacher_loss 1.0871 (0.9871) loss_zs_kd 1.4023 (1.2949) loss_oracle 0.5817 (0.5196) acc 56.2500 (65.2303) lr 1.9980e-03 eta 0:22:39
epoch [3/50] batch [400/403] time 0.061 (0.071) data 0.000 (0.002) loss 2.0272 (1.8796) teacher_loss 1.1547 (0.9857) loss_zs_kd 1.2403 (1.2932) loss_oracle 0.5400 (0.5210) acc 65.6250 (65.2891) lr 1.9980e-03 eta 0:22:21
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,550
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 48.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,212
* accuracy: 37.6%
* error: 62.4%
* macro_f1: 27.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      64.1%, epoch: 3 *******
******* Domain 4 best val test acc: 37.6%, epoch: 3 *******
******* Domain 4 best test acc:     37.6%, epoch: 3 *******
epoch [4/50] batch [20/403] time 0.071 (0.106) data 0.000 (0.032) loss 1.7809 (1.8464) teacher_loss 0.8917 (0.9552) loss_zs_kd 1.7311 (1.2367) loss_oracle 0.4998 (0.5216) acc 62.5000 (66.0938) lr 1.9921e-03 eta 0:33:32
epoch [4/50] batch [40/403] time 0.069 (0.090) data 0.000 (0.016) loss 1.9630 (1.8143) teacher_loss 1.1850 (0.9694) loss_zs_kd 1.5378 (1.2570) loss_oracle 0.4890 (0.5100) acc 65.6250 (65.9375) lr 1.9921e-03 eta 0:28:18
epoch [4/50] batch [60/403] time 0.071 (0.084) data 0.000 (0.011) loss 1.8283 (1.8079) teacher_loss 1.0219 (0.9695) loss_zs_kd 1.2583 (1.2980) loss_oracle 0.4868 (0.5074) acc 59.3750 (65.1562) lr 1.9921e-03 eta 0:26:19
epoch [4/50] batch [80/403] time 0.074 (0.080) data 0.000 (0.008) loss 2.3936 (1.8345) teacher_loss 1.4258 (0.9866) loss_zs_kd 1.2109 (1.2882) loss_oracle 0.5045 (0.5039) acc 53.1250 (65.3125) lr 1.9921e-03 eta 0:25:17
epoch [4/50] batch [100/403] time 0.075 (0.079) data 0.000 (0.007) loss 1.8932 (1.8386) teacher_loss 1.0067 (0.9915) loss_zs_kd 1.3314 (1.2901) loss_oracle 0.5205 (0.5011) acc 62.5000 (64.7812) lr 1.9921e-03 eta 0:24:52
epoch [4/50] batch [120/403] time 0.073 (0.078) data 0.000 (0.006) loss 2.0358 (1.8404) teacher_loss 1.1298 (0.9920) loss_zs_kd 1.3357 (1.2755) loss_oracle 0.5354 (0.5008) acc 65.6250 (64.7396) lr 1.9921e-03 eta 0:24:26
epoch [4/50] batch [140/403] time 0.077 (0.077) data 0.000 (0.005) loss 1.8979 (1.8515) teacher_loss 1.0646 (0.9907) loss_zs_kd 1.1798 (1.2903) loss_oracle 0.4968 (0.5029) acc 68.7500 (64.7545) lr 1.9921e-03 eta 0:24:10
epoch [4/50] batch [160/403] time 0.069 (0.078) data 0.000 (0.004) loss 1.8409 (1.8601) teacher_loss 0.9338 (0.9905) loss_zs_kd 1.3542 (1.2931) loss_oracle 0.5336 (0.5035) acc 78.1250 (64.5703) lr 1.9921e-03 eta 0:24:30
epoch [4/50] batch [180/403] time 0.056 (0.078) data 0.000 (0.004) loss 2.0775 (1.8629) teacher_loss 1.1217 (0.9902) loss_zs_kd 1.4882 (1.2990) loss_oracle 0.5628 (0.5033) acc 68.7500 (64.6007) lr 1.9921e-03 eta 0:24:14
epoch [4/50] batch [200/403] time 0.045 (0.075) data 0.000 (0.003) loss 1.7716 (1.8608) teacher_loss 0.9072 (0.9874) loss_zs_kd 1.0259 (1.2945) loss_oracle 0.5443 (0.5040) acc 65.6250 (64.9688) lr 1.9921e-03 eta 0:23:16
epoch [4/50] batch [220/403] time 0.044 (0.072) data 0.000 (0.003) loss 1.7379 (1.8600) teacher_loss 0.9486 (0.9853) loss_zs_kd 1.1792 (1.2916) loss_oracle 0.4959 (0.5064) acc 65.6250 (65.2415) lr 1.9921e-03 eta 0:22:32
epoch [4/50] batch [240/403] time 0.052 (0.070) data 0.000 (0.003) loss 1.6453 (1.8562) teacher_loss 0.7528 (0.9774) loss_zs_kd 1.2670 (1.3085) loss_oracle 0.5470 (0.5085) acc 65.6250 (65.5339) lr 1.9921e-03 eta 0:21:57
epoch [4/50] batch [260/403] time 0.047 (0.069) data 0.000 (0.003) loss 1.6941 (1.8423) teacher_loss 0.8453 (0.9628) loss_zs_kd 1.2829 (1.3174) loss_oracle 0.5220 (0.5110) acc 71.8750 (66.0216) lr 1.9921e-03 eta 0:21:27
epoch [4/50] batch [280/403] time 0.053 (0.067) data 0.000 (0.003) loss 2.1898 (1.8444) teacher_loss 1.2270 (0.9641) loss_zs_kd 1.5789 (1.3322) loss_oracle 0.5623 (0.5132) acc 53.1250 (66.0491) lr 1.9921e-03 eta 0:20:58
epoch [4/50] batch [300/403] time 0.072 (0.068) data 0.000 (0.002) loss 1.5655 (1.8363) teacher_loss 0.6536 (0.9558) loss_zs_kd 1.3262 (1.3381) loss_oracle 0.5571 (0.5136) acc 78.1250 (66.3021) lr 1.9921e-03 eta 0:20:59
epoch [4/50] batch [320/403] time 0.073 (0.068) data 0.000 (0.002) loss 1.6521 (1.8373) teacher_loss 0.8250 (0.9556) loss_zs_kd 1.5296 (1.3377) loss_oracle 0.5022 (0.5135) acc 75.0000 (66.4746) lr 1.9921e-03 eta 0:21:02
epoch [4/50] batch [340/403] time 0.068 (0.068) data 0.000 (0.002) loss 2.1938 (1.8385) teacher_loss 1.1813 (0.9542) loss_zs_kd 1.2485 (1.3335) loss_oracle 0.5184 (0.5134) acc 62.5000 (66.5257) lr 1.9921e-03 eta 0:21:02
epoch [4/50] batch [360/403] time 0.067 (0.068) data 0.000 (0.002) loss 1.8080 (1.8493) teacher_loss 0.7950 (0.9572) loss_zs_kd 1.6611 (1.3394) loss_oracle 0.5274 (0.5157) acc 68.7500 (66.3889) lr 1.9921e-03 eta 0:21:07
epoch [4/50] batch [380/403] time 0.072 (0.068) data 0.000 (0.002) loss 1.3540 (1.8502) teacher_loss 0.5231 (0.9566) loss_zs_kd 1.4391 (1.3444) loss_oracle 0.5522 (0.5159) acc 81.2500 (66.3322) lr 1.9921e-03 eta 0:21:07
epoch [4/50] batch [400/403] time 0.061 (0.068) data 0.000 (0.002) loss 1.9855 (1.8503) teacher_loss 0.9888 (0.9560) loss_zs_kd 1.3657 (1.3460) loss_oracle 0.5944 (0.5168) acc 59.3750 (66.2031) lr 1.9921e-03 eta 0:21:05
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,601
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 46.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,018
* accuracy: 34.3%
* error: 65.7%
* macro_f1: 22.2%
******* Domain 4 best val acc:      65.1%, epoch: 4 *******
******* Domain 4 best val test acc: 34.3%, epoch: 4 *******
******* Domain 4 best test acc:     37.6%, epoch: 3 *******
epoch [5/50] batch [20/403] time 0.063 (0.101) data 0.000 (0.026) loss 1.7844 (1.8852) teacher_loss 0.8356 (0.9463) loss_zs_kd 1.2899 (1.3386) loss_oracle 0.4886 (0.5206) acc 71.8750 (68.4375) lr 1.9823e-03 eta 0:31:06
epoch [5/50] batch [40/403] time 0.069 (0.085) data 0.000 (0.013) loss 1.6145 (1.8658) teacher_loss 0.6904 (0.9422) loss_zs_kd 1.2104 (1.3065) loss_oracle 0.4895 (0.5105) acc 68.7500 (67.5781) lr 1.9823e-03 eta 0:26:12
epoch [5/50] batch [60/403] time 0.069 (0.080) data 0.001 (0.009) loss 1.7598 (1.8758) teacher_loss 0.8305 (0.9499) loss_zs_kd 1.3650 (1.3429) loss_oracle 0.5454 (0.5171) acc 65.6250 (66.9271) lr 1.9823e-03 eta 0:24:35
epoch [5/50] batch [80/403] time 0.076 (0.078) data 0.000 (0.007) loss 2.0606 (1.9046) teacher_loss 0.9861 (0.9642) loss_zs_kd 1.1198 (1.3286) loss_oracle 0.5076 (0.5180) acc 59.3750 (66.4844) lr 1.9823e-03 eta 0:24:05
epoch [5/50] batch [100/403] time 0.075 (0.077) data 0.000 (0.005) loss 1.8081 (1.9052) teacher_loss 0.8265 (0.9646) loss_zs_kd 1.1732 (1.3161) loss_oracle 0.5277 (0.5174) acc 68.7500 (66.5312) lr 1.9823e-03 eta 0:23:34
epoch [5/50] batch [120/403] time 0.078 (0.076) data 0.000 (0.005) loss 1.6256 (1.8983) teacher_loss 0.6658 (0.9612) loss_zs_kd 1.0845 (1.3230) loss_oracle 0.5473 (0.5160) acc 65.6250 (66.4583) lr 1.9823e-03 eta 0:23:14
epoch [5/50] batch [140/403] time 0.078 (0.075) data 0.001 (0.004) loss 2.1691 (1.8907) teacher_loss 1.2108 (0.9621) loss_zs_kd 1.3471 (1.3272) loss_oracle 0.5018 (0.5121) acc 50.0000 (66.3839) lr 1.9823e-03 eta 0:23:02
epoch [5/50] batch [160/403] time 0.072 (0.075) data 0.000 (0.004) loss 2.0506 (1.8988) teacher_loss 1.1337 (0.9622) loss_zs_kd 1.4208 (1.3421) loss_oracle 0.5243 (0.5121) acc 59.3750 (66.2305) lr 1.9823e-03 eta 0:22:51
epoch [5/50] batch [180/403] time 0.070 (0.074) data 0.000 (0.003) loss 2.0677 (1.8960) teacher_loss 1.0822 (0.9586) loss_zs_kd 1.2083 (1.3430) loss_oracle 0.5104 (0.5119) acc 56.2500 (66.2326) lr 1.9823e-03 eta 0:22:41
epoch [5/50] batch [200/403] time 0.085 (0.074) data 0.000 (0.003) loss 1.6339 (1.8974) teacher_loss 0.7340 (0.9583) loss_zs_kd 1.5079 (1.3420) loss_oracle 0.4875 (0.5105) acc 81.2500 (66.2031) lr 1.9823e-03 eta 0:22:37
epoch [5/50] batch [220/403] time 0.068 (0.074) data 0.000 (0.003) loss 2.1062 (1.8956) teacher_loss 1.1426 (0.9588) loss_zs_kd 1.2948 (1.3531) loss_oracle 0.5280 (0.5109) acc 62.5000 (66.3920) lr 1.9823e-03 eta 0:22:34
epoch [5/50] batch [240/403] time 0.066 (0.074) data 0.000 (0.002) loss 2.0468 (1.8825) teacher_loss 1.1682 (0.9503) loss_zs_kd 1.2771 (1.3496) loss_oracle 0.5317 (0.5101) acc 56.2500 (66.7057) lr 1.9823e-03 eta 0:22:26
epoch [5/50] batch [260/403] time 0.070 (0.073) data 0.000 (0.002) loss 1.7740 (1.8797) teacher_loss 0.8159 (0.9493) loss_zs_kd 1.5035 (1.3596) loss_oracle 0.5593 (0.5101) acc 75.0000 (66.8389) lr 1.9823e-03 eta 0:22:18
epoch [5/50] batch [280/403] time 0.072 (0.073) data 0.000 (0.002) loss 2.0906 (1.8799) teacher_loss 1.1895 (0.9503) loss_zs_kd 1.7022 (1.3625) loss_oracle 0.5075 (0.5092) acc 59.3750 (66.7969) lr 1.9823e-03 eta 0:22:10
epoch [5/50] batch [300/403] time 0.074 (0.073) data 0.000 (0.002) loss 2.0782 (1.8861) teacher_loss 1.1104 (0.9526) loss_zs_kd 1.3560 (1.3641) loss_oracle 0.5527 (0.5101) acc 50.0000 (66.7500) lr 1.9823e-03 eta 0:22:07
epoch [5/50] batch [320/403] time 0.080 (0.073) data 0.000 (0.002) loss 1.8141 (1.8872) teacher_loss 0.9406 (0.9529) loss_zs_kd 1.4931 (1.3680) loss_oracle 0.4714 (0.5098) acc 71.8750 (66.7773) lr 1.9823e-03 eta 0:22:06
epoch [5/50] batch [340/403] time 0.086 (0.073) data 0.000 (0.002) loss 2.0186 (1.8867) teacher_loss 1.2106 (0.9573) loss_zs_kd 1.6536 (1.3871) loss_oracle 0.4903 (0.5093) acc 50.0000 (66.5257) lr 1.9823e-03 eta 0:22:04
epoch [5/50] batch [360/403] time 0.077 (0.073) data 0.000 (0.002) loss 1.6829 (1.8827) teacher_loss 0.7818 (0.9561) loss_zs_kd 1.5701 (1.3878) loss_oracle 0.5114 (0.5087) acc 75.0000 (66.5017) lr 1.9823e-03 eta 0:22:02
epoch [5/50] batch [380/403] time 0.076 (0.073) data 0.000 (0.002) loss 1.8422 (1.8775) teacher_loss 0.9595 (0.9543) loss_zs_kd 1.5601 (1.3923) loss_oracle 0.5498 (0.5086) acc 68.7500 (66.5214) lr 1.9823e-03 eta 0:22:01
epoch [5/50] batch [400/403] time 0.051 (0.073) data 0.000 (0.002) loss 1.9724 (1.8808) teacher_loss 1.0667 (0.9577) loss_zs_kd 1.4428 (1.4035) loss_oracle 0.4845 (0.5097) acc 56.2500 (66.4688) lr 1.9823e-03 eta 0:21:55
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,756
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 52.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,322
* accuracy: 39.5%
* error: 60.5%
* macro_f1: 27.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      67.9%, epoch: 5 *******
******* Domain 4 best val test acc: 39.5%, epoch: 5 *******
******* Domain 4 best test acc:     39.5%, epoch: 5 *******
epoch [6/50] batch [20/403] time 0.080 (0.102) data 0.000 (0.024) loss 1.8179 (1.8364) teacher_loss 0.7733 (0.8964) loss_zs_kd 1.4088 (1.4321) loss_oracle 0.5454 (0.5230) acc 68.7500 (68.7500) lr 1.9686e-03 eta 0:30:47
epoch [6/50] batch [40/403] time 0.071 (0.087) data 0.000 (0.012) loss 2.1424 (1.8862) teacher_loss 1.2164 (0.9402) loss_zs_kd 1.5208 (1.4341) loss_oracle 0.5393 (0.5250) acc 50.0000 (66.4062) lr 1.9686e-03 eta 0:26:23
epoch [6/50] batch [60/403] time 0.064 (0.082) data 0.001 (0.008) loss 1.5945 (1.8749) teacher_loss 0.7319 (0.9332) loss_zs_kd 1.3429 (1.4414) loss_oracle 0.5148 (0.5306) acc 75.0000 (67.1354) lr 1.9686e-03 eta 0:24:45
epoch [6/50] batch [80/403] time 0.074 (0.080) data 0.000 (0.006) loss 1.8232 (1.8925) teacher_loss 0.8819 (0.9434) loss_zs_kd 1.2453 (1.4503) loss_oracle 0.5374 (0.5318) acc 65.6250 (66.9922) lr 1.9686e-03 eta 0:24:05
epoch [6/50] batch [100/403] time 0.073 (0.078) data 0.000 (0.005) loss 1.6597 (1.8962) teacher_loss 0.7127 (0.9458) loss_zs_kd 1.4202 (1.4404) loss_oracle 0.5635 (0.5315) acc 71.8750 (66.6562) lr 1.9686e-03 eta 0:23:33
epoch [6/50] batch [120/403] time 0.071 (0.078) data 0.000 (0.004) loss 1.8785 (1.8773) teacher_loss 0.9267 (0.9301) loss_zs_kd 1.4916 (1.4301) loss_oracle 0.5672 (0.5319) acc 65.6250 (67.3438) lr 1.9686e-03 eta 0:23:19
epoch [6/50] batch [140/403] time 0.071 (0.077) data 0.000 (0.004) loss 2.0314 (1.8778) teacher_loss 1.0440 (0.9302) loss_zs_kd 1.4085 (1.4451) loss_oracle 0.5743 (0.5318) acc 62.5000 (67.2991) lr 1.9686e-03 eta 0:23:03
epoch [6/50] batch [160/403] time 0.073 (0.076) data 0.000 (0.003) loss 2.0506 (1.8847) teacher_loss 1.2027 (0.9322) loss_zs_kd 1.4172 (1.4475) loss_oracle 0.5252 (0.5334) acc 59.3750 (67.1875) lr 1.9686e-03 eta 0:22:54
epoch [6/50] batch [180/403] time 0.072 (0.076) data 0.000 (0.003) loss 1.9520 (1.8804) teacher_loss 1.0460 (0.9296) loss_zs_kd 1.3613 (1.4460) loss_oracle 0.4650 (0.5344) acc 71.8750 (67.2743) lr 1.9686e-03 eta 0:22:43
epoch [6/50] batch [200/403] time 0.128 (0.077) data 0.000 (0.003) loss 1.9627 (1.8756) teacher_loss 1.0091 (0.9267) loss_zs_kd 1.8349 (1.4452) loss_oracle 0.5332 (0.5339) acc 59.3750 (67.4375) lr 1.9686e-03 eta 0:23:06
epoch [6/50] batch [220/403] time 0.074 (0.077) data 0.000 (0.002) loss 1.5744 (1.8669) teacher_loss 0.7166 (0.9225) loss_zs_kd 1.4403 (1.4447) loss_oracle 0.4987 (0.5327) acc 71.8750 (67.4432) lr 1.9686e-03 eta 0:23:02
epoch [6/50] batch [240/403] time 0.074 (0.077) data 0.000 (0.002) loss 1.5735 (1.8624) teacher_loss 0.6674 (0.9223) loss_zs_kd 1.8390 (1.4568) loss_oracle 0.5284 (0.5322) acc 78.1250 (67.3828) lr 1.9686e-03 eta 0:22:52
epoch [6/50] batch [260/403] time 0.075 (0.076) data 0.000 (0.002) loss 1.6730 (1.8597) teacher_loss 0.8853 (0.9236) loss_zs_kd 1.5841 (1.4612) loss_oracle 0.5523 (0.5321) acc 71.8750 (67.3438) lr 1.9686e-03 eta 0:22:46
epoch [6/50] batch [280/403] time 0.072 (0.076) data 0.000 (0.002) loss 1.7056 (1.8526) teacher_loss 0.8392 (0.9201) loss_zs_kd 1.2370 (1.4556) loss_oracle 0.5494 (0.5323) acc 75.0000 (67.4777) lr 1.9686e-03 eta 0:22:40
epoch [6/50] batch [300/403] time 0.068 (0.076) data 0.000 (0.002) loss 2.0945 (1.8470) teacher_loss 1.2467 (0.9209) loss_zs_kd 1.7502 (1.4578) loss_oracle 0.5603 (0.5323) acc 53.1250 (67.4583) lr 1.9686e-03 eta 0:22:34
epoch [6/50] batch [320/403] time 0.073 (0.076) data 0.000 (0.002) loss 1.5745 (1.8442) teacher_loss 0.7506 (0.9227) loss_zs_kd 0.9695 (1.4517) loss_oracle 0.4721 (0.5321) acc 78.1250 (67.4414) lr 1.9686e-03 eta 0:22:29
epoch [6/50] batch [340/403] time 0.071 (0.076) data 0.000 (0.002) loss 1.9216 (1.8478) teacher_loss 1.0289 (0.9278) loss_zs_kd 1.5000 (1.4497) loss_oracle 0.5208 (0.5312) acc 68.7500 (67.2426) lr 1.9686e-03 eta 0:22:27
epoch [6/50] batch [360/403] time 0.072 (0.076) data 0.000 (0.002) loss 2.2444 (1.8533) teacher_loss 1.2561 (0.9310) loss_zs_kd 1.8123 (1.4598) loss_oracle 0.5674 (0.5307) acc 53.1250 (67.0312) lr 1.9686e-03 eta 0:22:24
epoch [6/50] batch [380/403] time 0.076 (0.076) data 0.000 (0.002) loss 2.1784 (1.8554) teacher_loss 1.2125 (0.9329) loss_zs_kd 1.3159 (1.4588) loss_oracle 0.5072 (0.5306) acc 56.2500 (67.0066) lr 1.9686e-03 eta 0:22:22
epoch [6/50] batch [400/403] time 0.064 (0.075) data 0.000 (0.001) loss 1.7015 (1.8572) teacher_loss 0.7867 (0.9344) loss_zs_kd 1.3081 (1.4581) loss_oracle 0.4731 (0.5293) acc 75.0000 (67.0000) lr 1.9686e-03 eta 0:22:13
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,828
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 54.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,431
* accuracy: 41.3%
* error: 58.7%
* macro_f1: 28.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      69.2%, epoch: 6 *******
******* Domain 4 best val test acc: 41.3%, epoch: 6 *******
******* Domain 4 best test acc:     41.3%, epoch: 6 *******
epoch [7/50] batch [20/403] time 0.067 (0.107) data 0.000 (0.030) loss 2.0302 (1.8696) teacher_loss 1.1876 (0.9975) loss_zs_kd 1.1867 (1.4583) loss_oracle 0.4973 (0.5088) acc 59.3750 (65.1562) lr 1.9511e-03 eta 0:31:28
epoch [7/50] batch [40/403] time 0.065 (0.089) data 0.000 (0.015) loss 1.8117 (1.8525) teacher_loss 0.9364 (0.9760) loss_zs_kd 1.7245 (1.4479) loss_oracle 0.5382 (0.5203) acc 62.5000 (65.2344) lr 1.9511e-03 eta 0:26:13
epoch [7/50] batch [60/403] time 0.069 (0.084) data 0.001 (0.010) loss 2.1457 (1.8383) teacher_loss 1.1062 (0.9509) loss_zs_kd 1.9903 (1.5002) loss_oracle 0.6281 (0.5262) acc 65.6250 (66.4062) lr 1.9511e-03 eta 0:24:45
epoch [7/50] batch [80/403] time 0.070 (0.081) data 0.000 (0.008) loss 1.8674 (1.8359) teacher_loss 0.9720 (0.9461) loss_zs_kd 1.8997 (1.4845) loss_oracle 0.5777 (0.5264) acc 65.6250 (66.4062) lr 1.9511e-03 eta 0:23:56
epoch [7/50] batch [100/403] time 0.073 (0.079) data 0.000 (0.006) loss 2.3796 (1.8414) teacher_loss 1.4034 (0.9463) loss_zs_kd 1.6205 (1.4824) loss_oracle 0.5024 (0.5260) acc 46.8750 (66.2188) lr 1.9511e-03 eta 0:23:16
epoch [7/50] batch [120/403] time 0.068 (0.078) data 0.000 (0.005) loss 1.8921 (1.8224) teacher_loss 0.9957 (0.9330) loss_zs_kd 1.6244 (1.4894) loss_oracle 0.5227 (0.5237) acc 62.5000 (66.9792) lr 1.9511e-03 eta 0:22:53
epoch [7/50] batch [140/403] time 0.072 (0.077) data 0.000 (0.004) loss 1.8025 (1.8147) teacher_loss 0.9703 (0.9305) loss_zs_kd 1.3292 (1.4891) loss_oracle 0.4879 (0.5197) acc 68.7500 (67.2098) lr 1.9511e-03 eta 0:22:35
epoch [7/50] batch [160/403] time 0.066 (0.076) data 0.000 (0.004) loss 1.8429 (1.8040) teacher_loss 0.9577 (0.9231) loss_zs_kd 1.0790 (1.4884) loss_oracle 0.4773 (0.5181) acc 65.6250 (67.8125) lr 1.9511e-03 eta 0:22:19
epoch [7/50] batch [180/403] time 0.077 (0.076) data 0.000 (0.004) loss 2.2071 (1.8163) teacher_loss 1.2235 (0.9255) loss_zs_kd 1.5906 (1.5059) loss_oracle 0.6220 (0.5204) acc 62.5000 (67.5868) lr 1.9511e-03 eta 0:22:11
epoch [7/50] batch [200/403] time 0.077 (0.075) data 0.000 (0.003) loss 1.8029 (1.8143) teacher_loss 0.9109 (0.9230) loss_zs_kd 1.4280 (1.5304) loss_oracle 0.5393 (0.5209) acc 68.7500 (67.6562) lr 1.9511e-03 eta 0:22:02
epoch [7/50] batch [220/403] time 0.073 (0.075) data 0.000 (0.003) loss 1.8935 (1.8128) teacher_loss 1.0762 (0.9229) loss_zs_kd 1.5414 (1.5306) loss_oracle 0.4776 (0.5200) acc 65.6250 (67.4858) lr 1.9511e-03 eta 0:21:57
epoch [7/50] batch [240/403] time 0.069 (0.075) data 0.000 (0.003) loss 1.5976 (1.8037) teacher_loss 0.7374 (0.9160) loss_zs_kd 1.6980 (1.5418) loss_oracle 0.4727 (0.5189) acc 78.1250 (67.6562) lr 1.9511e-03 eta 0:21:53
epoch [7/50] batch [260/403] time 0.082 (0.075) data 0.000 (0.003) loss 1.8725 (1.8039) teacher_loss 0.9123 (0.9159) loss_zs_kd 1.8978 (1.5546) loss_oracle 0.5138 (0.5197) acc 65.6250 (67.5962) lr 1.9511e-03 eta 0:21:49
epoch [7/50] batch [280/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.6260 (1.8000) teacher_loss 0.7793 (0.9135) loss_zs_kd 1.6108 (1.5596) loss_oracle 0.5046 (0.5197) acc 71.8750 (67.7567) lr 1.9511e-03 eta 0:21:46
epoch [7/50] batch [300/403] time 0.079 (0.075) data 0.001 (0.002) loss 1.3959 (1.7928) teacher_loss 0.5272 (0.9081) loss_zs_kd 1.6914 (1.5580) loss_oracle 0.5346 (0.5191) acc 78.1250 (67.9375) lr 1.9511e-03 eta 0:21:42
epoch [7/50] batch [320/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.7783 (1.7856) teacher_loss 0.8826 (0.9037) loss_zs_kd 1.3611 (1.5643) loss_oracle 0.5329 (0.5195) acc 71.8750 (68.1543) lr 1.9511e-03 eta 0:21:38
epoch [7/50] batch [340/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.5581 (1.7867) teacher_loss 0.7599 (0.9058) loss_zs_kd 1.4487 (1.5583) loss_oracle 0.5017 (0.5201) acc 71.8750 (67.9688) lr 1.9511e-03 eta 0:21:34
epoch [7/50] batch [360/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.9929 (1.7850) teacher_loss 1.1374 (0.9058) loss_zs_kd 1.2037 (1.5490) loss_oracle 0.4910 (0.5194) acc 59.3750 (67.9167) lr 1.9511e-03 eta 0:21:30
epoch [7/50] batch [380/403] time 0.071 (0.074) data 0.000 (0.002) loss 2.0898 (1.7879) teacher_loss 1.1627 (0.9078) loss_zs_kd 1.8028 (1.5383) loss_oracle 0.5443 (0.5189) acc 53.1250 (67.7220) lr 1.9511e-03 eta 0:21:27
epoch [7/50] batch [400/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.7595 (1.7845) teacher_loss 0.9144 (0.9061) loss_zs_kd 1.6547 (1.5356) loss_oracle 0.5671 (0.5187) acc 56.2500 (67.7969) lr 1.9511e-03 eta 0:21:21
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,787
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 53.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,489
* accuracy: 42.3%
* error: 57.7%
* macro_f1: 29.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      69.2%, epoch: 6 *******
******* Domain 4 best val test acc: 41.3%, epoch: 6 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [8/50] batch [20/403] time 0.069 (0.100) data 0.000 (0.028) loss 2.0962 (1.8294) teacher_loss 1.1765 (0.9375) loss_zs_kd 1.3952 (1.5815) loss_oracle 0.5417 (0.5240) acc 40.6250 (65.0000) lr 1.9298e-03 eta 0:28:49
epoch [8/50] batch [40/403] time 0.073 (0.084) data 0.000 (0.014) loss 1.6713 (1.8232) teacher_loss 0.7485 (0.9283) loss_zs_kd 1.2966 (1.5430) loss_oracle 0.4520 (0.5062) acc 81.2500 (65.5469) lr 1.9298e-03 eta 0:24:10
epoch [8/50] batch [60/403] time 0.075 (0.080) data 0.001 (0.010) loss 2.0837 (1.8309) teacher_loss 1.0426 (0.9319) loss_zs_kd 1.6415 (1.5305) loss_oracle 0.5286 (0.4996) acc 65.6250 (66.3542) lr 1.9298e-03 eta 0:23:00
epoch [8/50] batch [80/403] time 0.077 (0.078) data 0.000 (0.007) loss 1.5822 (1.8461) teacher_loss 0.6787 (0.9268) loss_zs_kd 1.3935 (1.5607) loss_oracle 0.4697 (0.5028) acc 71.8750 (67.1094) lr 1.9298e-03 eta 0:22:33
epoch [8/50] batch [100/403] time 0.080 (0.077) data 0.000 (0.006) loss 1.7373 (1.8275) teacher_loss 0.9170 (0.9161) loss_zs_kd 1.4412 (1.5411) loss_oracle 0.4468 (0.5020) acc 65.6250 (67.6875) lr 1.9298e-03 eta 0:22:14
epoch [8/50] batch [120/403] time 0.086 (0.077) data 0.001 (0.005) loss 1.9114 (1.8262) teacher_loss 0.9033 (0.9142) loss_zs_kd 1.1017 (1.5411) loss_oracle 0.5475 (0.4993) acc 68.7500 (67.5521) lr 1.9298e-03 eta 0:22:01
epoch [8/50] batch [140/403] time 0.076 (0.076) data 0.000 (0.004) loss 1.8684 (1.8274) teacher_loss 0.9759 (0.9137) loss_zs_kd 1.2405 (1.5321) loss_oracle 0.4835 (0.4975) acc 68.7500 (67.5223) lr 1.9298e-03 eta 0:21:47
epoch [8/50] batch [160/403] time 0.079 (0.076) data 0.000 (0.004) loss 1.8439 (1.8351) teacher_loss 0.8657 (0.9137) loss_zs_kd 1.5154 (1.5361) loss_oracle 0.5502 (0.4981) acc 71.8750 (67.4609) lr 1.9298e-03 eta 0:21:37
epoch [8/50] batch [180/403] time 0.070 (0.075) data 0.000 (0.003) loss 1.8665 (1.8371) teacher_loss 0.8919 (0.9114) loss_zs_kd 1.6007 (1.5288) loss_oracle 0.5264 (0.4989) acc 59.3750 (67.3264) lr 1.9298e-03 eta 0:21:31
epoch [8/50] batch [200/403] time 0.085 (0.075) data 0.000 (0.003) loss 1.8106 (1.8402) teacher_loss 0.7932 (0.9102) loss_zs_kd 1.2533 (1.5216) loss_oracle 0.5794 (0.4998) acc 71.8750 (67.3594) lr 1.9298e-03 eta 0:21:26
epoch [8/50] batch [220/403] time 0.108 (0.076) data 0.000 (0.003) loss 2.0726 (1.8417) teacher_loss 1.0637 (0.9125) loss_zs_kd 1.5952 (1.5171) loss_oracle 0.5508 (0.5009) acc 65.6250 (67.4006) lr 1.9298e-03 eta 0:21:40
epoch [8/50] batch [240/403] time 0.062 (0.076) data 0.001 (0.003) loss 1.7922 (1.8373) teacher_loss 0.8904 (0.9114) loss_zs_kd 1.3975 (1.5332) loss_oracle 0.5273 (0.5007) acc 75.0000 (67.4740) lr 1.9298e-03 eta 0:21:37
epoch [8/50] batch [260/403] time 0.078 (0.076) data 0.000 (0.002) loss 2.0727 (1.8392) teacher_loss 1.2267 (0.9158) loss_zs_kd 1.2698 (1.5371) loss_oracle 0.4828 (0.5011) acc 62.5000 (67.2957) lr 1.9298e-03 eta 0:21:30
epoch [8/50] batch [280/403] time 0.069 (0.076) data 0.000 (0.002) loss 2.0040 (1.8446) teacher_loss 1.0784 (0.9210) loss_zs_kd 1.5572 (1.5327) loss_oracle 0.5686 (0.5013) acc 56.2500 (67.0982) lr 1.9298e-03 eta 0:21:29
epoch [8/50] batch [300/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.8544 (1.8444) teacher_loss 0.8102 (0.9187) loss_zs_kd 1.3925 (1.5330) loss_oracle 0.5307 (0.5022) acc 71.8750 (67.1979) lr 1.9298e-03 eta 0:21:24
epoch [8/50] batch [320/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.7151 (1.8443) teacher_loss 0.8087 (0.9186) loss_zs_kd 1.3115 (1.5329) loss_oracle 0.5159 (0.5023) acc 71.8750 (67.2754) lr 1.9298e-03 eta 0:21:21
epoch [8/50] batch [340/403] time 0.078 (0.075) data 0.000 (0.002) loss 2.0520 (1.8432) teacher_loss 1.0806 (0.9171) loss_zs_kd 1.7360 (1.5360) loss_oracle 0.5232 (0.5030) acc 59.3750 (67.3897) lr 1.9298e-03 eta 0:21:16
epoch [8/50] batch [360/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.6341 (1.8418) teacher_loss 0.7778 (0.9171) loss_zs_kd 1.7756 (1.5357) loss_oracle 0.5050 (0.5035) acc 75.0000 (67.2656) lr 1.9298e-03 eta 0:21:12
epoch [8/50] batch [380/403] time 0.115 (0.075) data 0.000 (0.002) loss 1.7968 (1.8364) teacher_loss 0.8239 (0.9120) loss_zs_kd 1.6136 (1.5431) loss_oracle 0.5348 (0.5045) acc 68.7500 (67.3355) lr 1.9298e-03 eta 0:21:09
epoch [8/50] batch [400/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.7987 (1.8371) teacher_loss 0.8909 (0.9133) loss_zs_kd 1.7499 (1.5477) loss_oracle 0.5602 (0.5047) acc 65.6250 (67.2578) lr 1.9298e-03 eta 0:21:03
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,839
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 55.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,437
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 28.7%
******* Domain 4 best val acc:      69.4%, epoch: 8 *******
******* Domain 4 best val test acc: 41.4%, epoch: 8 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [9/50] batch [20/403] time 0.070 (0.105) data 0.000 (0.032) loss 1.7436 (1.8003) teacher_loss 0.8285 (0.8501) loss_zs_kd 1.6883 (1.6142) loss_oracle 0.5399 (0.5177) acc 78.1250 (70.1562) lr 1.9048e-03 eta 0:29:37
epoch [9/50] batch [40/403] time 0.073 (0.088) data 0.000 (0.016) loss 1.7212 (1.8090) teacher_loss 0.7675 (0.8591) loss_zs_kd 1.6406 (1.5966) loss_oracle 0.5665 (0.5191) acc 78.1250 (69.4531) lr 1.9048e-03 eta 0:24:51
epoch [9/50] batch [60/403] time 0.067 (0.083) data 0.001 (0.011) loss 1.9174 (1.8059) teacher_loss 0.9132 (0.8628) loss_zs_kd 1.7865 (1.6162) loss_oracle 0.5106 (0.5171) acc 62.5000 (68.8542) lr 1.9048e-03 eta 0:23:22
epoch [9/50] batch [80/403] time 0.066 (0.079) data 0.000 (0.008) loss 1.7941 (1.8060) teacher_loss 0.8615 (0.8772) loss_zs_kd 1.5315 (1.6394) loss_oracle 0.5415 (0.5170) acc 65.6250 (67.8125) lr 1.9048e-03 eta 0:22:12
epoch [9/50] batch [100/403] time 0.065 (0.078) data 0.000 (0.007) loss 1.7723 (1.8264) teacher_loss 0.8145 (0.8962) loss_zs_kd 1.5459 (1.6034) loss_oracle 0.5931 (0.5191) acc 68.7500 (67.2812) lr 1.9048e-03 eta 0:21:44
epoch [9/50] batch [120/403] time 0.076 (0.077) data 0.000 (0.006) loss 1.9841 (1.8191) teacher_loss 1.0447 (0.8928) loss_zs_kd 1.6217 (1.5820) loss_oracle 0.5258 (0.5180) acc 68.7500 (67.4740) lr 1.9048e-03 eta 0:21:28
epoch [9/50] batch [140/403] time 0.081 (0.076) data 0.000 (0.005) loss 1.6837 (1.8202) teacher_loss 0.8462 (0.8914) loss_zs_kd 1.3970 (1.5754) loss_oracle 0.5368 (0.5186) acc 84.3750 (67.7009) lr 1.9048e-03 eta 0:21:17
epoch [9/50] batch [160/403] time 0.073 (0.075) data 0.000 (0.004) loss 1.6405 (1.8139) teacher_loss 0.8051 (0.8869) loss_zs_kd 1.8457 (1.5760) loss_oracle 0.5105 (0.5191) acc 68.7500 (68.0469) lr 1.9048e-03 eta 0:21:04
epoch [9/50] batch [180/403] time 0.066 (0.075) data 0.000 (0.004) loss 1.7029 (1.8154) teacher_loss 0.8123 (0.8852) loss_zs_kd 1.3410 (1.5673) loss_oracle 0.5078 (0.5202) acc 75.0000 (68.1250) lr 1.9048e-03 eta 0:20:50
epoch [9/50] batch [200/403] time 0.071 (0.074) data 0.000 (0.003) loss 1.4213 (1.8030) teacher_loss 0.5310 (0.8756) loss_zs_kd 1.8644 (1.5690) loss_oracle 0.4886 (0.5194) acc 78.1250 (68.5781) lr 1.9048e-03 eta 0:20:42
epoch [9/50] batch [220/403] time 0.076 (0.074) data 0.000 (0.003) loss 1.8078 (1.8052) teacher_loss 0.9757 (0.8818) loss_zs_kd 1.3812 (1.5728) loss_oracle 0.4867 (0.5186) acc 65.6250 (68.4801) lr 1.9048e-03 eta 0:20:37
epoch [9/50] batch [240/403] time 0.069 (0.074) data 0.000 (0.003) loss 1.9531 (1.8014) teacher_loss 1.0054 (0.8799) loss_zs_kd 1.7425 (1.5791) loss_oracle 0.5203 (0.5178) acc 59.3750 (68.5677) lr 1.9048e-03 eta 0:20:30
epoch [9/50] batch [260/403] time 0.075 (0.074) data 0.000 (0.003) loss 1.7770 (1.8092) teacher_loss 0.9571 (0.8871) loss_zs_kd 1.4402 (1.5655) loss_oracle 0.4936 (0.5169) acc 78.1250 (68.4014) lr 1.9048e-03 eta 0:20:26
epoch [9/50] batch [280/403] time 0.071 (0.073) data 0.000 (0.003) loss 1.8131 (1.8086) teacher_loss 0.7946 (0.8875) loss_zs_kd 1.6864 (1.5530) loss_oracle 0.5605 (0.5163) acc 56.2500 (68.3594) lr 1.9048e-03 eta 0:20:21
epoch [9/50] batch [300/403] time 0.070 (0.073) data 0.000 (0.002) loss 1.6283 (1.8033) teacher_loss 0.7669 (0.8845) loss_zs_kd 1.4151 (1.5529) loss_oracle 0.5332 (0.5152) acc 78.1250 (68.7396) lr 1.9048e-03 eta 0:20:16
epoch [9/50] batch [320/403] time 0.073 (0.073) data 0.000 (0.002) loss 1.6049 (1.8003) teacher_loss 0.7812 (0.8833) loss_zs_kd 1.1691 (1.5513) loss_oracle 0.4892 (0.5147) acc 78.1250 (68.7695) lr 1.9048e-03 eta 0:20:11
epoch [9/50] batch [340/403] time 0.081 (0.073) data 0.000 (0.002) loss 1.6727 (1.8011) teacher_loss 0.7064 (0.8825) loss_zs_kd 1.7225 (1.5454) loss_oracle 0.5323 (0.5144) acc 62.5000 (68.7224) lr 1.9048e-03 eta 0:20:10
epoch [9/50] batch [360/403] time 0.082 (0.073) data 0.000 (0.002) loss 1.9203 (1.8026) teacher_loss 1.0120 (0.8850) loss_zs_kd 1.4189 (1.5438) loss_oracle 0.4918 (0.5142) acc 65.6250 (68.6806) lr 1.9048e-03 eta 0:20:08
epoch [9/50] batch [380/403] time 0.074 (0.073) data 0.000 (0.002) loss 1.7188 (1.7931) teacher_loss 0.8902 (0.8805) loss_zs_kd 1.6898 (1.5401) loss_oracle 0.5190 (0.5132) acc 75.0000 (68.9474) lr 1.9048e-03 eta 0:20:07
epoch [9/50] batch [400/403] time 0.068 (0.073) data 0.000 (0.002) loss 1.9644 (1.7940) teacher_loss 1.0227 (0.8819) loss_zs_kd 2.1530 (1.5409) loss_oracle 0.5558 (0.5137) acc 65.6250 (68.8984) lr 1.9048e-03 eta 0:20:03
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,820
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 53.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,320
* accuracy: 39.4%
* error: 60.6%
* macro_f1: 25.7%
******* Domain 4 best val acc:      69.4%, epoch: 8 *******
******* Domain 4 best val test acc: 41.4%, epoch: 8 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [10/50] batch [20/403] time 0.066 (0.100) data 0.000 (0.026) loss 2.1309 (1.8223) teacher_loss 1.1946 (0.9112) loss_zs_kd 1.5014 (1.7101) loss_oracle 0.5254 (0.5057) acc 53.1250 (68.5938) lr 1.8763e-03 eta 0:27:23
epoch [10/50] batch [40/403] time 0.079 (0.086) data 0.000 (0.013) loss 1.7855 (1.7749) teacher_loss 0.8720 (0.8707) loss_zs_kd 1.7466 (1.5984) loss_oracle 0.5118 (0.5112) acc 68.7500 (70.0781) lr 1.8763e-03 eta 0:23:37
epoch [10/50] batch [60/403] time 0.075 (0.081) data 0.001 (0.009) loss 1.5387 (1.7701) teacher_loss 0.7043 (0.8684) loss_zs_kd 1.6826 (1.5528) loss_oracle 0.5118 (0.5139) acc 71.8750 (70.0521) lr 1.8763e-03 eta 0:22:18
epoch [10/50] batch [80/403] time 0.065 (0.079) data 0.000 (0.007) loss 1.7299 (1.7973) teacher_loss 0.7994 (0.8924) loss_zs_kd 1.7412 (1.5562) loss_oracle 0.5559 (0.5169) acc 65.6250 (69.2578) lr 1.8763e-03 eta 0:21:41
epoch [10/50] batch [100/403] time 0.069 (0.077) data 0.000 (0.005) loss 2.0540 (1.7905) teacher_loss 1.1381 (0.8923) loss_zs_kd 1.2939 (1.5411) loss_oracle 0.5374 (0.5188) acc 62.5000 (69.5000) lr 1.8763e-03 eta 0:21:01
epoch [10/50] batch [120/403] time 0.076 (0.076) data 0.000 (0.005) loss 1.9618 (1.7914) teacher_loss 1.0608 (0.8937) loss_zs_kd 1.5818 (1.5586) loss_oracle 0.5211 (0.5196) acc 65.6250 (69.0104) lr 1.8763e-03 eta 0:20:41
epoch [10/50] batch [140/403] time 0.066 (0.075) data 0.000 (0.004) loss 1.6627 (1.7938) teacher_loss 0.7191 (0.8956) loss_zs_kd 1.7246 (1.5573) loss_oracle 0.5412 (0.5202) acc 75.0000 (68.7277) lr 1.8763e-03 eta 0:20:25
epoch [10/50] batch [160/403] time 0.065 (0.074) data 0.000 (0.003) loss 2.3483 (1.7875) teacher_loss 1.4075 (0.8861) loss_zs_kd 1.5485 (1.5728) loss_oracle 0.5025 (0.5195) acc 50.0000 (69.2969) lr 1.8763e-03 eta 0:20:15
epoch [10/50] batch [180/403] time 0.065 (0.074) data 0.000 (0.003) loss 1.7596 (1.7793) teacher_loss 0.9567 (0.8783) loss_zs_kd 1.3053 (1.5738) loss_oracle 0.4761 (0.5181) acc 71.8750 (69.6354) lr 1.8763e-03 eta 0:20:04
epoch [10/50] batch [200/403] time 0.070 (0.074) data 0.000 (0.003) loss 1.6339 (1.7732) teacher_loss 0.7057 (0.8711) loss_zs_kd 1.3570 (1.5706) loss_oracle 0.4839 (0.5171) acc 71.8750 (70.2500) lr 1.8763e-03 eta 0:20:03
epoch [10/50] batch [220/403] time 0.068 (0.074) data 0.000 (0.003) loss 1.8140 (1.7779) teacher_loss 0.8045 (0.8701) loss_zs_kd 1.7170 (1.5603) loss_oracle 0.5635 (0.5184) acc 71.8750 (70.2557) lr 1.8763e-03 eta 0:19:59
epoch [10/50] batch [240/403] time 0.067 (0.075) data 0.000 (0.002) loss 2.0762 (1.7858) teacher_loss 1.0543 (0.8731) loss_zs_kd 2.0682 (1.5757) loss_oracle 0.5463 (0.5191) acc 62.5000 (70.2344) lr 1.8763e-03 eta 0:20:20
epoch [10/50] batch [260/403] time 0.080 (0.075) data 0.000 (0.002) loss 1.9004 (1.7975) teacher_loss 0.9698 (0.8791) loss_zs_kd 1.3680 (1.5784) loss_oracle 0.5018 (0.5194) acc 75.0000 (69.9639) lr 1.8763e-03 eta 0:20:19
epoch [10/50] batch [280/403] time 0.077 (0.075) data 0.000 (0.002) loss 2.1930 (1.8016) teacher_loss 1.2854 (0.8843) loss_zs_kd 1.7422 (1.5776) loss_oracle 0.5778 (0.5200) acc 56.2500 (69.7768) lr 1.8763e-03 eta 0:20:14
epoch [10/50] batch [300/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.7399 (1.8030) teacher_loss 0.8973 (0.8878) loss_zs_kd 1.3616 (1.5713) loss_oracle 0.5038 (0.5197) acc 65.6250 (69.5833) lr 1.8763e-03 eta 0:20:11
epoch [10/50] batch [320/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.8952 (1.8052) teacher_loss 0.9885 (0.8883) loss_zs_kd 1.5385 (1.5695) loss_oracle 0.5073 (0.5202) acc 56.2500 (69.3555) lr 1.8763e-03 eta 0:20:07
epoch [10/50] batch [340/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.7734 (1.8113) teacher_loss 0.8472 (0.8905) loss_zs_kd 1.4768 (1.5641) loss_oracle 0.4908 (0.5209) acc 71.8750 (69.1820) lr 1.8763e-03 eta 0:20:00
epoch [10/50] batch [360/403] time 0.077 (0.074) data 0.000 (0.002) loss 2.0061 (1.8200) teacher_loss 1.0864 (0.8965) loss_zs_kd 1.4084 (1.5568) loss_oracle 0.4982 (0.5219) acc 59.3750 (68.9497) lr 1.8763e-03 eta 0:19:57
epoch [10/50] batch [380/403] time 0.065 (0.074) data 0.000 (0.002) loss 1.6176 (1.8181) teacher_loss 0.7860 (0.8952) loss_zs_kd 1.5286 (1.5586) loss_oracle 0.5378 (0.5223) acc 71.8750 (68.9556) lr 1.8763e-03 eta 0:19:57
epoch [10/50] batch [400/403] time 0.067 (0.074) data 0.000 (0.002) loss 1.7092 (1.8112) teacher_loss 0.8943 (0.8910) loss_zs_kd 1.4530 (1.5579) loss_oracle 0.5051 (0.5219) acc 68.7500 (69.0859) lr 1.8763e-03 eta 0:19:51
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,852
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 54.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,464
* accuracy: 41.9%
* error: 58.1%
* macro_f1: 28.5%
******* Domain 4 best val acc:      69.6%, epoch: 10 *******
******* Domain 4 best val test acc: 41.9%, epoch: 10 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [11/50] batch [20/403] time 0.080 (0.114) data 0.000 (0.033) loss 1.7247 (1.7626) teacher_loss 0.8693 (0.9275) loss_zs_kd 1.6970 (1.5068) loss_oracle 0.5177 (0.5138) acc 68.7500 (67.5000) lr 1.8443e-03 eta 0:30:31
epoch [11/50] batch [40/403] time 0.068 (0.092) data 0.000 (0.017) loss 1.7697 (1.7414) teacher_loss 0.8159 (0.9053) loss_zs_kd 2.0909 (1.6324) loss_oracle 0.5474 (0.5120) acc 71.8750 (67.1875) lr 1.8443e-03 eta 0:24:36
epoch [11/50] batch [60/403] time 0.080 (0.085) data 0.001 (0.011) loss 2.0080 (1.7403) teacher_loss 1.1174 (0.9006) loss_zs_kd 1.6669 (1.6442) loss_oracle 0.5824 (0.5135) acc 68.7500 (68.3333) lr 1.8443e-03 eta 0:22:38
epoch [11/50] batch [80/403] time 0.075 (0.081) data 0.000 (0.008) loss 1.4734 (1.7312) teacher_loss 0.5995 (0.8811) loss_zs_kd 1.5279 (1.6443) loss_oracle 0.5399 (0.5207) acc 78.1250 (69.3359) lr 1.8443e-03 eta 0:21:46
epoch [11/50] batch [100/403] time 0.066 (0.079) data 0.000 (0.007) loss 1.7293 (1.7395) teacher_loss 0.7679 (0.8818) loss_zs_kd 1.8775 (1.6499) loss_oracle 0.5395 (0.5217) acc 68.7500 (69.1875) lr 1.8443e-03 eta 0:21:07
epoch [11/50] batch [120/403] time 0.064 (0.078) data 0.000 (0.006) loss 1.6450 (1.7438) teacher_loss 0.8150 (0.8800) loss_zs_kd 1.5462 (1.6487) loss_oracle 0.4539 (0.5213) acc 78.1250 (69.3490) lr 1.8443e-03 eta 0:20:44
epoch [11/50] batch [140/403] time 0.084 (0.078) data 0.001 (0.005) loss 1.7111 (1.7407) teacher_loss 0.8579 (0.8732) loss_zs_kd 1.9324 (1.6517) loss_oracle 0.4960 (0.5211) acc 65.6250 (69.5536) lr 1.8443e-03 eta 0:20:39
epoch [11/50] batch [160/403] time 0.068 (0.077) data 0.000 (0.004) loss 1.5804 (1.7329) teacher_loss 0.6560 (0.8664) loss_zs_kd 2.1144 (1.6473) loss_oracle 0.5417 (0.5207) acc 78.1250 (69.6289) lr 1.8443e-03 eta 0:20:23
epoch [11/50] batch [180/403] time 0.070 (0.076) data 0.000 (0.004) loss 1.9523 (1.7228) teacher_loss 1.1491 (0.8591) loss_zs_kd 1.5605 (1.6214) loss_oracle 0.5085 (0.5204) acc 53.1250 (69.8090) lr 1.8443e-03 eta 0:20:13
epoch [11/50] batch [200/403] time 0.066 (0.076) data 0.000 (0.004) loss 1.6687 (1.7162) teacher_loss 0.7519 (0.8517) loss_zs_kd 1.8347 (1.6245) loss_oracle 0.4697 (0.5200) acc 78.1250 (70.2656) lr 1.8443e-03 eta 0:20:12
epoch [11/50] batch [220/403] time 0.072 (0.076) data 0.000 (0.003) loss 1.6391 (1.7164) teacher_loss 0.7142 (0.8542) loss_zs_kd 1.4593 (1.6257) loss_oracle 0.4797 (0.5192) acc 71.8750 (70.1420) lr 1.8443e-03 eta 0:20:02
epoch [11/50] batch [240/403] time 0.063 (0.075) data 0.000 (0.003) loss 1.6889 (1.7160) teacher_loss 0.8764 (0.8507) loss_zs_kd 1.5778 (1.6305) loss_oracle 0.4468 (0.5193) acc 68.7500 (70.2995) lr 1.8443e-03 eta 0:19:58
epoch [11/50] batch [260/403] time 0.072 (0.075) data 0.000 (0.003) loss 2.2433 (1.7188) teacher_loss 1.2741 (0.8499) loss_zs_kd 1.3018 (1.6290) loss_oracle 0.5615 (0.5204) acc 62.5000 (70.4808) lr 1.8443e-03 eta 0:19:56
epoch [11/50] batch [280/403] time 0.071 (0.076) data 0.001 (0.003) loss 1.7141 (1.7252) teacher_loss 0.8294 (0.8546) loss_zs_kd 1.4583 (1.6177) loss_oracle 0.5246 (0.5190) acc 71.8750 (70.1116) lr 1.8443e-03 eta 0:20:01
epoch [11/50] batch [300/403] time 0.069 (0.076) data 0.000 (0.003) loss 1.5910 (1.7314) teacher_loss 0.6754 (0.8565) loss_zs_kd 1.7069 (1.6105) loss_oracle 0.5047 (0.5178) acc 75.0000 (70.0312) lr 1.8443e-03 eta 0:19:59
epoch [11/50] batch [320/403] time 0.072 (0.076) data 0.000 (0.002) loss 1.5981 (1.7362) teacher_loss 0.7009 (0.8583) loss_zs_kd 1.3006 (1.6076) loss_oracle 0.4371 (0.5185) acc 75.0000 (70.0195) lr 1.8443e-03 eta 0:19:53
epoch [11/50] batch [340/403] time 0.067 (0.075) data 0.000 (0.002) loss 1.5373 (1.7383) teacher_loss 0.6418 (0.8574) loss_zs_kd 1.8564 (1.6087) loss_oracle 0.5932 (0.5185) acc 81.2500 (70.0460) lr 1.8443e-03 eta 0:19:46
epoch [11/50] batch [360/403] time 0.076 (0.075) data 0.000 (0.002) loss 2.1554 (1.7487) teacher_loss 1.1764 (0.8617) loss_zs_kd 1.5188 (1.6090) loss_oracle 0.5408 (0.5188) acc 56.2500 (69.8872) lr 1.8443e-03 eta 0:19:43
epoch [11/50] batch [380/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.7766 (1.7581) teacher_loss 0.6405 (0.8629) loss_zs_kd 1.4603 (1.6053) loss_oracle 0.5402 (0.5183) acc 81.2500 (69.8273) lr 1.8443e-03 eta 0:19:37
epoch [11/50] batch [400/403] time 0.065 (0.075) data 0.000 (0.002) loss 2.1054 (1.7660) teacher_loss 1.0644 (0.8642) loss_zs_kd 1.5238 (1.5998) loss_oracle 0.5505 (0.5188) acc 59.3750 (69.8281) lr 1.8443e-03 eta 0:19:32
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,411
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 51.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,137
* accuracy: 36.3%
* error: 63.7%
* macro_f1: 24.7%
******* Domain 4 best val acc:      69.6%, epoch: 10 *******
******* Domain 4 best val test acc: 41.9%, epoch: 10 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [12/50] batch [20/403] time 0.073 (0.108) data 0.000 (0.032) loss 2.0437 (1.8543) teacher_loss 1.0442 (0.8342) loss_zs_kd 1.4163 (1.5503) loss_oracle 0.5450 (0.5344) acc 68.7500 (72.0312) lr 1.8090e-03 eta 0:28:11
epoch [12/50] batch [40/403] time 0.069 (0.090) data 0.000 (0.016) loss 1.9205 (1.8768) teacher_loss 0.9235 (0.8466) loss_zs_kd 1.4486 (1.6327) loss_oracle 0.5742 (0.5468) acc 68.7500 (71.2500) lr 1.8090e-03 eta 0:23:25
epoch [12/50] batch [60/403] time 0.078 (0.084) data 0.001 (0.011) loss 2.3281 (1.8595) teacher_loss 1.2786 (0.8272) loss_zs_kd 2.3101 (1.6228) loss_oracle 0.5788 (0.5530) acc 56.2500 (71.9792) lr 1.8090e-03 eta 0:21:51
epoch [12/50] batch [80/403] time 0.071 (0.081) data 0.000 (0.008) loss 1.9729 (1.8682) teacher_loss 1.0258 (0.8391) loss_zs_kd 1.6401 (1.6799) loss_oracle 0.5393 (0.5472) acc 59.3750 (71.7578) lr 1.8090e-03 eta 0:21:07
epoch [12/50] batch [100/403] time 0.072 (0.079) data 0.000 (0.007) loss 1.7289 (1.8555) teacher_loss 0.7227 (0.8365) loss_zs_kd 1.5630 (1.6641) loss_oracle 0.5658 (0.5443) acc 78.1250 (71.5000) lr 1.8090e-03 eta 0:20:35
epoch [12/50] batch [120/403] time 0.070 (0.078) data 0.000 (0.006) loss 1.9956 (1.8599) teacher_loss 1.0787 (0.8512) loss_zs_kd 1.6521 (1.6708) loss_oracle 0.5005 (0.5424) acc 75.0000 (71.1458) lr 1.8090e-03 eta 0:20:13
epoch [12/50] batch [140/403] time 0.071 (0.077) data 0.000 (0.005) loss 1.8427 (1.8467) teacher_loss 0.9402 (0.8546) loss_zs_kd 1.4968 (1.6640) loss_oracle 0.5161 (0.5425) acc 68.7500 (70.9598) lr 1.8090e-03 eta 0:20:01
epoch [12/50] batch [160/403] time 0.070 (0.077) data 0.000 (0.004) loss 1.6772 (1.8258) teacher_loss 0.7690 (0.8483) loss_zs_kd 1.8857 (1.6727) loss_oracle 0.5103 (0.5408) acc 75.0000 (71.0742) lr 1.8090e-03 eta 0:19:53
epoch [12/50] batch [180/403] time 0.079 (0.076) data 0.001 (0.004) loss 1.6833 (1.8217) teacher_loss 0.7609 (0.8532) loss_zs_kd 1.6623 (1.6845) loss_oracle 0.5412 (0.5399) acc 75.0000 (70.5903) lr 1.8090e-03 eta 0:19:43
epoch [12/50] batch [200/403] time 0.073 (0.076) data 0.000 (0.004) loss 1.3054 (1.8104) teacher_loss 0.4613 (0.8493) loss_zs_kd 1.3781 (1.6809) loss_oracle 0.5219 (0.5377) acc 87.5000 (70.6562) lr 1.8090e-03 eta 0:19:37
epoch [12/50] batch [220/403] time 0.087 (0.077) data 0.000 (0.003) loss 1.7920 (1.8032) teacher_loss 0.9309 (0.8481) loss_zs_kd 1.9669 (1.6741) loss_oracle 0.5091 (0.5350) acc 71.8750 (70.6534) lr 1.8090e-03 eta 0:19:54
epoch [12/50] batch [240/403] time 0.068 (0.077) data 0.000 (0.003) loss 1.5957 (1.8007) teacher_loss 0.8326 (0.8514) loss_zs_kd 2.2867 (1.6876) loss_oracle 0.5138 (0.5325) acc 65.6250 (70.4818) lr 1.8090e-03 eta 0:19:44
epoch [12/50] batch [260/403] time 0.070 (0.076) data 0.000 (0.003) loss 1.8335 (1.8008) teacher_loss 0.9897 (0.8597) loss_zs_kd 1.4204 (1.6796) loss_oracle 0.4772 (0.5304) acc 59.3750 (70.0962) lr 1.8090e-03 eta 0:19:36
epoch [12/50] batch [280/403] time 0.068 (0.076) data 0.000 (0.003) loss 1.5771 (1.7963) teacher_loss 0.8030 (0.8620) loss_zs_kd 2.0352 (1.6784) loss_oracle 0.4663 (0.5287) acc 75.0000 (69.9888) lr 1.8090e-03 eta 0:19:30
epoch [12/50] batch [300/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.5513 (1.7862) teacher_loss 0.7363 (0.8602) loss_zs_kd 1.6381 (1.6724) loss_oracle 0.5195 (0.5269) acc 71.8750 (70.0104) lr 1.8090e-03 eta 0:19:23
epoch [12/50] batch [320/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.5670 (1.7850) teacher_loss 0.7124 (0.8658) loss_zs_kd 1.3997 (1.6697) loss_oracle 0.5116 (0.5254) acc 71.8750 (69.7656) lr 1.8090e-03 eta 0:19:20
epoch [12/50] batch [340/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.6045 (1.7761) teacher_loss 0.7758 (0.8633) loss_zs_kd 1.4646 (1.6606) loss_oracle 0.5093 (0.5235) acc 71.8750 (69.8162) lr 1.8090e-03 eta 0:19:16
epoch [12/50] batch [360/403] time 0.066 (0.075) data 0.000 (0.002) loss 1.7167 (1.7707) teacher_loss 0.9110 (0.8628) loss_zs_kd 1.6874 (1.6617) loss_oracle 0.4427 (0.5214) acc 75.0000 (69.9306) lr 1.8090e-03 eta 0:19:12
epoch [12/50] batch [380/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.4926 (1.7626) teacher_loss 0.6434 (0.8595) loss_zs_kd 1.7325 (1.6615) loss_oracle 0.4380 (0.5191) acc 78.1250 (70.0576) lr 1.8090e-03 eta 0:19:08
epoch [12/50] batch [400/403] time 0.065 (0.075) data 0.000 (0.002) loss 1.7479 (1.7564) teacher_loss 0.8847 (0.8582) loss_zs_kd 1.9081 (1.6645) loss_oracle 0.4664 (0.5171) acc 75.0000 (70.1250) lr 1.8090e-03 eta 0:19:02
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,799
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 56.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,428
* accuracy: 41.3%
* error: 58.7%
* macro_f1: 27.9%
******* Domain 4 best val acc:      69.6%, epoch: 10 *******
******* Domain 4 best val test acc: 41.9%, epoch: 10 *******
******* Domain 4 best test acc:     42.3%, epoch: 7 *******
epoch [13/50] batch [20/403] time 0.067 (0.113) data 0.000 (0.033) loss 1.9429 (1.7298) teacher_loss 1.0602 (0.8805) loss_zs_kd 1.7213 (1.7097) loss_oracle 0.4265 (0.4871) acc 62.5000 (68.5938) lr 1.7705e-03 eta 0:28:47
epoch [13/50] batch [40/403] time 0.071 (0.091) data 0.000 (0.017) loss 1.7867 (1.7067) teacher_loss 0.9037 (0.8477) loss_zs_kd 1.4656 (1.7075) loss_oracle 0.5170 (0.4976) acc 65.6250 (70.1562) lr 1.7705e-03 eta 0:23:12
epoch [13/50] batch [60/403] time 0.080 (0.086) data 0.001 (0.011) loss 1.3122 (1.6913) teacher_loss 0.5904 (0.8440) loss_zs_kd 1.6967 (1.7214) loss_oracle 0.4650 (0.4950) acc 78.1250 (70.3646) lr 1.7705e-03 eta 0:21:46
epoch [13/50] batch [80/403] time 0.078 (0.083) data 0.000 (0.009) loss 1.1477 (1.6732) teacher_loss 0.3347 (0.8326) loss_zs_kd 1.7887 (1.7104) loss_oracle 0.4949 (0.4923) acc 96.8750 (70.8594) lr 1.7705e-03 eta 0:20:57
epoch [13/50] batch [100/403] time 0.081 (0.080) data 0.000 (0.007) loss 1.6150 (1.6655) teacher_loss 0.8575 (0.8253) loss_zs_kd 1.2121 (1.7104) loss_oracle 0.4916 (0.4891) acc 68.7500 (71.1562) lr 1.7705e-03 eta 0:20:21
epoch [13/50] batch [120/403] time 0.073 (0.079) data 0.000 (0.006) loss 1.6479 (1.6602) teacher_loss 0.7543 (0.8247) loss_zs_kd 1.5126 (1.7180) loss_oracle 0.5156 (0.4885) acc 78.1250 (71.8490) lr 1.7705e-03 eta 0:19:59
epoch [13/50] batch [140/403] time 0.069 (0.077) data 0.000 (0.005) loss 1.8647 (1.6539) teacher_loss 1.0663 (0.8243) loss_zs_kd 1.5357 (1.7233) loss_oracle 0.4522 (0.4877) acc 59.3750 (71.8527) lr 1.7705e-03 eta 0:19:33
epoch [13/50] batch [160/403] time 0.078 (0.077) data 0.000 (0.004) loss 1.5459 (1.6451) teacher_loss 0.7536 (0.8203) loss_zs_kd 2.1874 (1.7195) loss_oracle 0.4816 (0.4844) acc 75.0000 (71.9531) lr 1.7705e-03 eta 0:19:24
epoch [13/50] batch [180/403] time 0.074 (0.076) data 0.000 (0.004) loss 1.3374 (1.6364) teacher_loss 0.5781 (0.8174) loss_zs_kd 1.8613 (1.7459) loss_oracle 0.4827 (0.4827) acc 81.2500 (71.9618) lr 1.7705e-03 eta 0:19:15
epoch [13/50] batch [200/403] time 0.074 (0.076) data 0.000 (0.004) loss 1.6146 (1.6377) teacher_loss 0.7482 (0.8154) loss_zs_kd 1.8040 (1.7484) loss_oracle 0.4905 (0.4826) acc 75.0000 (72.1406) lr 1.7705e-03 eta 0:19:09
epoch [13/50] batch [220/403] time 0.070 (0.076) data 0.000 (0.003) loss 1.7035 (1.6391) teacher_loss 0.8138 (0.8189) loss_zs_kd 1.1423 (1.7401) loss_oracle 0.5061 (0.4809) acc 71.8750 (71.8182) lr 1.7705e-03 eta 0:19:04
epoch [13/50] batch [240/403] time 0.071 (0.076) data 0.000 (0.003) loss 1.7597 (1.6352) teacher_loss 0.9469 (0.8175) loss_zs_kd 2.1727 (1.7310) loss_oracle 0.4501 (0.4797) acc 75.0000 (71.7057) lr 1.7705e-03 eta 0:18:58
epoch [13/50] batch [260/403] time 0.074 (0.075) data 0.000 (0.003) loss 1.4887 (1.6306) teacher_loss 0.7113 (0.8176) loss_zs_kd 1.8280 (1.7216) loss_oracle 0.4014 (0.4774) acc 75.0000 (71.7548) lr 1.7705e-03 eta 0:18:55
epoch [13/50] batch [280/403] time 0.079 (0.075) data 0.000 (0.003) loss 1.5539 (1.6288) teacher_loss 0.8301 (0.8188) loss_zs_kd 1.8936 (1.7163) loss_oracle 0.4331 (0.4750) acc 65.6250 (71.6629) lr 1.7705e-03 eta 0:18:52
epoch [13/50] batch [300/403] time 0.071 (0.075) data 0.000 (0.003) loss 1.6354 (1.6305) teacher_loss 0.7516 (0.8203) loss_zs_kd 1.4896 (1.7018) loss_oracle 0.5258 (0.4743) acc 81.2500 (71.6667) lr 1.7705e-03 eta 0:18:48
epoch [13/50] batch [320/403] time 0.071 (0.075) data 0.000 (0.002) loss 1.5955 (1.6327) teacher_loss 0.8396 (0.8220) loss_zs_kd 1.6043 (1.6962) loss_oracle 0.4522 (0.4746) acc 65.6250 (71.5820) lr 1.7705e-03 eta 0:18:44
epoch [13/50] batch [340/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.5000 (1.6295) teacher_loss 0.7493 (0.8182) loss_zs_kd 1.6113 (1.6907) loss_oracle 0.4698 (0.4752) acc 68.7500 (71.7647) lr 1.7705e-03 eta 0:18:40
epoch [13/50] batch [360/403] time 0.077 (0.075) data 0.000 (0.002) loss 1.5185 (1.6268) teacher_loss 0.7458 (0.8154) loss_zs_kd 1.4474 (1.6848) loss_oracle 0.4573 (0.4753) acc 68.7500 (71.7882) lr 1.7705e-03 eta 0:18:38
epoch [13/50] batch [380/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.7931 (1.6266) teacher_loss 0.9293 (0.8141) loss_zs_kd 1.7112 (1.6893) loss_oracle 0.5220 (0.4762) acc 62.5000 (71.7845) lr 1.7705e-03 eta 0:18:35
epoch [13/50] batch [400/403] time 0.067 (0.075) data 0.000 (0.002) loss 1.7526 (1.6301) teacher_loss 0.8611 (0.8161) loss_zs_kd 1.9270 (1.6985) loss_oracle 0.5994 (0.4771) acc 71.8750 (71.6719) lr 1.7705e-03 eta 0:18:31
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,818
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 54.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,769
* accuracy: 47.1%
* error: 52.9%
* macro_f1: 34.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      69.6%, epoch: 10 *******
******* Domain 4 best val test acc: 41.9%, epoch: 10 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [14/50] batch [20/403] time 0.076 (0.088) data 0.000 (0.024) loss 1.5756 (1.7472) teacher_loss 0.8653 (0.8898) loss_zs_kd 1.1661 (1.7161) loss_oracle 0.4121 (0.4815) acc 62.5000 (69.5312) lr 1.7290e-03 eta 0:21:45
epoch [14/50] batch [40/403] time 0.064 (0.081) data 0.000 (0.012) loss 1.4884 (1.7320) teacher_loss 0.6638 (0.8738) loss_zs_kd 1.5310 (1.6640) loss_oracle 0.4752 (0.4713) acc 75.0000 (69.6094) lr 1.7290e-03 eta 0:20:02
epoch [14/50] batch [60/403] time 0.065 (0.078) data 0.000 (0.008) loss 1.3694 (1.6994) teacher_loss 0.7331 (0.8611) loss_zs_kd 1.4917 (1.6326) loss_oracle 0.3899 (0.4616) acc 81.2500 (69.7917) lr 1.7290e-03 eta 0:19:17
epoch [14/50] batch [80/403] time 0.073 (0.077) data 0.000 (0.006) loss 1.5909 (1.7148) teacher_loss 0.7747 (0.8730) loss_zs_kd 1.7627 (1.6806) loss_oracle 0.4386 (0.4595) acc 68.7500 (69.4922) lr 1.7290e-03 eta 0:19:01
epoch [14/50] batch [100/403] time 0.068 (0.076) data 0.000 (0.005) loss 1.4352 (1.7144) teacher_loss 0.6474 (0.8768) loss_zs_kd 1.8477 (1.6686) loss_oracle 0.4850 (0.4584) acc 81.2500 (69.8438) lr 1.7290e-03 eta 0:18:40
epoch [14/50] batch [120/403] time 0.064 (0.074) data 0.000 (0.004) loss 1.9305 (1.7110) teacher_loss 1.0779 (0.8736) loss_zs_kd 1.5911 (1.6552) loss_oracle 0.5003 (0.4556) acc 53.1250 (69.5573) lr 1.7290e-03 eta 0:18:18
epoch [14/50] batch [140/403] time 0.077 (0.074) data 0.000 (0.004) loss 1.7632 (1.7111) teacher_loss 1.0479 (0.8695) loss_zs_kd 1.4280 (1.6434) loss_oracle 0.4108 (0.4562) acc 62.5000 (69.5312) lr 1.7290e-03 eta 0:18:14
epoch [14/50] batch [160/403] time 0.064 (0.074) data 0.000 (0.003) loss 1.6179 (1.7185) teacher_loss 0.7683 (0.8744) loss_zs_kd 1.5101 (1.6503) loss_oracle 0.4810 (0.4592) acc 75.0000 (69.2578) lr 1.7290e-03 eta 0:18:06
epoch [14/50] batch [180/403] time 0.062 (0.074) data 0.000 (0.003) loss 1.8050 (1.7247) teacher_loss 0.9417 (0.8761) loss_zs_kd 1.5106 (1.6445) loss_oracle 0.4738 (0.4616) acc 65.6250 (69.4271) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [200/403] time 0.075 (0.073) data 0.000 (0.003) loss 1.8382 (1.7259) teacher_loss 0.9611 (0.8753) loss_zs_kd 1.4496 (1.6434) loss_oracle 0.4559 (0.4628) acc 68.7500 (69.3750) lr 1.7290e-03 eta 0:17:57
epoch [14/50] batch [220/403] time 0.073 (0.073) data 0.000 (0.003) loss 1.4857 (1.7123) teacher_loss 0.6465 (0.8652) loss_zs_kd 1.3310 (1.6381) loss_oracle 0.4102 (0.4619) acc 75.0000 (69.6165) lr 1.7290e-03 eta 0:17:55
epoch [14/50] batch [240/403] time 0.078 (0.074) data 0.000 (0.002) loss 1.5534 (1.7127) teacher_loss 0.5912 (0.8627) loss_zs_kd 1.9690 (1.6365) loss_oracle 0.4462 (0.4599) acc 78.1250 (69.7396) lr 1.7290e-03 eta 0:18:10
epoch [14/50] batch [260/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.8623 (1.7174) teacher_loss 1.0204 (0.8643) loss_zs_kd 1.5415 (1.6377) loss_oracle 0.4536 (0.4593) acc 56.2500 (69.7476) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [280/403] time 0.076 (0.074) data 0.000 (0.002) loss 1.6868 (1.7177) teacher_loss 0.8120 (0.8654) loss_zs_kd 1.6482 (1.6483) loss_oracle 0.4723 (0.4581) acc 75.0000 (69.8214) lr 1.7290e-03 eta 0:18:00
epoch [14/50] batch [300/403] time 0.066 (0.074) data 0.000 (0.002) loss 1.4342 (1.7117) teacher_loss 0.6814 (0.8608) loss_zs_kd 1.3185 (1.6502) loss_oracle 0.4102 (0.4571) acc 71.8750 (70.0312) lr 1.7290e-03 eta 0:17:57
epoch [14/50] batch [320/403] time 0.081 (0.074) data 0.000 (0.002) loss 1.5297 (1.7089) teacher_loss 0.8046 (0.8618) loss_zs_kd 1.4113 (1.6498) loss_oracle 0.4008 (0.4557) acc 71.8750 (70.0488) lr 1.7290e-03 eta 0:17:56
epoch [14/50] batch [340/403] time 0.078 (0.074) data 0.000 (0.002) loss 1.7071 (1.7024) teacher_loss 0.8699 (0.8595) loss_zs_kd 1.6973 (1.6495) loss_oracle 0.4492 (0.4553) acc 65.6250 (70.1195) lr 1.7290e-03 eta 0:17:54
epoch [14/50] batch [360/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.6146 (1.6991) teacher_loss 0.7773 (0.8569) loss_zs_kd 1.1150 (1.6492) loss_oracle 0.4127 (0.4544) acc 75.0000 (70.2517) lr 1.7290e-03 eta 0:17:52
epoch [14/50] batch [380/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.6934 (1.6987) teacher_loss 0.8576 (0.8563) loss_zs_kd 1.4771 (1.6438) loss_oracle 0.4469 (0.4535) acc 75.0000 (70.2961) lr 1.7290e-03 eta 0:17:48
epoch [14/50] batch [400/403] time 0.063 (0.073) data 0.000 (0.002) loss 1.7739 (1.6992) teacher_loss 0.9317 (0.8575) loss_zs_kd 1.2749 (1.6373) loss_oracle 0.4456 (0.4532) acc 65.6250 (70.2422) lr 1.7290e-03 eta 0:17:42
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,875
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 57.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,689
* accuracy: 45.7%
* error: 54.3%
* macro_f1: 32.3%
******* Domain 4 best val acc:      70.0%, epoch: 14 *******
******* Domain 4 best val test acc: 45.7%, epoch: 14 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [15/50] batch [20/403] time 0.058 (0.115) data 0.000 (0.028) loss 1.7364 (1.7276) teacher_loss 0.7899 (0.8552) loss_zs_kd 1.5962 (1.6043) loss_oracle 0.4558 (0.4574) acc 75.0000 (70.6250) lr 1.6845e-03 eta 0:27:40
epoch [15/50] batch [40/403] time 0.069 (0.090) data 0.000 (0.014) loss 1.3910 (1.7141) teacher_loss 0.7343 (0.8651) loss_zs_kd 1.1719 (1.5908) loss_oracle 0.4412 (0.4552) acc 71.8750 (70.3125) lr 1.6845e-03 eta 0:21:40
epoch [15/50] batch [60/403] time 0.071 (0.085) data 0.001 (0.010) loss 1.5924 (1.7156) teacher_loss 0.7125 (0.8762) loss_zs_kd 1.8385 (1.5939) loss_oracle 0.4697 (0.4499) acc 75.0000 (69.4792) lr 1.6845e-03 eta 0:20:23
epoch [15/50] batch [80/403] time 0.072 (0.082) data 0.000 (0.007) loss 1.5347 (1.6853) teacher_loss 0.7257 (0.8592) loss_zs_kd 1.5997 (1.6020) loss_oracle 0.4312 (0.4453) acc 81.2500 (70.7031) lr 1.6845e-03 eta 0:19:45
epoch [15/50] batch [100/403] time 0.073 (0.080) data 0.000 (0.006) loss 1.6568 (1.6646) teacher_loss 0.7826 (0.8428) loss_zs_kd 2.0821 (1.6178) loss_oracle 0.4417 (0.4435) acc 71.8750 (71.3438) lr 1.6845e-03 eta 0:19:14
epoch [15/50] batch [120/403] time 0.083 (0.079) data 0.000 (0.005) loss 1.4582 (1.6495) teacher_loss 0.6189 (0.8312) loss_zs_kd 2.1020 (1.6528) loss_oracle 0.4697 (0.4438) acc 81.2500 (72.0573) lr 1.6845e-03 eta 0:18:52
epoch [15/50] batch [140/403] time 0.071 (0.078) data 0.000 (0.004) loss 1.7528 (1.6457) teacher_loss 0.9280 (0.8298) loss_zs_kd 1.5862 (1.6663) loss_oracle 0.4233 (0.4429) acc 71.8750 (72.2321) lr 1.6845e-03 eta 0:18:40
epoch [15/50] batch [160/403] time 0.081 (0.077) data 0.000 (0.004) loss 1.7428 (1.6464) teacher_loss 0.7557 (0.8278) loss_zs_kd 1.8312 (1.6875) loss_oracle 0.5103 (0.4441) acc 81.2500 (72.2461) lr 1.6845e-03 eta 0:18:31
epoch [15/50] batch [180/403] time 0.067 (0.077) data 0.000 (0.003) loss 1.6258 (1.6461) teacher_loss 0.7318 (0.8228) loss_zs_kd 1.6609 (1.7031) loss_oracle 0.4469 (0.4460) acc 71.8750 (72.1701) lr 1.6845e-03 eta 0:18:25
epoch [15/50] batch [200/403] time 0.070 (0.077) data 0.000 (0.003) loss 1.3506 (1.6503) teacher_loss 0.4951 (0.8221) loss_zs_kd 1.3704 (1.7049) loss_oracle 0.4536 (0.4472) acc 87.5000 (72.0781) lr 1.6845e-03 eta 0:18:16
epoch [15/50] batch [220/403] time 0.069 (0.076) data 0.000 (0.003) loss 1.9701 (1.6389) teacher_loss 1.2070 (0.8121) loss_zs_kd 1.9112 (1.7172) loss_oracle 0.4658 (0.4488) acc 56.2500 (72.3580) lr 1.6845e-03 eta 0:18:09
epoch [15/50] batch [240/403] time 0.069 (0.076) data 0.000 (0.003) loss 1.8213 (1.6426) teacher_loss 1.0580 (0.8183) loss_zs_kd 1.3259 (1.7133) loss_oracle 0.4109 (0.4479) acc 62.5000 (72.1224) lr 1.6845e-03 eta 0:18:03
epoch [15/50] batch [260/403] time 0.074 (0.076) data 0.000 (0.002) loss 1.7067 (1.6483) teacher_loss 0.7781 (0.8205) loss_zs_kd 1.4409 (1.7054) loss_oracle 0.4596 (0.4475) acc 68.7500 (71.9231) lr 1.6845e-03 eta 0:17:57
epoch [15/50] batch [280/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.8539 (1.6498) teacher_loss 1.0211 (0.8193) loss_zs_kd 1.6498 (1.6884) loss_oracle 0.4088 (0.4456) acc 59.3750 (71.9866) lr 1.6845e-03 eta 0:17:47
epoch [15/50] batch [300/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.9752 (1.6569) teacher_loss 1.0785 (0.8247) loss_zs_kd 1.6176 (1.6861) loss_oracle 0.5134 (0.4464) acc 62.5000 (71.6771) lr 1.6845e-03 eta 0:17:42
epoch [15/50] batch [320/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.6621 (1.6575) teacher_loss 0.8254 (0.8274) loss_zs_kd 1.6694 (1.6776) loss_oracle 0.4155 (0.4463) acc 68.7500 (71.5820) lr 1.6845e-03 eta 0:17:40
epoch [15/50] batch [340/403] time 0.077 (0.075) data 0.000 (0.002) loss 1.8007 (1.6597) teacher_loss 0.9161 (0.8315) loss_zs_kd 1.5261 (1.6729) loss_oracle 0.4355 (0.4463) acc 68.7500 (71.4522) lr 1.6845e-03 eta 0:17:37
epoch [15/50] batch [360/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.6080 (1.6590) teacher_loss 0.6625 (0.8305) loss_zs_kd 1.6569 (1.6696) loss_oracle 0.4413 (0.4460) acc 84.3750 (71.5104) lr 1.6845e-03 eta 0:17:34
epoch [15/50] batch [380/403] time 0.079 (0.074) data 0.001 (0.002) loss 1.6926 (1.6658) teacher_loss 0.8872 (0.8347) loss_zs_kd 1.3723 (1.6677) loss_oracle 0.4411 (0.4461) acc 75.0000 (71.3980) lr 1.6845e-03 eta 0:17:30
epoch [15/50] batch [400/403] time 0.060 (0.074) data 0.000 (0.002) loss 1.4665 (1.6622) teacher_loss 0.6147 (0.8323) loss_zs_kd 1.3001 (1.6582) loss_oracle 0.4272 (0.4451) acc 78.1250 (71.5391) lr 1.6845e-03 eta 0:17:23
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,866
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 57.0%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,718
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 32.8%
******* Domain 4 best val acc:      70.0%, epoch: 14 *******
******* Domain 4 best val test acc: 45.7%, epoch: 14 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [16/50] batch [20/403] time 0.062 (0.088) data 0.000 (0.028) loss 1.8416 (1.8391) teacher_loss 0.8573 (0.9190) loss_zs_kd 1.6602 (1.7598) loss_oracle 0.4376 (0.4516) acc 75.0000 (68.9062) lr 1.6374e-03 eta 0:20:40
epoch [16/50] batch [40/403] time 0.077 (0.080) data 0.000 (0.014) loss 1.7725 (1.8074) teacher_loss 1.0000 (0.8947) loss_zs_kd 1.8722 (1.7423) loss_oracle 0.3978 (0.4570) acc 75.0000 (69.2969) lr 1.6374e-03 eta 0:18:46
epoch [16/50] batch [60/403] time 0.073 (0.077) data 0.001 (0.010) loss 1.6889 (1.7832) teacher_loss 0.9459 (0.9015) loss_zs_kd 1.3613 (1.6795) loss_oracle 0.4663 (0.4544) acc 68.7500 (68.6979) lr 1.6374e-03 eta 0:18:01
epoch [16/50] batch [80/403] time 0.077 (0.076) data 0.000 (0.007) loss 1.9216 (1.7709) teacher_loss 0.9605 (0.8984) loss_zs_kd 1.6817 (1.6691) loss_oracle 0.4522 (0.4593) acc 59.3750 (68.9844) lr 1.6374e-03 eta 0:17:50
epoch [16/50] batch [100/403] time 0.073 (0.075) data 0.000 (0.006) loss 1.6222 (1.7389) teacher_loss 0.8263 (0.8777) loss_zs_kd 1.4415 (1.6884) loss_oracle 0.3862 (0.4546) acc 71.8750 (69.9688) lr 1.6374e-03 eta 0:17:37
epoch [16/50] batch [120/403] time 0.069 (0.075) data 0.000 (0.005) loss 1.4912 (1.7116) teacher_loss 0.7895 (0.8603) loss_zs_kd 1.5772 (1.6648) loss_oracle 0.3844 (0.4512) acc 71.8750 (70.5469) lr 1.6374e-03 eta 0:17:25
epoch [16/50] batch [140/403] time 0.075 (0.074) data 0.000 (0.004) loss 1.7694 (1.6925) teacher_loss 0.9641 (0.8481) loss_zs_kd 2.0052 (1.6755) loss_oracle 0.4187 (0.4508) acc 75.0000 (71.0714) lr 1.6374e-03 eta 0:17:19
epoch [16/50] batch [160/403] time 0.069 (0.074) data 0.000 (0.004) loss 1.9046 (1.6707) teacher_loss 1.1012 (0.8306) loss_zs_kd 1.7478 (1.6841) loss_oracle 0.4178 (0.4480) acc 71.8750 (71.4062) lr 1.6374e-03 eta 0:17:17
epoch [16/50] batch [180/403] time 0.069 (0.074) data 0.000 (0.003) loss 1.6639 (1.6590) teacher_loss 0.8089 (0.8286) loss_zs_kd 1.7507 (1.6932) loss_oracle 0.4386 (0.4472) acc 71.8750 (71.6840) lr 1.6374e-03 eta 0:17:13
epoch [16/50] batch [200/403] time 0.070 (0.074) data 0.000 (0.003) loss 2.1038 (1.6609) teacher_loss 1.1628 (0.8343) loss_zs_kd 1.6480 (1.6820) loss_oracle 0.4804 (0.4450) acc 56.2500 (71.3906) lr 1.6374e-03 eta 0:17:08
epoch [16/50] batch [220/403] time 0.078 (0.074) data 0.001 (0.003) loss 1.9242 (1.6525) teacher_loss 1.0380 (0.8284) loss_zs_kd 1.3993 (1.6670) loss_oracle 0.4371 (0.4433) acc 59.3750 (71.4631) lr 1.6374e-03 eta 0:17:03
epoch [16/50] batch [240/403] time 0.069 (0.073) data 0.000 (0.003) loss 1.3070 (1.6503) teacher_loss 0.5127 (0.8247) loss_zs_kd 1.9334 (1.6691) loss_oracle 0.4811 (0.4432) acc 81.2500 (71.6927) lr 1.6374e-03 eta 0:16:58
epoch [16/50] batch [260/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.5755 (1.6557) teacher_loss 0.7666 (0.8273) loss_zs_kd 1.9228 (1.6659) loss_oracle 0.4421 (0.4441) acc 71.8750 (71.5264) lr 1.6374e-03 eta 0:17:14
epoch [16/50] batch [280/403] time 0.075 (0.075) data 0.001 (0.002) loss 1.8589 (1.6554) teacher_loss 1.0783 (0.8266) loss_zs_kd 1.6103 (1.6629) loss_oracle 0.4288 (0.4451) acc 56.2500 (71.4955) lr 1.6374e-03 eta 0:17:10
epoch [16/50] batch [300/403] time 0.071 (0.074) data 0.000 (0.002) loss 1.6727 (1.6483) teacher_loss 0.8787 (0.8212) loss_zs_kd 1.6158 (1.6664) loss_oracle 0.3959 (0.4451) acc 68.7500 (71.6562) lr 1.6374e-03 eta 0:17:04
epoch [16/50] batch [320/403] time 0.068 (0.074) data 0.000 (0.002) loss 1.1793 (1.6407) teacher_loss 0.4948 (0.8164) loss_zs_kd 1.6470 (1.6642) loss_oracle 0.4340 (0.4446) acc 81.2500 (71.8457) lr 1.6374e-03 eta 0:17:03
epoch [16/50] batch [340/403] time 0.077 (0.074) data 0.000 (0.002) loss 1.7898 (1.6377) teacher_loss 1.0080 (0.8168) loss_zs_kd 1.7458 (1.6629) loss_oracle 0.5008 (0.4433) acc 62.5000 (71.8474) lr 1.6374e-03 eta 0:17:00
epoch [16/50] batch [360/403] time 0.077 (0.074) data 0.000 (0.002) loss 1.5850 (1.6315) teacher_loss 0.7673 (0.8137) loss_zs_kd 1.5698 (1.6653) loss_oracle 0.4891 (0.4426) acc 71.8750 (71.9965) lr 1.6374e-03 eta 0:16:58
epoch [16/50] batch [380/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.8171 (1.6302) teacher_loss 0.9616 (0.8123) loss_zs_kd 1.5648 (1.6639) loss_oracle 0.5001 (0.4428) acc 71.8750 (72.0312) lr 1.6374e-03 eta 0:16:56
epoch [16/50] batch [400/403] time 0.063 (0.074) data 0.000 (0.002) loss 2.1228 (1.6332) teacher_loss 1.0855 (0.8133) loss_zs_kd 2.0978 (1.6617) loss_oracle 0.4697 (0.4429) acc 59.3750 (72.0312) lr 1.6374e-03 eta 0:16:50
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,889
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,688
* accuracy: 45.7%
* error: 54.3%
* macro_f1: 31.7%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [17/50] batch [20/403] time 0.076 (0.102) data 0.000 (0.030) loss 2.0257 (1.7184) teacher_loss 1.0727 (0.8312) loss_zs_kd 1.4519 (1.7456) loss_oracle 0.4420 (0.4475) acc 62.5000 (70.0000) lr 1.5878e-03 eta 0:23:17
epoch [17/50] batch [40/403] time 0.072 (0.097) data 0.000 (0.015) loss 1.8809 (1.7171) teacher_loss 1.0883 (0.8206) loss_zs_kd 1.7719 (1.6764) loss_oracle 0.3823 (0.4460) acc 68.7500 (71.2500) lr 1.5878e-03 eta 0:22:06
epoch [17/50] batch [60/403] time 0.072 (0.089) data 0.001 (0.010) loss 1.6432 (1.7230) teacher_loss 0.7382 (0.8184) loss_zs_kd 1.7016 (1.7353) loss_oracle 0.4296 (0.4507) acc 75.0000 (71.3542) lr 1.5878e-03 eta 0:20:19
epoch [17/50] batch [80/403] time 0.071 (0.085) data 0.000 (0.008) loss 1.5834 (1.7253) teacher_loss 0.7755 (0.8220) loss_zs_kd 1.7250 (1.7350) loss_oracle 0.3889 (0.4515) acc 78.1250 (71.7188) lr 1.5878e-03 eta 0:19:23
epoch [17/50] batch [100/403] time 0.071 (0.082) data 0.000 (0.006) loss 1.6437 (1.7222) teacher_loss 0.8268 (0.8264) loss_zs_kd 2.0640 (1.7470) loss_oracle 0.4777 (0.4472) acc 62.5000 (71.5312) lr 1.5878e-03 eta 0:18:32
epoch [17/50] batch [120/403] time 0.067 (0.079) data 0.000 (0.005) loss 1.6702 (1.7228) teacher_loss 0.7815 (0.8268) loss_zs_kd 1.6290 (1.7620) loss_oracle 0.4461 (0.4486) acc 71.8750 (71.4062) lr 1.5878e-03 eta 0:17:58
epoch [17/50] batch [140/403] time 0.072 (0.078) data 0.000 (0.005) loss 1.7727 (1.7110) teacher_loss 0.9007 (0.8224) loss_zs_kd 1.5104 (1.7607) loss_oracle 0.3991 (0.4507) acc 65.6250 (71.5848) lr 1.5878e-03 eta 0:17:40
epoch [17/50] batch [160/403] time 0.071 (0.077) data 0.001 (0.004) loss 1.7395 (1.7013) teacher_loss 0.8936 (0.8240) loss_zs_kd 1.6001 (1.7414) loss_oracle 0.4287 (0.4500) acc 68.7500 (71.4453) lr 1.5878e-03 eta 0:17:26
epoch [17/50] batch [180/403] time 0.070 (0.077) data 0.000 (0.004) loss 1.6559 (1.6903) teacher_loss 0.9786 (0.8217) loss_zs_kd 1.6542 (1.7375) loss_oracle 0.4525 (0.4477) acc 68.7500 (71.5104) lr 1.5878e-03 eta 0:17:14
epoch [17/50] batch [200/403] time 0.071 (0.076) data 0.000 (0.003) loss 1.6577 (1.6917) teacher_loss 0.8475 (0.8225) loss_zs_kd 1.2183 (1.7353) loss_oracle 0.4353 (0.4472) acc 75.0000 (71.5000) lr 1.5878e-03 eta 0:17:05
epoch [17/50] batch [220/403] time 0.080 (0.076) data 0.000 (0.003) loss 1.7613 (1.6948) teacher_loss 0.9593 (0.8274) loss_zs_kd 1.7547 (1.7313) loss_oracle 0.4572 (0.4475) acc 75.0000 (71.3068) lr 1.5878e-03 eta 0:17:01
epoch [17/50] batch [240/403] time 0.076 (0.076) data 0.000 (0.003) loss 1.7544 (1.6968) teacher_loss 0.9637 (0.8278) loss_zs_kd 1.3292 (1.7257) loss_oracle 0.3908 (0.4472) acc 68.7500 (71.3411) lr 1.5878e-03 eta 0:16:57
epoch [17/50] batch [260/403] time 0.072 (0.075) data 0.000 (0.003) loss 1.4650 (1.6995) teacher_loss 0.6750 (0.8298) loss_zs_kd 1.8839 (1.7125) loss_oracle 0.4069 (0.4458) acc 68.7500 (71.1058) lr 1.5878e-03 eta 0:16:49
epoch [17/50] batch [280/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.6394 (1.6937) teacher_loss 0.8418 (0.8266) loss_zs_kd 1.6780 (1.7148) loss_oracle 0.4314 (0.4457) acc 68.7500 (71.3504) lr 1.5878e-03 eta 0:16:48
epoch [17/50] batch [300/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.5912 (1.6899) teacher_loss 0.7950 (0.8278) loss_zs_kd 1.6662 (1.7111) loss_oracle 0.4663 (0.4452) acc 71.8750 (71.2604) lr 1.5878e-03 eta 0:16:43
epoch [17/50] batch [320/403] time 0.065 (0.075) data 0.000 (0.002) loss 1.5751 (1.6843) teacher_loss 0.7229 (0.8246) loss_zs_kd 1.5164 (1.7057) loss_oracle 0.4276 (0.4450) acc 81.2500 (71.4062) lr 1.5878e-03 eta 0:16:37
epoch [17/50] batch [340/403] time 0.077 (0.074) data 0.000 (0.002) loss 1.6784 (1.6795) teacher_loss 0.8655 (0.8218) loss_zs_kd 1.6649 (1.6985) loss_oracle 0.3858 (0.4439) acc 75.0000 (71.5809) lr 1.5878e-03 eta 0:16:34
epoch [17/50] batch [360/403] time 0.075 (0.074) data 0.000 (0.002) loss 1.5267 (1.6800) teacher_loss 0.6503 (0.8219) loss_zs_kd 2.4473 (1.7031) loss_oracle 0.4695 (0.4433) acc 75.0000 (71.5972) lr 1.5878e-03 eta 0:16:31
epoch [17/50] batch [380/403] time 0.071 (0.074) data 0.000 (0.002) loss 1.7288 (1.6839) teacher_loss 0.7002 (0.8221) loss_zs_kd 2.0478 (1.7070) loss_oracle 0.4766 (0.4430) acc 75.0000 (71.5707) lr 1.5878e-03 eta 0:16:27
epoch [17/50] batch [400/403] time 0.062 (0.074) data 0.000 (0.002) loss 1.4874 (1.6869) teacher_loss 0.7008 (0.8218) loss_zs_kd 1.6984 (1.7101) loss_oracle 0.4481 (0.4434) acc 78.1250 (71.5000) lr 1.5878e-03 eta 0:16:22
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,856
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 54.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,399
* accuracy: 40.8%
* error: 59.2%
* macro_f1: 28.4%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [18/50] batch [20/403] time 0.077 (0.098) data 0.000 (0.024) loss 1.3377 (1.6538) teacher_loss 0.6203 (0.8355) loss_zs_kd 1.7249 (1.6930) loss_oracle 0.4250 (0.4408) acc 81.2500 (70.7812) lr 1.5358e-03 eta 0:21:40
epoch [18/50] batch [40/403] time 0.071 (0.084) data 0.000 (0.012) loss 1.4979 (1.6376) teacher_loss 0.6751 (0.8228) loss_zs_kd 2.2435 (1.7372) loss_oracle 0.4456 (0.4425) acc 75.0000 (71.6406) lr 1.5358e-03 eta 0:18:31
epoch [18/50] batch [60/403] time 0.086 (0.080) data 0.000 (0.008) loss 1.6536 (1.6419) teacher_loss 0.7254 (0.8226) loss_zs_kd 1.8598 (1.7415) loss_oracle 0.4653 (0.4446) acc 65.6250 (70.8333) lr 1.5358e-03 eta 0:17:41
epoch [18/50] batch [80/403] time 0.077 (0.078) data 0.000 (0.006) loss 1.4788 (1.6509) teacher_loss 0.6793 (0.8145) loss_zs_kd 1.6464 (1.7295) loss_oracle 0.4821 (0.4473) acc 78.1250 (71.2500) lr 1.5358e-03 eta 0:17:16
epoch [18/50] batch [100/403] time 0.069 (0.077) data 0.000 (0.005) loss 1.7802 (1.6786) teacher_loss 0.7548 (0.8214) loss_zs_kd 1.5853 (1.7132) loss_oracle 0.4778 (0.4490) acc 62.5000 (70.8750) lr 1.5358e-03 eta 0:16:53
epoch [18/50] batch [120/403] time 0.071 (0.076) data 0.000 (0.004) loss 1.8346 (1.7048) teacher_loss 1.0231 (0.8353) loss_zs_kd 1.2581 (1.7147) loss_oracle 0.3957 (0.4480) acc 68.7500 (70.5469) lr 1.5358e-03 eta 0:16:38
epoch [18/50] batch [140/403] time 0.069 (0.075) data 0.000 (0.004) loss 2.0201 (1.7109) teacher_loss 1.1554 (0.8347) loss_zs_kd 1.9764 (1.7064) loss_oracle 0.4558 (0.4469) acc 65.6250 (71.0268) lr 1.5358e-03 eta 0:16:29
epoch [18/50] batch [160/403] time 0.069 (0.075) data 0.000 (0.003) loss 1.6773 (1.7137) teacher_loss 0.8622 (0.8375) loss_zs_kd 1.4923 (1.7110) loss_oracle 0.3953 (0.4464) acc 71.8750 (70.8789) lr 1.5358e-03 eta 0:16:19
epoch [18/50] batch [180/403] time 0.074 (0.074) data 0.000 (0.003) loss 1.5232 (1.7154) teacher_loss 0.8168 (0.8435) loss_zs_kd 1.8078 (1.7171) loss_oracle 0.4157 (0.4468) acc 78.1250 (71.0243) lr 1.5358e-03 eta 0:16:16
epoch [18/50] batch [200/403] time 0.072 (0.074) data 0.000 (0.003) loss 1.8854 (1.7034) teacher_loss 1.0388 (0.8352) loss_zs_kd 1.5081 (1.7217) loss_oracle 0.4382 (0.4456) acc 59.3750 (71.4375) lr 1.5358e-03 eta 0:16:12
epoch [18/50] batch [220/403] time 0.070 (0.074) data 0.000 (0.002) loss 1.6762 (1.7014) teacher_loss 0.8227 (0.8386) loss_zs_kd 1.8742 (1.7214) loss_oracle 0.4836 (0.4438) acc 65.6250 (70.9659) lr 1.5358e-03 eta 0:16:08
epoch [18/50] batch [240/403] time 0.113 (0.075) data 0.000 (0.002) loss 1.5906 (1.6938) teacher_loss 0.9527 (0.8349) loss_zs_kd 1.4693 (1.7315) loss_oracle 0.3925 (0.4432) acc 68.7500 (71.1458) lr 1.5358e-03 eta 0:16:21
epoch [18/50] batch [260/403] time 0.063 (0.075) data 0.000 (0.002) loss 1.6523 (1.6853) teacher_loss 0.7812 (0.8296) loss_zs_kd 0.9936 (1.7281) loss_oracle 0.4321 (0.4422) acc 78.1250 (71.3942) lr 1.5358e-03 eta 0:16:18
epoch [18/50] batch [280/403] time 0.076 (0.075) data 0.000 (0.002) loss 1.4416 (1.6848) teacher_loss 0.6988 (0.8320) loss_zs_kd 1.6409 (1.7242) loss_oracle 0.4299 (0.4409) acc 71.8750 (71.3504) lr 1.5358e-03 eta 0:16:13
epoch [18/50] batch [300/403] time 0.064 (0.075) data 0.000 (0.002) loss 1.5972 (1.6815) teacher_loss 0.8848 (0.8346) loss_zs_kd 1.5907 (1.7056) loss_oracle 0.4399 (0.4389) acc 62.5000 (71.3438) lr 1.5358e-03 eta 0:16:09
epoch [18/50] batch [320/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.9061 (1.6835) teacher_loss 0.9555 (0.8363) loss_zs_kd 1.5885 (1.7042) loss_oracle 0.4316 (0.4390) acc 59.3750 (71.1621) lr 1.5358e-03 eta 0:16:06
epoch [18/50] batch [340/403] time 0.068 (0.074) data 0.000 (0.002) loss 1.2490 (1.6843) teacher_loss 0.5125 (0.8361) loss_zs_kd 1.1549 (1.6963) loss_oracle 0.3596 (0.4393) acc 81.2500 (71.2684) lr 1.5358e-03 eta 0:16:03
epoch [18/50] batch [360/403] time 0.075 (0.074) data 0.000 (0.002) loss 1.5789 (1.6795) teacher_loss 0.6047 (0.8318) loss_zs_kd 1.5598 (1.6846) loss_oracle 0.5321 (0.4402) acc 71.8750 (71.3281) lr 1.5358e-03 eta 0:16:00
epoch [18/50] batch [380/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.9080 (1.6815) teacher_loss 1.0405 (0.8315) loss_zs_kd 1.7035 (1.6901) loss_oracle 0.4847 (0.4411) acc 68.7500 (71.4145) lr 1.5358e-03 eta 0:15:57
epoch [18/50] batch [400/403] time 0.063 (0.074) data 0.000 (0.001) loss 1.7847 (1.6900) teacher_loss 0.8984 (0.8351) loss_zs_kd 1.5036 (1.6915) loss_oracle 0.3697 (0.4422) acc 62.5000 (71.2812) lr 1.5358e-03 eta 0:15:51
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,880
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 55.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,281
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 26.5%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [19/50] batch [20/403] time 0.130 (0.102) data 0.000 (0.026) loss 1.4172 (1.7373) teacher_loss 0.4966 (0.7724) loss_zs_kd 1.3214 (1.4847) loss_oracle 0.4071 (0.4337) acc 87.5000 (72.8125) lr 1.4818e-03 eta 0:21:50
epoch [19/50] batch [40/403] time 0.065 (0.093) data 0.000 (0.013) loss 1.6177 (1.7691) teacher_loss 0.6368 (0.8109) loss_zs_kd 1.7209 (1.5987) loss_oracle 0.4304 (0.4460) acc 78.1250 (72.0312) lr 1.4818e-03 eta 0:19:59
epoch [19/50] batch [60/403] time 0.073 (0.086) data 0.000 (0.009) loss 2.0686 (1.7901) teacher_loss 1.0494 (0.8187) loss_zs_kd 1.7965 (1.6505) loss_oracle 0.4894 (0.4536) acc 62.5000 (72.0312) lr 1.4818e-03 eta 0:18:21
epoch [19/50] batch [80/403] time 0.067 (0.082) data 0.000 (0.007) loss 1.8666 (1.8090) teacher_loss 0.8007 (0.8291) loss_zs_kd 1.6654 (1.6599) loss_oracle 0.4868 (0.4529) acc 78.1250 (71.3281) lr 1.4818e-03 eta 0:17:34
epoch [19/50] batch [100/403] time 0.071 (0.080) data 0.000 (0.005) loss 1.7733 (1.8122) teacher_loss 0.7862 (0.8228) loss_zs_kd 1.8327 (1.6851) loss_oracle 0.4702 (0.4523) acc 65.6250 (71.2812) lr 1.4818e-03 eta 0:17:01
epoch [19/50] batch [120/403] time 0.069 (0.078) data 0.000 (0.005) loss 1.8888 (1.8261) teacher_loss 0.8166 (0.8250) loss_zs_kd 1.6543 (1.6823) loss_oracle 0.3909 (0.4534) acc 65.6250 (71.1979) lr 1.4818e-03 eta 0:16:40
epoch [19/50] batch [140/403] time 0.062 (0.077) data 0.000 (0.004) loss 2.0859 (1.8468) teacher_loss 0.8618 (0.8329) loss_zs_kd 2.0985 (1.6721) loss_oracle 0.5372 (0.4575) acc 65.6250 (70.6920) lr 1.4818e-03 eta 0:16:23
epoch [19/50] batch [160/403] time 0.067 (0.076) data 0.000 (0.003) loss 1.6130 (1.8594) teacher_loss 0.5947 (0.8404) loss_zs_kd 1.4092 (1.6682) loss_oracle 0.4628 (0.4589) acc 78.1250 (70.5078) lr 1.4818e-03 eta 0:16:10
epoch [19/50] batch [180/403] time 0.066 (0.076) data 0.000 (0.003) loss 1.9929 (1.8547) teacher_loss 0.8032 (0.8369) loss_zs_kd 1.7092 (1.6660) loss_oracle 0.5286 (0.4596) acc 68.7500 (70.6250) lr 1.4818e-03 eta 0:16:04
epoch [19/50] batch [200/403] time 0.073 (0.075) data 0.000 (0.003) loss 1.5895 (1.8483) teacher_loss 0.6750 (0.8332) loss_zs_kd 1.6253 (1.6753) loss_oracle 0.4471 (0.4612) acc 68.7500 (70.6719) lr 1.4818e-03 eta 0:15:56
epoch [19/50] batch [220/403] time 0.072 (0.075) data 0.000 (0.003) loss 1.7484 (1.8392) teacher_loss 0.9314 (0.8312) loss_zs_kd 2.1514 (1.6886) loss_oracle 0.4910 (0.4622) acc 62.5000 (70.7102) lr 1.4818e-03 eta 0:15:50
epoch [19/50] batch [240/403] time 0.077 (0.075) data 0.000 (0.002) loss 2.0758 (1.8322) teacher_loss 1.1212 (0.8301) loss_zs_kd 2.4241 (1.6999) loss_oracle 0.5965 (0.4646) acc 56.2500 (70.9766) lr 1.4818e-03 eta 0:15:46
epoch [19/50] batch [260/403] time 0.070 (0.075) data 0.000 (0.002) loss 2.0997 (1.8332) teacher_loss 1.2643 (0.8395) loss_zs_kd 1.4142 (1.6987) loss_oracle 0.4923 (0.4657) acc 59.3750 (70.6611) lr 1.4818e-03 eta 0:15:42
epoch [19/50] batch [280/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.5308 (1.8211) teacher_loss 0.6665 (0.8391) loss_zs_kd 1.6424 (1.6950) loss_oracle 0.4750 (0.4648) acc 75.0000 (70.7478) lr 1.4818e-03 eta 0:15:37
epoch [19/50] batch [300/403] time 0.068 (0.074) data 0.000 (0.002) loss 1.3799 (1.8051) teacher_loss 0.7065 (0.8375) loss_zs_kd 1.8243 (1.6948) loss_oracle 0.4395 (0.4629) acc 65.6250 (70.8438) lr 1.4818e-03 eta 0:15:33
epoch [19/50] batch [320/403] time 0.068 (0.074) data 0.000 (0.002) loss 1.4916 (1.7955) teacher_loss 0.6480 (0.8388) loss_zs_kd 1.7311 (1.6958) loss_oracle 0.4574 (0.4612) acc 84.3750 (70.8984) lr 1.4818e-03 eta 0:15:29
epoch [19/50] batch [340/403] time 0.063 (0.073) data 0.000 (0.002) loss 1.4993 (1.7860) teacher_loss 0.6608 (0.8379) loss_zs_kd 1.5315 (1.6962) loss_oracle 0.4907 (0.4602) acc 75.0000 (70.9283) lr 1.4818e-03 eta 0:15:21
epoch [19/50] batch [360/403] time 0.068 (0.073) data 0.000 (0.002) loss 1.3986 (1.7818) teacher_loss 0.7109 (0.8391) loss_zs_kd 1.8705 (1.7026) loss_oracle 0.4308 (0.4598) acc 68.7500 (70.9201) lr 1.4818e-03 eta 0:15:17
epoch [19/50] batch [380/403] time 0.074 (0.073) data 0.000 (0.002) loss 1.7718 (1.7745) teacher_loss 0.9218 (0.8381) loss_zs_kd 1.4406 (1.7003) loss_oracle 0.3713 (0.4582) acc 65.6250 (70.9293) lr 1.4818e-03 eta 0:15:15
epoch [19/50] batch [400/403] time 0.064 (0.073) data 0.000 (0.002) loss 1.6035 (1.7675) teacher_loss 0.8127 (0.8367) loss_zs_kd 1.9729 (1.7020) loss_oracle 0.3957 (0.4577) acc 65.6250 (71.0625) lr 1.4818e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,856
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 55.0%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,496
* accuracy: 42.4%
* error: 57.6%
* macro_f1: 30.1%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [20/50] batch [20/403] time 0.069 (0.094) data 0.000 (0.025) loss 1.4601 (1.5773) teacher_loss 0.6061 (0.7490) loss_zs_kd 2.0286 (1.7109) loss_oracle 0.5057 (0.4503) acc 75.0000 (73.7500) lr 1.4258e-03 eta 0:19:30
epoch [20/50] batch [40/403] time 0.079 (0.083) data 0.000 (0.013) loss 1.7547 (1.6478) teacher_loss 0.7044 (0.7982) loss_zs_kd 1.8907 (1.7383) loss_oracle 0.4718 (0.4498) acc 78.1250 (73.2031) lr 1.4258e-03 eta 0:17:17
epoch [20/50] batch [60/403] time 0.077 (0.081) data 0.000 (0.009) loss 1.5568 (1.6538) teacher_loss 0.7063 (0.8002) loss_zs_kd 1.5733 (1.7654) loss_oracle 0.4269 (0.4484) acc 81.2500 (72.9167) lr 1.4258e-03 eta 0:16:41
epoch [20/50] batch [80/403] time 0.079 (0.080) data 0.000 (0.006) loss 1.6408 (1.6579) teacher_loss 0.7638 (0.7924) loss_zs_kd 1.5758 (1.7457) loss_oracle 0.4525 (0.4497) acc 71.8750 (72.7734) lr 1.4258e-03 eta 0:16:28
epoch [20/50] batch [100/403] time 0.068 (0.079) data 0.000 (0.005) loss 1.5545 (1.6708) teacher_loss 0.7596 (0.7984) loss_zs_kd 1.9320 (1.7386) loss_oracle 0.3983 (0.4479) acc 71.8750 (72.2500) lr 1.4258e-03 eta 0:16:13
epoch [20/50] batch [120/403] time 0.077 (0.077) data 0.000 (0.004) loss 1.7501 (1.6985) teacher_loss 0.9792 (0.8184) loss_zs_kd 1.7532 (1.7421) loss_oracle 0.4185 (0.4487) acc 62.5000 (71.2240) lr 1.4258e-03 eta 0:15:47
epoch [20/50] batch [140/403] time 0.074 (0.076) data 0.000 (0.004) loss 1.4854 (1.7002) teacher_loss 0.7012 (0.8209) loss_zs_kd 2.0794 (1.7355) loss_oracle 0.4848 (0.4492) acc 75.0000 (71.1384) lr 1.4258e-03 eta 0:15:35
epoch [20/50] batch [160/403] time 0.080 (0.076) data 0.000 (0.003) loss 1.7083 (1.6992) teacher_loss 0.8131 (0.8207) loss_zs_kd 1.8215 (1.7223) loss_oracle 0.5196 (0.4508) acc 75.0000 (71.2305) lr 1.4258e-03 eta 0:15:37
epoch [20/50] batch [180/403] time 0.080 (0.076) data 0.000 (0.003) loss 1.6456 (1.6983) teacher_loss 0.7987 (0.8236) loss_zs_kd 1.6678 (1.7240) loss_oracle 0.4261 (0.4521) acc 78.1250 (71.1806) lr 1.4258e-03 eta 0:15:30
epoch [20/50] batch [200/403] time 0.069 (0.075) data 0.000 (0.003) loss 1.6617 (1.6947) teacher_loss 0.7800 (0.8273) loss_zs_kd 1.8310 (1.7160) loss_oracle 0.4725 (0.4527) acc 75.0000 (70.9844) lr 1.4258e-03 eta 0:15:25
epoch [20/50] batch [220/403] time 0.070 (0.074) data 0.000 (0.003) loss 1.7410 (1.6892) teacher_loss 0.7768 (0.8281) loss_zs_kd 1.9368 (1.7111) loss_oracle 0.4761 (0.4516) acc 78.1250 (70.9091) lr 1.4258e-03 eta 0:15:13
epoch [20/50] batch [240/403] time 0.083 (0.074) data 0.000 (0.002) loss 1.6227 (1.6842) teacher_loss 0.7534 (0.8279) loss_zs_kd 1.7485 (1.7039) loss_oracle 0.4576 (0.4524) acc 71.8750 (71.0026) lr 1.4258e-03 eta 0:15:09
epoch [20/50] batch [260/403] time 0.082 (0.074) data 0.001 (0.002) loss 1.8740 (1.6747) teacher_loss 1.1149 (0.8215) loss_zs_kd 1.6567 (1.7066) loss_oracle 0.4356 (0.4523) acc 56.2500 (71.3341) lr 1.4258e-03 eta 0:15:07
epoch [20/50] batch [280/403] time 0.066 (0.075) data 0.000 (0.002) loss 1.4511 (1.6722) teacher_loss 0.6807 (0.8226) loss_zs_kd 1.5434 (1.7094) loss_oracle 0.4518 (0.4523) acc 81.2500 (71.3281) lr 1.4258e-03 eta 0:15:19
epoch [20/50] batch [300/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.8425 (1.6727) teacher_loss 1.0265 (0.8235) loss_zs_kd 1.7285 (1.7087) loss_oracle 0.4397 (0.4523) acc 56.2500 (71.2812) lr 1.4258e-03 eta 0:15:14
epoch [20/50] batch [320/403] time 0.078 (0.075) data 0.000 (0.002) loss 1.4426 (1.6719) teacher_loss 0.6540 (0.8237) loss_zs_kd 1.4647 (1.7021) loss_oracle 0.4459 (0.4517) acc 68.7500 (71.3965) lr 1.4258e-03 eta 0:15:11
epoch [20/50] batch [340/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.6289 (1.6672) teacher_loss 0.8086 (0.8208) loss_zs_kd 1.8930 (1.6961) loss_oracle 0.4336 (0.4514) acc 68.7500 (71.4246) lr 1.4258e-03 eta 0:15:09
epoch [20/50] batch [360/403] time 0.078 (0.075) data 0.000 (0.002) loss 1.5836 (1.6664) teacher_loss 0.5955 (0.8190) loss_zs_kd 1.6525 (1.6977) loss_oracle 0.5409 (0.4510) acc 84.3750 (71.4410) lr 1.4258e-03 eta 0:15:07
epoch [20/50] batch [380/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.5722 (1.6675) teacher_loss 0.7475 (0.8200) loss_zs_kd 1.7911 (1.6980) loss_oracle 0.4082 (0.4499) acc 71.8750 (71.3158) lr 1.4258e-03 eta 0:15:07
epoch [20/50] batch [400/403] time 0.064 (0.075) data 0.000 (0.002) loss 1.9856 (1.6680) teacher_loss 1.0547 (0.8204) loss_zs_kd 2.0967 (1.6984) loss_oracle 0.4312 (0.4488) acc 59.3750 (71.2969) lr 1.4258e-03 eta 0:15:01
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,848
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 55.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,579
* accuracy: 43.8%
* error: 56.2%
* macro_f1: 32.5%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [21/50] batch [20/403] time 0.072 (0.109) data 0.000 (0.032) loss 1.4676 (1.7572) teacher_loss 0.6532 (0.8542) loss_zs_kd 1.6403 (1.7218) loss_oracle 0.4163 (0.4522) acc 84.3750 (69.8438) lr 1.3681e-03 eta 0:21:56
epoch [21/50] batch [40/403] time 0.074 (0.091) data 0.000 (0.016) loss 1.7212 (1.7472) teacher_loss 0.8399 (0.8771) loss_zs_kd 1.4540 (1.6418) loss_oracle 0.4388 (0.4448) acc 65.6250 (69.2188) lr 1.3681e-03 eta 0:18:19
epoch [21/50] batch [60/403] time 0.078 (0.091) data 0.001 (0.011) loss 1.6200 (1.7412) teacher_loss 0.7198 (0.8614) loss_zs_kd 1.8937 (1.6227) loss_oracle 0.4769 (0.4456) acc 75.0000 (70.1562) lr 1.3681e-03 eta 0:18:10
epoch [21/50] batch [80/403] time 0.076 (0.086) data 0.000 (0.008) loss 1.7765 (1.7335) teacher_loss 0.7946 (0.8377) loss_zs_kd 2.1408 (1.6439) loss_oracle 0.5470 (0.4501) acc 78.1250 (70.8594) lr 1.3681e-03 eta 0:17:13
epoch [21/50] batch [100/403] time 0.067 (0.081) data 0.000 (0.007) loss 1.9472 (1.7493) teacher_loss 0.8783 (0.8364) loss_zs_kd 1.7441 (1.6768) loss_oracle 0.4494 (0.4529) acc 71.8750 (71.1562) lr 1.3681e-03 eta 0:16:13
epoch [21/50] batch [120/403] time 0.064 (0.080) data 0.000 (0.006) loss 1.5316 (1.7509) teacher_loss 0.6711 (0.8260) loss_zs_kd 1.7546 (1.7042) loss_oracle 0.4245 (0.4552) acc 78.1250 (71.3021) lr 1.3681e-03 eta 0:15:54
epoch [21/50] batch [140/403] time 0.070 (0.079) data 0.000 (0.005) loss 1.5777 (1.7535) teacher_loss 0.6475 (0.8235) loss_zs_kd 1.9665 (1.7192) loss_oracle 0.4397 (0.4561) acc 75.0000 (71.3616) lr 1.3681e-03 eta 0:15:39
epoch [21/50] batch [160/403] time 0.071 (0.078) data 0.000 (0.004) loss 1.4231 (1.7699) teacher_loss 0.7023 (0.8459) loss_zs_kd 1.9720 (1.7226) loss_oracle 0.4022 (0.4554) acc 71.8750 (70.6445) lr 1.3681e-03 eta 0:15:28
epoch [21/50] batch [180/403] time 0.073 (0.077) data 0.000 (0.004) loss 1.8033 (1.7690) teacher_loss 1.0039 (0.8528) loss_zs_kd 1.6711 (1.7180) loss_oracle 0.4027 (0.4531) acc 65.6250 (70.3472) lr 1.3681e-03 eta 0:15:19
epoch [21/50] batch [200/403] time 0.078 (0.077) data 0.000 (0.003) loss 1.7748 (1.7537) teacher_loss 0.9430 (0.8475) loss_zs_kd 1.9366 (1.6951) loss_oracle 0.4479 (0.4507) acc 65.6250 (70.5312) lr 1.3681e-03 eta 0:15:10
epoch [21/50] batch [220/403] time 0.074 (0.076) data 0.000 (0.003) loss 1.7092 (1.7439) teacher_loss 1.0510 (0.8496) loss_zs_kd 1.6280 (1.6876) loss_oracle 0.4285 (0.4501) acc 56.2500 (70.4830) lr 1.3681e-03 eta 0:15:06
epoch [21/50] batch [240/403] time 0.072 (0.076) data 0.000 (0.003) loss 1.5486 (1.7267) teacher_loss 0.6753 (0.8425) loss_zs_kd 2.1607 (1.6928) loss_oracle 0.5447 (0.4496) acc 84.3750 (70.8203) lr 1.3681e-03 eta 0:15:02
epoch [21/50] batch [260/403] time 0.074 (0.076) data 0.000 (0.003) loss 1.3577 (1.7192) teacher_loss 0.4893 (0.8382) loss_zs_kd 1.7375 (1.6998) loss_oracle 0.4961 (0.4487) acc 84.3750 (70.8413) lr 1.3681e-03 eta 0:14:57
epoch [21/50] batch [280/403] time 0.066 (0.076) data 0.000 (0.003) loss 1.7770 (1.7152) teacher_loss 1.0272 (0.8366) loss_zs_kd 1.6653 (1.7056) loss_oracle 0.4295 (0.4483) acc 68.7500 (71.0491) lr 1.3681e-03 eta 0:14:53
epoch [21/50] batch [300/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.8173 (1.7220) teacher_loss 0.9203 (0.8393) loss_zs_kd 1.8063 (1.7169) loss_oracle 0.4247 (0.4490) acc 68.7500 (71.0417) lr 1.3681e-03 eta 0:14:47
epoch [21/50] batch [320/403] time 0.071 (0.075) data 0.001 (0.002) loss 2.2436 (1.7376) teacher_loss 1.1828 (0.8470) loss_zs_kd 1.7627 (1.7170) loss_oracle 0.4814 (0.4489) acc 62.5000 (70.7422) lr 1.3681e-03 eta 0:14:41
epoch [21/50] batch [340/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.6554 (1.7413) teacher_loss 0.7278 (0.8452) loss_zs_kd 1.7983 (1.7164) loss_oracle 0.4329 (0.4495) acc 78.1250 (70.7996) lr 1.3681e-03 eta 0:14:37
epoch [21/50] batch [360/403] time 0.082 (0.074) data 0.000 (0.002) loss 1.8781 (1.7466) teacher_loss 1.0037 (0.8455) loss_zs_kd 1.5373 (1.7230) loss_oracle 0.5001 (0.4511) acc 68.7500 (70.8160) lr 1.3681e-03 eta 0:14:33
epoch [21/50] batch [380/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.9692 (1.7504) teacher_loss 1.0309 (0.8469) loss_zs_kd 1.5862 (1.7192) loss_oracle 0.4519 (0.4521) acc 68.7500 (70.8141) lr 1.3681e-03 eta 0:14:35
epoch [21/50] batch [400/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.8951 (1.7553) teacher_loss 0.9208 (0.8469) loss_zs_kd 1.9972 (1.7260) loss_oracle 0.4864 (0.4538) acc 75.0000 (70.8047) lr 1.3681e-03 eta 0:14:30
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,840
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 56.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,435
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 30.6%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [22/50] batch [20/403] time 0.070 (0.103) data 0.000 (0.026) loss 2.0022 (1.8336) teacher_loss 0.9710 (0.8318) loss_zs_kd 1.6308 (2.0395) loss_oracle 0.4830 (0.4998) acc 68.7500 (71.7188) lr 1.3090e-03 eta 0:19:56
epoch [22/50] batch [40/403] time 0.073 (0.088) data 0.000 (0.013) loss 1.8769 (1.8211) teacher_loss 0.8725 (0.8364) loss_zs_kd 1.7774 (1.9611) loss_oracle 0.4996 (0.4989) acc 81.2500 (71.3281) lr 1.3090e-03 eta 0:16:59
epoch [22/50] batch [60/403] time 0.072 (0.082) data 0.001 (0.009) loss 1.8294 (1.8044) teacher_loss 0.7967 (0.8293) loss_zs_kd 1.9695 (1.8873) loss_oracle 0.4918 (0.4894) acc 65.6250 (71.5104) lr 1.3090e-03 eta 0:15:57
epoch [22/50] batch [80/403] time 0.067 (0.080) data 0.000 (0.007) loss 1.6539 (1.7963) teacher_loss 0.6738 (0.8310) loss_zs_kd 1.9023 (1.8724) loss_oracle 0.4449 (0.4842) acc 71.8750 (72.0312) lr 1.3090e-03 eta 0:15:30
epoch [22/50] batch [100/403] time 0.073 (0.079) data 0.000 (0.005) loss 1.4237 (1.7952) teacher_loss 0.5537 (0.8414) loss_zs_kd 1.6215 (1.8210) loss_oracle 0.4613 (0.4792) acc 81.2500 (71.5625) lr 1.3090e-03 eta 0:15:12
epoch [22/50] batch [120/403] time 0.073 (0.078) data 0.000 (0.005) loss 1.8265 (1.7959) teacher_loss 0.8888 (0.8509) loss_zs_kd 1.8417 (1.8021) loss_oracle 0.5198 (0.4780) acc 68.7500 (70.9375) lr 1.3090e-03 eta 0:15:04
epoch [22/50] batch [140/403] time 0.078 (0.077) data 0.000 (0.004) loss 1.7963 (1.7854) teacher_loss 0.8703 (0.8493) loss_zs_kd 1.8625 (1.7927) loss_oracle 0.4989 (0.4751) acc 68.7500 (70.9152) lr 1.3090e-03 eta 0:14:50
epoch [22/50] batch [160/403] time 0.072 (0.077) data 0.000 (0.004) loss 1.9932 (1.7850) teacher_loss 0.9570 (0.8514) loss_zs_kd 1.6289 (1.7792) loss_oracle 0.3934 (0.4715) acc 81.2500 (70.6836) lr 1.3090e-03 eta 0:14:44
epoch [22/50] batch [180/403] time 0.071 (0.076) data 0.000 (0.003) loss 1.6306 (1.7819) teacher_loss 0.6885 (0.8486) loss_zs_kd 1.8879 (1.7731) loss_oracle 0.3945 (0.4703) acc 78.1250 (70.8160) lr 1.3090e-03 eta 0:14:35
epoch [22/50] batch [200/403] time 0.073 (0.076) data 0.000 (0.003) loss 1.5327 (1.7713) teacher_loss 0.7597 (0.8464) loss_zs_kd 1.4326 (1.7627) loss_oracle 0.4215 (0.4683) acc 71.8750 (70.9062) lr 1.3090e-03 eta 0:14:27
epoch [22/50] batch [220/403] time 0.111 (0.075) data 0.000 (0.003) loss 1.7931 (1.7619) teacher_loss 0.9606 (0.8471) loss_zs_kd 1.8777 (1.7525) loss_oracle 0.5152 (0.4669) acc 71.8750 (70.9943) lr 1.3090e-03 eta 0:14:23
epoch [22/50] batch [240/403] time 0.077 (0.075) data 0.000 (0.002) loss 1.4180 (1.7478) teacher_loss 0.6948 (0.8418) loss_zs_kd 1.2290 (1.7588) loss_oracle 0.4399 (0.4658) acc 71.8750 (71.0938) lr 1.3090e-03 eta 0:14:20
epoch [22/50] batch [260/403] time 0.065 (0.075) data 0.000 (0.002) loss 2.0768 (1.7407) teacher_loss 1.1218 (0.8408) loss_zs_kd 1.8102 (1.7526) loss_oracle 0.5416 (0.4657) acc 62.5000 (71.1659) lr 1.3090e-03 eta 0:14:15
epoch [22/50] batch [280/403] time 0.109 (0.076) data 0.000 (0.002) loss 1.7199 (1.7326) teacher_loss 0.8499 (0.8384) loss_zs_kd 1.4601 (1.7415) loss_oracle 0.4715 (0.4644) acc 75.0000 (71.3504) lr 1.3090e-03 eta 0:14:23
epoch [22/50] batch [300/403] time 0.075 (0.076) data 0.000 (0.002) loss 1.9683 (1.7312) teacher_loss 0.9876 (0.8380) loss_zs_kd 1.8228 (1.7372) loss_oracle 0.4922 (0.4635) acc 68.7500 (71.3542) lr 1.3090e-03 eta 0:14:20
epoch [22/50] batch [320/403] time 0.070 (0.076) data 0.000 (0.002) loss 1.8444 (1.7348) teacher_loss 0.9026 (0.8398) loss_zs_kd 1.6767 (1.7349) loss_oracle 0.4577 (0.4634) acc 65.6250 (71.2988) lr 1.3090e-03 eta 0:14:18
epoch [22/50] batch [340/403] time 0.074 (0.075) data 0.001 (0.002) loss 1.5304 (1.7337) teacher_loss 0.6370 (0.8384) loss_zs_kd 1.7920 (1.7394) loss_oracle 0.4769 (0.4636) acc 78.1250 (71.2868) lr 1.3090e-03 eta 0:14:15
epoch [22/50] batch [360/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.9193 (1.7353) teacher_loss 0.9255 (0.8370) loss_zs_kd 1.8844 (1.7383) loss_oracle 0.4271 (0.4627) acc 62.5000 (71.2847) lr 1.3090e-03 eta 0:14:11
epoch [22/50] batch [380/403] time 0.056 (0.075) data 0.000 (0.002) loss 1.7321 (1.7399) teacher_loss 0.7594 (0.8373) loss_zs_kd 2.0214 (1.7367) loss_oracle 0.5228 (0.4635) acc 71.8750 (71.3076) lr 1.3090e-03 eta 0:14:06
epoch [22/50] batch [400/403] time 0.064 (0.074) data 0.000 (0.002) loss 1.8151 (1.7407) teacher_loss 0.8866 (0.8371) loss_zs_kd 1.7335 (1.7346) loss_oracle 0.4889 (0.4642) acc 75.0000 (71.4219) lr 1.3090e-03 eta 0:14:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,872
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 56.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,622
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 32.6%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [23/50] batch [20/403] time 0.070 (0.092) data 0.000 (0.024) loss 1.9145 (1.6330) teacher_loss 1.0084 (0.7727) loss_zs_kd 1.5815 (1.6321) loss_oracle 0.4489 (0.4465) acc 59.3750 (73.4375) lr 1.2487e-03 eta 0:17:20
epoch [23/50] batch [40/403] time 0.074 (0.082) data 0.001 (0.012) loss 1.5826 (1.6506) teacher_loss 0.7973 (0.7924) loss_zs_kd 1.6019 (1.6433) loss_oracle 0.4200 (0.4516) acc 62.5000 (72.5000) lr 1.2487e-03 eta 0:15:19
epoch [23/50] batch [60/403] time 0.067 (0.078) data 0.001 (0.008) loss 1.6360 (1.6719) teacher_loss 0.7865 (0.8008) loss_zs_kd 1.5961 (1.7006) loss_oracle 0.4231 (0.4546) acc 65.6250 (72.0833) lr 1.2487e-03 eta 0:14:37
epoch [23/50] batch [80/403] time 0.073 (0.081) data 0.000 (0.006) loss 1.8267 (1.6854) teacher_loss 0.8559 (0.8052) loss_zs_kd 1.6501 (1.7136) loss_oracle 0.5106 (0.4581) acc 65.6250 (71.5625) lr 1.2487e-03 eta 0:15:03
epoch [23/50] batch [100/403] time 0.079 (0.079) data 0.000 (0.005) loss 1.7440 (1.7074) teacher_loss 0.9885 (0.8236) loss_zs_kd 1.5776 (1.7390) loss_oracle 0.3779 (0.4579) acc 68.7500 (71.0625) lr 1.2487e-03 eta 0:14:43
epoch [23/50] batch [120/403] time 0.068 (0.078) data 0.000 (0.004) loss 1.6392 (1.7031) teacher_loss 0.8047 (0.8229) loss_zs_kd 1.3424 (1.7012) loss_oracle 0.4440 (0.4573) acc 71.8750 (71.3802) lr 1.2487e-03 eta 0:14:35
epoch [23/50] batch [140/403] time 0.073 (0.078) data 0.000 (0.004) loss 1.8490 (1.7004) teacher_loss 1.0096 (0.8277) loss_zs_kd 2.1043 (1.6971) loss_oracle 0.4686 (0.4572) acc 65.6250 (71.6518) lr 1.2487e-03 eta 0:14:26
epoch [23/50] batch [160/403] time 0.080 (0.077) data 0.000 (0.003) loss 1.4401 (1.7047) teacher_loss 0.6924 (0.8355) loss_zs_kd 1.8384 (1.7015) loss_oracle 0.4211 (0.4576) acc 81.2500 (71.5039) lr 1.2487e-03 eta 0:14:18
epoch [23/50] batch [180/403] time 0.076 (0.077) data 0.000 (0.003) loss 1.5850 (1.7045) teacher_loss 0.8239 (0.8390) loss_zs_kd 1.6383 (1.7046) loss_oracle 0.4423 (0.4576) acc 65.6250 (71.1806) lr 1.2487e-03 eta 0:14:14
epoch [23/50] batch [200/403] time 0.073 (0.077) data 0.000 (0.003) loss 1.3577 (1.6988) teacher_loss 0.5114 (0.8381) loss_zs_kd 1.7994 (1.6928) loss_oracle 0.4798 (0.4576) acc 78.1250 (71.2500) lr 1.2487e-03 eta 0:14:08
epoch [23/50] batch [220/403] time 0.078 (0.076) data 0.000 (0.002) loss 1.3923 (1.6922) teacher_loss 0.7339 (0.8376) loss_zs_kd 1.6316 (1.6954) loss_oracle 0.4577 (0.4586) acc 78.1250 (71.2926) lr 1.2487e-03 eta 0:14:03
epoch [23/50] batch [240/403] time 0.075 (0.076) data 0.000 (0.002) loss 1.4109 (1.6841) teacher_loss 0.7433 (0.8365) loss_zs_kd 1.9708 (1.6969) loss_oracle 0.4602 (0.4583) acc 75.0000 (71.3802) lr 1.2487e-03 eta 0:13:59
epoch [23/50] batch [260/403] time 0.067 (0.076) data 0.000 (0.002) loss 1.4290 (1.6738) teacher_loss 0.6393 (0.8303) loss_zs_kd 1.6298 (1.7097) loss_oracle 0.4515 (0.4580) acc 81.2500 (71.5986) lr 1.2487e-03 eta 0:13:55
epoch [23/50] batch [280/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.3389 (1.6627) teacher_loss 0.5413 (0.8236) loss_zs_kd 1.7962 (1.7201) loss_oracle 0.4315 (0.4572) acc 78.1250 (71.7857) lr 1.2487e-03 eta 0:13:50
epoch [23/50] batch [300/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.3768 (1.6531) teacher_loss 0.6148 (0.8191) loss_zs_kd 1.8711 (1.7173) loss_oracle 0.4551 (0.4565) acc 71.8750 (72.0208) lr 1.2487e-03 eta 0:13:44
epoch [23/50] batch [320/403] time 0.083 (0.075) data 0.000 (0.002) loss 1.3614 (1.6463) teacher_loss 0.6428 (0.8168) loss_zs_kd 1.5661 (1.7205) loss_oracle 0.3928 (0.4561) acc 84.3750 (72.1484) lr 1.2487e-03 eta 0:13:42
epoch [23/50] batch [340/403] time 0.076 (0.075) data 0.000 (0.002) loss 1.4216 (1.6435) teacher_loss 0.6316 (0.8166) loss_zs_kd 1.4979 (1.7210) loss_oracle 0.4689 (0.4566) acc 75.0000 (72.1507) lr 1.2487e-03 eta 0:13:40
epoch [23/50] batch [360/403] time 0.078 (0.075) data 0.000 (0.002) loss 1.3075 (1.6388) teacher_loss 0.5117 (0.8146) loss_zs_kd 1.6161 (1.7265) loss_oracle 0.4703 (0.4565) acc 87.5000 (72.1962) lr 1.2487e-03 eta 0:13:38
epoch [23/50] batch [380/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.4983 (1.6340) teacher_loss 0.7920 (0.8136) loss_zs_kd 1.8490 (1.7294) loss_oracle 0.4076 (0.4559) acc 78.1250 (72.2204) lr 1.2487e-03 eta 0:13:35
epoch [23/50] batch [400/403] time 0.066 (0.075) data 0.000 (0.001) loss 1.8670 (1.6348) teacher_loss 1.0311 (0.8159) loss_zs_kd 1.7752 (1.7349) loss_oracle 0.4493 (0.4560) acc 62.5000 (72.1406) lr 1.2487e-03 eta 0:13:31
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,887
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 58.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,392
* accuracy: 40.7%
* error: 59.3%
* macro_f1: 29.9%
******* Domain 4 best val acc:      70.3%, epoch: 16 *******
******* Domain 4 best val test acc: 45.7%, epoch: 16 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [24/50] batch [20/403] time 0.061 (0.086) data 0.000 (0.025) loss 1.5219 (1.5351) teacher_loss 0.8330 (0.7593) loss_zs_kd 2.3161 (1.9345) loss_oracle 0.4267 (0.4373) acc 75.0000 (72.9688) lr 1.1874e-03 eta 0:15:37
epoch [24/50] batch [40/403] time 0.073 (0.076) data 0.000 (0.013) loss 1.4238 (1.5358) teacher_loss 0.6701 (0.7636) loss_zs_kd 2.0524 (1.9291) loss_oracle 0.4504 (0.4426) acc 78.1250 (73.4375) lr 1.1874e-03 eta 0:13:40
epoch [24/50] batch [60/403] time 0.077 (0.074) data 0.001 (0.009) loss 1.6640 (1.5443) teacher_loss 0.7860 (0.7666) loss_zs_kd 1.7139 (1.9031) loss_oracle 0.4871 (0.4493) acc 65.6250 (73.3333) lr 1.1874e-03 eta 0:13:23
epoch [24/50] batch [80/403] time 0.069 (0.074) data 0.000 (0.007) loss 1.5736 (1.5527) teacher_loss 0.7761 (0.7800) loss_zs_kd 1.8220 (1.8572) loss_oracle 0.4357 (0.4451) acc 78.1250 (73.1250) lr 1.1874e-03 eta 0:13:20
epoch [24/50] batch [100/403] time 0.076 (0.074) data 0.000 (0.005) loss 1.5786 (1.5452) teacher_loss 0.8378 (0.7709) loss_zs_kd 1.5655 (1.8378) loss_oracle 0.4548 (0.4459) acc 71.8750 (73.3438) lr 1.1874e-03 eta 0:13:16
epoch [24/50] batch [120/403] time 0.077 (0.074) data 0.000 (0.004) loss 1.6990 (1.5364) teacher_loss 0.7399 (0.7647) loss_zs_kd 1.5974 (1.8183) loss_oracle 0.4854 (0.4447) acc 71.8750 (73.4896) lr 1.1874e-03 eta 0:13:15
epoch [24/50] batch [140/403] time 0.066 (0.074) data 0.000 (0.004) loss 1.6406 (1.5406) teacher_loss 0.7850 (0.7706) loss_zs_kd 1.4015 (1.8042) loss_oracle 0.5497 (0.4431) acc 71.8750 (73.4375) lr 1.1874e-03 eta 0:13:11
epoch [24/50] batch [160/403] time 0.075 (0.074) data 0.000 (0.003) loss 2.0196 (1.5522) teacher_loss 1.2840 (0.7834) loss_zs_kd 1.3432 (1.7962) loss_oracle 0.4154 (0.4407) acc 53.1250 (73.0469) lr 1.1874e-03 eta 0:13:09
epoch [24/50] batch [180/403] time 0.074 (0.074) data 0.000 (0.003) loss 1.7200 (1.5512) teacher_loss 0.9120 (0.7811) loss_zs_kd 1.9238 (1.7913) loss_oracle 0.4219 (0.4396) acc 65.6250 (73.0208) lr 1.1874e-03 eta 0:13:09
epoch [24/50] batch [200/403] time 0.082 (0.074) data 0.001 (0.003) loss 1.4795 (1.5516) teacher_loss 0.7760 (0.7824) loss_zs_kd 1.8254 (1.7880) loss_oracle 0.3932 (0.4392) acc 71.8750 (72.8750) lr 1.1874e-03 eta 0:13:07
epoch [24/50] batch [220/403] time 0.082 (0.074) data 0.001 (0.003) loss 1.8373 (1.5553) teacher_loss 1.0349 (0.7882) loss_zs_kd 1.7845 (1.7755) loss_oracle 0.4149 (0.4378) acc 71.8750 (72.6420) lr 1.1874e-03 eta 0:13:10
epoch [24/50] batch [240/403] time 0.074 (0.074) data 0.000 (0.002) loss 1.7807 (1.5575) teacher_loss 0.8888 (0.7891) loss_zs_kd 1.9872 (1.7643) loss_oracle 0.4746 (0.4358) acc 68.7500 (72.5651) lr 1.1874e-03 eta 0:13:06
epoch [24/50] batch [260/403] time 0.070 (0.074) data 0.000 (0.002) loss 1.4489 (1.5616) teacher_loss 0.6721 (0.7925) loss_zs_kd 1.7015 (1.7583) loss_oracle 0.4783 (0.4359) acc 71.8750 (72.3678) lr 1.1874e-03 eta 0:13:03
epoch [24/50] batch [280/403] time 0.075 (0.074) data 0.000 (0.002) loss 1.5634 (1.5682) teacher_loss 0.7231 (0.7988) loss_zs_kd 1.3116 (1.7517) loss_oracle 0.4561 (0.4356) acc 81.2500 (72.2433) lr 1.1874e-03 eta 0:13:00
epoch [24/50] batch [300/403] time 0.107 (0.074) data 0.001 (0.002) loss 1.9615 (1.5743) teacher_loss 1.1344 (0.8009) loss_zs_kd 2.1190 (1.7478) loss_oracle 0.4442 (0.4349) acc 68.7500 (72.1250) lr 1.1874e-03 eta 0:13:03
epoch [24/50] batch [320/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.7146 (1.5810) teacher_loss 0.8166 (0.8060) loss_zs_kd 2.0014 (1.7473) loss_oracle 0.4858 (0.4342) acc 68.7500 (71.9238) lr 1.1874e-03 eta 0:13:06
epoch [24/50] batch [340/403] time 0.082 (0.075) data 0.000 (0.002) loss 1.7944 (1.5895) teacher_loss 0.9460 (0.8111) loss_zs_kd 1.7493 (1.7485) loss_oracle 0.3987 (0.4342) acc 56.2500 (71.7096) lr 1.1874e-03 eta 0:13:07
epoch [24/50] batch [360/403] time 0.076 (0.075) data 0.000 (0.002) loss 1.6976 (1.5921) teacher_loss 0.8884 (0.8110) loss_zs_kd 1.7253 (1.7445) loss_oracle 0.4077 (0.4339) acc 65.6250 (71.7882) lr 1.1874e-03 eta 0:13:05
epoch [24/50] batch [380/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.5508 (1.5957) teacher_loss 0.7910 (0.8129) loss_zs_kd 1.8815 (1.7479) loss_oracle 0.4137 (0.4334) acc 78.1250 (71.7681) lr 1.1874e-03 eta 0:13:03
epoch [24/50] batch [400/403] time 0.070 (0.075) data 0.000 (0.002) loss 1.9815 (1.6006) teacher_loss 1.1212 (0.8158) loss_zs_kd 1.9545 (1.7548) loss_oracle 0.4156 (0.4330) acc 62.5000 (71.6172) lr 1.1874e-03 eta 0:13:02
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,905
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 56.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,640
* accuracy: 44.9%
* error: 55.1%
* macro_f1: 32.7%
******* Domain 4 best val acc:      70.6%, epoch: 24 *******
******* Domain 4 best val test acc: 44.9%, epoch: 24 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [25/50] batch [20/403] time 0.065 (0.103) data 0.000 (0.030) loss 1.8847 (1.6457) teacher_loss 1.0595 (0.8241) loss_zs_kd 1.7021 (1.9356) loss_oracle 0.4520 (0.4248) acc 62.5000 (69.6875) lr 1.1253e-03 eta 0:17:53
epoch [25/50] batch [40/403] time 0.065 (0.087) data 0.000 (0.015) loss 1.5786 (1.6479) teacher_loss 0.7186 (0.8176) loss_zs_kd 1.9384 (1.8624) loss_oracle 0.4540 (0.4263) acc 71.8750 (71.0938) lr 1.1253e-03 eta 0:15:11
epoch [25/50] batch [60/403] time 0.075 (0.082) data 0.001 (0.010) loss 2.0202 (1.6951) teacher_loss 1.1351 (0.8284) loss_zs_kd 1.9351 (1.8512) loss_oracle 0.3999 (0.4354) acc 65.6250 (70.6771) lr 1.1253e-03 eta 0:14:19
epoch [25/50] batch [80/403] time 0.070 (0.084) data 0.000 (0.008) loss 1.6995 (1.7180) teacher_loss 0.8378 (0.8308) loss_zs_kd 1.4570 (1.8193) loss_oracle 0.4347 (0.4367) acc 71.8750 (70.6641) lr 1.1253e-03 eta 0:14:31
epoch [25/50] batch [100/403] time 0.071 (0.082) data 0.000 (0.006) loss 1.3109 (1.7400) teacher_loss 0.5622 (0.8447) loss_zs_kd 1.5331 (1.8013) loss_oracle 0.4148 (0.4365) acc 78.1250 (70.4375) lr 1.1253e-03 eta 0:14:13
epoch [25/50] batch [120/403] time 0.067 (0.080) data 0.000 (0.005) loss 1.9829 (1.7384) teacher_loss 1.0145 (0.8508) loss_zs_kd 2.1613 (1.7839) loss_oracle 0.5135 (0.4362) acc 68.7500 (70.1302) lr 1.1253e-03 eta 0:13:53
epoch [25/50] batch [140/403] time 0.067 (0.079) data 0.000 (0.004) loss 1.3713 (1.7359) teacher_loss 0.4702 (0.8469) loss_zs_kd 1.9826 (1.7815) loss_oracle 0.4836 (0.4393) acc 87.5000 (70.3125) lr 1.1253e-03 eta 0:13:37
epoch [25/50] batch [160/403] time 0.075 (0.078) data 0.000 (0.004) loss 1.4570 (1.7305) teacher_loss 0.7389 (0.8436) loss_zs_kd 1.5417 (1.7863) loss_oracle 0.3946 (0.4387) acc 71.8750 (70.4492) lr 1.1253e-03 eta 0:13:28
epoch [25/50] batch [180/403] time 0.079 (0.078) data 0.001 (0.004) loss 1.8304 (1.7254) teacher_loss 0.9203 (0.8429) loss_zs_kd 2.0316 (1.7827) loss_oracle 0.4595 (0.4404) acc 71.8750 (70.3472) lr 1.1253e-03 eta 0:13:21
epoch [25/50] batch [200/403] time 0.079 (0.077) data 0.000 (0.003) loss 1.5524 (1.7197) teacher_loss 0.7597 (0.8405) loss_zs_kd 1.7041 (1.7777) loss_oracle 0.4120 (0.4414) acc 75.0000 (70.3125) lr 1.1253e-03 eta 0:13:13
epoch [25/50] batch [220/403] time 0.075 (0.077) data 0.000 (0.003) loss 1.7890 (1.7119) teacher_loss 0.7914 (0.8339) loss_zs_kd 1.9723 (1.7723) loss_oracle 0.5655 (0.4427) acc 71.8750 (70.5114) lr 1.1253e-03 eta 0:13:08
epoch [25/50] batch [240/403] time 0.074 (0.076) data 0.000 (0.003) loss 1.9325 (1.7115) teacher_loss 1.0308 (0.8375) loss_zs_kd 1.6321 (1.7665) loss_oracle 0.4178 (0.4418) acc 56.2500 (70.5078) lr 1.1253e-03 eta 0:13:01
epoch [25/50] batch [260/403] time 0.077 (0.076) data 0.000 (0.003) loss 1.5316 (1.7036) teacher_loss 0.7757 (0.8368) loss_zs_kd 1.7811 (1.7674) loss_oracle 0.3974 (0.4415) acc 78.1250 (70.6490) lr 1.1253e-03 eta 0:12:57
epoch [25/50] batch [280/403] time 0.073 (0.076) data 0.000 (0.002) loss 1.8267 (1.6981) teacher_loss 1.0716 (0.8393) loss_zs_kd 1.8203 (1.7693) loss_oracle 0.4335 (0.4405) acc 65.6250 (70.6362) lr 1.1253e-03 eta 0:12:54
epoch [25/50] batch [300/403] time 0.068 (0.076) data 0.000 (0.002) loss 1.5490 (1.6901) teacher_loss 0.7664 (0.8386) loss_zs_kd 1.7747 (1.7662) loss_oracle 0.5047 (0.4392) acc 68.7500 (70.6042) lr 1.1253e-03 eta 0:12:50
epoch [25/50] batch [320/403] time 0.071 (0.075) data 0.000 (0.002) loss 1.4568 (1.6840) teacher_loss 0.7544 (0.8368) loss_zs_kd 1.7630 (1.7668) loss_oracle 0.4021 (0.4383) acc 71.8750 (70.6934) lr 1.1253e-03 eta 0:12:45
epoch [25/50] batch [340/403] time 0.066 (0.075) data 0.000 (0.002) loss 1.7742 (1.6812) teacher_loss 0.9218 (0.8385) loss_zs_kd 1.3383 (1.7643) loss_oracle 0.4553 (0.4375) acc 71.8750 (70.7077) lr 1.1253e-03 eta 0:12:38
epoch [25/50] batch [360/403] time 0.048 (0.074) data 0.000 (0.002) loss 1.6437 (1.6755) teacher_loss 0.6937 (0.8342) loss_zs_kd 1.8670 (1.7655) loss_oracle 0.4726 (0.4367) acc 75.0000 (70.9288) lr 1.1253e-03 eta 0:12:33
epoch [25/50] batch [380/403] time 0.074 (0.074) data 0.000 (0.002) loss 1.4557 (1.6721) teacher_loss 0.7469 (0.8323) loss_zs_kd 1.6429 (1.7601) loss_oracle 0.3827 (0.4362) acc 78.1250 (71.0526) lr 1.1253e-03 eta 0:12:25
epoch [25/50] batch [400/403] time 0.061 (0.073) data 0.000 (0.002) loss 2.0433 (1.6723) teacher_loss 1.0960 (0.8337) loss_zs_kd 1.6270 (1.7541) loss_oracle 0.4841 (0.4355) acc 65.6250 (70.9922) lr 1.1253e-03 eta 0:12:20
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,892
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 55.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,524
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 31.5%
******* Domain 4 best val acc:      70.6%, epoch: 24 *******
******* Domain 4 best val test acc: 44.9%, epoch: 24 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [26/50] batch [20/403] time 0.070 (0.102) data 0.000 (0.027) loss 1.6286 (1.7120) teacher_loss 0.6666 (0.8200) loss_zs_kd 1.5687 (1.6239) loss_oracle 0.3963 (0.4301) acc 81.2500 (72.6562) lr 1.0628e-03 eta 0:17:07
epoch [26/50] batch [40/403] time 0.066 (0.087) data 0.000 (0.014) loss 1.6943 (1.7768) teacher_loss 0.8727 (0.8646) loss_zs_kd 1.8490 (1.6723) loss_oracle 0.4157 (0.4333) acc 68.7500 (70.7812) lr 1.0628e-03 eta 0:14:30
epoch [26/50] batch [60/403] time 0.068 (0.082) data 0.001 (0.009) loss 2.0288 (1.7523) teacher_loss 1.0333 (0.8464) loss_zs_kd 1.7278 (1.6603) loss_oracle 0.4598 (0.4292) acc 68.7500 (70.9375) lr 1.0628e-03 eta 0:13:37
epoch [26/50] batch [80/403] time 0.069 (0.077) data 0.000 (0.007) loss 1.5566 (1.7511) teacher_loss 0.6820 (0.8514) loss_zs_kd 1.5627 (1.6642) loss_oracle 0.4364 (0.4281) acc 81.2500 (70.8594) lr 1.0628e-03 eta 0:12:48
epoch [26/50] batch [100/403] time 0.073 (0.076) data 0.000 (0.006) loss 2.0074 (1.7464) teacher_loss 1.1097 (0.8471) loss_zs_kd 1.8872 (1.6790) loss_oracle 0.3992 (0.4281) acc 62.5000 (70.6875) lr 1.0628e-03 eta 0:12:40
epoch [26/50] batch [120/403] time 0.073 (0.075) data 0.000 (0.005) loss 1.3163 (1.7290) teacher_loss 0.5182 (0.8399) loss_zs_kd 1.8375 (1.6772) loss_oracle 0.3907 (0.4300) acc 84.3750 (70.9115) lr 1.0628e-03 eta 0:12:29
epoch [26/50] batch [140/403] time 0.070 (0.075) data 0.000 (0.004) loss 1.5936 (1.7134) teacher_loss 0.7933 (0.8346) loss_zs_kd 1.9851 (1.6926) loss_oracle 0.4703 (0.4313) acc 75.0000 (71.2054) lr 1.0628e-03 eta 0:12:27
epoch [26/50] batch [160/403] time 0.069 (0.075) data 0.000 (0.004) loss 1.8183 (1.6998) teacher_loss 1.1149 (0.8342) loss_zs_kd 1.3308 (1.6857) loss_oracle 0.3738 (0.4292) acc 59.3750 (71.1523) lr 1.0628e-03 eta 0:12:22
epoch [26/50] batch [180/403] time 0.071 (0.075) data 0.000 (0.003) loss 1.8489 (1.6919) teacher_loss 0.9221 (0.8343) loss_zs_kd 2.1039 (1.6904) loss_oracle 0.4812 (0.4306) acc 71.8750 (71.2674) lr 1.0628e-03 eta 0:12:20
epoch [26/50] batch [200/403] time 0.066 (0.074) data 0.000 (0.003) loss 1.7601 (1.6907) teacher_loss 0.8659 (0.8365) loss_zs_kd 2.0217 (1.7092) loss_oracle 0.4757 (0.4327) acc 78.1250 (71.3281) lr 1.0628e-03 eta 0:12:13
epoch [26/50] batch [220/403] time 0.078 (0.074) data 0.000 (0.003) loss 1.4770 (1.6718) teacher_loss 0.8312 (0.8247) loss_zs_kd 1.6920 (1.6997) loss_oracle 0.4106 (0.4327) acc 68.7500 (71.7898) lr 1.0628e-03 eta 0:12:08
epoch [26/50] batch [240/403] time 0.068 (0.074) data 0.000 (0.003) loss 1.7019 (1.6642) teacher_loss 0.8741 (0.8210) loss_zs_kd 1.9840 (1.7070) loss_oracle 0.4167 (0.4328) acc 65.6250 (71.9661) lr 1.0628e-03 eta 0:12:03
epoch [26/50] batch [260/403] time 0.077 (0.073) data 0.000 (0.002) loss 2.0151 (1.6584) teacher_loss 1.1249 (0.8178) loss_zs_kd 2.0252 (1.7217) loss_oracle 0.5090 (0.4341) acc 62.5000 (72.1635) lr 1.0628e-03 eta 0:12:00
epoch [26/50] batch [280/403] time 0.077 (0.073) data 0.000 (0.002) loss 1.7191 (1.6585) teacher_loss 0.8354 (0.8179) loss_zs_kd 1.6407 (1.7232) loss_oracle 0.4768 (0.4357) acc 65.6250 (72.0982) lr 1.0628e-03 eta 0:11:59
epoch [26/50] batch [300/403] time 0.065 (0.073) data 0.000 (0.002) loss 1.8035 (1.6555) teacher_loss 0.9358 (0.8169) loss_zs_kd 1.7809 (1.7313) loss_oracle 0.4236 (0.4360) acc 62.5000 (72.0625) lr 1.0628e-03 eta 0:11:56
epoch [26/50] batch [320/403] time 0.062 (0.074) data 0.000 (0.002) loss 1.7506 (1.6554) teacher_loss 0.7374 (0.8181) loss_zs_kd 2.2151 (1.7334) loss_oracle 0.4985 (0.4362) acc 71.8750 (71.8945) lr 1.0628e-03 eta 0:12:00
epoch [26/50] batch [340/403] time 0.067 (0.074) data 0.000 (0.002) loss 1.8926 (1.6593) teacher_loss 1.1445 (0.8227) loss_zs_kd 1.7608 (1.7357) loss_oracle 0.4347 (0.4360) acc 62.5000 (71.8566) lr 1.0628e-03 eta 0:11:56
epoch [26/50] batch [360/403] time 0.083 (0.074) data 0.001 (0.002) loss 1.5485 (1.6590) teacher_loss 0.7521 (0.8215) loss_zs_kd 1.6201 (1.7342) loss_oracle 0.4317 (0.4358) acc 75.0000 (71.8490) lr 1.0628e-03 eta 0:11:55
epoch [26/50] batch [380/403] time 0.074 (0.073) data 0.001 (0.002) loss 1.6598 (1.6568) teacher_loss 0.8436 (0.8211) loss_zs_kd 1.3207 (1.7252) loss_oracle 0.4272 (0.4348) acc 75.0000 (71.8421) lr 1.0628e-03 eta 0:11:52
epoch [26/50] batch [400/403] time 0.069 (0.073) data 0.000 (0.002) loss 1.5645 (1.6605) teacher_loss 0.8120 (0.8253) loss_zs_kd 1.2000 (1.7287) loss_oracle 0.3716 (0.4347) acc 81.2500 (71.7344) lr 1.0628e-03 eta 0:11:50
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,908
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 56.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,437
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 31.7%
******* Domain 4 best val acc:      70.6%, epoch: 26 *******
******* Domain 4 best val test acc: 41.4%, epoch: 26 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [27/50] batch [20/403] time 0.071 (0.107) data 0.000 (0.028) loss 1.5801 (1.6117) teacher_loss 0.6741 (0.7996) loss_zs_kd 1.9721 (1.8175) loss_oracle 0.4349 (0.4076) acc 78.1250 (72.9688) lr 1.0000e-03 eta 0:17:08
epoch [27/50] batch [40/403] time 0.074 (0.090) data 0.000 (0.014) loss 1.3820 (1.5769) teacher_loss 0.5219 (0.7705) loss_zs_kd 1.9431 (1.7858) loss_oracle 0.4788 (0.4138) acc 84.3750 (74.2188) lr 1.0000e-03 eta 0:14:31
epoch [27/50] batch [60/403] time 0.070 (0.084) data 0.001 (0.009) loss 1.6549 (1.5791) teacher_loss 0.7975 (0.7830) loss_zs_kd 2.1526 (1.7613) loss_oracle 0.4970 (0.4153) acc 65.6250 (73.2292) lr 1.0000e-03 eta 0:13:28
epoch [27/50] batch [80/403] time 0.069 (0.081) data 0.000 (0.007) loss 1.6182 (1.5788) teacher_loss 0.7360 (0.7807) loss_zs_kd 1.8217 (1.7523) loss_oracle 0.5048 (0.4183) acc 71.8750 (73.2031) lr 1.0000e-03 eta 0:12:57
epoch [27/50] batch [100/403] time 0.073 (0.083) data 0.000 (0.006) loss 1.5446 (1.5981) teacher_loss 0.8686 (0.7937) loss_zs_kd 1.7758 (1.7762) loss_oracle 0.4181 (0.4280) acc 59.3750 (72.5625) lr 1.0000e-03 eta 0:13:11
epoch [27/50] batch [120/403] time 0.077 (0.081) data 0.000 (0.005) loss 1.5307 (1.6069) teacher_loss 0.6447 (0.8014) loss_zs_kd 1.4433 (1.7621) loss_oracle 0.3535 (0.4275) acc 75.0000 (72.2917) lr 1.0000e-03 eta 0:12:53
epoch [27/50] batch [140/403] time 0.072 (0.080) data 0.000 (0.004) loss 1.3915 (1.6142) teacher_loss 0.7153 (0.8087) loss_zs_kd 1.4574 (1.7379) loss_oracle 0.4126 (0.4266) acc 78.1250 (71.8080) lr 1.0000e-03 eta 0:12:40
epoch [27/50] batch [160/403] time 0.077 (0.079) data 0.000 (0.004) loss 1.4192 (1.6122) teacher_loss 0.6869 (0.8083) loss_zs_kd 1.6921 (1.7361) loss_oracle 0.4234 (0.4255) acc 78.1250 (71.8359) lr 1.0000e-03 eta 0:12:32
epoch [27/50] batch [180/403] time 0.068 (0.078) data 0.000 (0.003) loss 1.3605 (1.6083) teacher_loss 0.5397 (0.8058) loss_zs_kd 2.1581 (1.7409) loss_oracle 0.4045 (0.4258) acc 81.2500 (71.9444) lr 1.0000e-03 eta 0:12:22
epoch [27/50] batch [200/403] time 0.065 (0.078) data 0.000 (0.003) loss 1.7471 (1.6180) teacher_loss 0.9348 (0.8107) loss_zs_kd 1.8277 (1.7383) loss_oracle 0.4421 (0.4263) acc 65.6250 (71.7812) lr 1.0000e-03 eta 0:12:17
epoch [27/50] batch [220/403] time 0.063 (0.077) data 0.000 (0.003) loss 1.7061 (1.6163) teacher_loss 0.8460 (0.8091) loss_zs_kd 2.0008 (1.7276) loss_oracle 0.4996 (0.4274) acc 71.8750 (71.9318) lr 1.0000e-03 eta 0:12:10
epoch [27/50] batch [240/403] time 0.066 (0.077) data 0.000 (0.003) loss 1.5943 (1.6208) teacher_loss 0.7987 (0.8104) loss_zs_kd 1.6430 (1.7295) loss_oracle 0.4518 (0.4302) acc 71.8750 (72.0052) lr 1.0000e-03 eta 0:12:04
epoch [27/50] batch [260/403] time 0.067 (0.076) data 0.000 (0.002) loss 1.8172 (1.6175) teacher_loss 1.0245 (0.8092) loss_zs_kd 1.8422 (1.7316) loss_oracle 0.4812 (0.4314) acc 56.2500 (72.1034) lr 1.0000e-03 eta 0:11:57
epoch [27/50] batch [280/403] time 0.066 (0.076) data 0.000 (0.002) loss 1.2468 (1.6146) teacher_loss 0.6918 (0.8082) loss_zs_kd 1.3320 (1.7251) loss_oracle 0.3890 (0.4325) acc 81.2500 (72.2210) lr 1.0000e-03 eta 0:11:52
epoch [27/50] batch [300/403] time 0.071 (0.076) data 0.000 (0.002) loss 1.6578 (1.6146) teacher_loss 0.8960 (0.8089) loss_zs_kd 1.7750 (1.7379) loss_oracle 0.4305 (0.4330) acc 71.8750 (72.2396) lr 1.0000e-03 eta 0:11:50
epoch [27/50] batch [320/403] time 0.073 (0.076) data 0.000 (0.002) loss 2.3368 (1.6167) teacher_loss 1.3992 (0.8108) loss_zs_kd 1.5565 (1.7379) loss_oracle 0.4754 (0.4341) acc 50.0000 (72.2461) lr 1.0000e-03 eta 0:11:47
epoch [27/50] batch [340/403] time 0.073 (0.076) data 0.000 (0.002) loss 1.7979 (1.6155) teacher_loss 0.9575 (0.8094) loss_zs_kd 2.0393 (1.7364) loss_oracle 0.3936 (0.4342) acc 75.0000 (72.3529) lr 1.0000e-03 eta 0:11:45
epoch [27/50] batch [360/403] time 0.068 (0.076) data 0.000 (0.002) loss 1.8399 (1.6201) teacher_loss 0.9987 (0.8117) loss_zs_kd 1.4821 (1.7347) loss_oracle 0.5303 (0.4345) acc 59.3750 (72.1875) lr 1.0000e-03 eta 0:11:43
epoch [27/50] batch [380/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.8274 (1.6183) teacher_loss 1.0667 (0.8114) loss_zs_kd 1.3347 (1.7291) loss_oracle 0.3685 (0.4356) acc 62.5000 (72.2039) lr 1.0000e-03 eta 0:11:41
epoch [27/50] batch [400/403] time 0.067 (0.075) data 0.000 (0.002) loss 2.0644 (1.6190) teacher_loss 1.0974 (0.8120) loss_zs_kd 1.4074 (1.7291) loss_oracle 0.5571 (0.4368) acc 56.2500 (72.1953) lr 1.0000e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,899
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 56.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,640
* accuracy: 44.9%
* error: 55.1%
* macro_f1: 32.5%
******* Domain 4 best val acc:      70.6%, epoch: 26 *******
******* Domain 4 best val test acc: 41.4%, epoch: 26 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [28/50] batch [20/403] time 0.080 (0.104) data 0.000 (0.026) loss 1.8877 (1.6016) teacher_loss 0.9125 (0.8005) loss_zs_kd 1.9655 (1.6604) loss_oracle 0.5000 (0.4472) acc 71.8750 (73.2812) lr 9.3721e-04 eta 0:16:04
epoch [28/50] batch [40/403] time 0.073 (0.089) data 0.000 (0.013) loss 2.0741 (1.5869) teacher_loss 1.1770 (0.7817) loss_zs_kd 1.4495 (1.6818) loss_oracle 0.4710 (0.4516) acc 62.5000 (73.1250) lr 9.3721e-04 eta 0:13:44
epoch [28/50] batch [60/403] time 0.082 (0.085) data 0.001 (0.009) loss 1.4554 (1.5825) teacher_loss 0.7111 (0.7806) loss_zs_kd 1.6439 (1.7072) loss_oracle 0.4482 (0.4445) acc 75.0000 (73.1771) lr 9.3721e-04 eta 0:12:59
epoch [28/50] batch [80/403] time 0.078 (0.082) data 0.000 (0.007) loss 1.4993 (1.5801) teacher_loss 0.6174 (0.7873) loss_zs_kd 1.8464 (1.7108) loss_oracle 0.4440 (0.4406) acc 81.2500 (72.9688) lr 9.3721e-04 eta 0:12:31
epoch [28/50] batch [100/403] time 0.088 (0.080) data 0.000 (0.005) loss 1.1913 (1.5721) teacher_loss 0.5318 (0.7828) loss_zs_kd 1.4577 (1.7056) loss_oracle 0.4129 (0.4370) acc 75.0000 (73.0000) lr 9.3721e-04 eta 0:12:14
epoch [28/50] batch [120/403] time 0.070 (0.080) data 0.000 (0.005) loss 1.4282 (1.5714) teacher_loss 0.6007 (0.7816) loss_zs_kd 2.0449 (1.7225) loss_oracle 0.4956 (0.4346) acc 78.1250 (73.2031) lr 9.3721e-04 eta 0:12:12
epoch [28/50] batch [140/403] time 0.074 (0.079) data 0.000 (0.004) loss 1.8187 (1.5777) teacher_loss 1.0184 (0.7925) loss_zs_kd 1.5699 (1.7095) loss_oracle 0.4321 (0.4329) acc 50.0000 (72.7902) lr 9.3721e-04 eta 0:12:03
epoch [28/50] batch [160/403] time 0.068 (0.079) data 0.000 (0.004) loss 1.5719 (1.5754) teacher_loss 0.8630 (0.7936) loss_zs_kd 1.8557 (1.7039) loss_oracle 0.4451 (0.4332) acc 71.8750 (72.7344) lr 9.3721e-04 eta 0:11:56
epoch [28/50] batch [180/403] time 0.072 (0.078) data 0.000 (0.003) loss 1.9224 (1.5778) teacher_loss 1.1570 (0.7992) loss_zs_kd 1.8996 (1.7196) loss_oracle 0.4751 (0.4343) acc 68.7500 (72.7951) lr 9.3721e-04 eta 0:11:49
epoch [28/50] batch [200/403] time 0.073 (0.078) data 0.000 (0.003) loss 1.6182 (1.5768) teacher_loss 0.7731 (0.8005) loss_zs_kd 1.8237 (1.7159) loss_oracle 0.4399 (0.4332) acc 78.1250 (72.8281) lr 9.3721e-04 eta 0:11:43
epoch [28/50] batch [220/403] time 0.076 (0.077) data 0.000 (0.003) loss 2.1895 (1.5874) teacher_loss 1.2823 (0.8083) loss_zs_kd 1.6615 (1.7194) loss_oracle 0.3795 (0.4318) acc 56.2500 (72.3864) lr 9.3721e-04 eta 0:11:40
epoch [28/50] batch [240/403] time 0.073 (0.077) data 0.000 (0.002) loss 1.6499 (1.5807) teacher_loss 0.8944 (0.8009) loss_zs_kd 1.5555 (1.7236) loss_oracle 0.4029 (0.4308) acc 71.8750 (72.6042) lr 9.3721e-04 eta 0:11:36
epoch [28/50] batch [260/403] time 0.080 (0.077) data 0.000 (0.002) loss 1.7273 (1.5898) teacher_loss 0.8512 (0.8066) loss_zs_kd 1.4859 (1.7271) loss_oracle 0.5194 (0.4308) acc 78.1250 (72.3918) lr 9.3721e-04 eta 0:11:33
epoch [28/50] batch [280/403] time 0.080 (0.077) data 0.000 (0.002) loss 1.2217 (1.5954) teacher_loss 0.5174 (0.8093) loss_zs_kd 1.8475 (1.7354) loss_oracle 0.4326 (0.4317) acc 87.5000 (72.3772) lr 9.3721e-04 eta 0:11:29
epoch [28/50] batch [300/403] time 0.062 (0.077) data 0.000 (0.002) loss 1.8744 (1.5969) teacher_loss 0.9593 (0.8100) loss_zs_kd 1.6736 (1.7371) loss_oracle 0.4702 (0.4320) acc 71.8750 (72.3229) lr 9.3721e-04 eta 0:11:34
epoch [28/50] batch [320/403] time 0.066 (0.077) data 0.000 (0.002) loss 1.6117 (1.5976) teacher_loss 0.7786 (0.8108) loss_zs_kd 1.8397 (1.7339) loss_oracle 0.4152 (0.4315) acc 71.8750 (72.3047) lr 9.3721e-04 eta 0:11:28
epoch [28/50] batch [340/403] time 0.077 (0.077) data 0.000 (0.002) loss 1.7156 (1.5994) teacher_loss 0.8254 (0.8100) loss_zs_kd 2.3960 (1.7356) loss_oracle 0.4699 (0.4315) acc 71.8750 (72.2886) lr 9.3721e-04 eta 0:11:23
epoch [28/50] batch [360/403] time 0.068 (0.076) data 0.000 (0.002) loss 1.6298 (1.6040) teacher_loss 0.7076 (0.8114) loss_zs_kd 1.7592 (1.7375) loss_oracle 0.4021 (0.4313) acc 78.1250 (72.1962) lr 9.3721e-04 eta 0:11:20
epoch [28/50] batch [380/403] time 0.077 (0.076) data 0.000 (0.002) loss 1.6940 (1.6087) teacher_loss 0.7980 (0.8121) loss_zs_kd 1.3775 (1.7350) loss_oracle 0.4125 (0.4304) acc 65.6250 (72.1793) lr 9.3721e-04 eta 0:11:18
epoch [28/50] batch [400/403] time 0.068 (0.076) data 0.000 (0.002) loss 1.8199 (1.6172) teacher_loss 1.0908 (0.8153) loss_zs_kd 1.4120 (1.7344) loss_oracle 0.3744 (0.4292) acc 65.6250 (72.0469) lr 9.3721e-04 eta 0:11:17
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,944
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 59.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,597
* accuracy: 44.1%
* error: 55.9%
* macro_f1: 32.6%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [29/50] batch [20/403] time 0.077 (0.107) data 0.001 (0.032) loss 1.4683 (1.7690) teacher_loss 0.5198 (0.8410) loss_zs_kd 1.6994 (1.7993) loss_oracle 0.4188 (0.4224) acc 78.1250 (72.3438) lr 8.7467e-04 eta 0:15:46
epoch [29/50] batch [40/403] time 0.076 (0.090) data 0.000 (0.016) loss 2.0792 (1.7580) teacher_loss 1.1018 (0.8312) loss_zs_kd 1.8622 (1.7827) loss_oracle 0.4184 (0.4227) acc 62.5000 (72.1875) lr 8.7467e-04 eta 0:13:16
epoch [29/50] batch [60/403] time 0.069 (0.084) data 0.001 (0.011) loss 1.8312 (1.7642) teacher_loss 0.8310 (0.8159) loss_zs_kd 1.7255 (1.7822) loss_oracle 0.4774 (0.4343) acc 68.7500 (72.0312) lr 8.7467e-04 eta 0:12:22
epoch [29/50] batch [80/403] time 0.070 (0.085) data 0.000 (0.008) loss 1.8172 (1.7635) teacher_loss 0.8432 (0.8091) loss_zs_kd 2.0495 (1.7724) loss_oracle 0.4272 (0.4312) acc 75.0000 (72.3047) lr 8.7467e-04 eta 0:12:27
epoch [29/50] batch [100/403] time 0.066 (0.083) data 0.000 (0.007) loss 1.4308 (1.7613) teacher_loss 0.5730 (0.8098) loss_zs_kd 1.6543 (1.7708) loss_oracle 0.4466 (0.4305) acc 84.3750 (72.8750) lr 8.7467e-04 eta 0:12:04
epoch [29/50] batch [120/403] time 0.073 (0.081) data 0.000 (0.006) loss 1.6457 (1.7632) teacher_loss 0.6939 (0.8170) loss_zs_kd 1.5672 (1.7664) loss_oracle 0.3926 (0.4320) acc 87.5000 (72.4219) lr 8.7467e-04 eta 0:11:50
epoch [29/50] batch [140/403] time 0.069 (0.080) data 0.000 (0.005) loss 1.3384 (1.7556) teacher_loss 0.4850 (0.8190) loss_zs_kd 1.7319 (1.7625) loss_oracle 0.4152 (0.4298) acc 87.5000 (72.2545) lr 8.7467e-04 eta 0:11:37
epoch [29/50] batch [160/403] time 0.070 (0.079) data 0.000 (0.004) loss 1.7794 (1.7467) teacher_loss 0.7184 (0.8154) loss_zs_kd 1.8633 (1.7619) loss_oracle 0.4255 (0.4307) acc 71.8750 (72.1680) lr 8.7467e-04 eta 0:11:29
epoch [29/50] batch [180/403] time 0.066 (0.078) data 0.000 (0.004) loss 1.8620 (1.7517) teacher_loss 0.9773 (0.8222) loss_zs_kd 1.7734 (1.7578) loss_oracle 0.4204 (0.4308) acc 53.1250 (71.8403) lr 8.7467e-04 eta 0:11:19
epoch [29/50] batch [200/403] time 0.076 (0.078) data 0.000 (0.003) loss 1.9036 (1.7636) teacher_loss 0.9964 (0.8336) loss_zs_kd 1.4851 (1.7580) loss_oracle 0.4398 (0.4300) acc 65.6250 (71.5000) lr 8.7467e-04 eta 0:11:14
epoch [29/50] batch [220/403] time 0.074 (0.077) data 0.000 (0.003) loss 1.6963 (1.7626) teacher_loss 0.7473 (0.8328) loss_zs_kd 1.7970 (1.7628) loss_oracle 0.4380 (0.4305) acc 75.0000 (71.5909) lr 8.7467e-04 eta 0:11:08
epoch [29/50] batch [240/403] time 0.072 (0.077) data 0.000 (0.003) loss 1.7652 (1.7705) teacher_loss 0.7410 (0.8404) loss_zs_kd 1.6415 (1.7584) loss_oracle 0.4400 (0.4294) acc 78.1250 (71.2370) lr 8.7467e-04 eta 0:11:04
epoch [29/50] batch [260/403] time 0.075 (0.077) data 0.000 (0.003) loss 1.8335 (1.7742) teacher_loss 0.8772 (0.8403) loss_zs_kd 1.6955 (1.7532) loss_oracle 0.4317 (0.4286) acc 75.0000 (71.1538) lr 8.7467e-04 eta 0:11:00
epoch [29/50] batch [280/403] time 0.068 (0.076) data 0.000 (0.003) loss 1.4135 (1.7776) teacher_loss 0.4715 (0.8386) loss_zs_kd 1.9290 (1.7552) loss_oracle 0.4819 (0.4298) acc 90.6250 (71.2277) lr 8.7467e-04 eta 0:10:53
epoch [29/50] batch [300/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.9866 (1.7816) teacher_loss 0.8678 (0.8359) loss_zs_kd 1.8753 (1.7608) loss_oracle 0.4273 (0.4320) acc 71.8750 (71.3542) lr 8.7467e-04 eta 0:10:46
epoch [29/50] batch [320/403] time 0.071 (0.075) data 0.000 (0.002) loss 1.8674 (1.7846) teacher_loss 1.0099 (0.8343) loss_zs_kd 1.5473 (1.7637) loss_oracle 0.4099 (0.4339) acc 59.3750 (71.3477) lr 8.7467e-04 eta 0:10:44
epoch [29/50] batch [340/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.5694 (1.7901) teacher_loss 0.6193 (0.8352) loss_zs_kd 1.3589 (1.7641) loss_oracle 0.4425 (0.4366) acc 75.0000 (71.3235) lr 8.7467e-04 eta 0:10:42
epoch [29/50] batch [360/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.8139 (1.7885) teacher_loss 0.7007 (0.8285) loss_zs_kd 1.4674 (1.7612) loss_oracle 0.4958 (0.4384) acc 78.1250 (71.5799) lr 8.7467e-04 eta 0:10:40
epoch [29/50] batch [380/403] time 0.079 (0.075) data 0.000 (0.002) loss 1.7253 (1.7882) teacher_loss 0.8380 (0.8249) loss_zs_kd 1.6837 (1.7667) loss_oracle 0.4036 (0.4392) acc 71.8750 (71.6447) lr 8.7467e-04 eta 0:10:38
epoch [29/50] batch [400/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.8560 (1.7921) teacher_loss 0.9480 (0.8266) loss_zs_kd 1.8187 (1.7664) loss_oracle 0.4484 (0.4409) acc 71.8750 (71.5781) lr 8.7467e-04 eta 0:10:34
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,840
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 57.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,417
* accuracy: 41.1%
* error: 58.9%
* macro_f1: 30.7%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [30/50] batch [20/403] time 0.073 (0.100) data 0.000 (0.026) loss 1.5358 (1.7922) teacher_loss 0.6053 (0.8007) loss_zs_kd 1.9924 (1.8023) loss_oracle 0.4460 (0.4698) acc 75.0000 (72.1875) lr 8.1262e-04 eta 0:14:07
epoch [30/50] batch [40/403] time 0.073 (0.087) data 0.000 (0.013) loss 1.7224 (1.7877) teacher_loss 0.6136 (0.7821) loss_zs_kd 1.9237 (1.8049) loss_oracle 0.4468 (0.4688) acc 81.2500 (72.7344) lr 8.1262e-04 eta 0:12:12
epoch [30/50] batch [60/403] time 0.069 (0.082) data 0.001 (0.009) loss 1.7174 (1.7776) teacher_loss 0.6637 (0.7701) loss_zs_kd 2.0696 (1.7924) loss_oracle 0.5829 (0.4704) acc 81.2500 (73.4896) lr 8.1262e-04 eta 0:11:25
epoch [30/50] batch [80/403] time 0.065 (0.078) data 0.000 (0.007) loss 1.9414 (1.7762) teacher_loss 0.8220 (0.7730) loss_zs_kd 2.1288 (1.8045) loss_oracle 0.4674 (0.4699) acc 81.2500 (73.8672) lr 8.1262e-04 eta 0:10:57
epoch [30/50] batch [100/403] time 0.078 (0.077) data 0.001 (0.006) loss 2.2184 (1.7879) teacher_loss 1.1545 (0.7881) loss_zs_kd 1.9575 (1.8142) loss_oracle 0.4765 (0.4725) acc 65.6250 (73.4688) lr 8.1262e-04 eta 0:10:40
epoch [30/50] batch [120/403] time 0.075 (0.076) data 0.000 (0.005) loss 2.3077 (1.7918) teacher_loss 1.2282 (0.7834) loss_zs_kd 2.0193 (1.8215) loss_oracle 0.4536 (0.4745) acc 62.5000 (73.9583) lr 8.1262e-04 eta 0:10:32
epoch [30/50] batch [140/403] time 0.071 (0.075) data 0.000 (0.004) loss 1.7576 (1.7904) teacher_loss 0.7598 (0.7819) loss_zs_kd 2.1911 (1.8249) loss_oracle 0.4223 (0.4746) acc 68.7500 (73.8170) lr 8.1262e-04 eta 0:10:22
epoch [30/50] batch [160/403] time 0.070 (0.074) data 0.000 (0.004) loss 1.7088 (1.7918) teacher_loss 0.7330 (0.7816) loss_zs_kd 2.2600 (1.8267) loss_oracle 0.4427 (0.4737) acc 78.1250 (73.6719) lr 8.1262e-04 eta 0:10:16
epoch [30/50] batch [180/403] time 0.072 (0.074) data 0.000 (0.003) loss 2.0474 (1.7932) teacher_loss 0.9980 (0.7813) loss_zs_kd 1.8164 (1.8241) loss_oracle 0.4792 (0.4735) acc 68.7500 (73.7153) lr 8.1262e-04 eta 0:10:14
epoch [30/50] batch [200/403] time 0.064 (0.074) data 0.000 (0.003) loss 1.7805 (1.8008) teacher_loss 0.7287 (0.7846) loss_zs_kd 1.7524 (1.8237) loss_oracle 0.4347 (0.4731) acc 78.1250 (73.5156) lr 8.1262e-04 eta 0:10:10
epoch [30/50] batch [220/403] time 0.079 (0.074) data 0.000 (0.003) loss 1.7029 (1.7957) teacher_loss 0.7344 (0.7796) loss_zs_kd 2.5028 (1.8254) loss_oracle 0.4876 (0.4747) acc 81.2500 (73.7500) lr 8.1262e-04 eta 0:10:09
epoch [30/50] batch [240/403] time 0.073 (0.074) data 0.000 (0.002) loss 2.0274 (1.8031) teacher_loss 1.0090 (0.7863) loss_zs_kd 1.5367 (1.8149) loss_oracle 0.4469 (0.4756) acc 68.7500 (73.6068) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [260/403] time 0.074 (0.074) data 0.000 (0.002) loss 2.0441 (1.8025) teacher_loss 1.0572 (0.7858) loss_zs_kd 1.9970 (1.8243) loss_oracle 0.4253 (0.4758) acc 65.6250 (73.5216) lr 8.1262e-04 eta 0:10:06
epoch [30/50] batch [280/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.7443 (1.7957) teacher_loss 0.6318 (0.7796) loss_zs_kd 1.9997 (1.8292) loss_oracle 0.5381 (0.4756) acc 78.1250 (73.8058) lr 8.1262e-04 eta 0:10:04
epoch [30/50] batch [300/403] time 0.074 (0.074) data 0.000 (0.002) loss 1.4606 (1.7950) teacher_loss 0.4689 (0.7784) loss_zs_kd 1.9374 (1.8306) loss_oracle 0.5841 (0.4773) acc 81.2500 (73.8542) lr 8.1262e-04 eta 0:10:03
epoch [30/50] batch [320/403] time 0.076 (0.075) data 0.000 (0.002) loss 1.5466 (1.7951) teacher_loss 0.6421 (0.7779) loss_zs_kd 1.5772 (1.8300) loss_oracle 0.4274 (0.4781) acc 84.3750 (73.8477) lr 8.1262e-04 eta 0:10:10
epoch [30/50] batch [340/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.7607 (1.7925) teacher_loss 0.7041 (0.7752) loss_zs_kd 2.2111 (1.8335) loss_oracle 0.4947 (0.4780) acc 78.1250 (73.9338) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [360/403] time 0.063 (0.075) data 0.000 (0.002) loss 1.5511 (1.7883) teacher_loss 0.6916 (0.7737) loss_zs_kd 1.5716 (1.8337) loss_oracle 0.4541 (0.4779) acc 78.1250 (74.0451) lr 8.1262e-04 eta 0:10:04
epoch [30/50] batch [380/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.6528 (1.7877) teacher_loss 0.6580 (0.7741) loss_zs_kd 1.7004 (1.8370) loss_oracle 0.5249 (0.4779) acc 75.0000 (74.0296) lr 8.1262e-04 eta 0:10:02
epoch [30/50] batch [400/403] time 0.065 (0.074) data 0.000 (0.002) loss 1.7508 (1.7862) teacher_loss 0.7359 (0.7741) loss_zs_kd 1.8515 (1.8440) loss_oracle 0.3923 (0.4778) acc 78.1250 (73.9844) lr 8.1262e-04 eta 0:09:58
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,657
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 54.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,455
* accuracy: 41.7%
* error: 58.3%
* macro_f1: 29.5%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [31/50] batch [20/403] time 0.070 (0.107) data 0.000 (0.032) loss 1.7159 (1.7347) teacher_loss 0.7549 (0.7785) loss_zs_kd 1.6265 (1.8552) loss_oracle 0.4646 (0.4635) acc 68.7500 (72.9688) lr 7.5131e-04 eta 0:14:22
epoch [31/50] batch [40/403] time 0.064 (0.090) data 0.000 (0.016) loss 1.6284 (1.6886) teacher_loss 0.6546 (0.7163) loss_zs_kd 1.8746 (1.9301) loss_oracle 0.4828 (0.4694) acc 81.2500 (76.4844) lr 7.5131e-04 eta 0:11:57
epoch [31/50] batch [60/403] time 0.074 (0.084) data 0.001 (0.011) loss 1.5257 (1.6909) teacher_loss 0.5775 (0.7149) loss_zs_kd 1.7251 (1.9674) loss_oracle 0.4422 (0.4794) acc 78.1250 (76.9271) lr 7.5131e-04 eta 0:11:11
epoch [31/50] batch [80/403] time 0.075 (0.081) data 0.000 (0.008) loss 1.9816 (1.7212) teacher_loss 0.9138 (0.7427) loss_zs_kd 2.0012 (1.9653) loss_oracle 0.4339 (0.4768) acc 75.0000 (75.9766) lr 7.5131e-04 eta 0:10:47
epoch [31/50] batch [100/403] time 0.115 (0.083) data 0.001 (0.007) loss 1.3581 (1.7178) teacher_loss 0.5287 (0.7404) loss_zs_kd 1.8499 (1.9391) loss_oracle 0.4402 (0.4780) acc 81.2500 (75.6875) lr 7.5131e-04 eta 0:10:58
epoch [31/50] batch [120/403] time 0.071 (0.081) data 0.000 (0.006) loss 1.5003 (1.7190) teacher_loss 0.4293 (0.7442) loss_zs_kd 2.0222 (1.9358) loss_oracle 0.5331 (0.4794) acc 90.6250 (75.6250) lr 7.5131e-04 eta 0:10:46
epoch [31/50] batch [140/403] time 0.071 (0.080) data 0.000 (0.005) loss 1.5896 (1.7234) teacher_loss 0.5593 (0.7498) loss_zs_kd 2.1089 (1.9503) loss_oracle 0.4886 (0.4781) acc 75.0000 (75.2679) lr 7.5131e-04 eta 0:10:34
epoch [31/50] batch [160/403] time 0.074 (0.079) data 0.000 (0.004) loss 1.4922 (1.7245) teacher_loss 0.4847 (0.7515) loss_zs_kd 1.8560 (1.9220) loss_oracle 0.4797 (0.4762) acc 81.2500 (74.9609) lr 7.5131e-04 eta 0:10:27
epoch [31/50] batch [180/403] time 0.068 (0.078) data 0.000 (0.004) loss 1.9045 (1.7282) teacher_loss 0.9092 (0.7522) loss_zs_kd 1.9817 (1.9119) loss_oracle 0.5073 (0.4764) acc 65.6250 (74.8264) lr 7.5131e-04 eta 0:10:16
epoch [31/50] batch [200/403] time 0.074 (0.078) data 0.000 (0.003) loss 1.5903 (1.7317) teacher_loss 0.6142 (0.7546) loss_zs_kd 1.8206 (1.9165) loss_oracle 0.4252 (0.4770) acc 78.1250 (74.9375) lr 7.5131e-04 eta 0:10:09
epoch [31/50] batch [220/403] time 0.077 (0.077) data 0.001 (0.003) loss 1.8940 (1.7323) teacher_loss 0.9495 (0.7555) loss_zs_kd 1.8496 (1.8998) loss_oracle 0.5294 (0.4768) acc 56.2500 (74.7017) lr 7.5131e-04 eta 0:10:03
epoch [31/50] batch [240/403] time 0.065 (0.076) data 0.000 (0.003) loss 1.9387 (1.7354) teacher_loss 0.9007 (0.7590) loss_zs_kd 1.9781 (1.8937) loss_oracle 0.5049 (0.4773) acc 62.5000 (74.4661) lr 7.5131e-04 eta 0:09:57
epoch [31/50] batch [260/403] time 0.076 (0.076) data 0.000 (0.003) loss 1.9075 (1.7379) teacher_loss 0.8534 (0.7570) loss_zs_kd 2.0557 (1.8877) loss_oracle 0.4573 (0.4784) acc 65.6250 (74.5433) lr 7.5131e-04 eta 0:09:56
epoch [31/50] batch [280/403] time 0.077 (0.076) data 0.000 (0.003) loss 1.7262 (1.7441) teacher_loss 0.7013 (0.7601) loss_zs_kd 2.0643 (1.8780) loss_oracle 0.4547 (0.4796) acc 71.8750 (74.4420) lr 7.5131e-04 eta 0:09:53
epoch [31/50] batch [300/403] time 0.077 (0.076) data 0.001 (0.002) loss 1.7152 (1.7470) teacher_loss 0.7257 (0.7637) loss_zs_kd 2.3647 (1.8776) loss_oracle 0.4938 (0.4799) acc 71.8750 (74.3229) lr 7.5131e-04 eta 0:09:51
epoch [31/50] batch [320/403] time 0.084 (0.076) data 0.002 (0.002) loss 1.5935 (1.7494) teacher_loss 0.7093 (0.7657) loss_zs_kd 1.6033 (1.8680) loss_oracle 0.5177 (0.4800) acc 78.1250 (74.2676) lr 7.5131e-04 eta 0:09:49
epoch [31/50] batch [340/403] time 0.076 (0.076) data 0.000 (0.002) loss 1.7045 (1.7506) teacher_loss 0.7034 (0.7653) loss_zs_kd 1.6555 (1.8670) loss_oracle 0.4772 (0.4818) acc 75.0000 (74.3750) lr 7.5131e-04 eta 0:09:46
epoch [31/50] batch [360/403] time 0.072 (0.076) data 0.000 (0.002) loss 1.4854 (1.7539) teacher_loss 0.5211 (0.7687) loss_zs_kd 1.4106 (1.8654) loss_oracle 0.4793 (0.4825) acc 84.3750 (74.2622) lr 7.5131e-04 eta 0:09:41
epoch [31/50] batch [380/403] time 0.078 (0.075) data 0.000 (0.002) loss 1.7872 (1.7572) teacher_loss 0.8523 (0.7710) loss_zs_kd 1.8328 (1.8600) loss_oracle 0.4934 (0.4825) acc 78.1250 (74.1694) lr 7.5131e-04 eta 0:09:38
epoch [31/50] batch [400/403] time 0.063 (0.075) data 0.000 (0.002) loss 1.6360 (1.7575) teacher_loss 0.6368 (0.7711) loss_zs_kd 1.8922 (1.8534) loss_oracle 0.5269 (0.4827) acc 78.1250 (74.1250) lr 7.5131e-04 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,656
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 55.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,339
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 30.8%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [32/50] batch [20/403] time 0.066 (0.101) data 0.000 (0.027) loss 2.0002 (1.8206) teacher_loss 1.1194 (0.8198) loss_zs_kd 2.1111 (1.8844) loss_oracle 0.4169 (0.4897) acc 62.5000 (72.5000) lr 6.9098e-04 eta 0:12:48
epoch [32/50] batch [40/403] time 0.077 (0.086) data 0.000 (0.014) loss 1.9710 (1.7849) teacher_loss 0.9617 (0.7906) loss_zs_kd 1.7048 (1.8745) loss_oracle 0.4571 (0.4865) acc 71.8750 (73.6719) lr 6.9098e-04 eta 0:10:56
epoch [32/50] batch [60/403] time 0.070 (0.081) data 0.000 (0.009) loss 1.8805 (1.8116) teacher_loss 0.8237 (0.8091) loss_zs_kd 1.5540 (1.8238) loss_oracle 0.4599 (0.4887) acc 75.0000 (73.2812) lr 6.9098e-04 eta 0:10:16
epoch [32/50] batch [80/403] time 0.074 (0.080) data 0.000 (0.007) loss 1.7662 (1.7977) teacher_loss 0.7375 (0.7999) loss_zs_kd 2.1094 (1.7977) loss_oracle 0.5756 (0.4861) acc 68.7500 (73.0078) lr 6.9098e-04 eta 0:10:05
epoch [32/50] batch [100/403] time 0.076 (0.079) data 0.000 (0.006) loss 1.6963 (1.7957) teacher_loss 0.7558 (0.7975) loss_zs_kd 1.9462 (1.8145) loss_oracle 0.4517 (0.4858) acc 71.8750 (72.9688) lr 6.9098e-04 eta 0:09:56
epoch [32/50] batch [120/403] time 0.081 (0.078) data 0.000 (0.005) loss 1.5363 (1.7977) teacher_loss 0.5612 (0.7960) loss_zs_kd 1.8855 (1.8196) loss_oracle 0.5184 (0.4900) acc 81.2500 (73.2292) lr 6.9098e-04 eta 0:09:47
epoch [32/50] batch [140/403] time 0.071 (0.077) data 0.000 (0.004) loss 1.9838 (1.7984) teacher_loss 1.0166 (0.8010) loss_zs_kd 1.5923 (1.8258) loss_oracle 0.5118 (0.4920) acc 62.5000 (72.9464) lr 6.9098e-04 eta 0:09:42
epoch [32/50] batch [160/403] time 0.081 (0.077) data 0.001 (0.004) loss 1.5577 (1.7836) teacher_loss 0.6113 (0.7894) loss_zs_kd 1.3866 (1.8115) loss_oracle 0.4674 (0.4911) acc 78.1250 (73.3594) lr 6.9098e-04 eta 0:09:37
epoch [32/50] batch [180/403] time 0.079 (0.076) data 0.000 (0.003) loss 1.6820 (1.7790) teacher_loss 0.7821 (0.7899) loss_zs_kd 2.0574 (1.8069) loss_oracle 0.5382 (0.4908) acc 71.8750 (73.1424) lr 6.9098e-04 eta 0:09:31
epoch [32/50] batch [200/403] time 0.076 (0.076) data 0.000 (0.003) loss 1.5846 (1.7732) teacher_loss 0.6246 (0.7896) loss_zs_kd 2.1104 (1.8040) loss_oracle 0.4828 (0.4900) acc 75.0000 (73.2031) lr 6.9098e-04 eta 0:09:25
epoch [32/50] batch [220/403] time 0.083 (0.076) data 0.000 (0.003) loss 1.6869 (1.7734) teacher_loss 0.7592 (0.7931) loss_zs_kd 2.1618 (1.7985) loss_oracle 0.4986 (0.4887) acc 78.1250 (73.1392) lr 6.9098e-04 eta 0:09:23
epoch [32/50] batch [240/403] time 0.070 (0.075) data 0.000 (0.003) loss 1.9394 (1.7737) teacher_loss 0.9659 (0.7967) loss_zs_kd 1.9472 (1.8023) loss_oracle 0.4876 (0.4881) acc 59.3750 (72.9818) lr 6.9098e-04 eta 0:09:19
epoch [32/50] batch [260/403] time 0.075 (0.075) data 0.000 (0.002) loss 1.5449 (1.7715) teacher_loss 0.6383 (0.7992) loss_zs_kd 1.8278 (1.7936) loss_oracle 0.5324 (0.4877) acc 81.2500 (72.8365) lr 6.9098e-04 eta 0:09:15
epoch [32/50] batch [280/403] time 0.080 (0.075) data 0.000 (0.002) loss 1.5113 (1.7749) teacher_loss 0.6119 (0.8051) loss_zs_kd 1.5332 (1.7915) loss_oracle 0.4515 (0.4876) acc 78.1250 (72.6674) lr 6.9098e-04 eta 0:09:12
epoch [32/50] batch [300/403] time 0.107 (0.075) data 0.000 (0.002) loss 1.5384 (1.7756) teacher_loss 0.5563 (0.8068) loss_zs_kd 1.7174 (1.7935) loss_oracle 0.4884 (0.4868) acc 81.2500 (72.4688) lr 6.9098e-04 eta 0:09:13
epoch [32/50] batch [320/403] time 0.089 (0.076) data 0.000 (0.002) loss 1.6460 (1.7743) teacher_loss 0.5922 (0.8029) loss_zs_kd 1.9315 (1.7963) loss_oracle 0.5430 (0.4881) acc 84.3750 (72.5879) lr 6.9098e-04 eta 0:09:20
epoch [32/50] batch [340/403] time 0.077 (0.076) data 0.000 (0.002) loss 1.8147 (1.7770) teacher_loss 0.8288 (0.8039) loss_zs_kd 2.2467 (1.8021) loss_oracle 0.5019 (0.4896) acc 68.7500 (72.6195) lr 6.9098e-04 eta 0:09:17
epoch [32/50] batch [360/403] time 0.050 (0.075) data 0.000 (0.002) loss 1.6176 (1.7794) teacher_loss 0.6970 (0.8049) loss_zs_kd 1.7009 (1.8024) loss_oracle 0.4255 (0.4896) acc 78.1250 (72.5174) lr 6.9098e-04 eta 0:09:09
epoch [32/50] batch [380/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.9406 (1.7843) teacher_loss 0.9355 (0.8079) loss_zs_kd 1.8460 (1.7973) loss_oracle 0.5194 (0.4910) acc 62.5000 (72.5000) lr 6.9098e-04 eta 0:09:04
epoch [32/50] batch [400/403] time 0.064 (0.075) data 0.000 (0.002) loss 1.8787 (1.7828) teacher_loss 0.7087 (0.8074) loss_zs_kd 2.1787 (1.7964) loss_oracle 0.5807 (0.4910) acc 84.3750 (72.5703) lr 6.9098e-04 eta 0:09:01
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,649
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,320
* accuracy: 39.4%
* error: 60.6%
* macro_f1: 30.3%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [33/50] batch [20/403] time 0.074 (0.102) data 0.000 (0.027) loss 1.6713 (1.7241) teacher_loss 0.6963 (0.7473) loss_zs_kd 1.6477 (1.8149) loss_oracle 0.4748 (0.5022) acc 78.1250 (73.9062) lr 6.3188e-04 eta 0:12:16
epoch [33/50] batch [40/403] time 0.074 (0.088) data 0.000 (0.014) loss 1.5151 (1.7340) teacher_loss 0.4834 (0.7516) loss_zs_kd 2.3139 (1.8451) loss_oracle 0.5585 (0.5025) acc 84.3750 (74.5312) lr 6.3188e-04 eta 0:10:31
epoch [33/50] batch [60/403] time 0.074 (0.083) data 0.001 (0.009) loss 1.9490 (1.7395) teacher_loss 1.0022 (0.7569) loss_zs_kd 1.5382 (1.8536) loss_oracle 0.4592 (0.5024) acc 62.5000 (74.1667) lr 6.3188e-04 eta 0:09:56
epoch [33/50] batch [80/403] time 0.073 (0.081) data 0.000 (0.007) loss 1.7474 (1.7473) teacher_loss 0.7911 (0.7654) loss_zs_kd 1.7828 (1.8410) loss_oracle 0.4944 (0.5029) acc 65.6250 (74.1797) lr 6.3188e-04 eta 0:09:38
epoch [33/50] batch [100/403] time 0.072 (0.082) data 0.000 (0.006) loss 1.5388 (1.7540) teacher_loss 0.6679 (0.7740) loss_zs_kd 1.9397 (1.8598) loss_oracle 0.4843 (0.5031) acc 84.3750 (73.7500) lr 6.3188e-04 eta 0:09:49
epoch [33/50] batch [120/403] time 0.087 (0.081) data 0.000 (0.005) loss 1.8344 (1.7580) teacher_loss 0.8575 (0.7743) loss_zs_kd 2.0082 (1.8417) loss_oracle 0.5016 (0.5021) acc 71.8750 (73.3333) lr 6.3188e-04 eta 0:09:37
epoch [33/50] batch [140/403] time 0.071 (0.079) data 0.000 (0.004) loss 1.9274 (1.7564) teacher_loss 0.9787 (0.7725) loss_zs_kd 2.3064 (1.8564) loss_oracle 0.5034 (0.5031) acc 68.7500 (73.4375) lr 6.3188e-04 eta 0:09:25
epoch [33/50] batch [160/403] time 0.074 (0.078) data 0.000 (0.004) loss 1.4700 (1.7551) teacher_loss 0.5190 (0.7735) loss_zs_kd 1.9310 (1.8591) loss_oracle 0.5026 (0.5011) acc 84.3750 (73.4375) lr 6.3188e-04 eta 0:09:12
epoch [33/50] batch [180/403] time 0.068 (0.077) data 0.000 (0.003) loss 1.6273 (1.7527) teacher_loss 0.5876 (0.7723) loss_zs_kd 1.7643 (1.8593) loss_oracle 0.4888 (0.5006) acc 87.5000 (73.7500) lr 6.3188e-04 eta 0:09:06
epoch [33/50] batch [200/403] time 0.072 (0.077) data 0.000 (0.003) loss 1.6602 (1.7488) teacher_loss 0.6641 (0.7709) loss_zs_kd 1.4257 (1.8530) loss_oracle 0.4897 (0.4996) acc 81.2500 (73.7031) lr 6.3188e-04 eta 0:09:00
epoch [33/50] batch [220/403] time 0.074 (0.076) data 0.000 (0.003) loss 1.7375 (1.7465) teacher_loss 0.7704 (0.7696) loss_zs_kd 1.9996 (1.8516) loss_oracle 0.5285 (0.5006) acc 78.1250 (73.6364) lr 6.3188e-04 eta 0:08:56
epoch [33/50] batch [240/403] time 0.072 (0.076) data 0.000 (0.003) loss 1.6053 (1.7426) teacher_loss 0.6023 (0.7676) loss_zs_kd 1.9987 (1.8476) loss_oracle 0.5117 (0.5010) acc 81.2500 (73.6719) lr 6.3188e-04 eta 0:08:52
epoch [33/50] batch [260/403] time 0.066 (0.076) data 0.000 (0.002) loss 1.9889 (1.7425) teacher_loss 0.9581 (0.7694) loss_zs_kd 2.1725 (1.8498) loss_oracle 0.5482 (0.5012) acc 65.6250 (73.5096) lr 6.3188e-04 eta 0:08:49
epoch [33/50] batch [280/403] time 0.067 (0.076) data 0.000 (0.002) loss 1.4931 (1.7374) teacher_loss 0.5875 (0.7678) loss_zs_kd 2.1007 (1.8462) loss_oracle 0.5248 (0.5008) acc 81.2500 (73.5603) lr 6.3188e-04 eta 0:08:46
epoch [33/50] batch [300/403] time 0.077 (0.075) data 0.000 (0.002) loss 2.0411 (1.7402) teacher_loss 1.0982 (0.7707) loss_zs_kd 1.9265 (1.8433) loss_oracle 0.4883 (0.5008) acc 65.6250 (73.4479) lr 6.3188e-04 eta 0:08:44
epoch [33/50] batch [320/403] time 0.062 (0.075) data 0.000 (0.002) loss 1.8799 (1.7415) teacher_loss 0.8966 (0.7722) loss_zs_kd 2.3982 (1.8480) loss_oracle 0.5420 (0.5018) acc 65.6250 (73.4668) lr 6.3188e-04 eta 0:08:41
epoch [33/50] batch [340/403] time 0.063 (0.074) data 0.000 (0.002) loss 1.5784 (1.7400) teacher_loss 0.7534 (0.7709) loss_zs_kd 1.7878 (1.8513) loss_oracle 0.4779 (0.5028) acc 75.0000 (73.4926) lr 6.3188e-04 eta 0:08:34
epoch [33/50] batch [360/403] time 0.067 (0.074) data 0.000 (0.002) loss 2.0938 (1.7427) teacher_loss 1.1123 (0.7734) loss_zs_kd 1.6178 (1.8579) loss_oracle 0.5058 (0.5033) acc 65.6250 (73.4549) lr 6.3188e-04 eta 0:08:28
epoch [33/50] batch [380/403] time 0.065 (0.074) data 0.000 (0.002) loss 1.9443 (1.7471) teacher_loss 0.9432 (0.7794) loss_zs_kd 1.4082 (1.8474) loss_oracle 0.5394 (0.5035) acc 68.7500 (73.2072) lr 6.3188e-04 eta 0:08:26
epoch [33/50] batch [400/403] time 0.069 (0.073) data 0.000 (0.002) loss 1.6891 (1.7460) teacher_loss 0.7450 (0.7784) loss_zs_kd 1.9578 (1.8407) loss_oracle 0.4822 (0.5034) acc 75.0000 (73.1953) lr 6.3188e-04 eta 0:08:23
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,912
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 59.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,459
* accuracy: 41.8%
* error: 58.2%
* macro_f1: 31.6%
******* Domain 4 best val acc:      71.3%, epoch: 28 *******
******* Domain 4 best val test acc: 44.1%, epoch: 28 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [34/50] batch [20/403] time 0.064 (0.100) data 0.000 (0.028) loss 1.5762 (1.7178) teacher_loss 0.6739 (0.7591) loss_zs_kd 1.5200 (1.9277) loss_oracle 0.5248 (0.5053) acc 78.1250 (72.5000) lr 5.7422e-04 eta 0:11:25
epoch [34/50] batch [40/403] time 0.065 (0.085) data 0.000 (0.014) loss 1.9470 (1.7384) teacher_loss 0.9780 (0.7751) loss_zs_kd 1.5814 (1.7954) loss_oracle 0.5326 (0.4999) acc 62.5000 (72.5781) lr 5.7422e-04 eta 0:09:35
epoch [34/50] batch [60/403] time 0.072 (0.079) data 0.001 (0.010) loss 1.8963 (1.7413) teacher_loss 0.8039 (0.7745) loss_zs_kd 1.9122 (1.8243) loss_oracle 0.6144 (0.5079) acc 68.7500 (73.0729) lr 5.7422e-04 eta 0:08:59
epoch [34/50] batch [80/403] time 0.068 (0.079) data 0.000 (0.007) loss 1.6898 (1.7625) teacher_loss 0.7939 (0.7887) loss_zs_kd 2.2202 (1.8461) loss_oracle 0.5009 (0.5085) acc 65.6250 (72.5000) lr 5.7422e-04 eta 0:08:53
epoch [34/50] batch [100/403] time 0.073 (0.076) data 0.000 (0.006) loss 1.9357 (1.7639) teacher_loss 0.9995 (0.7974) loss_zs_kd 2.0249 (1.8315) loss_oracle 0.5272 (0.5059) acc 62.5000 (72.1562) lr 5.7422e-04 eta 0:08:35
epoch [34/50] batch [120/403] time 0.078 (0.076) data 0.000 (0.005) loss 1.7966 (1.7592) teacher_loss 0.8918 (0.7947) loss_zs_kd 1.7582 (1.8194) loss_oracle 0.5237 (0.5051) acc 65.6250 (72.2135) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [140/403] time 0.081 (0.075) data 0.000 (0.004) loss 2.2255 (1.7524) teacher_loss 1.1383 (0.7896) loss_zs_kd 1.8576 (1.8384) loss_oracle 0.5500 (0.5057) acc 65.6250 (72.5670) lr 5.7422e-04 eta 0:08:24
epoch [34/50] batch [160/403] time 0.072 (0.075) data 0.000 (0.004) loss 1.5002 (1.7464) teacher_loss 0.5458 (0.7840) loss_zs_kd 1.9135 (1.8391) loss_oracle 0.4671 (0.5054) acc 81.2500 (72.7539) lr 5.7422e-04 eta 0:08:22
epoch [34/50] batch [180/403] time 0.077 (0.075) data 0.000 (0.003) loss 1.6196 (1.7454) teacher_loss 0.5892 (0.7809) loss_zs_kd 1.8293 (1.8331) loss_oracle 0.4860 (0.5054) acc 81.2500 (72.9167) lr 5.7422e-04 eta 0:08:17
epoch [34/50] batch [200/403] time 0.075 (0.074) data 0.000 (0.003) loss 1.5407 (1.7468) teacher_loss 0.6298 (0.7817) loss_zs_kd 1.7041 (1.8460) loss_oracle 0.4737 (0.5059) acc 84.3750 (73.0312) lr 5.7422e-04 eta 0:08:13
epoch [34/50] batch [220/403] time 0.072 (0.074) data 0.000 (0.003) loss 2.2785 (1.7501) teacher_loss 1.2553 (0.7866) loss_zs_kd 1.7987 (1.8439) loss_oracle 0.5321 (0.5054) acc 53.1250 (72.9403) lr 5.7422e-04 eta 0:08:10
epoch [34/50] batch [240/403] time 0.073 (0.074) data 0.000 (0.003) loss 1.5728 (1.7496) teacher_loss 0.7181 (0.7883) loss_zs_kd 1.8282 (1.8299) loss_oracle 0.4796 (0.5051) acc 81.2500 (72.8776) lr 5.7422e-04 eta 0:08:09
epoch [34/50] batch [260/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.3702 (1.7464) teacher_loss 0.4767 (0.7870) loss_zs_kd 2.2879 (1.8289) loss_oracle 0.5051 (0.5050) acc 87.5000 (72.8726) lr 5.7422e-04 eta 0:08:09
epoch [34/50] batch [280/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.3161 (1.7453) teacher_loss 0.4492 (0.7884) loss_zs_kd 1.5792 (1.8235) loss_oracle 0.4897 (0.5046) acc 84.3750 (72.7344) lr 5.7422e-04 eta 0:08:06
epoch [34/50] batch [300/403] time 0.075 (0.074) data 0.000 (0.002) loss 2.0137 (1.7464) teacher_loss 1.0194 (0.7896) loss_zs_kd 2.1921 (1.8132) loss_oracle 0.5479 (0.5050) acc 71.8750 (72.6875) lr 5.7422e-04 eta 0:08:03
epoch [34/50] batch [320/403] time 0.072 (0.074) data 0.000 (0.002) loss 2.0866 (1.7438) teacher_loss 1.1771 (0.7881) loss_zs_kd 1.2889 (1.8135) loss_oracle 0.5424 (0.5050) acc 56.2500 (72.7051) lr 5.7422e-04 eta 0:08:01
epoch [34/50] batch [340/403] time 0.090 (0.075) data 0.001 (0.002) loss 1.6895 (1.7433) teacher_loss 0.7400 (0.7885) loss_zs_kd 1.4648 (1.8080) loss_oracle 0.5028 (0.5045) acc 71.8750 (72.6930) lr 5.7422e-04 eta 0:08:05
epoch [34/50] batch [360/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.9317 (1.7441) teacher_loss 0.9902 (0.7901) loss_zs_kd 2.0677 (1.8030) loss_oracle 0.5159 (0.5043) acc 71.8750 (72.6476) lr 5.7422e-04 eta 0:08:05
epoch [34/50] batch [380/403] time 0.077 (0.075) data 0.000 (0.002) loss 1.6999 (1.7447) teacher_loss 0.8355 (0.7912) loss_zs_kd 1.6033 (1.7976) loss_oracle 0.4940 (0.5039) acc 62.5000 (72.6151) lr 5.7422e-04 eta 0:08:03
epoch [34/50] batch [400/403] time 0.066 (0.075) data 0.000 (0.002) loss 1.7604 (1.7448) teacher_loss 0.7826 (0.7919) loss_zs_kd 2.0907 (1.8008) loss_oracle 0.5373 (0.5038) acc 75.0000 (72.6172) lr 5.7422e-04 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,953
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 58.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,421
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 31.0%
******* Domain 4 best val acc:      71.4%, epoch: 34 *******
******* Domain 4 best val test acc: 41.2%, epoch: 34 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [35/50] batch [20/403] time 0.068 (0.098) data 0.000 (0.026) loss 1.7638 (1.7638) teacher_loss 0.8666 (0.8316) loss_zs_kd 2.2274 (1.8902) loss_oracle 0.4806 (0.5042) acc 75.0000 (70.4688) lr 5.1825e-04 eta 0:10:32
epoch [35/50] batch [40/403] time 0.071 (0.085) data 0.000 (0.013) loss 1.7826 (1.7393) teacher_loss 0.8569 (0.8116) loss_zs_kd 1.7345 (1.9012) loss_oracle 0.4669 (0.5085) acc 68.7500 (72.4219) lr 5.1825e-04 eta 0:09:03
epoch [35/50] batch [60/403] time 0.074 (0.081) data 0.001 (0.009) loss 1.7448 (1.7454) teacher_loss 0.8561 (0.8179) loss_zs_kd 1.7084 (1.8715) loss_oracle 0.5202 (0.5044) acc 81.2500 (73.1250) lr 5.1825e-04 eta 0:08:34
epoch [35/50] batch [80/403] time 0.068 (0.078) data 0.000 (0.007) loss 1.7145 (1.7314) teacher_loss 0.7218 (0.8029) loss_zs_kd 1.6849 (1.8703) loss_oracle 0.4829 (0.5027) acc 71.8750 (73.6328) lr 5.1825e-04 eta 0:08:18
epoch [35/50] batch [100/403] time 0.073 (0.077) data 0.000 (0.005) loss 1.7930 (1.7343) teacher_loss 0.9096 (0.8078) loss_zs_kd 1.6072 (1.8659) loss_oracle 0.5270 (0.5033) acc 68.7500 (73.1562) lr 5.1825e-04 eta 0:08:08
epoch [35/50] batch [120/403] time 0.080 (0.079) data 0.001 (0.005) loss 1.5367 (1.7334) teacher_loss 0.5657 (0.8065) loss_zs_kd 1.9875 (1.8828) loss_oracle 0.4917 (0.5023) acc 78.1250 (72.8385) lr 5.1825e-04 eta 0:08:19
epoch [35/50] batch [140/403] time 0.070 (0.078) data 0.000 (0.004) loss 1.8468 (1.7295) teacher_loss 0.9434 (0.8021) loss_zs_kd 1.4659 (1.8905) loss_oracle 0.4943 (0.5015) acc 68.7500 (72.9911) lr 5.1825e-04 eta 0:08:12
epoch [35/50] batch [160/403] time 0.072 (0.077) data 0.000 (0.004) loss 1.7532 (1.7386) teacher_loss 0.8530 (0.8109) loss_zs_kd 1.7588 (1.8932) loss_oracle 0.4582 (0.5006) acc 68.7500 (72.6367) lr 5.1825e-04 eta 0:08:07
epoch [35/50] batch [180/403] time 0.067 (0.077) data 0.000 (0.003) loss 1.7279 (1.7394) teacher_loss 0.7928 (0.8090) loss_zs_kd 1.3911 (1.8817) loss_oracle 0.5188 (0.5000) acc 78.1250 (72.7083) lr 5.1825e-04 eta 0:08:02
epoch [35/50] batch [200/403] time 0.067 (0.076) data 0.000 (0.003) loss 1.6582 (1.7384) teacher_loss 0.7079 (0.8064) loss_zs_kd 1.7851 (1.8793) loss_oracle 0.4545 (0.4997) acc 78.1250 (72.7812) lr 5.1825e-04 eta 0:07:53
epoch [35/50] batch [220/403] time 0.081 (0.076) data 0.001 (0.003) loss 1.7254 (1.7450) teacher_loss 0.7804 (0.8110) loss_zs_kd 2.2710 (1.8764) loss_oracle 0.5460 (0.5009) acc 68.7500 (72.5710) lr 5.1825e-04 eta 0:07:50
epoch [35/50] batch [240/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.5326 (1.7402) teacher_loss 0.6079 (0.8035) loss_zs_kd 1.8590 (1.8707) loss_oracle 0.4498 (0.5014) acc 75.0000 (72.7734) lr 5.1825e-04 eta 0:07:48
epoch [35/50] batch [260/403] time 0.096 (0.075) data 0.001 (0.002) loss 1.9722 (1.7424) teacher_loss 0.8970 (0.8038) loss_zs_kd 1.6383 (1.8668) loss_oracle 0.4913 (0.5014) acc 75.0000 (72.6442) lr 5.1825e-04 eta 0:07:45
epoch [35/50] batch [280/403] time 0.067 (0.075) data 0.000 (0.002) loss 1.8111 (1.7423) teacher_loss 0.8909 (0.8017) loss_zs_kd 1.6044 (1.8515) loss_oracle 0.5054 (0.5021) acc 59.3750 (72.5781) lr 5.1825e-04 eta 0:07:43
epoch [35/50] batch [300/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.6620 (1.7408) teacher_loss 0.7210 (0.7986) loss_zs_kd 1.6013 (1.8492) loss_oracle 0.4890 (0.5023) acc 84.3750 (72.7083) lr 5.1825e-04 eta 0:07:41
epoch [35/50] batch [320/403] time 0.083 (0.075) data 0.000 (0.002) loss 1.6504 (1.7432) teacher_loss 0.5976 (0.7999) loss_zs_kd 1.6551 (1.8502) loss_oracle 0.5072 (0.5038) acc 81.2500 (72.6855) lr 5.1825e-04 eta 0:07:38
epoch [35/50] batch [340/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.7720 (1.7446) teacher_loss 0.8638 (0.7999) loss_zs_kd 1.5554 (1.8481) loss_oracle 0.4983 (0.5039) acc 68.7500 (72.7022) lr 5.1825e-04 eta 0:07:36
epoch [35/50] batch [360/403] time 0.062 (0.074) data 0.000 (0.002) loss 1.6165 (1.7469) teacher_loss 0.5729 (0.8008) loss_zs_kd 1.4384 (1.8407) loss_oracle 0.5264 (0.5045) acc 81.2500 (72.7517) lr 5.1825e-04 eta 0:07:31
epoch [35/50] batch [380/403] time 0.071 (0.074) data 0.000 (0.002) loss 1.6070 (1.7421) teacher_loss 0.6542 (0.7937) loss_zs_kd 1.8890 (1.8444) loss_oracle 0.4910 (0.5053) acc 75.0000 (73.0181) lr 5.1825e-04 eta 0:07:29
epoch [35/50] batch [400/403] time 0.060 (0.074) data 0.000 (0.002) loss 1.7194 (1.7401) teacher_loss 0.7331 (0.7898) loss_zs_kd 1.6093 (1.8419) loss_oracle 0.5124 (0.5063) acc 71.8750 (73.1172) lr 5.1825e-04 eta 0:07:26
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,845
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 58.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,420
* accuracy: 41.1%
* error: 58.9%
* macro_f1: 31.0%
******* Domain 4 best val acc:      71.4%, epoch: 34 *******
******* Domain 4 best val test acc: 41.2%, epoch: 34 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [36/50] batch [20/403] time 0.069 (0.100) data 0.000 (0.028) loss 1.8708 (1.7764) teacher_loss 0.9364 (0.8155) loss_zs_kd 2.4612 (1.8841) loss_oracle 0.5055 (0.5144) acc 62.5000 (71.5625) lr 4.6417e-04 eta 0:10:04
epoch [36/50] batch [40/403] time 0.059 (0.083) data 0.000 (0.014) loss 1.6138 (1.7810) teacher_loss 0.6744 (0.8169) loss_zs_kd 1.9076 (1.8539) loss_oracle 0.4923 (0.5151) acc 87.5000 (71.7188) lr 4.6417e-04 eta 0:08:17
epoch [36/50] batch [60/403] time 0.070 (0.080) data 0.001 (0.010) loss 1.9406 (1.7805) teacher_loss 0.9897 (0.8157) loss_zs_kd 2.1167 (1.8811) loss_oracle 0.5294 (0.5208) acc 68.7500 (71.9792) lr 4.6417e-04 eta 0:07:58
epoch [36/50] batch [80/403] time 0.072 (0.078) data 0.000 (0.007) loss 1.7793 (1.7701) teacher_loss 0.7833 (0.8007) loss_zs_kd 1.7254 (1.8624) loss_oracle 0.5047 (0.5209) acc 71.8750 (72.7344) lr 4.6417e-04 eta 0:07:43
epoch [36/50] batch [100/403] time 0.075 (0.076) data 0.000 (0.006) loss 1.6590 (1.7635) teacher_loss 0.7521 (0.7925) loss_zs_kd 1.9962 (1.8711) loss_oracle 0.5354 (0.5218) acc 75.0000 (73.3125) lr 4.6417e-04 eta 0:07:32
epoch [36/50] batch [120/403] time 0.065 (0.074) data 0.000 (0.005) loss 1.4620 (1.7590) teacher_loss 0.5441 (0.7912) loss_zs_kd 1.9474 (1.8579) loss_oracle 0.5012 (0.5201) acc 84.3750 (73.3854) lr 4.6417e-04 eta 0:07:18
epoch [36/50] batch [140/403] time 0.065 (0.074) data 0.000 (0.004) loss 1.9218 (1.7649) teacher_loss 1.0068 (0.7984) loss_zs_kd 1.8285 (1.8636) loss_oracle 0.5300 (0.5199) acc 62.5000 (73.0804) lr 4.6417e-04 eta 0:07:14
epoch [36/50] batch [160/403] time 0.084 (0.073) data 0.000 (0.004) loss 1.8569 (1.7484) teacher_loss 0.8420 (0.7836) loss_zs_kd 1.8877 (1.8570) loss_oracle 0.5290 (0.5198) acc 71.8750 (73.4766) lr 4.6417e-04 eta 0:07:11
epoch [36/50] batch [180/403] time 0.069 (0.073) data 0.000 (0.003) loss 2.0366 (1.7466) teacher_loss 1.0457 (0.7837) loss_zs_kd 2.1411 (1.8652) loss_oracle 0.5711 (0.5200) acc 62.5000 (73.5417) lr 4.6417e-04 eta 0:07:10
epoch [36/50] batch [200/403] time 0.075 (0.073) data 0.000 (0.003) loss 2.0340 (1.7494) teacher_loss 1.1338 (0.7889) loss_zs_kd 1.7492 (1.8583) loss_oracle 0.5267 (0.5193) acc 59.3750 (73.4844) lr 4.6417e-04 eta 0:07:07
epoch [36/50] batch [220/403] time 0.067 (0.073) data 0.000 (0.003) loss 1.5650 (1.7481) teacher_loss 0.6384 (0.7904) loss_zs_kd 1.6323 (1.8572) loss_oracle 0.4807 (0.5184) acc 75.0000 (73.3097) lr 4.6417e-04 eta 0:07:04
epoch [36/50] batch [240/403] time 0.077 (0.073) data 0.000 (0.003) loss 1.9211 (1.7388) teacher_loss 1.0194 (0.7838) loss_zs_kd 2.0503 (1.8651) loss_oracle 0.4749 (0.5174) acc 68.7500 (73.5286) lr 4.6417e-04 eta 0:07:02
epoch [36/50] batch [260/403] time 0.070 (0.073) data 0.000 (0.002) loss 1.8396 (1.7331) teacher_loss 0.8533 (0.7818) loss_zs_kd 1.7607 (1.8642) loss_oracle 0.4883 (0.5163) acc 71.8750 (73.6418) lr 4.6417e-04 eta 0:07:01
epoch [36/50] batch [280/403] time 0.068 (0.073) data 0.000 (0.002) loss 1.8975 (1.7319) teacher_loss 0.9954 (0.7843) loss_zs_kd 1.6762 (1.8622) loss_oracle 0.5001 (0.5151) acc 53.1250 (73.6049) lr 4.6417e-04 eta 0:06:58
epoch [36/50] batch [300/403] time 0.079 (0.073) data 0.000 (0.002) loss 1.5147 (1.7320) teacher_loss 0.6857 (0.7870) loss_zs_kd 1.5810 (1.8557) loss_oracle 0.4976 (0.5145) acc 78.1250 (73.4479) lr 4.6417e-04 eta 0:06:57
epoch [36/50] batch [320/403] time 0.074 (0.073) data 0.000 (0.002) loss 1.6236 (1.7308) teacher_loss 0.7447 (0.7883) loss_zs_kd 1.6054 (1.8526) loss_oracle 0.4920 (0.5139) acc 75.0000 (73.3203) lr 4.6417e-04 eta 0:06:56
epoch [36/50] batch [340/403] time 0.064 (0.073) data 0.000 (0.002) loss 1.7745 (1.7361) teacher_loss 0.9384 (0.7961) loss_zs_kd 1.9832 (1.8529) loss_oracle 0.5217 (0.5135) acc 75.0000 (73.1158) lr 4.6417e-04 eta 0:06:54
epoch [36/50] batch [360/403] time 0.072 (0.074) data 0.000 (0.002) loss 1.8695 (1.7376) teacher_loss 0.9188 (0.8000) loss_zs_kd 2.3092 (1.8498) loss_oracle 0.5420 (0.5125) acc 65.6250 (72.9080) lr 4.6417e-04 eta 0:06:58
epoch [36/50] batch [380/403] time 0.072 (0.073) data 0.000 (0.002) loss 1.8160 (1.7345) teacher_loss 1.0001 (0.8001) loss_zs_kd 2.2669 (1.8514) loss_oracle 0.4972 (0.5115) acc 59.3750 (72.8125) lr 4.6417e-04 eta 0:06:55
epoch [36/50] batch [400/403] time 0.071 (0.073) data 0.001 (0.002) loss 1.7264 (1.7334) teacher_loss 0.8276 (0.8009) loss_zs_kd 1.7078 (1.8453) loss_oracle 0.4724 (0.5111) acc 65.6250 (72.7422) lr 4.6417e-04 eta 0:06:52
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,950
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 58.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,555
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.1%
******* Domain 4 best val acc:      71.4%, epoch: 34 *******
******* Domain 4 best val test acc: 41.2%, epoch: 34 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [37/50] batch [20/403] time 0.063 (0.089) data 0.000 (0.025) loss 1.8014 (1.7637) teacher_loss 0.8522 (0.8581) loss_zs_kd 2.2057 (1.9697) loss_oracle 0.4920 (0.5019) acc 65.6250 (71.5625) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [40/403] time 0.080 (0.080) data 0.000 (0.012) loss 1.6619 (1.7363) teacher_loss 0.7748 (0.8400) loss_zs_kd 1.8987 (1.8936) loss_oracle 0.5006 (0.4997) acc 71.8750 (72.0312) lr 4.1221e-04 eta 0:07:27
epoch [37/50] batch [60/403] time 0.070 (0.077) data 0.000 (0.008) loss 1.7175 (1.7297) teacher_loss 0.7545 (0.8318) loss_zs_kd 2.1453 (1.8585) loss_oracle 0.5388 (0.4996) acc 68.7500 (71.1458) lr 4.1221e-04 eta 0:07:09
epoch [37/50] batch [80/403] time 0.066 (0.075) data 0.000 (0.006) loss 1.7940 (1.7272) teacher_loss 0.8430 (0.8274) loss_zs_kd 2.0783 (1.8956) loss_oracle 0.5245 (0.5016) acc 75.0000 (71.6406) lr 4.1221e-04 eta 0:06:57
epoch [37/50] batch [100/403] time 0.072 (0.074) data 0.000 (0.005) loss 1.6867 (1.7208) teacher_loss 0.8067 (0.8220) loss_zs_kd 2.0483 (1.8754) loss_oracle 0.4615 (0.4996) acc 71.8750 (71.9688) lr 4.1221e-04 eta 0:06:50
epoch [37/50] batch [120/403] time 0.083 (0.074) data 0.000 (0.004) loss 1.4883 (1.7160) teacher_loss 0.5651 (0.8210) loss_zs_kd 2.0267 (1.8458) loss_oracle 0.4877 (0.4986) acc 78.1250 (71.7188) lr 4.1221e-04 eta 0:06:46
epoch [37/50] batch [140/403] time 0.072 (0.076) data 0.000 (0.004) loss 1.6974 (1.7092) teacher_loss 0.8549 (0.8171) loss_zs_kd 1.6942 (1.8312) loss_oracle 0.4910 (0.4981) acc 68.7500 (71.9196) lr 4.1221e-04 eta 0:06:58
epoch [37/50] batch [160/403] time 0.068 (0.075) data 0.000 (0.003) loss 1.4651 (1.7062) teacher_loss 0.5346 (0.8160) loss_zs_kd 1.9275 (1.8266) loss_oracle 0.4676 (0.4979) acc 81.2500 (71.6406) lr 4.1221e-04 eta 0:06:51
epoch [37/50] batch [180/403] time 0.075 (0.075) data 0.000 (0.003) loss 1.5860 (1.7078) teacher_loss 0.6364 (0.8161) loss_zs_kd 1.7289 (1.8299) loss_oracle 0.5313 (0.4985) acc 78.1250 (71.8056) lr 4.1221e-04 eta 0:06:48
epoch [37/50] batch [200/403] time 0.074 (0.074) data 0.000 (0.003) loss 1.9899 (1.7047) teacher_loss 1.0989 (0.8139) loss_zs_kd 1.5744 (1.8201) loss_oracle 0.5084 (0.4978) acc 62.5000 (71.9531) lr 4.1221e-04 eta 0:06:44
epoch [37/50] batch [220/403] time 0.073 (0.074) data 0.000 (0.003) loss 1.7216 (1.7019) teacher_loss 0.8536 (0.8103) loss_zs_kd 2.1498 (1.8257) loss_oracle 0.5549 (0.4987) acc 71.8750 (72.0597) lr 4.1221e-04 eta 0:06:43
epoch [37/50] batch [240/403] time 0.070 (0.074) data 0.000 (0.002) loss 1.4969 (1.7019) teacher_loss 0.5861 (0.8098) loss_zs_kd 2.0532 (1.8201) loss_oracle 0.4963 (0.4988) acc 78.1250 (72.0703) lr 4.1221e-04 eta 0:06:39
epoch [37/50] batch [260/403] time 0.055 (0.074) data 0.000 (0.002) loss 1.4959 (1.7068) teacher_loss 0.6432 (0.8153) loss_zs_kd 2.0210 (1.8248) loss_oracle 0.4659 (0.4987) acc 81.2500 (71.9591) lr 4.1221e-04 eta 0:06:37
epoch [37/50] batch [280/403] time 0.062 (0.073) data 0.000 (0.002) loss 1.8982 (1.7066) teacher_loss 0.9679 (0.8141) loss_zs_kd 2.0939 (1.8280) loss_oracle 0.5071 (0.4987) acc 71.8750 (71.9754) lr 4.1221e-04 eta 0:06:31
epoch [37/50] batch [300/403] time 0.045 (0.072) data 0.000 (0.002) loss 1.7073 (1.7098) teacher_loss 0.8797 (0.8176) loss_zs_kd 1.8299 (1.8272) loss_oracle 0.5017 (0.4991) acc 65.6250 (71.7917) lr 4.1221e-04 eta 0:06:22
epoch [37/50] batch [320/403] time 0.067 (0.070) data 0.000 (0.002) loss 1.3417 (1.7095) teacher_loss 0.4798 (0.8184) loss_zs_kd 1.5916 (1.8301) loss_oracle 0.4794 (0.4986) acc 87.5000 (71.7969) lr 4.1221e-04 eta 0:06:13
epoch [37/50] batch [340/403] time 0.070 (0.070) data 0.000 (0.002) loss 1.6902 (1.7091) teacher_loss 0.7583 (0.8171) loss_zs_kd 1.9481 (1.8330) loss_oracle 0.4972 (0.4994) acc 78.1250 (71.8199) lr 4.1221e-04 eta 0:06:08
epoch [37/50] batch [360/403] time 0.070 (0.069) data 0.000 (0.002) loss 1.4509 (1.7096) teacher_loss 0.5261 (0.8168) loss_zs_kd 1.5749 (1.8308) loss_oracle 0.4856 (0.4992) acc 78.1250 (71.7361) lr 4.1221e-04 eta 0:06:04
epoch [37/50] batch [380/403] time 0.071 (0.069) data 0.000 (0.002) loss 1.7295 (1.7101) teacher_loss 0.8508 (0.8167) loss_zs_kd 1.9477 (1.8352) loss_oracle 0.5227 (0.4994) acc 68.7500 (71.7434) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [400/403] time 0.068 (0.069) data 0.001 (0.002) loss 1.9448 (1.7129) teacher_loss 1.0914 (0.8198) loss_zs_kd 1.9070 (1.8352) loss_oracle 0.4647 (0.4993) acc 59.3750 (71.6875) lr 4.1221e-04 eta 0:06:01
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,954
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 58.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,582
* accuracy: 43.9%
* error: 56.1%
* macro_f1: 32.9%
******* Domain 4 best val acc:      71.4%, epoch: 37 *******
******* Domain 4 best val test acc: 43.9%, epoch: 37 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [38/50] batch [20/403] time 0.076 (0.102) data 0.000 (0.027) loss 2.0984 (1.7261) teacher_loss 1.0464 (0.8098) loss_zs_kd 1.7462 (1.7844) loss_oracle 0.5381 (0.4881) acc 62.5000 (71.2500) lr 3.6258e-04 eta 0:08:49
epoch [38/50] batch [40/403] time 0.076 (0.087) data 0.000 (0.014) loss 1.9313 (1.7379) teacher_loss 1.0329 (0.8216) loss_zs_kd 2.0908 (1.7834) loss_oracle 0.4748 (0.4936) acc 71.8750 (71.7188) lr 3.6258e-04 eta 0:07:34
epoch [38/50] batch [60/403] time 0.076 (0.083) data 0.001 (0.009) loss 1.9164 (1.7333) teacher_loss 1.0441 (0.8167) loss_zs_kd 1.6838 (1.8072) loss_oracle 0.4740 (0.4927) acc 65.6250 (72.2917) lr 3.6258e-04 eta 0:07:08
epoch [38/50] batch [80/403] time 0.068 (0.080) data 0.000 (0.007) loss 1.8073 (1.7212) teacher_loss 0.8907 (0.8028) loss_zs_kd 1.7945 (1.8176) loss_oracle 0.5067 (0.4950) acc 68.7500 (72.3047) lr 3.6258e-04 eta 0:06:53
epoch [38/50] batch [100/403] time 0.053 (0.078) data 0.000 (0.006) loss 1.9153 (1.7239) teacher_loss 1.0443 (0.8061) loss_zs_kd 1.5805 (1.8362) loss_oracle 0.4752 (0.4946) acc 65.6250 (72.1875) lr 3.6258e-04 eta 0:06:41
epoch [38/50] batch [120/403] time 0.063 (0.074) data 0.000 (0.005) loss 1.7774 (1.7331) teacher_loss 0.8087 (0.8128) loss_zs_kd 1.8913 (1.8402) loss_oracle 0.5139 (0.4949) acc 68.7500 (71.9792) lr 3.6258e-04 eta 0:06:17
epoch [38/50] batch [140/403] time 0.068 (0.073) data 0.000 (0.004) loss 1.5835 (1.7389) teacher_loss 0.6570 (0.8183) loss_zs_kd 1.8458 (1.8468) loss_oracle 0.5147 (0.4954) acc 75.0000 (71.8304) lr 3.6258e-04 eta 0:06:13
epoch [38/50] batch [160/403] time 0.069 (0.073) data 0.000 (0.004) loss 1.6643 (1.7344) teacher_loss 0.7281 (0.8150) loss_zs_kd 1.8136 (1.8370) loss_oracle 0.5127 (0.4956) acc 81.2500 (71.8945) lr 3.6258e-04 eta 0:06:10
epoch [38/50] batch [180/403] time 0.065 (0.073) data 0.000 (0.003) loss 1.6404 (1.7295) teacher_loss 0.6839 (0.8125) loss_zs_kd 1.8102 (1.8313) loss_oracle 0.4763 (0.4940) acc 78.1250 (71.7882) lr 3.6258e-04 eta 0:06:08
epoch [38/50] batch [200/403] time 0.070 (0.073) data 0.000 (0.003) loss 1.8775 (1.7383) teacher_loss 0.8937 (0.8213) loss_zs_kd 1.6314 (1.8269) loss_oracle 0.4792 (0.4942) acc 71.8750 (71.7188) lr 3.6258e-04 eta 0:06:06
epoch [38/50] batch [220/403] time 0.086 (0.073) data 0.000 (0.003) loss 1.6893 (1.7383) teacher_loss 0.8082 (0.8232) loss_zs_kd 2.1229 (1.8234) loss_oracle 0.5134 (0.4937) acc 71.8750 (71.6903) lr 3.6258e-04 eta 0:06:05
epoch [38/50] batch [240/403] time 0.071 (0.073) data 0.000 (0.003) loss 1.7403 (1.7376) teacher_loss 0.8522 (0.8211) loss_zs_kd 2.4773 (1.8234) loss_oracle 0.4342 (0.4938) acc 75.0000 (71.6797) lr 3.6258e-04 eta 0:06:04
epoch [38/50] batch [260/403] time 0.069 (0.073) data 0.000 (0.002) loss 1.8230 (1.7372) teacher_loss 0.8198 (0.8199) loss_zs_kd 1.1988 (1.8206) loss_oracle 0.4949 (0.4942) acc 71.8750 (71.7428) lr 3.6258e-04 eta 0:06:03
epoch [38/50] batch [280/403] time 0.069 (0.073) data 0.000 (0.002) loss 1.8568 (1.7336) teacher_loss 0.9604 (0.8158) loss_zs_kd 1.9475 (1.8208) loss_oracle 0.5296 (0.4945) acc 65.6250 (71.8527) lr 3.6258e-04 eta 0:06:01
epoch [38/50] batch [300/403] time 0.077 (0.073) data 0.000 (0.002) loss 1.7651 (1.7329) teacher_loss 0.8806 (0.8159) loss_zs_kd 2.0001 (1.8230) loss_oracle 0.4986 (0.4947) acc 65.6250 (71.7812) lr 3.6258e-04 eta 0:06:00
epoch [38/50] batch [320/403] time 0.070 (0.073) data 0.000 (0.002) loss 1.7359 (1.7327) teacher_loss 0.8101 (0.8145) loss_zs_kd 2.3800 (1.8325) loss_oracle 0.4988 (0.4948) acc 65.6250 (71.8555) lr 3.6258e-04 eta 0:06:00
epoch [38/50] batch [340/403] time 0.067 (0.073) data 0.000 (0.002) loss 1.7051 (1.7265) teacher_loss 0.7355 (0.8096) loss_zs_kd 1.9779 (1.8354) loss_oracle 0.5296 (0.4951) acc 71.8750 (72.0037) lr 3.6258e-04 eta 0:05:58
epoch [38/50] batch [360/403] time 0.072 (0.073) data 0.000 (0.002) loss 1.5987 (1.7248) teacher_loss 0.6642 (0.8078) loss_zs_kd 1.9467 (1.8353) loss_oracle 0.5409 (0.4955) acc 71.8750 (72.0486) lr 3.6258e-04 eta 0:05:56
epoch [38/50] batch [380/403] time 0.066 (0.073) data 0.000 (0.002) loss 1.6520 (1.7237) teacher_loss 0.6825 (0.8074) loss_zs_kd 1.6657 (1.8327) loss_oracle 0.5213 (0.4953) acc 81.2500 (72.1628) lr 3.6258e-04 eta 0:05:54
epoch [38/50] batch [400/403] time 0.056 (0.074) data 0.000 (0.002) loss 2.2246 (1.7254) teacher_loss 1.2158 (0.8085) loss_zs_kd 2.1030 (1.8355) loss_oracle 0.5097 (0.4955) acc 65.6250 (72.1875) lr 3.6258e-04 eta 0:05:56
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,948
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 58.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,539
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.3%
******* Domain 4 best val acc:      71.4%, epoch: 37 *******
******* Domain 4 best val test acc: 43.9%, epoch: 37 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [39/50] batch [20/403] time 0.084 (0.109) data 0.000 (0.032) loss 1.9388 (1.6383) teacher_loss 0.9363 (0.7284) loss_zs_kd 1.6699 (1.7945) loss_oracle 0.5103 (0.4955) acc 65.6250 (74.3750) lr 3.1545e-04 eta 0:08:43
epoch [39/50] batch [40/403] time 0.065 (0.090) data 0.000 (0.016) loss 1.6954 (1.6945) teacher_loss 0.7314 (0.7840) loss_zs_kd 1.7316 (1.8411) loss_oracle 0.4825 (0.4915) acc 75.0000 (72.8906) lr 3.1545e-04 eta 0:07:13
epoch [39/50] batch [60/403] time 0.067 (0.085) data 0.000 (0.011) loss 1.6871 (1.7056) teacher_loss 0.8028 (0.7916) loss_zs_kd 1.6791 (1.8813) loss_oracle 0.4750 (0.4935) acc 68.7500 (73.0729) lr 3.1545e-04 eta 0:06:45
epoch [39/50] batch [80/403] time 0.071 (0.082) data 0.000 (0.008) loss 1.5116 (1.6972) teacher_loss 0.4770 (0.7800) loss_zs_kd 2.1073 (1.9137) loss_oracle 0.5118 (0.4947) acc 84.3750 (73.3203) lr 3.1545e-04 eta 0:06:29
epoch [39/50] batch [100/403] time 0.067 (0.080) data 0.000 (0.007) loss 1.5006 (1.7151) teacher_loss 0.6163 (0.8014) loss_zs_kd 1.9532 (1.9191) loss_oracle 0.4822 (0.4955) acc 84.3750 (72.1875) lr 3.1545e-04 eta 0:06:17
epoch [39/50] batch [120/403] time 0.084 (0.078) data 0.001 (0.006) loss 1.6657 (1.7246) teacher_loss 0.8148 (0.8129) loss_zs_kd 1.3083 (1.8870) loss_oracle 0.4763 (0.4940) acc 68.7500 (72.1354) lr 3.1545e-04 eta 0:06:09
epoch [39/50] batch [140/403] time 0.069 (0.078) data 0.000 (0.005) loss 1.7717 (1.7174) teacher_loss 0.8493 (0.8069) loss_zs_kd 2.0820 (1.8785) loss_oracle 0.4994 (0.4942) acc 75.0000 (72.2545) lr 3.1545e-04 eta 0:06:04
epoch [39/50] batch [160/403] time 0.073 (0.077) data 0.000 (0.004) loss 1.5937 (1.7219) teacher_loss 0.6882 (0.8127) loss_zs_kd 2.1262 (1.8784) loss_oracle 0.4985 (0.4941) acc 78.1250 (72.1680) lr 3.1545e-04 eta 0:05:59
epoch [39/50] batch [180/403] time 0.070 (0.078) data 0.000 (0.004) loss 1.9434 (1.7102) teacher_loss 1.1008 (0.8052) loss_zs_kd 2.0142 (1.8759) loss_oracle 0.5056 (0.4933) acc 62.5000 (72.5000) lr 3.1545e-04 eta 0:06:04
epoch [39/50] batch [200/403] time 0.064 (0.078) data 0.000 (0.003) loss 1.3805 (1.6981) teacher_loss 0.5380 (0.7965) loss_zs_kd 1.7637 (1.8724) loss_oracle 0.4766 (0.4936) acc 84.3750 (72.7188) lr 3.1545e-04 eta 0:05:59
epoch [39/50] batch [220/403] time 0.076 (0.077) data 0.000 (0.003) loss 1.9639 (1.6956) teacher_loss 1.1137 (0.7975) loss_zs_kd 2.2660 (1.8741) loss_oracle 0.5020 (0.4933) acc 62.5000 (72.6705) lr 3.1545e-04 eta 0:05:55
epoch [39/50] batch [240/403] time 0.067 (0.077) data 0.000 (0.003) loss 1.4491 (1.6912) teacher_loss 0.6147 (0.7990) loss_zs_kd 1.8541 (1.8675) loss_oracle 0.4589 (0.4929) acc 75.0000 (72.5521) lr 3.1545e-04 eta 0:05:52
epoch [39/50] batch [260/403] time 0.074 (0.076) data 0.000 (0.003) loss 1.5990 (1.6986) teacher_loss 0.6508 (0.8075) loss_zs_kd 1.8181 (1.8601) loss_oracle 0.5525 (0.4927) acc 71.8750 (72.2596) lr 3.1545e-04 eta 0:05:49
epoch [39/50] batch [280/403] time 0.085 (0.076) data 0.001 (0.003) loss 1.6040 (1.6956) teacher_loss 0.6873 (0.8045) loss_zs_kd 2.0299 (1.8595) loss_oracle 0.4810 (0.4921) acc 71.8750 (72.3438) lr 3.1545e-04 eta 0:05:46
epoch [39/50] batch [300/403] time 0.069 (0.076) data 0.000 (0.002) loss 1.8301 (1.7005) teacher_loss 1.0053 (0.8092) loss_zs_kd 1.6336 (1.8552) loss_oracle 0.4604 (0.4920) acc 65.6250 (72.1458) lr 3.1545e-04 eta 0:05:43
epoch [39/50] batch [320/403] time 0.076 (0.075) data 0.000 (0.002) loss 2.1445 (1.7045) teacher_loss 1.2451 (0.8125) loss_zs_kd 2.4961 (1.8574) loss_oracle 0.5178 (0.4924) acc 56.2500 (71.9727) lr 3.1545e-04 eta 0:05:40
epoch [39/50] batch [340/403] time 0.081 (0.075) data 0.000 (0.002) loss 1.4712 (1.7068) teacher_loss 0.6601 (0.8147) loss_zs_kd 1.3399 (1.8484) loss_oracle 0.4859 (0.4922) acc 81.2500 (71.9393) lr 3.1545e-04 eta 0:05:38
epoch [39/50] batch [360/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.5401 (1.7077) teacher_loss 0.6615 (0.8148) loss_zs_kd 1.7399 (1.8394) loss_oracle 0.4597 (0.4917) acc 71.8750 (71.8056) lr 3.1545e-04 eta 0:05:36
epoch [39/50] batch [380/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.6345 (1.7081) teacher_loss 0.7611 (0.8144) loss_zs_kd 1.8309 (1.8426) loss_oracle 0.5228 (0.4914) acc 71.8750 (71.7763) lr 3.1545e-04 eta 0:05:34
epoch [39/50] batch [400/403] time 0.066 (0.075) data 0.000 (0.002) loss 1.9882 (1.7116) teacher_loss 1.0072 (0.8172) loss_zs_kd 1.9091 (1.8424) loss_oracle 0.4853 (0.4911) acc 68.7500 (71.7266) lr 3.1545e-04 eta 0:05:31
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,993
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 60.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,584
* accuracy: 43.9%
* error: 56.1%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [40/50] batch [20/403] time 0.084 (0.112) data 0.001 (0.026) loss 1.7149 (1.6580) teacher_loss 0.7584 (0.7593) loss_zs_kd 1.7565 (1.8113) loss_oracle 0.4888 (0.4910) acc 75.0000 (75.0000) lr 2.7103e-04 eta 0:08:12
epoch [40/50] batch [40/403] time 0.080 (0.094) data 0.000 (0.013) loss 1.6897 (1.6948) teacher_loss 0.7687 (0.7890) loss_zs_kd 2.1340 (1.8239) loss_oracle 0.4721 (0.4908) acc 71.8750 (73.3594) lr 2.7103e-04 eta 0:06:52
epoch [40/50] batch [60/403] time 0.079 (0.088) data 0.001 (0.009) loss 1.7938 (1.6905) teacher_loss 0.8777 (0.7855) loss_zs_kd 1.3086 (1.8451) loss_oracle 0.4803 (0.4899) acc 62.5000 (72.9167) lr 2.7103e-04 eta 0:06:22
epoch [40/50] batch [80/403] time 0.071 (0.084) data 0.000 (0.007) loss 1.5717 (1.6964) teacher_loss 0.6759 (0.7970) loss_zs_kd 1.6000 (1.8175) loss_oracle 0.4600 (0.4889) acc 81.2500 (72.7734) lr 2.7103e-04 eta 0:06:07
epoch [40/50] batch [100/403] time 0.079 (0.082) data 0.001 (0.006) loss 1.7683 (1.7037) teacher_loss 0.8518 (0.8071) loss_zs_kd 2.2512 (1.8321) loss_oracle 0.5036 (0.4891) acc 68.7500 (72.6875) lr 2.7103e-04 eta 0:05:55
epoch [40/50] batch [120/403] time 0.065 (0.080) data 0.000 (0.005) loss 1.8574 (1.7033) teacher_loss 0.9573 (0.8051) loss_zs_kd 1.7501 (1.8325) loss_oracle 0.4983 (0.4884) acc 65.6250 (72.3698) lr 2.7103e-04 eta 0:05:46
epoch [40/50] batch [140/403] time 0.069 (0.079) data 0.000 (0.004) loss 1.8105 (1.7056) teacher_loss 0.8620 (0.8075) loss_zs_kd 1.5949 (1.8222) loss_oracle 0.5099 (0.4880) acc 68.7500 (72.4554) lr 2.7103e-04 eta 0:05:39
epoch [40/50] batch [160/403] time 0.080 (0.077) data 0.000 (0.004) loss 1.7583 (1.7052) teacher_loss 0.8476 (0.8085) loss_zs_kd 2.2443 (1.8235) loss_oracle 0.5209 (0.4880) acc 62.5000 (72.4219) lr 2.7103e-04 eta 0:05:29
epoch [40/50] batch [180/403] time 0.073 (0.077) data 0.000 (0.003) loss 2.0425 (1.7051) teacher_loss 1.1283 (0.8088) loss_zs_kd 1.6277 (1.8134) loss_oracle 0.4565 (0.4879) acc 68.7500 (72.2917) lr 2.7103e-04 eta 0:05:26
epoch [40/50] batch [200/403] time 0.072 (0.076) data 0.000 (0.003) loss 1.7232 (1.7035) teacher_loss 0.8116 (0.8087) loss_zs_kd 2.1138 (1.8117) loss_oracle 0.5233 (0.4871) acc 75.0000 (72.2500) lr 2.7103e-04 eta 0:05:23
epoch [40/50] batch [220/403] time 0.070 (0.076) data 0.000 (0.003) loss 1.4747 (1.6957) teacher_loss 0.7063 (0.8020) loss_zs_kd 1.9324 (1.8080) loss_oracle 0.5070 (0.4867) acc 81.2500 (72.5284) lr 2.7103e-04 eta 0:05:21
epoch [40/50] batch [240/403] time 0.073 (0.076) data 0.000 (0.002) loss 1.7549 (1.7024) teacher_loss 0.7478 (0.8076) loss_zs_kd 1.1837 (1.8160) loss_oracle 0.4563 (0.4862) acc 75.0000 (72.2396) lr 2.7103e-04 eta 0:05:17
epoch [40/50] batch [260/403] time 0.073 (0.076) data 0.000 (0.002) loss 1.9304 (1.7022) teacher_loss 1.0922 (0.8071) loss_zs_kd 1.6386 (1.8134) loss_oracle 0.4772 (0.4860) acc 62.5000 (72.2716) lr 2.7103e-04 eta 0:05:15
epoch [40/50] batch [280/403] time 0.063 (0.075) data 0.000 (0.002) loss 1.3344 (1.7035) teacher_loss 0.4279 (0.8069) loss_zs_kd 1.8713 (1.8106) loss_oracle 0.4437 (0.4856) acc 81.2500 (72.3214) lr 2.7103e-04 eta 0:05:12
epoch [40/50] batch [300/403] time 0.068 (0.075) data 0.000 (0.002) loss 1.5971 (1.7011) teacher_loss 0.6634 (0.8030) loss_zs_kd 1.9701 (1.8161) loss_oracle 0.4981 (0.4859) acc 90.6250 (72.4167) lr 2.7103e-04 eta 0:05:10
epoch [40/50] batch [320/403] time 0.069 (0.075) data 0.000 (0.002) loss 2.0929 (1.7001) teacher_loss 1.0432 (0.8001) loss_zs_kd 1.8192 (1.8171) loss_oracle 0.5333 (0.4863) acc 59.3750 (72.5000) lr 2.7103e-04 eta 0:05:07
epoch [40/50] batch [340/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.8098 (1.7032) teacher_loss 0.8545 (0.8011) loss_zs_kd 1.5393 (1.8258) loss_oracle 0.5246 (0.4866) acc 68.7500 (72.2794) lr 2.7103e-04 eta 0:05:04
epoch [40/50] batch [360/403] time 0.074 (0.074) data 0.000 (0.002) loss 2.0889 (1.7023) teacher_loss 1.1690 (0.7987) loss_zs_kd 2.1913 (1.8262) loss_oracle 0.5149 (0.4863) acc 65.6250 (72.4392) lr 2.7103e-04 eta 0:05:02
epoch [40/50] batch [380/403] time 0.082 (0.074) data 0.001 (0.002) loss 1.7461 (1.7072) teacher_loss 0.8098 (0.8029) loss_zs_kd 1.8534 (1.8281) loss_oracle 0.4627 (0.4865) acc 78.1250 (72.2944) lr 2.7103e-04 eta 0:05:00
epoch [40/50] batch [400/403] time 0.061 (0.074) data 0.000 (0.002) loss 1.9588 (1.7088) teacher_loss 0.9790 (0.8045) loss_zs_kd 1.8735 (1.8277) loss_oracle 0.4518 (0.4864) acc 68.7500 (72.3047) lr 2.7103e-04 eta 0:04:57
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,971
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,581
* accuracy: 43.9%
* error: 56.1%
* macro_f1: 32.9%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [41/50] batch [20/403] time 0.076 (0.103) data 0.000 (0.027) loss 1.6271 (1.7394) teacher_loss 0.7974 (0.8164) loss_zs_kd 2.2113 (1.8270) loss_oracle 0.4689 (0.4866) acc 81.2500 (73.5938) lr 2.2949e-04 eta 0:06:53
epoch [41/50] batch [40/403] time 0.066 (0.087) data 0.000 (0.014) loss 1.8796 (1.7422) teacher_loss 1.0489 (0.8267) loss_zs_kd 2.1700 (1.8509) loss_oracle 0.5111 (0.4903) acc 56.2500 (72.4219) lr 2.2949e-04 eta 0:05:48
epoch [41/50] batch [60/403] time 0.069 (0.082) data 0.001 (0.009) loss 1.7490 (1.7488) teacher_loss 0.8030 (0.8379) loss_zs_kd 2.3047 (1.8483) loss_oracle 0.5607 (0.4921) acc 78.1250 (71.9271) lr 2.2949e-04 eta 0:05:26
epoch [41/50] batch [80/403] time 0.073 (0.080) data 0.000 (0.007) loss 1.6111 (1.7333) teacher_loss 0.7067 (0.8311) loss_zs_kd 1.6429 (1.8473) loss_oracle 0.5093 (0.4908) acc 81.2500 (72.3438) lr 2.2949e-04 eta 0:05:15
epoch [41/50] batch [100/403] time 0.066 (0.078) data 0.000 (0.006) loss 1.6618 (1.7163) teacher_loss 0.8235 (0.8145) loss_zs_kd 1.6705 (1.8427) loss_oracle 0.4935 (0.4899) acc 71.8750 (72.7500) lr 2.2949e-04 eta 0:05:06
epoch [41/50] batch [120/403] time 0.073 (0.077) data 0.000 (0.005) loss 1.7941 (1.7110) teacher_loss 0.9168 (0.8080) loss_zs_kd 2.0061 (1.8522) loss_oracle 0.4648 (0.4902) acc 78.1250 (72.8646) lr 2.2949e-04 eta 0:05:01
epoch [41/50] batch [140/403] time 0.063 (0.076) data 0.000 (0.004) loss 1.4352 (1.6985) teacher_loss 0.5995 (0.7964) loss_zs_kd 2.1000 (1.8517) loss_oracle 0.4833 (0.4911) acc 81.2500 (73.4375) lr 2.2949e-04 eta 0:04:56
epoch [41/50] batch [160/403] time 0.071 (0.075) data 0.000 (0.004) loss 1.5919 (1.6948) teacher_loss 0.7411 (0.7899) loss_zs_kd 1.8466 (1.8539) loss_oracle 0.4764 (0.4910) acc 81.2500 (73.6914) lr 2.2949e-04 eta 0:04:51
epoch [41/50] batch [180/403] time 0.069 (0.075) data 0.000 (0.003) loss 1.5536 (1.6933) teacher_loss 0.6670 (0.7897) loss_zs_kd 1.6308 (1.8559) loss_oracle 0.5027 (0.4909) acc 75.0000 (73.6458) lr 2.2949e-04 eta 0:04:48
epoch [41/50] batch [200/403] time 0.071 (0.077) data 0.000 (0.003) loss 1.7349 (1.6988) teacher_loss 0.8431 (0.7960) loss_zs_kd 2.0370 (1.8632) loss_oracle 0.4617 (0.4892) acc 62.5000 (73.4219) lr 2.2949e-04 eta 0:04:53
epoch [41/50] batch [220/403] time 0.067 (0.076) data 0.000 (0.003) loss 1.6231 (1.7044) teacher_loss 0.7486 (0.8000) loss_zs_kd 1.5357 (1.8624) loss_oracle 0.4625 (0.4893) acc 81.2500 (73.2528) lr 2.2949e-04 eta 0:04:50
epoch [41/50] batch [240/403] time 0.082 (0.076) data 0.000 (0.003) loss 1.7941 (1.7026) teacher_loss 0.8547 (0.7966) loss_zs_kd 2.2350 (1.8630) loss_oracle 0.5145 (0.4886) acc 65.6250 (73.2422) lr 2.2949e-04 eta 0:04:48
epoch [41/50] batch [260/403] time 0.069 (0.076) data 0.000 (0.002) loss 1.4760 (1.7036) teacher_loss 0.5602 (0.7987) loss_zs_kd 2.0234 (1.8598) loss_oracle 0.5210 (0.4880) acc 84.3750 (73.1130) lr 2.2949e-04 eta 0:04:45
epoch [41/50] batch [280/403] time 0.081 (0.075) data 0.000 (0.002) loss 1.7823 (1.7063) teacher_loss 0.8696 (0.8015) loss_zs_kd 1.5639 (1.8614) loss_oracle 0.4757 (0.4876) acc 62.5000 (72.8237) lr 2.2949e-04 eta 0:04:42
epoch [41/50] batch [300/403] time 0.071 (0.075) data 0.000 (0.002) loss 1.6875 (1.7036) teacher_loss 0.8653 (0.7990) loss_zs_kd 1.5218 (1.8556) loss_oracle 0.4997 (0.4876) acc 71.8750 (72.9583) lr 2.2949e-04 eta 0:04:39
epoch [41/50] batch [320/403] time 0.074 (0.075) data 0.000 (0.002) loss 1.5546 (1.7035) teacher_loss 0.6506 (0.7983) loss_zs_kd 1.8217 (1.8547) loss_oracle 0.4749 (0.4877) acc 75.0000 (72.8320) lr 2.2949e-04 eta 0:04:37
epoch [41/50] batch [340/403] time 0.072 (0.075) data 0.000 (0.002) loss 1.7332 (1.7046) teacher_loss 0.8363 (0.7999) loss_zs_kd 1.3284 (1.8499) loss_oracle 0.4572 (0.4878) acc 84.3750 (72.7757) lr 2.2949e-04 eta 0:04:36
epoch [41/50] batch [360/403] time 0.076 (0.075) data 0.000 (0.002) loss 1.6740 (1.7026) teacher_loss 0.9044 (0.8002) loss_zs_kd 1.4771 (1.8485) loss_oracle 0.4353 (0.4871) acc 78.1250 (72.6823) lr 2.2949e-04 eta 0:04:34
epoch [41/50] batch [380/403] time 0.073 (0.075) data 0.000 (0.002) loss 1.4661 (1.7006) teacher_loss 0.6693 (0.7996) loss_zs_kd 1.4662 (1.8458) loss_oracle 0.4353 (0.4860) acc 75.0000 (72.6316) lr 2.2949e-04 eta 0:04:32
epoch [41/50] batch [400/403] time 0.066 (0.074) data 0.000 (0.002) loss 1.4231 (1.7008) teacher_loss 0.5932 (0.8010) loss_zs_kd 1.6568 (1.8429) loss_oracle 0.4833 (0.4856) acc 75.0000 (72.5234) lr 2.2949e-04 eta 0:04:29
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,954
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 58.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,541
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [42/50] batch [20/403] time 0.053 (0.099) data 0.000 (0.025) loss 1.4033 (1.6799) teacher_loss 0.4965 (0.7911) loss_zs_kd 1.4833 (1.8219) loss_oracle 0.4577 (0.4859) acc 78.1250 (71.2500) lr 1.9098e-04 eta 0:05:55
epoch [42/50] batch [40/403] time 0.083 (0.082) data 0.000 (0.013) loss 1.8716 (1.7012) teacher_loss 0.9289 (0.8123) loss_zs_kd 1.9458 (1.8525) loss_oracle 0.4929 (0.4843) acc 65.6250 (71.0938) lr 1.9098e-04 eta 0:04:54
epoch [42/50] batch [60/403] time 0.075 (0.078) data 0.001 (0.009) loss 1.5614 (1.7051) teacher_loss 0.6707 (0.8191) loss_zs_kd 1.6661 (1.8334) loss_oracle 0.4833 (0.4822) acc 78.1250 (70.9375) lr 1.9098e-04 eta 0:04:39
epoch [42/50] batch [80/403] time 0.062 (0.076) data 0.000 (0.007) loss 1.9184 (1.6989) teacher_loss 1.0682 (0.8143) loss_zs_kd 1.8395 (1.8219) loss_oracle 0.4601 (0.4820) acc 65.6250 (71.1719) lr 1.9098e-04 eta 0:04:29
epoch [42/50] batch [100/403] time 0.053 (0.074) data 0.000 (0.005) loss 1.7046 (1.7064) teacher_loss 0.7914 (0.8229) loss_zs_kd 1.9980 (1.8278) loss_oracle 0.4800 (0.4830) acc 68.7500 (70.9375) lr 1.9098e-04 eta 0:04:20
epoch [42/50] batch [120/403] time 0.080 (0.073) data 0.000 (0.004) loss 1.5341 (1.6849) teacher_loss 0.6659 (0.8058) loss_zs_kd 1.4750 (1.8206) loss_oracle 0.4887 (0.4833) acc 75.0000 (71.7969) lr 1.9098e-04 eta 0:04:16
epoch [42/50] batch [140/403] time 0.074 (0.073) data 0.000 (0.004) loss 1.7694 (1.6917) teacher_loss 0.9127 (0.8156) loss_zs_kd 2.5373 (1.8194) loss_oracle 0.5017 (0.4834) acc 71.8750 (71.4955) lr 1.9098e-04 eta 0:04:14
epoch [42/50] batch [160/403] time 0.066 (0.073) data 0.000 (0.003) loss 1.6092 (1.6946) teacher_loss 0.7142 (0.8176) loss_zs_kd 1.6363 (1.8154) loss_oracle 0.4544 (0.4840) acc 71.8750 (71.3086) lr 1.9098e-04 eta 0:04:11
epoch [42/50] batch [180/403] time 0.072 (0.073) data 0.000 (0.003) loss 1.8021 (1.6905) teacher_loss 0.8431 (0.8133) loss_zs_kd 1.6144 (1.8076) loss_oracle 0.4797 (0.4834) acc 71.8750 (71.5278) lr 1.9098e-04 eta 0:04:10
epoch [42/50] batch [200/403] time 0.071 (0.073) data 0.000 (0.003) loss 2.0143 (1.6971) teacher_loss 0.9874 (0.8168) loss_zs_kd 1.7092 (1.8119) loss_oracle 0.4755 (0.4834) acc 62.5000 (71.4688) lr 1.9098e-04 eta 0:04:08
epoch [42/50] batch [220/403] time 0.068 (0.072) data 0.000 (0.003) loss 1.8599 (1.6936) teacher_loss 0.9577 (0.8116) loss_zs_kd 1.8371 (1.8139) loss_oracle 0.4756 (0.4841) acc 56.2500 (71.6193) lr 1.9098e-04 eta 0:04:06
epoch [42/50] batch [240/403] time 0.075 (0.072) data 0.000 (0.002) loss 1.4700 (1.6944) teacher_loss 0.5531 (0.8113) loss_zs_kd 1.4541 (1.8127) loss_oracle 0.4798 (0.4837) acc 84.3750 (71.6146) lr 1.9098e-04 eta 0:04:03
epoch [42/50] batch [260/403] time 0.063 (0.071) data 0.000 (0.002) loss 1.6517 (1.6979) teacher_loss 0.7848 (0.8131) loss_zs_kd 1.6544 (1.8197) loss_oracle 0.4954 (0.4839) acc 75.0000 (71.5385) lr 1.9098e-04 eta 0:04:00
epoch [42/50] batch [280/403] time 0.069 (0.071) data 0.000 (0.002) loss 1.6529 (1.6950) teacher_loss 0.7637 (0.8104) loss_zs_kd 1.7693 (1.8247) loss_oracle 0.4713 (0.4838) acc 75.0000 (71.6295) lr 1.9098e-04 eta 0:03:58
epoch [42/50] batch [300/403] time 0.055 (0.071) data 0.000 (0.002) loss 1.8975 (1.6969) teacher_loss 1.0002 (0.8119) loss_zs_kd 1.7958 (1.8193) loss_oracle 0.4974 (0.4833) acc 71.8750 (71.5000) lr 1.9098e-04 eta 0:03:56
epoch [42/50] batch [320/403] time 0.073 (0.071) data 0.000 (0.002) loss 1.4394 (1.6950) teacher_loss 0.5291 (0.8092) loss_zs_kd 1.6624 (1.8241) loss_oracle 0.4737 (0.4828) acc 84.3750 (71.6602) lr 1.9098e-04 eta 0:03:55
epoch [42/50] batch [340/403] time 0.076 (0.071) data 0.000 (0.002) loss 1.6178 (1.6969) teacher_loss 0.7802 (0.8098) loss_zs_kd 1.9413 (1.8254) loss_oracle 0.5168 (0.4831) acc 71.8750 (71.6820) lr 1.9098e-04 eta 0:03:53
epoch [42/50] batch [360/403] time 0.076 (0.071) data 0.001 (0.002) loss 1.7258 (1.6988) teacher_loss 0.8719 (0.8112) loss_zs_kd 2.4701 (1.8265) loss_oracle 0.5115 (0.4827) acc 78.1250 (71.6580) lr 1.9098e-04 eta 0:03:52
epoch [42/50] batch [380/403] time 0.075 (0.071) data 0.000 (0.002) loss 1.6972 (1.6999) teacher_loss 0.8242 (0.8122) loss_zs_kd 2.1238 (1.8241) loss_oracle 0.4997 (0.4826) acc 68.7500 (71.6036) lr 1.9098e-04 eta 0:03:51
epoch [42/50] batch [400/403] time 0.061 (0.071) data 0.000 (0.002) loss 1.5291 (1.6982) teacher_loss 0.6513 (0.8108) loss_zs_kd 2.1068 (1.8239) loss_oracle 0.4930 (0.4825) acc 78.1250 (71.6484) lr 1.9098e-04 eta 0:03:49
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,978
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,618
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 33.3%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [43/50] batch [20/403] time 0.065 (0.092) data 0.000 (0.026) loss 1.6722 (1.6901) teacher_loss 0.7566 (0.7620) loss_zs_kd 1.4423 (1.8288) loss_oracle 0.4690 (0.4823) acc 81.2500 (72.0312) lr 1.5567e-04 eta 0:04:54
epoch [43/50] batch [40/403] time 0.070 (0.081) data 0.000 (0.013) loss 1.6140 (1.7038) teacher_loss 0.8145 (0.7820) loss_zs_kd 1.8379 (1.8537) loss_oracle 0.4566 (0.4819) acc 78.1250 (72.0312) lr 1.5567e-04 eta 0:04:19
epoch [43/50] batch [60/403] time 0.075 (0.078) data 0.001 (0.009) loss 1.7281 (1.6853) teacher_loss 0.9067 (0.7704) loss_zs_kd 1.7298 (1.8432) loss_oracle 0.4496 (0.4812) acc 68.7500 (72.6562) lr 1.5567e-04 eta 0:04:07
epoch [43/50] batch [80/403] time 0.071 (0.074) data 0.000 (0.007) loss 1.5216 (1.6799) teacher_loss 0.6316 (0.7659) loss_zs_kd 1.8701 (1.8276) loss_oracle 0.5128 (0.4809) acc 81.2500 (72.8906) lr 1.5567e-04 eta 0:03:53
epoch [43/50] batch [100/403] time 0.071 (0.074) data 0.000 (0.005) loss 1.5934 (1.6870) teacher_loss 0.7313 (0.7763) loss_zs_kd 2.2710 (1.8541) loss_oracle 0.4699 (0.4813) acc 71.8750 (72.7812) lr 1.5567e-04 eta 0:03:50
epoch [43/50] batch [120/403] time 0.076 (0.074) data 0.000 (0.005) loss 1.6902 (1.6819) teacher_loss 0.6651 (0.7739) loss_zs_kd 1.4975 (1.8495) loss_oracle 0.4646 (0.4815) acc 75.0000 (72.7344) lr 1.5567e-04 eta 0:03:49
epoch [43/50] batch [140/403] time 0.068 (0.074) data 0.000 (0.004) loss 1.5605 (1.6806) teacher_loss 0.7385 (0.7753) loss_zs_kd 1.4014 (1.8403) loss_oracle 0.4795 (0.4818) acc 68.7500 (72.6339) lr 1.5567e-04 eta 0:03:47
epoch [43/50] batch [160/403] time 0.072 (0.073) data 0.000 (0.003) loss 1.9648 (1.6799) teacher_loss 1.0801 (0.7786) loss_zs_kd 2.2200 (1.8398) loss_oracle 0.4982 (0.4817) acc 68.7500 (72.6367) lr 1.5567e-04 eta 0:03:44
epoch [43/50] batch [180/403] time 0.064 (0.073) data 0.000 (0.003) loss 1.9762 (1.6796) teacher_loss 1.1565 (0.7833) loss_zs_kd 1.5108 (1.8266) loss_oracle 0.4373 (0.4805) acc 71.8750 (72.3611) lr 1.5567e-04 eta 0:03:42
epoch [43/50] batch [200/403] time 0.068 (0.073) data 0.000 (0.003) loss 1.7747 (1.6833) teacher_loss 0.8624 (0.7888) loss_zs_kd 1.9667 (1.8319) loss_oracle 0.5017 (0.4801) acc 71.8750 (72.3281) lr 1.5567e-04 eta 0:03:39
epoch [43/50] batch [220/403] time 0.120 (0.074) data 0.000 (0.003) loss 1.8238 (1.6828) teacher_loss 0.8738 (0.7888) loss_zs_kd 2.2111 (1.8312) loss_oracle 0.5230 (0.4807) acc 65.6250 (72.4716) lr 1.5567e-04 eta 0:03:40
epoch [43/50] batch [240/403] time 0.074 (0.074) data 0.000 (0.002) loss 1.7289 (1.6845) teacher_loss 0.8488 (0.7926) loss_zs_kd 1.8875 (1.8306) loss_oracle 0.5272 (0.4811) acc 65.6250 (72.2656) lr 1.5567e-04 eta 0:03:41
epoch [43/50] batch [260/403] time 0.076 (0.074) data 0.000 (0.002) loss 2.0356 (1.6854) teacher_loss 1.1207 (0.7943) loss_zs_kd 1.9093 (1.8294) loss_oracle 0.5170 (0.4810) acc 56.2500 (72.1875) lr 1.5567e-04 eta 0:03:39
epoch [43/50] batch [280/403] time 0.071 (0.074) data 0.000 (0.002) loss 1.4955 (1.6829) teacher_loss 0.7683 (0.7919) loss_zs_kd 1.4638 (1.8351) loss_oracle 0.4357 (0.4811) acc 81.2500 (72.2768) lr 1.5567e-04 eta 0:03:37
epoch [43/50] batch [300/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.8605 (1.6836) teacher_loss 0.9650 (0.7938) loss_zs_kd 1.8984 (1.8335) loss_oracle 0.4875 (0.4810) acc 59.3750 (72.2604) lr 1.5567e-04 eta 0:03:35
epoch [43/50] batch [320/403] time 0.079 (0.074) data 0.001 (0.002) loss 1.7230 (1.6881) teacher_loss 0.8961 (0.7994) loss_zs_kd 1.3842 (1.8308) loss_oracle 0.4712 (0.4810) acc 68.7500 (72.2559) lr 1.5567e-04 eta 0:03:34
epoch [43/50] batch [340/403] time 0.070 (0.074) data 0.000 (0.002) loss 1.5045 (1.6886) teacher_loss 0.6716 (0.8005) loss_zs_kd 1.6914 (1.8254) loss_oracle 0.4591 (0.4806) acc 75.0000 (72.1783) lr 1.5567e-04 eta 0:03:32
epoch [43/50] batch [360/403] time 0.076 (0.074) data 0.001 (0.002) loss 1.9568 (1.6906) teacher_loss 1.0721 (0.8019) loss_zs_kd 1.2946 (1.8207) loss_oracle 0.4837 (0.4801) acc 65.6250 (72.1094) lr 1.5567e-04 eta 0:03:30
epoch [43/50] batch [380/403] time 0.071 (0.073) data 0.000 (0.002) loss 1.8258 (1.6934) teacher_loss 0.9235 (0.8041) loss_zs_kd 1.6814 (1.8180) loss_oracle 0.4625 (0.4801) acc 65.6250 (71.9819) lr 1.5567e-04 eta 0:03:28
epoch [43/50] batch [400/403] time 0.061 (0.073) data 0.000 (0.002) loss 1.5136 (1.6949) teacher_loss 0.5743 (0.8060) loss_zs_kd 1.7267 (1.8148) loss_oracle 0.4839 (0.4796) acc 78.1250 (71.9219) lr 1.5567e-04 eta 0:03:25
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,962
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,561
* accuracy: 43.5%
* error: 56.5%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [44/50] batch [20/403] time 0.065 (0.119) data 0.000 (0.028) loss 1.7644 (1.7285) teacher_loss 0.9637 (0.8555) loss_zs_kd 2.0039 (1.7644) loss_oracle 0.4565 (0.4804) acc 59.3750 (69.2188) lr 1.2369e-04 eta 0:05:33
epoch [44/50] batch [40/403] time 0.052 (0.093) data 0.000 (0.014) loss 1.8194 (1.7063) teacher_loss 0.8782 (0.8247) loss_zs_kd 1.9933 (1.7845) loss_oracle 0.4769 (0.4808) acc 62.5000 (71.7188) lr 1.2369e-04 eta 0:04:19
epoch [44/50] batch [60/403] time 0.063 (0.082) data 0.001 (0.009) loss 1.5666 (1.7027) teacher_loss 0.6457 (0.8149) loss_zs_kd 1.6087 (1.8174) loss_oracle 0.4862 (0.4825) acc 78.1250 (72.0312) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [80/403] time 0.078 (0.079) data 0.000 (0.007) loss 1.5498 (1.7078) teacher_loss 0.7916 (0.8206) loss_zs_kd 1.7456 (1.8007) loss_oracle 0.4596 (0.4792) acc 75.0000 (71.9922) lr 1.2369e-04 eta 0:03:36
epoch [44/50] batch [100/403] time 0.071 (0.078) data 0.000 (0.006) loss 1.6587 (1.6950) teacher_loss 0.7095 (0.8086) loss_zs_kd 2.5057 (1.8263) loss_oracle 0.5055 (0.4782) acc 71.8750 (72.1250) lr 1.2369e-04 eta 0:03:31
epoch [44/50] batch [120/403] time 0.071 (0.077) data 0.000 (0.005) loss 2.0602 (1.7023) teacher_loss 1.2308 (0.8158) loss_zs_kd 1.8723 (1.8070) loss_oracle 0.4399 (0.4780) acc 59.3750 (72.0052) lr 1.2369e-04 eta 0:03:28
epoch [44/50] batch [140/403] time 0.078 (0.076) data 0.000 (0.004) loss 1.7372 (1.7052) teacher_loss 0.8253 (0.8181) loss_zs_kd 1.7265 (1.8024) loss_oracle 0.5025 (0.4775) acc 68.7500 (71.9643) lr 1.2369e-04 eta 0:03:24
epoch [44/50] batch [160/403] time 0.077 (0.076) data 0.000 (0.004) loss 1.4039 (1.6930) teacher_loss 0.4961 (0.8047) loss_zs_kd 1.6350 (1.8094) loss_oracle 0.4385 (0.4790) acc 90.6250 (72.5391) lr 1.2369e-04 eta 0:03:21
epoch [44/50] batch [180/403] time 0.065 (0.075) data 0.000 (0.003) loss 1.6513 (1.6923) teacher_loss 0.7716 (0.8052) loss_zs_kd 2.2104 (1.8088) loss_oracle 0.4667 (0.4796) acc 68.7500 (72.5174) lr 1.2369e-04 eta 0:03:18
epoch [44/50] batch [200/403] time 0.072 (0.075) data 0.000 (0.003) loss 1.7744 (1.6921) teacher_loss 0.8951 (0.8034) loss_zs_kd 1.4971 (1.7993) loss_oracle 0.4414 (0.4789) acc 71.8750 (72.4219) lr 1.2369e-04 eta 0:03:15
epoch [44/50] batch [220/403] time 0.073 (0.075) data 0.000 (0.003) loss 1.7050 (1.6909) teacher_loss 0.7874 (0.8009) loss_zs_kd 2.1951 (1.8060) loss_oracle 0.5147 (0.4787) acc 62.5000 (72.3295) lr 1.2369e-04 eta 0:03:14
epoch [44/50] batch [240/403] time 0.077 (0.075) data 0.000 (0.003) loss 1.4576 (1.6906) teacher_loss 0.5887 (0.7998) loss_zs_kd 2.1127 (1.8119) loss_oracle 0.4540 (0.4785) acc 78.1250 (72.4089) lr 1.2369e-04 eta 0:03:12
epoch [44/50] batch [260/403] time 0.072 (0.074) data 0.000 (0.002) loss 2.2447 (1.6958) teacher_loss 1.2855 (0.8043) loss_zs_kd 1.8352 (1.8160) loss_oracle 0.4644 (0.4793) acc 56.2500 (72.3438) lr 1.2369e-04 eta 0:03:09
epoch [44/50] batch [280/403] time 0.079 (0.074) data 0.000 (0.002) loss 1.7088 (1.6959) teacher_loss 0.7316 (0.8029) loss_zs_kd 1.6940 (1.8160) loss_oracle 0.5045 (0.4803) acc 71.8750 (72.3884) lr 1.2369e-04 eta 0:03:08
epoch [44/50] batch [300/403] time 0.075 (0.074) data 0.001 (0.002) loss 1.5574 (1.6966) teacher_loss 0.7014 (0.8029) loss_zs_kd 1.7774 (1.8111) loss_oracle 0.4480 (0.4800) acc 78.1250 (72.3438) lr 1.2369e-04 eta 0:03:06
epoch [44/50] batch [320/403] time 0.077 (0.074) data 0.000 (0.002) loss 1.8110 (1.6938) teacher_loss 0.9352 (0.8002) loss_zs_kd 1.8754 (1.8123) loss_oracle 0.4419 (0.4806) acc 68.7500 (72.2363) lr 1.2369e-04 eta 0:03:04
epoch [44/50] batch [340/403] time 0.070 (0.074) data 0.000 (0.002) loss 1.7796 (1.6936) teacher_loss 0.9155 (0.8009) loss_zs_kd 2.0928 (1.8124) loss_oracle 0.4589 (0.4800) acc 71.8750 (72.2059) lr 1.2369e-04 eta 0:03:02
epoch [44/50] batch [360/403] time 0.069 (0.073) data 0.000 (0.002) loss 1.7709 (1.6989) teacher_loss 0.8778 (0.8054) loss_zs_kd 1.7669 (1.8139) loss_oracle 0.4964 (0.4797) acc 68.7500 (72.1267) lr 1.2369e-04 eta 0:03:00
epoch [44/50] batch [380/403] time 0.072 (0.073) data 0.000 (0.002) loss 1.6696 (1.6968) teacher_loss 0.7940 (0.8040) loss_zs_kd 1.5726 (1.8123) loss_oracle 0.4607 (0.4798) acc 75.0000 (72.1793) lr 1.2369e-04 eta 0:02:58
epoch [44/50] batch [400/403] time 0.064 (0.073) data 0.000 (0.002) loss 1.8922 (1.6976) teacher_loss 0.9239 (0.8038) loss_zs_kd 2.1202 (1.8169) loss_oracle 0.4809 (0.4801) acc 65.6250 (72.2188) lr 1.2369e-04 eta 0:02:56
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,978
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,556
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.7%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [45/50] batch [20/403] time 0.076 (0.104) data 0.000 (0.030) loss 1.6061 (1.6698) teacher_loss 0.7004 (0.7767) loss_zs_kd 2.0358 (1.9349) loss_oracle 0.5261 (0.4810) acc 71.8750 (72.0312) lr 9.5173e-05 eta 0:04:09
epoch [45/50] batch [40/403] time 0.068 (0.088) data 0.000 (0.015) loss 1.4563 (1.6937) teacher_loss 0.6097 (0.7958) loss_zs_kd 1.6560 (1.9154) loss_oracle 0.4735 (0.4823) acc 75.0000 (72.5000) lr 9.5173e-05 eta 0:03:28
epoch [45/50] batch [60/403] time 0.065 (0.082) data 0.001 (0.010) loss 1.9725 (1.6932) teacher_loss 1.0923 (0.7992) loss_zs_kd 1.3104 (1.9078) loss_oracle 0.4744 (0.4835) acc 71.8750 (71.9271) lr 9.5173e-05 eta 0:03:14
epoch [45/50] batch [80/403] time 0.077 (0.078) data 0.000 (0.008) loss 1.6860 (1.7174) teacher_loss 0.7052 (0.8153) loss_zs_kd 2.0393 (1.8921) loss_oracle 0.5169 (0.4837) acc 78.1250 (71.5625) lr 9.5173e-05 eta 0:03:02
epoch [45/50] batch [100/403] time 0.070 (0.075) data 0.000 (0.006) loss 1.7932 (1.7083) teacher_loss 0.8600 (0.8067) loss_zs_kd 1.8306 (1.8932) loss_oracle 0.5431 (0.4829) acc 68.7500 (71.9375) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [120/403] time 0.069 (0.074) data 0.000 (0.005) loss 1.6537 (1.7161) teacher_loss 0.7273 (0.8159) loss_zs_kd 1.7801 (1.8749) loss_oracle 0.4727 (0.4814) acc 81.2500 (71.7188) lr 9.5173e-05 eta 0:02:50
epoch [45/50] batch [140/403] time 0.068 (0.074) data 0.000 (0.004) loss 2.0492 (1.7071) teacher_loss 1.1489 (0.8107) loss_zs_kd 2.0642 (1.8690) loss_oracle 0.4994 (0.4811) acc 71.8750 (72.0759) lr 9.5173e-05 eta 0:02:47
epoch [45/50] batch [160/403] time 0.070 (0.074) data 0.000 (0.004) loss 1.6103 (1.7095) teacher_loss 0.7408 (0.8143) loss_zs_kd 1.9750 (1.8687) loss_oracle 0.4666 (0.4812) acc 75.0000 (71.8945) lr 9.5173e-05 eta 0:02:46
epoch [45/50] batch [180/403] time 0.078 (0.074) data 0.000 (0.004) loss 1.8767 (1.7045) teacher_loss 1.0154 (0.8109) loss_zs_kd 1.7713 (1.8591) loss_oracle 0.4921 (0.4803) acc 65.6250 (72.0139) lr 9.5173e-05 eta 0:02:44
epoch [45/50] batch [200/403] time 0.073 (0.074) data 0.000 (0.003) loss 1.6747 (1.7163) teacher_loss 0.7741 (0.8211) loss_zs_kd 2.3115 (1.8546) loss_oracle 0.4937 (0.4801) acc 75.0000 (71.9062) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [220/403] time 0.079 (0.074) data 0.000 (0.003) loss 1.5434 (1.7105) teacher_loss 0.6051 (0.8162) loss_zs_kd 2.2950 (1.8485) loss_oracle 0.4942 (0.4798) acc 84.3750 (72.0739) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [240/403] time 0.063 (0.075) data 0.000 (0.003) loss 1.6519 (1.7101) teacher_loss 0.8058 (0.8155) loss_zs_kd 1.7432 (1.8571) loss_oracle 0.4597 (0.4802) acc 71.8750 (71.9792) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [260/403] time 0.064 (0.075) data 0.000 (0.003) loss 1.6887 (1.7066) teacher_loss 0.7962 (0.8119) loss_zs_kd 1.5391 (1.8506) loss_oracle 0.4580 (0.4799) acc 71.8750 (72.1514) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [280/403] time 0.067 (0.074) data 0.000 (0.002) loss 1.5947 (1.6994) teacher_loss 0.8125 (0.8062) loss_zs_kd 1.7446 (1.8506) loss_oracle 0.4326 (0.4792) acc 68.7500 (72.3214) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [300/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.6722 (1.7021) teacher_loss 0.8412 (0.8093) loss_zs_kd 1.8409 (1.8516) loss_oracle 0.4409 (0.4792) acc 78.1250 (72.1771) lr 9.5173e-05 eta 0:02:36
epoch [45/50] batch [320/403] time 0.073 (0.074) data 0.000 (0.002) loss 1.6864 (1.7058) teacher_loss 0.7896 (0.8130) loss_zs_kd 1.9631 (1.8510) loss_oracle 0.4843 (0.4790) acc 78.1250 (71.9434) lr 9.5173e-05 eta 0:02:35
epoch [45/50] batch [340/403] time 0.069 (0.074) data 0.000 (0.002) loss 1.6753 (1.7027) teacher_loss 0.8457 (0.8097) loss_zs_kd 1.7439 (1.8478) loss_oracle 0.4516 (0.4782) acc 71.8750 (72.0588) lr 9.5173e-05 eta 0:02:33
epoch [45/50] batch [360/403] time 0.070 (0.074) data 0.000 (0.002) loss 2.2210 (1.7043) teacher_loss 1.2784 (0.8116) loss_zs_kd 2.3198 (1.8479) loss_oracle 0.5029 (0.4778) acc 56.2500 (71.9705) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [380/403] time 0.075 (0.073) data 0.000 (0.002) loss 1.5165 (1.7046) teacher_loss 0.6769 (0.8119) loss_zs_kd 1.0947 (1.8364) loss_oracle 0.4748 (0.4777) acc 75.0000 (72.0230) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [400/403] time 0.070 (0.073) data 0.000 (0.002) loss 1.5640 (1.7020) teacher_loss 0.6382 (0.8095) loss_zs_kd 1.1663 (1.8355) loss_oracle 0.4459 (0.4783) acc 78.1250 (72.1016) lr 9.5173e-05 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,977
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,562
* accuracy: 43.5%
* error: 56.5%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [46/50] batch [20/403] time 0.065 (0.104) data 0.000 (0.027) loss 1.4323 (1.6184) teacher_loss 0.5260 (0.7372) loss_zs_kd 1.4265 (1.8477) loss_oracle 0.4487 (0.4799) acc 87.5000 (74.0625) lr 7.0224e-05 eta 0:03:27
epoch [46/50] batch [40/403] time 0.072 (0.097) data 0.000 (0.014) loss 1.4443 (1.6214) teacher_loss 0.6037 (0.7500) loss_zs_kd 1.6745 (1.8367) loss_oracle 0.4367 (0.4801) acc 78.1250 (73.7500) lr 7.0224e-05 eta 0:03:11
epoch [46/50] batch [60/403] time 0.071 (0.090) data 0.000 (0.009) loss 1.5253 (1.6421) teacher_loss 0.7106 (0.7632) loss_zs_kd 2.3080 (1.8459) loss_oracle 0.4320 (0.4778) acc 75.0000 (73.3854) lr 7.0224e-05 eta 0:02:54
epoch [46/50] batch [80/403] time 0.063 (0.085) data 0.000 (0.007) loss 1.5798 (1.6494) teacher_loss 0.6527 (0.7726) loss_zs_kd 1.6273 (1.8267) loss_oracle 0.4708 (0.4784) acc 75.0000 (72.6953) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [100/403] time 0.065 (0.080) data 0.000 (0.006) loss 1.7638 (1.6553) teacher_loss 0.8851 (0.7741) loss_zs_kd 1.7306 (1.8439) loss_oracle 0.4440 (0.4801) acc 65.6250 (72.8125) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [120/403] time 0.069 (0.079) data 0.000 (0.005) loss 1.6197 (1.6604) teacher_loss 0.8110 (0.7786) loss_zs_kd 1.9296 (1.8582) loss_oracle 0.4633 (0.4804) acc 78.1250 (72.9167) lr 7.0224e-05 eta 0:02:29
epoch [46/50] batch [140/403] time 0.068 (0.077) data 0.000 (0.004) loss 1.8490 (1.6690) teacher_loss 0.9118 (0.7870) loss_zs_kd 2.0580 (1.8489) loss_oracle 0.4547 (0.4789) acc 71.8750 (72.4777) lr 7.0224e-05 eta 0:02:24
epoch [46/50] batch [160/403] time 0.042 (0.076) data 0.000 (0.004) loss 1.7594 (1.6715) teacher_loss 0.8124 (0.7911) loss_zs_kd 1.6607 (1.8418) loss_oracle 0.4975 (0.4796) acc 65.6250 (72.1094) lr 7.0224e-05 eta 0:02:20
epoch [46/50] batch [180/403] time 0.056 (0.073) data 0.000 (0.003) loss 1.9802 (1.6792) teacher_loss 1.1296 (0.7985) loss_zs_kd 1.7136 (1.8445) loss_oracle 0.4630 (0.4799) acc 56.2500 (71.9792) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [200/403] time 0.090 (0.075) data 0.000 (0.003) loss 1.4215 (1.6818) teacher_loss 0.5438 (0.8004) loss_zs_kd 1.9415 (1.8372) loss_oracle 0.5018 (0.4794) acc 84.3750 (72.1094) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [220/403] time 0.088 (0.076) data 0.000 (0.003) loss 1.4845 (1.6853) teacher_loss 0.5746 (0.8039) loss_zs_kd 1.7637 (1.8311) loss_oracle 0.4739 (0.4783) acc 84.3750 (71.9602) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [240/403] time 0.090 (0.077) data 0.000 (0.003) loss 1.6819 (1.6890) teacher_loss 0.6991 (0.8072) loss_zs_kd 1.6606 (1.8309) loss_oracle 0.4667 (0.4778) acc 71.8750 (71.6927) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [260/403] time 0.093 (0.078) data 0.000 (0.002) loss 1.7593 (1.6907) teacher_loss 0.8614 (0.8093) loss_zs_kd 1.5401 (1.8273) loss_oracle 0.4687 (0.4779) acc 65.6250 (71.6226) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [280/403] time 0.096 (0.078) data 0.000 (0.002) loss 1.6029 (1.6922) teacher_loss 0.8060 (0.8100) loss_zs_kd 1.6528 (1.8283) loss_oracle 0.4746 (0.4780) acc 68.7500 (71.5848) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [300/403] time 0.088 (0.079) data 0.000 (0.002) loss 1.8454 (1.6898) teacher_loss 0.9612 (0.8086) loss_zs_kd 2.1026 (1.8303) loss_oracle 0.5156 (0.4773) acc 68.7500 (71.6875) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [320/403] time 0.086 (0.080) data 0.000 (0.002) loss 1.8508 (1.6905) teacher_loss 0.9756 (0.8082) loss_zs_kd 1.4863 (1.8285) loss_oracle 0.4810 (0.4770) acc 62.5000 (71.6992) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [340/403] time 0.075 (0.080) data 0.000 (0.002) loss 1.8262 (1.6939) teacher_loss 0.9074 (0.8115) loss_zs_kd 1.3133 (1.8221) loss_oracle 0.4521 (0.4768) acc 65.6250 (71.6452) lr 7.0224e-05 eta 0:02:13
epoch [46/50] batch [360/403] time 0.089 (0.080) data 0.000 (0.002) loss 2.0896 (1.6929) teacher_loss 1.2246 (0.8115) loss_zs_kd 1.6297 (1.8237) loss_oracle 0.4720 (0.4766) acc 53.1250 (71.5712) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [380/403] time 0.085 (0.080) data 0.000 (0.002) loss 1.7760 (1.6903) teacher_loss 0.9038 (0.8094) loss_zs_kd 1.8379 (1.8275) loss_oracle 0.4908 (0.4767) acc 68.7500 (71.6530) lr 7.0224e-05 eta 0:02:11
epoch [46/50] batch [400/403] time 0.063 (0.080) data 0.000 (0.002) loss 1.3833 (1.6927) teacher_loss 0.5232 (0.8118) loss_zs_kd 1.9211 (1.8288) loss_oracle 0.4209 (0.4765) acc 78.1250 (71.5156) lr 7.0224e-05 eta 0:02:09
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,982
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,544
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.0%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [47/50] batch [20/403] time 0.065 (0.112) data 0.000 (0.033) loss 1.4087 (1.6805) teacher_loss 0.5306 (0.8066) loss_zs_kd 2.0357 (1.8335) loss_oracle 0.4703 (0.4732) acc 81.2500 (74.0625) lr 4.8943e-05 eta 0:02:58
epoch [47/50] batch [40/403] time 0.072 (0.094) data 0.000 (0.017) loss 1.8806 (1.6781) teacher_loss 1.1021 (0.7999) loss_zs_kd 1.7479 (1.8065) loss_oracle 0.4477 (0.4745) acc 62.5000 (72.5781) lr 4.8943e-05 eta 0:02:27
epoch [47/50] batch [60/403] time 0.087 (0.086) data 0.001 (0.011) loss 1.9856 (1.6805) teacher_loss 1.0986 (0.7994) loss_zs_kd 1.5816 (1.8194) loss_oracle 0.4544 (0.4756) acc 62.5000 (72.2917) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [80/403] time 0.061 (0.088) data 0.000 (0.008) loss 1.7120 (1.6633) teacher_loss 0.8724 (0.7799) loss_zs_kd 1.9314 (1.8190) loss_oracle 0.4735 (0.4751) acc 65.6250 (73.2422) lr 4.8943e-05 eta 0:02:14
epoch [47/50] batch [100/403] time 0.066 (0.090) data 0.001 (0.007) loss 1.4626 (1.6711) teacher_loss 0.4784 (0.7864) loss_zs_kd 1.5468 (1.8177) loss_oracle 0.4592 (0.4781) acc 90.6250 (73.1562) lr 4.8943e-05 eta 0:02:16
epoch [47/50] batch [120/403] time 0.070 (0.090) data 0.000 (0.006) loss 1.4388 (1.6761) teacher_loss 0.6202 (0.7923) loss_zs_kd 1.3816 (1.8121) loss_oracle 0.4405 (0.4779) acc 84.3750 (73.0208) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [140/403] time 0.154 (0.091) data 0.000 (0.005) loss 1.8637 (1.6759) teacher_loss 0.9358 (0.7908) loss_zs_kd 2.2732 (1.8283) loss_oracle 0.5012 (0.4768) acc 68.7500 (72.7009) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [160/403] time 0.060 (0.089) data 0.000 (0.004) loss 1.5031 (1.6826) teacher_loss 0.6585 (0.7979) loss_zs_kd 1.7212 (1.8232) loss_oracle 0.4679 (0.4771) acc 81.2500 (72.4609) lr 4.8943e-05 eta 0:02:08
epoch [47/50] batch [180/403] time 0.092 (0.089) data 0.001 (0.004) loss 1.7996 (1.6917) teacher_loss 0.8750 (0.8096) loss_zs_kd 1.7917 (1.8201) loss_oracle 0.4589 (0.4771) acc 65.6250 (71.8576) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [200/403] time 0.146 (0.089) data 0.000 (0.004) loss 1.6171 (1.6910) teacher_loss 0.7035 (0.8089) loss_zs_kd 1.9806 (1.8165) loss_oracle 0.4763 (0.4771) acc 75.0000 (71.7969) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [220/403] time 0.091 (0.089) data 0.000 (0.003) loss 1.5470 (1.6886) teacher_loss 0.7391 (0.8064) loss_zs_kd 1.5123 (1.8114) loss_oracle 0.4754 (0.4769) acc 75.0000 (72.0455) lr 4.8943e-05 eta 0:02:03
epoch [47/50] batch [240/403] time 0.063 (0.088) data 0.000 (0.003) loss 1.5944 (1.6919) teacher_loss 0.6817 (0.8088) loss_zs_kd 1.9527 (1.8153) loss_oracle 0.4890 (0.4775) acc 78.1250 (71.9792) lr 4.8943e-05 eta 0:02:01
epoch [47/50] batch [260/403] time 0.095 (0.089) data 0.000 (0.003) loss 1.8152 (1.6924) teacher_loss 0.8173 (0.8111) loss_zs_kd 1.7091 (1.8161) loss_oracle 0.4993 (0.4779) acc 75.0000 (71.7548) lr 4.8943e-05 eta 0:02:00
epoch [47/50] batch [280/403] time 0.097 (0.088) data 0.000 (0.003) loss 1.4935 (1.6892) teacher_loss 0.5623 (0.8079) loss_zs_kd 2.2169 (1.8090) loss_oracle 0.5112 (0.4774) acc 87.5000 (71.9643) lr 4.8943e-05 eta 0:01:56
epoch [47/50] batch [300/403] time 0.075 (0.088) data 0.000 (0.003) loss 1.5104 (1.6898) teacher_loss 0.6774 (0.8087) loss_zs_kd 1.8389 (1.8125) loss_oracle 0.4727 (0.4777) acc 75.0000 (71.8958) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [320/403] time 0.086 (0.088) data 0.000 (0.002) loss 1.5453 (1.6891) teacher_loss 0.6891 (0.8077) loss_zs_kd 1.9937 (1.8160) loss_oracle 0.4644 (0.4770) acc 75.0000 (71.9629) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [340/403] time 0.089 (0.088) data 0.000 (0.002) loss 1.7415 (1.6882) teacher_loss 0.8365 (0.8062) loss_zs_kd 1.6111 (1.8168) loss_oracle 0.4748 (0.4774) acc 68.7500 (71.9393) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [360/403] time 0.091 (0.087) data 0.000 (0.002) loss 1.4133 (1.6866) teacher_loss 0.5863 (0.8051) loss_zs_kd 2.0846 (1.8175) loss_oracle 0.4546 (0.4774) acc 81.2500 (72.0139) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [380/403] time 0.090 (0.087) data 0.000 (0.002) loss 1.9509 (1.6881) teacher_loss 1.0579 (0.8072) loss_zs_kd 1.4456 (1.8191) loss_oracle 0.5115 (0.4771) acc 43.7500 (71.8257) lr 4.8943e-05 eta 0:01:47
epoch [47/50] batch [400/403] time 0.088 (0.087) data 0.000 (0.002) loss 1.6777 (1.6888) teacher_loss 0.7977 (0.8076) loss_zs_kd 1.8059 (1.8222) loss_oracle 0.4656 (0.4772) acc 65.6250 (71.7734) lr 4.8943e-05 eta 0:01:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,979
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,549
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [48/50] batch [20/403] time 0.088 (0.118) data 0.000 (0.025) loss 1.7908 (1.6868) teacher_loss 0.8991 (0.8107) loss_zs_kd 1.6802 (1.8891) loss_oracle 0.4653 (0.4787) acc 59.3750 (70.9375) lr 3.1417e-05 eta 0:02:19
epoch [48/50] batch [40/403] time 0.087 (0.102) data 0.000 (0.013) loss 1.8130 (1.6972) teacher_loss 0.9922 (0.8233) loss_zs_kd 1.6940 (1.8868) loss_oracle 0.4806 (0.4781) acc 65.6250 (71.3281) lr 3.1417e-05 eta 0:01:59
epoch [48/50] batch [60/403] time 0.088 (0.098) data 0.001 (0.009) loss 1.3675 (1.6888) teacher_loss 0.6063 (0.8148) loss_zs_kd 2.3364 (1.8623) loss_oracle 0.4405 (0.4738) acc 84.3750 (71.6146) lr 3.1417e-05 eta 0:01:52
epoch [48/50] batch [80/403] time 0.086 (0.095) data 0.000 (0.007) loss 1.9252 (1.6746) teacher_loss 0.9991 (0.8024) loss_zs_kd 1.9740 (1.8373) loss_oracle 0.5026 (0.4722) acc 56.2500 (71.9922) lr 3.1417e-05 eta 0:01:47
epoch [48/50] batch [100/403] time 0.071 (0.091) data 0.000 (0.005) loss 1.4631 (1.6728) teacher_loss 0.5934 (0.8010) loss_zs_kd 1.6151 (1.8296) loss_oracle 0.5117 (0.4730) acc 84.3750 (72.2188) lr 3.1417e-05 eta 0:01:40
epoch [48/50] batch [120/403] time 0.105 (0.090) data 0.000 (0.004) loss 1.7684 (1.6870) teacher_loss 0.7917 (0.8131) loss_zs_kd 2.3244 (1.8185) loss_oracle 0.4788 (0.4725) acc 71.8750 (71.7708) lr 3.1417e-05 eta 0:01:38
epoch [48/50] batch [140/403] time 0.062 (0.091) data 0.000 (0.004) loss 1.5627 (1.6822) teacher_loss 0.7329 (0.8074) loss_zs_kd 1.7882 (1.8287) loss_oracle 0.4871 (0.4732) acc 75.0000 (71.7857) lr 3.1417e-05 eta 0:01:37
epoch [48/50] batch [160/403] time 0.064 (0.091) data 0.000 (0.003) loss 1.5423 (1.6831) teacher_loss 0.7539 (0.8107) loss_zs_kd 1.4866 (1.8227) loss_oracle 0.4391 (0.4725) acc 78.1250 (71.5820) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [180/403] time 0.106 (0.092) data 0.000 (0.003) loss 1.6996 (1.6812) teacher_loss 0.7575 (0.8075) loss_zs_kd 2.0874 (1.8182) loss_oracle 0.4967 (0.4721) acc 71.8750 (71.7708) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [200/403] time 0.068 (0.091) data 0.001 (0.003) loss 1.6990 (1.6795) teacher_loss 0.8282 (0.8055) loss_zs_kd 1.8544 (1.8159) loss_oracle 0.4560 (0.4717) acc 78.1250 (72.0469) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [220/403] time 0.056 (0.088) data 0.001 (0.003) loss 1.3911 (1.6732) teacher_loss 0.5391 (0.7978) loss_zs_kd 1.7438 (1.8241) loss_oracle 0.4910 (0.4726) acc 78.1250 (72.4432) lr 3.1417e-05 eta 0:01:27
epoch [48/50] batch [240/403] time 0.114 (0.088) data 0.000 (0.002) loss 1.5146 (1.6815) teacher_loss 0.6286 (0.8057) loss_zs_kd 1.6650 (1.8186) loss_oracle 0.4765 (0.4729) acc 78.1250 (72.2005) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [260/403] time 0.087 (0.088) data 0.000 (0.002) loss 1.4879 (1.6780) teacher_loss 0.6948 (0.8037) loss_zs_kd 1.6144 (1.8232) loss_oracle 0.4634 (0.4730) acc 81.2500 (72.3197) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [280/403] time 0.063 (0.088) data 0.000 (0.002) loss 1.6076 (1.6730) teacher_loss 0.6916 (0.7992) loss_zs_kd 1.4909 (1.8172) loss_oracle 0.5193 (0.4727) acc 81.2500 (72.4665) lr 3.1417e-05 eta 0:01:21
epoch [48/50] batch [300/403] time 0.065 (0.089) data 0.000 (0.002) loss 1.8503 (1.6762) teacher_loss 0.8904 (0.8006) loss_zs_kd 1.9415 (1.8195) loss_oracle 0.4718 (0.4731) acc 65.6250 (72.3542) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [320/403] time 0.097 (0.088) data 0.000 (0.002) loss 1.9301 (1.6811) teacher_loss 1.0452 (0.8047) loss_zs_kd 1.7644 (1.8181) loss_oracle 0.4964 (0.4729) acc 71.8750 (72.2266) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [340/403] time 0.089 (0.088) data 0.000 (0.002) loss 1.3874 (1.6795) teacher_loss 0.4287 (0.8026) loss_zs_kd 1.7097 (1.8267) loss_oracle 0.4672 (0.4729) acc 81.2500 (72.2243) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [360/403] time 0.082 (0.088) data 0.000 (0.002) loss 2.0639 (1.6851) teacher_loss 1.1988 (0.8077) loss_zs_kd 1.4905 (1.8280) loss_oracle 0.4622 (0.4729) acc 65.6250 (72.1094) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [380/403] time 0.090 (0.088) data 0.000 (0.002) loss 1.4801 (1.6850) teacher_loss 0.7014 (0.8068) loss_zs_kd 1.7577 (1.8327) loss_oracle 0.4542 (0.4734) acc 78.1250 (72.2780) lr 3.1417e-05 eta 0:01:12
epoch [48/50] batch [400/403] time 0.064 (0.088) data 0.000 (0.002) loss 1.4945 (1.6831) teacher_loss 0.5695 (0.8047) loss_zs_kd 1.8890 (1.8323) loss_oracle 0.4499 (0.4733) acc 87.5000 (72.4141) lr 3.1417e-05 eta 0:01:10
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,980
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,551
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [49/50] batch [20/403] time 0.073 (0.112) data 0.000 (0.024) loss 1.6087 (1.6374) teacher_loss 0.7695 (0.7792) loss_zs_kd 1.9473 (1.7757) loss_oracle 0.4362 (0.4713) acc 68.7500 (72.3438) lr 1.7713e-05 eta 0:01:28
epoch [49/50] batch [40/403] time 0.079 (0.102) data 0.000 (0.012) loss 1.8220 (1.6791) teacher_loss 0.9129 (0.8046) loss_zs_kd 1.4365 (1.7800) loss_oracle 0.5010 (0.4710) acc 71.8750 (71.4062) lr 1.7713e-05 eta 0:01:18
epoch [49/50] batch [60/403] time 0.094 (0.098) data 0.001 (0.008) loss 1.7361 (1.6815) teacher_loss 0.8288 (0.8062) loss_zs_kd 1.8532 (1.7943) loss_oracle 0.4832 (0.4749) acc 71.8750 (71.7708) lr 1.7713e-05 eta 0:01:13
epoch [49/50] batch [80/403] time 0.071 (0.095) data 0.000 (0.006) loss 1.4434 (1.6738) teacher_loss 0.5024 (0.7945) loss_zs_kd 2.0975 (1.8118) loss_oracle 0.4921 (0.4769) acc 90.6250 (72.7734) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [100/403] time 0.078 (0.093) data 0.000 (0.005) loss 2.0186 (1.6859) teacher_loss 1.1262 (0.8055) loss_zs_kd 1.7075 (1.8040) loss_oracle 0.4841 (0.4773) acc 68.7500 (72.3438) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [120/403] time 0.091 (0.092) data 0.000 (0.004) loss 1.8418 (1.6926) teacher_loss 1.0491 (0.8096) loss_zs_kd 1.4046 (1.8006) loss_oracle 0.4795 (0.4773) acc 65.6250 (72.1615) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [140/403] time 0.080 (0.091) data 0.000 (0.004) loss 1.8612 (1.6923) teacher_loss 0.9618 (0.8103) loss_zs_kd 1.4546 (1.7904) loss_oracle 0.5024 (0.4766) acc 68.7500 (72.0089) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [160/403] time 0.086 (0.090) data 0.000 (0.003) loss 1.6669 (1.6976) teacher_loss 0.8663 (0.8145) loss_zs_kd 1.8181 (1.7922) loss_oracle 0.4880 (0.4765) acc 65.6250 (71.9922) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [180/403] time 0.071 (0.088) data 0.000 (0.003) loss 1.6747 (1.7046) teacher_loss 0.8589 (0.8212) loss_zs_kd 1.7350 (1.7992) loss_oracle 0.4738 (0.4765) acc 78.1250 (71.8924) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [200/403] time 0.071 (0.089) data 0.000 (0.003) loss 1.8041 (1.7000) teacher_loss 0.9003 (0.8186) loss_zs_kd 1.7766 (1.8094) loss_oracle 0.5075 (0.4764) acc 62.5000 (71.9375) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [220/403] time 0.065 (0.088) data 0.000 (0.002) loss 1.3577 (1.6959) teacher_loss 0.6160 (0.8145) loss_zs_kd 1.5776 (1.8201) loss_oracle 0.4760 (0.4769) acc 68.7500 (72.0881) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [240/403] time 0.084 (0.089) data 0.000 (0.002) loss 1.6270 (1.6914) teacher_loss 0.8193 (0.8097) loss_zs_kd 2.1616 (1.8268) loss_oracle 0.4643 (0.4768) acc 78.1250 (72.1094) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [260/403] time 0.143 (0.089) data 0.000 (0.002) loss 1.6343 (1.6944) teacher_loss 0.8428 (0.8122) loss_zs_kd 1.5147 (1.8241) loss_oracle 0.4542 (0.4769) acc 68.7500 (72.0793) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [280/403] time 0.070 (0.089) data 0.000 (0.002) loss 1.6094 (1.6912) teacher_loss 0.8498 (0.8107) loss_zs_kd 1.0245 (1.8212) loss_oracle 0.4518 (0.4766) acc 75.0000 (72.2433) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [300/403] time 0.073 (0.088) data 0.000 (0.002) loss 1.4435 (1.6917) teacher_loss 0.6005 (0.8124) loss_zs_kd 2.1377 (1.8279) loss_oracle 0.4815 (0.4762) acc 81.2500 (72.1458) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [320/403] time 0.068 (0.088) data 0.000 (0.002) loss 1.5769 (1.6888) teacher_loss 0.6784 (0.8090) loss_zs_kd 1.9462 (1.8298) loss_oracle 0.4809 (0.4762) acc 78.1250 (72.2852) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [340/403] time 0.070 (0.088) data 0.000 (0.002) loss 1.5466 (1.6894) teacher_loss 0.6639 (0.8079) loss_zs_kd 2.0710 (1.8309) loss_oracle 0.4973 (0.4760) acc 75.0000 (72.2151) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [360/403] time 0.082 (0.089) data 0.000 (0.002) loss 1.7329 (1.6921) teacher_loss 0.8029 (0.8109) loss_zs_kd 1.5119 (1.8346) loss_oracle 0.4872 (0.4759) acc 65.6250 (72.0312) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [380/403] time 0.159 (0.089) data 0.000 (0.002) loss 1.6273 (1.6909) teacher_loss 0.8113 (0.8102) loss_zs_kd 2.0950 (1.8308) loss_oracle 0.4499 (0.4753) acc 81.2500 (72.0230) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [400/403] time 0.081 (0.088) data 0.000 (0.002) loss 1.4995 (1.6913) teacher_loss 0.5614 (0.8108) loss_zs_kd 1.8852 (1.8329) loss_oracle 0.4627 (0.4752) acc 84.3750 (72.0078) lr 1.7713e-05 eta 0:00:35
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,981
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,550
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
epoch [50/50] batch [20/403] time 0.090 (0.124) data 0.000 (0.033) loss 1.5859 (1.6699) teacher_loss 0.7501 (0.8071) loss_zs_kd 1.8872 (1.8040) loss_oracle 0.4700 (0.4789) acc 87.5000 (70.4688) lr 7.8853e-06 eta 0:00:47
epoch [50/50] batch [40/403] time 0.071 (0.105) data 0.000 (0.016) loss 1.6992 (1.7089) teacher_loss 0.7372 (0.8375) loss_zs_kd 2.3023 (1.8263) loss_oracle 0.4998 (0.4764) acc 65.6250 (69.8438) lr 7.8853e-06 eta 0:00:38
epoch [50/50] batch [60/403] time 0.065 (0.098) data 0.000 (0.011) loss 1.7476 (1.7030) teacher_loss 0.8965 (0.8339) loss_zs_kd 2.0155 (1.8300) loss_oracle 0.4813 (0.4748) acc 71.8750 (70.3125) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [80/403] time 0.077 (0.091) data 0.000 (0.008) loss 1.5468 (1.6932) teacher_loss 0.6300 (0.8218) loss_zs_kd 1.5667 (1.8157) loss_oracle 0.4655 (0.4748) acc 75.0000 (71.0547) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [100/403] time 0.075 (0.086) data 0.000 (0.007) loss 1.6751 (1.6885) teacher_loss 0.7616 (0.8169) loss_zs_kd 1.4960 (1.8096) loss_oracle 0.4901 (0.4742) acc 71.8750 (71.0000) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [120/403] time 0.069 (0.084) data 0.000 (0.006) loss 1.9012 (1.6944) teacher_loss 0.9608 (0.8198) loss_zs_kd 1.9180 (1.8142) loss_oracle 0.5190 (0.4762) acc 56.2500 (71.0677) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [140/403] time 0.092 (0.084) data 0.000 (0.005) loss 1.8325 (1.6887) teacher_loss 0.9250 (0.8160) loss_zs_kd 1.7753 (1.8275) loss_oracle 0.5078 (0.4753) acc 71.8750 (71.5402) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [160/403] time 0.077 (0.082) data 0.000 (0.004) loss 1.6663 (1.6806) teacher_loss 0.7706 (0.8089) loss_zs_kd 2.0569 (1.8315) loss_oracle 0.4390 (0.4749) acc 71.8750 (71.7969) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [180/403] time 0.077 (0.082) data 0.000 (0.004) loss 1.6584 (1.6836) teacher_loss 0.7177 (0.8137) loss_zs_kd 1.7265 (1.8258) loss_oracle 0.5055 (0.4750) acc 71.8750 (71.5799) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [200/403] time 0.079 (0.082) data 0.000 (0.004) loss 1.6024 (1.6817) teacher_loss 0.8079 (0.8087) loss_zs_kd 2.1864 (1.8225) loss_oracle 0.4387 (0.4742) acc 71.8750 (71.7500) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [220/403] time 0.092 (0.083) data 0.000 (0.003) loss 1.8685 (1.6799) teacher_loss 0.9677 (0.8072) loss_zs_kd 1.8440 (1.8103) loss_oracle 0.4845 (0.4742) acc 75.0000 (71.9034) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [240/403] time 0.091 (0.083) data 0.000 (0.003) loss 1.7892 (1.6823) teacher_loss 0.9488 (0.8091) loss_zs_kd 1.8150 (1.8075) loss_oracle 0.5029 (0.4750) acc 62.5000 (71.7708) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [260/403] time 0.084 (0.083) data 0.000 (0.003) loss 1.9467 (1.6852) teacher_loss 1.1041 (0.8117) loss_zs_kd 1.2481 (1.8121) loss_oracle 0.4486 (0.4750) acc 56.2500 (71.6106) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [280/403] time 0.070 (0.082) data 0.000 (0.003) loss 1.9153 (1.6887) teacher_loss 1.0527 (0.8136) loss_zs_kd 1.7006 (1.8134) loss_oracle 0.4707 (0.4749) acc 65.6250 (71.6964) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [300/403] time 0.057 (0.082) data 0.000 (0.002) loss 1.5766 (1.6917) teacher_loss 0.6335 (0.8168) loss_zs_kd 1.9806 (1.8185) loss_oracle 0.4752 (0.4745) acc 78.1250 (71.6875) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [320/403] time 0.128 (0.081) data 0.000 (0.002) loss 1.7582 (1.6978) teacher_loss 0.8578 (0.8234) loss_zs_kd 1.9712 (1.8201) loss_oracle 0.4505 (0.4742) acc 68.7500 (71.3867) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [340/403] time 0.064 (0.081) data 0.000 (0.002) loss 1.6584 (1.6989) teacher_loss 0.8197 (0.8233) loss_zs_kd 1.7833 (1.8252) loss_oracle 0.4973 (0.4745) acc 65.6250 (71.2592) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [360/403] time 0.109 (0.082) data 0.000 (0.002) loss 1.4996 (1.7006) teacher_loss 0.6405 (0.8234) loss_zs_kd 1.5208 (1.8286) loss_oracle 0.4939 (0.4749) acc 78.1250 (71.2847) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [380/403] time 0.055 (0.082) data 0.000 (0.002) loss 1.7065 (1.7028) teacher_loss 0.8382 (0.8248) loss_zs_kd 1.6101 (1.8269) loss_oracle 0.4689 (0.4748) acc 71.8750 (71.2007) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [400/403] time 0.054 (0.082) data 0.000 (0.002) loss 1.4832 (1.7013) teacher_loss 0.5998 (0.8233) loss_zs_kd 2.4569 (1.8285) loss_oracle 0.4963 (0.4751) acc 78.1250 (71.2344) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,981
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,553
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.1%, epoch: 39 *******
******* Domain 4 best val test acc: 43.9%, epoch: 39 *******
******* Domain 4 best test acc:     47.1%, epoch: 13 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:41:22

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_38', 'location_46']
Target     ['location_43']
# classes  10
# train_x  14,252
# val      6,108
# test     3,970
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  256
gate.mlp.2.bias                                    2
Total trainable params: 70,019
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/445] time 0.063 (0.140) data 0.000 (0.036) loss 2.9418 (2.8479) teacher_loss 2.3559 (2.2823) loss_zs_kd 0.0007 (0.0002) loss_oracle 0.0089 (0.0043) acc 31.2500 (30.7812) lr 1.0000e-05 eta 0:51:50
epoch [1/50] batch [40/445] time 0.071 (0.113) data 0.000 (0.018) loss 3.0037 (2.8637) teacher_loss 2.4513 (2.2944) loss_zs_kd 0.0058 (0.0015) loss_oracle 0.0374 (0.0113) acc 15.6250 (28.8281) lr 1.0000e-05 eta 0:41:46
epoch [1/50] batch [60/445] time 0.059 (0.102) data 0.000 (0.012) loss 2.5937 (2.8234) teacher_loss 2.0398 (2.2479) loss_zs_kd 0.0178 (0.0045) loss_oracle 0.0376 (0.0194) acc 37.5000 (30.8333) lr 1.0000e-05 eta 0:37:40
epoch [1/50] batch [80/445] time 0.153 (0.099) data 0.000 (0.009) loss 2.3289 (2.8187) teacher_loss 1.7306 (2.2311) loss_zs_kd 0.0466 (0.0103) loss_oracle 0.0533 (0.0280) acc 53.1250 (31.2109) lr 1.0000e-05 eta 0:36:29
epoch [1/50] batch [100/445] time 0.052 (0.096) data 0.000 (0.007) loss 2.2583 (2.7549) teacher_loss 1.6244 (2.1689) loss_zs_kd 0.1542 (0.0249) loss_oracle 0.1886 (0.0324) acc 46.8750 (32.5625) lr 1.0000e-05 eta 0:35:28
epoch [1/50] batch [120/445] time 0.153 (0.095) data 0.000 (0.006) loss 2.4260 (2.7382) teacher_loss 1.6923 (2.1198) loss_zs_kd 0.3149 (0.0685) loss_oracle 0.4859 (0.0958) acc 37.5000 (33.3073) lr 1.0000e-05 eta 0:35:06
epoch [1/50] batch [140/445] time 0.072 (0.095) data 0.000 (0.005) loss 2.3368 (2.7206) teacher_loss 1.6601 (2.0744) loss_zs_kd 0.4292 (0.1229) loss_oracle 0.2354 (0.1486) acc 34.3750 (34.1964) lr 1.0000e-05 eta 0:35:02
epoch [1/50] batch [160/445] time 0.084 (0.094) data 0.000 (0.005) loss 2.5436 (2.7060) teacher_loss 1.7032 (2.0318) loss_zs_kd 0.4247 (0.1676) loss_oracle 0.5884 (0.1998) acc 37.5000 (35.4102) lr 1.0000e-05 eta 0:34:45
epoch [1/50] batch [180/445] time 0.086 (0.093) data 0.000 (0.004) loss 2.6364 (2.6796) teacher_loss 1.7636 (1.9814) loss_zs_kd 0.3373 (0.1957) loss_oracle 0.5061 (0.2427) acc 34.3750 (36.4583) lr 1.0000e-05 eta 0:34:16
epoch [1/50] batch [200/445] time 0.086 (0.092) data 0.000 (0.004) loss 3.2289 (2.6728) teacher_loss 2.2988 (1.9546) loss_zs_kd 0.6730 (0.2334) loss_oracle 0.5716 (0.2753) acc 21.8750 (36.8125) lr 1.0000e-05 eta 0:33:55
epoch [1/50] batch [220/445] time 0.077 (0.091) data 0.000 (0.004) loss 2.4459 (2.6686) teacher_loss 1.5538 (1.9339) loss_zs_kd 0.4763 (0.2659) loss_oracle 0.5327 (0.3037) acc 40.6250 (37.2017) lr 1.0000e-05 eta 0:33:35
epoch [1/50] batch [240/445] time 0.091 (0.091) data 0.000 (0.003) loss 2.7462 (2.6622) teacher_loss 1.7641 (1.9131) loss_zs_kd 0.5106 (0.2898) loss_oracle 0.6199 (0.3256) acc 34.3750 (37.4479) lr 1.0000e-05 eta 0:33:25
epoch [1/50] batch [260/445] time 0.083 (0.091) data 0.000 (0.003) loss 2.4607 (2.6514) teacher_loss 1.5965 (1.8904) loss_zs_kd 0.5924 (0.3128) loss_oracle 0.5851 (0.3461) acc 46.8750 (38.1370) lr 1.0000e-05 eta 0:33:18
epoch [1/50] batch [280/445] time 0.088 (0.090) data 0.000 (0.003) loss 2.8654 (2.6397) teacher_loss 1.9313 (1.8692) loss_zs_kd 0.5924 (0.3317) loss_oracle 0.5725 (0.3629) acc 37.5000 (38.7835) lr 1.0000e-05 eta 0:33:07
epoch [1/50] batch [300/445] time 0.077 (0.090) data 0.000 (0.003) loss 2.7288 (2.6358) teacher_loss 1.7067 (1.8511) loss_zs_kd 1.0061 (0.3585) loss_oracle 0.7002 (0.3825) acc 50.0000 (39.1979) lr 1.0000e-05 eta 0:32:55
epoch [1/50] batch [320/445] time 0.085 (0.090) data 0.000 (0.002) loss 2.5771 (2.6382) teacher_loss 1.5840 (1.8391) loss_zs_kd 0.9562 (0.4016) loss_oracle 0.6469 (0.4016) acc 56.2500 (39.4434) lr 1.0000e-05 eta 0:32:46
epoch [1/50] batch [340/445] time 0.087 (0.089) data 0.000 (0.002) loss 2.8288 (2.6449) teacher_loss 1.9019 (1.8358) loss_zs_kd 0.6957 (0.4167) loss_oracle 0.6608 (0.4166) acc 37.5000 (39.5037) lr 1.0000e-05 eta 0:32:39
epoch [1/50] batch [360/445] time 0.060 (0.089) data 0.000 (0.002) loss 2.5634 (2.6351) teacher_loss 1.6125 (1.8194) loss_zs_kd 0.4980 (0.4242) loss_oracle 0.6453 (0.4283) acc 50.0000 (39.9132) lr 1.0000e-05 eta 0:32:29
epoch [1/50] batch [380/445] time 0.084 (0.089) data 0.000 (0.002) loss 2.6084 (2.6343) teacher_loss 1.6611 (1.8117) loss_zs_kd 0.4989 (0.4340) loss_oracle 0.6256 (0.4394) acc 40.6250 (40.0740) lr 1.0000e-05 eta 0:32:24
epoch [1/50] batch [400/445] time 0.081 (0.089) data 0.000 (0.002) loss 2.7631 (2.6309) teacher_loss 1.7942 (1.8022) loss_zs_kd 0.6969 (0.4495) loss_oracle 0.6158 (0.4489) acc 34.3750 (40.3047) lr 1.0000e-05 eta 0:32:18
epoch [1/50] batch [420/445] time 0.085 (0.089) data 0.000 (0.002) loss 2.7745 (2.6240) teacher_loss 1.8073 (1.7932) loss_zs_kd 0.5054 (0.4522) loss_oracle 0.5961 (0.4527) acc 43.7500 (40.4985) lr 1.0000e-05 eta 0:32:12
epoch [1/50] batch [440/445] time 0.083 (0.088) data 0.000 (0.002) loss 2.5103 (2.6178) teacher_loss 1.6153 (1.7857) loss_zs_kd 0.4932 (0.4551) loss_oracle 0.4551 (0.4555) acc 50.0000 (40.6605) lr 1.0000e-05 eta 0:32:06
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 2,886
* accuracy: 47.2%
* error: 52.8%
* macro_f1: 34.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,400
* accuracy: 35.3%
* error: 64.7%
* macro_f1: 26.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      47.2%, epoch: 1 *******
******* Domain 3 best val test acc: 35.3%, epoch: 1 *******
******* Domain 3 best test acc:     35.3%, epoch: 1 *******
epoch [2/50] batch [20/445] time 0.068 (0.123) data 0.000 (0.031) loss 2.8082 (2.6453) teacher_loss 1.8438 (1.6976) loss_zs_kd 0.6463 (0.4599) loss_oracle 0.6373 (0.6230) acc 43.7500 (45.3125) lr 2.0000e-03 eta 0:44:37
epoch [2/50] batch [40/445] time 0.063 (0.107) data 0.000 (0.016) loss 2.3393 (2.5583) teacher_loss 1.3629 (1.6068) loss_zs_kd 0.4638 (0.5916) loss_oracle 0.6689 (0.6372) acc 46.8750 (47.3438) lr 2.0000e-03 eta 0:38:56
epoch [2/50] batch [60/445] time 0.056 (0.101) data 0.000 (0.011) loss 2.6636 (2.5041) teacher_loss 1.6931 (1.5458) loss_zs_kd 0.5835 (0.6000) loss_oracle 0.6525 (0.6440) acc 43.7500 (49.1667) lr 2.0000e-03 eta 0:36:31
epoch [2/50] batch [80/445] time 0.069 (0.099) data 0.000 (0.008) loss 2.1203 (2.4402) teacher_loss 1.1725 (1.4817) loss_zs_kd 0.7214 (0.6111) loss_oracle 0.6373 (0.6431) acc 62.5000 (51.0156) lr 2.0000e-03 eta 0:35:50
epoch [2/50] batch [100/445] time 0.087 (0.096) data 0.000 (0.007) loss 2.2577 (2.4020) teacher_loss 1.3097 (1.4459) loss_zs_kd 1.0080 (0.6539) loss_oracle 0.6276 (0.6404) acc 43.7500 (51.9375) lr 2.0000e-03 eta 0:34:53
epoch [2/50] batch [120/445] time 0.084 (0.094) data 0.000 (0.005) loss 2.0886 (2.3597) teacher_loss 1.1392 (1.4097) loss_zs_kd 0.9153 (0.7014) loss_oracle 0.5873 (0.6355) acc 71.8750 (52.7865) lr 2.0000e-03 eta 0:34:06
epoch [2/50] batch [140/445] time 0.086 (0.093) data 0.000 (0.005) loss 2.0194 (2.3135) teacher_loss 1.0705 (1.3648) loss_zs_kd 1.0423 (0.7342) loss_oracle 0.5997 (0.6315) acc 59.3750 (54.0179) lr 2.0000e-03 eta 0:33:38
epoch [2/50] batch [160/445] time 0.084 (0.092) data 0.000 (0.004) loss 2.7151 (2.2814) teacher_loss 1.8080 (1.3380) loss_zs_kd 0.9225 (0.7448) loss_oracle 0.5962 (0.6267) acc 15.6250 (54.6680) lr 2.0000e-03 eta 0:33:15
epoch [2/50] batch [180/445] time 0.086 (0.091) data 0.000 (0.004) loss 1.8471 (2.2519) teacher_loss 0.9589 (1.3144) loss_zs_kd 0.7779 (0.7582) loss_oracle 0.5763 (0.6220) acc 62.5000 (55.4167) lr 2.0000e-03 eta 0:32:55
epoch [2/50] batch [200/445] time 0.078 (0.091) data 0.000 (0.003) loss 2.0121 (2.2350) teacher_loss 1.1371 (1.3038) loss_zs_kd 0.9744 (0.7750) loss_oracle 0.5637 (0.6166) acc 53.1250 (55.5156) lr 2.0000e-03 eta 0:32:39
epoch [2/50] batch [220/445] time 0.086 (0.090) data 0.000 (0.003) loss 1.9083 (2.2215) teacher_loss 1.0571 (1.2967) loss_zs_kd 0.6888 (0.7805) loss_oracle 0.5517 (0.6112) acc 59.3750 (55.7244) lr 2.0000e-03 eta 0:32:27
epoch [2/50] batch [240/445] time 0.084 (0.090) data 0.000 (0.003) loss 2.2489 (2.2038) teacher_loss 1.4237 (1.2863) loss_zs_kd 0.7364 (0.7832) loss_oracle 0.5393 (0.6058) acc 59.3750 (56.1719) lr 2.0000e-03 eta 0:32:15
epoch [2/50] batch [260/445] time 0.079 (0.089) data 0.000 (0.003) loss 1.7066 (2.1885) teacher_loss 0.9406 (1.2781) loss_zs_kd 1.0227 (0.7845) loss_oracle 0.5268 (0.6001) acc 65.6250 (56.3462) lr 2.0000e-03 eta 0:32:02
epoch [2/50] batch [280/445] time 0.085 (0.089) data 0.000 (0.003) loss 2.2892 (2.1713) teacher_loss 1.4636 (1.2670) loss_zs_kd 1.0940 (0.7945) loss_oracle 0.5157 (0.5943) acc 43.7500 (56.6406) lr 2.0000e-03 eta 0:31:53
epoch [2/50] batch [300/445] time 0.082 (0.089) data 0.000 (0.002) loss 2.0771 (2.1571) teacher_loss 1.2734 (1.2597) loss_zs_kd 0.9734 (0.8025) loss_oracle 0.5049 (0.5887) acc 53.1250 (56.8646) lr 2.0000e-03 eta 0:31:46
epoch [2/50] batch [320/445] time 0.082 (0.088) data 0.000 (0.002) loss 1.6957 (2.1464) teacher_loss 0.9223 (1.2555) loss_zs_kd 0.9626 (0.8061) loss_oracle 0.4793 (0.5833) acc 65.6250 (56.9336) lr 2.0000e-03 eta 0:31:39
epoch [2/50] batch [340/445] time 0.085 (0.089) data 0.000 (0.002) loss 1.9780 (2.1273) teacher_loss 1.1504 (1.2418) loss_zs_kd 1.2880 (0.8259) loss_oracle 0.4931 (0.5781) acc 65.6250 (57.4540) lr 2.0000e-03 eta 0:31:42
epoch [2/50] batch [360/445] time 0.090 (0.088) data 0.000 (0.002) loss 1.6753 (2.1142) teacher_loss 0.9222 (1.2346) loss_zs_kd 0.8108 (0.8425) loss_oracle 0.4647 (0.5729) acc 65.6250 (57.6215) lr 2.0000e-03 eta 0:31:37
epoch [2/50] batch [380/445] time 0.088 (0.088) data 0.000 (0.002) loss 1.7742 (2.1015) teacher_loss 1.0424 (1.2286) loss_zs_kd 1.0682 (0.8533) loss_oracle 0.4836 (0.5680) acc 62.5000 (57.8125) lr 2.0000e-03 eta 0:31:30
epoch [2/50] batch [400/445] time 0.080 (0.088) data 0.000 (0.002) loss 1.7374 (2.0869) teacher_loss 0.9577 (1.2188) loss_zs_kd 1.0439 (0.8682) loss_oracle 0.4571 (0.5630) acc 65.6250 (58.0703) lr 2.0000e-03 eta 0:31:23
epoch [2/50] batch [420/445] time 0.073 (0.087) data 0.000 (0.002) loss 2.1524 (2.0768) teacher_loss 1.3804 (1.2133) loss_zs_kd 1.0073 (0.8813) loss_oracle 0.4521 (0.5580) acc 53.1250 (58.2812) lr 2.0000e-03 eta 0:31:04
epoch [2/50] batch [440/445] time 0.061 (0.087) data 0.000 (0.002) loss 1.9307 (2.0720) teacher_loss 1.1313 (1.2128) loss_zs_kd 0.8927 (0.8885) loss_oracle 0.4467 (0.5532) acc 71.8750 (58.3310) lr 2.0000e-03 eta 0:31:02
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,904
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 48.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,705
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 27.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      63.9%, epoch: 2 *******
******* Domain 3 best val test acc: 42.9%, epoch: 2 *******
******* Domain 3 best test acc:     42.9%, epoch: 2 *******
epoch [3/50] batch [20/445] time 0.083 (0.124) data 0.000 (0.034) loss 1.6858 (1.8439) teacher_loss 0.9547 (1.0692) loss_zs_kd 1.2328 (1.1303) loss_oracle 0.4295 (0.4441) acc 62.5000 (62.3438) lr 1.9980e-03 eta 0:44:01
epoch [3/50] batch [40/445] time 0.077 (0.099) data 0.000 (0.017) loss 1.8020 (1.8460) teacher_loss 1.0603 (1.0712) loss_zs_kd 1.4294 (1.2102) loss_oracle 0.4474 (0.4447) acc 59.3750 (62.5000) lr 1.9980e-03 eta 0:35:08
epoch [3/50] batch [60/445] time 0.066 (0.090) data 0.000 (0.012) loss 1.4008 (1.8447) teacher_loss 0.7390 (1.0867) loss_zs_kd 1.0472 (1.2578) loss_oracle 0.4285 (0.4435) acc 78.1250 (61.8229) lr 1.9980e-03 eta 0:31:48
epoch [3/50] batch [80/445] time 0.085 (0.088) data 0.000 (0.009) loss 2.0025 (1.8248) teacher_loss 1.1802 (1.0812) loss_zs_kd 1.4674 (1.2502) loss_oracle 0.4484 (0.4431) acc 59.3750 (62.1484) lr 1.9980e-03 eta 0:31:19
epoch [3/50] batch [100/445] time 0.084 (0.088) data 0.000 (0.007) loss 1.6918 (1.8274) teacher_loss 0.9989 (1.0844) loss_zs_kd 1.5024 (1.2612) loss_oracle 0.4165 (0.4395) acc 65.6250 (62.3750) lr 1.9980e-03 eta 0:31:00
epoch [3/50] batch [120/445] time 0.086 (0.087) data 0.000 (0.006) loss 2.1294 (1.8271) teacher_loss 1.2965 (1.0856) loss_zs_kd 1.4369 (1.2417) loss_oracle 0.4417 (0.4379) acc 59.3750 (62.6562) lr 1.9980e-03 eta 0:30:47
epoch [3/50] batch [140/445] time 0.087 (0.087) data 0.000 (0.005) loss 2.1131 (1.8322) teacher_loss 1.4118 (1.0899) loss_zs_kd 1.2024 (1.2515) loss_oracle 0.4473 (0.4360) acc 50.0000 (62.5670) lr 1.9980e-03 eta 0:30:41
epoch [3/50] batch [160/445] time 0.083 (0.087) data 0.000 (0.004) loss 1.8435 (1.8304) teacher_loss 1.1655 (1.0938) loss_zs_kd 0.9564 (1.2284) loss_oracle 0.4189 (0.4346) acc 43.7500 (62.3633) lr 1.9980e-03 eta 0:30:36
epoch [3/50] batch [180/445] time 0.085 (0.086) data 0.000 (0.004) loss 1.1706 (1.8109) teacher_loss 0.5301 (1.0834) loss_zs_kd 1.2201 (1.2221) loss_oracle 0.4232 (0.4322) acc 87.5000 (62.6389) lr 1.9980e-03 eta 0:30:19
epoch [3/50] batch [200/445] time 0.084 (0.086) data 0.000 (0.004) loss 1.7759 (1.8064) teacher_loss 1.0677 (1.0815) loss_zs_kd 0.9333 (1.2163) loss_oracle 0.4156 (0.4301) acc 62.5000 (62.5469) lr 1.9980e-03 eta 0:30:09
epoch [3/50] batch [220/445] time 0.081 (0.085) data 0.000 (0.003) loss 2.0164 (1.8056) teacher_loss 1.3571 (1.0827) loss_zs_kd 1.3518 (1.2215) loss_oracle 0.4018 (0.4283) acc 50.0000 (62.5710) lr 1.9980e-03 eta 0:30:05
epoch [3/50] batch [240/445] time 0.085 (0.085) data 0.000 (0.003) loss 1.4413 (1.7985) teacher_loss 0.8293 (1.0827) loss_zs_kd 1.2626 (1.2279) loss_oracle 0.3876 (0.4263) acc 71.8750 (62.6302) lr 1.9980e-03 eta 0:30:01
epoch [3/50] batch [260/445] time 0.086 (0.085) data 0.000 (0.003) loss 1.9062 (1.8007) teacher_loss 1.1790 (1.0876) loss_zs_kd 1.0103 (1.2284) loss_oracle 0.4116 (0.4242) acc 53.1250 (62.2716) lr 1.9980e-03 eta 0:29:59
epoch [3/50] batch [280/445] time 0.085 (0.085) data 0.000 (0.003) loss 2.1329 (1.7965) teacher_loss 1.3607 (1.0859) loss_zs_kd 1.2960 (1.2244) loss_oracle 0.3764 (0.4226) acc 59.3750 (62.4107) lr 1.9980e-03 eta 0:29:55
epoch [3/50] batch [300/445] time 0.085 (0.085) data 0.000 (0.002) loss 1.4677 (1.7964) teacher_loss 0.8447 (1.0868) loss_zs_kd 0.8902 (1.2260) loss_oracle 0.3959 (0.4209) acc 68.7500 (62.2292) lr 1.9980e-03 eta 0:29:52
epoch [3/50] batch [320/445] time 0.086 (0.085) data 0.000 (0.002) loss 1.7586 (1.7894) teacher_loss 1.0627 (1.0792) loss_zs_kd 1.4942 (1.2404) loss_oracle 0.4222 (0.4192) acc 71.8750 (62.5098) lr 1.9980e-03 eta 0:29:49
epoch [3/50] batch [340/445] time 0.080 (0.085) data 0.000 (0.002) loss 2.1015 (1.7897) teacher_loss 1.3016 (1.0779) loss_zs_kd 1.3849 (1.2589) loss_oracle 0.4100 (0.4176) acc 59.3750 (62.6011) lr 1.9980e-03 eta 0:29:45
epoch [3/50] batch [360/445] time 0.067 (0.084) data 0.000 (0.002) loss 1.9246 (1.7907) teacher_loss 1.1562 (1.0772) loss_zs_kd 1.3444 (1.2782) loss_oracle 0.4111 (0.4167) acc 59.3750 (62.7431) lr 1.9980e-03 eta 0:29:27
epoch [3/50] batch [380/445] time 0.154 (0.085) data 0.000 (0.002) loss 1.7356 (1.7879) teacher_loss 1.0152 (1.0754) loss_zs_kd 1.5356 (1.2874) loss_oracle 0.4199 (0.4158) acc 65.6250 (62.7385) lr 1.9980e-03 eta 0:29:34
epoch [3/50] batch [400/445] time 0.066 (0.085) data 0.000 (0.002) loss 1.9256 (1.7828) teacher_loss 1.2750 (1.0721) loss_zs_kd 1.5379 (1.2954) loss_oracle 0.3896 (0.4141) acc 65.6250 (62.9297) lr 1.9980e-03 eta 0:29:40
epoch [3/50] batch [420/445] time 0.064 (0.085) data 0.000 (0.002) loss 1.8153 (1.7815) teacher_loss 1.0952 (1.0725) loss_zs_kd 1.0187 (1.3010) loss_oracle 0.3645 (0.4129) acc 65.6250 (62.9613) lr 1.9980e-03 eta 0:29:39
epoch [3/50] batch [440/445] time 0.155 (0.085) data 0.000 (0.002) loss 1.7480 (1.7805) teacher_loss 0.9274 (1.0716) loss_zs_kd 1.2769 (1.3054) loss_oracle 0.3614 (0.4114) acc 65.6250 (62.9119) lr 1.9980e-03 eta 0:29:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,926
* accuracy: 64.3%
* error: 35.7%
* macro_f1: 49.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,014
* accuracy: 50.7%
* error: 49.3%
* macro_f1: 32.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      64.3%, epoch: 3 *******
******* Domain 3 best val test acc: 50.7%, epoch: 3 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [4/50] batch [20/445] time 0.085 (0.113) data 0.000 (0.026) loss 1.9742 (1.6348) teacher_loss 1.2606 (0.9517) loss_zs_kd 1.4709 (1.6551) loss_oracle 0.4207 (0.3875) acc 59.3750 (67.1875) lr 1.9921e-03 eta 0:39:30
epoch [4/50] batch [40/445] time 0.086 (0.100) data 0.000 (0.013) loss 1.4813 (1.6676) teacher_loss 0.8806 (1.0070) loss_zs_kd 1.6026 (1.6563) loss_oracle 0.3603 (0.3824) acc 71.8750 (65.3125) lr 1.9921e-03 eta 0:34:37
epoch [4/50] batch [60/445] time 0.087 (0.095) data 0.000 (0.009) loss 1.8308 (1.6830) teacher_loss 1.1831 (1.0235) loss_zs_kd 1.8865 (1.6677) loss_oracle 0.3842 (0.3792) acc 59.3750 (64.5312) lr 1.9921e-03 eta 0:33:04
epoch [4/50] batch [80/445] time 0.084 (0.093) data 0.000 (0.007) loss 1.6031 (1.6806) teacher_loss 0.8984 (1.0211) loss_zs_kd 1.5978 (1.6833) loss_oracle 0.4147 (0.3772) acc 68.7500 (64.5703) lr 1.9921e-03 eta 0:32:10
epoch [4/50] batch [100/445] time 0.071 (0.089) data 0.000 (0.005) loss 1.7387 (1.6770) teacher_loss 1.0778 (1.0241) loss_zs_kd 1.6595 (1.6565) loss_oracle 0.4007 (0.3764) acc 59.3750 (64.5625) lr 1.9921e-03 eta 0:30:46
epoch [4/50] batch [120/445] time 0.085 (0.087) data 0.000 (0.005) loss 1.5554 (1.6846) teacher_loss 0.8406 (1.0317) loss_zs_kd 1.2233 (1.5956) loss_oracle 0.3424 (0.3746) acc 71.8750 (64.1927) lr 1.9921e-03 eta 0:30:03
epoch [4/50] batch [140/445] time 0.088 (0.087) data 0.000 (0.004) loss 1.4945 (1.6921) teacher_loss 0.8297 (1.0362) loss_zs_kd 1.0286 (1.5389) loss_oracle 0.3786 (0.3740) acc 84.3750 (64.2857) lr 1.9921e-03 eta 0:29:59
epoch [4/50] batch [160/445] time 0.109 (0.087) data 0.000 (0.003) loss 1.7016 (1.6843) teacher_loss 1.0058 (1.0273) loss_zs_kd 1.4622 (1.5286) loss_oracle 0.3749 (0.3739) acc 71.8750 (64.2578) lr 1.9921e-03 eta 0:30:11
epoch [4/50] batch [180/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.4131 (1.6839) teacher_loss 0.7835 (1.0247) loss_zs_kd 1.9349 (1.5406) loss_oracle 0.3500 (0.3719) acc 68.7500 (64.5660) lr 1.9921e-03 eta 0:30:09
epoch [4/50] batch [200/445] time 0.083 (0.087) data 0.000 (0.003) loss 1.4138 (1.6917) teacher_loss 0.5949 (1.0240) loss_zs_kd 1.7609 (1.5444) loss_oracle 0.3484 (0.3711) acc 81.2500 (64.5625) lr 1.9921e-03 eta 0:30:03
epoch [4/50] batch [220/445] time 0.070 (0.086) data 0.000 (0.003) loss 1.5704 (1.6954) teacher_loss 0.8684 (1.0194) loss_zs_kd 1.7512 (1.5659) loss_oracle 0.3485 (0.3704) acc 68.7500 (64.8580) lr 1.9921e-03 eta 0:29:40
epoch [4/50] batch [240/445] time 0.070 (0.085) data 0.000 (0.002) loss 1.5573 (1.6984) teacher_loss 0.8535 (1.0174) loss_zs_kd 1.6237 (1.5872) loss_oracle 0.3470 (0.3701) acc 78.1250 (65.0651) lr 1.9921e-03 eta 0:29:16
epoch [4/50] batch [260/445] time 0.068 (0.084) data 0.000 (0.002) loss 1.5757 (1.7023) teacher_loss 0.9344 (1.0188) loss_zs_kd 1.9260 (1.6031) loss_oracle 0.3468 (0.3700) acc 78.1250 (65.0240) lr 1.9921e-03 eta 0:28:53
epoch [4/50] batch [280/445] time 0.088 (0.084) data 0.000 (0.002) loss 1.8048 (1.7047) teacher_loss 0.9599 (1.0193) loss_zs_kd 1.6002 (1.6203) loss_oracle 0.3558 (0.3695) acc 71.8750 (65.0223) lr 1.9921e-03 eta 0:28:43
epoch [4/50] batch [300/445] time 0.082 (0.084) data 0.000 (0.002) loss 1.3554 (1.7089) teacher_loss 0.7443 (1.0241) loss_zs_kd 1.3884 (1.6030) loss_oracle 0.3424 (0.3687) acc 71.8750 (64.5625) lr 1.9921e-03 eta 0:28:41
epoch [4/50] batch [320/445] time 0.080 (0.083) data 0.000 (0.002) loss 1.6755 (1.7091) teacher_loss 0.9755 (1.0262) loss_zs_kd 1.1426 (1.5844) loss_oracle 0.4203 (0.3684) acc 65.6250 (64.4824) lr 1.9921e-03 eta 0:28:23
epoch [4/50] batch [340/445] time 0.066 (0.084) data 0.000 (0.002) loss 1.7607 (1.7094) teacher_loss 1.1465 (1.0296) loss_zs_kd 1.3548 (1.5669) loss_oracle 0.3982 (0.3683) acc 62.5000 (64.3934) lr 1.9921e-03 eta 0:28:44
epoch [4/50] batch [360/445] time 0.065 (0.084) data 0.000 (0.002) loss 1.8329 (1.7084) teacher_loss 1.1282 (1.0277) loss_zs_kd 1.9098 (1.5564) loss_oracle 0.3690 (0.3680) acc 53.1250 (64.3663) lr 1.9921e-03 eta 0:28:44
epoch [4/50] batch [380/445] time 0.068 (0.084) data 0.000 (0.002) loss 1.3845 (1.7026) teacher_loss 0.8527 (1.0243) loss_zs_kd 1.5130 (1.5451) loss_oracle 0.3422 (0.3674) acc 71.8750 (64.4408) lr 1.9921e-03 eta 0:28:48
epoch [4/50] batch [400/445] time 0.079 (0.084) data 0.000 (0.002) loss 1.4658 (1.7007) teacher_loss 0.8187 (1.0244) loss_zs_kd 1.6858 (1.5386) loss_oracle 0.3695 (0.3671) acc 71.8750 (64.4375) lr 1.9921e-03 eta 0:28:46
epoch [4/50] batch [420/445] time 0.072 (0.084) data 0.000 (0.001) loss 1.7236 (1.7002) teacher_loss 1.1150 (1.0240) loss_zs_kd 1.0230 (1.5310) loss_oracle 0.3510 (0.3664) acc 53.1250 (64.5164) lr 1.9921e-03 eta 0:28:35
epoch [4/50] batch [440/445] time 0.118 (0.084) data 0.000 (0.001) loss 1.9230 (1.6978) teacher_loss 1.2328 (1.0232) loss_zs_kd 0.9587 (1.5216) loss_oracle 0.3444 (0.3658) acc 62.5000 (64.4744) lr 1.9921e-03 eta 0:28:37
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,055
* accuracy: 66.4%
* error: 33.6%
* macro_f1: 51.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,824
* accuracy: 45.9%
* error: 54.1%
* macro_f1: 28.9%
******* Domain 3 best val acc:      66.4%, epoch: 4 *******
******* Domain 3 best val test acc: 45.9%, epoch: 4 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [5/50] batch [20/445] time 0.083 (0.114) data 0.000 (0.025) loss 1.4493 (1.6600) teacher_loss 0.7971 (1.0002) loss_zs_kd 1.8396 (1.4377) loss_oracle 0.3672 (0.3568) acc 71.8750 (65.6250) lr 1.9823e-03 eta 0:38:58
epoch [5/50] batch [40/445] time 0.084 (0.100) data 0.000 (0.013) loss 1.8422 (1.6608) teacher_loss 1.3206 (1.0265) loss_zs_kd 1.6485 (1.4780) loss_oracle 0.3381 (0.3526) acc 53.1250 (64.2969) lr 1.9823e-03 eta 0:33:59
epoch [5/50] batch [60/445] time 0.088 (0.095) data 0.000 (0.008) loss 1.9295 (1.6603) teacher_loss 1.3353 (1.0466) loss_zs_kd 1.6514 (1.4526) loss_oracle 0.3649 (0.3501) acc 50.0000 (63.2292) lr 1.9823e-03 eta 0:32:17
epoch [5/50] batch [80/445] time 0.085 (0.092) data 0.000 (0.006) loss 1.6508 (1.6504) teacher_loss 0.9666 (1.0430) loss_zs_kd 1.0485 (1.3995) loss_oracle 0.3646 (0.3499) acc 65.6250 (62.8125) lr 1.9823e-03 eta 0:31:21
epoch [5/50] batch [100/445] time 0.088 (0.091) data 0.000 (0.005) loss 2.0629 (1.6504) teacher_loss 1.3635 (1.0417) loss_zs_kd 1.2813 (1.3893) loss_oracle 0.3927 (0.3515) acc 59.3750 (62.7500) lr 1.9823e-03 eta 0:30:48
epoch [5/50] batch [120/445] time 0.085 (0.090) data 0.000 (0.004) loss 1.9523 (1.6521) teacher_loss 1.3405 (1.0378) loss_zs_kd 1.5648 (1.3840) loss_oracle 0.3626 (0.3509) acc 56.2500 (62.8906) lr 1.9823e-03 eta 0:30:28
epoch [5/50] batch [140/445] time 0.085 (0.089) data 0.000 (0.004) loss 1.7417 (1.6627) teacher_loss 1.0329 (1.0377) loss_zs_kd 1.4766 (1.3840) loss_oracle 0.3915 (0.3510) acc 59.3750 (63.0580) lr 1.9823e-03 eta 0:30:12
epoch [5/50] batch [160/445] time 0.087 (0.089) data 0.000 (0.003) loss 1.6266 (1.6706) teacher_loss 0.9608 (1.0403) loss_zs_kd 1.5080 (1.4146) loss_oracle 0.3915 (0.3495) acc 65.6250 (63.0469) lr 1.9823e-03 eta 0:29:59
epoch [5/50] batch [180/445] time 0.082 (0.088) data 0.000 (0.003) loss 1.4425 (1.6712) teacher_loss 0.8341 (1.0352) loss_zs_kd 1.6303 (1.4376) loss_oracle 0.3556 (0.3499) acc 65.6250 (63.1597) lr 1.9823e-03 eta 0:29:50
epoch [5/50] batch [200/445] time 0.096 (0.088) data 0.000 (0.003) loss 1.8634 (1.6833) teacher_loss 1.2272 (1.0446) loss_zs_kd 0.9671 (1.4274) loss_oracle 0.3334 (0.3498) acc 56.2500 (62.9219) lr 1.9823e-03 eta 0:29:41
epoch [5/50] batch [220/445] time 0.087 (0.088) data 0.000 (0.003) loss 1.5635 (1.6745) teacher_loss 0.9724 (1.0384) loss_zs_kd 1.1942 (1.4095) loss_oracle 0.3616 (0.3504) acc 71.8750 (63.1818) lr 1.9823e-03 eta 0:29:32
epoch [5/50] batch [240/445] time 0.088 (0.087) data 0.000 (0.002) loss 1.6628 (1.6736) teacher_loss 0.9909 (1.0360) loss_zs_kd 1.0628 (1.3915) loss_oracle 0.3849 (0.3508) acc 65.6250 (63.0859) lr 1.9823e-03 eta 0:29:26
epoch [5/50] batch [260/445] time 0.082 (0.087) data 0.000 (0.002) loss 1.6774 (1.6799) teacher_loss 1.0496 (1.0369) loss_zs_kd 1.1712 (1.3868) loss_oracle 0.3608 (0.3508) acc 68.7500 (63.2332) lr 1.9823e-03 eta 0:29:19
epoch [5/50] batch [280/445] time 0.073 (0.086) data 0.000 (0.002) loss 1.4535 (1.6759) teacher_loss 0.7098 (1.0313) loss_zs_kd 1.5680 (1.3963) loss_oracle 0.3606 (0.3504) acc 75.0000 (63.5826) lr 1.9823e-03 eta 0:29:00
epoch [5/50] batch [300/445] time 0.069 (0.087) data 0.000 (0.002) loss 1.7781 (1.6870) teacher_loss 0.9391 (1.0332) loss_zs_kd 1.2049 (1.4050) loss_oracle 0.4179 (0.3507) acc 71.8750 (63.5312) lr 1.9823e-03 eta 0:29:09
epoch [5/50] batch [320/445] time 0.064 (0.088) data 0.000 (0.002) loss 1.5765 (1.6925) teacher_loss 0.6784 (1.0290) loss_zs_kd 1.3443 (1.4072) loss_oracle 0.3592 (0.3506) acc 84.3750 (63.7012) lr 1.9823e-03 eta 0:29:26
epoch [5/50] batch [340/445] time 0.061 (0.089) data 0.000 (0.002) loss 1.7565 (1.7007) teacher_loss 1.1057 (1.0306) loss_zs_kd 1.4228 (1.4135) loss_oracle 0.3312 (0.3506) acc 65.6250 (63.6581) lr 1.9823e-03 eta 0:29:42
epoch [5/50] batch [360/445] time 0.070 (0.088) data 0.000 (0.002) loss 1.7357 (1.7002) teacher_loss 0.9119 (1.0258) loss_zs_kd 1.6244 (1.4317) loss_oracle 0.3212 (0.3509) acc 71.8750 (63.8976) lr 1.9823e-03 eta 0:29:29
epoch [5/50] batch [380/445] time 0.053 (0.087) data 0.000 (0.002) loss 1.7371 (1.6994) teacher_loss 1.0961 (1.0235) loss_zs_kd 1.8507 (1.4517) loss_oracle 0.3600 (0.3510) acc 62.5000 (64.0296) lr 1.9823e-03 eta 0:29:11
epoch [5/50] batch [400/445] time 0.075 (0.088) data 0.000 (0.002) loss 1.3906 (1.6947) teacher_loss 0.7985 (1.0225) loss_zs_kd 1.4914 (1.4555) loss_oracle 0.3305 (0.3506) acc 71.8750 (64.0469) lr 1.9823e-03 eta 0:29:18
epoch [5/50] batch [420/445] time 0.163 (0.088) data 0.000 (0.001) loss 1.3700 (1.6918) teacher_loss 0.7875 (1.0212) loss_zs_kd 1.5144 (1.4559) loss_oracle 0.3445 (0.3503) acc 75.0000 (64.1071) lr 1.9823e-03 eta 0:29:19
epoch [5/50] batch [440/445] time 0.062 (0.088) data 0.000 (0.001) loss 1.5460 (1.6846) teacher_loss 0.8611 (1.0166) loss_zs_kd 1.1400 (1.4472) loss_oracle 0.3862 (0.3503) acc 75.0000 (64.2401) lr 1.9823e-03 eta 0:29:22
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,108
* accuracy: 67.3%
* error: 32.7%
* macro_f1: 52.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,938
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 30.5%
******* Domain 3 best val acc:      67.3%, epoch: 5 *******
******* Domain 3 best val test acc: 48.8%, epoch: 5 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [6/50] batch [20/445] time 0.072 (0.094) data 0.000 (0.023) loss 1.4174 (1.6740) teacher_loss 0.8536 (1.0239) loss_zs_kd 1.2502 (1.3136) loss_oracle 0.3482 (0.3457) acc 65.6250 (62.9688) lr 1.9686e-03 eta 0:31:26
epoch [6/50] batch [40/445] time 0.078 (0.084) data 0.000 (0.012) loss 1.6232 (1.6617) teacher_loss 0.8962 (0.9912) loss_zs_kd 1.5928 (1.3805) loss_oracle 0.3576 (0.3453) acc 65.6250 (63.3594) lr 1.9686e-03 eta 0:27:55
epoch [6/50] batch [60/445] time 0.065 (0.079) data 0.000 (0.008) loss 1.6741 (1.6743) teacher_loss 1.0326 (1.0058) loss_zs_kd 1.6125 (1.4913) loss_oracle 0.3586 (0.3465) acc 65.6250 (63.3333) lr 1.9686e-03 eta 0:26:07
epoch [6/50] batch [80/445] time 0.082 (0.077) data 0.000 (0.006) loss 1.4593 (1.6723) teacher_loss 0.8367 (1.0101) loss_zs_kd 1.5222 (1.4864) loss_oracle 0.3836 (0.3471) acc 68.7500 (63.0078) lr 1.9686e-03 eta 0:25:40
epoch [6/50] batch [100/445] time 0.072 (0.075) data 0.000 (0.005) loss 1.7824 (1.6815) teacher_loss 1.0619 (1.0123) loss_zs_kd 1.3730 (1.4517) loss_oracle 0.3287 (0.3483) acc 65.6250 (62.9375) lr 1.9686e-03 eta 0:25:01
epoch [6/50] batch [120/445] time 0.084 (0.076) data 0.000 (0.004) loss 1.6345 (1.6916) teacher_loss 0.9945 (1.0169) loss_zs_kd 1.3974 (1.4571) loss_oracle 0.3273 (0.3473) acc 68.7500 (62.8906) lr 1.9686e-03 eta 0:25:20
epoch [6/50] batch [140/445] time 0.089 (0.078) data 0.000 (0.004) loss 1.8541 (1.6955) teacher_loss 1.2296 (1.0200) loss_zs_kd 1.5297 (1.4609) loss_oracle 0.3197 (0.3464) acc 56.2500 (62.9464) lr 1.9686e-03 eta 0:25:44
epoch [6/50] batch [160/445] time 0.090 (0.079) data 0.000 (0.003) loss 1.6979 (1.6898) teacher_loss 0.9704 (1.0139) loss_zs_kd 1.2768 (1.4560) loss_oracle 0.3550 (0.3472) acc 65.6250 (62.8516) lr 1.9686e-03 eta 0:26:00
epoch [6/50] batch [180/445] time 0.077 (0.079) data 0.000 (0.003) loss 1.7257 (1.7041) teacher_loss 0.8606 (1.0120) loss_zs_kd 1.4028 (1.4631) loss_oracle 0.4159 (0.3482) acc 71.8750 (63.0208) lr 1.9686e-03 eta 0:26:10
epoch [6/50] batch [200/445] time 0.077 (0.078) data 0.000 (0.003) loss 1.4428 (1.7087) teacher_loss 0.8306 (1.0124) loss_zs_kd 1.2222 (1.4601) loss_oracle 0.3409 (0.3479) acc 71.8750 (63.2500) lr 1.9686e-03 eta 0:25:51
epoch [6/50] batch [220/445] time 0.066 (0.079) data 0.000 (0.002) loss 1.7465 (1.7093) teacher_loss 0.9725 (1.0130) loss_zs_kd 1.1873 (1.4458) loss_oracle 0.3854 (0.3482) acc 71.8750 (63.2102) lr 1.9686e-03 eta 0:26:07
epoch [6/50] batch [240/445] time 0.069 (0.080) data 0.000 (0.002) loss 1.3724 (1.7055) teacher_loss 0.6884 (1.0101) loss_zs_kd 1.5463 (1.4345) loss_oracle 0.3564 (0.3480) acc 78.1250 (63.4115) lr 1.9686e-03 eta 0:26:16
epoch [6/50] batch [260/445] time 0.069 (0.080) data 0.000 (0.002) loss 1.8980 (1.7077) teacher_loss 1.0926 (1.0098) loss_zs_kd 1.8660 (1.4458) loss_oracle 0.3645 (0.3479) acc 56.2500 (63.7019) lr 1.9686e-03 eta 0:26:24
epoch [6/50] batch [280/445] time 0.157 (0.082) data 0.000 (0.002) loss 1.7146 (1.7062) teacher_loss 0.9591 (1.0047) loss_zs_kd 1.5658 (1.4469) loss_oracle 0.3173 (0.3482) acc 68.7500 (63.9397) lr 1.9686e-03 eta 0:26:56
epoch [6/50] batch [300/445] time 0.074 (0.081) data 0.000 (0.002) loss 1.5252 (1.7053) teacher_loss 0.7778 (1.0003) loss_zs_kd 1.6271 (1.4463) loss_oracle 0.3261 (0.3483) acc 62.5000 (64.2188) lr 1.9686e-03 eta 0:26:43
epoch [6/50] batch [320/445] time 0.067 (0.082) data 0.000 (0.002) loss 1.7980 (1.7060) teacher_loss 1.1103 (0.9969) loss_zs_kd 2.2077 (1.4629) loss_oracle 0.3271 (0.3483) acc 62.5000 (64.4043) lr 1.9686e-03 eta 0:26:46
epoch [6/50] batch [340/445] time 0.065 (0.083) data 0.000 (0.002) loss 1.7273 (1.7077) teacher_loss 1.1082 (1.0001) loss_zs_kd 1.6222 (1.4706) loss_oracle 0.3269 (0.3481) acc 62.5000 (64.3750) lr 1.9686e-03 eta 0:27:10
epoch [6/50] batch [360/445] time 0.069 (0.083) data 0.000 (0.002) loss 1.7517 (1.7069) teacher_loss 1.1130 (1.0010) loss_zs_kd 1.7731 (1.4774) loss_oracle 0.3532 (0.3476) acc 46.8750 (64.4358) lr 1.9686e-03 eta 0:27:18
epoch [6/50] batch [380/445] time 0.063 (0.084) data 0.000 (0.001) loss 1.8512 (1.7038) teacher_loss 1.1484 (0.9996) loss_zs_kd 1.4600 (1.4922) loss_oracle 0.3266 (0.3474) acc 65.6250 (64.5148) lr 1.9686e-03 eta 0:27:27
epoch [6/50] batch [400/445] time 0.068 (0.084) data 0.000 (0.001) loss 1.4820 (1.6997) teacher_loss 0.8372 (0.9958) loss_zs_kd 1.8796 (1.5126) loss_oracle 0.3174 (0.3470) acc 68.7500 (64.7812) lr 1.9686e-03 eta 0:27:37
epoch [6/50] batch [420/445] time 0.066 (0.085) data 0.000 (0.001) loss 1.7884 (1.7019) teacher_loss 1.0953 (0.9954) loss_zs_kd 1.6380 (1.5330) loss_oracle 0.3264 (0.3467) acc 68.7500 (64.9033) lr 1.9686e-03 eta 0:27:41
epoch [6/50] batch [440/445] time 0.155 (0.085) data 0.000 (0.001) loss 1.4549 (1.6986) teacher_loss 0.8125 (0.9953) loss_zs_kd 1.7486 (1.5452) loss_oracle 0.3258 (0.3462) acc 65.6250 (64.9077) lr 1.9686e-03 eta 0:27:51
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 3,996
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 50.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,948
* accuracy: 49.1%
* error: 50.9%
* macro_f1: 29.3%
******* Domain 3 best val acc:      67.3%, epoch: 5 *******
******* Domain 3 best val test acc: 48.8%, epoch: 5 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [7/50] batch [20/445] time 0.087 (0.111) data 0.000 (0.024) loss 1.6197 (1.6144) teacher_loss 0.9128 (0.9668) loss_zs_kd 1.6547 (1.8611) loss_oracle 0.3846 (0.3417) acc 68.7500 (67.9688) lr 1.9511e-03 eta 0:36:13
epoch [7/50] batch [40/445] time 0.087 (0.098) data 0.000 (0.012) loss 1.6673 (1.5955) teacher_loss 0.9043 (0.9346) loss_zs_kd 2.1090 (1.8050) loss_oracle 0.3259 (0.3348) acc 75.0000 (68.9062) lr 1.9511e-03 eta 0:31:59
epoch [7/50] batch [60/445] time 0.087 (0.094) data 0.000 (0.008) loss 1.5226 (1.6075) teacher_loss 0.8701 (0.9361) loss_zs_kd 1.9346 (1.7836) loss_oracle 0.3152 (0.3353) acc 68.7500 (68.5417) lr 1.9511e-03 eta 0:30:40
epoch [7/50] batch [80/445] time 0.091 (0.092) data 0.000 (0.006) loss 1.7365 (1.6237) teacher_loss 0.8787 (0.9395) loss_zs_kd 1.8876 (1.8166) loss_oracle 0.3251 (0.3350) acc 59.3750 (67.9688) lr 1.9511e-03 eta 0:29:56
epoch [7/50] batch [100/445] time 0.085 (0.091) data 0.000 (0.005) loss 1.8846 (1.6639) teacher_loss 1.1423 (0.9512) loss_zs_kd 1.6610 (1.8313) loss_oracle 0.3261 (0.3371) acc 62.5000 (67.8125) lr 1.9511e-03 eta 0:29:24
epoch [7/50] batch [120/445] time 0.095 (0.091) data 0.000 (0.004) loss 1.5489 (1.6730) teacher_loss 0.7352 (0.9426) loss_zs_kd 1.7572 (1.8204) loss_oracle 0.3514 (0.3382) acc 65.6250 (67.7865) lr 1.9511e-03 eta 0:29:23
epoch [7/50] batch [140/445] time 0.076 (0.088) data 0.000 (0.004) loss 1.5650 (1.6874) teacher_loss 0.7749 (0.9457) loss_zs_kd 1.3730 (1.8081) loss_oracle 0.3548 (0.3405) acc 78.1250 (67.9241) lr 1.9511e-03 eta 0:28:38
epoch [7/50] batch [160/445] time 0.153 (0.089) data 0.000 (0.003) loss 1.9323 (1.7056) teacher_loss 1.1566 (0.9526) loss_zs_kd 1.6316 (1.7561) loss_oracle 0.3535 (0.3428) acc 62.5000 (67.6562) lr 1.9511e-03 eta 0:28:51
epoch [7/50] batch [180/445] time 0.067 (0.089) data 0.000 (0.003) loss 2.7940 (1.7217) teacher_loss 1.9573 (0.9652) loss_zs_kd 1.4121 (1.7302) loss_oracle 0.3253 (0.3449) acc 40.6250 (67.0312) lr 1.9511e-03 eta 0:28:41
epoch [7/50] batch [200/445] time 0.154 (0.090) data 0.000 (0.003) loss 1.5081 (1.7159) teacher_loss 0.9323 (0.9672) loss_zs_kd 1.5048 (1.7060) loss_oracle 0.3424 (0.3438) acc 75.0000 (66.7656) lr 1.9511e-03 eta 0:28:55
epoch [7/50] batch [220/445] time 0.062 (0.089) data 0.000 (0.002) loss 1.4221 (1.7048) teacher_loss 0.8242 (0.9659) loss_zs_kd 1.4679 (1.6893) loss_oracle 0.3252 (0.3433) acc 75.0000 (66.6619) lr 1.9511e-03 eta 0:28:42
epoch [7/50] batch [240/445] time 0.067 (0.086) data 0.000 (0.002) loss 1.1732 (1.6920) teacher_loss 0.5412 (0.9602) loss_zs_kd 1.7254 (1.6693) loss_oracle 0.3249 (0.3441) acc 81.2500 (67.0052) lr 1.9511e-03 eta 0:27:51
epoch [7/50] batch [260/445] time 0.115 (0.086) data 0.000 (0.002) loss 1.4417 (1.6853) teacher_loss 0.7693 (0.9622) loss_zs_kd 1.6079 (1.6592) loss_oracle 0.3544 (0.3444) acc 75.0000 (66.8990) lr 1.9511e-03 eta 0:27:40
epoch [7/50] batch [280/445] time 0.069 (0.086) data 0.000 (0.002) loss 1.5772 (1.6819) teacher_loss 0.9138 (0.9623) loss_zs_kd 1.5677 (1.6491) loss_oracle 0.3541 (0.3454) acc 59.3750 (66.7411) lr 1.9511e-03 eta 0:27:41
epoch [7/50] batch [300/445] time 0.160 (0.087) data 0.000 (0.002) loss 1.5550 (1.6818) teacher_loss 0.9579 (0.9657) loss_zs_kd 1.9257 (1.6473) loss_oracle 0.3242 (0.3458) acc 75.0000 (66.6042) lr 1.9511e-03 eta 0:27:54
epoch [7/50] batch [320/445] time 0.065 (0.087) data 0.000 (0.002) loss 1.9590 (1.6808) teacher_loss 1.2391 (0.9647) loss_zs_kd 1.5732 (1.6467) loss_oracle 0.3540 (0.3467) acc 75.0000 (66.6797) lr 1.9511e-03 eta 0:27:51
epoch [7/50] batch [340/445] time 0.066 (0.088) data 0.000 (0.002) loss 1.4768 (1.6774) teacher_loss 0.7431 (0.9605) loss_zs_kd 1.5850 (1.6450) loss_oracle 0.3476 (0.3463) acc 75.0000 (66.8199) lr 1.9511e-03 eta 0:28:04
epoch [7/50] batch [360/445] time 0.085 (0.087) data 0.000 (0.002) loss 1.6944 (1.6834) teacher_loss 0.9107 (0.9632) loss_zs_kd 1.6159 (1.6422) loss_oracle 0.3898 (0.3472) acc 65.6250 (66.7708) lr 1.9511e-03 eta 0:28:00
epoch [7/50] batch [380/445] time 0.064 (0.088) data 0.000 (0.002) loss 1.6279 (1.6825) teacher_loss 0.9589 (0.9623) loss_zs_kd 1.7392 (1.6393) loss_oracle 0.3208 (0.3477) acc 68.7500 (66.7763) lr 1.9511e-03 eta 0:28:12
epoch [7/50] batch [400/445] time 0.162 (0.089) data 0.000 (0.001) loss 1.9848 (1.6850) teacher_loss 1.1275 (0.9649) loss_zs_kd 1.7853 (1.6378) loss_oracle 0.4037 (0.3483) acc 65.6250 (66.6250) lr 1.9511e-03 eta 0:28:24
epoch [7/50] batch [420/445] time 0.087 (0.088) data 0.000 (0.001) loss 1.8659 (1.6900) teacher_loss 1.0372 (0.9665) loss_zs_kd 1.3388 (1.6271) loss_oracle 0.3239 (0.3483) acc 56.2500 (66.5774) lr 1.9511e-03 eta 0:27:59
epoch [7/50] batch [440/445] time 0.083 (0.088) data 0.000 (0.001) loss 2.1023 (1.6915) teacher_loss 1.3251 (0.9654) loss_zs_kd 1.7572 (1.6207) loss_oracle 0.3129 (0.3483) acc 59.3750 (66.6548) lr 1.9511e-03 eta 0:27:55
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,101
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 53.2%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,766
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 29.1%
******* Domain 3 best val acc:      67.3%, epoch: 5 *******
******* Domain 3 best val test acc: 48.8%, epoch: 5 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [8/50] batch [20/445] time 0.073 (0.110) data 0.000 (0.024) loss 1.2735 (1.6643) teacher_loss 0.6695 (0.9421) loss_zs_kd 1.8276 (1.5737) loss_oracle 0.3161 (0.3383) acc 75.0000 (66.0938) lr 1.9298e-03 eta 0:35:07
epoch [8/50] batch [40/445] time 0.085 (0.097) data 0.000 (0.012) loss 1.4564 (1.6172) teacher_loss 0.7617 (0.9114) loss_zs_kd 1.7099 (1.6785) loss_oracle 0.3834 (0.3393) acc 65.6250 (67.1875) lr 1.9298e-03 eta 0:30:43
epoch [8/50] batch [60/445] time 0.086 (0.093) data 0.000 (0.008) loss 1.7307 (1.6244) teacher_loss 0.9424 (0.9060) loss_zs_kd 1.7128 (1.6912) loss_oracle 0.3533 (0.3374) acc 62.5000 (67.6042) lr 1.9298e-03 eta 0:29:30
epoch [8/50] batch [80/445] time 0.081 (0.090) data 0.000 (0.006) loss 1.6686 (1.6343) teacher_loss 0.8473 (0.9155) loss_zs_kd 1.7584 (1.6974) loss_oracle 0.3236 (0.3355) acc 75.0000 (67.4609) lr 1.9298e-03 eta 0:28:42
epoch [8/50] batch [100/445] time 0.066 (0.087) data 0.000 (0.005) loss 1.7413 (1.6357) teacher_loss 0.9418 (0.9198) loss_zs_kd 1.8227 (1.7163) loss_oracle 0.3760 (0.3361) acc 59.3750 (67.7188) lr 1.9298e-03 eta 0:27:33
epoch [8/50] batch [120/445] time 0.068 (0.087) data 0.000 (0.004) loss 1.7240 (1.6431) teacher_loss 0.8966 (0.9215) loss_zs_kd 1.6484 (1.7239) loss_oracle 0.3236 (0.3361) acc 65.6250 (67.7865) lr 1.9298e-03 eta 0:27:28
epoch [8/50] batch [140/445] time 0.146 (0.088) data 0.000 (0.004) loss 1.3692 (1.6344) teacher_loss 0.6333 (0.9138) loss_zs_kd 1.7867 (1.7321) loss_oracle 0.3233 (0.3350) acc 75.0000 (68.4375) lr 1.9298e-03 eta 0:27:53
epoch [8/50] batch [160/445] time 0.060 (0.088) data 0.000 (0.003) loss 1.9067 (1.6322) teacher_loss 1.0706 (0.9055) loss_zs_kd 1.7452 (1.7351) loss_oracle 0.3809 (0.3368) acc 59.3750 (69.1016) lr 1.9298e-03 eta 0:27:51
epoch [8/50] batch [180/445] time 0.063 (0.088) data 0.000 (0.003) loss 1.9825 (1.6482) teacher_loss 1.1718 (0.9090) loss_zs_kd 2.1609 (1.7413) loss_oracle 0.3215 (0.3381) acc 59.3750 (68.8194) lr 1.9298e-03 eta 0:27:45
epoch [8/50] batch [200/445] time 0.081 (0.086) data 0.000 (0.003) loss 1.4061 (1.6506) teacher_loss 0.8920 (0.9172) loss_zs_kd 1.2442 (1.7253) loss_oracle 0.3531 (0.3382) acc 59.3750 (68.4844) lr 1.9298e-03 eta 0:27:11
epoch [8/50] batch [220/445] time 0.068 (0.086) data 0.000 (0.002) loss 1.8813 (1.6510) teacher_loss 1.2271 (0.9241) loss_zs_kd 1.4403 (1.7082) loss_oracle 0.3227 (0.3394) acc 56.2500 (68.0966) lr 1.9298e-03 eta 0:27:09
epoch [8/50] batch [240/445] time 0.133 (0.087) data 0.001 (0.002) loss 1.6112 (1.6532) teacher_loss 1.0043 (0.9290) loss_zs_kd 1.5542 (1.6895) loss_oracle 0.3480 (0.3394) acc 56.2500 (67.8125) lr 1.9298e-03 eta 0:27:21
epoch [8/50] batch [260/445] time 0.069 (0.088) data 0.000 (0.002) loss 1.6403 (1.6613) teacher_loss 0.9468 (0.9366) loss_zs_kd 1.4025 (1.6789) loss_oracle 0.3740 (0.3398) acc 71.8750 (67.5962) lr 1.9298e-03 eta 0:27:40
epoch [8/50] batch [280/445] time 0.068 (0.089) data 0.000 (0.002) loss 2.0784 (1.6699) teacher_loss 1.3647 (0.9428) loss_zs_kd 1.4285 (1.6677) loss_oracle 0.3229 (0.3401) acc 53.1250 (67.3661) lr 1.9298e-03 eta 0:27:55
epoch [8/50] batch [300/445] time 0.067 (0.089) data 0.000 (0.002) loss 1.5366 (1.6690) teacher_loss 0.9035 (0.9413) loss_zs_kd 1.3699 (1.6560) loss_oracle 0.3608 (0.3404) acc 71.8750 (67.3646) lr 1.9298e-03 eta 0:27:49
epoch [8/50] batch [320/445] time 0.189 (0.089) data 0.000 (0.002) loss 1.5569 (1.6692) teacher_loss 0.9548 (0.9442) loss_zs_kd 1.4132 (1.6473) loss_oracle 0.3226 (0.3410) acc 62.5000 (67.2852) lr 1.9298e-03 eta 0:27:48
epoch [8/50] batch [340/445] time 0.061 (0.089) data 0.000 (0.002) loss 1.6658 (1.6700) teacher_loss 0.8443 (0.9477) loss_zs_kd 1.8571 (1.6391) loss_oracle 0.3225 (0.3412) acc 62.5000 (67.0956) lr 1.9298e-03 eta 0:27:50
epoch [8/50] batch [360/445] time 0.059 (0.089) data 0.000 (0.002) loss 1.6654 (1.6735) teacher_loss 0.8405 (0.9503) loss_zs_kd 1.4251 (1.6383) loss_oracle 0.3528 (0.3422) acc 71.8750 (67.0312) lr 1.9298e-03 eta 0:27:59
epoch [8/50] batch [380/445] time 0.090 (0.089) data 0.000 (0.002) loss 1.4972 (1.6740) teacher_loss 0.7528 (0.9517) loss_zs_kd 1.5827 (1.6267) loss_oracle 0.3827 (0.3427) acc 75.0000 (66.9984) lr 1.9298e-03 eta 0:27:43
epoch [8/50] batch [400/445] time 0.078 (0.089) data 0.000 (0.001) loss 1.6478 (1.6705) teacher_loss 1.0401 (0.9506) loss_zs_kd 1.3230 (1.6210) loss_oracle 0.3525 (0.3422) acc 62.5000 (66.9531) lr 1.9298e-03 eta 0:27:38
epoch [8/50] batch [420/445] time 0.084 (0.088) data 0.000 (0.001) loss 1.3689 (1.6708) teacher_loss 0.7890 (0.9524) loss_zs_kd 2.0829 (1.6204) loss_oracle 0.3527 (0.3419) acc 68.7500 (66.8378) lr 1.9298e-03 eta 0:27:26
epoch [8/50] batch [440/445] time 0.085 (0.088) data 0.000 (0.001) loss 1.7584 (1.6718) teacher_loss 1.0539 (0.9568) loss_zs_kd 1.6231 (1.6170) loss_oracle 0.3822 (0.3417) acc 65.6250 (66.7259) lr 1.9298e-03 eta 0:27:22
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,099
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 51.4%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,908
* accuracy: 48.1%
* error: 51.9%
* macro_f1: 28.7%
******* Domain 3 best val acc:      67.3%, epoch: 5 *******
******* Domain 3 best val test acc: 48.8%, epoch: 5 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [9/50] batch [20/445] time 0.087 (0.113) data 0.000 (0.024) loss 1.9877 (1.6569) teacher_loss 1.2989 (1.0414) loss_zs_kd 1.7227 (1.5298) loss_oracle 0.3218 (0.3357) acc 59.3750 (62.0312) lr 1.9048e-03 eta 0:35:02
epoch [9/50] batch [40/445] time 0.083 (0.099) data 0.000 (0.012) loss 1.4612 (1.6498) teacher_loss 0.7779 (1.0096) loss_zs_kd 1.2672 (1.4846) loss_oracle 0.3481 (0.3422) acc 75.0000 (64.2969) lr 1.9048e-03 eta 0:30:41
epoch [9/50] batch [60/445] time 0.065 (0.091) data 0.000 (0.008) loss 1.4653 (1.6168) teacher_loss 0.9037 (0.9831) loss_zs_kd 1.5244 (1.4342) loss_oracle 0.3498 (0.3416) acc 68.7500 (64.6875) lr 1.9048e-03 eta 0:28:07
epoch [9/50] batch [80/445] time 0.155 (0.088) data 0.000 (0.006) loss 1.8227 (1.6387) teacher_loss 1.2463 (1.0058) loss_zs_kd 1.4446 (1.4305) loss_oracle 0.3520 (0.3424) acc 53.1250 (64.1797) lr 1.9048e-03 eta 0:27:18
epoch [9/50] batch [100/445] time 0.066 (0.090) data 0.000 (0.005) loss 1.8588 (1.6311) teacher_loss 1.2094 (1.0003) loss_zs_kd 1.3108 (1.4291) loss_oracle 0.3507 (0.3421) acc 53.1250 (64.0312) lr 1.9048e-03 eta 0:27:45
epoch [9/50] batch [120/445] time 0.130 (0.091) data 0.000 (0.004) loss 1.6038 (1.6247) teacher_loss 0.9603 (0.9929) loss_zs_kd 1.3226 (1.4312) loss_oracle 0.3158 (0.3419) acc 62.5000 (64.4010) lr 1.9048e-03 eta 0:28:01
epoch [9/50] batch [140/445] time 0.062 (0.090) data 0.000 (0.004) loss 1.3817 (1.6150) teacher_loss 0.6906 (0.9794) loss_zs_kd 1.6047 (1.4508) loss_oracle 0.3167 (0.3412) acc 75.0000 (64.9107) lr 1.9048e-03 eta 0:27:58
epoch [9/50] batch [160/445] time 0.066 (0.088) data 0.000 (0.003) loss 1.5460 (1.6112) teacher_loss 0.7834 (0.9735) loss_zs_kd 1.3974 (1.4650) loss_oracle 0.3367 (0.3414) acc 71.8750 (65.3125) lr 1.9048e-03 eta 0:27:09
epoch [9/50] batch [180/445] time 0.065 (0.088) data 0.000 (0.003) loss 1.5592 (1.6075) teacher_loss 0.9090 (0.9676) loss_zs_kd 1.6579 (1.4709) loss_oracle 0.3212 (0.3414) acc 65.6250 (65.4861) lr 1.9048e-03 eta 0:27:02
epoch [9/50] batch [200/445] time 0.160 (0.089) data 0.000 (0.003) loss 1.3189 (1.6101) teacher_loss 0.7232 (0.9671) loss_zs_kd 1.5414 (1.4850) loss_oracle 0.3214 (0.3409) acc 84.3750 (65.4844) lr 1.9048e-03 eta 0:27:27
epoch [9/50] batch [220/445] time 0.161 (0.089) data 0.000 (0.002) loss 1.7738 (1.6160) teacher_loss 1.0104 (0.9687) loss_zs_kd 1.4808 (1.4875) loss_oracle 0.3210 (0.3411) acc 65.6250 (65.5256) lr 1.9048e-03 eta 0:27:27
epoch [9/50] batch [240/445] time 0.067 (0.090) data 0.000 (0.002) loss 1.8195 (1.6210) teacher_loss 1.1578 (0.9719) loss_zs_kd 1.4569 (1.4871) loss_oracle 0.3807 (0.3413) acc 59.3750 (65.5339) lr 1.9048e-03 eta 0:27:34
epoch [9/50] batch [260/445] time 0.079 (0.090) data 0.000 (0.002) loss 1.9287 (1.6156) teacher_loss 1.3408 (0.9715) loss_zs_kd 1.8347 (1.5018) loss_oracle 0.3209 (0.3405) acc 46.8750 (65.5769) lr 1.9048e-03 eta 0:27:47
epoch [9/50] batch [280/445] time 0.071 (0.090) data 0.000 (0.002) loss 1.5577 (1.6145) teacher_loss 0.9433 (0.9718) loss_zs_kd 1.7544 (1.5081) loss_oracle 0.3193 (0.3412) acc 65.6250 (65.5580) lr 1.9048e-03 eta 0:27:38
epoch [9/50] batch [300/445] time 0.071 (0.091) data 0.000 (0.002) loss 1.3417 (1.6133) teacher_loss 0.8022 (0.9708) loss_zs_kd 1.1876 (1.5184) loss_oracle 0.3207 (0.3423) acc 71.8750 (65.6354) lr 1.9048e-03 eta 0:27:49
epoch [9/50] batch [320/445] time 0.056 (0.090) data 0.000 (0.002) loss 1.6707 (1.6130) teacher_loss 1.0714 (0.9743) loss_zs_kd 1.7399 (1.5317) loss_oracle 0.3508 (0.3424) acc 59.3750 (65.5078) lr 1.9048e-03 eta 0:27:42
epoch [9/50] batch [340/445] time 0.086 (0.090) data 0.000 (0.002) loss 1.5430 (1.6055) teacher_loss 0.9281 (0.9678) loss_zs_kd 1.4704 (1.5306) loss_oracle 0.3575 (0.3429) acc 71.8750 (65.7721) lr 1.9048e-03 eta 0:27:29
epoch [9/50] batch [360/445] time 0.096 (0.090) data 0.001 (0.002) loss 1.5749 (1.6031) teacher_loss 0.9734 (0.9684) loss_zs_kd 1.6640 (1.5377) loss_oracle 0.3509 (0.3428) acc 68.7500 (65.7205) lr 1.9048e-03 eta 0:27:28
epoch [9/50] batch [380/445] time 0.082 (0.090) data 0.000 (0.002) loss 1.4919 (1.6004) teacher_loss 0.9847 (0.9686) loss_zs_kd 1.5394 (1.5406) loss_oracle 0.3508 (0.3425) acc 65.6250 (65.7484) lr 1.9048e-03 eta 0:27:24
epoch [9/50] batch [400/445] time 0.079 (0.089) data 0.000 (0.001) loss 1.4862 (1.5967) teacher_loss 0.8851 (0.9672) loss_zs_kd 1.7510 (1.5429) loss_oracle 0.2943 (0.3423) acc 68.7500 (65.7422) lr 1.9048e-03 eta 0:27:15
epoch [9/50] batch [420/445] time 0.082 (0.089) data 0.000 (0.001) loss 1.4650 (1.5884) teacher_loss 0.9040 (0.9607) loss_zs_kd 2.1324 (1.5561) loss_oracle 0.3203 (0.3418) acc 62.5000 (65.9375) lr 1.9048e-03 eta 0:27:09
epoch [9/50] batch [440/445] time 0.083 (0.089) data 0.000 (0.001) loss 1.6075 (1.5876) teacher_loss 0.9775 (0.9622) loss_zs_kd 1.7794 (1.5659) loss_oracle 0.3505 (0.3414) acc 62.5000 (65.9304) lr 1.9048e-03 eta 0:27:03
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,077
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 52.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,969
* accuracy: 49.6%
* error: 50.4%
* macro_f1: 27.5%
******* Domain 3 best val acc:      67.3%, epoch: 5 *******
******* Domain 3 best val test acc: 48.8%, epoch: 5 *******
******* Domain 3 best test acc:     50.7%, epoch: 3 *******
epoch [10/50] batch [20/445] time 0.155 (0.111) data 0.000 (0.023) loss 1.3065 (1.5753) teacher_loss 0.7482 (1.0063) loss_zs_kd 1.6443 (1.7029) loss_oracle 0.3200 (0.3217) acc 78.1250 (64.2188) lr 1.8763e-03 eta 0:33:42
epoch [10/50] batch [40/445] time 0.063 (0.098) data 0.000 (0.012) loss 1.4475 (1.5480) teacher_loss 0.9078 (0.9743) loss_zs_kd 1.6044 (1.5775) loss_oracle 0.3504 (0.3278) acc 59.3750 (65.0000) lr 1.8763e-03 eta 0:29:42
epoch [10/50] batch [60/445] time 0.082 (0.099) data 0.000 (0.008) loss 1.5429 (1.5426) teacher_loss 0.9793 (0.9612) loss_zs_kd 1.0552 (1.5437) loss_oracle 0.3503 (0.3304) acc 62.5000 (65.7812) lr 1.8763e-03 eta 0:29:59
epoch [10/50] batch [80/445] time 0.066 (0.095) data 0.000 (0.006) loss 2.1301 (1.5709) teacher_loss 1.4134 (0.9812) loss_zs_kd 1.3004 (1.5410) loss_oracle 0.3414 (0.3299) acc 56.2500 (65.5859) lr 1.8763e-03 eta 0:28:42
epoch [10/50] batch [100/445] time 0.063 (0.094) data 0.000 (0.005) loss 1.3894 (1.5651) teacher_loss 0.6895 (0.9712) loss_zs_kd 1.8374 (1.5319) loss_oracle 0.3199 (0.3296) acc 78.1250 (66.4062) lr 1.8763e-03 eta 0:28:21
epoch [10/50] batch [120/445] time 0.064 (0.095) data 0.000 (0.004) loss 1.7579 (1.5782) teacher_loss 1.1560 (0.9803) loss_zs_kd 1.9658 (1.5510) loss_oracle 0.3197 (0.3305) acc 56.2500 (66.0677) lr 1.8763e-03 eta 0:28:46
epoch [10/50] batch [140/445] time 0.068 (0.095) data 0.000 (0.004) loss 1.4604 (1.5695) teacher_loss 0.8562 (0.9706) loss_zs_kd 1.6221 (1.5412) loss_oracle 0.3491 (0.3314) acc 71.8750 (66.2723) lr 1.8763e-03 eta 0:28:31
epoch [10/50] batch [160/445] time 0.154 (0.095) data 0.000 (0.003) loss 1.2726 (1.5706) teacher_loss 0.6972 (0.9672) loss_zs_kd 1.5834 (1.5513) loss_oracle 0.3498 (0.3333) acc 78.1250 (66.3281) lr 1.8763e-03 eta 0:28:37
epoch [10/50] batch [180/445] time 0.123 (0.095) data 0.000 (0.003) loss 1.8430 (1.5648) teacher_loss 0.9277 (0.9588) loss_zs_kd 1.4011 (1.5478) loss_oracle 0.3455 (0.3330) acc 75.0000 (66.6493) lr 1.8763e-03 eta 0:28:31
epoch [10/50] batch [200/445] time 0.061 (0.094) data 0.000 (0.003) loss 2.0098 (1.5720) teacher_loss 1.3885 (0.9643) loss_zs_kd 1.6495 (1.5513) loss_oracle 0.3176 (0.3324) acc 53.1250 (66.4375) lr 1.8763e-03 eta 0:28:22
epoch [10/50] batch [220/445] time 0.117 (0.093) data 0.000 (0.002) loss 1.5906 (1.5781) teacher_loss 0.9564 (0.9672) loss_zs_kd 1.5671 (1.5511) loss_oracle 0.3417 (0.3328) acc 71.8750 (66.2216) lr 1.8763e-03 eta 0:28:03
epoch [10/50] batch [240/445] time 0.066 (0.093) data 0.000 (0.002) loss 1.6224 (1.5789) teacher_loss 0.9488 (0.9674) loss_zs_kd 1.6382 (1.5600) loss_oracle 0.3194 (0.3326) acc 56.2500 (66.1719) lr 1.8763e-03 eta 0:27:58
epoch [10/50] batch [260/445] time 0.081 (0.092) data 0.000 (0.002) loss 1.9395 (1.5813) teacher_loss 1.2690 (0.9732) loss_zs_kd 1.4786 (1.5570) loss_oracle 0.3437 (0.3331) acc 56.2500 (65.9135) lr 1.8763e-03 eta 0:27:40
epoch [10/50] batch [280/445] time 0.086 (0.092) data 0.000 (0.002) loss 1.5242 (1.5826) teacher_loss 0.9284 (0.9738) loss_zs_kd 1.5083 (1.5545) loss_oracle 0.3172 (0.3337) acc 68.7500 (65.7478) lr 1.8763e-03 eta 0:27:28
epoch [10/50] batch [300/445] time 0.085 (0.091) data 0.000 (0.002) loss 1.3782 (1.5795) teacher_loss 0.7388 (0.9727) loss_zs_kd 1.2143 (1.5548) loss_oracle 0.3388 (0.3334) acc 75.0000 (65.7083) lr 1.8763e-03 eta 0:27:18
epoch [10/50] batch [320/445] time 0.088 (0.091) data 0.000 (0.002) loss 1.3396 (1.5741) teacher_loss 0.7735 (0.9687) loss_zs_kd 1.6098 (1.5513) loss_oracle 0.3463 (0.3334) acc 68.7500 (65.9473) lr 1.8763e-03 eta 0:27:09
epoch [10/50] batch [340/445] time 0.089 (0.091) data 0.000 (0.002) loss 1.5413 (1.5746) teacher_loss 0.9884 (0.9684) loss_zs_kd 1.2501 (1.5565) loss_oracle 0.3189 (0.3333) acc 59.3750 (65.9926) lr 1.8763e-03 eta 0:27:01
epoch [10/50] batch [360/445] time 0.084 (0.090) data 0.000 (0.002) loss 1.2523 (1.5822) teacher_loss 0.6136 (0.9722) loss_zs_kd 1.3766 (1.5595) loss_oracle 0.3118 (0.3331) acc 81.2500 (65.9201) lr 1.8763e-03 eta 0:26:52
epoch [10/50] batch [380/445] time 0.084 (0.090) data 0.000 (0.001) loss 1.3275 (1.5864) teacher_loss 0.6516 (0.9721) loss_zs_kd 1.3032 (1.5584) loss_oracle 0.3491 (0.3334) acc 78.1250 (65.8635) lr 1.8763e-03 eta 0:26:45
epoch [10/50] batch [400/445] time 0.084 (0.090) data 0.000 (0.001) loss 1.2768 (1.5886) teacher_loss 0.6859 (0.9704) loss_zs_kd 1.9989 (1.5696) loss_oracle 0.3492 (0.3338) acc 84.3750 (66.0234) lr 1.8763e-03 eta 0:26:38
epoch [10/50] batch [420/445] time 0.083 (0.089) data 0.000 (0.001) loss 1.5886 (1.5885) teacher_loss 0.8331 (0.9674) loss_zs_kd 1.9424 (1.5792) loss_oracle 0.3493 (0.3339) acc 78.1250 (66.0938) lr 1.8763e-03 eta 0:26:32
epoch [10/50] batch [440/445] time 0.083 (0.089) data 0.000 (0.001) loss 1.7028 (1.5915) teacher_loss 1.0561 (0.9680) loss_zs_kd 1.4952 (1.5864) loss_oracle 0.3188 (0.3342) acc 59.3750 (66.0938) lr 1.8763e-03 eta 0:26:26
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,227
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 55.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,029
* accuracy: 51.1%
* error: 48.9%
* macro_f1: 31.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      69.2%, epoch: 10 *******
******* Domain 3 best val test acc: 51.1%, epoch: 10 *******
******* Domain 3 best test acc:     51.1%, epoch: 10 *******
epoch [11/50] batch [20/445] time 0.130 (0.107) data 0.000 (0.023) loss 1.1059 (1.5871) teacher_loss 0.5868 (0.9167) loss_zs_kd 1.7443 (1.6905) loss_oracle 0.3187 (0.3354) acc 84.3750 (68.7500) lr 1.8443e-03 eta 0:31:46
epoch [11/50] batch [40/445] time 0.062 (0.098) data 0.000 (0.012) loss 1.3268 (1.6199) teacher_loss 0.6412 (0.9373) loss_zs_kd 1.8803 (1.6862) loss_oracle 0.3796 (0.3369) acc 71.8750 (67.1875) lr 1.8443e-03 eta 0:29:03
epoch [11/50] batch [60/445] time 0.044 (0.098) data 0.000 (0.008) loss 1.4477 (1.6415) teacher_loss 0.8124 (0.9519) loss_zs_kd 1.7439 (1.7249) loss_oracle 0.3145 (0.3347) acc 65.6250 (66.1979) lr 1.8443e-03 eta 0:28:53
epoch [11/50] batch [80/445] time 0.069 (0.095) data 0.000 (0.006) loss 1.6728 (1.6300) teacher_loss 0.9495 (0.9402) loss_zs_kd 1.6475 (1.7137) loss_oracle 0.3188 (0.3327) acc 65.6250 (66.5234) lr 1.8443e-03 eta 0:28:00
epoch [11/50] batch [100/445] time 0.152 (0.096) data 0.000 (0.005) loss 1.1893 (1.6098) teacher_loss 0.5871 (0.9379) loss_zs_kd 1.7506 (1.7337) loss_oracle 0.3173 (0.3319) acc 78.1250 (66.5625) lr 1.8443e-03 eta 0:28:15
epoch [11/50] batch [120/445] time 0.153 (0.094) data 0.000 (0.004) loss 1.1719 (1.5954) teacher_loss 0.6994 (0.9334) loss_zs_kd 1.5590 (1.7419) loss_oracle 0.3186 (0.3310) acc 78.1250 (66.7448) lr 1.8443e-03 eta 0:27:46
epoch [11/50] batch [140/445] time 0.156 (0.094) data 0.000 (0.004) loss 1.7036 (1.6015) teacher_loss 1.1751 (0.9468) loss_zs_kd 1.3942 (1.7407) loss_oracle 0.3187 (0.3316) acc 56.2500 (66.3616) lr 1.8443e-03 eta 0:27:36
epoch [11/50] batch [160/445] time 0.073 (0.093) data 0.000 (0.003) loss 1.2316 (1.5854) teacher_loss 0.7395 (0.9404) loss_zs_kd 1.7604 (1.7320) loss_oracle 0.3185 (0.3299) acc 68.7500 (66.5234) lr 1.8443e-03 eta 0:27:12
epoch [11/50] batch [180/445] time 0.096 (0.094) data 0.000 (0.003) loss 1.1678 (1.5747) teacher_loss 0.5554 (0.9377) loss_zs_kd 1.6341 (1.7356) loss_oracle 0.3794 (0.3302) acc 84.3750 (66.5451) lr 1.8443e-03 eta 0:27:37
epoch [11/50] batch [200/445] time 0.088 (0.094) data 0.000 (0.003) loss 1.6442 (1.5744) teacher_loss 1.0699 (0.9421) loss_zs_kd 1.4710 (1.7135) loss_oracle 0.3109 (0.3304) acc 59.3750 (66.5156) lr 1.8443e-03 eta 0:27:25
epoch [11/50] batch [220/445] time 0.079 (0.093) data 0.000 (0.002) loss 1.6583 (1.5757) teacher_loss 1.0156 (0.9431) loss_zs_kd 1.6306 (1.7035) loss_oracle 0.3046 (0.3305) acc 62.5000 (66.6761) lr 1.8443e-03 eta 0:27:09
epoch [11/50] batch [240/445] time 0.085 (0.092) data 0.000 (0.002) loss 2.0088 (1.5759) teacher_loss 1.3483 (0.9424) loss_zs_kd 1.7297 (1.6910) loss_oracle 0.3183 (0.3305) acc 56.2500 (66.7318) lr 1.8443e-03 eta 0:26:58
epoch [11/50] batch [260/445] time 0.076 (0.092) data 0.000 (0.002) loss 1.6902 (1.5801) teacher_loss 1.0076 (0.9456) loss_zs_kd 1.8005 (1.6861) loss_oracle 0.3489 (0.3301) acc 62.5000 (66.5264) lr 1.8443e-03 eta 0:26:46
epoch [11/50] batch [280/445] time 0.087 (0.091) data 0.000 (0.002) loss 1.2478 (1.5820) teacher_loss 0.6936 (0.9477) loss_zs_kd 1.6630 (1.6806) loss_oracle 0.3772 (0.3303) acc 78.1250 (66.4955) lr 1.8443e-03 eta 0:26:36
epoch [11/50] batch [300/445] time 0.092 (0.091) data 0.000 (0.002) loss 1.3500 (1.5780) teacher_loss 0.8154 (0.9446) loss_zs_kd 1.7347 (1.6766) loss_oracle 0.3169 (0.3309) acc 68.7500 (66.6250) lr 1.8443e-03 eta 0:26:28
epoch [11/50] batch [320/445] time 0.087 (0.091) data 0.000 (0.002) loss 1.6286 (1.5745) teacher_loss 1.0286 (0.9433) loss_zs_kd 1.4379 (1.6737) loss_oracle 0.3455 (0.3312) acc 68.7500 (66.5918) lr 1.8443e-03 eta 0:26:21
epoch [11/50] batch [340/445] time 0.085 (0.090) data 0.000 (0.002) loss 1.6156 (1.5738) teacher_loss 1.0474 (0.9454) loss_zs_kd 1.5994 (1.6734) loss_oracle 0.3179 (0.3313) acc 59.3750 (66.4706) lr 1.8443e-03 eta 0:26:15
epoch [11/50] batch [360/445] time 0.085 (0.090) data 0.000 (0.002) loss 1.2037 (1.5709) teacher_loss 0.7251 (0.9469) loss_zs_kd 1.4560 (1.6716) loss_oracle 0.3179 (0.3314) acc 78.1250 (66.4323) lr 1.8443e-03 eta 0:26:10
epoch [11/50] batch [380/445] time 0.085 (0.090) data 0.000 (0.001) loss 1.6821 (1.5735) teacher_loss 0.9977 (0.9521) loss_zs_kd 1.5245 (1.6683) loss_oracle 0.3162 (0.3318) acc 59.3750 (66.2336) lr 1.8443e-03 eta 0:26:05
epoch [11/50] batch [400/445] time 0.084 (0.090) data 0.000 (0.001) loss 1.1527 (1.5739) teacher_loss 0.6176 (0.9538) loss_zs_kd 1.4546 (1.6657) loss_oracle 0.3709 (0.3319) acc 75.0000 (66.1953) lr 1.8443e-03 eta 0:26:00
epoch [11/50] batch [420/445] time 0.085 (0.090) data 0.000 (0.001) loss 1.6159 (1.5736) teacher_loss 1.0316 (0.9544) loss_zs_kd 1.7091 (1.6635) loss_oracle 0.3084 (0.3323) acc 62.5000 (66.1607) lr 1.8443e-03 eta 0:25:55
epoch [11/50] batch [440/445] time 0.086 (0.089) data 0.000 (0.001) loss 1.6464 (1.5734) teacher_loss 1.0227 (0.9552) loss_zs_kd 1.6577 (1.6557) loss_oracle 0.3383 (0.3324) acc 59.3750 (66.2003) lr 1.8443e-03 eta 0:25:50
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,175
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 52.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,854
* accuracy: 46.7%
* error: 53.3%
* macro_f1: 29.9%
******* Domain 3 best val acc:      69.2%, epoch: 10 *******
******* Domain 3 best val test acc: 51.1%, epoch: 10 *******
******* Domain 3 best test acc:     51.1%, epoch: 10 *******
epoch [12/50] batch [20/445] time 0.132 (0.124) data 0.000 (0.024) loss 1.2409 (1.5713) teacher_loss 0.6846 (0.9517) loss_zs_kd 1.6820 (1.5291) loss_oracle 0.3126 (0.3360) acc 81.2500 (65.6250) lr 1.8090e-03 eta 0:35:43
epoch [12/50] batch [40/445] time 0.064 (0.102) data 0.000 (0.012) loss 1.8139 (1.6492) teacher_loss 1.1302 (1.0000) loss_zs_kd 1.5766 (1.5284) loss_oracle 0.3179 (0.3342) acc 53.1250 (65.0781) lr 1.8090e-03 eta 0:29:31
epoch [12/50] batch [60/445] time 0.063 (0.097) data 0.000 (0.008) loss 1.3915 (1.6481) teacher_loss 0.8031 (0.9944) loss_zs_kd 1.7546 (1.5332) loss_oracle 0.3381 (0.3362) acc 59.3750 (65.3125) lr 1.8090e-03 eta 0:28:01
epoch [12/50] batch [80/445] time 0.059 (0.098) data 0.000 (0.006) loss 1.6182 (1.6296) teacher_loss 0.9688 (0.9765) loss_zs_kd 1.5138 (1.5534) loss_oracle 0.3178 (0.3347) acc 62.5000 (66.0938) lr 1.8090e-03 eta 0:28:09
epoch [12/50] batch [100/445] time 0.067 (0.094) data 0.000 (0.005) loss 1.4477 (1.6197) teacher_loss 0.8479 (0.9706) loss_zs_kd 1.2811 (1.5365) loss_oracle 0.3150 (0.3332) acc 62.5000 (66.0625) lr 1.8090e-03 eta 0:27:09
epoch [12/50] batch [120/445] time 0.081 (0.092) data 0.000 (0.004) loss 1.4590 (1.6016) teacher_loss 0.8943 (0.9626) loss_zs_kd 2.1794 (1.5471) loss_oracle 0.3176 (0.3321) acc 62.5000 (66.2760) lr 1.8090e-03 eta 0:26:28
epoch [12/50] batch [140/445] time 0.086 (0.091) data 0.000 (0.004) loss 1.6364 (1.5989) teacher_loss 1.0452 (0.9633) loss_zs_kd 1.4482 (1.5488) loss_oracle 0.3177 (0.3324) acc 50.0000 (65.9375) lr 1.8090e-03 eta 0:26:10
epoch [12/50] batch [160/445] time 0.088 (0.090) data 0.000 (0.003) loss 1.6155 (1.5906) teacher_loss 0.9953 (0.9552) loss_zs_kd 1.7286 (1.5590) loss_oracle 0.3396 (0.3319) acc 65.6250 (66.1914) lr 1.8090e-03 eta 0:25:54
epoch [12/50] batch [180/445] time 0.085 (0.090) data 0.000 (0.003) loss 1.6003 (1.5769) teacher_loss 0.9055 (0.9463) loss_zs_kd 1.6005 (1.5506) loss_oracle 0.3170 (0.3316) acc 75.0000 (66.6667) lr 1.8090e-03 eta 0:25:41
epoch [12/50] batch [200/445] time 0.090 (0.089) data 0.000 (0.003) loss 1.4555 (1.5697) teacher_loss 0.9629 (0.9427) loss_zs_kd 1.9436 (1.5623) loss_oracle 0.3174 (0.3318) acc 62.5000 (66.9375) lr 1.8090e-03 eta 0:25:28
epoch [12/50] batch [220/445] time 0.087 (0.089) data 0.000 (0.002) loss 1.6248 (1.5742) teacher_loss 0.9492 (0.9486) loss_zs_kd 2.0991 (1.5906) loss_oracle 0.3176 (0.3322) acc 71.8750 (66.6761) lr 1.8090e-03 eta 0:25:21
epoch [12/50] batch [240/445] time 0.091 (0.088) data 0.000 (0.002) loss 1.6805 (1.5733) teacher_loss 0.9559 (0.9498) loss_zs_kd 1.5440 (1.6076) loss_oracle 0.3782 (0.3319) acc 71.8750 (66.7448) lr 1.8090e-03 eta 0:25:11
epoch [12/50] batch [260/445] time 0.079 (0.088) data 0.000 (0.002) loss 1.7620 (1.5755) teacher_loss 1.0745 (0.9496) loss_zs_kd 1.6201 (1.6140) loss_oracle 0.3150 (0.3329) acc 59.3750 (66.6587) lr 1.8090e-03 eta 0:25:04
epoch [12/50] batch [280/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.9486 (1.5800) teacher_loss 1.3035 (0.9529) loss_zs_kd 1.7234 (1.6147) loss_oracle 0.3317 (0.3331) acc 56.2500 (66.4621) lr 1.8090e-03 eta 0:25:09
epoch [12/50] batch [300/445] time 0.090 (0.088) data 0.000 (0.002) loss 1.7630 (1.5810) teacher_loss 1.1741 (0.9541) loss_zs_kd 1.8414 (1.6146) loss_oracle 0.3173 (0.3331) acc 59.3750 (66.3854) lr 1.8090e-03 eta 0:25:04
epoch [12/50] batch [320/445] time 0.078 (0.088) data 0.000 (0.002) loss 1.9482 (1.5844) teacher_loss 1.2975 (0.9577) loss_zs_kd 1.3639 (1.6023) loss_oracle 0.3112 (0.3329) acc 53.1250 (66.2695) lr 1.8090e-03 eta 0:24:58
epoch [12/50] batch [340/445] time 0.086 (0.088) data 0.000 (0.002) loss 1.5104 (1.5836) teacher_loss 1.0048 (0.9583) loss_zs_kd 1.6369 (1.5972) loss_oracle 0.3480 (0.3327) acc 56.2500 (66.1029) lr 1.8090e-03 eta 0:24:54
epoch [12/50] batch [360/445] time 0.088 (0.088) data 0.000 (0.002) loss 1.5072 (1.5772) teacher_loss 0.7944 (0.9529) loss_zs_kd 1.7687 (1.5951) loss_oracle 0.3271 (0.3328) acc 71.8750 (66.1285) lr 1.8090e-03 eta 0:24:50
epoch [12/50] batch [380/445] time 0.087 (0.087) data 0.000 (0.002) loss 1.3363 (1.5830) teacher_loss 0.6683 (0.9568) loss_zs_kd 1.9672 (1.5986) loss_oracle 0.3479 (0.3335) acc 78.1250 (66.0115) lr 1.8090e-03 eta 0:24:44
epoch [12/50] batch [400/445] time 0.097 (0.087) data 0.000 (0.001) loss 1.5410 (1.5822) teacher_loss 0.9534 (0.9566) loss_zs_kd 1.8390 (1.6011) loss_oracle 0.3479 (0.3334) acc 62.5000 (65.9375) lr 1.8090e-03 eta 0:24:40
epoch [12/50] batch [420/445] time 0.086 (0.087) data 0.000 (0.001) loss 1.5437 (1.5805) teacher_loss 0.7663 (0.9545) loss_zs_kd 1.3540 (1.6010) loss_oracle 0.3775 (0.3333) acc 71.8750 (66.1161) lr 1.8090e-03 eta 0:24:36
epoch [12/50] batch [440/445] time 0.062 (0.086) data 0.000 (0.001) loss 1.4136 (1.5824) teacher_loss 0.7547 (0.9569) loss_zs_kd 1.7928 (1.6068) loss_oracle 0.3171 (0.3329) acc 78.1250 (66.0440) lr 1.8090e-03 eta 0:24:19
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,228
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 55.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,009
* accuracy: 50.6%
* error: 49.4%
* macro_f1: 30.2%
******* Domain 3 best val acc:      69.2%, epoch: 12 *******
******* Domain 3 best val test acc: 50.6%, epoch: 12 *******
******* Domain 3 best test acc:     51.1%, epoch: 10 *******
epoch [13/50] batch [20/445] time 0.138 (0.123) data 0.000 (0.028) loss 1.4144 (1.6127) teacher_loss 0.7710 (0.9812) loss_zs_kd 1.5228 (1.5955) loss_oracle 0.3748 (0.3381) acc 75.0000 (66.0938) lr 1.7705e-03 eta 0:34:39
epoch [13/50] batch [40/445] time 0.075 (0.098) data 0.000 (0.014) loss 1.3851 (1.6278) teacher_loss 0.8065 (0.9877) loss_zs_kd 1.5394 (1.5224) loss_oracle 0.3082 (0.3347) acc 59.3750 (64.1406) lr 1.7705e-03 eta 0:27:37
epoch [13/50] batch [60/445] time 0.098 (0.093) data 0.000 (0.009) loss 1.4743 (1.6078) teacher_loss 0.9137 (0.9808) loss_zs_kd 1.5008 (1.5130) loss_oracle 0.3170 (0.3329) acc 65.6250 (64.6354) lr 1.7705e-03 eta 0:26:03
epoch [13/50] batch [80/445] time 0.074 (0.090) data 0.000 (0.007) loss 1.5796 (1.5740) teacher_loss 0.9132 (0.9584) loss_zs_kd 1.7003 (1.4897) loss_oracle 0.3172 (0.3305) acc 65.6250 (65.7031) lr 1.7705e-03 eta 0:25:11
epoch [13/50] batch [100/445] time 0.089 (0.088) data 0.000 (0.006) loss 1.3613 (1.5556) teacher_loss 0.8009 (0.9457) loss_zs_kd 1.8552 (1.4885) loss_oracle 0.3172 (0.3288) acc 71.8750 (66.0938) lr 1.7705e-03 eta 0:24:40
epoch [13/50] batch [120/445] time 0.078 (0.087) data 0.000 (0.005) loss 1.4272 (1.5686) teacher_loss 0.8214 (0.9572) loss_zs_kd 1.2375 (1.4898) loss_oracle 0.3473 (0.3287) acc 75.0000 (66.0417) lr 1.7705e-03 eta 0:24:24
epoch [13/50] batch [140/445] time 0.072 (0.086) data 0.000 (0.004) loss 1.7416 (1.5728) teacher_loss 1.0589 (0.9587) loss_zs_kd 1.3842 (1.4905) loss_oracle 0.3171 (0.3282) acc 59.3750 (65.6027) lr 1.7705e-03 eta 0:24:04
epoch [13/50] batch [160/445] time 0.082 (0.085) data 0.000 (0.004) loss 1.8336 (1.5813) teacher_loss 1.1555 (0.9630) loss_zs_kd 1.5784 (1.5072) loss_oracle 0.3784 (0.3290) acc 53.1250 (65.4297) lr 1.7705e-03 eta 0:23:51
epoch [13/50] batch [180/445] time 0.050 (0.084) data 0.000 (0.003) loss 1.6013 (1.5788) teacher_loss 0.9550 (0.9574) loss_zs_kd 1.5107 (1.5218) loss_oracle 0.3168 (0.3279) acc 68.7500 (65.4861) lr 1.7705e-03 eta 0:23:30
epoch [13/50] batch [200/445] time 0.075 (0.083) data 0.000 (0.003) loss 1.2905 (1.5755) teacher_loss 0.7475 (0.9548) loss_zs_kd 1.1278 (1.5204) loss_oracle 0.3168 (0.3279) acc 78.1250 (65.7656) lr 1.7705e-03 eta 0:23:14
epoch [13/50] batch [220/445] time 0.076 (0.083) data 0.000 (0.003) loss 1.6519 (1.5738) teacher_loss 1.0187 (0.9557) loss_zs_kd 1.3036 (1.5233) loss_oracle 0.3477 (0.3283) acc 59.3750 (65.6534) lr 1.7705e-03 eta 0:23:08
epoch [13/50] batch [240/445] time 0.083 (0.083) data 0.000 (0.003) loss 1.4698 (1.5727) teacher_loss 0.8228 (0.9554) loss_zs_kd 1.3234 (1.5290) loss_oracle 0.3227 (0.3283) acc 62.5000 (65.6771) lr 1.7705e-03 eta 0:23:10
epoch [13/50] batch [260/445] time 0.084 (0.084) data 0.000 (0.002) loss 1.4324 (1.5708) teacher_loss 0.7410 (0.9552) loss_zs_kd 1.4206 (1.5306) loss_oracle 0.3467 (0.3283) acc 68.7500 (65.5649) lr 1.7705e-03 eta 0:23:11
epoch [13/50] batch [280/445] time 0.085 (0.084) data 0.000 (0.002) loss 1.6188 (1.5635) teacher_loss 1.0078 (0.9502) loss_zs_kd 1.3677 (1.5312) loss_oracle 0.3158 (0.3280) acc 65.6250 (65.6696) lr 1.7705e-03 eta 0:23:11
epoch [13/50] batch [300/445] time 0.079 (0.084) data 0.000 (0.002) loss 1.5947 (1.5660) teacher_loss 1.0167 (0.9526) loss_zs_kd 1.5617 (1.5332) loss_oracle 0.3473 (0.3287) acc 68.7500 (65.7396) lr 1.7705e-03 eta 0:23:11
epoch [13/50] batch [320/445] time 0.092 (0.084) data 0.000 (0.002) loss 1.7070 (1.5666) teacher_loss 1.0501 (0.9548) loss_zs_kd 1.7310 (1.5413) loss_oracle 0.3167 (0.3289) acc 59.3750 (65.6641) lr 1.7705e-03 eta 0:23:11
epoch [13/50] batch [340/445] time 0.088 (0.084) data 0.000 (0.002) loss 1.5891 (1.5623) teacher_loss 1.1072 (0.9545) loss_zs_kd 1.5116 (1.5468) loss_oracle 0.3166 (0.3287) acc 62.5000 (65.6985) lr 1.7705e-03 eta 0:23:11
epoch [13/50] batch [360/445] time 0.070 (0.083) data 0.000 (0.002) loss 1.6128 (1.5603) teacher_loss 0.9649 (0.9550) loss_zs_kd 2.0292 (1.5542) loss_oracle 0.3168 (0.3283) acc 65.6250 (65.7292) lr 1.7705e-03 eta 0:22:57
epoch [13/50] batch [380/445] time 0.059 (0.083) data 0.000 (0.002) loss 1.3876 (1.5584) teacher_loss 0.8349 (0.9542) loss_zs_kd 1.7413 (1.5545) loss_oracle 0.3167 (0.3282) acc 62.5000 (65.7072) lr 1.7705e-03 eta 0:22:55
epoch [13/50] batch [400/445] time 0.078 (0.083) data 0.000 (0.002) loss 1.3937 (1.5568) teacher_loss 0.7320 (0.9516) loss_zs_kd 1.6882 (1.5544) loss_oracle 0.3068 (0.3284) acc 68.7500 (65.9531) lr 1.7705e-03 eta 0:22:55
epoch [13/50] batch [420/445] time 0.114 (0.084) data 0.000 (0.002) loss 1.3949 (1.5559) teacher_loss 0.7684 (0.9512) loss_zs_kd 1.6893 (1.5538) loss_oracle 0.3474 (0.3283) acc 71.8750 (65.9449) lr 1.7705e-03 eta 0:23:00
epoch [13/50] batch [440/445] time 0.062 (0.084) data 0.000 (0.002) loss 1.4540 (1.5565) teacher_loss 0.7568 (0.9513) loss_zs_kd 1.6045 (1.5559) loss_oracle 0.3423 (0.3288) acc 78.1250 (66.0227) lr 1.7705e-03 eta 0:23:08
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,184
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 54.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,024
* accuracy: 51.0%
* error: 49.0%
* macro_f1: 30.6%
******* Domain 3 best val acc:      69.2%, epoch: 12 *******
******* Domain 3 best val test acc: 50.6%, epoch: 12 *******
******* Domain 3 best test acc:     51.1%, epoch: 10 *******
epoch [14/50] batch [20/445] time 0.085 (0.117) data 0.000 (0.031) loss 1.3679 (1.5177) teacher_loss 0.7801 (0.9224) loss_zs_kd 1.8540 (1.7048) loss_oracle 0.3772 (0.3300) acc 65.6250 (68.1250) lr 1.7290e-03 eta 0:32:00
epoch [14/50] batch [40/445] time 0.084 (0.101) data 0.000 (0.015) loss 1.3578 (1.5435) teacher_loss 0.8067 (0.9504) loss_zs_kd 1.8633 (1.6525) loss_oracle 0.3473 (0.3340) acc 71.8750 (66.9531) lr 1.7290e-03 eta 0:27:39
epoch [14/50] batch [60/445] time 0.083 (0.096) data 0.000 (0.010) loss 1.1403 (1.5302) teacher_loss 0.6158 (0.9406) loss_zs_kd 1.3819 (1.6420) loss_oracle 0.3165 (0.3316) acc 81.2500 (67.2917) lr 1.7290e-03 eta 0:26:13
epoch [14/50] batch [80/445] time 0.088 (0.093) data 0.000 (0.008) loss 1.3946 (1.5398) teacher_loss 0.8545 (0.9473) loss_zs_kd 1.6000 (1.6532) loss_oracle 0.3472 (0.3326) acc 68.7500 (66.8359) lr 1.7290e-03 eta 0:25:24
epoch [14/50] batch [100/445] time 0.081 (0.091) data 0.000 (0.006) loss 1.6954 (1.5531) teacher_loss 1.1302 (0.9625) loss_zs_kd 1.7667 (1.6512) loss_oracle 0.3163 (0.3317) acc 62.5000 (66.2500) lr 1.7290e-03 eta 0:24:56
epoch [14/50] batch [120/445] time 0.088 (0.091) data 0.001 (0.005) loss 1.2975 (1.5572) teacher_loss 0.7937 (0.9711) loss_zs_kd 1.7340 (1.6453) loss_oracle 0.3474 (0.3322) acc 78.1250 (65.6510) lr 1.7290e-03 eta 0:24:48
epoch [14/50] batch [140/445] time 0.089 (0.091) data 0.000 (0.005) loss 1.5469 (1.5618) teacher_loss 0.9336 (0.9794) loss_zs_kd 1.4118 (1.6157) loss_oracle 0.3445 (0.3316) acc 62.5000 (65.3348) lr 1.7290e-03 eta 0:24:42
epoch [14/50] batch [160/445] time 0.086 (0.090) data 0.000 (0.004) loss 1.4784 (1.5597) teacher_loss 0.9156 (0.9785) loss_zs_kd 1.5687 (1.6132) loss_oracle 0.3163 (0.3306) acc 71.8750 (65.3711) lr 1.7290e-03 eta 0:24:28
epoch [14/50] batch [180/445] time 0.086 (0.090) data 0.000 (0.004) loss 1.6953 (1.5519) teacher_loss 1.1271 (0.9719) loss_zs_kd 1.6782 (1.6244) loss_oracle 0.3166 (0.3302) acc 56.2500 (65.5903) lr 1.7290e-03 eta 0:24:20
epoch [14/50] batch [200/445] time 0.097 (0.089) data 0.001 (0.003) loss 1.6290 (1.5544) teacher_loss 1.0023 (0.9708) loss_zs_kd 1.6743 (1.6190) loss_oracle 0.3299 (0.3304) acc 65.6250 (65.5312) lr 1.7290e-03 eta 0:24:11
epoch [14/50] batch [220/445] time 0.083 (0.089) data 0.000 (0.003) loss 1.4776 (1.5580) teacher_loss 0.9501 (0.9739) loss_zs_kd 1.4840 (1.6345) loss_oracle 0.3472 (0.3299) acc 71.8750 (65.4261) lr 1.7290e-03 eta 0:24:02
epoch [14/50] batch [240/445] time 0.089 (0.089) data 0.000 (0.003) loss 1.7762 (1.5526) teacher_loss 1.2503 (0.9702) loss_zs_kd 1.6074 (1.6306) loss_oracle 0.3163 (0.3295) acc 53.1250 (65.4036) lr 1.7290e-03 eta 0:23:56
epoch [14/50] batch [260/445] time 0.084 (0.088) data 0.000 (0.003) loss 1.3073 (1.5422) teacher_loss 0.6932 (0.9619) loss_zs_kd 1.7326 (1.6334) loss_oracle 0.3164 (0.3289) acc 71.8750 (65.8173) lr 1.7290e-03 eta 0:23:51
epoch [14/50] batch [280/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.6592 (1.5452) teacher_loss 1.0446 (0.9631) loss_zs_kd 1.4118 (1.6366) loss_oracle 0.3148 (0.3281) acc 46.8750 (65.6473) lr 1.7290e-03 eta 0:23:46
epoch [14/50] batch [300/445] time 0.069 (0.087) data 0.000 (0.002) loss 1.3453 (1.5450) teacher_loss 0.7030 (0.9612) loss_zs_kd 1.7120 (1.6275) loss_oracle 0.3466 (0.3279) acc 71.8750 (65.7083) lr 1.7290e-03 eta 0:23:29
epoch [14/50] batch [320/445] time 0.058 (0.087) data 0.000 (0.002) loss 1.3659 (1.5467) teacher_loss 0.7267 (0.9624) loss_zs_kd 1.2607 (1.6199) loss_oracle 0.3471 (0.3278) acc 75.0000 (65.7422) lr 1.7290e-03 eta 0:23:25
epoch [14/50] batch [340/445] time 0.146 (0.087) data 0.000 (0.002) loss 1.4163 (1.5395) teacher_loss 0.8201 (0.9564) loss_zs_kd 1.8361 (1.6193) loss_oracle 0.3155 (0.3274) acc 65.6250 (65.8824) lr 1.7290e-03 eta 0:23:24
epoch [14/50] batch [360/445] time 0.070 (0.087) data 0.000 (0.002) loss 1.4882 (1.5360) teacher_loss 0.9410 (0.9536) loss_zs_kd 1.5359 (1.6209) loss_oracle 0.3163 (0.3271) acc 71.8750 (65.9722) lr 1.7290e-03 eta 0:23:19
epoch [14/50] batch [380/445] time 0.064 (0.088) data 0.000 (0.002) loss 2.0300 (1.5336) teacher_loss 1.3817 (0.9514) loss_zs_kd 1.5940 (1.6246) loss_oracle 0.3470 (0.3269) acc 43.7500 (66.0362) lr 1.7290e-03 eta 0:23:30
epoch [14/50] batch [400/445] time 0.064 (0.087) data 0.000 (0.002) loss 1.3803 (1.5332) teacher_loss 0.7347 (0.9512) loss_zs_kd 1.7165 (1.6313) loss_oracle 0.3231 (0.3267) acc 78.1250 (66.0625) lr 1.7290e-03 eta 0:23:14
epoch [14/50] batch [420/445] time 0.122 (0.087) data 0.001 (0.002) loss 1.5429 (1.5321) teacher_loss 1.0689 (0.9508) loss_zs_kd 1.4216 (1.6244) loss_oracle 0.3161 (0.3265) acc 62.5000 (66.0863) lr 1.7290e-03 eta 0:23:12
epoch [14/50] batch [440/445] time 0.150 (0.087) data 0.000 (0.002) loss 1.5220 (1.5278) teacher_loss 0.9430 (0.9456) loss_zs_kd 1.7711 (1.6261) loss_oracle 0.3445 (0.3266) acc 75.0000 (66.3068) lr 1.7290e-03 eta 0:23:13
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,221
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 54.4%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,053
* accuracy: 51.7%
* error: 48.3%
* macro_f1: 31.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      69.2%, epoch: 12 *******
******* Domain 3 best val test acc: 50.6%, epoch: 12 *******
******* Domain 3 best test acc:     51.7%, epoch: 14 *******
epoch [15/50] batch [20/445] time 0.082 (0.104) data 0.000 (0.023) loss 1.5661 (1.6149) teacher_loss 0.9617 (0.9842) loss_zs_kd 1.4042 (1.5901) loss_oracle 0.3063 (0.3231) acc 68.7500 (64.5312) lr 1.6845e-03 eta 0:27:44
epoch [15/50] batch [40/445] time 0.074 (0.090) data 0.000 (0.012) loss 1.7607 (1.5669) teacher_loss 1.1285 (0.9463) loss_zs_kd 1.6246 (1.5000) loss_oracle 0.3469 (0.3268) acc 59.3750 (66.4844) lr 1.6845e-03 eta 0:24:02
epoch [15/50] batch [60/445] time 0.085 (0.088) data 0.000 (0.008) loss 1.6172 (1.5554) teacher_loss 1.0091 (0.9450) loss_zs_kd 1.5852 (1.5140) loss_oracle 0.3469 (0.3252) acc 68.7500 (66.5625) lr 1.6845e-03 eta 0:23:24
epoch [15/50] batch [80/445] time 0.052 (0.086) data 0.000 (0.006) loss 1.6057 (1.5415) teacher_loss 1.0482 (0.9321) loss_zs_kd 1.6675 (1.5001) loss_oracle 0.3160 (0.3264) acc 59.3750 (66.9922) lr 1.6845e-03 eta 0:22:46
epoch [15/50] batch [100/445] time 0.088 (0.085) data 0.000 (0.005) loss 1.6213 (1.5563) teacher_loss 1.0042 (0.9402) loss_zs_kd 1.6330 (1.4925) loss_oracle 0.3153 (0.3263) acc 62.5000 (66.2812) lr 1.6845e-03 eta 0:22:34
epoch [15/50] batch [120/445] time 0.084 (0.085) data 0.000 (0.004) loss 1.6536 (1.5607) teacher_loss 1.0088 (0.9451) loss_zs_kd 1.6972 (1.5065) loss_oracle 0.3161 (0.3250) acc 65.6250 (66.1979) lr 1.6845e-03 eta 0:22:34
epoch [15/50] batch [140/445] time 0.082 (0.085) data 0.000 (0.004) loss 1.5805 (1.5706) teacher_loss 0.9618 (0.9517) loss_zs_kd 1.6152 (1.5296) loss_oracle 0.3160 (0.3255) acc 71.8750 (66.0714) lr 1.6845e-03 eta 0:22:31
epoch [15/50] batch [160/445] time 0.081 (0.085) data 0.000 (0.003) loss 1.6043 (1.5608) teacher_loss 1.0210 (0.9421) loss_zs_kd 1.3792 (1.5387) loss_oracle 0.3160 (0.3254) acc 65.6250 (66.3672) lr 1.6845e-03 eta 0:22:30
epoch [15/50] batch [180/445] time 0.085 (0.085) data 0.000 (0.003) loss 1.6441 (1.5528) teacher_loss 1.0590 (0.9358) loss_zs_kd 1.6576 (1.5290) loss_oracle 0.3159 (0.3262) acc 59.3750 (66.8229) lr 1.6845e-03 eta 0:22:29
epoch [15/50] batch [200/445] time 0.083 (0.085) data 0.000 (0.003) loss 1.5504 (1.5495) teacher_loss 0.9517 (0.9367) loss_zs_kd 1.5158 (1.5251) loss_oracle 0.3048 (0.3265) acc 65.6250 (66.9531) lr 1.6845e-03 eta 0:22:28
epoch [15/50] batch [220/445] time 0.084 (0.085) data 0.000 (0.002) loss 1.3740 (1.5434) teacher_loss 0.8096 (0.9338) loss_zs_kd 1.4599 (1.5283) loss_oracle 0.3159 (0.3264) acc 68.7500 (66.9886) lr 1.6845e-03 eta 0:22:26
epoch [15/50] batch [240/445] time 0.088 (0.085) data 0.001 (0.002) loss 1.5170 (1.5407) teacher_loss 0.8859 (0.9335) loss_zs_kd 1.7583 (1.5367) loss_oracle 0.3159 (0.3260) acc 62.5000 (66.9531) lr 1.6845e-03 eta 0:22:26
epoch [15/50] batch [260/445] time 0.069 (0.085) data 0.000 (0.002) loss 1.3655 (1.5409) teacher_loss 0.7738 (0.9352) loss_zs_kd 1.4936 (1.5422) loss_oracle 0.3159 (0.3266) acc 68.7500 (67.0312) lr 1.6845e-03 eta 0:22:18
epoch [15/50] batch [280/445] time 0.162 (0.085) data 0.001 (0.002) loss 1.2055 (1.5416) teacher_loss 0.6475 (0.9361) loss_zs_kd 1.9492 (1.5428) loss_oracle 0.3160 (0.3265) acc 81.2500 (66.9643) lr 1.6845e-03 eta 0:22:21
epoch [15/50] batch [300/445] time 0.063 (0.086) data 0.000 (0.002) loss 1.3056 (1.5409) teacher_loss 0.7704 (0.9349) loss_zs_kd 1.4985 (1.5485) loss_oracle 0.3158 (0.3267) acc 65.6250 (66.9583) lr 1.6845e-03 eta 0:22:30
epoch [15/50] batch [320/445] time 0.149 (0.087) data 0.000 (0.002) loss 1.4768 (1.5410) teacher_loss 0.8865 (0.9352) loss_zs_kd 1.4700 (1.5468) loss_oracle 0.3074 (0.3267) acc 71.8750 (66.9531) lr 1.6845e-03 eta 0:22:41
epoch [15/50] batch [340/445] time 0.073 (0.086) data 0.000 (0.002) loss 1.5343 (1.5398) teacher_loss 0.9679 (0.9331) loss_zs_kd 1.4365 (1.5499) loss_oracle 0.3158 (0.3266) acc 75.0000 (66.9669) lr 1.6845e-03 eta 0:22:30
epoch [15/50] batch [360/445] time 0.092 (0.086) data 0.000 (0.002) loss 1.3186 (1.5362) teacher_loss 0.7495 (0.9276) loss_zs_kd 1.5848 (1.5557) loss_oracle 0.3158 (0.3263) acc 71.8750 (67.1528) lr 1.6845e-03 eta 0:22:29
epoch [15/50] batch [380/445] time 0.165 (0.086) data 0.000 (0.001) loss 1.6575 (1.5355) teacher_loss 1.0249 (0.9258) loss_zs_kd 2.3413 (1.5662) loss_oracle 0.3159 (0.3265) acc 68.7500 (67.3026) lr 1.6845e-03 eta 0:22:30
epoch [15/50] batch [400/445] time 0.083 (0.087) data 0.000 (0.001) loss 1.7877 (1.5398) teacher_loss 1.1941 (0.9292) loss_zs_kd 1.6798 (1.5744) loss_oracle 0.3158 (0.3263) acc 56.2500 (67.2266) lr 1.6845e-03 eta 0:22:37
epoch [15/50] batch [420/445] time 0.061 (0.087) data 0.000 (0.001) loss 1.7652 (1.5401) teacher_loss 1.0716 (0.9295) loss_zs_kd 1.7376 (1.5819) loss_oracle 0.3159 (0.3262) acc 56.2500 (67.1875) lr 1.6845e-03 eta 0:22:34
epoch [15/50] batch [440/445] time 0.059 (0.087) data 0.000 (0.001) loss 1.2839 (1.5394) teacher_loss 0.7644 (0.9290) loss_zs_kd 1.2401 (1.5825) loss_oracle 0.3158 (0.3260) acc 75.0000 (67.2088) lr 1.6845e-03 eta 0:22:42
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,282
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 55.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,013
* accuracy: 50.7%
* error: 49.3%
* macro_f1: 31.7%
******* Domain 3 best val acc:      70.1%, epoch: 15 *******
******* Domain 3 best val test acc: 50.7%, epoch: 15 *******
******* Domain 3 best test acc:     51.7%, epoch: 14 *******
epoch [16/50] batch [20/445] time 0.080 (0.112) data 0.000 (0.026) loss 1.4932 (1.4823) teacher_loss 0.8805 (0.8981) loss_zs_kd 1.6406 (1.5654) loss_oracle 0.3158 (0.3232) acc 68.7500 (67.9688) lr 1.6374e-03 eta 0:28:57
epoch [16/50] batch [40/445] time 0.084 (0.099) data 0.000 (0.013) loss 1.2187 (1.4953) teacher_loss 0.6723 (0.8991) loss_zs_kd 1.7370 (1.6818) loss_oracle 0.3150 (0.3288) acc 78.1250 (68.5156) lr 1.6374e-03 eta 0:25:37
epoch [16/50] batch [60/445] time 0.084 (0.094) data 0.000 (0.009) loss 1.4738 (1.4674) teacher_loss 0.8605 (0.8798) loss_zs_kd 2.0974 (1.6915) loss_oracle 0.3081 (0.3262) acc 78.1250 (69.8438) lr 1.6374e-03 eta 0:24:25
epoch [16/50] batch [80/445] time 0.082 (0.092) data 0.000 (0.007) loss 1.1874 (1.4766) teacher_loss 0.6644 (0.8946) loss_zs_kd 1.6871 (1.7043) loss_oracle 0.3157 (0.3244) acc 75.0000 (69.2188) lr 1.6374e-03 eta 0:23:48
epoch [16/50] batch [100/445] time 0.086 (0.091) data 0.000 (0.005) loss 1.3329 (1.4844) teacher_loss 0.7054 (0.9013) loss_zs_kd 1.4896 (1.7143) loss_oracle 0.3158 (0.3235) acc 75.0000 (68.4375) lr 1.6374e-03 eta 0:23:24
epoch [16/50] batch [120/445] time 0.085 (0.090) data 0.000 (0.005) loss 1.6878 (1.4996) teacher_loss 0.9830 (0.9172) loss_zs_kd 2.2251 (1.7180) loss_oracle 0.3405 (0.3236) acc 59.3750 (68.3333) lr 1.6374e-03 eta 0:23:08
epoch [16/50] batch [140/445] time 0.080 (0.089) data 0.000 (0.004) loss 1.3581 (1.5019) teacher_loss 0.7221 (0.9133) loss_zs_kd 1.8138 (1.7252) loss_oracle 0.3157 (0.3230) acc 68.7500 (68.4375) lr 1.6374e-03 eta 0:22:58
epoch [16/50] batch [160/445] time 0.082 (0.089) data 0.000 (0.003) loss 1.6068 (1.5107) teacher_loss 0.9300 (0.9173) loss_zs_kd 1.7845 (1.7340) loss_oracle 0.3381 (0.3246) acc 62.5000 (68.1445) lr 1.6374e-03 eta 0:22:50
epoch [16/50] batch [180/445] time 0.072 (0.088) data 0.000 (0.003) loss 1.5540 (1.5153) teacher_loss 0.8967 (0.9177) loss_zs_kd 1.4919 (1.7288) loss_oracle 0.3156 (0.3260) acc 65.6250 (67.8993) lr 1.6374e-03 eta 0:22:35
epoch [16/50] batch [200/445] time 0.155 (0.087) data 0.000 (0.003) loss 1.5427 (1.5167) teacher_loss 0.9645 (0.9194) loss_zs_kd 1.5043 (1.7181) loss_oracle 0.3156 (0.3258) acc 75.0000 (67.6406) lr 1.6374e-03 eta 0:22:17
epoch [16/50] batch [220/445] time 0.071 (0.087) data 0.000 (0.003) loss 1.4495 (1.5177) teacher_loss 0.8942 (0.9179) loss_zs_kd 1.5219 (1.7063) loss_oracle 0.3156 (0.3255) acc 56.2500 (67.6420) lr 1.6374e-03 eta 0:22:18
epoch [16/50] batch [240/445] time 0.072 (0.087) data 0.000 (0.002) loss 1.2235 (1.5136) teacher_loss 0.5971 (0.9127) loss_zs_kd 1.8627 (1.7082) loss_oracle 0.3156 (0.3250) acc 78.1250 (67.7734) lr 1.6374e-03 eta 0:22:15
epoch [16/50] batch [260/445] time 0.155 (0.088) data 0.000 (0.002) loss 1.4241 (1.5149) teacher_loss 0.7452 (0.9139) loss_zs_kd 1.7204 (1.7197) loss_oracle 0.3679 (0.3250) acc 78.1250 (67.6082) lr 1.6374e-03 eta 0:22:31
epoch [16/50] batch [280/445] time 0.078 (0.087) data 0.000 (0.002) loss 1.8689 (1.5166) teacher_loss 1.1925 (0.9157) loss_zs_kd 1.4340 (1.7113) loss_oracle 0.3156 (0.3249) acc 59.3750 (67.4219) lr 1.6374e-03 eta 0:22:15
epoch [16/50] batch [300/445] time 0.064 (0.087) data 0.000 (0.002) loss 1.4842 (1.5155) teacher_loss 0.9329 (0.9152) loss_zs_kd 1.8360 (1.7069) loss_oracle 0.3157 (0.3244) acc 62.5000 (67.5521) lr 1.6374e-03 eta 0:22:13
epoch [16/50] batch [320/445] time 0.075 (0.088) data 0.000 (0.002) loss 1.4892 (1.5189) teacher_loss 0.8330 (0.9190) loss_zs_kd 1.8638 (1.6991) loss_oracle 0.3157 (0.3244) acc 71.8750 (67.2754) lr 1.6374e-03 eta 0:22:26
epoch [16/50] batch [340/445] time 0.153 (0.089) data 0.000 (0.002) loss 1.4382 (1.5242) teacher_loss 0.8809 (0.9236) loss_zs_kd 1.7116 (1.6944) loss_oracle 0.3157 (0.3241) acc 78.1250 (67.1783) lr 1.6374e-03 eta 0:22:38
epoch [16/50] batch [360/445] time 0.157 (0.089) data 0.000 (0.002) loss 2.0949 (1.5291) teacher_loss 1.5148 (0.9295) loss_zs_kd 1.8155 (1.6925) loss_oracle 0.3138 (0.3238) acc 59.3750 (66.9010) lr 1.6374e-03 eta 0:22:36
epoch [16/50] batch [380/445] time 0.068 (0.089) data 0.000 (0.002) loss 1.3387 (1.5284) teacher_loss 0.6633 (0.9287) loss_zs_kd 1.5771 (1.6947) loss_oracle 0.3271 (0.3237) acc 71.8750 (66.9572) lr 1.6374e-03 eta 0:22:35
epoch [16/50] batch [400/445] time 0.072 (0.089) data 0.000 (0.002) loss 1.8443 (1.5278) teacher_loss 1.2698 (0.9289) loss_zs_kd 1.9063 (1.6939) loss_oracle 0.3288 (0.3237) acc 59.3750 (66.9375) lr 1.6374e-03 eta 0:22:32
epoch [16/50] batch [420/445] time 0.068 (0.089) data 0.000 (0.002) loss 1.7958 (1.5280) teacher_loss 1.1373 (0.9295) loss_zs_kd 1.7820 (1.6943) loss_oracle 0.3427 (0.3237) acc 59.3750 (66.9940) lr 1.6374e-03 eta 0:22:28
epoch [16/50] batch [440/445] time 0.056 (0.089) data 0.000 (0.001) loss 1.2240 (1.5258) teacher_loss 0.6772 (0.9279) loss_zs_kd 1.5963 (1.6888) loss_oracle 0.3156 (0.3236) acc 75.0000 (67.0384) lr 1.6374e-03 eta 0:22:34
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,234
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 55.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,963
* accuracy: 49.4%
* error: 50.6%
* macro_f1: 30.1%
******* Domain 3 best val acc:      70.1%, epoch: 15 *******
******* Domain 3 best val test acc: 50.7%, epoch: 15 *******
******* Domain 3 best test acc:     51.7%, epoch: 14 *******
epoch [17/50] batch [20/445] time 0.083 (0.133) data 0.000 (0.038) loss 1.4123 (1.5487) teacher_loss 0.7762 (0.9240) loss_zs_kd 1.1667 (1.5254) loss_oracle 0.3415 (0.3318) acc 78.1250 (66.4062) lr 1.5878e-03 eta 0:33:28
epoch [17/50] batch [40/445] time 0.084 (0.109) data 0.000 (0.019) loss 1.6133 (1.5312) teacher_loss 0.9566 (0.9210) loss_zs_kd 1.8122 (1.5690) loss_oracle 0.3155 (0.3273) acc 65.6250 (67.1094) lr 1.5878e-03 eta 0:27:28
epoch [17/50] batch [60/445] time 0.084 (0.103) data 0.000 (0.013) loss 1.7200 (1.5507) teacher_loss 1.1625 (0.9426) loss_zs_kd 1.7021 (1.6267) loss_oracle 0.3040 (0.3261) acc 62.5000 (66.6146) lr 1.5878e-03 eta 0:25:56
epoch [17/50] batch [80/445] time 0.083 (0.099) data 0.000 (0.010) loss 1.5985 (1.5337) teacher_loss 1.0136 (0.9343) loss_zs_kd 1.3763 (1.6134) loss_oracle 0.3157 (0.3245) acc 68.7500 (66.4062) lr 1.5878e-03 eta 0:24:46
epoch [17/50] batch [100/445] time 0.085 (0.096) data 0.000 (0.008) loss 1.5056 (1.5366) teacher_loss 0.8959 (0.9385) loss_zs_kd 1.6462 (1.6173) loss_oracle 0.3700 (0.3252) acc 65.6250 (66.4062) lr 1.5878e-03 eta 0:24:00
epoch [17/50] batch [120/445] time 0.070 (0.092) data 0.000 (0.006) loss 1.4658 (1.5435) teacher_loss 0.8892 (0.9454) loss_zs_kd 1.8390 (1.6321) loss_oracle 0.3132 (0.3241) acc 65.6250 (66.3542) lr 1.5878e-03 eta 0:23:00
epoch [17/50] batch [140/445] time 0.157 (0.093) data 0.000 (0.006) loss 1.3313 (1.5448) teacher_loss 0.8440 (0.9451) loss_zs_kd 1.3829 (1.6139) loss_oracle 0.3154 (0.3238) acc 71.8750 (66.4509) lr 1.5878e-03 eta 0:23:08
epoch [17/50] batch [160/445] time 0.076 (0.091) data 0.000 (0.005) loss 1.7444 (1.5449) teacher_loss 1.1249 (0.9442) loss_zs_kd 2.0128 (1.6091) loss_oracle 0.3366 (0.3238) acc 62.5000 (66.2891) lr 1.5878e-03 eta 0:22:43
epoch [17/50] batch [180/445] time 0.082 (0.092) data 0.000 (0.004) loss 1.3981 (1.5461) teacher_loss 0.7331 (0.9479) loss_zs_kd 2.0680 (1.6186) loss_oracle 0.3314 (0.3240) acc 59.3750 (66.1285) lr 1.5878e-03 eta 0:22:58
epoch [17/50] batch [200/445] time 0.075 (0.091) data 0.000 (0.004) loss 1.5767 (1.5479) teacher_loss 0.9488 (0.9509) loss_zs_kd 1.3371 (1.6247) loss_oracle 0.3155 (0.3238) acc 68.7500 (66.1250) lr 1.5878e-03 eta 0:22:43
epoch [17/50] batch [220/445] time 0.147 (0.090) data 0.000 (0.004) loss 1.6474 (1.5491) teacher_loss 1.0270 (0.9512) loss_zs_kd 1.5347 (1.6197) loss_oracle 0.3140 (0.3240) acc 68.7500 (66.1648) lr 1.5878e-03 eta 0:22:23
epoch [17/50] batch [240/445] time 0.089 (0.090) data 0.000 (0.003) loss 1.6637 (1.5460) teacher_loss 1.0423 (0.9477) loss_zs_kd 1.7189 (1.6232) loss_oracle 0.3154 (0.3238) acc 65.6250 (66.2891) lr 1.5878e-03 eta 0:22:24
epoch [17/50] batch [260/445] time 0.064 (0.091) data 0.000 (0.003) loss 1.2213 (1.5414) teacher_loss 0.6597 (0.9410) loss_zs_kd 1.8867 (1.6246) loss_oracle 0.3154 (0.3245) acc 84.3750 (66.6466) lr 1.5878e-03 eta 0:22:33
epoch [17/50] batch [280/445] time 0.153 (0.092) data 0.000 (0.003) loss 1.3564 (1.5387) teacher_loss 0.8858 (0.9385) loss_zs_kd 2.0476 (1.6324) loss_oracle 0.3154 (0.3249) acc 68.7500 (66.7746) lr 1.5878e-03 eta 0:22:45
epoch [17/50] batch [300/445] time 0.071 (0.091) data 0.000 (0.003) loss 1.5943 (1.5411) teacher_loss 0.9025 (0.9389) loss_zs_kd 1.9599 (1.6336) loss_oracle 0.3155 (0.3254) acc 65.6250 (66.9271) lr 1.5878e-03 eta 0:22:35
epoch [17/50] batch [320/445] time 0.118 (0.092) data 0.000 (0.003) loss 1.3516 (1.5379) teacher_loss 0.8534 (0.9358) loss_zs_kd 2.0045 (1.6373) loss_oracle 0.3154 (0.3256) acc 75.0000 (67.0605) lr 1.5878e-03 eta 0:22:48
epoch [17/50] batch [340/445] time 0.155 (0.092) data 0.000 (0.002) loss 1.3216 (1.5337) teacher_loss 0.7622 (0.9330) loss_zs_kd 1.7111 (1.6436) loss_oracle 0.3154 (0.3252) acc 68.7500 (67.1783) lr 1.5878e-03 eta 0:22:46
epoch [17/50] batch [360/445] time 0.066 (0.093) data 0.000 (0.002) loss 1.7648 (1.5333) teacher_loss 1.0789 (0.9329) loss_zs_kd 1.6787 (1.6479) loss_oracle 0.3759 (0.3254) acc 68.7500 (67.2830) lr 1.5878e-03 eta 0:22:47
epoch [17/50] batch [380/445] time 0.069 (0.092) data 0.000 (0.002) loss 1.9036 (1.5316) teacher_loss 1.3206 (0.9330) loss_zs_kd 1.9471 (1.6580) loss_oracle 0.3148 (0.3254) acc 56.2500 (67.1957) lr 1.5878e-03 eta 0:22:31
epoch [17/50] batch [400/445] time 0.084 (0.091) data 0.000 (0.002) loss 1.8661 (1.5333) teacher_loss 1.1746 (0.9350) loss_zs_kd 2.0576 (1.6611) loss_oracle 0.3154 (0.3253) acc 62.5000 (67.0859) lr 1.5878e-03 eta 0:22:22
epoch [17/50] batch [420/445] time 0.087 (0.091) data 0.000 (0.002) loss 1.4272 (1.5346) teacher_loss 0.7868 (0.9364) loss_zs_kd 1.5894 (1.6589) loss_oracle 0.3452 (0.3255) acc 65.6250 (67.0089) lr 1.5878e-03 eta 0:22:17
epoch [17/50] batch [440/445] time 0.085 (0.091) data 0.001 (0.002) loss 1.7483 (1.5359) teacher_loss 1.2202 (0.9373) loss_zs_kd 1.9709 (1.6564) loss_oracle 0.3153 (0.3258) acc 62.5000 (66.9957) lr 1.5878e-03 eta 0:22:11
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,202
* accuracy: 68.8%
* error: 31.2%
* macro_f1: 54.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,960
* accuracy: 49.4%
* error: 50.6%
* macro_f1: 29.3%
******* Domain 3 best val acc:      70.1%, epoch: 15 *******
******* Domain 3 best val test acc: 50.7%, epoch: 15 *******
******* Domain 3 best test acc:     51.7%, epoch: 14 *******
epoch [18/50] batch [20/445] time 0.088 (0.116) data 0.000 (0.029) loss 1.4790 (1.5597) teacher_loss 0.9286 (0.9604) loss_zs_kd 1.9589 (1.6437) loss_oracle 0.3153 (0.3236) acc 62.5000 (63.7500) lr 1.5358e-03 eta 0:28:24
epoch [18/50] batch [40/445] time 0.065 (0.094) data 0.000 (0.015) loss 1.4637 (1.5780) teacher_loss 0.8032 (0.9731) loss_zs_kd 1.7192 (1.6371) loss_oracle 0.3154 (0.3247) acc 68.7500 (64.6094) lr 1.5358e-03 eta 0:22:57
epoch [18/50] batch [60/445] time 0.072 (0.092) data 0.000 (0.010) loss 1.9353 (1.5932) teacher_loss 1.2925 (0.9896) loss_zs_kd 1.5747 (1.6200) loss_oracle 0.3461 (0.3240) acc 50.0000 (64.1146) lr 1.5358e-03 eta 0:22:30
epoch [18/50] batch [80/445] time 0.081 (0.091) data 0.000 (0.007) loss 1.6347 (1.5585) teacher_loss 0.9842 (0.9631) loss_zs_kd 1.6031 (1.5947) loss_oracle 0.3153 (0.3243) acc 68.7500 (65.0391) lr 1.5358e-03 eta 0:22:09
epoch [18/50] batch [100/445] time 0.157 (0.092) data 0.000 (0.006) loss 1.2950 (1.5380) teacher_loss 0.7054 (0.9399) loss_zs_kd 1.5734 (1.6095) loss_oracle 0.3153 (0.3239) acc 68.7500 (65.8750) lr 1.5358e-03 eta 0:22:19
epoch [18/50] batch [120/445] time 0.067 (0.093) data 0.000 (0.005) loss 1.8831 (1.5417) teacher_loss 1.2544 (0.9422) loss_zs_kd 1.7494 (1.6228) loss_oracle 0.3070 (0.3250) acc 50.0000 (65.7812) lr 1.5358e-03 eta 0:22:30
epoch [18/50] batch [140/445] time 0.154 (0.093) data 0.000 (0.004) loss 1.4895 (1.5459) teacher_loss 0.8930 (0.9428) loss_zs_kd 1.6932 (1.6182) loss_oracle 0.3075 (0.3249) acc 75.0000 (65.6920) lr 1.5358e-03 eta 0:22:30
epoch [18/50] batch [160/445] time 0.061 (0.093) data 0.000 (0.004) loss 1.5401 (1.5438) teacher_loss 0.8928 (0.9430) loss_zs_kd 1.3604 (1.6157) loss_oracle 0.3153 (0.3245) acc 62.5000 (65.7422) lr 1.5358e-03 eta 0:22:27
epoch [18/50] batch [180/445] time 0.067 (0.094) data 0.000 (0.003) loss 1.5772 (1.5469) teacher_loss 0.8767 (0.9450) loss_zs_kd 1.3850 (1.6053) loss_oracle 0.3463 (0.3273) acc 71.8750 (65.8160) lr 1.5358e-03 eta 0:22:40
epoch [18/50] batch [200/445] time 0.081 (0.094) data 0.000 (0.003) loss 1.4145 (1.5435) teacher_loss 0.8248 (0.9384) loss_zs_kd 1.4177 (1.5969) loss_oracle 0.3152 (0.3277) acc 78.1250 (66.1562) lr 1.5358e-03 eta 0:22:46
epoch [18/50] batch [220/445] time 0.059 (0.093) data 0.000 (0.003) loss 1.6659 (1.5398) teacher_loss 1.1525 (0.9356) loss_zs_kd 1.7431 (1.6119) loss_oracle 0.3435 (0.3281) acc 59.3750 (66.3352) lr 1.5358e-03 eta 0:22:26
epoch [18/50] batch [240/445] time 0.064 (0.094) data 0.000 (0.003) loss 1.5721 (1.5440) teacher_loss 0.9987 (0.9403) loss_zs_kd 1.7286 (1.6129) loss_oracle 0.3153 (0.3286) acc 68.7500 (66.3151) lr 1.5358e-03 eta 0:22:32
epoch [18/50] batch [260/445] time 0.157 (0.094) data 0.000 (0.003) loss 1.3058 (1.5422) teacher_loss 0.8003 (0.9400) loss_zs_kd 1.5408 (1.6051) loss_oracle 0.3115 (0.3288) acc 78.1250 (66.4303) lr 1.5358e-03 eta 0:22:32
epoch [18/50] batch [280/445] time 0.073 (0.094) data 0.000 (0.002) loss 1.6397 (1.5439) teacher_loss 1.0014 (0.9408) loss_zs_kd 1.3104 (1.5909) loss_oracle 0.3436 (0.3290) acc 68.7500 (66.4621) lr 1.5358e-03 eta 0:22:28
epoch [18/50] batch [300/445] time 0.085 (0.092) data 0.000 (0.002) loss 1.9569 (1.5504) teacher_loss 1.2704 (0.9425) loss_zs_kd 1.8049 (1.5867) loss_oracle 0.3456 (0.3293) acc 50.0000 (66.4375) lr 1.5358e-03 eta 0:22:00
epoch [18/50] batch [320/445] time 0.085 (0.091) data 0.000 (0.002) loss 1.7479 (1.5572) teacher_loss 1.1147 (0.9457) loss_zs_kd 1.1918 (1.5831) loss_oracle 0.3401 (0.3291) acc 65.6250 (66.2988) lr 1.5358e-03 eta 0:21:51
epoch [18/50] batch [340/445] time 0.086 (0.091) data 0.000 (0.002) loss 1.4184 (1.5582) teacher_loss 0.7915 (0.9453) loss_zs_kd 1.9211 (1.5831) loss_oracle 0.3309 (0.3294) acc 75.0000 (66.2500) lr 1.5358e-03 eta 0:21:45
epoch [18/50] batch [360/445] time 0.087 (0.091) data 0.000 (0.002) loss 1.2659 (1.5570) teacher_loss 0.6656 (0.9431) loss_zs_kd 1.6532 (1.5800) loss_oracle 0.3152 (0.3290) acc 81.2500 (66.2847) lr 1.5358e-03 eta 0:21:39
epoch [18/50] batch [380/445] time 0.083 (0.090) data 0.000 (0.002) loss 1.4831 (1.5571) teacher_loss 0.8115 (0.9406) loss_zs_kd 1.4395 (1.5774) loss_oracle 0.3105 (0.3290) acc 68.7500 (66.3487) lr 1.5358e-03 eta 0:21:33
epoch [18/50] batch [400/445] time 0.085 (0.090) data 0.000 (0.002) loss 1.6167 (1.5609) teacher_loss 1.0013 (0.9415) loss_zs_kd 1.6374 (1.5751) loss_oracle 0.3152 (0.3291) acc 59.3750 (66.3359) lr 1.5358e-03 eta 0:21:28
epoch [18/50] batch [420/445] time 0.086 (0.090) data 0.000 (0.002) loss 1.3625 (1.5624) teacher_loss 0.7321 (0.9411) loss_zs_kd 1.2561 (1.5734) loss_oracle 0.3125 (0.3291) acc 71.8750 (66.3914) lr 1.5358e-03 eta 0:21:21
epoch [18/50] batch [440/445] time 0.082 (0.090) data 0.000 (0.002) loss 1.8442 (1.5667) teacher_loss 1.0964 (0.9427) loss_zs_kd 1.5057 (1.5729) loss_oracle 0.3364 (0.3292) acc 56.2500 (66.3494) lr 1.5358e-03 eta 0:21:15
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,298
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 56.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,081
* accuracy: 52.4%
* error: 47.6%
* macro_f1: 32.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [19/50] batch [20/445] time 0.158 (0.135) data 0.000 (0.026) loss 1.3550 (1.6037) teacher_loss 0.6726 (0.9509) loss_zs_kd 1.4838 (1.5500) loss_oracle 0.3152 (0.3261) acc 84.3750 (65.0000) lr 1.4818e-03 eta 0:32:01
epoch [19/50] batch [40/445] time 0.115 (0.112) data 0.000 (0.013) loss 1.6779 (1.6366) teacher_loss 1.0848 (0.9698) loss_zs_kd 1.5364 (1.5485) loss_oracle 0.3431 (0.3396) acc 62.5000 (64.7656) lr 1.4818e-03 eta 0:26:33
epoch [19/50] batch [60/445] time 0.073 (0.098) data 0.000 (0.009) loss 1.2931 (1.6142) teacher_loss 0.6432 (0.9603) loss_zs_kd 1.3061 (1.5936) loss_oracle 0.3771 (0.3368) acc 75.0000 (65.3646) lr 1.4818e-03 eta 0:23:09
epoch [19/50] batch [80/445] time 0.060 (0.095) data 0.000 (0.007) loss 1.5720 (1.6003) teacher_loss 0.8876 (0.9567) loss_zs_kd 1.3780 (1.5526) loss_oracle 0.3151 (0.3357) acc 68.7500 (65.6641) lr 1.4818e-03 eta 0:22:23
epoch [19/50] batch [100/445] time 0.056 (0.093) data 0.000 (0.006) loss 1.4655 (1.5859) teacher_loss 0.7620 (0.9431) loss_zs_kd 1.8320 (1.5628) loss_oracle 0.3152 (0.3339) acc 71.8750 (66.1250) lr 1.4818e-03 eta 0:21:49
epoch [19/50] batch [120/445] time 0.119 (0.093) data 0.000 (0.005) loss 1.5411 (1.5801) teacher_loss 0.8531 (0.9391) loss_zs_kd 1.3422 (1.5733) loss_oracle 0.3055 (0.3329) acc 75.0000 (66.2240) lr 1.4818e-03 eta 0:21:52
epoch [19/50] batch [140/445] time 0.149 (0.093) data 0.000 (0.004) loss 1.8406 (1.5828) teacher_loss 1.0870 (0.9357) loss_zs_kd 1.4491 (1.5648) loss_oracle 0.3461 (0.3317) acc 59.3750 (66.4286) lr 1.4818e-03 eta 0:21:46
epoch [19/50] batch [160/445] time 0.066 (0.092) data 0.000 (0.004) loss 1.9568 (1.5827) teacher_loss 1.2350 (0.9304) loss_zs_kd 1.8338 (1.5867) loss_oracle 0.3462 (0.3319) acc 53.1250 (66.5234) lr 1.4818e-03 eta 0:21:35
epoch [19/50] batch [180/445] time 0.061 (0.092) data 0.000 (0.003) loss 1.4584 (1.5755) teacher_loss 0.8818 (0.9202) loss_zs_kd 1.7006 (1.5883) loss_oracle 0.3128 (0.3318) acc 68.7500 (66.9618) lr 1.4818e-03 eta 0:21:38
epoch [19/50] batch [200/445] time 0.153 (0.092) data 0.000 (0.003) loss 1.2138 (1.5729) teacher_loss 0.5235 (0.9171) loss_zs_kd 1.3055 (1.5892) loss_oracle 0.3462 (0.3321) acc 87.5000 (67.1875) lr 1.4818e-03 eta 0:21:36
epoch [19/50] batch [220/445] time 0.157 (0.091) data 0.000 (0.003) loss 1.6104 (1.5748) teacher_loss 0.9502 (0.9192) loss_zs_kd 1.3126 (1.5879) loss_oracle 0.3074 (0.3321) acc 62.5000 (66.9744) lr 1.4818e-03 eta 0:21:16
epoch [19/50] batch [240/445] time 0.093 (0.089) data 0.000 (0.002) loss 1.5146 (1.5731) teacher_loss 0.9451 (0.9191) loss_zs_kd 1.9142 (1.5948) loss_oracle 0.3257 (0.3312) acc 65.6250 (67.0182) lr 1.4818e-03 eta 0:20:51
epoch [19/50] batch [260/445] time 0.093 (0.090) data 0.000 (0.002) loss 1.2794 (1.5663) teacher_loss 0.6477 (0.9147) loss_zs_kd 1.7562 (1.5986) loss_oracle 0.3311 (0.3315) acc 78.1250 (67.1995) lr 1.4818e-03 eta 0:20:51
epoch [19/50] batch [280/445] time 0.082 (0.089) data 0.000 (0.002) loss 1.6840 (1.5670) teacher_loss 0.9708 (0.9173) loss_zs_kd 1.7017 (1.5999) loss_oracle 0.3100 (0.3310) acc 65.6250 (67.2545) lr 1.4818e-03 eta 0:20:44
epoch [19/50] batch [300/445] time 0.089 (0.089) data 0.000 (0.002) loss 1.6718 (1.5690) teacher_loss 1.0183 (0.9215) loss_zs_kd 1.4446 (1.6001) loss_oracle 0.3661 (0.3319) acc 62.5000 (67.1250) lr 1.4818e-03 eta 0:20:39
epoch [19/50] batch [320/445] time 0.081 (0.089) data 0.000 (0.002) loss 1.7762 (1.5688) teacher_loss 1.1141 (0.9233) loss_zs_kd 1.7467 (1.5999) loss_oracle 0.3672 (0.3322) acc 68.7500 (66.9629) lr 1.4818e-03 eta 0:20:33
epoch [19/50] batch [340/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.3635 (1.5684) teacher_loss 0.8263 (0.9237) loss_zs_kd 1.5105 (1.5956) loss_oracle 0.3210 (0.3325) acc 71.8750 (67.0221) lr 1.4818e-03 eta 0:20:29
epoch [19/50] batch [360/445] time 0.090 (0.088) data 0.000 (0.002) loss 1.4414 (1.5692) teacher_loss 0.7744 (0.9235) loss_zs_kd 1.8391 (1.5948) loss_oracle 0.3413 (0.3323) acc 71.8750 (67.0486) lr 1.4818e-03 eta 0:20:25
epoch [19/50] batch [380/445] time 0.085 (0.088) data 0.000 (0.002) loss 1.2114 (1.5693) teacher_loss 0.6702 (0.9238) loss_zs_kd 1.5271 (1.5955) loss_oracle 0.3125 (0.3322) acc 78.1250 (67.0724) lr 1.4818e-03 eta 0:20:20
epoch [19/50] batch [400/445] time 0.087 (0.088) data 0.000 (0.002) loss 1.5125 (1.5695) teacher_loss 0.8909 (0.9223) loss_zs_kd 1.7469 (1.5973) loss_oracle 0.3146 (0.3325) acc 68.7500 (67.1172) lr 1.4818e-03 eta 0:20:16
epoch [19/50] batch [420/445] time 0.092 (0.088) data 0.000 (0.002) loss 1.4700 (1.5674) teacher_loss 0.9204 (0.9218) loss_zs_kd 1.6899 (1.5965) loss_oracle 0.3062 (0.3324) acc 62.5000 (67.2247) lr 1.4818e-03 eta 0:20:13
epoch [19/50] batch [440/445] time 0.085 (0.088) data 0.000 (0.001) loss 1.2904 (1.5651) teacher_loss 0.7041 (0.9200) loss_zs_kd 1.3761 (1.6003) loss_oracle 0.3460 (0.3321) acc 78.1250 (67.2585) lr 1.4818e-03 eta 0:20:09
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,243
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 55.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,039
* accuracy: 51.4%
* error: 48.6%
* macro_f1: 31.0%
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [20/50] batch [20/445] time 0.075 (0.100) data 0.000 (0.026) loss 1.2450 (1.5033) teacher_loss 0.5919 (0.9026) loss_zs_kd 1.3534 (1.5568) loss_oracle 0.3110 (0.3246) acc 78.1250 (68.4375) lr 1.4258e-03 eta 0:22:56
epoch [20/50] batch [40/445] time 0.134 (0.093) data 0.000 (0.013) loss 1.6051 (1.5459) teacher_loss 0.8710 (0.9180) loss_zs_kd 1.9887 (1.5697) loss_oracle 0.3653 (0.3324) acc 65.6250 (67.8906) lr 1.4258e-03 eta 0:21:14
epoch [20/50] batch [60/445] time 0.083 (0.094) data 0.000 (0.009) loss 1.3767 (1.5508) teacher_loss 0.6514 (0.9193) loss_zs_kd 1.6778 (1.6066) loss_oracle 0.3166 (0.3317) acc 78.1250 (67.3958) lr 1.4258e-03 eta 0:21:29
epoch [20/50] batch [80/445] time 0.158 (0.094) data 0.000 (0.007) loss 1.8717 (1.5683) teacher_loss 1.2762 (0.9285) loss_zs_kd 1.1138 (1.5739) loss_oracle 0.3120 (0.3286) acc 56.2500 (66.8359) lr 1.4258e-03 eta 0:21:24
epoch [20/50] batch [100/445] time 0.120 (0.093) data 0.000 (0.005) loss 1.9559 (1.5764) teacher_loss 1.1490 (0.9272) loss_zs_kd 1.4411 (1.5620) loss_oracle 0.3766 (0.3300) acc 59.3750 (66.7500) lr 1.4258e-03 eta 0:21:20
epoch [20/50] batch [120/445] time 0.125 (0.095) data 0.000 (0.005) loss 1.6993 (1.5939) teacher_loss 0.9986 (0.9395) loss_zs_kd 1.7527 (1.5806) loss_oracle 0.3149 (0.3292) acc 50.0000 (66.2500) lr 1.4258e-03 eta 0:21:37
epoch [20/50] batch [140/445] time 0.067 (0.096) data 0.000 (0.004) loss 1.4906 (1.5856) teacher_loss 0.8789 (0.9362) loss_zs_kd 1.5825 (1.5632) loss_oracle 0.3109 (0.3299) acc 75.0000 (66.5848) lr 1.4258e-03 eta 0:21:49
epoch [20/50] batch [160/445] time 0.070 (0.095) data 0.000 (0.003) loss 1.4661 (1.5874) teacher_loss 0.8330 (0.9401) loss_zs_kd 1.6493 (1.5592) loss_oracle 0.3150 (0.3297) acc 71.8750 (66.6211) lr 1.4258e-03 eta 0:21:32
epoch [20/50] batch [180/445] time 0.064 (0.094) data 0.000 (0.003) loss 1.6951 (1.5813) teacher_loss 1.0311 (0.9371) loss_zs_kd 1.9189 (1.5663) loss_oracle 0.3119 (0.3295) acc 53.1250 (66.8056) lr 1.4258e-03 eta 0:21:17
epoch [20/50] batch [200/445] time 0.090 (0.093) data 0.000 (0.003) loss 2.1998 (1.5734) teacher_loss 1.5395 (0.9340) loss_zs_kd 1.9737 (1.5824) loss_oracle 0.3456 (0.3286) acc 53.1250 (67.0625) lr 1.4258e-03 eta 0:21:05
epoch [20/50] batch [220/445] time 0.088 (0.092) data 0.000 (0.003) loss 1.3452 (1.5678) teacher_loss 0.6841 (0.9315) loss_zs_kd 1.2035 (1.5940) loss_oracle 0.3402 (0.3287) acc 81.2500 (67.0739) lr 1.4258e-03 eta 0:20:53
epoch [20/50] batch [240/445] time 0.080 (0.092) data 0.000 (0.002) loss 1.9966 (1.5730) teacher_loss 1.2494 (0.9361) loss_zs_kd 1.6038 (1.5894) loss_oracle 0.3416 (0.3285) acc 53.1250 (66.9271) lr 1.4258e-03 eta 0:20:43
epoch [20/50] batch [260/445] time 0.079 (0.091) data 0.000 (0.002) loss 1.9776 (1.5693) teacher_loss 1.3044 (0.9309) loss_zs_kd 1.5930 (1.6020) loss_oracle 0.3771 (0.3294) acc 56.2500 (67.1274) lr 1.4258e-03 eta 0:20:33
epoch [20/50] batch [280/445] time 0.088 (0.091) data 0.000 (0.002) loss 1.4131 (1.5677) teacher_loss 0.7745 (0.9287) loss_zs_kd 1.6777 (1.6087) loss_oracle 0.3113 (0.3296) acc 78.1250 (67.2433) lr 1.4258e-03 eta 0:20:26
epoch [20/50] batch [300/445] time 0.100 (0.090) data 0.000 (0.002) loss 1.8347 (1.5690) teacher_loss 1.0941 (0.9286) loss_zs_kd 2.1301 (1.6200) loss_oracle 0.3761 (0.3298) acc 53.1250 (67.3958) lr 1.4258e-03 eta 0:20:16
epoch [20/50] batch [320/445] time 0.085 (0.090) data 0.000 (0.002) loss 1.6350 (1.5709) teacher_loss 0.8537 (0.9308) loss_zs_kd 1.9325 (1.6288) loss_oracle 0.4079 (0.3302) acc 75.0000 (67.3242) lr 1.4258e-03 eta 0:20:11
epoch [20/50] batch [340/445] time 0.087 (0.090) data 0.000 (0.002) loss 1.8303 (1.5703) teacher_loss 1.2470 (0.9322) loss_zs_kd 1.7935 (1.6264) loss_oracle 0.3054 (0.3299) acc 50.0000 (67.2702) lr 1.4258e-03 eta 0:20:05
epoch [20/50] batch [360/445] time 0.083 (0.089) data 0.000 (0.002) loss 1.5027 (1.5652) teacher_loss 0.8375 (0.9279) loss_zs_kd 1.9280 (1.6232) loss_oracle 0.3151 (0.3296) acc 71.8750 (67.4392) lr 1.4258e-03 eta 0:19:58
epoch [20/50] batch [380/445] time 0.093 (0.089) data 0.001 (0.002) loss 1.8732 (1.5645) teacher_loss 1.2986 (0.9277) loss_zs_kd 1.8191 (1.6258) loss_oracle 0.3240 (0.3297) acc 50.0000 (67.3602) lr 1.4258e-03 eta 0:19:58
epoch [20/50] batch [400/445] time 0.070 (0.089) data 0.000 (0.002) loss 1.2400 (1.5641) teacher_loss 0.7170 (0.9266) loss_zs_kd 1.9111 (1.6298) loss_oracle 0.3460 (0.3296) acc 78.1250 (67.4844) lr 1.4258e-03 eta 0:19:54
epoch [20/50] batch [420/445] time 0.089 (0.089) data 0.000 (0.002) loss 1.3023 (1.5609) teacher_loss 0.8215 (0.9264) loss_zs_kd 1.8070 (1.6286) loss_oracle 0.3150 (0.3292) acc 65.6250 (67.4554) lr 1.4258e-03 eta 0:19:49
epoch [20/50] batch [440/445] time 0.076 (0.088) data 0.000 (0.001) loss 1.5573 (1.5581) teacher_loss 1.0218 (0.9250) loss_zs_kd 1.7956 (1.6298) loss_oracle 0.3386 (0.3290) acc 53.1250 (67.5213) lr 1.4258e-03 eta 0:19:39
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,289
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 56.2%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,973
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 30.9%
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [21/50] batch [20/445] time 0.059 (0.120) data 0.000 (0.024) loss 1.4420 (1.5365) teacher_loss 0.8801 (0.9208) loss_zs_kd 1.8282 (1.7050) loss_oracle 0.3150 (0.3269) acc 75.0000 (67.8125) lr 1.3681e-03 eta 0:26:39
epoch [21/50] batch [40/445] time 0.126 (0.104) data 0.000 (0.012) loss 1.3601 (1.5320) teacher_loss 0.7022 (0.9042) loss_zs_kd 1.4672 (1.6661) loss_oracle 0.3691 (0.3330) acc 71.8750 (66.9531) lr 1.3681e-03 eta 0:23:03
epoch [21/50] batch [60/445] time 0.066 (0.103) data 0.001 (0.008) loss 1.3477 (1.5179) teacher_loss 0.8674 (0.9034) loss_zs_kd 1.7546 (1.6466) loss_oracle 0.3149 (0.3318) acc 62.5000 (67.2917) lr 1.3681e-03 eta 0:22:42
epoch [21/50] batch [80/445] time 0.050 (0.101) data 0.000 (0.006) loss 1.4324 (1.5344) teacher_loss 0.7749 (0.9196) loss_zs_kd 1.4685 (1.6405) loss_oracle 0.3150 (0.3301) acc 68.7500 (66.9922) lr 1.3681e-03 eta 0:22:25
epoch [21/50] batch [100/445] time 0.080 (0.095) data 0.000 (0.005) loss 1.5972 (1.5368) teacher_loss 0.9726 (0.9177) loss_zs_kd 1.7643 (1.6348) loss_oracle 0.3458 (0.3288) acc 65.6250 (67.0312) lr 1.3681e-03 eta 0:20:57
epoch [21/50] batch [120/445] time 0.083 (0.093) data 0.000 (0.004) loss 1.6657 (1.5577) teacher_loss 1.1485 (0.9380) loss_zs_kd 1.2425 (1.6264) loss_oracle 0.3117 (0.3292) acc 59.3750 (66.8490) lr 1.3681e-03 eta 0:20:35
epoch [21/50] batch [140/445] time 0.082 (0.092) data 0.000 (0.004) loss 1.3729 (1.5469) teacher_loss 0.6938 (0.9295) loss_zs_kd 2.0254 (1.6072) loss_oracle 0.3410 (0.3298) acc 78.1250 (67.0089) lr 1.3681e-03 eta 0:20:18
epoch [21/50] batch [160/445] time 0.084 (0.091) data 0.000 (0.003) loss 1.6758 (1.5471) teacher_loss 0.8665 (0.9286) loss_zs_kd 1.1096 (1.6008) loss_oracle 0.3769 (0.3300) acc 68.7500 (67.0898) lr 1.3681e-03 eta 0:20:04
epoch [21/50] batch [180/445] time 0.082 (0.091) data 0.000 (0.003) loss 1.3206 (1.5456) teacher_loss 0.7849 (0.9269) loss_zs_kd 1.9097 (1.6147) loss_oracle 0.3149 (0.3315) acc 68.7500 (67.3090) lr 1.3681e-03 eta 0:19:51
epoch [21/50] batch [200/445] time 0.086 (0.090) data 0.000 (0.003) loss 1.5809 (1.5426) teacher_loss 1.0062 (0.9266) loss_zs_kd 1.1446 (1.6165) loss_oracle 0.3460 (0.3320) acc 65.6250 (67.1562) lr 1.3681e-03 eta 0:19:42
epoch [21/50] batch [220/445] time 0.085 (0.089) data 0.000 (0.002) loss 1.2640 (1.5382) teacher_loss 0.6349 (0.9235) loss_zs_kd 1.4897 (1.6143) loss_oracle 0.3459 (0.3317) acc 78.1250 (67.3864) lr 1.3681e-03 eta 0:19:34
epoch [21/50] batch [240/445] time 0.086 (0.089) data 0.000 (0.002) loss 1.3888 (1.5385) teacher_loss 0.8587 (0.9238) loss_zs_kd 1.5832 (1.6198) loss_oracle 0.3149 (0.3315) acc 68.7500 (67.2656) lr 1.3681e-03 eta 0:19:28
epoch [21/50] batch [260/445] time 0.081 (0.089) data 0.000 (0.002) loss 1.3596 (1.5358) teacher_loss 0.7208 (0.9218) loss_zs_kd 1.7600 (1.6224) loss_oracle 0.3394 (0.3317) acc 78.1250 (67.4760) lr 1.3681e-03 eta 0:19:22
epoch [21/50] batch [280/445] time 0.090 (0.089) data 0.000 (0.002) loss 1.6795 (1.5398) teacher_loss 1.1836 (0.9286) loss_zs_kd 1.4645 (1.6309) loss_oracle 0.3149 (0.3314) acc 59.3750 (67.2656) lr 1.3681e-03 eta 0:19:17
epoch [21/50] batch [300/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.3908 (1.5398) teacher_loss 0.8161 (0.9281) loss_zs_kd 2.0869 (1.6349) loss_oracle 0.3459 (0.3313) acc 71.8750 (67.2188) lr 1.3681e-03 eta 0:19:12
epoch [21/50] batch [320/445] time 0.088 (0.088) data 0.000 (0.002) loss 1.6054 (1.5442) teacher_loss 1.0341 (0.9310) loss_zs_kd 1.4144 (1.6385) loss_oracle 0.3459 (0.3310) acc 68.7500 (67.0801) lr 1.3681e-03 eta 0:19:07
epoch [21/50] batch [340/445] time 0.085 (0.088) data 0.000 (0.002) loss 1.7408 (1.5466) teacher_loss 1.0538 (0.9320) loss_zs_kd 1.9228 (1.6491) loss_oracle 0.3422 (0.3306) acc 59.3750 (67.0496) lr 1.3681e-03 eta 0:19:03
epoch [21/50] batch [360/445] time 0.092 (0.088) data 0.000 (0.002) loss 1.5992 (1.5437) teacher_loss 0.9442 (0.9286) loss_zs_kd 1.8678 (1.6536) loss_oracle 0.3895 (0.3313) acc 62.5000 (67.1007) lr 1.3681e-03 eta 0:18:59
epoch [21/50] batch [380/445] time 0.085 (0.088) data 0.000 (0.002) loss 1.7898 (1.5458) teacher_loss 0.9967 (0.9293) loss_zs_kd 1.6265 (1.6557) loss_oracle 0.3478 (0.3314) acc 68.7500 (67.0395) lr 1.3681e-03 eta 0:18:55
epoch [21/50] batch [400/445] time 0.087 (0.087) data 0.000 (0.001) loss 1.8267 (1.5455) teacher_loss 1.1936 (0.9283) loss_zs_kd 1.6067 (1.6546) loss_oracle 0.3459 (0.3315) acc 46.8750 (67.1016) lr 1.3681e-03 eta 0:18:52
epoch [21/50] batch [420/445] time 0.068 (0.087) data 0.000 (0.001) loss 1.6278 (1.5477) teacher_loss 0.9863 (0.9292) loss_zs_kd 1.7500 (1.6610) loss_oracle 0.3056 (0.3311) acc 62.5000 (67.0015) lr 1.3681e-03 eta 0:18:45
epoch [21/50] batch [440/445] time 0.152 (0.086) data 0.000 (0.001) loss 1.4414 (1.5449) teacher_loss 0.9174 (0.9259) loss_zs_kd 1.6698 (1.6695) loss_oracle 0.3148 (0.3308) acc 68.7500 (67.1520) lr 1.3681e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,281
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 56.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,020
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 31.4%
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [22/50] batch [20/445] time 0.120 (0.115) data 0.000 (0.026) loss 1.0622 (1.5436) teacher_loss 0.5105 (0.9026) loss_zs_kd 1.8775 (1.8712) loss_oracle 0.3994 (0.3447) acc 75.0000 (66.7188) lr 1.3090e-03 eta 0:24:40
epoch [22/50] batch [40/445] time 0.066 (0.096) data 0.000 (0.013) loss 1.2736 (1.5222) teacher_loss 0.5946 (0.8901) loss_zs_kd 1.6573 (1.8807) loss_oracle 0.3149 (0.3353) acc 78.1250 (67.1875) lr 1.3090e-03 eta 0:20:34
epoch [22/50] batch [60/445] time 0.087 (0.093) data 0.000 (0.009) loss 1.6633 (1.5577) teacher_loss 1.0649 (0.9172) loss_zs_kd 1.9088 (1.8411) loss_oracle 0.3459 (0.3372) acc 59.3750 (66.6146) lr 1.3090e-03 eta 0:19:53
epoch [22/50] batch [80/445] time 0.083 (0.091) data 0.000 (0.007) loss 1.4963 (1.5389) teacher_loss 0.8668 (0.9073) loss_zs_kd 1.8055 (1.7947) loss_oracle 0.3458 (0.3354) acc 68.7500 (67.3047) lr 1.3090e-03 eta 0:19:27
epoch [22/50] batch [100/445] time 0.085 (0.090) data 0.000 (0.005) loss 1.5351 (1.5502) teacher_loss 0.8715 (0.9201) loss_zs_kd 1.7595 (1.7650) loss_oracle 0.3459 (0.3325) acc 71.8750 (67.3438) lr 1.3090e-03 eta 0:19:12
epoch [22/50] batch [120/445] time 0.085 (0.089) data 0.000 (0.005) loss 1.3300 (1.5516) teacher_loss 0.6831 (0.9228) loss_zs_kd 1.2805 (1.7380) loss_oracle 0.3148 (0.3309) acc 71.8750 (67.1615) lr 1.3090e-03 eta 0:18:58
epoch [22/50] batch [140/445] time 0.081 (0.088) data 0.000 (0.004) loss 1.5166 (1.5446) teacher_loss 0.8328 (0.9181) loss_zs_kd 1.2247 (1.7335) loss_oracle 0.3362 (0.3307) acc 71.8750 (67.3438) lr 1.3090e-03 eta 0:18:48
epoch [22/50] batch [160/445] time 0.080 (0.088) data 0.000 (0.003) loss 1.5397 (1.5432) teacher_loss 0.9464 (0.9232) loss_zs_kd 1.9462 (1.7235) loss_oracle 0.3398 (0.3302) acc 62.5000 (67.2461) lr 1.3090e-03 eta 0:18:41
epoch [22/50] batch [180/445] time 0.087 (0.088) data 0.000 (0.003) loss 1.2154 (1.5301) teacher_loss 0.7191 (0.9144) loss_zs_kd 1.5558 (1.7175) loss_oracle 0.3148 (0.3289) acc 71.8750 (67.6042) lr 1.3090e-03 eta 0:18:34
epoch [22/50] batch [200/445] time 0.107 (0.088) data 0.000 (0.003) loss 1.5239 (1.5245) teacher_loss 0.8695 (0.9124) loss_zs_kd 2.0102 (1.7210) loss_oracle 0.3149 (0.3290) acc 68.7500 (68.0000) lr 1.3090e-03 eta 0:18:39
epoch [22/50] batch [220/445] time 0.085 (0.088) data 0.000 (0.003) loss 1.4895 (1.5266) teacher_loss 0.8093 (0.9138) loss_zs_kd 1.6367 (1.7214) loss_oracle 0.3459 (0.3286) acc 65.6250 (67.8125) lr 1.3090e-03 eta 0:18:34
epoch [22/50] batch [240/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.5509 (1.5238) teacher_loss 0.8996 (0.9101) loss_zs_kd 1.3088 (1.6946) loss_oracle 0.4002 (0.3288) acc 75.0000 (68.0078) lr 1.3090e-03 eta 0:18:29
epoch [22/50] batch [260/445] time 0.083 (0.088) data 0.000 (0.002) loss 1.4682 (1.5228) teacher_loss 0.8752 (0.9082) loss_zs_kd 1.6790 (1.6797) loss_oracle 0.3391 (0.3296) acc 59.3750 (67.9327) lr 1.3090e-03 eta 0:18:26
epoch [22/50] batch [280/445] time 0.086 (0.087) data 0.000 (0.002) loss 1.5958 (1.5291) teacher_loss 0.9472 (0.9137) loss_zs_kd 1.2843 (1.6835) loss_oracle 0.3767 (0.3308) acc 62.5000 (67.6897) lr 1.3090e-03 eta 0:18:22
epoch [22/50] batch [300/445] time 0.079 (0.087) data 0.000 (0.002) loss 1.2489 (1.5276) teacher_loss 0.7075 (0.9129) loss_zs_kd 1.5389 (1.6849) loss_oracle 0.3458 (0.3311) acc 68.7500 (67.8438) lr 1.3090e-03 eta 0:18:18
epoch [22/50] batch [320/445] time 0.088 (0.087) data 0.000 (0.002) loss 1.5879 (1.5245) teacher_loss 1.0438 (0.9115) loss_zs_kd 1.7678 (1.6905) loss_oracle 0.3282 (0.3313) acc 56.2500 (67.8711) lr 1.3090e-03 eta 0:18:15
epoch [22/50] batch [340/445] time 0.090 (0.087) data 0.000 (0.002) loss 1.5945 (1.5257) teacher_loss 1.0311 (0.9137) loss_zs_kd 1.4599 (1.6815) loss_oracle 0.3148 (0.3316) acc 62.5000 (67.7665) lr 1.3090e-03 eta 0:18:12
epoch [22/50] batch [360/445] time 0.064 (0.086) data 0.001 (0.002) loss 1.5438 (1.5270) teacher_loss 0.9655 (0.9158) loss_zs_kd 1.5360 (1.6767) loss_oracle 0.3138 (0.3317) acc 65.6250 (67.6389) lr 1.3090e-03 eta 0:18:04
epoch [22/50] batch [380/445] time 0.073 (0.086) data 0.000 (0.002) loss 1.4402 (1.5230) teacher_loss 0.8358 (0.9128) loss_zs_kd 1.9314 (1.6739) loss_oracle 0.3148 (0.3317) acc 68.7500 (67.6645) lr 1.3090e-03 eta 0:17:52
epoch [22/50] batch [400/445] time 0.148 (0.086) data 0.000 (0.002) loss 1.4595 (1.5265) teacher_loss 0.8353 (0.9162) loss_zs_kd 1.6363 (1.6751) loss_oracle 0.3768 (0.3325) acc 75.0000 (67.5781) lr 1.3090e-03 eta 0:17:56
epoch [22/50] batch [420/445] time 0.095 (0.086) data 0.000 (0.002) loss 1.3417 (1.5301) teacher_loss 0.7042 (0.9189) loss_zs_kd 1.4540 (1.6699) loss_oracle 0.3051 (0.3328) acc 78.1250 (67.5521) lr 1.3090e-03 eta 0:17:58
epoch [22/50] batch [440/445] time 0.063 (0.086) data 0.001 (0.001) loss 1.6519 (1.5312) teacher_loss 0.9943 (0.9202) loss_zs_kd 1.5637 (1.6648) loss_oracle 0.3349 (0.3331) acc 65.6250 (67.5142) lr 1.3090e-03 eta 0:17:57
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,192
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 54.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,989
* accuracy: 50.1%
* error: 49.9%
* macro_f1: 30.1%
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [23/50] batch [20/445] time 0.062 (0.116) data 0.000 (0.029) loss 1.6060 (1.4747) teacher_loss 0.8792 (0.8690) loss_zs_kd 1.4417 (1.6293) loss_oracle 0.3458 (0.3306) acc 75.0000 (69.6875) lr 1.2487e-03 eta 0:24:04
epoch [23/50] batch [40/445] time 0.091 (0.101) data 0.000 (0.015) loss 1.1109 (1.4599) teacher_loss 0.5363 (0.8533) loss_zs_kd 1.7153 (1.5826) loss_oracle 0.3458 (0.3363) acc 81.2500 (68.8281) lr 1.2487e-03 eta 0:20:49
epoch [23/50] batch [60/445] time 0.087 (0.095) data 0.000 (0.010) loss 1.8595 (1.4774) teacher_loss 1.1705 (0.8728) loss_zs_kd 1.5330 (1.6053) loss_oracle 0.3767 (0.3396) acc 62.5000 (68.6458) lr 1.2487e-03 eta 0:19:38
epoch [23/50] batch [80/445] time 0.084 (0.092) data 0.000 (0.008) loss 1.7906 (1.4906) teacher_loss 1.1018 (0.8889) loss_zs_kd 1.9381 (1.5992) loss_oracle 0.3457 (0.3370) acc 59.3750 (67.9688) lr 1.2487e-03 eta 0:19:01
epoch [23/50] batch [100/445] time 0.084 (0.091) data 0.000 (0.006) loss 1.4293 (1.4871) teacher_loss 0.7826 (0.8864) loss_zs_kd 1.7216 (1.5992) loss_oracle 0.3675 (0.3381) acc 68.7500 (68.1562) lr 1.2487e-03 eta 0:18:42
epoch [23/50] batch [120/445] time 0.080 (0.090) data 0.000 (0.005) loss 1.5088 (1.5037) teacher_loss 0.8923 (0.8982) loss_zs_kd 1.4994 (1.6133) loss_oracle 0.3147 (0.3375) acc 71.8750 (67.9688) lr 1.2487e-03 eta 0:18:26
epoch [23/50] batch [140/445] time 0.084 (0.089) data 0.000 (0.004) loss 1.2786 (1.5084) teacher_loss 0.7976 (0.8964) loss_zs_kd 1.5455 (1.6293) loss_oracle 0.3458 (0.3388) acc 65.6250 (67.9241) lr 1.2487e-03 eta 0:18:15
epoch [23/50] batch [160/445] time 0.083 (0.088) data 0.000 (0.004) loss 1.4612 (1.5135) teacher_loss 0.8154 (0.8985) loss_zs_kd 1.3721 (1.6328) loss_oracle 0.3715 (0.3402) acc 75.0000 (67.8516) lr 1.2487e-03 eta 0:18:06
epoch [23/50] batch [180/445] time 0.085 (0.088) data 0.000 (0.003) loss 1.7432 (1.5184) teacher_loss 1.1886 (0.9036) loss_zs_kd 1.6021 (1.6204) loss_oracle 0.3137 (0.3401) acc 56.2500 (67.4826) lr 1.2487e-03 eta 0:17:59
epoch [23/50] batch [200/445] time 0.074 (0.087) data 0.000 (0.003) loss 1.1478 (1.5188) teacher_loss 0.5372 (0.9039) loss_zs_kd 1.5394 (1.6180) loss_oracle 0.3735 (0.3402) acc 81.2500 (67.2188) lr 1.2487e-03 eta 0:17:51
epoch [23/50] batch [220/445] time 0.083 (0.087) data 0.000 (0.003) loss 1.4856 (1.5206) teacher_loss 0.8777 (0.9039) loss_zs_kd 1.7694 (1.6251) loss_oracle 0.3147 (0.3395) acc 75.0000 (67.1591) lr 1.2487e-03 eta 0:17:43
epoch [23/50] batch [240/445] time 0.081 (0.087) data 0.000 (0.003) loss 1.6186 (1.5294) teacher_loss 0.9447 (0.9112) loss_zs_kd 1.7437 (1.6343) loss_oracle 0.3147 (0.3391) acc 65.6250 (67.0703) lr 1.2487e-03 eta 0:17:38
epoch [23/50] batch [260/445] time 0.085 (0.086) data 0.000 (0.002) loss 1.4310 (1.5338) teacher_loss 0.8438 (0.9173) loss_zs_kd 1.3607 (1.6300) loss_oracle 0.3147 (0.3383) acc 71.8750 (66.8149) lr 1.2487e-03 eta 0:17:35
epoch [23/50] batch [280/445] time 0.085 (0.086) data 0.000 (0.002) loss 1.3252 (1.5390) teacher_loss 0.7528 (0.9201) loss_zs_kd 1.2996 (1.6317) loss_oracle 0.3742 (0.3383) acc 75.0000 (66.7746) lr 1.2487e-03 eta 0:17:31
epoch [23/50] batch [300/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.4234 (1.5379) teacher_loss 0.8335 (0.9184) loss_zs_kd 2.1018 (1.6364) loss_oracle 0.3137 (0.3380) acc 78.1250 (66.8646) lr 1.2487e-03 eta 0:17:29
epoch [23/50] batch [320/445] time 0.070 (0.086) data 0.000 (0.002) loss 1.0999 (1.5343) teacher_loss 0.5780 (0.9156) loss_zs_kd 1.5410 (1.6415) loss_oracle 0.3105 (0.3377) acc 78.1250 (67.0215) lr 1.2487e-03 eta 0:17:19
epoch [23/50] batch [340/445] time 0.074 (0.086) data 0.000 (0.002) loss 1.6634 (1.5328) teacher_loss 0.9831 (0.9150) loss_zs_kd 1.7825 (1.6412) loss_oracle 0.3137 (0.3375) acc 53.1250 (67.0680) lr 1.2487e-03 eta 0:17:19
epoch [23/50] batch [360/445] time 0.064 (0.086) data 0.000 (0.002) loss 1.5631 (1.5341) teacher_loss 1.0372 (0.9157) loss_zs_kd 1.5935 (1.6412) loss_oracle 0.3147 (0.3372) acc 62.5000 (67.0399) lr 1.2487e-03 eta 0:17:23
epoch [23/50] batch [380/445] time 0.129 (0.087) data 0.000 (0.002) loss 1.4894 (1.5340) teacher_loss 0.8943 (0.9164) loss_zs_kd 1.6554 (1.6416) loss_oracle 0.3148 (0.3368) acc 68.7500 (67.0559) lr 1.2487e-03 eta 0:17:25
epoch [23/50] batch [400/445] time 0.076 (0.087) data 0.000 (0.002) loss 1.7155 (1.5377) teacher_loss 1.0550 (0.9207) loss_zs_kd 1.8081 (1.6462) loss_oracle 0.3381 (0.3365) acc 71.8750 (66.8672) lr 1.2487e-03 eta 0:17:26
epoch [23/50] batch [420/445] time 0.070 (0.086) data 0.000 (0.002) loss 1.3460 (1.5372) teacher_loss 0.7446 (0.9208) loss_zs_kd 1.7038 (1.6538) loss_oracle 0.2954 (0.3364) acc 75.0000 (66.8750) lr 1.2487e-03 eta 0:17:17
epoch [23/50] batch [440/445] time 0.127 (0.086) data 0.000 (0.002) loss 1.2533 (1.5340) teacher_loss 0.5984 (0.9184) loss_zs_kd 1.7813 (1.6590) loss_oracle 0.3660 (0.3362) acc 78.1250 (67.0170) lr 1.2487e-03 eta 0:17:16
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,198
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 55.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,019
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 30.7%
******* Domain 3 best val acc:      70.4%, epoch: 18 *******
******* Domain 3 best val test acc: 52.4%, epoch: 18 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [24/50] batch [20/445] time 0.082 (0.092) data 0.000 (0.023) loss 1.6403 (1.5296) teacher_loss 1.0256 (0.9084) loss_zs_kd 1.7598 (1.7585) loss_oracle 0.3361 (0.3370) acc 65.6250 (69.2188) lr 1.1874e-03 eta 0:18:23
epoch [24/50] batch [40/445] time 0.084 (0.089) data 0.000 (0.012) loss 1.9253 (1.5583) teacher_loss 1.2754 (0.9293) loss_zs_kd 2.2834 (1.7833) loss_oracle 0.3148 (0.3390) acc 56.2500 (68.7500) lr 1.1874e-03 eta 0:17:46
epoch [24/50] batch [60/445] time 0.077 (0.088) data 0.000 (0.008) loss 1.5501 (1.5450) teacher_loss 0.9875 (0.9197) loss_zs_kd 1.6542 (1.7925) loss_oracle 0.3703 (0.3364) acc 65.6250 (68.6458) lr 1.1874e-03 eta 0:17:26
epoch [24/50] batch [80/445] time 0.086 (0.089) data 0.000 (0.006) loss 1.5013 (1.5477) teacher_loss 0.9089 (0.9285) loss_zs_kd 1.7359 (1.7697) loss_oracle 0.3148 (0.3364) acc 65.6250 (68.3984) lr 1.1874e-03 eta 0:17:41
epoch [24/50] batch [100/445] time 0.084 (0.088) data 0.000 (0.005) loss 1.6802 (1.5441) teacher_loss 1.0156 (0.9266) loss_zs_kd 1.7914 (1.7669) loss_oracle 0.3000 (0.3345) acc 65.6250 (67.9062) lr 1.1874e-03 eta 0:17:32
epoch [24/50] batch [120/445] time 0.086 (0.088) data 0.000 (0.004) loss 1.3054 (1.5471) teacher_loss 0.8009 (0.9333) loss_zs_kd 1.8365 (1.7624) loss_oracle 0.3147 (0.3337) acc 68.7500 (67.6823) lr 1.1874e-03 eta 0:17:24
epoch [24/50] batch [140/445] time 0.075 (0.088) data 0.000 (0.004) loss 1.1350 (1.5370) teacher_loss 0.6298 (0.9247) loss_zs_kd 2.1043 (1.7716) loss_oracle 0.3147 (0.3335) acc 71.8750 (67.5893) lr 1.1874e-03 eta 0:17:19
epoch [24/50] batch [160/445] time 0.086 (0.087) data 0.000 (0.003) loss 1.6172 (1.5381) teacher_loss 0.9428 (0.9280) loss_zs_kd 1.6285 (1.7907) loss_oracle 0.3144 (0.3320) acc 68.7500 (67.2656) lr 1.1874e-03 eta 0:17:12
epoch [24/50] batch [180/445] time 0.083 (0.087) data 0.000 (0.003) loss 1.3773 (1.5266) teacher_loss 0.7266 (0.9161) loss_zs_kd 2.0335 (1.7927) loss_oracle 0.3147 (0.3314) acc 75.0000 (67.7778) lr 1.1874e-03 eta 0:17:07
epoch [24/50] batch [200/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.2837 (1.5228) teacher_loss 0.7014 (0.9137) loss_zs_kd 1.8676 (1.7890) loss_oracle 0.3458 (0.3304) acc 78.1250 (67.9844) lr 1.1874e-03 eta 0:17:03
epoch [24/50] batch [220/445] time 0.088 (0.087) data 0.000 (0.002) loss 1.3697 (1.5244) teacher_loss 0.6570 (0.9144) loss_zs_kd 1.8201 (1.7794) loss_oracle 0.3147 (0.3295) acc 68.7500 (67.6705) lr 1.1874e-03 eta 0:17:00
epoch [24/50] batch [240/445] time 0.090 (0.086) data 0.000 (0.002) loss 1.5127 (1.5266) teacher_loss 0.8887 (0.9161) loss_zs_kd 1.6297 (1.7800) loss_oracle 0.3146 (0.3297) acc 68.7500 (67.6562) lr 1.1874e-03 eta 0:16:57
epoch [24/50] batch [260/445] time 0.082 (0.086) data 0.000 (0.002) loss 1.4978 (1.5224) teacher_loss 0.9182 (0.9108) loss_zs_kd 1.8261 (1.7879) loss_oracle 0.3147 (0.3298) acc 68.7500 (67.7764) lr 1.1874e-03 eta 0:16:53
epoch [24/50] batch [280/445] time 0.083 (0.085) data 0.000 (0.002) loss 1.7375 (1.5225) teacher_loss 1.1598 (0.9115) loss_zs_kd 2.0147 (1.7945) loss_oracle 0.3147 (0.3297) acc 56.2500 (67.7009) lr 1.1874e-03 eta 0:16:40
epoch [24/50] batch [300/445] time 0.059 (0.086) data 0.000 (0.002) loss 1.2115 (1.5238) teacher_loss 0.6628 (0.9110) loss_zs_kd 1.9983 (1.7878) loss_oracle 0.3127 (0.3301) acc 81.2500 (67.6979) lr 1.1874e-03 eta 0:16:47
epoch [24/50] batch [320/445] time 0.149 (0.086) data 0.000 (0.002) loss 1.5213 (1.5266) teacher_loss 0.8516 (0.9130) loss_zs_kd 1.7759 (1.7862) loss_oracle 0.3147 (0.3301) acc 62.5000 (67.5781) lr 1.1874e-03 eta 0:16:46
epoch [24/50] batch [340/445] time 0.049 (0.085) data 0.000 (0.002) loss 1.5011 (1.5257) teacher_loss 0.7783 (0.9107) loss_zs_kd 1.6622 (1.7858) loss_oracle 0.3457 (0.3302) acc 68.7500 (67.7390) lr 1.1874e-03 eta 0:16:36
epoch [24/50] batch [360/445] time 0.065 (0.085) data 0.000 (0.002) loss 1.6071 (1.5245) teacher_loss 0.9963 (0.9085) loss_zs_kd 1.5491 (1.7810) loss_oracle 0.3146 (0.3303) acc 56.2500 (67.8906) lr 1.1874e-03 eta 0:16:31
epoch [24/50] batch [380/445] time 0.068 (0.084) data 0.000 (0.001) loss 1.2956 (1.5287) teacher_loss 0.7102 (0.9109) loss_zs_kd 1.5418 (1.7797) loss_oracle 0.3147 (0.3303) acc 65.6250 (67.9441) lr 1.1874e-03 eta 0:16:20
epoch [24/50] batch [400/445] time 0.153 (0.085) data 0.000 (0.001) loss 1.1569 (1.5288) teacher_loss 0.5851 (0.9099) loss_zs_kd 1.5737 (1.7713) loss_oracle 0.3122 (0.3304) acc 81.2500 (67.9844) lr 1.1874e-03 eta 0:16:26
epoch [24/50] batch [420/445] time 0.062 (0.085) data 0.000 (0.001) loss 1.4932 (1.5279) teacher_loss 0.7733 (0.9077) loss_zs_kd 1.7859 (1.7708) loss_oracle 0.3147 (0.3305) acc 75.0000 (68.1176) lr 1.1874e-03 eta 0:16:29
epoch [24/50] batch [440/445] time 0.153 (0.085) data 0.000 (0.001) loss 1.3622 (1.5318) teacher_loss 0.7894 (0.9104) loss_zs_kd 1.4801 (1.7638) loss_oracle 0.3147 (0.3305) acc 78.1250 (68.0256) lr 1.1874e-03 eta 0:16:28
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,309
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,019
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 30.9%
******* Domain 3 best val acc:      70.5%, epoch: 24 *******
******* Domain 3 best val test acc: 50.9%, epoch: 24 *******
******* Domain 3 best test acc:     52.4%, epoch: 18 *******
epoch [25/50] batch [20/445] time 0.088 (0.116) data 0.000 (0.029) loss 1.4296 (1.6069) teacher_loss 0.8158 (0.9781) loss_zs_kd 1.5697 (1.5928) loss_oracle 0.3430 (0.3331) acc 65.6250 (66.2500) lr 1.1253e-03 eta 0:22:18
epoch [25/50] batch [40/445] time 0.083 (0.101) data 0.000 (0.015) loss 1.3229 (1.5443) teacher_loss 0.6803 (0.9225) loss_zs_kd 1.6959 (1.6344) loss_oracle 0.3146 (0.3300) acc 81.2500 (67.5781) lr 1.1253e-03 eta 0:19:23
epoch [25/50] batch [60/445] time 0.085 (0.096) data 0.000 (0.010) loss 1.6507 (1.5276) teacher_loss 1.0937 (0.9188) loss_zs_kd 1.9335 (1.6552) loss_oracle 0.3147 (0.3287) acc 62.5000 (66.9792) lr 1.1253e-03 eta 0:18:23
epoch [25/50] batch [80/445] time 0.086 (0.094) data 0.000 (0.007) loss 1.4566 (1.5436) teacher_loss 0.8729 (0.9224) loss_zs_kd 1.5341 (1.6686) loss_oracle 0.3106 (0.3286) acc 75.0000 (66.8750) lr 1.1253e-03 eta 0:17:54
epoch [25/50] batch [100/445] time 0.086 (0.092) data 0.000 (0.006) loss 1.5408 (1.5454) teacher_loss 0.9599 (0.9221) loss_zs_kd 1.7560 (1.6588) loss_oracle 0.3135 (0.3297) acc 65.6250 (67.0312) lr 1.1253e-03 eta 0:17:34
epoch [25/50] batch [120/445] time 0.083 (0.091) data 0.000 (0.005) loss 1.5069 (1.5377) teacher_loss 0.8747 (0.9168) loss_zs_kd 2.1418 (1.6598) loss_oracle 0.3132 (0.3301) acc 75.0000 (67.2135) lr 1.1253e-03 eta 0:17:20
epoch [25/50] batch [140/445] time 0.086 (0.090) data 0.000 (0.004) loss 1.9075 (1.5368) teacher_loss 1.2158 (0.9168) loss_zs_kd 1.7163 (1.6569) loss_oracle 0.3432 (0.3313) acc 46.8750 (67.1652) lr 1.1253e-03 eta 0:17:10
epoch [25/50] batch [160/445] time 0.086 (0.090) data 0.000 (0.004) loss 1.3341 (1.5333) teacher_loss 0.6775 (0.9113) loss_zs_kd 1.7353 (1.6606) loss_oracle 0.3141 (0.3328) acc 68.7500 (67.4609) lr 1.1253e-03 eta 0:17:02
epoch [25/50] batch [180/445] time 0.080 (0.089) data 0.000 (0.003) loss 1.4674 (1.5338) teacher_loss 0.8890 (0.9122) loss_zs_kd 1.6129 (1.6631) loss_oracle 0.3147 (0.3326) acc 65.6250 (67.6389) lr 1.1253e-03 eta 0:16:54
epoch [25/50] batch [200/445] time 0.106 (0.090) data 0.000 (0.003) loss 1.5498 (1.5314) teacher_loss 0.9198 (0.9112) loss_zs_kd 1.5266 (1.6725) loss_oracle 0.3367 (0.3325) acc 71.8750 (67.6719) lr 1.1253e-03 eta 0:17:01
epoch [25/50] batch [220/445] time 0.052 (0.087) data 0.000 (0.003) loss 1.3557 (1.5330) teacher_loss 0.7867 (0.9124) loss_zs_kd 2.1788 (1.6892) loss_oracle 0.3447 (0.3331) acc 68.7500 (67.5142) lr 1.1253e-03 eta 0:16:31
epoch [25/50] batch [240/445] time 0.071 (0.085) data 0.000 (0.003) loss 1.3077 (1.5319) teacher_loss 0.7184 (0.9125) loss_zs_kd 1.7018 (1.7012) loss_oracle 0.3457 (0.3321) acc 68.7500 (67.4219) lr 1.1253e-03 eta 0:16:06
epoch [25/50] batch [260/445] time 0.062 (0.086) data 0.000 (0.002) loss 1.4668 (1.5308) teacher_loss 0.9527 (0.9116) loss_zs_kd 1.5596 (1.7017) loss_oracle 0.3077 (0.3319) acc 62.5000 (67.5120) lr 1.1253e-03 eta 0:16:08
epoch [25/50] batch [280/445] time 0.071 (0.086) data 0.000 (0.002) loss 1.5301 (1.5313) teacher_loss 0.9447 (0.9096) loss_zs_kd 1.5103 (1.7051) loss_oracle 0.3127 (0.3326) acc 56.2500 (67.5112) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [300/445] time 0.144 (0.087) data 0.001 (0.002) loss 1.8868 (1.5344) teacher_loss 1.1057 (0.9105) loss_zs_kd 1.3334 (1.7117) loss_oracle 0.3767 (0.3327) acc 62.5000 (67.5729) lr 1.1253e-03 eta 0:16:15
epoch [25/50] batch [320/445] time 0.068 (0.087) data 0.000 (0.002) loss 1.3997 (1.5335) teacher_loss 0.7625 (0.9091) loss_zs_kd 1.8845 (1.7113) loss_oracle 0.3147 (0.3329) acc 68.7500 (67.6660) lr 1.1253e-03 eta 0:16:13
epoch [25/50] batch [340/445] time 0.152 (0.086) data 0.000 (0.002) loss 1.5015 (1.5393) teacher_loss 0.8180 (0.9129) loss_zs_kd 1.4592 (1.7067) loss_oracle 0.3138 (0.3329) acc 59.3750 (67.4908) lr 1.1253e-03 eta 0:16:05
epoch [25/50] batch [360/445] time 0.147 (0.086) data 0.000 (0.002) loss 1.3435 (1.5390) teacher_loss 0.6990 (0.9122) loss_zs_kd 1.9700 (1.7036) loss_oracle 0.3765 (0.3327) acc 78.1250 (67.4566) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [380/445] time 0.144 (0.087) data 0.001 (0.002) loss 1.6983 (1.5349) teacher_loss 1.0358 (0.9097) loss_zs_kd 1.8299 (1.7111) loss_oracle 0.3353 (0.3323) acc 68.7500 (67.5658) lr 1.1253e-03 eta 0:16:09
epoch [25/50] batch [400/445] time 0.052 (0.087) data 0.000 (0.002) loss 1.1409 (1.5315) teacher_loss 0.4938 (0.9063) loss_zs_kd 1.7472 (1.7118) loss_oracle 0.3116 (0.3321) acc 90.6250 (67.6953) lr 1.1253e-03 eta 0:16:13
epoch [25/50] batch [420/445] time 0.069 (0.087) data 0.000 (0.002) loss 1.6326 (1.5339) teacher_loss 1.0622 (0.9086) loss_zs_kd 2.0075 (1.7121) loss_oracle 0.3146 (0.3322) acc 59.3750 (67.7307) lr 1.1253e-03 eta 0:16:12
epoch [25/50] batch [440/445] time 0.071 (0.088) data 0.000 (0.002) loss 1.4893 (1.5350) teacher_loss 0.8767 (0.9100) loss_zs_kd 1.7092 (1.7196) loss_oracle 0.3094 (0.3320) acc 65.6250 (67.6989) lr 1.1253e-03 eta 0:16:15
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,265
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,093
* accuracy: 52.7%
* error: 47.3%
* macro_f1: 33.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 3 best val acc:      70.5%, epoch: 24 *******
******* Domain 3 best val test acc: 50.9%, epoch: 24 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [26/50] batch [20/445] time 0.088 (0.115) data 0.000 (0.027) loss 1.3241 (1.4871) teacher_loss 0.7192 (0.8741) loss_zs_kd 1.5421 (1.7278) loss_oracle 0.3146 (0.3306) acc 78.1250 (68.1250) lr 1.0628e-03 eta 0:21:12
epoch [26/50] batch [40/445] time 0.085 (0.100) data 0.000 (0.013) loss 1.3697 (1.4998) teacher_loss 0.7747 (0.8771) loss_zs_kd 1.4796 (1.7410) loss_oracle 0.3690 (0.3341) acc 71.8750 (68.7500) lr 1.0628e-03 eta 0:18:26
epoch [26/50] batch [60/445] time 0.068 (0.094) data 0.000 (0.009) loss 1.4000 (1.5159) teacher_loss 0.7811 (0.8970) loss_zs_kd 1.8797 (1.7404) loss_oracle 0.3146 (0.3337) acc 71.8750 (67.7604) lr 1.0628e-03 eta 0:17:21
epoch [26/50] batch [80/445] time 0.085 (0.092) data 0.000 (0.007) loss 1.5392 (1.5092) teacher_loss 0.8870 (0.8927) loss_zs_kd 1.6573 (1.7136) loss_oracle 0.3146 (0.3297) acc 75.0000 (68.3594) lr 1.0628e-03 eta 0:16:55
epoch [26/50] batch [100/445] time 0.089 (0.091) data 0.000 (0.006) loss 1.1693 (1.5091) teacher_loss 0.5600 (0.8937) loss_zs_kd 1.7440 (1.6984) loss_oracle 0.3637 (0.3300) acc 84.3750 (68.5312) lr 1.0628e-03 eta 0:16:40
epoch [26/50] batch [120/445] time 0.088 (0.090) data 0.000 (0.005) loss 1.5195 (1.5085) teacher_loss 0.9691 (0.8941) loss_zs_kd 1.8903 (1.7348) loss_oracle 0.3146 (0.3293) acc 59.3750 (68.3073) lr 1.0628e-03 eta 0:16:29
epoch [26/50] batch [140/445] time 0.092 (0.089) data 0.000 (0.004) loss 1.3208 (1.5149) teacher_loss 0.7624 (0.9014) loss_zs_kd 1.9530 (1.7465) loss_oracle 0.3221 (0.3292) acc 65.6250 (67.9688) lr 1.0628e-03 eta 0:16:23
epoch [26/50] batch [160/445] time 0.085 (0.089) data 0.000 (0.004) loss 1.6557 (1.5285) teacher_loss 1.0011 (0.9153) loss_zs_kd 1.6787 (1.7363) loss_oracle 0.3147 (0.3295) acc 62.5000 (67.4805) lr 1.0628e-03 eta 0:16:15
epoch [26/50] batch [180/445] time 0.073 (0.088) data 0.001 (0.003) loss 1.4562 (1.5161) teacher_loss 0.8748 (0.9062) loss_zs_kd 1.6896 (1.7144) loss_oracle 0.3146 (0.3287) acc 65.6250 (67.7083) lr 1.0628e-03 eta 0:16:02
epoch [26/50] batch [200/445] time 0.071 (0.086) data 0.000 (0.003) loss 1.1778 (1.5299) teacher_loss 0.5746 (0.9209) loss_zs_kd 1.7412 (1.7107) loss_oracle 0.3086 (0.3291) acc 78.1250 (67.0156) lr 1.0628e-03 eta 0:15:42
epoch [26/50] batch [220/445] time 0.067 (0.088) data 0.000 (0.003) loss 1.4760 (1.5251) teacher_loss 0.8914 (0.9168) loss_zs_kd 1.7446 (1.7092) loss_oracle 0.3398 (0.3285) acc 78.1250 (67.0597) lr 1.0628e-03 eta 0:15:56
epoch [26/50] batch [240/445] time 0.075 (0.088) data 0.000 (0.002) loss 1.4152 (1.5232) teacher_loss 0.8279 (0.9169) loss_zs_kd 1.8597 (1.7117) loss_oracle 0.3146 (0.3285) acc 68.7500 (67.1224) lr 1.0628e-03 eta 0:15:55
epoch [26/50] batch [260/445] time 0.075 (0.088) data 0.000 (0.002) loss 1.6997 (1.5212) teacher_loss 1.0225 (0.9149) loss_zs_kd 1.6511 (1.7162) loss_oracle 0.3457 (0.3285) acc 62.5000 (67.4399) lr 1.0628e-03 eta 0:15:52
epoch [26/50] batch [280/445] time 0.141 (0.088) data 0.000 (0.002) loss 1.4919 (1.5171) teacher_loss 0.9118 (0.9111) loss_zs_kd 1.8142 (1.7239) loss_oracle 0.3146 (0.3283) acc 65.6250 (67.6116) lr 1.0628e-03 eta 0:15:52
epoch [26/50] batch [300/445] time 0.070 (0.087) data 0.000 (0.002) loss 1.4424 (1.5081) teacher_loss 0.8585 (0.9024) loss_zs_kd 1.6099 (1.7230) loss_oracle 0.3145 (0.3285) acc 65.6250 (67.8750) lr 1.0628e-03 eta 0:15:40
epoch [26/50] batch [320/445] time 0.066 (0.087) data 0.000 (0.002) loss 1.1795 (1.5133) teacher_loss 0.6774 (0.9063) loss_zs_kd 1.4015 (1.7266) loss_oracle 0.3455 (0.3293) acc 81.2500 (67.7051) lr 1.0628e-03 eta 0:15:45
epoch [26/50] batch [340/445] time 0.073 (0.087) data 0.000 (0.002) loss 1.5137 (1.5191) teacher_loss 0.8667 (0.9108) loss_zs_kd 1.3850 (1.7244) loss_oracle 0.3146 (0.3297) acc 65.6250 (67.5827) lr 1.0628e-03 eta 0:15:43
epoch [26/50] batch [360/445] time 0.159 (0.088) data 0.000 (0.002) loss 1.3000 (1.5152) teacher_loss 0.7011 (0.9079) loss_zs_kd 1.8455 (1.7288) loss_oracle 0.3146 (0.3298) acc 78.1250 (67.7344) lr 1.0628e-03 eta 0:15:48
epoch [26/50] batch [380/445] time 0.137 (0.088) data 0.000 (0.002) loss 1.6724 (1.5155) teacher_loss 1.1165 (0.9079) loss_zs_kd 1.4669 (1.7236) loss_oracle 0.3085 (0.3299) acc 53.1250 (67.7714) lr 1.0628e-03 eta 0:15:46
epoch [26/50] batch [400/445] time 0.068 (0.088) data 0.000 (0.002) loss 1.1646 (1.5141) teacher_loss 0.5856 (0.9068) loss_zs_kd 1.7991 (1.7223) loss_oracle 0.3106 (0.3300) acc 78.1250 (67.7891) lr 1.0628e-03 eta 0:15:48
epoch [26/50] batch [420/445] time 0.153 (0.089) data 0.000 (0.002) loss 1.9229 (1.5115) teacher_loss 1.2161 (0.9047) loss_zs_kd 1.9444 (1.7231) loss_oracle 0.3927 (0.3304) acc 56.2500 (67.8795) lr 1.0628e-03 eta 0:15:51
epoch [26/50] batch [440/445] time 0.055 (0.089) data 0.000 (0.001) loss 1.2451 (1.5122) teacher_loss 0.6417 (0.9052) loss_zs_kd 1.4788 (1.7258) loss_oracle 0.3047 (0.3301) acc 78.1250 (67.8480) lr 1.0628e-03 eta 0:15:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,292
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,034
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 31.5%
******* Domain 3 best val acc:      70.5%, epoch: 24 *******
******* Domain 3 best val test acc: 50.9%, epoch: 24 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [27/50] batch [20/445] time 0.056 (0.093) data 0.000 (0.023) loss 1.4906 (1.5057) teacher_loss 0.9215 (0.8856) loss_zs_kd 1.5222 (1.7105) loss_oracle 0.3456 (0.3342) acc 65.6250 (67.0312) lr 1.0000e-03 eta 0:16:27
epoch [27/50] batch [40/445] time 0.085 (0.083) data 0.000 (0.012) loss 1.6741 (1.4912) teacher_loss 1.0101 (0.8656) loss_zs_kd 1.3782 (1.6864) loss_oracle 0.3455 (0.3346) acc 68.7500 (69.0625) lr 1.0000e-03 eta 0:14:44
epoch [27/50] batch [60/445] time 0.096 (0.086) data 0.000 (0.008) loss 1.5389 (1.5002) teacher_loss 0.9617 (0.8858) loss_zs_kd 1.8098 (1.6793) loss_oracle 0.3146 (0.3332) acc 62.5000 (68.1771) lr 1.0000e-03 eta 0:15:09
epoch [27/50] batch [80/445] time 0.088 (0.085) data 0.000 (0.006) loss 1.8493 (1.5043) teacher_loss 1.2208 (0.8902) loss_zs_kd 1.8482 (1.7339) loss_oracle 0.3650 (0.3337) acc 65.6250 (68.0469) lr 1.0000e-03 eta 0:15:00
epoch [27/50] batch [100/445] time 0.085 (0.085) data 0.000 (0.005) loss 1.2545 (1.5050) teacher_loss 0.6419 (0.8878) loss_zs_kd 1.9141 (1.7544) loss_oracle 0.3145 (0.3335) acc 78.1250 (68.2812) lr 1.0000e-03 eta 0:14:59
epoch [27/50] batch [120/445] time 0.084 (0.085) data 0.000 (0.004) loss 1.3783 (1.5059) teacher_loss 0.7920 (0.8893) loss_zs_kd 1.9422 (1.7629) loss_oracle 0.3145 (0.3329) acc 68.7500 (68.1510) lr 1.0000e-03 eta 0:14:57
epoch [27/50] batch [140/445] time 0.078 (0.085) data 0.000 (0.004) loss 1.3837 (1.5034) teacher_loss 0.8125 (0.8928) loss_zs_kd 1.7575 (1.7591) loss_oracle 0.3144 (0.3311) acc 71.8750 (67.9241) lr 1.0000e-03 eta 0:14:54
epoch [27/50] batch [160/445] time 0.067 (0.084) data 0.000 (0.003) loss 1.6125 (1.5061) teacher_loss 1.0033 (0.8976) loss_zs_kd 1.4639 (1.7489) loss_oracle 0.3126 (0.3303) acc 75.0000 (67.6367) lr 1.0000e-03 eta 0:14:38
epoch [27/50] batch [180/445] time 0.066 (0.086) data 0.000 (0.003) loss 1.7308 (1.5079) teacher_loss 1.0714 (0.8996) loss_zs_kd 2.1004 (1.7658) loss_oracle 0.3455 (0.3303) acc 65.6250 (67.6215) lr 1.0000e-03 eta 0:15:02
epoch [27/50] batch [200/445] time 0.065 (0.087) data 0.000 (0.003) loss 1.4055 (1.5094) teacher_loss 0.8873 (0.9022) loss_zs_kd 1.5458 (1.7667) loss_oracle 0.3145 (0.3300) acc 68.7500 (67.6094) lr 1.0000e-03 eta 0:15:08
epoch [27/50] batch [220/445] time 0.067 (0.088) data 0.000 (0.002) loss 1.1516 (1.5069) teacher_loss 0.6628 (0.9026) loss_zs_kd 1.5137 (1.7587) loss_oracle 0.3145 (0.3296) acc 71.8750 (67.7131) lr 1.0000e-03 eta 0:15:24
epoch [27/50] batch [240/445] time 0.061 (0.087) data 0.000 (0.002) loss 1.1967 (1.5059) teacher_loss 0.6080 (0.9030) loss_zs_kd 1.4374 (1.7525) loss_oracle 0.3455 (0.3298) acc 71.8750 (67.7474) lr 1.0000e-03 eta 0:15:05
epoch [27/50] batch [260/445] time 0.061 (0.087) data 0.000 (0.002) loss 1.5235 (1.5080) teacher_loss 0.9217 (0.9046) loss_zs_kd 1.8455 (1.7476) loss_oracle 0.3456 (0.3300) acc 71.8750 (67.7043) lr 1.0000e-03 eta 0:15:04
epoch [27/50] batch [280/445] time 0.156 (0.087) data 0.000 (0.002) loss 1.4773 (1.5056) teacher_loss 0.9356 (0.9037) loss_zs_kd 1.6535 (1.7388) loss_oracle 0.3448 (0.3293) acc 59.3750 (67.8013) lr 1.0000e-03 eta 0:15:06
epoch [27/50] batch [300/445] time 0.064 (0.088) data 0.000 (0.002) loss 1.3439 (1.5120) teacher_loss 0.8478 (0.9097) loss_zs_kd 1.7153 (1.7293) loss_oracle 0.3144 (0.3295) acc 75.0000 (67.6771) lr 1.0000e-03 eta 0:15:08
epoch [27/50] batch [320/445] time 0.064 (0.088) data 0.000 (0.002) loss 1.3591 (1.5072) teacher_loss 0.7408 (0.9074) loss_zs_kd 1.3421 (1.7207) loss_oracle 0.3058 (0.3292) acc 78.1250 (67.8320) lr 1.0000e-03 eta 0:15:16
epoch [27/50] batch [340/445] time 0.156 (0.089) data 0.000 (0.002) loss 1.6370 (1.5073) teacher_loss 1.0801 (0.9093) loss_zs_kd 1.7650 (1.7208) loss_oracle 0.3145 (0.3290) acc 59.3750 (67.7849) lr 1.0000e-03 eta 0:15:22
epoch [27/50] batch [360/445] time 0.073 (0.089) data 0.000 (0.002) loss 1.5328 (1.5085) teacher_loss 0.9294 (0.9098) loss_zs_kd 1.3202 (1.7155) loss_oracle 0.3146 (0.3290) acc 65.6250 (67.7431) lr 1.0000e-03 eta 0:15:18
epoch [27/50] batch [380/445] time 0.081 (0.089) data 0.000 (0.002) loss 1.4209 (1.5080) teacher_loss 0.7914 (0.9091) loss_zs_kd 2.2146 (1.7165) loss_oracle 0.3456 (0.3289) acc 71.8750 (67.8207) lr 1.0000e-03 eta 0:15:20
epoch [27/50] batch [400/445] time 0.128 (0.089) data 0.000 (0.001) loss 1.6648 (1.5067) teacher_loss 0.9894 (0.9073) loss_zs_kd 1.5255 (1.7107) loss_oracle 0.3145 (0.3292) acc 59.3750 (67.8984) lr 1.0000e-03 eta 0:15:14
epoch [27/50] batch [420/445] time 0.090 (0.088) data 0.000 (0.001) loss 1.7081 (1.5054) teacher_loss 0.9281 (0.9054) loss_zs_kd 1.8268 (1.7061) loss_oracle 0.3812 (0.3293) acc 65.6250 (67.9390) lr 1.0000e-03 eta 0:15:02
epoch [27/50] batch [440/445] time 0.084 (0.088) data 0.000 (0.001) loss 1.3669 (1.5110) teacher_loss 0.8493 (0.9103) loss_zs_kd 1.6447 (1.7066) loss_oracle 0.3119 (0.3293) acc 68.7500 (67.8196) lr 1.0000e-03 eta 0:15:01
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,305
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 56.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,033
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 32.7%
******* Domain 3 best val acc:      70.5%, epoch: 24 *******
******* Domain 3 best val test acc: 50.9%, epoch: 24 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [28/50] batch [20/445] time 0.081 (0.096) data 0.000 (0.025) loss 1.1132 (1.4715) teacher_loss 0.5433 (0.8897) loss_zs_kd 2.3181 (1.6833) loss_oracle 0.3145 (0.3230) acc 81.2500 (70.4688) lr 9.3721e-04 eta 0:16:15
epoch [28/50] batch [40/445] time 0.072 (0.084) data 0.000 (0.013) loss 1.3063 (1.4942) teacher_loss 0.7052 (0.8909) loss_zs_kd 1.9179 (1.6973) loss_oracle 0.3752 (0.3299) acc 75.0000 (68.7500) lr 9.3721e-04 eta 0:14:14
epoch [28/50] batch [60/445] time 0.077 (0.080) data 0.001 (0.009) loss 1.4950 (1.4745) teacher_loss 0.8854 (0.8754) loss_zs_kd 1.5547 (1.7443) loss_oracle 0.3442 (0.3308) acc 62.5000 (69.2188) lr 9.3721e-04 eta 0:13:31
epoch [28/50] batch [80/445] time 0.064 (0.076) data 0.000 (0.007) loss 1.5002 (1.4653) teacher_loss 0.9250 (0.8700) loss_zs_kd 1.4156 (1.7521) loss_oracle 0.3139 (0.3280) acc 62.5000 (69.2578) lr 9.3721e-04 eta 0:12:53
epoch [28/50] batch [100/445] time 0.068 (0.076) data 0.000 (0.005) loss 1.7363 (1.4692) teacher_loss 1.0569 (0.8672) loss_zs_kd 1.7230 (1.7700) loss_oracle 0.3145 (0.3283) acc 75.0000 (69.6562) lr 9.3721e-04 eta 0:12:48
epoch [28/50] batch [120/445] time 0.067 (0.080) data 0.000 (0.004) loss 1.4644 (1.4799) teacher_loss 0.8084 (0.8804) loss_zs_kd 1.8619 (1.7673) loss_oracle 0.3456 (0.3272) acc 65.6250 (69.2188) lr 9.3721e-04 eta 0:13:28
epoch [28/50] batch [140/445] time 0.066 (0.083) data 0.000 (0.004) loss 1.2280 (1.4906) teacher_loss 0.6890 (0.8926) loss_zs_kd 1.8211 (1.7829) loss_oracle 0.3415 (0.3269) acc 75.0000 (68.7946) lr 9.3721e-04 eta 0:13:59
epoch [28/50] batch [160/445] time 0.062 (0.085) data 0.000 (0.003) loss 1.7321 (1.4915) teacher_loss 1.1518 (0.8922) loss_zs_kd 1.8237 (1.7793) loss_oracle 0.3145 (0.3276) acc 59.3750 (68.8867) lr 9.3721e-04 eta 0:14:18
epoch [28/50] batch [180/445] time 0.069 (0.084) data 0.000 (0.003) loss 1.4201 (1.4941) teacher_loss 0.8552 (0.8953) loss_zs_kd 1.5487 (1.7792) loss_oracle 0.3448 (0.3274) acc 59.3750 (68.3854) lr 9.3721e-04 eta 0:14:01
epoch [28/50] batch [200/445] time 0.154 (0.084) data 0.000 (0.003) loss 1.5960 (1.4923) teacher_loss 1.0470 (0.8936) loss_zs_kd 1.8097 (1.7771) loss_oracle 0.3561 (0.3285) acc 65.6250 (68.5156) lr 9.3721e-04 eta 0:14:07
epoch [28/50] batch [220/445] time 0.062 (0.085) data 0.000 (0.003) loss 1.5514 (1.4987) teacher_loss 0.8469 (0.8970) loss_zs_kd 1.3881 (1.7723) loss_oracle 0.3121 (0.3289) acc 71.8750 (68.3239) lr 9.3721e-04 eta 0:14:15
epoch [28/50] batch [240/445] time 0.064 (0.087) data 0.000 (0.002) loss 1.9920 (1.4992) teacher_loss 1.3588 (0.8972) loss_zs_kd 1.5775 (1.7671) loss_oracle 0.3143 (0.3288) acc 53.1250 (68.3333) lr 9.3721e-04 eta 0:14:27
epoch [28/50] batch [260/445] time 0.063 (0.087) data 0.000 (0.002) loss 1.5057 (1.5002) teacher_loss 0.8539 (0.8953) loss_zs_kd 2.0262 (1.7699) loss_oracle 0.3093 (0.3292) acc 75.0000 (68.3053) lr 9.3721e-04 eta 0:14:27
epoch [28/50] batch [280/445] time 0.067 (0.087) data 0.000 (0.002) loss 1.3346 (1.5021) teacher_loss 0.7968 (0.8965) loss_zs_kd 1.3557 (1.7624) loss_oracle 0.3145 (0.3294) acc 71.8750 (68.2366) lr 9.3721e-04 eta 0:14:24
epoch [28/50] batch [300/445] time 0.152 (0.087) data 0.000 (0.002) loss 1.5020 (1.5058) teacher_loss 0.8826 (0.8996) loss_zs_kd 1.6814 (1.7504) loss_oracle 0.3145 (0.3302) acc 65.6250 (68.1042) lr 9.3721e-04 eta 0:14:26
epoch [28/50] batch [320/445] time 0.067 (0.088) data 0.000 (0.002) loss 1.2300 (1.5066) teacher_loss 0.6586 (0.8979) loss_zs_kd 1.4890 (1.7475) loss_oracle 0.3145 (0.3303) acc 71.8750 (68.1250) lr 9.3721e-04 eta 0:14:29
epoch [28/50] batch [340/445] time 0.059 (0.088) data 0.000 (0.002) loss 1.3574 (1.5058) teacher_loss 0.7982 (0.8974) loss_zs_kd 1.6056 (1.7410) loss_oracle 0.3138 (0.3306) acc 75.0000 (68.2077) lr 9.3721e-04 eta 0:14:31
epoch [28/50] batch [360/445] time 0.093 (0.087) data 0.000 (0.002) loss 1.2287 (1.5100) teacher_loss 0.6377 (0.9010) loss_zs_kd 1.9347 (1.7392) loss_oracle 0.3381 (0.3309) acc 78.1250 (67.9948) lr 9.3721e-04 eta 0:14:23
epoch [28/50] batch [380/445] time 0.080 (0.087) data 0.000 (0.002) loss 1.4729 (1.5085) teacher_loss 0.7842 (0.8997) loss_zs_kd 1.8222 (1.7389) loss_oracle 0.3135 (0.3305) acc 68.7500 (68.0181) lr 9.3721e-04 eta 0:14:21
epoch [28/50] batch [400/445] time 0.086 (0.087) data 0.000 (0.002) loss 1.8108 (1.5077) teacher_loss 1.1067 (0.8975) loss_zs_kd 1.2929 (1.7400) loss_oracle 0.3766 (0.3309) acc 65.6250 (68.0156) lr 9.3721e-04 eta 0:14:18
epoch [28/50] batch [420/445] time 0.085 (0.087) data 0.000 (0.001) loss 1.4569 (1.5110) teacher_loss 0.9192 (0.9014) loss_zs_kd 1.8272 (1.7338) loss_oracle 0.3067 (0.3307) acc 68.7500 (67.8423) lr 9.3721e-04 eta 0:14:16
epoch [28/50] batch [440/445] time 0.084 (0.087) data 0.000 (0.001) loss 1.7473 (1.5091) teacher_loss 1.1288 (0.8990) loss_zs_kd 1.5625 (1.7276) loss_oracle 0.3382 (0.3310) acc 56.2500 (67.9332) lr 9.3721e-04 eta 0:14:13
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,264
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 55.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,973
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 29.8%
******* Domain 3 best val acc:      70.5%, epoch: 24 *******
******* Domain 3 best val test acc: 50.9%, epoch: 24 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [29/50] batch [20/445] time 0.066 (0.114) data 0.000 (0.029) loss 1.8094 (1.5405) teacher_loss 1.2142 (0.9305) loss_zs_kd 1.9337 (1.7923) loss_oracle 0.3145 (0.3378) acc 53.1250 (69.0625) lr 8.7467e-04 eta 0:18:37
epoch [29/50] batch [40/445] time 0.070 (0.090) data 0.000 (0.014) loss 1.5574 (1.5249) teacher_loss 0.9828 (0.9163) loss_zs_kd 1.6100 (1.7375) loss_oracle 0.3145 (0.3330) acc 65.6250 (68.9062) lr 8.7467e-04 eta 0:14:34
epoch [29/50] batch [60/445] time 0.124 (0.088) data 0.000 (0.010) loss 1.3364 (1.5106) teacher_loss 0.7418 (0.9010) loss_zs_kd 1.8197 (1.7527) loss_oracle 0.3134 (0.3338) acc 68.7500 (68.6979) lr 8.7467e-04 eta 0:14:20
epoch [29/50] batch [80/445] time 0.061 (0.088) data 0.000 (0.007) loss 1.6864 (1.5165) teacher_loss 1.1049 (0.9054) loss_zs_kd 1.9196 (1.7758) loss_oracle 0.3145 (0.3324) acc 56.2500 (68.6719) lr 8.7467e-04 eta 0:14:10
epoch [29/50] batch [100/445] time 0.068 (0.090) data 0.000 (0.006) loss 1.3330 (1.5193) teacher_loss 0.6288 (0.9058) loss_zs_kd 1.8910 (1.8003) loss_oracle 0.4076 (0.3330) acc 75.0000 (68.7812) lr 8.7467e-04 eta 0:14:33
epoch [29/50] batch [120/445] time 0.072 (0.089) data 0.000 (0.005) loss 1.2992 (1.5068) teacher_loss 0.5847 (0.8909) loss_zs_kd 1.8464 (1.8058) loss_oracle 0.3121 (0.3329) acc 78.1250 (69.2969) lr 8.7467e-04 eta 0:14:16
epoch [29/50] batch [140/445] time 0.150 (0.088) data 0.000 (0.004) loss 1.5016 (1.5046) teacher_loss 0.9017 (0.8880) loss_zs_kd 1.3544 (1.7972) loss_oracle 0.3766 (0.3339) acc 62.5000 (69.2634) lr 8.7467e-04 eta 0:14:12
epoch [29/50] batch [160/445] time 0.064 (0.088) data 0.000 (0.004) loss 1.2346 (1.4969) teacher_loss 0.6818 (0.8817) loss_zs_kd 1.5563 (1.7907) loss_oracle 0.3455 (0.3340) acc 78.1250 (69.5508) lr 8.7467e-04 eta 0:14:04
epoch [29/50] batch [180/445] time 0.172 (0.089) data 0.000 (0.003) loss 1.6468 (1.4997) teacher_loss 0.9675 (0.8830) loss_zs_kd 1.8634 (1.7986) loss_oracle 0.3764 (0.3345) acc 65.6250 (69.2361) lr 8.7467e-04 eta 0:14:17
epoch [29/50] batch [200/445] time 0.156 (0.090) data 0.000 (0.003) loss 1.9582 (1.5095) teacher_loss 1.3089 (0.8918) loss_zs_kd 2.1076 (1.7900) loss_oracle 0.3137 (0.3338) acc 59.3750 (69.0469) lr 8.7467e-04 eta 0:14:19
epoch [29/50] batch [220/445] time 0.065 (0.089) data 0.000 (0.003) loss 1.8667 (1.5154) teacher_loss 1.1120 (0.8940) loss_zs_kd 2.0025 (1.7916) loss_oracle 0.3745 (0.3337) acc 56.2500 (69.0199) lr 8.7467e-04 eta 0:14:12
epoch [29/50] batch [240/445] time 0.082 (0.090) data 0.000 (0.003) loss 1.6684 (1.5128) teacher_loss 1.0766 (0.8933) loss_zs_kd 2.0273 (1.7925) loss_oracle 0.3145 (0.3329) acc 53.1250 (68.8672) lr 8.7467e-04 eta 0:14:20
epoch [29/50] batch [260/445] time 0.158 (0.090) data 0.000 (0.002) loss 1.5417 (1.5134) teacher_loss 0.9076 (0.8942) loss_zs_kd 1.3456 (1.7860) loss_oracle 0.3759 (0.3336) acc 62.5000 (68.6659) lr 8.7467e-04 eta 0:14:19
epoch [29/50] batch [280/445] time 0.070 (0.091) data 0.000 (0.002) loss 1.6571 (1.5123) teacher_loss 1.0204 (0.8942) loss_zs_kd 1.9650 (1.7859) loss_oracle 0.3540 (0.3337) acc 68.7500 (68.5491) lr 8.7467e-04 eta 0:14:22
epoch [29/50] batch [300/445] time 0.084 (0.090) data 0.000 (0.002) loss 1.8012 (1.5196) teacher_loss 1.0241 (0.9007) loss_zs_kd 1.6547 (1.7836) loss_oracle 0.3699 (0.3343) acc 68.7500 (68.3438) lr 8.7467e-04 eta 0:14:16
epoch [29/50] batch [320/445] time 0.088 (0.090) data 0.000 (0.002) loss 1.3240 (1.5190) teacher_loss 0.7405 (0.8991) loss_zs_kd 1.4445 (1.7785) loss_oracle 0.3425 (0.3347) acc 71.8750 (68.4082) lr 8.7467e-04 eta 0:14:11
epoch [29/50] batch [340/445] time 0.084 (0.090) data 0.000 (0.002) loss 1.4350 (1.5227) teacher_loss 0.8731 (0.9014) loss_zs_kd 2.0391 (1.7705) loss_oracle 0.3046 (0.3348) acc 68.7500 (68.3364) lr 8.7467e-04 eta 0:14:07
epoch [29/50] batch [360/445] time 0.086 (0.089) data 0.000 (0.002) loss 1.2008 (1.5215) teacher_loss 0.5826 (0.8985) loss_zs_kd 1.9895 (1.7691) loss_oracle 0.3144 (0.3352) acc 78.1250 (68.4462) lr 8.7467e-04 eta 0:14:02
epoch [29/50] batch [380/445] time 0.090 (0.089) data 0.000 (0.002) loss 1.5339 (1.5181) teacher_loss 0.8812 (0.8954) loss_zs_kd 1.8892 (1.7656) loss_oracle 0.3391 (0.3354) acc 71.8750 (68.5609) lr 8.7467e-04 eta 0:13:58
epoch [29/50] batch [400/445] time 0.084 (0.089) data 0.000 (0.002) loss 1.4686 (1.5201) teacher_loss 0.8177 (0.8964) loss_zs_kd 1.6576 (1.7615) loss_oracle 0.3737 (0.3356) acc 65.6250 (68.3516) lr 8.7467e-04 eta 0:13:54
epoch [29/50] batch [420/445] time 0.087 (0.089) data 0.000 (0.002) loss 1.4140 (1.5241) teacher_loss 0.7662 (0.8985) loss_zs_kd 1.5190 (1.7537) loss_oracle 0.3333 (0.3362) acc 78.1250 (68.3185) lr 8.7467e-04 eta 0:13:50
epoch [29/50] batch [440/445] time 0.078 (0.088) data 0.000 (0.002) loss 1.3675 (1.5268) teacher_loss 0.8139 (0.9003) loss_zs_kd 1.2304 (1.7439) loss_oracle 0.3451 (0.3361) acc 71.8750 (68.2457) lr 8.7467e-04 eta 0:13:46
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,323
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 56.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,021
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 32.2%
******* Domain 3 best val acc:      70.8%, epoch: 29 *******
******* Domain 3 best val test acc: 50.9%, epoch: 29 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [30/50] batch [20/445] time 0.081 (0.122) data 0.000 (0.024) loss 1.6270 (1.5374) teacher_loss 1.1231 (0.8773) loss_zs_kd 1.5651 (1.6557) loss_oracle 0.3141 (0.3376) acc 62.5000 (71.0938) lr 8.1262e-04 eta 0:19:00
epoch [30/50] batch [40/445] time 0.070 (0.097) data 0.000 (0.012) loss 1.1828 (1.5346) teacher_loss 0.6246 (0.8852) loss_zs_kd 1.6294 (1.6894) loss_oracle 0.3122 (0.3366) acc 71.8750 (70.3125) lr 8.1262e-04 eta 0:15:03
epoch [30/50] batch [60/445] time 0.062 (0.092) data 0.000 (0.008) loss 1.5892 (1.5381) teacher_loss 0.8632 (0.8907) loss_zs_kd 1.6397 (1.6920) loss_oracle 0.4663 (0.3350) acc 56.2500 (69.6354) lr 8.1262e-04 eta 0:14:13
epoch [30/50] batch [80/445] time 0.071 (0.091) data 0.000 (0.006) loss 1.6103 (1.5152) teacher_loss 0.9035 (0.8819) loss_zs_kd 1.8411 (1.6845) loss_oracle 0.4076 (0.3363) acc 65.6250 (69.6484) lr 8.1262e-04 eta 0:14:06
epoch [30/50] batch [100/445] time 0.125 (0.091) data 0.000 (0.005) loss 1.4564 (1.5022) teacher_loss 0.9669 (0.8772) loss_zs_kd 1.7041 (1.6825) loss_oracle 0.3139 (0.3334) acc 65.6250 (69.4375) lr 8.1262e-04 eta 0:13:56
epoch [30/50] batch [120/445] time 0.064 (0.091) data 0.000 (0.004) loss 1.3531 (1.5021) teacher_loss 0.8423 (0.8782) loss_zs_kd 1.3464 (1.6769) loss_oracle 0.3143 (0.3340) acc 75.0000 (69.5833) lr 8.1262e-04 eta 0:14:03
epoch [30/50] batch [140/445] time 0.073 (0.093) data 0.000 (0.004) loss 1.3824 (1.5118) teacher_loss 0.8112 (0.8908) loss_zs_kd 1.5724 (1.6671) loss_oracle 0.2952 (0.3328) acc 65.6250 (68.7723) lr 8.1262e-04 eta 0:14:13
epoch [30/50] batch [160/445] time 0.157 (0.093) data 0.000 (0.003) loss 1.8372 (1.5187) teacher_loss 1.2198 (0.9010) loss_zs_kd 1.8746 (1.6641) loss_oracle 0.3454 (0.3325) acc 62.5000 (68.4180) lr 8.1262e-04 eta 0:14:18
epoch [30/50] batch [180/445] time 0.067 (0.093) data 0.000 (0.003) loss 1.4345 (1.5231) teacher_loss 0.8057 (0.9049) loss_zs_kd 1.6576 (1.6673) loss_oracle 0.3045 (0.3319) acc 71.8750 (68.1076) lr 8.1262e-04 eta 0:14:11
epoch [30/50] batch [200/445] time 0.064 (0.093) data 0.000 (0.003) loss 1.2754 (1.5192) teacher_loss 0.7255 (0.9030) loss_zs_kd 1.6561 (1.6642) loss_oracle 0.3138 (0.3313) acc 68.7500 (67.9688) lr 8.1262e-04 eta 0:14:14
epoch [30/50] batch [220/445] time 0.084 (0.092) data 0.000 (0.002) loss 1.3686 (1.5188) teacher_loss 0.6533 (0.9017) loss_zs_kd 1.5547 (1.6705) loss_oracle 0.3278 (0.3320) acc 75.0000 (68.0256) lr 8.1262e-04 eta 0:13:59
epoch [30/50] batch [240/445] time 0.085 (0.091) data 0.000 (0.002) loss 1.2801 (1.5131) teacher_loss 0.6202 (0.8964) loss_zs_kd 1.5662 (1.6687) loss_oracle 0.3455 (0.3321) acc 71.8750 (68.3333) lr 8.1262e-04 eta 0:13:51
epoch [30/50] batch [260/445] time 0.084 (0.091) data 0.000 (0.002) loss 1.7190 (1.5104) teacher_loss 1.1142 (0.8951) loss_zs_kd 1.8014 (1.6655) loss_oracle 0.3053 (0.3322) acc 53.1250 (68.3413) lr 8.1262e-04 eta 0:13:45
epoch [30/50] batch [280/445] time 0.074 (0.090) data 0.000 (0.002) loss 1.4966 (1.5068) teacher_loss 0.9218 (0.8921) loss_zs_kd 1.6492 (1.6678) loss_oracle 0.3371 (0.3323) acc 68.7500 (68.5603) lr 8.1262e-04 eta 0:13:39
epoch [30/50] batch [300/445] time 0.082 (0.090) data 0.000 (0.002) loss 1.3604 (1.5110) teacher_loss 0.8014 (0.8945) loss_zs_kd 1.8362 (1.6704) loss_oracle 0.3455 (0.3323) acc 68.7500 (68.5729) lr 8.1262e-04 eta 0:13:34
epoch [30/50] batch [320/445] time 0.085 (0.090) data 0.000 (0.002) loss 1.5491 (1.5080) teacher_loss 0.9853 (0.8928) loss_zs_kd 2.0177 (1.6746) loss_oracle 0.3401 (0.3324) acc 56.2500 (68.5840) lr 8.1262e-04 eta 0:13:30
epoch [30/50] batch [340/445] time 0.086 (0.090) data 0.000 (0.002) loss 1.6443 (1.5085) teacher_loss 1.0685 (0.8944) loss_zs_kd 2.0696 (1.6804) loss_oracle 0.3365 (0.3328) acc 62.5000 (68.5294) lr 8.1262e-04 eta 0:13:26
epoch [30/50] batch [360/445] time 0.111 (0.089) data 0.000 (0.002) loss 1.7114 (1.5125) teacher_loss 1.0643 (0.8984) loss_zs_kd 1.6373 (1.6878) loss_oracle 0.3766 (0.3333) acc 62.5000 (68.4375) lr 8.1262e-04 eta 0:13:23
epoch [30/50] batch [380/445] time 0.087 (0.090) data 0.000 (0.002) loss 1.3298 (1.5088) teacher_loss 0.7514 (0.8949) loss_zs_kd 1.6899 (1.6921) loss_oracle 0.3043 (0.3330) acc 71.8750 (68.5938) lr 8.1262e-04 eta 0:13:22
epoch [30/50] batch [400/445] time 0.080 (0.089) data 0.000 (0.001) loss 1.3132 (1.5126) teacher_loss 0.7006 (0.8984) loss_zs_kd 1.1952 (1.6929) loss_oracle 0.3451 (0.3336) acc 75.0000 (68.4766) lr 8.1262e-04 eta 0:13:19
epoch [30/50] batch [420/445] time 0.088 (0.089) data 0.000 (0.001) loss 1.4491 (1.5106) teacher_loss 0.7428 (0.8958) loss_zs_kd 1.6745 (1.6902) loss_oracle 0.3144 (0.3334) acc 78.1250 (68.5417) lr 8.1262e-04 eta 0:13:15
epoch [30/50] batch [440/445] time 0.083 (0.089) data 0.000 (0.001) loss 1.1828 (1.5099) teacher_loss 0.4772 (0.8940) loss_zs_kd 1.7838 (1.6926) loss_oracle 0.3420 (0.3336) acc 81.2500 (68.7003) lr 8.1262e-04 eta 0:13:12
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,330
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 56.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,040
* accuracy: 51.4%
* error: 48.6%
* macro_f1: 31.6%
******* Domain 3 best val acc:      70.9%, epoch: 30 *******
******* Domain 3 best val test acc: 51.4%, epoch: 30 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [31/50] batch [20/445] time 0.086 (0.127) data 0.000 (0.032) loss 1.6092 (1.5572) teacher_loss 0.9471 (0.8987) loss_zs_kd 1.7251 (1.6955) loss_oracle 0.3734 (0.3369) acc 71.8750 (69.6875) lr 7.5131e-04 eta 0:18:47
epoch [31/50] batch [40/445] time 0.066 (0.111) data 0.000 (0.016) loss 1.2313 (1.5331) teacher_loss 0.6638 (0.8927) loss_zs_kd 1.6516 (1.7615) loss_oracle 0.3450 (0.3353) acc 81.2500 (68.5156) lr 7.5131e-04 eta 0:16:27
epoch [31/50] batch [60/445] time 0.093 (0.104) data 0.001 (0.011) loss 1.5184 (1.5151) teacher_loss 0.9503 (0.8804) loss_zs_kd 1.2854 (1.7439) loss_oracle 0.3144 (0.3373) acc 62.5000 (69.4271) lr 7.5131e-04 eta 0:15:16
epoch [31/50] batch [80/445] time 0.066 (0.105) data 0.000 (0.008) loss 1.6834 (1.5074) teacher_loss 1.0182 (0.8773) loss_zs_kd 1.6943 (1.7178) loss_oracle 0.3713 (0.3382) acc 62.5000 (69.6094) lr 7.5131e-04 eta 0:15:28
epoch [31/50] batch [100/445] time 0.137 (0.103) data 0.000 (0.007) loss 1.2888 (1.5010) teacher_loss 0.6837 (0.8761) loss_zs_kd 1.9327 (1.7405) loss_oracle 0.3138 (0.3381) acc 71.8750 (69.8125) lr 7.5131e-04 eta 0:15:03
epoch [31/50] batch [120/445] time 0.134 (0.101) data 0.000 (0.006) loss 1.1652 (1.5025) teacher_loss 0.5371 (0.8797) loss_zs_kd 1.3393 (1.7324) loss_oracle 0.3304 (0.3386) acc 81.2500 (69.6094) lr 7.5131e-04 eta 0:14:48
epoch [31/50] batch [140/445] time 0.085 (0.098) data 0.000 (0.005) loss 1.2057 (1.5012) teacher_loss 0.6588 (0.8811) loss_zs_kd 1.4566 (1.7247) loss_oracle 0.3454 (0.3383) acc 81.2500 (69.6429) lr 7.5131e-04 eta 0:14:14
epoch [31/50] batch [160/445] time 0.084 (0.096) data 0.000 (0.004) loss 1.4373 (1.5084) teacher_loss 0.8227 (0.8889) loss_zs_kd 1.9896 (1.7283) loss_oracle 0.3144 (0.3371) acc 75.0000 (69.1992) lr 7.5131e-04 eta 0:14:00
epoch [31/50] batch [180/445] time 0.079 (0.095) data 0.000 (0.004) loss 1.4449 (1.5114) teacher_loss 0.8828 (0.8910) loss_zs_kd 1.6509 (1.7135) loss_oracle 0.3763 (0.3388) acc 65.6250 (69.2535) lr 7.5131e-04 eta 0:13:47
epoch [31/50] batch [200/445] time 0.088 (0.093) data 0.000 (0.003) loss 1.7866 (1.5075) teacher_loss 1.0570 (0.8875) loss_zs_kd 1.6631 (1.7080) loss_oracle 0.3149 (0.3394) acc 62.5000 (69.4688) lr 7.5131e-04 eta 0:13:32
epoch [31/50] batch [220/445] time 0.078 (0.092) data 0.000 (0.003) loss 1.3544 (1.5105) teacher_loss 0.7489 (0.8933) loss_zs_kd 1.5020 (1.7030) loss_oracle 0.3144 (0.3383) acc 71.8750 (69.2188) lr 7.5131e-04 eta 0:13:19
epoch [31/50] batch [240/445] time 0.087 (0.091) data 0.000 (0.003) loss 1.4610 (1.5157) teacher_loss 0.8671 (0.8973) loss_zs_kd 2.3816 (1.6995) loss_oracle 0.3219 (0.3385) acc 65.6250 (69.0885) lr 7.5131e-04 eta 0:13:12
epoch [31/50] batch [260/445] time 0.089 (0.091) data 0.000 (0.003) loss 1.3151 (1.5162) teacher_loss 0.7350 (0.8989) loss_zs_kd 1.5270 (1.6970) loss_oracle 0.3015 (0.3379) acc 78.1250 (68.9904) lr 7.5131e-04 eta 0:13:06
epoch [31/50] batch [280/445] time 0.085 (0.091) data 0.000 (0.003) loss 1.2029 (1.5130) teacher_loss 0.6665 (0.8969) loss_zs_kd 1.2104 (1.6929) loss_oracle 0.3691 (0.3374) acc 87.5000 (69.0513) lr 7.5131e-04 eta 0:13:01
epoch [31/50] batch [300/445] time 0.088 (0.090) data 0.000 (0.002) loss 1.7847 (1.5151) teacher_loss 1.1105 (0.8994) loss_zs_kd 1.5499 (1.6847) loss_oracle 0.3748 (0.3369) acc 71.8750 (68.9062) lr 7.5131e-04 eta 0:12:57
epoch [31/50] batch [320/445] time 0.084 (0.090) data 0.000 (0.002) loss 1.5867 (1.5117) teacher_loss 1.0336 (0.8972) loss_zs_kd 1.6226 (1.6846) loss_oracle 0.3100 (0.3367) acc 65.6250 (69.0137) lr 7.5131e-04 eta 0:12:52
epoch [31/50] batch [340/445] time 0.081 (0.090) data 0.000 (0.002) loss 1.3895 (1.5130) teacher_loss 0.7774 (0.8978) loss_zs_kd 2.1549 (1.6919) loss_oracle 0.3142 (0.3366) acc 68.7500 (68.9614) lr 7.5131e-04 eta 0:12:47
epoch [31/50] batch [360/445] time 0.086 (0.089) data 0.000 (0.002) loss 1.5582 (1.5090) teacher_loss 0.9831 (0.8927) loss_zs_kd 1.5629 (1.6861) loss_oracle 0.3144 (0.3366) acc 65.6250 (69.1319) lr 7.5131e-04 eta 0:12:43
epoch [31/50] batch [380/445] time 0.084 (0.089) data 0.000 (0.002) loss 1.4317 (1.5079) teacher_loss 0.7758 (0.8913) loss_zs_kd 1.6143 (1.6884) loss_oracle 0.3765 (0.3365) acc 68.7500 (69.0954) lr 7.5131e-04 eta 0:12:40
epoch [31/50] batch [400/445] time 0.084 (0.089) data 0.000 (0.002) loss 1.2466 (1.5099) teacher_loss 0.6401 (0.8931) loss_zs_kd 1.4817 (1.6810) loss_oracle 0.3432 (0.3359) acc 84.3750 (69.0391) lr 7.5131e-04 eta 0:12:36
epoch [31/50] batch [420/445] time 0.078 (0.089) data 0.000 (0.002) loss 1.4313 (1.5082) teacher_loss 0.8077 (0.8910) loss_zs_kd 1.4102 (1.6763) loss_oracle 0.3144 (0.3357) acc 75.0000 (69.1369) lr 7.5131e-04 eta 0:12:33
epoch [31/50] batch [440/445] time 0.088 (0.089) data 0.000 (0.002) loss 2.0666 (1.5108) teacher_loss 1.4032 (0.8922) loss_zs_kd 1.7122 (1.6768) loss_oracle 0.3144 (0.3357) acc 53.1250 (69.1264) lr 7.5131e-04 eta 0:12:29
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,346
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 57.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,045
* accuracy: 51.5%
* error: 48.5%
* macro_f1: 32.3%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [32/50] batch [20/445] time 0.066 (0.118) data 0.000 (0.027) loss 1.4793 (1.5342) teacher_loss 0.9244 (0.8945) loss_zs_kd 1.5480 (1.6868) loss_oracle 0.3310 (0.3392) acc 65.6250 (67.6562) lr 6.9098e-04 eta 0:16:36
epoch [32/50] batch [40/445] time 0.054 (0.097) data 0.000 (0.013) loss 1.4475 (1.5608) teacher_loss 0.7752 (0.9129) loss_zs_kd 2.0178 (1.7375) loss_oracle 0.3455 (0.3365) acc 75.0000 (67.1875) lr 6.9098e-04 eta 0:13:36
epoch [32/50] batch [60/445] time 0.061 (0.098) data 0.000 (0.009) loss 1.3425 (1.5410) teacher_loss 0.6941 (0.8934) loss_zs_kd 1.9252 (1.7281) loss_oracle 0.3144 (0.3373) acc 75.0000 (68.6458) lr 6.9098e-04 eta 0:13:40
epoch [32/50] batch [80/445] time 0.066 (0.095) data 0.000 (0.007) loss 1.7009 (1.5316) teacher_loss 1.0953 (0.8892) loss_zs_kd 1.7464 (1.7264) loss_oracle 0.3082 (0.3353) acc 65.6250 (69.3359) lr 6.9098e-04 eta 0:13:18
epoch [32/50] batch [100/445] time 0.077 (0.092) data 0.000 (0.006) loss 1.5622 (1.5243) teacher_loss 0.8491 (0.8862) loss_zs_kd 1.6794 (1.7150) loss_oracle 0.3357 (0.3340) acc 68.7500 (69.1250) lr 6.9098e-04 eta 0:12:45
epoch [32/50] batch [120/445] time 0.072 (0.089) data 0.000 (0.005) loss 1.2419 (1.5112) teacher_loss 0.7664 (0.8825) loss_zs_kd 1.7595 (1.7151) loss_oracle 0.3452 (0.3335) acc 68.7500 (69.0625) lr 6.9098e-04 eta 0:12:20
epoch [32/50] batch [140/445] time 0.081 (0.086) data 0.000 (0.004) loss 1.7915 (1.5130) teacher_loss 1.2500 (0.8855) loss_zs_kd 2.0319 (1.7212) loss_oracle 0.3363 (0.3335) acc 53.1250 (68.7500) lr 6.9098e-04 eta 0:11:56
epoch [32/50] batch [160/445] time 0.069 (0.084) data 0.000 (0.004) loss 1.7254 (1.5216) teacher_loss 1.0802 (0.8973) loss_zs_kd 1.8479 (1.7232) loss_oracle 0.3144 (0.3328) acc 56.2500 (68.2422) lr 6.9098e-04 eta 0:11:39
epoch [32/50] batch [180/445] time 0.072 (0.083) data 0.000 (0.003) loss 1.4125 (1.5157) teacher_loss 0.8887 (0.8931) loss_zs_kd 1.3535 (1.7226) loss_oracle 0.3249 (0.3322) acc 62.5000 (68.4722) lr 6.9098e-04 eta 0:11:28
epoch [32/50] batch [200/445] time 0.080 (0.083) data 0.000 (0.003) loss 1.7072 (1.5167) teacher_loss 1.0917 (0.8968) loss_zs_kd 1.5707 (1.7182) loss_oracle 0.3144 (0.3331) acc 56.2500 (68.3281) lr 6.9098e-04 eta 0:11:24
epoch [32/50] batch [220/445] time 0.081 (0.082) data 0.000 (0.003) loss 1.3657 (1.5079) teacher_loss 0.7512 (0.8913) loss_zs_kd 1.8937 (1.7279) loss_oracle 0.3053 (0.3329) acc 62.5000 (68.3807) lr 6.9098e-04 eta 0:11:18
epoch [32/50] batch [240/445] time 0.099 (0.082) data 0.000 (0.002) loss 2.0124 (1.5134) teacher_loss 1.3492 (0.8965) loss_zs_kd 1.7605 (1.7248) loss_oracle 0.3332 (0.3340) acc 53.1250 (68.1901) lr 6.9098e-04 eta 0:11:17
epoch [32/50] batch [260/445] time 0.079 (0.083) data 0.000 (0.002) loss 1.9772 (1.5091) teacher_loss 1.3753 (0.8916) loss_zs_kd 1.5270 (1.7292) loss_oracle 0.3386 (0.3348) acc 56.2500 (68.3774) lr 6.9098e-04 eta 0:11:18
epoch [32/50] batch [280/445] time 0.087 (0.083) data 0.000 (0.002) loss 1.6048 (1.5141) teacher_loss 0.9590 (0.8960) loss_zs_kd 1.7100 (1.7254) loss_oracle 0.3264 (0.3350) acc 65.6250 (68.2254) lr 6.9098e-04 eta 0:11:21
epoch [32/50] batch [300/445] time 0.085 (0.084) data 0.000 (0.002) loss 1.2535 (1.5144) teacher_loss 0.5937 (0.8959) loss_zs_kd 1.6514 (1.7112) loss_oracle 0.3454 (0.3356) acc 84.3750 (68.2500) lr 6.9098e-04 eta 0:11:21
epoch [32/50] batch [320/445] time 0.085 (0.084) data 0.000 (0.002) loss 1.3219 (1.5103) teacher_loss 0.7066 (0.8938) loss_zs_kd 1.4809 (1.7025) loss_oracle 0.3174 (0.3354) acc 71.8750 (68.1836) lr 6.9098e-04 eta 0:11:20
epoch [32/50] batch [340/445] time 0.086 (0.084) data 0.000 (0.002) loss 1.7348 (1.5125) teacher_loss 0.9843 (0.8963) loss_zs_kd 1.5553 (1.6982) loss_oracle 0.3428 (0.3354) acc 59.3750 (68.0423) lr 6.9098e-04 eta 0:11:19
epoch [32/50] batch [360/445] time 0.086 (0.084) data 0.000 (0.002) loss 1.5358 (1.5131) teacher_loss 0.9366 (0.8967) loss_zs_kd 1.6210 (1.6922) loss_oracle 0.3415 (0.3354) acc 71.8750 (68.0903) lr 6.9098e-04 eta 0:11:18
epoch [32/50] batch [380/445] time 0.090 (0.084) data 0.000 (0.002) loss 1.3297 (1.5170) teacher_loss 0.6943 (0.9010) loss_zs_kd 1.3667 (1.6901) loss_oracle 0.3676 (0.3353) acc 68.7500 (67.8783) lr 6.9098e-04 eta 0:11:16
epoch [32/50] batch [400/445] time 0.079 (0.084) data 0.000 (0.002) loss 1.7041 (1.5154) teacher_loss 1.1053 (0.8996) loss_zs_kd 1.0992 (1.6787) loss_oracle 0.3451 (0.3352) acc 62.5000 (68.0000) lr 6.9098e-04 eta 0:11:15
epoch [32/50] batch [420/445] time 0.081 (0.083) data 0.000 (0.002) loss 1.0930 (1.5116) teacher_loss 0.5125 (0.8955) loss_zs_kd 1.4131 (1.6721) loss_oracle 0.3141 (0.3352) acc 81.2500 (68.1101) lr 6.9098e-04 eta 0:11:10
epoch [32/50] batch [440/445] time 0.150 (0.083) data 0.000 (0.001) loss 1.6925 (1.5164) teacher_loss 1.0926 (0.8998) loss_zs_kd 1.5728 (1.6717) loss_oracle 0.3500 (0.3347) acc 65.6250 (67.9688) lr 6.9098e-04 eta 0:11:07
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,339
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 57.2%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,070
* accuracy: 52.1%
* error: 47.9%
* macro_f1: 32.4%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [33/50] batch [20/445] time 0.056 (0.131) data 0.000 (0.029) loss 1.3839 (1.4926) teacher_loss 0.7442 (0.8846) loss_zs_kd 1.7103 (1.6299) loss_oracle 0.4056 (0.3408) acc 75.0000 (70.9375) lr 6.3188e-04 eta 0:17:30
epoch [33/50] batch [40/445] time 0.078 (0.100) data 0.000 (0.014) loss 1.9575 (1.5106) teacher_loss 1.2022 (0.8965) loss_zs_kd 1.4565 (1.5956) loss_oracle 0.3845 (0.3382) acc 59.3750 (69.2969) lr 6.3188e-04 eta 0:13:16
epoch [33/50] batch [60/445] time 0.083 (0.094) data 0.000 (0.010) loss 1.7566 (1.4963) teacher_loss 1.0484 (0.8833) loss_zs_kd 1.5259 (1.6038) loss_oracle 0.3454 (0.3374) acc 56.2500 (69.7917) lr 6.3188e-04 eta 0:12:25
epoch [33/50] batch [80/445] time 0.077 (0.091) data 0.000 (0.007) loss 1.3147 (1.5097) teacher_loss 0.7777 (0.8856) loss_zs_kd 1.8980 (1.6248) loss_oracle 0.3144 (0.3369) acc 81.2500 (69.3359) lr 6.3188e-04 eta 0:12:04
epoch [33/50] batch [100/445] time 0.076 (0.090) data 0.000 (0.006) loss 1.4782 (1.5102) teacher_loss 0.8931 (0.8867) loss_zs_kd 1.3646 (1.6405) loss_oracle 0.3144 (0.3352) acc 71.8750 (69.0938) lr 6.3188e-04 eta 0:11:52
epoch [33/50] batch [120/445] time 0.088 (0.089) data 0.000 (0.005) loss 1.4663 (1.5028) teacher_loss 0.9254 (0.8834) loss_zs_kd 1.7301 (1.6592) loss_oracle 0.3143 (0.3344) acc 68.7500 (68.8281) lr 6.3188e-04 eta 0:11:41
epoch [33/50] batch [140/445] time 0.085 (0.088) data 0.000 (0.004) loss 1.7892 (1.5091) teacher_loss 1.1731 (0.8866) loss_zs_kd 1.6505 (1.6581) loss_oracle 0.3738 (0.3350) acc 62.5000 (68.6384) lr 6.3188e-04 eta 0:11:34
epoch [33/50] batch [160/445] time 0.085 (0.088) data 0.000 (0.004) loss 1.5064 (1.5221) teacher_loss 0.8830 (0.8994) loss_zs_kd 1.7465 (1.6749) loss_oracle 0.3135 (0.3340) acc 75.0000 (68.2617) lr 6.3188e-04 eta 0:11:29
epoch [33/50] batch [180/445] time 0.080 (0.087) data 0.000 (0.003) loss 1.4944 (1.5104) teacher_loss 0.8525 (0.8900) loss_zs_kd 1.8192 (1.6699) loss_oracle 0.3123 (0.3334) acc 65.6250 (68.3507) lr 6.3188e-04 eta 0:11:24
epoch [33/50] batch [200/445] time 0.086 (0.087) data 0.000 (0.003) loss 1.5016 (1.5121) teacher_loss 0.9655 (0.8916) loss_zs_kd 1.4659 (1.6668) loss_oracle 0.3092 (0.3350) acc 75.0000 (68.2812) lr 6.3188e-04 eta 0:11:21
epoch [33/50] batch [220/445] time 0.084 (0.087) data 0.000 (0.003) loss 1.2762 (1.5126) teacher_loss 0.7311 (0.8900) loss_zs_kd 1.4016 (1.6575) loss_oracle 0.3764 (0.3350) acc 68.7500 (68.5938) lr 6.3188e-04 eta 0:11:18
epoch [33/50] batch [240/445] time 0.088 (0.087) data 0.000 (0.003) loss 2.2476 (1.5125) teacher_loss 1.5732 (0.8910) loss_zs_kd 1.7277 (1.6557) loss_oracle 0.3733 (0.3349) acc 53.1250 (68.4896) lr 6.3188e-04 eta 0:11:15
epoch [33/50] batch [260/445] time 0.089 (0.087) data 0.000 (0.002) loss 1.4011 (1.5128) teacher_loss 0.7758 (0.8926) loss_zs_kd 1.9009 (1.6586) loss_oracle 0.3612 (0.3350) acc 75.0000 (68.4495) lr 6.3188e-04 eta 0:11:12
epoch [33/50] batch [280/445] time 0.092 (0.087) data 0.000 (0.002) loss 1.2788 (1.5134) teacher_loss 0.6313 (0.8922) loss_zs_kd 1.6660 (1.6614) loss_oracle 0.3453 (0.3350) acc 81.2500 (68.5268) lr 6.3188e-04 eta 0:11:10
epoch [33/50] batch [300/445] time 0.082 (0.087) data 0.000 (0.002) loss 1.6833 (1.5153) teacher_loss 1.1346 (0.8946) loss_zs_kd 1.9122 (1.6648) loss_oracle 0.3455 (0.3347) acc 68.7500 (68.3438) lr 6.3188e-04 eta 0:11:07
epoch [33/50] batch [320/445] time 0.082 (0.087) data 0.000 (0.002) loss 1.3079 (1.5158) teacher_loss 0.7135 (0.8931) loss_zs_kd 1.2499 (1.6645) loss_oracle 0.3141 (0.3347) acc 81.2500 (68.3594) lr 6.3188e-04 eta 0:11:05
epoch [33/50] batch [340/445] time 0.092 (0.087) data 0.000 (0.002) loss 1.6398 (1.5185) teacher_loss 0.9697 (0.8968) loss_zs_kd 1.6084 (1.6659) loss_oracle 0.3143 (0.3349) acc 59.3750 (68.2261) lr 6.3188e-04 eta 0:11:03
epoch [33/50] batch [360/445] time 0.077 (0.086) data 0.000 (0.002) loss 1.4382 (1.5172) teacher_loss 0.7545 (0.8937) loss_zs_kd 1.2004 (1.6658) loss_oracle 0.3304 (0.3349) acc 71.8750 (68.2812) lr 6.3188e-04 eta 0:11:01
epoch [33/50] batch [380/445] time 0.128 (0.086) data 0.000 (0.002) loss 1.3918 (1.5133) teacher_loss 0.7654 (0.8896) loss_zs_kd 1.2737 (1.6543) loss_oracle 0.3143 (0.3344) acc 75.0000 (68.3799) lr 6.3188e-04 eta 0:10:54
epoch [33/50] batch [400/445] time 0.084 (0.086) data 0.000 (0.002) loss 1.5772 (1.5132) teacher_loss 0.8903 (0.8891) loss_zs_kd 1.2939 (1.6541) loss_oracle 0.3251 (0.3341) acc 65.6250 (68.3828) lr 6.3188e-04 eta 0:10:53
epoch [33/50] batch [420/445] time 0.142 (0.085) data 0.000 (0.002) loss 1.4190 (1.5132) teacher_loss 0.6920 (0.8892) loss_zs_kd 1.7306 (1.6512) loss_oracle 0.3726 (0.3339) acc 71.8750 (68.3185) lr 6.3188e-04 eta 0:10:48
epoch [33/50] batch [440/445] time 0.060 (0.085) data 0.000 (0.002) loss 1.5420 (1.5175) teacher_loss 0.9243 (0.8932) loss_zs_kd 1.9472 (1.6527) loss_oracle 0.3144 (0.3337) acc 62.5000 (68.1889) lr 6.3188e-04 eta 0:10:45
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,319
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 56.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,948
* accuracy: 49.1%
* error: 50.9%
* macro_f1: 29.5%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [34/50] batch [20/445] time 0.076 (0.113) data 0.000 (0.026) loss 1.5029 (1.4262) teacher_loss 0.7745 (0.8091) loss_zs_kd 1.2262 (1.5798) loss_oracle 0.3143 (0.3294) acc 68.7500 (70.7812) lr 5.7422e-04 eta 0:14:14
epoch [34/50] batch [40/445] time 0.085 (0.099) data 0.000 (0.013) loss 1.7687 (1.4705) teacher_loss 1.0714 (0.8401) loss_zs_kd 1.4715 (1.6329) loss_oracle 0.3454 (0.3368) acc 53.1250 (70.3906) lr 5.7422e-04 eta 0:12:26
epoch [34/50] batch [60/445] time 0.090 (0.095) data 0.000 (0.009) loss 1.5038 (1.4762) teacher_loss 0.9839 (0.8567) loss_zs_kd 1.4760 (1.6321) loss_oracle 0.3144 (0.3342) acc 59.3750 (69.6875) lr 5.7422e-04 eta 0:11:51
epoch [34/50] batch [80/445] time 0.086 (0.092) data 0.000 (0.007) loss 1.3970 (1.4861) teacher_loss 0.7610 (0.8624) loss_zs_kd 1.9476 (1.6252) loss_oracle 0.3631 (0.3353) acc 78.1250 (69.2188) lr 5.7422e-04 eta 0:11:31
epoch [34/50] batch [100/445] time 0.091 (0.091) data 0.000 (0.005) loss 1.3385 (1.4984) teacher_loss 0.7174 (0.8669) loss_zs_kd 1.6942 (1.6213) loss_oracle 0.3392 (0.3371) acc 78.1250 (69.0625) lr 5.7422e-04 eta 0:11:18
epoch [34/50] batch [120/445] time 0.098 (0.091) data 0.001 (0.005) loss 1.3671 (1.5034) teacher_loss 0.8069 (0.8704) loss_zs_kd 1.7702 (1.6402) loss_oracle 0.3143 (0.3374) acc 71.8750 (69.2708) lr 5.7422e-04 eta 0:11:14
epoch [34/50] batch [140/445] time 0.087 (0.090) data 0.000 (0.004) loss 1.5656 (1.5219) teacher_loss 0.9262 (0.8841) loss_zs_kd 2.0821 (1.6646) loss_oracle 0.3483 (0.3376) acc 71.8750 (68.7946) lr 5.7422e-04 eta 0:11:05
epoch [34/50] batch [160/445] time 0.075 (0.089) data 0.000 (0.003) loss 1.3353 (1.5210) teacher_loss 0.7734 (0.8843) loss_zs_kd 1.4162 (1.6713) loss_oracle 0.3143 (0.3366) acc 78.1250 (69.0430) lr 5.7422e-04 eta 0:10:55
epoch [34/50] batch [180/445] time 0.086 (0.088) data 0.000 (0.003) loss 1.6390 (1.5189) teacher_loss 0.8939 (0.8817) loss_zs_kd 2.1632 (1.6720) loss_oracle 0.3139 (0.3366) acc 68.7500 (69.1493) lr 5.7422e-04 eta 0:10:48
epoch [34/50] batch [200/445] time 0.083 (0.088) data 0.000 (0.003) loss 1.6811 (1.5247) teacher_loss 1.0347 (0.8872) loss_zs_kd 1.8736 (1.6842) loss_oracle 0.3454 (0.3374) acc 59.3750 (68.7656) lr 5.7422e-04 eta 0:10:45
epoch [34/50] batch [220/445] time 0.082 (0.087) data 0.000 (0.003) loss 1.5100 (1.5265) teacher_loss 0.8353 (0.8899) loss_zs_kd 1.6524 (1.6796) loss_oracle 0.3415 (0.3373) acc 68.7500 (68.5227) lr 5.7422e-04 eta 0:10:41
epoch [34/50] batch [240/445] time 0.087 (0.087) data 0.000 (0.002) loss 1.5566 (1.5234) teacher_loss 0.9400 (0.8898) loss_zs_kd 1.7154 (1.6709) loss_oracle 0.3297 (0.3369) acc 68.7500 (68.6458) lr 5.7422e-04 eta 0:10:38
epoch [34/50] batch [260/445] time 0.086 (0.087) data 0.000 (0.002) loss 1.5979 (1.5271) teacher_loss 1.0348 (0.8945) loss_zs_kd 1.4040 (1.6746) loss_oracle 0.3142 (0.3361) acc 59.3750 (68.3293) lr 5.7422e-04 eta 0:10:35
epoch [34/50] batch [280/445] time 0.087 (0.087) data 0.000 (0.002) loss 1.3324 (1.5283) teacher_loss 0.7556 (0.8961) loss_zs_kd 1.6021 (1.6714) loss_oracle 0.3018 (0.3357) acc 81.2500 (68.3259) lr 5.7422e-04 eta 0:10:32
epoch [34/50] batch [300/445] time 0.076 (0.087) data 0.000 (0.002) loss 1.4454 (1.5322) teacher_loss 0.9059 (0.8995) loss_zs_kd 1.9768 (1.6692) loss_oracle 0.3434 (0.3358) acc 71.8750 (68.3542) lr 5.7422e-04 eta 0:10:29
epoch [34/50] batch [320/445] time 0.069 (0.086) data 0.000 (0.002) loss 1.3342 (1.5302) teacher_loss 0.7854 (0.8984) loss_zs_kd 1.7445 (1.6760) loss_oracle 0.3143 (0.3359) acc 78.1250 (68.4766) lr 5.7422e-04 eta 0:10:21
epoch [34/50] batch [340/445] time 0.064 (0.086) data 0.000 (0.002) loss 1.2150 (1.5250) teacher_loss 0.6150 (0.8925) loss_zs_kd 2.0339 (1.6766) loss_oracle 0.3143 (0.3360) acc 81.2500 (68.7224) lr 5.7422e-04 eta 0:10:19
epoch [34/50] batch [360/445] time 0.065 (0.087) data 0.000 (0.002) loss 1.7537 (1.5235) teacher_loss 0.9453 (0.8913) loss_zs_kd 1.8093 (1.6745) loss_oracle 0.3454 (0.3359) acc 65.6250 (68.7153) lr 5.7422e-04 eta 0:10:23
epoch [34/50] batch [380/445] time 0.143 (0.087) data 0.000 (0.002) loss 1.2121 (1.5199) teacher_loss 0.5561 (0.8892) loss_zs_kd 1.9131 (1.6685) loss_oracle 0.3454 (0.3360) acc 78.1250 (68.8487) lr 5.7422e-04 eta 0:10:24
epoch [34/50] batch [400/445] time 0.050 (0.086) data 0.000 (0.002) loss 1.8037 (1.5198) teacher_loss 1.2282 (0.8896) loss_zs_kd 1.6966 (1.6639) loss_oracle 0.3454 (0.3356) acc 62.5000 (68.8281) lr 5.7422e-04 eta 0:10:17
epoch [34/50] batch [420/445] time 0.165 (0.086) data 0.000 (0.001) loss 1.6989 (1.5188) teacher_loss 0.9670 (0.8896) loss_zs_kd 1.1176 (1.6648) loss_oracle 0.3142 (0.3350) acc 68.7500 (68.7798) lr 5.7422e-04 eta 0:10:12
epoch [34/50] batch [440/445] time 0.060 (0.086) data 0.000 (0.001) loss 1.3654 (1.5160) teacher_loss 0.7480 (0.8879) loss_zs_kd 1.5139 (1.6688) loss_oracle 0.3144 (0.3350) acc 71.8750 (68.9844) lr 5.7422e-04 eta 0:10:11
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,329
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 55.8%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,968
* accuracy: 49.6%
* error: 50.4%
* macro_f1: 30.6%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [35/50] batch [20/445] time 0.066 (0.090) data 0.000 (0.024) loss 1.5929 (1.4595) teacher_loss 0.9303 (0.8471) loss_zs_kd 1.9339 (1.7056) loss_oracle 0.3720 (0.3363) acc 65.6250 (69.5312) lr 5.1825e-04 eta 0:10:35
epoch [35/50] batch [40/445] time 0.071 (0.080) data 0.000 (0.012) loss 1.5346 (1.5111) teacher_loss 0.9168 (0.8924) loss_zs_kd 1.4016 (1.6964) loss_oracle 0.3142 (0.3335) acc 68.7500 (68.7500) lr 5.1825e-04 eta 0:09:28
epoch [35/50] batch [60/445] time 0.074 (0.078) data 0.001 (0.008) loss 1.5559 (1.5241) teacher_loss 1.0045 (0.9126) loss_zs_kd 1.4552 (1.7005) loss_oracle 0.3398 (0.3334) acc 65.6250 (68.0729) lr 5.1825e-04 eta 0:09:11
epoch [35/50] batch [80/445] time 0.073 (0.077) data 0.001 (0.006) loss 1.5526 (1.5112) teacher_loss 0.9609 (0.8967) loss_zs_kd 1.3116 (1.6783) loss_oracle 0.3377 (0.3341) acc 68.7500 (68.8281) lr 5.1825e-04 eta 0:09:02
epoch [35/50] batch [100/445] time 0.071 (0.077) data 0.000 (0.005) loss 1.4889 (1.5061) teacher_loss 0.7727 (0.8874) loss_zs_kd 1.8058 (1.7065) loss_oracle 0.3406 (0.3342) acc 71.8750 (69.3125) lr 5.1825e-04 eta 0:09:00
epoch [35/50] batch [120/445] time 0.084 (0.077) data 0.000 (0.004) loss 1.2549 (1.5124) teacher_loss 0.6544 (0.8933) loss_zs_kd 1.4251 (1.7256) loss_oracle 0.3143 (0.3337) acc 75.0000 (68.9062) lr 5.1825e-04 eta 0:08:58
epoch [35/50] batch [140/445] time 0.071 (0.077) data 0.000 (0.004) loss 1.4433 (1.5180) teacher_loss 0.8361 (0.8951) loss_zs_kd 1.5501 (1.7226) loss_oracle 0.3453 (0.3333) acc 71.8750 (68.9509) lr 5.1825e-04 eta 0:08:59
epoch [35/50] batch [160/445] time 0.075 (0.078) data 0.000 (0.003) loss 2.0704 (1.5235) teacher_loss 1.3927 (0.9010) loss_zs_kd 2.2562 (1.7374) loss_oracle 0.3454 (0.3320) acc 50.0000 (68.5938) lr 5.1825e-04 eta 0:09:00
epoch [35/50] batch [180/445] time 0.062 (0.077) data 0.000 (0.003) loss 1.4830 (1.5172) teacher_loss 0.9611 (0.8947) loss_zs_kd 1.9706 (1.7395) loss_oracle 0.3143 (0.3314) acc 59.3750 (68.6285) lr 5.1825e-04 eta 0:08:55
epoch [35/50] batch [200/445] time 0.079 (0.077) data 0.000 (0.003) loss 1.3901 (1.5169) teacher_loss 0.8585 (0.8966) loss_zs_kd 1.7147 (1.7248) loss_oracle 0.3765 (0.3321) acc 68.7500 (68.6562) lr 5.1825e-04 eta 0:08:50
epoch [35/50] batch [220/445] time 0.071 (0.076) data 0.000 (0.003) loss 1.3208 (1.5148) teacher_loss 0.8028 (0.8983) loss_zs_kd 1.9276 (1.7275) loss_oracle 0.3143 (0.3315) acc 68.7500 (68.5227) lr 5.1825e-04 eta 0:08:44
epoch [35/50] batch [240/445] time 0.069 (0.076) data 0.000 (0.002) loss 1.3404 (1.5131) teacher_loss 0.7385 (0.8975) loss_zs_kd 1.6371 (1.7176) loss_oracle 0.3143 (0.3317) acc 81.2500 (68.6068) lr 5.1825e-04 eta 0:08:40
epoch [35/50] batch [260/445] time 0.077 (0.076) data 0.000 (0.002) loss 1.3643 (1.5096) teacher_loss 0.6915 (0.8942) loss_zs_kd 1.8623 (1.7187) loss_oracle 0.3530 (0.3315) acc 75.0000 (68.8101) lr 5.1825e-04 eta 0:08:38
epoch [35/50] batch [280/445] time 0.100 (0.076) data 0.000 (0.002) loss 1.5147 (1.5095) teacher_loss 0.8959 (0.8941) loss_zs_kd 1.7036 (1.7110) loss_oracle 0.3144 (0.3314) acc 71.8750 (68.7835) lr 5.1825e-04 eta 0:08:42
epoch [35/50] batch [300/445] time 0.071 (0.077) data 0.000 (0.002) loss 1.4470 (1.5104) teacher_loss 0.9037 (0.8951) loss_zs_kd 2.1904 (1.7164) loss_oracle 0.2990 (0.3314) acc 68.7500 (68.6979) lr 5.1825e-04 eta 0:08:41
epoch [35/50] batch [320/445] time 0.064 (0.076) data 0.000 (0.002) loss 1.8082 (1.5115) teacher_loss 1.2084 (0.8980) loss_zs_kd 1.5558 (1.7118) loss_oracle 0.3204 (0.3316) acc 50.0000 (68.6426) lr 5.1825e-04 eta 0:08:38
epoch [35/50] batch [340/445] time 0.073 (0.076) data 0.001 (0.002) loss 1.5133 (1.5046) teacher_loss 0.9035 (0.8922) loss_zs_kd 1.7280 (1.7114) loss_oracle 0.3143 (0.3318) acc 68.7500 (68.9062) lr 5.1825e-04 eta 0:08:34
epoch [35/50] batch [360/445] time 0.076 (0.076) data 0.000 (0.002) loss 1.4906 (1.5077) teacher_loss 0.8735 (0.8955) loss_zs_kd 1.9472 (1.7145) loss_oracle 0.3047 (0.3319) acc 75.0000 (68.8194) lr 5.1825e-04 eta 0:08:33
epoch [35/50] batch [380/445] time 0.072 (0.076) data 0.000 (0.002) loss 1.9100 (1.5129) teacher_loss 1.2078 (0.9008) loss_zs_kd 1.7119 (1.7188) loss_oracle 0.3454 (0.3319) acc 53.1250 (68.6184) lr 5.1825e-04 eta 0:08:30
epoch [35/50] batch [400/445] time 0.069 (0.076) data 0.000 (0.002) loss 1.5329 (1.5098) teacher_loss 0.8944 (0.8992) loss_zs_kd 1.3949 (1.7149) loss_oracle 0.3720 (0.3320) acc 68.7500 (68.7109) lr 5.1825e-04 eta 0:08:28
epoch [35/50] batch [420/445] time 0.045 (0.075) data 0.000 (0.001) loss 1.4643 (1.5090) teacher_loss 1.0162 (0.8994) loss_zs_kd 1.9742 (1.7158) loss_oracle 0.3143 (0.3318) acc 59.3750 (68.6533) lr 5.1825e-04 eta 0:08:24
epoch [35/50] batch [440/445] time 0.060 (0.075) data 0.000 (0.001) loss 1.7248 (1.5092) teacher_loss 1.0086 (0.9004) loss_zs_kd 1.6816 (1.7113) loss_oracle 0.3454 (0.3316) acc 65.6250 (68.5440) lr 5.1825e-04 eta 0:08:19
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,326
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 57.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,955
* accuracy: 49.2%
* error: 50.8%
* macro_f1: 31.2%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [36/50] batch [20/445] time 0.073 (0.104) data 0.000 (0.025) loss 1.3483 (1.4773) teacher_loss 0.6751 (0.8743) loss_zs_kd 1.4301 (1.6064) loss_oracle 0.3139 (0.3364) acc 78.1250 (68.1250) lr 4.6417e-04 eta 0:11:29
epoch [36/50] batch [40/445] time 0.063 (0.090) data 0.000 (0.013) loss 1.2179 (1.4890) teacher_loss 0.7304 (0.8872) loss_zs_kd 1.4679 (1.5704) loss_oracle 0.3143 (0.3319) acc 75.0000 (67.7344) lr 4.6417e-04 eta 0:09:55
epoch [36/50] batch [60/445] time 0.065 (0.090) data 0.000 (0.009) loss 1.2994 (1.4848) teacher_loss 0.7170 (0.8840) loss_zs_kd 1.7257 (1.5899) loss_oracle 0.3765 (0.3320) acc 78.1250 (67.9167) lr 4.6417e-04 eta 0:09:56
epoch [36/50] batch [80/445] time 0.071 (0.086) data 0.000 (0.007) loss 1.3338 (1.4775) teacher_loss 0.7237 (0.8777) loss_zs_kd 1.8825 (1.6092) loss_oracle 0.3144 (0.3302) acc 65.6250 (68.7109) lr 4.6417e-04 eta 0:09:25
epoch [36/50] batch [100/445] time 0.069 (0.083) data 0.000 (0.005) loss 1.5756 (1.4728) teacher_loss 1.0125 (0.8749) loss_zs_kd 1.6567 (1.6221) loss_oracle 0.3049 (0.3300) acc 59.3750 (68.4688) lr 4.6417e-04 eta 0:09:05
epoch [36/50] batch [120/445] time 0.072 (0.081) data 0.000 (0.004) loss 1.7159 (1.4860) teacher_loss 1.0689 (0.8874) loss_zs_kd 1.9609 (1.6307) loss_oracle 0.3613 (0.3300) acc 65.6250 (68.1771) lr 4.6417e-04 eta 0:08:53
epoch [36/50] batch [140/445] time 0.078 (0.080) data 0.000 (0.004) loss 1.8122 (1.4829) teacher_loss 1.0006 (0.8825) loss_zs_kd 1.6339 (1.6294) loss_oracle 0.3764 (0.3300) acc 62.5000 (68.4821) lr 4.6417e-04 eta 0:08:43
epoch [36/50] batch [160/445] time 0.075 (0.079) data 0.000 (0.003) loss 0.9429 (1.4990) teacher_loss 0.3900 (0.8965) loss_zs_kd 1.5851 (1.6321) loss_oracle 0.3122 (0.3303) acc 93.7500 (68.1250) lr 4.6417e-04 eta 0:08:35
epoch [36/50] batch [180/445] time 0.071 (0.078) data 0.000 (0.003) loss 1.6707 (1.5032) teacher_loss 1.0512 (0.9027) loss_zs_kd 1.3250 (1.6200) loss_oracle 0.4283 (0.3307) acc 68.7500 (67.9688) lr 4.6417e-04 eta 0:08:29
epoch [36/50] batch [200/445] time 0.073 (0.078) data 0.000 (0.003) loss 1.4268 (1.5007) teacher_loss 0.8148 (0.9001) loss_zs_kd 1.4937 (1.6143) loss_oracle 0.4076 (0.3309) acc 68.7500 (67.9688) lr 4.6417e-04 eta 0:08:24
epoch [36/50] batch [220/445] time 0.075 (0.078) data 0.000 (0.003) loss 1.2244 (1.4973) teacher_loss 0.6083 (0.8977) loss_zs_kd 1.4486 (1.6137) loss_oracle 0.3140 (0.3309) acc 75.0000 (68.1818) lr 4.6417e-04 eta 0:08:21
epoch [36/50] batch [240/445] time 0.076 (0.077) data 0.001 (0.002) loss 1.4903 (1.4948) teacher_loss 0.9194 (0.8943) loss_zs_kd 1.9719 (1.6207) loss_oracle 0.3066 (0.3309) acc 65.6250 (68.2552) lr 4.6417e-04 eta 0:08:17
epoch [36/50] batch [260/445] time 0.070 (0.077) data 0.000 (0.002) loss 1.8827 (1.4978) teacher_loss 1.2199 (0.8963) loss_zs_kd 1.7995 (1.6276) loss_oracle 0.3347 (0.3311) acc 53.1250 (68.1731) lr 4.6417e-04 eta 0:08:14
epoch [36/50] batch [280/445] time 0.070 (0.077) data 0.000 (0.002) loss 1.5646 (1.4997) teacher_loss 0.9555 (0.8985) loss_zs_kd 1.8842 (1.6267) loss_oracle 0.2966 (0.3308) acc 75.0000 (68.2031) lr 4.6417e-04 eta 0:08:10
epoch [36/50] batch [300/445] time 0.067 (0.076) data 0.000 (0.002) loss 1.5364 (1.5003) teacher_loss 0.8891 (0.8987) loss_zs_kd 1.7335 (1.6242) loss_oracle 0.3130 (0.3302) acc 59.3750 (68.1458) lr 4.6417e-04 eta 0:08:06
epoch [36/50] batch [320/445] time 0.070 (0.076) data 0.000 (0.002) loss 1.7143 (1.5011) teacher_loss 1.0303 (0.8987) loss_zs_kd 1.5970 (1.6280) loss_oracle 0.3337 (0.3300) acc 62.5000 (68.0957) lr 4.6417e-04 eta 0:08:01
epoch [36/50] batch [340/445] time 0.068 (0.076) data 0.000 (0.002) loss 1.6260 (1.4994) teacher_loss 1.0211 (0.8963) loss_zs_kd 1.8719 (1.6328) loss_oracle 0.3143 (0.3292) acc 56.2500 (68.1618) lr 4.6417e-04 eta 0:07:59
epoch [36/50] batch [360/445] time 0.077 (0.076) data 0.000 (0.002) loss 1.5848 (1.4998) teacher_loss 0.9365 (0.8964) loss_zs_kd 1.7985 (1.6268) loss_oracle 0.3141 (0.3292) acc 65.6250 (68.1684) lr 4.6417e-04 eta 0:07:57
epoch [36/50] batch [380/445] time 0.076 (0.076) data 0.000 (0.002) loss 1.4341 (1.5012) teacher_loss 0.8639 (0.8972) loss_zs_kd 1.2774 (1.6292) loss_oracle 0.3143 (0.3293) acc 71.8750 (68.1086) lr 4.6417e-04 eta 0:07:56
epoch [36/50] batch [400/445] time 0.078 (0.075) data 0.000 (0.002) loss 1.1513 (1.4965) teacher_loss 0.6325 (0.8927) loss_zs_kd 1.6769 (1.6314) loss_oracle 0.3143 (0.3291) acc 71.8750 (68.2500) lr 4.6417e-04 eta 0:07:52
epoch [36/50] batch [420/445] time 0.077 (0.075) data 0.000 (0.002) loss 1.3161 (1.4948) teacher_loss 0.7809 (0.8911) loss_zs_kd 1.5338 (1.6352) loss_oracle 0.3140 (0.3289) acc 65.6250 (68.3631) lr 4.6417e-04 eta 0:07:51
epoch [36/50] batch [440/445] time 0.065 (0.075) data 0.000 (0.001) loss 1.4852 (1.4936) teacher_loss 0.9186 (0.8894) loss_zs_kd 1.8028 (1.6381) loss_oracle 0.3143 (0.3290) acc 68.7500 (68.4020) lr 4.6417e-04 eta 0:07:48
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,337
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 57.0%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,029
* accuracy: 51.1%
* error: 48.9%
* macro_f1: 32.1%
******* Domain 3 best val acc:      71.2%, epoch: 31 *******
******* Domain 3 best val test acc: 51.5%, epoch: 31 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [37/50] batch [20/445] time 0.062 (0.089) data 0.000 (0.028) loss 1.4593 (1.6311) teacher_loss 0.8970 (1.0035) loss_zs_kd 1.6321 (1.6673) loss_oracle 0.3451 (0.3311) acc 62.5000 (63.7500) lr 4.1221e-04 eta 0:09:14
epoch [37/50] batch [40/445] time 0.070 (0.080) data 0.000 (0.014) loss 1.5059 (1.5370) teacher_loss 0.9248 (0.9270) loss_zs_kd 1.7657 (1.6518) loss_oracle 0.3143 (0.3284) acc 71.8750 (67.5781) lr 4.1221e-04 eta 0:08:14
epoch [37/50] batch [60/445] time 0.082 (0.077) data 0.000 (0.010) loss 1.3701 (1.5327) teacher_loss 0.6913 (0.9265) loss_zs_kd 2.3439 (1.6608) loss_oracle 0.3357 (0.3260) acc 71.8750 (67.0833) lr 4.1221e-04 eta 0:07:58
epoch [37/50] batch [80/445] time 0.071 (0.077) data 0.000 (0.007) loss 1.3371 (1.5224) teacher_loss 0.7174 (0.9147) loss_zs_kd 1.2265 (1.6469) loss_oracle 0.3143 (0.3261) acc 71.8750 (67.9688) lr 4.1221e-04 eta 0:07:50
epoch [37/50] batch [100/445] time 0.065 (0.076) data 0.000 (0.006) loss 1.3616 (1.5164) teacher_loss 0.6372 (0.9094) loss_zs_kd 1.9701 (1.6573) loss_oracle 0.3303 (0.3254) acc 75.0000 (68.0938) lr 4.1221e-04 eta 0:07:47
epoch [37/50] batch [120/445] time 0.071 (0.076) data 0.000 (0.005) loss 1.3411 (1.5132) teacher_loss 0.7736 (0.9045) loss_zs_kd 1.6689 (1.6541) loss_oracle 0.3143 (0.3259) acc 68.7500 (68.2552) lr 4.1221e-04 eta 0:07:42
epoch [37/50] batch [140/445] time 0.067 (0.075) data 0.000 (0.004) loss 1.4529 (1.5049) teacher_loss 0.8005 (0.8945) loss_zs_kd 1.5052 (1.6602) loss_oracle 0.3347 (0.3264) acc 65.6250 (68.3259) lr 4.1221e-04 eta 0:07:38
epoch [37/50] batch [160/445] time 0.073 (0.075) data 0.000 (0.004) loss 1.1442 (1.5123) teacher_loss 0.5902 (0.9021) loss_zs_kd 1.4962 (1.6432) loss_oracle 0.3143 (0.3272) acc 84.3750 (68.3008) lr 4.1221e-04 eta 0:07:36
epoch [37/50] batch [180/445] time 0.073 (0.075) data 0.000 (0.003) loss 1.4015 (1.5019) teacher_loss 0.8594 (0.8941) loss_zs_kd 1.7488 (1.6317) loss_oracle 0.3143 (0.3268) acc 75.0000 (68.8021) lr 4.1221e-04 eta 0:07:33
epoch [37/50] batch [200/445] time 0.069 (0.075) data 0.000 (0.003) loss 1.7035 (1.5011) teacher_loss 1.0608 (0.8931) loss_zs_kd 1.6808 (1.6197) loss_oracle 0.3412 (0.3272) acc 56.2500 (68.8438) lr 4.1221e-04 eta 0:07:31
epoch [37/50] batch [220/445] time 0.077 (0.075) data 0.000 (0.003) loss 1.5860 (1.4998) teacher_loss 0.9387 (0.8925) loss_zs_kd 1.5897 (1.6341) loss_oracle 0.3143 (0.3267) acc 62.5000 (68.8352) lr 4.1221e-04 eta 0:07:31
epoch [37/50] batch [240/445] time 0.079 (0.075) data 0.000 (0.003) loss 1.6503 (1.4950) teacher_loss 1.1151 (0.8890) loss_zs_kd 1.4877 (1.6316) loss_oracle 0.3328 (0.3262) acc 56.2500 (68.9193) lr 4.1221e-04 eta 0:07:29
epoch [37/50] batch [260/445] time 0.073 (0.075) data 0.000 (0.003) loss 2.0943 (1.5010) teacher_loss 1.3654 (0.8946) loss_zs_kd 1.8789 (1.6417) loss_oracle 0.3449 (0.3262) acc 50.0000 (68.7139) lr 4.1221e-04 eta 0:07:27
epoch [37/50] batch [280/445] time 0.082 (0.076) data 0.000 (0.002) loss 1.5066 (1.5023) teacher_loss 0.9340 (0.8950) loss_zs_kd 1.9227 (1.6459) loss_oracle 0.2966 (0.3266) acc 62.5000 (68.7277) lr 4.1221e-04 eta 0:07:32
epoch [37/50] batch [300/445] time 0.074 (0.076) data 0.000 (0.002) loss 1.6638 (1.4997) teacher_loss 0.9895 (0.8929) loss_zs_kd 1.9116 (1.6461) loss_oracle 0.3626 (0.3270) acc 68.7500 (68.7604) lr 4.1221e-04 eta 0:07:30
epoch [37/50] batch [320/445] time 0.073 (0.076) data 0.000 (0.002) loss 1.6513 (1.4967) teacher_loss 1.0329 (0.8900) loss_zs_kd 1.6575 (1.6415) loss_oracle 0.3143 (0.3273) acc 50.0000 (68.8086) lr 4.1221e-04 eta 0:07:29
epoch [37/50] batch [340/445] time 0.072 (0.076) data 0.000 (0.002) loss 1.6608 (1.4938) teacher_loss 1.0782 (0.8879) loss_zs_kd 1.7124 (1.6397) loss_oracle 0.3454 (0.3278) acc 59.3750 (68.9246) lr 4.1221e-04 eta 0:07:26
epoch [37/50] batch [360/445] time 0.074 (0.076) data 0.000 (0.002) loss 1.4342 (1.4950) teacher_loss 0.8968 (0.8886) loss_zs_kd 1.3902 (1.6352) loss_oracle 0.3453 (0.3284) acc 62.5000 (68.9149) lr 4.1221e-04 eta 0:07:23
epoch [37/50] batch [380/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.8940 (1.4977) teacher_loss 1.2474 (0.8904) loss_zs_kd 1.6075 (1.6407) loss_oracle 0.3302 (0.3291) acc 56.2500 (68.7747) lr 4.1221e-04 eta 0:07:21
epoch [37/50] batch [400/445] time 0.079 (0.075) data 0.000 (0.002) loss 1.4297 (1.4974) teacher_loss 0.7732 (0.8905) loss_zs_kd 1.6586 (1.6425) loss_oracle 0.3189 (0.3290) acc 65.6250 (68.7109) lr 4.1221e-04 eta 0:07:19
epoch [37/50] batch [420/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.4738 (1.4955) teacher_loss 0.8554 (0.8891) loss_zs_kd 1.5208 (1.6481) loss_oracle 0.3143 (0.3288) acc 65.6250 (68.8170) lr 4.1221e-04 eta 0:07:17
epoch [37/50] batch [440/445] time 0.063 (0.075) data 0.000 (0.002) loss 1.3762 (1.4961) teacher_loss 0.7957 (0.8894) loss_zs_kd 1.5337 (1.6534) loss_oracle 0.3143 (0.3289) acc 68.7500 (68.8281) lr 4.1221e-04 eta 0:07:14
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,353
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 57.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,023
* accuracy: 51.0%
* error: 49.0%
* macro_f1: 31.9%
******* Domain 3 best val acc:      71.3%, epoch: 37 *******
******* Domain 3 best val test acc: 51.0%, epoch: 37 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [38/50] batch [20/445] time 0.095 (0.109) data 0.000 (0.024) loss 1.4556 (1.4743) teacher_loss 0.9237 (0.8627) loss_zs_kd 1.5997 (1.7476) loss_oracle 0.3500 (0.3228) acc 81.2500 (69.5312) lr 3.6258e-04 eta 0:10:28
epoch [38/50] batch [40/445] time 0.072 (0.092) data 0.000 (0.012) loss 1.4076 (1.4912) teacher_loss 0.7723 (0.8819) loss_zs_kd 1.8794 (1.7396) loss_oracle 0.3107 (0.3265) acc 68.7500 (67.9688) lr 3.6258e-04 eta 0:08:45
epoch [38/50] batch [60/445] time 0.077 (0.086) data 0.000 (0.008) loss 1.4030 (1.4778) teacher_loss 0.7747 (0.8695) loss_zs_kd 1.6572 (1.7332) loss_oracle 0.3454 (0.3289) acc 68.7500 (68.5417) lr 3.6258e-04 eta 0:08:10
epoch [38/50] batch [80/445] time 0.068 (0.084) data 0.000 (0.006) loss 1.1562 (1.4632) teacher_loss 0.5883 (0.8510) loss_zs_kd 1.9782 (1.7276) loss_oracle 0.3143 (0.3292) acc 87.5000 (69.1016) lr 3.6258e-04 eta 0:07:57
epoch [38/50] batch [100/445] time 0.076 (0.083) data 0.000 (0.005) loss 1.4557 (1.4714) teacher_loss 0.8020 (0.8567) loss_zs_kd 1.6767 (1.7195) loss_oracle 0.3454 (0.3306) acc 81.2500 (68.9375) lr 3.6258e-04 eta 0:07:50
epoch [38/50] batch [120/445] time 0.070 (0.081) data 0.000 (0.004) loss 1.3963 (1.4667) teacher_loss 0.8494 (0.8514) loss_zs_kd 1.1832 (1.7142) loss_oracle 0.3143 (0.3309) acc 71.8750 (69.4010) lr 3.6258e-04 eta 0:07:41
epoch [38/50] batch [140/445] time 0.082 (0.081) data 0.000 (0.004) loss 1.6485 (1.4730) teacher_loss 1.0006 (0.8579) loss_zs_kd 1.3958 (1.7043) loss_oracle 0.3142 (0.3311) acc 65.6250 (69.6205) lr 3.6258e-04 eta 0:07:38
epoch [38/50] batch [160/445] time 0.085 (0.082) data 0.000 (0.003) loss 1.6664 (1.4741) teacher_loss 1.1250 (0.8589) loss_zs_kd 1.6290 (1.7043) loss_oracle 0.3139 (0.3317) acc 56.2500 (69.5312) lr 3.6258e-04 eta 0:07:38
epoch [38/50] batch [180/445] time 0.070 (0.080) data 0.000 (0.003) loss 1.1519 (1.4727) teacher_loss 0.6419 (0.8552) loss_zs_kd 1.6486 (1.7041) loss_oracle 0.3449 (0.3315) acc 81.2500 (69.5833) lr 3.6258e-04 eta 0:07:30
epoch [38/50] batch [200/445] time 0.079 (0.081) data 0.000 (0.003) loss 1.7309 (1.4785) teacher_loss 1.0694 (0.8600) loss_zs_kd 1.9856 (1.7003) loss_oracle 0.3398 (0.3313) acc 68.7500 (69.4531) lr 3.6258e-04 eta 0:07:29
epoch [38/50] batch [220/445] time 0.081 (0.080) data 0.000 (0.003) loss 1.3805 (1.4793) teacher_loss 0.7170 (0.8583) loss_zs_kd 1.1205 (1.6999) loss_oracle 0.3357 (0.3316) acc 71.8750 (69.5170) lr 3.6258e-04 eta 0:07:26
epoch [38/50] batch [240/445] time 0.074 (0.080) data 0.000 (0.002) loss 1.6347 (1.4870) teacher_loss 1.0462 (0.8644) loss_zs_kd 1.2377 (1.7025) loss_oracle 0.3143 (0.3315) acc 62.5000 (69.2578) lr 3.6258e-04 eta 0:07:24
epoch [38/50] batch [260/445] time 0.067 (0.080) data 0.000 (0.002) loss 1.4031 (1.4860) teacher_loss 0.7225 (0.8639) loss_zs_kd 1.5909 (1.7022) loss_oracle 0.3047 (0.3309) acc 75.0000 (69.2308) lr 3.6258e-04 eta 0:07:22
epoch [38/50] batch [280/445] time 0.073 (0.080) data 0.000 (0.002) loss 1.2551 (1.4855) teacher_loss 0.6564 (0.8616) loss_zs_kd 1.3329 (1.6970) loss_oracle 0.4016 (0.3311) acc 75.0000 (69.3527) lr 3.6258e-04 eta 0:07:18
epoch [38/50] batch [300/445] time 0.073 (0.079) data 0.000 (0.002) loss 1.4759 (1.4868) teacher_loss 0.8454 (0.8631) loss_zs_kd 1.6423 (1.6953) loss_oracle 0.3105 (0.3309) acc 68.7500 (69.3542) lr 3.6258e-04 eta 0:07:15
epoch [38/50] batch [320/445] time 0.079 (0.079) data 0.000 (0.002) loss 1.5547 (1.4920) teacher_loss 0.9031 (0.8683) loss_zs_kd 1.9753 (1.6952) loss_oracle 0.3760 (0.3309) acc 62.5000 (69.2773) lr 3.6258e-04 eta 0:07:11
epoch [38/50] batch [340/445] time 0.071 (0.079) data 0.000 (0.002) loss 1.5659 (1.4947) teacher_loss 0.9529 (0.8716) loss_zs_kd 2.0523 (1.6962) loss_oracle 0.3386 (0.3309) acc 71.8750 (69.2371) lr 3.6258e-04 eta 0:07:09
epoch [38/50] batch [360/445] time 0.074 (0.079) data 0.000 (0.002) loss 1.6519 (1.4966) teacher_loss 1.0238 (0.8740) loss_zs_kd 2.1886 (1.7036) loss_oracle 0.3675 (0.3307) acc 56.2500 (69.0278) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [380/445] time 0.066 (0.078) data 0.000 (0.002) loss 1.6948 (1.5055) teacher_loss 1.1303 (0.8830) loss_zs_kd 1.5689 (1.7047) loss_oracle 0.3454 (0.3309) acc 59.3750 (68.6842) lr 3.6258e-04 eta 0:07:03
epoch [38/50] batch [400/445] time 0.070 (0.078) data 0.000 (0.002) loss 1.3037 (1.5074) teacher_loss 0.7116 (0.8845) loss_zs_kd 1.4230 (1.7023) loss_oracle 0.3689 (0.3311) acc 75.0000 (68.7578) lr 3.6258e-04 eta 0:07:00
epoch [38/50] batch [420/445] time 0.079 (0.078) data 0.000 (0.001) loss 1.3280 (1.5071) teacher_loss 0.7598 (0.8841) loss_zs_kd 1.3035 (1.7009) loss_oracle 0.3453 (0.3313) acc 75.0000 (68.8095) lr 3.6258e-04 eta 0:06:58
epoch [38/50] batch [440/445] time 0.069 (0.078) data 0.000 (0.001) loss 1.5120 (1.5115) teacher_loss 0.9253 (0.8876) loss_zs_kd 1.9291 (1.6971) loss_oracle 0.3143 (0.3311) acc 62.5000 (68.7216) lr 3.6258e-04 eta 0:06:55
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,360
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 57.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,063
* accuracy: 52.0%
* error: 48.0%
* macro_f1: 32.0%
******* Domain 3 best val acc:      71.4%, epoch: 38 *******
******* Domain 3 best val test acc: 52.0%, epoch: 38 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [39/50] batch [20/445] time 0.074 (0.105) data 0.000 (0.029) loss 1.2509 (1.5438) teacher_loss 0.6846 (0.9280) loss_zs_kd 1.5335 (1.5959) loss_oracle 0.3454 (0.3296) acc 78.1250 (67.0312) lr 3.1545e-04 eta 0:09:18
epoch [39/50] batch [40/445] time 0.065 (0.087) data 0.000 (0.015) loss 1.3502 (1.5075) teacher_loss 0.6398 (0.8889) loss_zs_kd 1.7019 (1.6076) loss_oracle 0.3646 (0.3373) acc 81.2500 (68.9844) lr 3.1545e-04 eta 0:07:40
epoch [39/50] batch [60/445] time 0.077 (0.082) data 0.000 (0.010) loss 1.5733 (1.4946) teacher_loss 0.8944 (0.8722) loss_zs_kd 1.5728 (1.6531) loss_oracle 0.3082 (0.3340) acc 68.7500 (69.7396) lr 3.1545e-04 eta 0:07:14
epoch [39/50] batch [80/445] time 0.066 (0.079) data 0.000 (0.008) loss 1.7305 (1.4958) teacher_loss 1.1846 (0.8757) loss_zs_kd 1.8114 (1.6620) loss_oracle 0.3438 (0.3350) acc 50.0000 (69.2969) lr 3.1545e-04 eta 0:06:55
epoch [39/50] batch [100/445] time 0.068 (0.077) data 0.000 (0.006) loss 1.3851 (1.4813) teacher_loss 0.7008 (0.8563) loss_zs_kd 1.8285 (1.6719) loss_oracle 0.3760 (0.3360) acc 78.1250 (70.0938) lr 3.1545e-04 eta 0:06:43
epoch [39/50] batch [120/445] time 0.076 (0.076) data 0.000 (0.005) loss 1.4157 (1.4783) teacher_loss 0.7802 (0.8539) loss_zs_kd 1.5685 (1.6789) loss_oracle 0.3758 (0.3347) acc 62.5000 (70.3646) lr 3.1545e-04 eta 0:06:38
epoch [39/50] batch [140/445] time 0.067 (0.076) data 0.000 (0.004) loss 1.4912 (1.4827) teacher_loss 0.8005 (0.8589) loss_zs_kd 1.6401 (1.6789) loss_oracle 0.3412 (0.3342) acc 71.8750 (70.1116) lr 3.1545e-04 eta 0:06:34
epoch [39/50] batch [160/445] time 0.071 (0.075) data 0.000 (0.004) loss 1.5579 (1.4772) teacher_loss 0.9114 (0.8529) loss_zs_kd 1.8900 (1.6732) loss_oracle 0.3454 (0.3351) acc 65.6250 (70.3906) lr 3.1545e-04 eta 0:06:30
epoch [39/50] batch [180/445] time 0.072 (0.075) data 0.000 (0.004) loss 1.5900 (1.4790) teacher_loss 0.8409 (0.8540) loss_zs_kd 1.7292 (1.6629) loss_oracle 0.4386 (0.3355) acc 78.1250 (70.0694) lr 3.1545e-04 eta 0:06:26
epoch [39/50] batch [200/445] time 0.088 (0.076) data 0.001 (0.003) loss 1.7572 (1.4839) teacher_loss 1.1582 (0.8605) loss_zs_kd 1.8484 (1.6631) loss_oracle 0.3445 (0.3360) acc 53.1250 (69.7656) lr 3.1545e-04 eta 0:06:30
epoch [39/50] batch [220/445] time 0.066 (0.075) data 0.000 (0.003) loss 1.1865 (1.4806) teacher_loss 0.5570 (0.8583) loss_zs_kd 1.8641 (1.6743) loss_oracle 0.3586 (0.3344) acc 84.3750 (69.8011) lr 3.1545e-04 eta 0:06:25
epoch [39/50] batch [240/445] time 0.075 (0.075) data 0.000 (0.003) loss 1.3601 (1.4789) teacher_loss 0.8264 (0.8584) loss_zs_kd 1.3642 (1.6774) loss_oracle 0.3141 (0.3341) acc 65.6250 (69.8047) lr 3.1545e-04 eta 0:06:21
epoch [39/50] batch [260/445] time 0.072 (0.075) data 0.000 (0.003) loss 1.6607 (1.4781) teacher_loss 0.9891 (0.8585) loss_zs_kd 1.7731 (1.6835) loss_oracle 0.3143 (0.3344) acc 75.0000 (69.7957) lr 3.1545e-04 eta 0:06:18
epoch [39/50] batch [280/445] time 0.073 (0.074) data 0.000 (0.002) loss 1.7198 (1.4802) teacher_loss 1.0116 (0.8593) loss_zs_kd 1.5504 (1.6905) loss_oracle 0.3454 (0.3348) acc 56.2500 (69.8103) lr 3.1545e-04 eta 0:06:15
epoch [39/50] batch [300/445] time 0.074 (0.074) data 0.000 (0.002) loss 1.4340 (1.4792) teacher_loss 0.8776 (0.8598) loss_zs_kd 1.8508 (1.6969) loss_oracle 0.3764 (0.3349) acc 75.0000 (69.6562) lr 3.1545e-04 eta 0:06:13
epoch [39/50] batch [320/445] time 0.071 (0.074) data 0.000 (0.002) loss 1.7379 (1.4861) teacher_loss 1.0954 (0.8654) loss_zs_kd 1.7528 (1.6982) loss_oracle 0.3444 (0.3349) acc 59.3750 (69.3848) lr 3.1545e-04 eta 0:06:11
epoch [39/50] batch [340/445] time 0.072 (0.074) data 0.000 (0.002) loss 1.5851 (1.4880) teacher_loss 0.8017 (0.8671) loss_zs_kd 2.4321 (1.7005) loss_oracle 0.3023 (0.3346) acc 71.8750 (69.4669) lr 3.1545e-04 eta 0:06:09
epoch [39/50] batch [360/445] time 0.076 (0.074) data 0.000 (0.002) loss 1.5280 (1.4878) teacher_loss 0.8865 (0.8666) loss_zs_kd 1.3668 (1.7028) loss_oracle 0.3444 (0.3344) acc 75.0000 (69.5747) lr 3.1545e-04 eta 0:06:08
epoch [39/50] batch [380/445] time 0.071 (0.074) data 0.000 (0.002) loss 1.4277 (1.4911) teacher_loss 0.8054 (0.8705) loss_zs_kd 1.2966 (1.7029) loss_oracle 0.3954 (0.3342) acc 65.6250 (69.4243) lr 3.1545e-04 eta 0:06:06
epoch [39/50] batch [400/445] time 0.072 (0.074) data 0.000 (0.002) loss 1.7513 (1.4925) teacher_loss 1.1627 (0.8716) loss_zs_kd 1.2154 (1.7025) loss_oracle 0.3043 (0.3337) acc 62.5000 (69.3203) lr 3.1545e-04 eta 0:06:04
epoch [39/50] batch [420/445] time 0.082 (0.074) data 0.000 (0.002) loss 1.5883 (1.4939) teacher_loss 0.9443 (0.8733) loss_zs_kd 1.9610 (1.7042) loss_oracle 0.3047 (0.3334) acc 65.6250 (69.1815) lr 3.1545e-04 eta 0:06:02
epoch [39/50] batch [440/445] time 0.069 (0.074) data 0.000 (0.002) loss 1.2823 (1.4949) teacher_loss 0.6725 (0.8737) loss_zs_kd 1.4453 (1.7044) loss_oracle 0.3374 (0.3337) acc 71.8750 (69.1619) lr 3.1545e-04 eta 0:06:00
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,358
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 56.9%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,018
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 31.5%
******* Domain 3 best val acc:      71.4%, epoch: 38 *******
******* Domain 3 best val test acc: 52.0%, epoch: 38 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [40/50] batch [20/445] time 0.073 (0.100) data 0.000 (0.025) loss 1.5262 (1.5147) teacher_loss 0.9539 (0.8954) loss_zs_kd 1.5081 (1.6625) loss_oracle 0.3055 (0.3280) acc 71.8750 (69.2188) lr 2.7103e-04 eta 0:08:06
epoch [40/50] batch [40/445] time 0.071 (0.086) data 0.000 (0.013) loss 1.3589 (1.4883) teacher_loss 0.6809 (0.8772) loss_zs_kd 2.0513 (1.6797) loss_oracle 0.3350 (0.3314) acc 78.1250 (70.1562) lr 2.7103e-04 eta 0:06:56
epoch [40/50] batch [60/445] time 0.084 (0.081) data 0.000 (0.009) loss 1.2778 (1.4648) teacher_loss 0.6388 (0.8553) loss_zs_kd 1.4294 (1.6933) loss_oracle 0.3645 (0.3327) acc 78.1250 (70.6771) lr 2.7103e-04 eta 0:06:33
epoch [40/50] batch [80/445] time 0.069 (0.079) data 0.000 (0.007) loss 1.3804 (1.4727) teacher_loss 0.8000 (0.8611) loss_zs_kd 1.7510 (1.7063) loss_oracle 0.3454 (0.3324) acc 65.6250 (70.9766) lr 2.7103e-04 eta 0:06:19
epoch [40/50] batch [100/445] time 0.073 (0.078) data 0.000 (0.005) loss 1.9708 (1.4916) teacher_loss 1.2985 (0.8747) loss_zs_kd 1.9758 (1.7313) loss_oracle 0.3433 (0.3326) acc 59.3750 (70.4688) lr 2.7103e-04 eta 0:06:13
epoch [40/50] batch [120/445] time 0.067 (0.077) data 0.000 (0.004) loss 1.6431 (1.4930) teacher_loss 1.0317 (0.8739) loss_zs_kd 1.7529 (1.7191) loss_oracle 0.3066 (0.3323) acc 62.5000 (70.2865) lr 2.7103e-04 eta 0:06:05
epoch [40/50] batch [140/445] time 0.073 (0.076) data 0.000 (0.004) loss 1.5130 (1.4857) teacher_loss 0.8250 (0.8671) loss_zs_kd 1.9335 (1.7104) loss_oracle 0.3281 (0.3327) acc 65.6250 (70.2009) lr 2.7103e-04 eta 0:06:01
epoch [40/50] batch [160/445] time 0.075 (0.076) data 0.000 (0.003) loss 1.5370 (1.4815) teacher_loss 0.9878 (0.8644) loss_zs_kd 1.4523 (1.7032) loss_oracle 0.3142 (0.3330) acc 62.5000 (70.2930) lr 2.7103e-04 eta 0:05:59
epoch [40/50] batch [180/445] time 0.071 (0.075) data 0.000 (0.003) loss 1.7626 (1.4826) teacher_loss 1.2355 (0.8687) loss_zs_kd 1.4800 (1.6984) loss_oracle 0.3143 (0.3316) acc 65.6250 (69.9132) lr 2.7103e-04 eta 0:05:54
epoch [40/50] batch [200/445] time 0.077 (0.075) data 0.001 (0.003) loss 1.6296 (1.4890) teacher_loss 0.8596 (0.8716) loss_zs_kd 2.1175 (1.7054) loss_oracle 0.3925 (0.3325) acc 71.8750 (69.7344) lr 2.7103e-04 eta 0:05:52
epoch [40/50] batch [220/445] time 0.071 (0.075) data 0.000 (0.003) loss 1.3501 (1.4860) teacher_loss 0.7816 (0.8712) loss_zs_kd 1.4837 (1.7019) loss_oracle 0.3380 (0.3325) acc 65.6250 (69.6591) lr 2.7103e-04 eta 0:05:50
epoch [40/50] batch [240/445] time 0.072 (0.075) data 0.000 (0.002) loss 1.4740 (1.4862) teacher_loss 0.8216 (0.8724) loss_zs_kd 1.9302 (1.7133) loss_oracle 0.3143 (0.3326) acc 65.6250 (69.6224) lr 2.7103e-04 eta 0:05:47
epoch [40/50] batch [260/445] time 0.069 (0.074) data 0.000 (0.002) loss 1.0779 (1.4844) teacher_loss 0.4867 (0.8689) loss_zs_kd 1.5598 (1.7048) loss_oracle 0.3142 (0.3335) acc 84.3750 (69.7236) lr 2.7103e-04 eta 0:05:44
epoch [40/50] batch [280/445] time 0.078 (0.074) data 0.000 (0.002) loss 1.5490 (1.4854) teacher_loss 0.8274 (0.8714) loss_zs_kd 1.7853 (1.7117) loss_oracle 0.3763 (0.3329) acc 75.0000 (69.6094) lr 2.7103e-04 eta 0:05:42
epoch [40/50] batch [300/445] time 0.076 (0.074) data 0.000 (0.002) loss 1.8301 (1.4852) teacher_loss 1.1940 (0.8709) loss_zs_kd 1.7593 (1.7190) loss_oracle 0.3447 (0.3338) acc 65.6250 (69.6250) lr 2.7103e-04 eta 0:05:41
epoch [40/50] batch [320/445] time 0.075 (0.074) data 0.000 (0.002) loss 1.3374 (1.4857) teacher_loss 0.7557 (0.8704) loss_zs_kd 2.0010 (1.7260) loss_oracle 0.3143 (0.3338) acc 68.7500 (69.6875) lr 2.7103e-04 eta 0:05:39
epoch [40/50] batch [340/445] time 0.075 (0.074) data 0.000 (0.002) loss 1.2495 (1.4864) teacher_loss 0.5543 (0.8709) loss_zs_kd 1.5884 (1.7267) loss_oracle 0.4194 (0.3345) acc 84.3750 (69.5956) lr 2.7103e-04 eta 0:05:37
epoch [40/50] batch [360/445] time 0.069 (0.074) data 0.000 (0.002) loss 1.2955 (1.4844) teacher_loss 0.7050 (0.8693) loss_zs_kd 2.2445 (1.7314) loss_oracle 0.3370 (0.3343) acc 75.0000 (69.6007) lr 2.7103e-04 eta 0:05:35
epoch [40/50] batch [380/445] time 0.072 (0.074) data 0.000 (0.002) loss 1.4757 (1.4836) teacher_loss 0.9005 (0.8693) loss_zs_kd 1.8814 (1.7311) loss_oracle 0.3464 (0.3337) acc 59.3750 (69.5970) lr 2.7103e-04 eta 0:05:33
epoch [40/50] batch [400/445] time 0.074 (0.074) data 0.000 (0.002) loss 1.6784 (1.4856) teacher_loss 1.1136 (0.8706) loss_zs_kd 1.8109 (1.7336) loss_oracle 0.3387 (0.3337) acc 71.8750 (69.5781) lr 2.7103e-04 eta 0:05:30
epoch [40/50] batch [420/445] time 0.065 (0.074) data 0.000 (0.002) loss 1.5222 (1.4831) teacher_loss 0.9288 (0.8685) loss_zs_kd 1.9639 (1.7357) loss_oracle 0.3143 (0.3334) acc 71.8750 (69.6949) lr 2.7103e-04 eta 0:05:32
epoch [40/50] batch [440/445] time 0.063 (0.074) data 0.000 (0.001) loss 1.0807 (1.4828) teacher_loss 0.5290 (0.8686) loss_zs_kd 1.4582 (1.7330) loss_oracle 0.3133 (0.3332) acc 81.2500 (69.6378) lr 2.7103e-04 eta 0:05:29
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,365
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 57.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,017
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 31.3%
******* Domain 3 best val acc:      71.5%, epoch: 40 *******
******* Domain 3 best val test acc: 50.8%, epoch: 40 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [41/50] batch [20/445] time 0.065 (0.089) data 0.000 (0.030) loss 1.5782 (1.5192) teacher_loss 0.9722 (0.9016) loss_zs_kd 1.6439 (1.6748) loss_oracle 0.3142 (0.3341) acc 68.7500 (67.9688) lr 2.2949e-04 eta 0:06:34
epoch [41/50] batch [40/445] time 0.054 (0.078) data 0.000 (0.015) loss 1.1837 (1.5058) teacher_loss 0.6975 (0.9002) loss_zs_kd 1.4803 (1.7299) loss_oracle 0.3143 (0.3289) acc 68.7500 (67.7344) lr 2.2949e-04 eta 0:05:45
epoch [41/50] batch [60/445] time 0.075 (0.075) data 0.000 (0.010) loss 1.1447 (1.4688) teacher_loss 0.5940 (0.8641) loss_zs_kd 1.5087 (1.7525) loss_oracle 0.3303 (0.3337) acc 81.2500 (69.2708) lr 2.2949e-04 eta 0:05:28
epoch [41/50] batch [80/445] time 0.069 (0.073) data 0.000 (0.008) loss 1.8802 (1.4913) teacher_loss 1.1741 (0.8803) loss_zs_kd 1.8247 (1.7640) loss_oracle 0.3737 (0.3334) acc 65.6250 (69.4922) lr 2.2949e-04 eta 0:05:21
epoch [41/50] batch [100/445] time 0.073 (0.073) data 0.000 (0.006) loss 1.3911 (1.4861) teacher_loss 0.8411 (0.8752) loss_zs_kd 1.6500 (1.7675) loss_oracle 0.3143 (0.3332) acc 71.8750 (69.8125) lr 2.2949e-04 eta 0:05:17
epoch [41/50] batch [120/445] time 0.082 (0.073) data 0.000 (0.005) loss 1.5395 (1.4918) teacher_loss 0.8785 (0.8781) loss_zs_kd 2.0207 (1.7614) loss_oracle 0.3344 (0.3344) acc 62.5000 (69.4271) lr 2.2949e-04 eta 0:05:14
epoch [41/50] batch [140/445] time 0.069 (0.073) data 0.000 (0.005) loss 1.9580 (1.4957) teacher_loss 1.3483 (0.8785) loss_zs_kd 1.5923 (1.7621) loss_oracle 0.4013 (0.3343) acc 53.1250 (69.4420) lr 2.2949e-04 eta 0:05:13
epoch [41/50] batch [160/445] time 0.073 (0.073) data 0.000 (0.004) loss 1.3701 (1.4977) teacher_loss 0.6849 (0.8808) loss_zs_kd 1.7528 (1.7557) loss_oracle 0.3371 (0.3334) acc 78.1250 (69.1992) lr 2.2949e-04 eta 0:05:11
epoch [41/50] batch [180/445] time 0.071 (0.073) data 0.000 (0.004) loss 1.4976 (1.4979) teacher_loss 0.8945 (0.8814) loss_zs_kd 1.6970 (1.7503) loss_oracle 0.3143 (0.3326) acc 65.6250 (69.1146) lr 2.2949e-04 eta 0:05:10
epoch [41/50] batch [200/445] time 0.075 (0.075) data 0.000 (0.003) loss 1.4946 (1.4943) teacher_loss 0.8612 (0.8784) loss_zs_kd 2.1501 (1.7489) loss_oracle 0.3047 (0.3327) acc 75.0000 (69.0469) lr 2.2949e-04 eta 0:05:16
epoch [41/50] batch [220/445] time 0.073 (0.074) data 0.000 (0.003) loss 1.3910 (1.4970) teacher_loss 0.7531 (0.8785) loss_zs_kd 1.8881 (1.7397) loss_oracle 0.3143 (0.3332) acc 78.1250 (69.1619) lr 2.2949e-04 eta 0:05:14
epoch [41/50] batch [240/445] time 0.073 (0.074) data 0.000 (0.003) loss 1.5187 (1.4936) teacher_loss 0.9338 (0.8764) loss_zs_kd 1.7287 (1.7397) loss_oracle 0.3752 (0.3333) acc 65.6250 (69.2318) lr 2.2949e-04 eta 0:05:12
epoch [41/50] batch [260/445] time 0.056 (0.073) data 0.000 (0.003) loss 1.7792 (1.4882) teacher_loss 1.0518 (0.8706) loss_zs_kd 2.3979 (1.7443) loss_oracle 0.3354 (0.3336) acc 56.2500 (69.1827) lr 2.2949e-04 eta 0:05:05
epoch [41/50] batch [280/445] time 0.066 (0.073) data 0.000 (0.002) loss 1.3819 (1.4882) teacher_loss 0.8647 (0.8695) loss_zs_kd 1.8389 (1.7440) loss_oracle 0.3088 (0.3339) acc 65.6250 (69.2411) lr 2.2949e-04 eta 0:05:02
epoch [41/50] batch [300/445] time 0.072 (0.073) data 0.000 (0.002) loss 1.4185 (1.4906) teacher_loss 0.8261 (0.8725) loss_zs_kd 1.6973 (1.7398) loss_oracle 0.3143 (0.3340) acc 68.7500 (69.2917) lr 2.2949e-04 eta 0:05:01
epoch [41/50] batch [320/445] time 0.064 (0.073) data 0.000 (0.002) loss 1.3673 (1.4880) teacher_loss 0.7920 (0.8704) loss_zs_kd 1.7044 (1.7407) loss_oracle 0.3764 (0.3335) acc 71.8750 (69.3652) lr 2.2949e-04 eta 0:04:59
epoch [41/50] batch [340/445] time 0.077 (0.072) data 0.000 (0.002) loss 1.6040 (1.4914) teacher_loss 1.0198 (0.8742) loss_zs_kd 1.7122 (1.7341) loss_oracle 0.3050 (0.3336) acc 75.0000 (69.3658) lr 2.2949e-04 eta 0:04:57
epoch [41/50] batch [360/445] time 0.074 (0.073) data 0.000 (0.002) loss 1.5491 (1.4947) teacher_loss 0.8753 (0.8768) loss_zs_kd 1.6348 (1.7331) loss_oracle 0.3760 (0.3339) acc 65.6250 (69.2361) lr 2.2949e-04 eta 0:04:56
epoch [41/50] batch [380/445] time 0.070 (0.073) data 0.000 (0.002) loss 1.6403 (1.4962) teacher_loss 0.9241 (0.8770) loss_zs_kd 1.8566 (1.7365) loss_oracle 0.3454 (0.3341) acc 68.7500 (69.1859) lr 2.2949e-04 eta 0:04:55
epoch [41/50] batch [400/445] time 0.082 (0.073) data 0.001 (0.002) loss 1.4190 (1.4955) teacher_loss 0.7884 (0.8768) loss_zs_kd 1.8859 (1.7382) loss_oracle 0.3134 (0.3343) acc 75.0000 (69.1328) lr 2.2949e-04 eta 0:04:54
epoch [41/50] batch [420/445] time 0.065 (0.073) data 0.000 (0.002) loss 1.7392 (1.4951) teacher_loss 1.1418 (0.8772) loss_zs_kd 1.6760 (1.7384) loss_oracle 0.3051 (0.3341) acc 62.5000 (69.0625) lr 2.2949e-04 eta 0:04:53
epoch [41/50] batch [440/445] time 0.067 (0.073) data 0.000 (0.002) loss 1.3108 (1.4951) teacher_loss 0.6365 (0.8768) loss_zs_kd 1.8652 (1.7355) loss_oracle 0.3143 (0.3344) acc 84.3750 (69.0838) lr 2.2949e-04 eta 0:04:51
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,357
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 57.3%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,019
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 31.7%
******* Domain 3 best val acc:      71.5%, epoch: 40 *******
******* Domain 3 best val test acc: 50.8%, epoch: 40 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [42/50] batch [20/445] time 0.069 (0.101) data 0.000 (0.025) loss 1.3834 (1.5130) teacher_loss 0.8319 (0.9037) loss_zs_kd 1.6015 (1.7903) loss_oracle 0.3143 (0.3360) acc 71.8750 (68.5938) lr 1.9098e-04 eta 0:06:41
epoch [42/50] batch [40/445] time 0.076 (0.086) data 0.000 (0.013) loss 1.4364 (1.5322) teacher_loss 0.8192 (0.9305) loss_zs_kd 1.7999 (1.7435) loss_oracle 0.3747 (0.3362) acc 71.8750 (66.7969) lr 1.9098e-04 eta 0:05:41
epoch [42/50] batch [60/445] time 0.080 (0.081) data 0.001 (0.009) loss 1.4517 (1.5029) teacher_loss 0.8545 (0.9069) loss_zs_kd 1.9770 (1.7642) loss_oracle 0.3099 (0.3323) acc 71.8750 (67.4479) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [80/445] time 0.076 (0.080) data 0.001 (0.007) loss 1.1097 (1.4718) teacher_loss 0.5279 (0.8729) loss_zs_kd 1.2827 (1.7211) loss_oracle 0.3073 (0.3336) acc 81.2500 (68.6719) lr 1.9098e-04 eta 0:05:13
epoch [42/50] batch [100/445] time 0.074 (0.078) data 0.000 (0.005) loss 0.9937 (1.4680) teacher_loss 0.4953 (0.8717) loss_zs_kd 1.4644 (1.7212) loss_oracle 0.3136 (0.3334) acc 81.2500 (68.9062) lr 1.9098e-04 eta 0:05:05
epoch [42/50] batch [120/445] time 0.069 (0.077) data 0.000 (0.004) loss 1.5335 (1.4746) teacher_loss 0.9548 (0.8752) loss_zs_kd 1.5496 (1.7208) loss_oracle 0.3187 (0.3336) acc 68.7500 (69.1406) lr 1.9098e-04 eta 0:04:58
epoch [42/50] batch [140/445] time 0.078 (0.076) data 0.000 (0.004) loss 1.6357 (1.4679) teacher_loss 1.0026 (0.8686) loss_zs_kd 1.7823 (1.7327) loss_oracle 0.3960 (0.3338) acc 62.5000 (69.3973) lr 1.9098e-04 eta 0:04:52
epoch [42/50] batch [160/445] time 0.065 (0.075) data 0.000 (0.003) loss 1.3905 (1.4743) teacher_loss 0.7376 (0.8693) loss_zs_kd 1.8961 (1.7455) loss_oracle 0.3221 (0.3335) acc 75.0000 (69.7070) lr 1.9098e-04 eta 0:04:49
epoch [42/50] batch [180/445] time 0.072 (0.075) data 0.000 (0.003) loss 1.4991 (1.4793) teacher_loss 0.8547 (0.8713) loss_zs_kd 1.8862 (1.7506) loss_oracle 0.3134 (0.3343) acc 75.0000 (69.4965) lr 1.9098e-04 eta 0:04:47
epoch [42/50] batch [200/445] time 0.076 (0.075) data 0.000 (0.003) loss 1.3562 (1.4914) teacher_loss 0.8282 (0.8815) loss_zs_kd 1.3841 (1.7467) loss_oracle 0.3140 (0.3352) acc 75.0000 (69.3281) lr 1.9098e-04 eta 0:04:44
epoch [42/50] batch [220/445] time 0.077 (0.075) data 0.000 (0.003) loss 1.4543 (1.4893) teacher_loss 0.7581 (0.8795) loss_zs_kd 1.4919 (1.7470) loss_oracle 0.3453 (0.3350) acc 75.0000 (69.4460) lr 1.9098e-04 eta 0:04:42
epoch [42/50] batch [240/445] time 0.068 (0.074) data 0.000 (0.002) loss 1.2904 (1.4903) teacher_loss 0.7192 (0.8798) loss_zs_kd 1.7757 (1.7494) loss_oracle 0.3105 (0.3348) acc 71.8750 (69.3229) lr 1.9098e-04 eta 0:04:40
epoch [42/50] batch [260/445] time 0.073 (0.074) data 0.000 (0.002) loss 1.4062 (1.4934) teacher_loss 0.9152 (0.8828) loss_zs_kd 1.7603 (1.7433) loss_oracle 0.3143 (0.3341) acc 65.6250 (69.2428) lr 1.9098e-04 eta 0:04:37
epoch [42/50] batch [280/445] time 0.071 (0.074) data 0.000 (0.002) loss 1.1114 (1.4906) teacher_loss 0.6030 (0.8810) loss_zs_kd 1.2583 (1.7370) loss_oracle 0.3363 (0.3337) acc 78.1250 (69.1964) lr 1.9098e-04 eta 0:04:35
epoch [42/50] batch [300/445] time 0.063 (0.074) data 0.000 (0.002) loss 1.2980 (1.4909) teacher_loss 0.7136 (0.8812) loss_zs_kd 1.5441 (1.7287) loss_oracle 0.3398 (0.3335) acc 75.0000 (69.1875) lr 1.9098e-04 eta 0:04:32
epoch [42/50] batch [320/445] time 0.074 (0.073) data 0.000 (0.002) loss 1.4311 (1.4861) teacher_loss 0.7245 (0.8771) loss_zs_kd 1.4327 (1.7246) loss_oracle 0.3453 (0.3336) acc 81.2500 (69.3164) lr 1.9098e-04 eta 0:04:30
epoch [42/50] batch [340/445] time 0.077 (0.073) data 0.000 (0.002) loss 1.3934 (1.4874) teacher_loss 0.7796 (0.8789) loss_zs_kd 2.1107 (1.7279) loss_oracle 0.3143 (0.3334) acc 71.8750 (69.2647) lr 1.9098e-04 eta 0:04:28
epoch [42/50] batch [360/445] time 0.080 (0.073) data 0.001 (0.002) loss 1.3728 (1.4840) teacher_loss 0.7759 (0.8753) loss_zs_kd 1.6461 (1.7244) loss_oracle 0.3697 (0.3332) acc 68.7500 (69.3924) lr 1.9098e-04 eta 0:04:27
epoch [42/50] batch [380/445] time 0.070 (0.073) data 0.000 (0.002) loss 1.6259 (1.4823) teacher_loss 0.9183 (0.8734) loss_zs_kd 1.9618 (1.7258) loss_oracle 0.3741 (0.3336) acc 65.6250 (69.4490) lr 1.9098e-04 eta 0:04:26
epoch [42/50] batch [400/445] time 0.073 (0.073) data 0.000 (0.002) loss 1.4301 (1.4852) teacher_loss 0.8036 (0.8763) loss_zs_kd 2.0705 (1.7306) loss_oracle 0.3530 (0.3335) acc 68.7500 (69.3125) lr 1.9098e-04 eta 0:04:24
epoch [42/50] batch [420/445] time 0.071 (0.074) data 0.000 (0.002) loss 1.5384 (1.4835) teacher_loss 0.9987 (0.8745) loss_zs_kd 1.5875 (1.7324) loss_oracle 0.3362 (0.3339) acc 62.5000 (69.4420) lr 1.9098e-04 eta 0:04:25
epoch [42/50] batch [440/445] time 0.065 (0.074) data 0.000 (0.001) loss 1.8042 (1.4834) teacher_loss 1.1488 (0.8736) loss_zs_kd 1.8343 (1.7306) loss_oracle 0.3142 (0.3336) acc 71.8750 (69.5099) lr 1.9098e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,363
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 58.1%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,986
* accuracy: 50.0%
* error: 50.0%
* macro_f1: 30.9%
******* Domain 3 best val acc:      71.5%, epoch: 40 *******
******* Domain 3 best val test acc: 50.8%, epoch: 40 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [43/50] batch [20/445] time 0.075 (0.103) data 0.000 (0.027) loss 1.4920 (1.4447) teacher_loss 0.8953 (0.8346) loss_zs_kd 1.7100 (1.8040) loss_oracle 0.3513 (0.3307) acc 71.8750 (71.0938) lr 1.5567e-04 eta 0:06:04
epoch [43/50] batch [40/445] time 0.075 (0.088) data 0.000 (0.013) loss 1.3793 (1.4516) teacher_loss 0.7939 (0.8340) loss_zs_kd 1.8798 (1.7839) loss_oracle 0.3435 (0.3333) acc 65.6250 (71.2500) lr 1.5567e-04 eta 0:05:09
epoch [43/50] batch [60/445] time 0.074 (0.083) data 0.000 (0.009) loss 1.8622 (1.4495) teacher_loss 1.2940 (0.8359) loss_zs_kd 1.8425 (1.7716) loss_oracle 0.2997 (0.3329) acc 56.2500 (71.0938) lr 1.5567e-04 eta 0:04:49
epoch [43/50] batch [80/445] time 0.078 (0.081) data 0.000 (0.007) loss 1.2035 (1.4329) teacher_loss 0.7063 (0.8177) loss_zs_kd 1.5614 (1.7522) loss_oracle 0.3408 (0.3317) acc 71.8750 (71.3281) lr 1.5567e-04 eta 0:04:41
epoch [43/50] batch [100/445] time 0.072 (0.080) data 0.000 (0.006) loss 1.5358 (1.4627) teacher_loss 0.9270 (0.8414) loss_zs_kd 1.7290 (1.7442) loss_oracle 0.3143 (0.3336) acc 68.7500 (70.7188) lr 1.5567e-04 eta 0:04:36
epoch [43/50] batch [120/445] time 0.081 (0.079) data 0.000 (0.005) loss 1.2614 (1.4628) teacher_loss 0.7305 (0.8440) loss_zs_kd 1.8175 (1.7526) loss_oracle 0.3484 (0.3332) acc 65.6250 (70.5990) lr 1.5567e-04 eta 0:04:31
epoch [43/50] batch [140/445] time 0.072 (0.078) data 0.000 (0.004) loss 1.6582 (1.4677) teacher_loss 1.0237 (0.8513) loss_zs_kd 1.8957 (1.7514) loss_oracle 0.3667 (0.3339) acc 59.3750 (70.2455) lr 1.5567e-04 eta 0:04:27
epoch [43/50] batch [160/445] time 0.107 (0.078) data 0.000 (0.004) loss 1.8000 (1.4760) teacher_loss 1.2054 (0.8577) loss_zs_kd 1.4715 (1.7441) loss_oracle 0.3137 (0.3332) acc 53.1250 (69.8438) lr 1.5567e-04 eta 0:04:26
epoch [43/50] batch [180/445] time 0.078 (0.078) data 0.000 (0.003) loss 1.2562 (1.4735) teacher_loss 0.7116 (0.8574) loss_zs_kd 1.4126 (1.7356) loss_oracle 0.3142 (0.3327) acc 81.2500 (70.0174) lr 1.5567e-04 eta 0:04:25
epoch [43/50] batch [200/445] time 0.070 (0.078) data 0.000 (0.003) loss 1.2092 (1.4675) teacher_loss 0.5549 (0.8537) loss_zs_kd 1.2308 (1.7374) loss_oracle 0.3448 (0.3324) acc 81.2500 (70.1250) lr 1.5567e-04 eta 0:04:20
epoch [43/50] batch [220/445] time 0.071 (0.078) data 0.000 (0.003) loss 1.6655 (1.4707) teacher_loss 1.0029 (0.8558) loss_zs_kd 1.7260 (1.7340) loss_oracle 0.3763 (0.3327) acc 53.1250 (69.8722) lr 1.5567e-04 eta 0:04:19
epoch [43/50] batch [240/445] time 0.074 (0.077) data 0.000 (0.003) loss 1.5552 (1.4807) teacher_loss 0.8838 (0.8655) loss_zs_kd 1.9993 (1.7297) loss_oracle 0.3047 (0.3329) acc 71.8750 (69.6224) lr 1.5567e-04 eta 0:04:16
epoch [43/50] batch [260/445] time 0.079 (0.077) data 0.000 (0.002) loss 1.3257 (1.4808) teacher_loss 0.6750 (0.8658) loss_zs_kd 1.4314 (1.7286) loss_oracle 0.3049 (0.3324) acc 75.0000 (69.4351) lr 1.5567e-04 eta 0:04:13
epoch [43/50] batch [280/445] time 0.070 (0.076) data 0.000 (0.002) loss 1.2030 (1.4844) teacher_loss 0.6185 (0.8686) loss_zs_kd 2.0428 (1.7197) loss_oracle 0.3454 (0.3325) acc 84.3750 (69.3638) lr 1.5567e-04 eta 0:04:10
epoch [43/50] batch [300/445] time 0.069 (0.076) data 0.000 (0.002) loss 1.3483 (1.4786) teacher_loss 0.7354 (0.8639) loss_zs_kd 2.3678 (1.7174) loss_oracle 0.4025 (0.3321) acc 68.7500 (69.5104) lr 1.5567e-04 eta 0:04:08
epoch [43/50] batch [320/445] time 0.076 (0.076) data 0.000 (0.002) loss 1.4548 (1.4806) teacher_loss 0.7937 (0.8675) loss_zs_kd 1.5434 (1.7149) loss_oracle 0.3453 (0.3324) acc 62.5000 (69.3750) lr 1.5567e-04 eta 0:04:06
epoch [43/50] batch [340/445] time 0.071 (0.076) data 0.000 (0.002) loss 1.4929 (1.4813) teacher_loss 0.7917 (0.8676) loss_zs_kd 1.9571 (1.7115) loss_oracle 0.3765 (0.3325) acc 68.7500 (69.3107) lr 1.5567e-04 eta 0:04:03
epoch [43/50] batch [360/445] time 0.073 (0.076) data 0.000 (0.002) loss 1.5492 (1.4774) teacher_loss 0.8921 (0.8652) loss_zs_kd 1.8841 (1.7119) loss_oracle 0.3143 (0.3321) acc 62.5000 (69.3924) lr 1.5567e-04 eta 0:04:01
epoch [43/50] batch [380/445] time 0.074 (0.075) data 0.000 (0.002) loss 1.1486 (1.4754) teacher_loss 0.5913 (0.8638) loss_zs_kd 1.4714 (1.7038) loss_oracle 0.3067 (0.3320) acc 78.1250 (69.5477) lr 1.5567e-04 eta 0:03:59
epoch [43/50] batch [400/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.4544 (1.4764) teacher_loss 0.8253 (0.8653) loss_zs_kd 1.3066 (1.7011) loss_oracle 0.3400 (0.3319) acc 68.7500 (69.4375) lr 1.5567e-04 eta 0:03:57
epoch [43/50] batch [420/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.2796 (1.4780) teacher_loss 0.6747 (0.8666) loss_zs_kd 1.8277 (1.7067) loss_oracle 0.3436 (0.3322) acc 71.8750 (69.3452) lr 1.5567e-04 eta 0:03:55
epoch [43/50] batch [440/445] time 0.064 (0.075) data 0.000 (0.002) loss 1.6067 (1.4802) teacher_loss 1.0270 (0.8690) loss_zs_kd 1.5201 (1.7039) loss_oracle 0.3110 (0.3323) acc 59.3750 (69.2543) lr 1.5567e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,359
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 57.7%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,016
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 31.5%
******* Domain 3 best val acc:      71.5%, epoch: 40 *******
******* Domain 3 best val test acc: 50.8%, epoch: 40 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [44/50] batch [20/445] time 0.071 (0.094) data 0.000 (0.034) loss 1.1487 (1.4699) teacher_loss 0.5888 (0.8471) loss_zs_kd 1.8314 (1.6375) loss_oracle 0.3453 (0.3298) acc 81.2500 (68.9062) lr 1.2369e-04 eta 0:04:51
epoch [44/50] batch [40/445] time 0.072 (0.082) data 0.000 (0.017) loss 1.2306 (1.5088) teacher_loss 0.6085 (0.8931) loss_zs_kd 1.4526 (1.6440) loss_oracle 0.3142 (0.3284) acc 75.0000 (67.5781) lr 1.2369e-04 eta 0:04:13
epoch [44/50] batch [60/445] time 0.065 (0.079) data 0.000 (0.012) loss 1.2483 (1.5013) teacher_loss 0.7140 (0.8899) loss_zs_kd 1.6750 (1.6535) loss_oracle 0.3142 (0.3283) acc 75.0000 (68.8542) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [80/445] time 0.073 (0.077) data 0.000 (0.009) loss 1.3735 (1.5139) teacher_loss 0.7951 (0.9002) loss_zs_kd 1.4344 (1.6549) loss_oracle 0.3050 (0.3293) acc 71.8750 (68.5547) lr 1.2369e-04 eta 0:03:53
epoch [44/50] batch [100/445] time 0.076 (0.076) data 0.000 (0.007) loss 1.3513 (1.5002) teacher_loss 0.8279 (0.8891) loss_zs_kd 1.3496 (1.6820) loss_oracle 0.3072 (0.3286) acc 71.8750 (69.0625) lr 1.2369e-04 eta 0:03:48
epoch [44/50] batch [120/445] time 0.072 (0.076) data 0.000 (0.006) loss 1.5438 (1.4959) teacher_loss 0.9127 (0.8881) loss_zs_kd 1.2279 (1.6779) loss_oracle 0.3120 (0.3281) acc 68.7500 (69.1146) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [140/445] time 0.085 (0.076) data 0.001 (0.005) loss 1.5916 (1.4956) teacher_loss 0.9204 (0.8842) loss_zs_kd 1.4672 (1.6799) loss_oracle 0.3501 (0.3284) acc 59.3750 (69.0625) lr 1.2369e-04 eta 0:03:44
epoch [44/50] batch [160/445] time 0.081 (0.075) data 0.000 (0.005) loss 1.1425 (1.4905) teacher_loss 0.5162 (0.8788) loss_zs_kd 1.7924 (1.6848) loss_oracle 0.3444 (0.3294) acc 84.3750 (69.1211) lr 1.2369e-04 eta 0:03:42
epoch [44/50] batch [180/445] time 0.073 (0.075) data 0.000 (0.004) loss 1.3962 (1.4893) teacher_loss 0.8723 (0.8804) loss_zs_kd 1.7230 (1.6875) loss_oracle 0.3143 (0.3280) acc 71.8750 (69.2535) lr 1.2369e-04 eta 0:03:40
epoch [44/50] batch [200/445] time 0.072 (0.075) data 0.000 (0.004) loss 1.5713 (1.4955) teacher_loss 0.9726 (0.8844) loss_zs_kd 1.9389 (1.6925) loss_oracle 0.3047 (0.3284) acc 65.6250 (69.0000) lr 1.2369e-04 eta 0:03:39
epoch [44/50] batch [220/445] time 0.067 (0.075) data 0.000 (0.003) loss 1.3761 (1.4916) teacher_loss 0.7875 (0.8784) loss_zs_kd 2.0421 (1.6921) loss_oracle 0.3140 (0.3289) acc 71.8750 (69.2045) lr 1.2369e-04 eta 0:03:37
epoch [44/50] batch [240/445] time 0.072 (0.075) data 0.000 (0.003) loss 1.7166 (1.4925) teacher_loss 1.1249 (0.8797) loss_zs_kd 1.2549 (1.6912) loss_oracle 0.3090 (0.3289) acc 53.1250 (69.1927) lr 1.2369e-04 eta 0:03:35
epoch [44/50] batch [260/445] time 0.076 (0.075) data 0.000 (0.003) loss 1.2310 (1.4909) teacher_loss 0.6942 (0.8790) loss_zs_kd 1.3170 (1.6941) loss_oracle 0.3142 (0.3287) acc 78.1250 (69.3149) lr 1.2369e-04 eta 0:03:34
epoch [44/50] batch [280/445] time 0.079 (0.075) data 0.001 (0.003) loss 1.4318 (1.4917) teacher_loss 0.7880 (0.8795) loss_zs_kd 1.9855 (1.6969) loss_oracle 0.3130 (0.3287) acc 65.6250 (69.2634) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [300/445] time 0.076 (0.075) data 0.000 (0.003) loss 1.2531 (1.4926) teacher_loss 0.6313 (0.8801) loss_zs_kd 2.1093 (1.7008) loss_oracle 0.3454 (0.3281) acc 78.1250 (69.2083) lr 1.2369e-04 eta 0:03:31
epoch [44/50] batch [320/445] time 0.078 (0.075) data 0.000 (0.002) loss 1.5676 (1.4950) teacher_loss 0.9586 (0.8822) loss_zs_kd 2.1760 (1.7033) loss_oracle 0.3248 (0.3281) acc 59.3750 (69.1504) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [340/445] time 0.068 (0.075) data 0.000 (0.002) loss 1.2812 (1.4930) teacher_loss 0.6566 (0.8794) loss_zs_kd 1.6111 (1.7073) loss_oracle 0.3453 (0.3285) acc 78.1250 (69.4118) lr 1.2369e-04 eta 0:03:28
epoch [44/50] batch [360/445] time 0.074 (0.075) data 0.000 (0.002) loss 1.6125 (1.4941) teacher_loss 1.0656 (0.8804) loss_zs_kd 1.5528 (1.7084) loss_oracle 0.3137 (0.3289) acc 62.5000 (69.3750) lr 1.2369e-04 eta 0:03:26
epoch [44/50] batch [380/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.5884 (1.4934) teacher_loss 0.8771 (0.8790) loss_zs_kd 1.8556 (1.7085) loss_oracle 0.3440 (0.3296) acc 62.5000 (69.4408) lr 1.2369e-04 eta 0:03:26
epoch [44/50] batch [400/445] time 0.066 (0.075) data 0.000 (0.002) loss 1.8300 (1.4902) teacher_loss 1.1286 (0.8765) loss_zs_kd 1.4545 (1.7017) loss_oracle 0.3737 (0.3293) acc 62.5000 (69.5234) lr 1.2369e-04 eta 0:03:23
epoch [44/50] batch [420/445] time 0.077 (0.075) data 0.001 (0.002) loss 1.6181 (1.4876) teacher_loss 0.9466 (0.8739) loss_zs_kd 1.8851 (1.7014) loss_oracle 0.3141 (0.3296) acc 59.3750 (69.6801) lr 1.2369e-04 eta 0:03:21
epoch [44/50] batch [440/445] time 0.064 (0.075) data 0.000 (0.002) loss 1.6008 (1.4880) teacher_loss 0.9949 (0.8734) loss_zs_kd 1.9330 (1.7039) loss_oracle 0.3138 (0.3298) acc 65.6250 (69.6662) lr 1.2369e-04 eta 0:03:19
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,351
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 57.4%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,025
* accuracy: 51.0%
* error: 49.0%
* macro_f1: 31.9%
******* Domain 3 best val acc:      71.5%, epoch: 40 *******
******* Domain 3 best val test acc: 50.8%, epoch: 40 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [45/50] batch [20/445] time 0.081 (0.098) data 0.000 (0.023) loss 1.3551 (1.4954) teacher_loss 0.7063 (0.8716) loss_zs_kd 1.4905 (1.7544) loss_oracle 0.3453 (0.3256) acc 75.0000 (68.2812) lr 9.5173e-05 eta 0:04:20
epoch [45/50] batch [40/445] time 0.064 (0.085) data 0.000 (0.012) loss 1.4762 (1.5164) teacher_loss 0.8711 (0.8884) loss_zs_kd 1.8409 (1.7320) loss_oracle 0.3142 (0.3305) acc 71.8750 (69.4531) lr 9.5173e-05 eta 0:03:43
epoch [45/50] batch [60/445] time 0.076 (0.081) data 0.000 (0.008) loss 1.4711 (1.4910) teacher_loss 0.8538 (0.8744) loss_zs_kd 1.5676 (1.6875) loss_oracle 0.3452 (0.3310) acc 71.8750 (69.5312) lr 9.5173e-05 eta 0:03:31
epoch [45/50] batch [80/445] time 0.072 (0.078) data 0.000 (0.006) loss 1.6588 (1.5074) teacher_loss 1.0710 (0.8923) loss_zs_kd 0.8909 (1.6655) loss_oracle 0.3142 (0.3297) acc 59.3750 (68.5156) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [100/445] time 0.064 (0.077) data 0.000 (0.005) loss 1.5075 (1.4970) teacher_loss 0.9051 (0.8859) loss_zs_kd 1.5023 (1.6551) loss_oracle 0.3143 (0.3293) acc 68.7500 (68.7812) lr 9.5173e-05 eta 0:03:18
epoch [45/50] batch [120/445] time 0.063 (0.079) data 0.000 (0.004) loss 1.1816 (1.4925) teacher_loss 0.5928 (0.8809) loss_zs_kd 1.6581 (1.6688) loss_oracle 0.3097 (0.3293) acc 84.3750 (69.2448) lr 9.5173e-05 eta 0:03:21
epoch [45/50] batch [140/445] time 0.073 (0.078) data 0.000 (0.004) loss 1.5037 (1.4847) teacher_loss 0.8581 (0.8712) loss_zs_kd 2.0475 (1.6753) loss_oracle 0.3142 (0.3284) acc 71.8750 (69.3304) lr 9.5173e-05 eta 0:03:16
epoch [45/50] batch [160/445] time 0.069 (0.077) data 0.000 (0.003) loss 1.8047 (1.4900) teacher_loss 1.0618 (0.8743) loss_zs_kd 1.7008 (1.6838) loss_oracle 0.4364 (0.3303) acc 62.5000 (69.1406) lr 9.5173e-05 eta 0:03:14
epoch [45/50] batch [180/445] time 0.071 (0.077) data 0.000 (0.003) loss 1.4288 (1.4827) teacher_loss 0.8700 (0.8667) loss_zs_kd 1.7682 (1.6862) loss_oracle 0.3143 (0.3303) acc 71.8750 (69.4618) lr 9.5173e-05 eta 0:03:11
epoch [45/50] batch [200/445] time 0.076 (0.076) data 0.000 (0.003) loss 1.3147 (1.4859) teacher_loss 0.7587 (0.8699) loss_zs_kd 1.6564 (1.6859) loss_oracle 0.3142 (0.3300) acc 71.8750 (69.3281) lr 9.5173e-05 eta 0:03:08
epoch [45/50] batch [220/445] time 0.067 (0.076) data 0.000 (0.002) loss 1.3027 (1.4870) teacher_loss 0.7280 (0.8716) loss_zs_kd 1.8893 (1.6934) loss_oracle 0.3380 (0.3296) acc 81.2500 (69.2614) lr 9.5173e-05 eta 0:03:06
epoch [45/50] batch [240/445] time 0.076 (0.076) data 0.000 (0.002) loss 1.6950 (1.4889) teacher_loss 1.1352 (0.8732) loss_zs_kd 1.7721 (1.6915) loss_oracle 0.3143 (0.3298) acc 56.2500 (69.1406) lr 9.5173e-05 eta 0:03:04
epoch [45/50] batch [260/445] time 0.067 (0.076) data 0.000 (0.002) loss 1.2630 (1.4832) teacher_loss 0.6320 (0.8673) loss_zs_kd 1.7343 (1.6979) loss_oracle 0.3129 (0.3298) acc 71.8750 (69.3870) lr 9.5173e-05 eta 0:03:02
epoch [45/50] batch [280/445] time 0.084 (0.076) data 0.000 (0.002) loss 1.7147 (1.4860) teacher_loss 1.0548 (0.8688) loss_zs_kd 2.0035 (1.6918) loss_oracle 0.3142 (0.3306) acc 62.5000 (69.2969) lr 9.5173e-05 eta 0:03:00
epoch [45/50] batch [300/445] time 0.067 (0.075) data 0.000 (0.002) loss 1.1292 (1.4836) teacher_loss 0.5819 (0.8682) loss_zs_kd 1.5258 (1.6869) loss_oracle 0.3454 (0.3304) acc 78.1250 (69.4062) lr 9.5173e-05 eta 0:02:57
epoch [45/50] batch [320/445] time 0.080 (0.075) data 0.001 (0.002) loss 1.4396 (1.4845) teacher_loss 0.8591 (0.8696) loss_zs_kd 1.6346 (1.6851) loss_oracle 0.3137 (0.3305) acc 68.7500 (69.3164) lr 9.5173e-05 eta 0:02:55
epoch [45/50] batch [340/445] time 0.072 (0.074) data 0.000 (0.002) loss 1.4299 (1.4819) teacher_loss 0.8890 (0.8670) loss_zs_kd 1.9778 (1.6886) loss_oracle 0.3142 (0.3306) acc 75.0000 (69.3474) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [360/445] time 0.063 (0.074) data 0.000 (0.002) loss 1.4019 (1.4827) teacher_loss 0.7632 (0.8686) loss_zs_kd 1.6242 (1.6848) loss_oracle 0.3657 (0.3310) acc 68.7500 (69.2969) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [380/445] time 0.064 (0.074) data 0.000 (0.001) loss 1.5919 (1.4865) teacher_loss 0.9112 (0.8725) loss_zs_kd 1.7497 (1.6836) loss_oracle 0.3749 (0.3311) acc 75.0000 (69.0707) lr 9.5173e-05 eta 0:02:49
epoch [45/50] batch [400/445] time 0.078 (0.074) data 0.000 (0.001) loss 1.4596 (1.4903) teacher_loss 0.8598 (0.8763) loss_zs_kd 1.7136 (1.6863) loss_oracle 0.3454 (0.3312) acc 75.0000 (68.8906) lr 9.5173e-05 eta 0:02:48
epoch [45/50] batch [420/445] time 0.068 (0.074) data 0.000 (0.001) loss 1.6847 (1.4952) teacher_loss 0.9708 (0.8793) loss_zs_kd 1.8088 (1.6938) loss_oracle 0.3668 (0.3312) acc 59.3750 (68.8021) lr 9.5173e-05 eta 0:02:46
epoch [45/50] batch [440/445] time 0.062 (0.074) data 0.000 (0.001) loss 1.6089 (1.4920) teacher_loss 0.9578 (0.8759) loss_zs_kd 1.7610 (1.6957) loss_oracle 0.3420 (0.3312) acc 62.5000 (68.9205) lr 9.5173e-05 eta 0:02:44
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,370
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 57.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,008
* accuracy: 50.6%
* error: 49.4%
* macro_f1: 31.5%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [46/50] batch [20/445] time 0.072 (0.090) data 0.000 (0.031) loss 1.8359 (1.5390) teacher_loss 1.1598 (0.9111) loss_zs_kd 1.9269 (1.7156) loss_oracle 0.3529 (0.3383) acc 56.2500 (66.4062) lr 7.0224e-05 eta 0:03:18
epoch [46/50] batch [40/445] time 0.075 (0.081) data 0.000 (0.016) loss 1.4968 (1.4937) teacher_loss 0.8776 (0.8680) loss_zs_kd 1.5096 (1.7296) loss_oracle 0.3313 (0.3375) acc 75.0000 (69.2188) lr 7.0224e-05 eta 0:02:56
epoch [46/50] batch [60/445] time 0.070 (0.078) data 0.000 (0.011) loss 1.5983 (1.5068) teacher_loss 0.9510 (0.8865) loss_zs_kd 1.8003 (1.6967) loss_oracle 0.3143 (0.3321) acc 68.7500 (68.9583) lr 7.0224e-05 eta 0:02:49
epoch [46/50] batch [80/445] time 0.068 (0.076) data 0.000 (0.008) loss 1.5733 (1.5079) teacher_loss 1.0333 (0.8933) loss_zs_kd 1.8384 (1.7062) loss_oracle 0.3142 (0.3311) acc 59.3750 (68.7891) lr 7.0224e-05 eta 0:02:42
epoch [46/50] batch [100/445] time 0.070 (0.074) data 0.000 (0.007) loss 1.5593 (1.4961) teacher_loss 0.9113 (0.8841) loss_zs_kd 2.0169 (1.7075) loss_oracle 0.3073 (0.3302) acc 71.8750 (69.3438) lr 7.0224e-05 eta 0:02:37
epoch [46/50] batch [120/445] time 0.080 (0.073) data 0.000 (0.005) loss 1.3588 (1.4944) teacher_loss 0.8446 (0.8832) loss_zs_kd 1.4192 (1.6953) loss_oracle 0.3143 (0.3296) acc 75.0000 (69.4792) lr 7.0224e-05 eta 0:02:34
epoch [46/50] batch [140/445] time 0.073 (0.073) data 0.000 (0.005) loss 1.6346 (1.4873) teacher_loss 0.9330 (0.8757) loss_zs_kd 1.5374 (1.6930) loss_oracle 0.3425 (0.3306) acc 59.3750 (69.5536) lr 7.0224e-05 eta 0:02:31
epoch [46/50] batch [160/445] time 0.070 (0.072) data 0.000 (0.004) loss 1.1546 (1.4850) teacher_loss 0.5642 (0.8740) loss_zs_kd 1.9109 (1.6921) loss_oracle 0.3071 (0.3290) acc 81.2500 (69.5508) lr 7.0224e-05 eta 0:02:29
epoch [46/50] batch [180/445] time 0.073 (0.073) data 0.000 (0.004) loss 1.5286 (1.4901) teacher_loss 0.8648 (0.8762) loss_zs_kd 1.3368 (1.6915) loss_oracle 0.3143 (0.3288) acc 68.7500 (69.7396) lr 7.0224e-05 eta 0:02:28
epoch [46/50] batch [200/445] time 0.085 (0.073) data 0.000 (0.003) loss 1.5266 (1.4898) teacher_loss 0.9998 (0.8774) loss_zs_kd 1.7423 (1.6918) loss_oracle 0.3142 (0.3285) acc 71.8750 (69.7031) lr 7.0224e-05 eta 0:02:27
epoch [46/50] batch [220/445] time 0.068 (0.072) data 0.000 (0.003) loss 1.2144 (1.4859) teacher_loss 0.6232 (0.8722) loss_zs_kd 1.8135 (1.6974) loss_oracle 0.3142 (0.3293) acc 81.2500 (69.9148) lr 7.0224e-05 eta 0:02:25
epoch [46/50] batch [240/445] time 0.071 (0.072) data 0.000 (0.003) loss 1.5815 (1.4842) teacher_loss 1.0355 (0.8716) loss_zs_kd 1.9584 (1.6961) loss_oracle 0.3141 (0.3297) acc 62.5000 (69.8568) lr 7.0224e-05 eta 0:02:23
epoch [46/50] batch [260/445] time 0.068 (0.072) data 0.000 (0.003) loss 1.6320 (1.4838) teacher_loss 0.9588 (0.8714) loss_zs_kd 1.9549 (1.7005) loss_oracle 0.3453 (0.3300) acc 68.7500 (69.8558) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [280/445] time 0.068 (0.072) data 0.000 (0.003) loss 1.7605 (1.4799) teacher_loss 1.1304 (0.8691) loss_zs_kd 2.1739 (1.6914) loss_oracle 0.3044 (0.3300) acc 62.5000 (69.8884) lr 7.0224e-05 eta 0:02:20
epoch [46/50] batch [300/445] time 0.072 (0.072) data 0.000 (0.002) loss 1.8818 (1.4799) teacher_loss 1.2237 (0.8680) loss_zs_kd 1.6073 (1.6937) loss_oracle 0.3453 (0.3307) acc 53.1250 (69.8854) lr 7.0224e-05 eta 0:02:18
epoch [46/50] batch [320/445] time 0.078 (0.072) data 0.000 (0.002) loss 1.5439 (1.4817) teacher_loss 0.8728 (0.8698) loss_zs_kd 1.6399 (1.6937) loss_oracle 0.3143 (0.3309) acc 71.8750 (69.8145) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [340/445] time 0.058 (0.073) data 0.000 (0.002) loss 1.2820 (1.4768) teacher_loss 0.6736 (0.8650) loss_zs_kd 1.9848 (1.6978) loss_oracle 0.3188 (0.3314) acc 81.2500 (69.9449) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [360/445] time 0.076 (0.073) data 0.000 (0.002) loss 1.3923 (1.4788) teacher_loss 0.7829 (0.8669) loss_zs_kd 1.9442 (1.7016) loss_oracle 0.3433 (0.3315) acc 78.1250 (69.9306) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [380/445] time 0.073 (0.073) data 0.000 (0.002) loss 1.6047 (1.4806) teacher_loss 0.9721 (0.8694) loss_zs_kd 1.8138 (1.7044) loss_oracle 0.3452 (0.3312) acc 62.5000 (69.7862) lr 7.0224e-05 eta 0:02:13
epoch [46/50] batch [400/445] time 0.064 (0.073) data 0.000 (0.002) loss 1.8540 (1.4824) teacher_loss 1.1777 (0.8722) loss_zs_kd 1.9609 (1.7026) loss_oracle 0.3454 (0.3310) acc 56.2500 (69.7109) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [420/445] time 0.067 (0.073) data 0.000 (0.002) loss 1.3705 (1.4830) teacher_loss 0.7925 (0.8725) loss_zs_kd 1.6584 (1.7036) loss_oracle 0.3142 (0.3311) acc 71.8750 (69.7619) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [440/445] time 0.067 (0.072) data 0.000 (0.002) loss 1.8295 (1.4830) teacher_loss 1.1911 (0.8731) loss_zs_kd 1.3382 (1.7020) loss_oracle 0.3453 (0.3309) acc 53.1250 (69.7230) lr 7.0224e-05 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,358
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,003
* accuracy: 50.5%
* error: 49.5%
* macro_f1: 31.4%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [47/50] batch [20/445] time 0.069 (0.099) data 0.000 (0.023) loss 1.2960 (1.5749) teacher_loss 0.7219 (0.9586) loss_zs_kd 1.8208 (1.6865) loss_oracle 0.3142 (0.3359) acc 75.0000 (67.5000) lr 4.8943e-05 eta 0:02:54
epoch [47/50] batch [40/445] time 0.067 (0.086) data 0.000 (0.012) loss 1.6795 (1.5549) teacher_loss 1.0706 (0.9380) loss_zs_kd 1.8405 (1.7064) loss_oracle 0.3140 (0.3312) acc 68.7500 (67.1094) lr 4.8943e-05 eta 0:02:29
epoch [47/50] batch [60/445] time 0.050 (0.076) data 0.001 (0.008) loss 1.4198 (1.5239) teacher_loss 0.8017 (0.9076) loss_zs_kd 1.4561 (1.6988) loss_oracle 0.3453 (0.3301) acc 78.1250 (67.8646) lr 4.8943e-05 eta 0:02:11
epoch [47/50] batch [80/445] time 0.066 (0.070) data 0.000 (0.006) loss 1.8740 (1.5288) teacher_loss 1.2252 (0.9126) loss_zs_kd 1.7863 (1.6878) loss_oracle 0.3141 (0.3321) acc 56.2500 (67.7344) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [100/445] time 0.071 (0.068) data 0.000 (0.005) loss 1.4262 (1.5028) teacher_loss 0.8231 (0.8917) loss_zs_kd 1.7981 (1.6738) loss_oracle 0.3453 (0.3326) acc 68.7500 (68.4375) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [120/445] time 0.075 (0.071) data 0.000 (0.004) loss 1.5623 (1.4902) teacher_loss 0.9272 (0.8781) loss_zs_kd 1.7536 (1.6761) loss_oracle 0.3414 (0.3343) acc 75.0000 (69.1146) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [140/445] time 0.074 (0.071) data 0.000 (0.004) loss 1.7465 (1.4912) teacher_loss 1.1514 (0.8797) loss_zs_kd 1.8261 (1.6709) loss_oracle 0.3143 (0.3334) acc 62.5000 (68.9062) lr 4.8943e-05 eta 0:01:56
epoch [47/50] batch [160/445] time 0.074 (0.072) data 0.000 (0.003) loss 1.2723 (1.4881) teacher_loss 0.7089 (0.8765) loss_zs_kd 1.7653 (1.6893) loss_oracle 0.3420 (0.3332) acc 71.8750 (69.0430) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [180/445] time 0.067 (0.072) data 0.000 (0.003) loss 1.4343 (1.4880) teacher_loss 0.8806 (0.8759) loss_zs_kd 1.9398 (1.6914) loss_oracle 0.3143 (0.3336) acc 78.1250 (69.2188) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [200/445] time 0.072 (0.072) data 0.000 (0.003) loss 1.3781 (1.4898) teacher_loss 0.8347 (0.8772) loss_zs_kd 1.9449 (1.7000) loss_oracle 0.3143 (0.3331) acc 75.0000 (68.9844) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [220/445] time 0.072 (0.072) data 0.000 (0.002) loss 1.4654 (1.4798) teacher_loss 0.8282 (0.8709) loss_zs_kd 1.7605 (1.7062) loss_oracle 0.3453 (0.3323) acc 65.6250 (69.1903) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [240/445] time 0.074 (0.072) data 0.000 (0.002) loss 1.6552 (1.4829) teacher_loss 1.0272 (0.8747) loss_zs_kd 1.6401 (1.7042) loss_oracle 0.3142 (0.3315) acc 62.5000 (69.0885) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [260/445] time 0.071 (0.072) data 0.000 (0.002) loss 1.6383 (1.4838) teacher_loss 0.9944 (0.8744) loss_zs_kd 2.0247 (1.7075) loss_oracle 0.3494 (0.3314) acc 68.7500 (69.2428) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [280/445] time 0.074 (0.072) data 0.000 (0.002) loss 1.2767 (1.4870) teacher_loss 0.7016 (0.8776) loss_zs_kd 1.4278 (1.7095) loss_oracle 0.3376 (0.3314) acc 78.1250 (69.1183) lr 4.8943e-05 eta 0:01:47
epoch [47/50] batch [300/445] time 0.073 (0.072) data 0.000 (0.002) loss 1.2849 (1.4817) teacher_loss 0.6818 (0.8725) loss_zs_kd 1.4377 (1.7036) loss_oracle 0.3764 (0.3311) acc 78.1250 (69.2708) lr 4.8943e-05 eta 0:01:46
epoch [47/50] batch [320/445] time 0.075 (0.072) data 0.000 (0.002) loss 1.3760 (1.4794) teacher_loss 0.6625 (0.8700) loss_zs_kd 1.6925 (1.7053) loss_oracle 0.3368 (0.3313) acc 81.2500 (69.5020) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [340/445] time 0.071 (0.072) data 0.000 (0.002) loss 1.5639 (1.4822) teacher_loss 0.8974 (0.8723) loss_zs_kd 1.4405 (1.7078) loss_oracle 0.3063 (0.3306) acc 65.6250 (69.3842) lr 4.8943e-05 eta 0:01:44
epoch [47/50] batch [360/445] time 0.066 (0.072) data 0.000 (0.002) loss 1.5223 (1.4818) teacher_loss 0.9018 (0.8721) loss_zs_kd 1.3926 (1.7067) loss_oracle 0.3264 (0.3302) acc 62.5000 (69.3576) lr 4.8943e-05 eta 0:01:42
epoch [47/50] batch [380/445] time 0.075 (0.072) data 0.000 (0.002) loss 1.4045 (1.4810) teacher_loss 0.8394 (0.8712) loss_zs_kd 1.8665 (1.7042) loss_oracle 0.3098 (0.3302) acc 62.5000 (69.4079) lr 4.8943e-05 eta 0:01:41
epoch [47/50] batch [400/445] time 0.067 (0.072) data 0.000 (0.001) loss 1.3998 (1.4818) teacher_loss 0.7358 (0.8719) loss_zs_kd 1.8210 (1.7015) loss_oracle 0.3419 (0.3305) acc 75.0000 (69.3516) lr 4.8943e-05 eta 0:01:39
epoch [47/50] batch [420/445] time 0.076 (0.072) data 0.000 (0.001) loss 1.5633 (1.4810) teacher_loss 1.0421 (0.8716) loss_zs_kd 1.7465 (1.7029) loss_oracle 0.3116 (0.3304) acc 62.5000 (69.2857) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [440/445] time 0.069 (0.072) data 0.000 (0.001) loss 1.1822 (1.4793) teacher_loss 0.6682 (0.8701) loss_zs_kd 1.9475 (1.7054) loss_oracle 0.3141 (0.3301) acc 75.0000 (69.3324) lr 4.8943e-05 eta 0:01:36
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,364
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,998
* accuracy: 50.3%
* error: 49.7%
* macro_f1: 31.3%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [48/50] batch [20/445] time 0.071 (0.103) data 0.000 (0.028) loss 1.2064 (1.4297) teacher_loss 0.6159 (0.8239) loss_zs_kd 1.6574 (1.7119) loss_oracle 0.3158 (0.3259) acc 81.2500 (70.0000) lr 3.1417e-05 eta 0:02:15
epoch [48/50] batch [40/445] time 0.069 (0.086) data 0.000 (0.014) loss 1.4109 (1.4813) teacher_loss 0.7692 (0.8702) loss_zs_kd 1.6916 (1.7272) loss_oracle 0.3433 (0.3268) acc 75.0000 (69.4531) lr 3.1417e-05 eta 0:01:51
epoch [48/50] batch [60/445] time 0.078 (0.082) data 0.000 (0.010) loss 1.2870 (1.4856) teacher_loss 0.7300 (0.8727) loss_zs_kd 1.7772 (1.7269) loss_oracle 0.3142 (0.3290) acc 71.8750 (69.4792) lr 3.1417e-05 eta 0:01:44
epoch [48/50] batch [80/445] time 0.073 (0.080) data 0.000 (0.007) loss 1.4175 (1.5038) teacher_loss 0.8367 (0.8917) loss_zs_kd 1.6122 (1.7137) loss_oracle 0.3452 (0.3303) acc 71.8750 (68.4766) lr 3.1417e-05 eta 0:01:39
epoch [48/50] batch [100/445] time 0.071 (0.078) data 0.000 (0.006) loss 1.4470 (1.5070) teacher_loss 0.8329 (0.8907) loss_zs_kd 1.4915 (1.7144) loss_oracle 0.3138 (0.3311) acc 62.5000 (68.5625) lr 3.1417e-05 eta 0:01:36
epoch [48/50] batch [120/445] time 0.069 (0.077) data 0.000 (0.005) loss 1.4080 (1.4990) teacher_loss 0.8442 (0.8872) loss_zs_kd 1.9934 (1.6980) loss_oracle 0.3074 (0.3310) acc 65.6250 (68.8542) lr 3.1417e-05 eta 0:01:33
epoch [48/50] batch [140/445] time 0.066 (0.076) data 0.000 (0.004) loss 1.2917 (1.5038) teacher_loss 0.7453 (0.8908) loss_zs_kd 1.5132 (1.7061) loss_oracle 0.3142 (0.3315) acc 62.5000 (68.5714) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [160/445] time 0.070 (0.076) data 0.000 (0.004) loss 1.1686 (1.4961) teacher_loss 0.6041 (0.8842) loss_zs_kd 1.5798 (1.7118) loss_oracle 0.3142 (0.3314) acc 75.0000 (68.8086) lr 3.1417e-05 eta 0:01:28
epoch [48/50] batch [180/445] time 0.069 (0.075) data 0.000 (0.003) loss 1.3742 (1.4942) teacher_loss 0.8102 (0.8831) loss_zs_kd 1.5461 (1.7084) loss_oracle 0.3454 (0.3319) acc 62.5000 (68.7847) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [200/445] time 0.067 (0.075) data 0.000 (0.003) loss 1.5051 (1.4947) teacher_loss 0.9519 (0.8831) loss_zs_kd 1.7799 (1.7075) loss_oracle 0.3498 (0.3316) acc 68.7500 (68.7500) lr 3.1417e-05 eta 0:01:25
epoch [48/50] batch [220/445] time 0.079 (0.075) data 0.000 (0.003) loss 1.5626 (1.4931) teacher_loss 1.0714 (0.8820) loss_zs_kd 1.3963 (1.7144) loss_oracle 0.3397 (0.3320) acc 65.6250 (68.9205) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [240/445] time 0.080 (0.075) data 0.000 (0.003) loss 1.3303 (1.4851) teacher_loss 0.8185 (0.8750) loss_zs_kd 1.5128 (1.7092) loss_oracle 0.3142 (0.3319) acc 68.7500 (69.2839) lr 3.1417e-05 eta 0:01:21
epoch [48/50] batch [260/445] time 0.067 (0.074) data 0.000 (0.002) loss 1.6111 (1.4850) teacher_loss 1.0185 (0.8741) loss_zs_kd 1.6105 (1.7124) loss_oracle 0.3142 (0.3312) acc 62.5000 (69.3750) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [280/445] time 0.059 (0.074) data 0.000 (0.002) loss 1.3094 (1.4851) teacher_loss 0.6991 (0.8747) loss_zs_kd 2.2072 (1.7129) loss_oracle 0.3365 (0.3311) acc 78.1250 (69.3527) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [300/445] time 0.073 (0.073) data 0.000 (0.002) loss 1.4037 (1.4802) teacher_loss 0.8438 (0.8698) loss_zs_kd 1.8816 (1.7085) loss_oracle 0.3452 (0.3311) acc 71.8750 (69.4896) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [320/445] time 0.125 (0.074) data 0.000 (0.002) loss 1.2840 (1.4775) teacher_loss 0.7074 (0.8663) loss_zs_kd 1.7117 (1.7172) loss_oracle 0.3394 (0.3313) acc 68.7500 (69.6387) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [340/445] time 0.075 (0.074) data 0.000 (0.002) loss 1.6235 (1.4749) teacher_loss 0.9791 (0.8649) loss_zs_kd 1.7516 (1.7150) loss_oracle 0.3763 (0.3313) acc 62.5000 (69.6967) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [360/445] time 0.078 (0.074) data 0.000 (0.002) loss 1.8129 (1.4815) teacher_loss 1.1141 (0.8707) loss_zs_kd 1.5342 (1.7111) loss_oracle 0.3347 (0.3312) acc 62.5000 (69.5660) lr 3.1417e-05 eta 0:01:12
epoch [48/50] batch [380/445] time 0.070 (0.074) data 0.000 (0.002) loss 1.5774 (1.4829) teacher_loss 0.9702 (0.8724) loss_zs_kd 2.0150 (1.7127) loss_oracle 0.3113 (0.3311) acc 59.3750 (69.5312) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [400/445] time 0.067 (0.074) data 0.000 (0.002) loss 1.5010 (1.4822) teacher_loss 0.8610 (0.8727) loss_zs_kd 1.9946 (1.7106) loss_oracle 0.3142 (0.3306) acc 68.7500 (69.5625) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [420/445] time 0.075 (0.074) data 0.000 (0.002) loss 1.1037 (1.4823) teacher_loss 0.5864 (0.8733) loss_zs_kd 1.8362 (1.7134) loss_oracle 0.3143 (0.3305) acc 78.1250 (69.5685) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [440/445] time 0.064 (0.074) data 0.000 (0.002) loss 1.1789 (1.4791) teacher_loss 0.5937 (0.8701) loss_zs_kd 1.2672 (1.7131) loss_oracle 0.3453 (0.3303) acc 87.5000 (69.6875) lr 3.1417e-05 eta 0:01:05
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,370
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 1,998
* accuracy: 50.3%
* error: 49.7%
* macro_f1: 31.4%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [49/50] batch [20/445] time 0.083 (0.106) data 0.000 (0.028) loss 1.1105 (1.4880) teacher_loss 0.6548 (0.8663) loss_zs_kd 1.6745 (1.7017) loss_oracle 0.3142 (0.3506) acc 75.0000 (70.0000) lr 1.7713e-05 eta 0:01:31
epoch [49/50] batch [40/445] time 0.063 (0.088) data 0.000 (0.014) loss 1.7267 (1.4915) teacher_loss 1.0680 (0.8795) loss_zs_kd 1.8867 (1.7321) loss_oracle 0.3392 (0.3363) acc 62.5000 (69.4531) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [60/445] time 0.067 (0.082) data 0.001 (0.010) loss 1.4967 (1.4741) teacher_loss 0.8439 (0.8632) loss_zs_kd 2.0572 (1.7445) loss_oracle 0.3081 (0.3331) acc 68.7500 (70.3646) lr 1.7713e-05 eta 0:01:08
epoch [49/50] batch [80/445] time 0.076 (0.082) data 0.000 (0.007) loss 1.5205 (1.4878) teacher_loss 0.8741 (0.8736) loss_zs_kd 2.0683 (1.7396) loss_oracle 0.2986 (0.3374) acc 65.6250 (69.6484) lr 1.7713e-05 eta 0:01:06
epoch [49/50] batch [100/445] time 0.083 (0.080) data 0.000 (0.006) loss 1.4737 (1.4912) teacher_loss 0.9121 (0.8739) loss_zs_kd 2.2952 (1.7215) loss_oracle 0.3449 (0.3383) acc 62.5000 (69.4062) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [120/445] time 0.069 (0.079) data 0.000 (0.005) loss 1.3105 (1.4890) teacher_loss 0.6717 (0.8748) loss_zs_kd 1.6214 (1.7088) loss_oracle 0.3454 (0.3378) acc 81.2500 (69.4531) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [140/445] time 0.062 (0.078) data 0.000 (0.004) loss 1.4810 (1.4863) teacher_loss 0.8694 (0.8709) loss_zs_kd 1.9425 (1.7168) loss_oracle 0.3469 (0.3362) acc 68.7500 (69.4196) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [160/445] time 0.072 (0.077) data 0.000 (0.004) loss 1.7659 (1.4980) teacher_loss 1.0771 (0.8809) loss_zs_kd 2.0220 (1.7188) loss_oracle 0.3143 (0.3360) acc 53.1250 (69.0430) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [180/445] time 0.072 (0.077) data 0.000 (0.003) loss 1.2159 (1.4935) teacher_loss 0.6400 (0.8791) loss_zs_kd 1.6094 (1.7193) loss_oracle 0.3133 (0.3351) acc 75.0000 (69.0799) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [200/445] time 0.074 (0.077) data 0.000 (0.003) loss 1.5523 (1.4926) teacher_loss 0.9492 (0.8782) loss_zs_kd 1.9354 (1.7144) loss_oracle 0.3122 (0.3347) acc 68.7500 (69.2031) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [220/445] time 0.084 (0.076) data 0.000 (0.003) loss 1.3888 (1.4903) teacher_loss 0.7522 (0.8747) loss_zs_kd 1.8429 (1.7137) loss_oracle 0.3453 (0.3337) acc 62.5000 (69.2756) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [240/445] time 0.084 (0.076) data 0.000 (0.003) loss 1.4437 (1.4931) teacher_loss 0.8451 (0.8761) loss_zs_kd 1.5475 (1.7194) loss_oracle 0.3295 (0.3336) acc 75.0000 (69.2448) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [260/445] time 0.073 (0.077) data 0.000 (0.002) loss 1.5541 (1.4911) teacher_loss 0.8937 (0.8742) loss_zs_kd 1.7973 (1.7153) loss_oracle 0.3390 (0.3330) acc 65.6250 (69.3029) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [280/445] time 0.068 (0.076) data 0.001 (0.002) loss 1.3677 (1.4848) teacher_loss 0.8480 (0.8702) loss_zs_kd 1.6672 (1.7076) loss_oracle 0.3143 (0.3320) acc 65.6250 (69.2634) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [300/445] time 0.070 (0.076) data 0.001 (0.002) loss 1.3832 (1.4870) teacher_loss 0.7021 (0.8716) loss_zs_kd 1.4913 (1.7045) loss_oracle 0.3729 (0.3319) acc 81.2500 (69.2708) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [320/445] time 0.076 (0.076) data 0.000 (0.002) loss 1.8223 (1.4856) teacher_loss 1.2269 (0.8706) loss_zs_kd 1.8753 (1.7033) loss_oracle 0.3134 (0.3319) acc 56.2500 (69.2676) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [340/445] time 0.082 (0.076) data 0.001 (0.002) loss 1.5692 (1.4865) teacher_loss 1.0236 (0.8713) loss_zs_kd 1.5070 (1.6993) loss_oracle 0.3142 (0.3320) acc 59.3750 (69.2188) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [360/445] time 0.073 (0.076) data 0.000 (0.002) loss 1.5137 (1.4854) teacher_loss 0.9100 (0.8705) loss_zs_kd 1.8165 (1.7011) loss_oracle 0.3369 (0.3320) acc 75.0000 (69.1927) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [380/445] time 0.065 (0.076) data 0.000 (0.002) loss 1.5547 (1.4888) teacher_loss 0.9175 (0.8742) loss_zs_kd 1.8355 (1.7009) loss_oracle 0.3453 (0.3320) acc 65.6250 (69.0543) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [400/445] time 0.072 (0.075) data 0.000 (0.002) loss 1.7131 (1.4904) teacher_loss 1.0912 (0.8756) loss_zs_kd 1.9824 (1.6969) loss_oracle 0.3143 (0.3322) acc 62.5000 (69.0703) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [420/445] time 0.069 (0.075) data 0.000 (0.002) loss 1.3239 (1.4913) teacher_loss 0.8279 (0.8776) loss_zs_kd 1.8499 (1.6984) loss_oracle 0.3137 (0.3321) acc 75.0000 (69.1220) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [440/445] time 0.066 (0.075) data 0.000 (0.002) loss 1.2977 (1.4882) teacher_loss 0.7596 (0.8751) loss_zs_kd 1.7538 (1.6977) loss_oracle 0.3143 (0.3323) acc 68.7500 (69.2472) lr 1.7713e-05 eta 0:00:33
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,365
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,006
* accuracy: 50.5%
* error: 49.5%
* macro_f1: 31.5%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
epoch [50/50] batch [20/445] time 0.073 (0.109) data 0.000 (0.034) loss 1.2376 (1.4900) teacher_loss 0.6577 (0.8665) loss_zs_kd 1.4551 (1.6658) loss_oracle 0.3142 (0.3358) acc 78.1250 (70.4688) lr 7.8853e-06 eta 0:00:46
epoch [50/50] batch [40/445] time 0.071 (0.091) data 0.000 (0.017) loss 1.6079 (1.4953) teacher_loss 0.8952 (0.8668) loss_zs_kd 2.0603 (1.7070) loss_oracle 0.3630 (0.3336) acc 65.6250 (69.5312) lr 7.8853e-06 eta 0:00:36
epoch [50/50] batch [60/445] time 0.069 (0.085) data 0.000 (0.012) loss 1.8089 (1.4725) teacher_loss 1.2321 (0.8514) loss_zs_kd 1.8616 (1.6984) loss_oracle 0.3453 (0.3316) acc 46.8750 (70.0521) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [80/445] time 0.072 (0.081) data 0.000 (0.009) loss 1.4201 (1.4789) teacher_loss 0.7285 (0.8640) loss_zs_kd 1.6899 (1.6921) loss_oracle 0.3660 (0.3303) acc 78.1250 (69.4531) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [100/445] time 0.074 (0.080) data 0.000 (0.007) loss 1.4469 (1.4897) teacher_loss 0.8639 (0.8731) loss_zs_kd 1.3950 (1.6914) loss_oracle 0.3352 (0.3313) acc 71.8750 (69.1250) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [120/445] time 0.074 (0.078) data 0.000 (0.006) loss 1.7520 (1.4967) teacher_loss 1.0835 (0.8811) loss_zs_kd 1.9559 (1.7009) loss_oracle 0.3440 (0.3336) acc 59.3750 (68.4896) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [140/445] time 0.074 (0.078) data 0.000 (0.005) loss 2.0224 (1.5002) teacher_loss 1.3037 (0.8839) loss_zs_kd 1.9313 (1.6965) loss_oracle 0.3139 (0.3336) acc 53.1250 (68.5714) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [160/445] time 0.075 (0.078) data 0.000 (0.005) loss 1.5451 (1.5018) teacher_loss 0.9507 (0.8848) loss_zs_kd 2.2006 (1.7008) loss_oracle 0.3143 (0.3336) acc 65.6250 (68.7109) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [180/445] time 0.072 (0.077) data 0.000 (0.004) loss 1.2586 (1.4991) teacher_loss 0.6320 (0.8835) loss_zs_kd 2.0390 (1.6984) loss_oracle 0.3234 (0.3326) acc 71.8750 (68.7674) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [200/445] time 0.073 (0.076) data 0.000 (0.004) loss 1.2851 (1.4923) teacher_loss 0.7495 (0.8809) loss_zs_kd 1.9495 (1.6967) loss_oracle 0.3142 (0.3317) acc 71.8750 (68.9844) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [220/445] time 0.080 (0.076) data 0.000 (0.003) loss 1.3174 (1.4923) teacher_loss 0.8129 (0.8817) loss_zs_kd 1.6648 (1.6987) loss_oracle 0.3140 (0.3320) acc 68.7500 (69.0625) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [240/445] time 0.063 (0.075) data 0.000 (0.003) loss 1.2885 (1.4917) teacher_loss 0.7659 (0.8806) loss_zs_kd 1.4920 (1.7030) loss_oracle 0.3142 (0.3323) acc 78.1250 (69.1406) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [260/445] time 0.137 (0.075) data 0.001 (0.003) loss 1.2251 (1.4917) teacher_loss 0.5884 (0.8812) loss_zs_kd 1.5280 (1.7072) loss_oracle 0.3140 (0.3325) acc 87.5000 (69.1106) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [280/445] time 0.066 (0.076) data 0.000 (0.003) loss 1.0813 (1.4894) teacher_loss 0.5746 (0.8796) loss_zs_kd 1.5376 (1.7058) loss_oracle 0.3142 (0.3321) acc 75.0000 (69.0737) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [300/445] time 0.069 (0.076) data 0.000 (0.003) loss 1.5281 (1.4940) teacher_loss 0.9546 (0.8842) loss_zs_kd 1.6659 (1.7065) loss_oracle 0.3450 (0.3320) acc 62.5000 (68.9271) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [320/445] time 0.081 (0.076) data 0.001 (0.002) loss 1.5457 (1.4916) teacher_loss 0.9148 (0.8824) loss_zs_kd 1.7880 (1.7099) loss_oracle 0.3453 (0.3323) acc 68.7500 (68.9551) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [340/445] time 0.070 (0.075) data 0.000 (0.002) loss 1.6754 (1.4922) teacher_loss 1.0681 (0.8836) loss_zs_kd 1.7609 (1.7107) loss_oracle 0.3453 (0.3321) acc 65.6250 (68.8695) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [360/445] time 0.083 (0.075) data 0.001 (0.002) loss 1.4201 (1.4878) teacher_loss 0.8450 (0.8795) loss_zs_kd 1.8492 (1.7118) loss_oracle 0.3325 (0.3320) acc 68.7500 (69.0191) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [380/445] time 0.067 (0.075) data 0.000 (0.002) loss 1.6237 (1.4855) teacher_loss 0.9430 (0.8781) loss_zs_kd 1.8304 (1.7072) loss_oracle 0.3756 (0.3319) acc 59.3750 (69.0461) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [400/445] time 0.075 (0.075) data 0.000 (0.002) loss 1.6715 (1.4884) teacher_loss 1.0162 (0.8799) loss_zs_kd 1.5533 (1.7026) loss_oracle 0.3158 (0.3322) acc 56.2500 (68.9375) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [420/445] time 0.068 (0.075) data 0.000 (0.002) loss 1.3643 (1.4888) teacher_loss 0.7969 (0.8802) loss_zs_kd 1.5669 (1.7028) loss_oracle 0.3436 (0.3326) acc 75.0000 (68.9286) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [440/445] time 0.069 (0.075) data 0.001 (0.002) loss 1.4715 (1.4861) teacher_loss 0.9558 (0.8785) loss_zs_kd 1.7388 (1.7045) loss_oracle 0.3142 (0.3324) acc 65.6250 (68.9631) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 6,108
* correct: 4,365
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 3,970
* correct: 2,003
* accuracy: 50.5%
* error: 49.5%
* macro_f1: 31.5%
******* Domain 3 best val acc:      71.5%, epoch: 45 *******
******* Domain 3 best val test acc: 50.6%, epoch: 45 *******
******* Domain 3 best test acc:     52.7%, epoch: 25 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_2prompt_detach/TRIP/terra_incognita/b32_ep50/ViT-B16/3/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:46:04

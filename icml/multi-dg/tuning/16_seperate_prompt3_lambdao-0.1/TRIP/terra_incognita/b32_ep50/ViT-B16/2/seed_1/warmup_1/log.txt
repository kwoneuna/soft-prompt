Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_43', 'location_46']
Target     ['location_38']
# classes  10
# train_x  10,216
# val      4,378
# test     9,736
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/319] time 0.078 (0.136) data 0.000 (0.039) loss 2.2197 (2.9633) teacher_loss 1.2525 (2.0157) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0132 (0.0052) kd_loss 0.9658 (0.9471) acc 59.3750 (37.0312) lr 1.0000e-05 eta 0:36:10
epoch [1/50] batch [40/319] time 0.083 (0.108) data 0.000 (0.020) loss 2.4836 (2.8422) teacher_loss 1.5742 (1.9122) loss_zs_kd 0.0016 (0.0003) loss_oracle 0.0116 (0.0110) kd_loss 0.9083 (0.9290) acc 56.2500 (39.6875) lr 1.0000e-05 eta 0:28:32
epoch [1/50] batch [60/319] time 0.079 (0.099) data 0.000 (0.013) loss 3.1227 (2.8761) teacher_loss 2.1706 (1.9405) loss_zs_kd 0.0027 (0.0008) loss_oracle 0.0230 (0.0151) kd_loss 0.9497 (0.9341) acc 31.2500 (39.1667) lr 1.0000e-05 eta 0:26:09
epoch [1/50] batch [80/319] time 0.086 (0.095) data 0.000 (0.010) loss 2.9013 (2.8569) teacher_loss 1.9689 (1.9216) loss_zs_kd 0.0041 (0.0015) loss_oracle 0.0998 (0.0243) kd_loss 0.9224 (0.9329) acc 43.7500 (38.8672) lr 1.0000e-05 eta 0:25:03
epoch [1/50] batch [100/319] time 0.083 (0.093) data 0.000 (0.008) loss 3.1927 (2.8178) teacher_loss 2.1719 (1.8828) loss_zs_kd 0.0079 (0.0025) loss_oracle 0.1561 (0.0440) kd_loss 1.0052 (0.9306) acc 25.0000 (39.5000) lr 1.0000e-05 eta 0:24:32
epoch [1/50] batch [120/319] time 0.085 (0.091) data 0.000 (0.007) loss 2.7442 (2.8152) teacher_loss 1.8670 (1.8808) loss_zs_kd 0.0065 (0.0035) loss_oracle 0.0683 (0.0556) kd_loss 0.8704 (0.9289) acc 40.6250 (39.6354) lr 1.0000e-05 eta 0:23:58
epoch [1/50] batch [140/319] time 0.081 (0.090) data 0.000 (0.006) loss 2.8732 (2.8128) teacher_loss 2.0516 (1.8807) loss_zs_kd 0.0103 (0.0045) loss_oracle 0.0213 (0.0554) kd_loss 0.8195 (0.9266) acc 37.5000 (39.5536) lr 1.0000e-05 eta 0:23:50
epoch [1/50] batch [160/319] time 0.071 (0.089) data 0.000 (0.005) loss 2.7353 (2.8066) teacher_loss 1.8230 (1.8767) loss_zs_kd 0.0140 (0.0058) loss_oracle 0.0385 (0.0522) kd_loss 0.9085 (0.9247) acc 34.3750 (39.6875) lr 1.0000e-05 eta 0:23:21
epoch [1/50] batch [180/319] time 0.074 (0.088) data 0.000 (0.005) loss 3.0301 (2.8017) teacher_loss 2.1707 (1.8733) loss_zs_kd 0.0239 (0.0073) loss_oracle 0.0677 (0.0523) kd_loss 0.8526 (0.9232) acc 28.1250 (39.6354) lr 1.0000e-05 eta 0:23:12
epoch [1/50] batch [200/319] time 0.076 (0.088) data 0.000 (0.004) loss 2.9840 (2.7975) teacher_loss 1.9916 (1.8686) loss_zs_kd 0.0253 (0.0089) loss_oracle 0.1543 (0.0573) kd_loss 0.9770 (0.9232) acc 31.2500 (39.6250) lr 1.0000e-05 eta 0:22:58
epoch [1/50] batch [220/319] time 0.077 (0.087) data 0.000 (0.004) loss 2.6671 (2.8043) teacher_loss 1.7086 (1.8743) loss_zs_kd 0.0324 (0.0108) loss_oracle 0.1291 (0.0653) kd_loss 0.9457 (0.9235) acc 43.7500 (39.2188) lr 1.0000e-05 eta 0:22:49
epoch [1/50] batch [240/319] time 0.081 (0.086) data 0.000 (0.004) loss 2.8433 (2.8136) teacher_loss 1.9302 (1.8808) loss_zs_kd 0.0450 (0.0128) loss_oracle 0.1510 (0.0729) kd_loss 0.8981 (0.9255) acc 28.1250 (38.9323) lr 1.0000e-05 eta 0:22:36
epoch [1/50] batch [260/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.9007 (2.8114) teacher_loss 1.9825 (1.8779) loss_zs_kd 0.0413 (0.0148) loss_oracle 0.2138 (0.0798) kd_loss 0.8968 (0.9255) acc 40.6250 (38.8942) lr 1.0000e-05 eta 0:22:27
epoch [1/50] batch [280/319] time 0.088 (0.086) data 0.000 (0.003) loss 3.0803 (2.8087) teacher_loss 2.0931 (1.8740) loss_zs_kd 0.0603 (0.0172) loss_oracle 0.2860 (0.0910) kd_loss 0.9585 (0.9256) acc 31.2500 (38.9621) lr 1.0000e-05 eta 0:22:26
epoch [1/50] batch [300/319] time 0.085 (0.086) data 0.000 (0.003) loss 3.2027 (2.8053) teacher_loss 2.2809 (1.8698) loss_zs_kd 0.0591 (0.0197) loss_oracle 0.1742 (0.0996) kd_loss 0.9044 (0.9255) acc 31.2500 (38.9583) lr 1.0000e-05 eta 0:22:21
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,779
* accuracy: 40.6%
* error: 59.4%
* macro_f1: 26.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,232
* accuracy: 33.2%
* error: 66.8%
* macro_f1: 14.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      40.6%, epoch: 1 *******
******* Domain 2 best val test acc: 33.2%, epoch: 1 *******
******* Domain 2 best test acc:     33.2%, epoch: 1 *******
epoch [2/50] batch [20/319] time 0.085 (0.113) data 0.000 (0.030) loss 2.7693 (2.6939) teacher_loss 1.6593 (1.6238) loss_zs_kd 0.4238 (0.3261) loss_oracle 1.0595 (0.8887) kd_loss 1.0041 (0.9812) acc 37.5000 (39.5312) lr 2.0000e-03 eta 0:29:29
epoch [2/50] batch [40/319] time 0.079 (0.099) data 0.000 (0.015) loss 3.1537 (2.6723) teacher_loss 2.0280 (1.5656) loss_zs_kd 0.7690 (0.3992) loss_oracle 1.0777 (0.9838) kd_loss 1.0179 (1.0084) acc 25.0000 (42.8906) lr 2.0000e-03 eta 0:25:40
epoch [2/50] batch [60/319] time 0.081 (0.093) data 0.000 (0.010) loss 2.4838 (2.6455) teacher_loss 1.3197 (1.5244) loss_zs_kd 0.4551 (0.4767) loss_oracle 1.0674 (1.0129) kd_loss 1.0573 (1.0198) acc 56.2500 (43.6458) lr 2.0000e-03 eta 0:24:05
epoch [2/50] batch [80/319] time 0.089 (0.091) data 0.000 (0.008) loss 2.8011 (2.6355) teacher_loss 1.6061 (1.5059) loss_zs_kd 0.5142 (0.4744) loss_oracle 1.0581 (1.0239) kd_loss 1.0892 (1.0272) acc 40.6250 (44.1406) lr 2.0000e-03 eta 0:23:34
epoch [2/50] batch [100/319] time 0.088 (0.089) data 0.000 (0.006) loss 2.6249 (2.6273) teacher_loss 1.4793 (1.4899) loss_zs_kd 0.9274 (0.5194) loss_oracle 1.0256 (1.0257) kd_loss 1.0431 (1.0349) acc 50.0000 (44.4375) lr 2.0000e-03 eta 0:23:05
epoch [2/50] batch [120/319] time 0.077 (0.087) data 0.000 (0.005) loss 2.1212 (2.5991) teacher_loss 0.9728 (1.4638) loss_zs_kd 0.6428 (0.6101) loss_oracle 1.0084 (1.0276) kd_loss 1.0476 (1.0325) acc 65.6250 (45.2865) lr 2.0000e-03 eta 0:22:36
epoch [2/50] batch [140/319] time 0.085 (0.087) data 0.000 (0.005) loss 2.4928 (2.5758) teacher_loss 1.3822 (1.4430) loss_zs_kd 0.5274 (0.5886) loss_oracle 1.0447 (1.0287) kd_loss 1.0061 (1.0299) acc 46.8750 (46.3170) lr 2.0000e-03 eta 0:22:23
epoch [2/50] batch [160/319] time 0.081 (0.087) data 0.000 (0.004) loss 2.4400 (2.5445) teacher_loss 1.2763 (1.4129) loss_zs_kd 0.6229 (0.5914) loss_oracle 1.0423 (1.0278) kd_loss 1.0594 (1.0288) acc 62.5000 (47.5000) lr 2.0000e-03 eta 0:22:23
epoch [2/50] batch [180/319] time 0.083 (0.086) data 0.000 (0.004) loss 2.7320 (2.5344) teacher_loss 1.5882 (1.4075) loss_zs_kd 0.3751 (0.5731) loss_oracle 1.0366 (1.0252) kd_loss 1.0402 (1.0243) acc 43.7500 (47.8819) lr 2.0000e-03 eta 0:22:14
epoch [2/50] batch [200/319] time 0.085 (0.086) data 0.000 (0.003) loss 2.7129 (2.5456) teacher_loss 1.5075 (1.4152) loss_zs_kd 0.5396 (0.5672) loss_oracle 0.9787 (1.0243) kd_loss 1.1076 (1.0280) acc 43.7500 (47.9531) lr 2.0000e-03 eta 0:22:11
epoch [2/50] batch [220/319] time 0.089 (0.086) data 0.000 (0.003) loss 2.9614 (2.5490) teacher_loss 1.7609 (1.4158) loss_zs_kd 0.4477 (0.5716) loss_oracle 0.9796 (1.0235) kd_loss 1.1025 (1.0309) acc 37.5000 (47.8551) lr 2.0000e-03 eta 0:22:01
epoch [2/50] batch [240/319] time 0.085 (0.085) data 0.000 (0.003) loss 2.3144 (2.5494) teacher_loss 1.1398 (1.4119) loss_zs_kd 0.6003 (0.5720) loss_oracle 1.0109 (1.0234) kd_loss 1.0735 (1.0351) acc 50.0000 (48.1380) lr 2.0000e-03 eta 0:21:54
epoch [2/50] batch [260/319] time 0.078 (0.085) data 0.000 (0.003) loss 2.4205 (2.5374) teacher_loss 1.2558 (1.3977) loss_zs_kd 0.6146 (0.5829) loss_oracle 0.9350 (1.0222) kd_loss 1.0712 (1.0375) acc 46.8750 (48.5577) lr 2.0000e-03 eta 0:21:46
epoch [2/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.002) loss 2.4482 (2.5377) teacher_loss 1.2935 (1.3969) loss_zs_kd 0.5454 (0.5850) loss_oracle 1.0616 (1.0216) kd_loss 1.0485 (1.0387) acc 37.5000 (48.3705) lr 2.0000e-03 eta 0:21:44
epoch [2/50] batch [300/319] time 0.136 (0.085) data 0.000 (0.002) loss 2.4936 (2.5390) teacher_loss 1.3620 (1.3961) loss_zs_kd 0.8443 (0.6048) loss_oracle 1.0450 (1.0229) kd_loss 1.0271 (1.0407) acc 59.3750 (48.3958) lr 2.0000e-03 eta 0:21:49
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,057
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 37.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,569
* accuracy: 36.7%
* error: 63.3%
* macro_f1: 21.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      47.0%, epoch: 2 *******
******* Domain 2 best val test acc: 36.7%, epoch: 2 *******
******* Domain 2 best test acc:     36.7%, epoch: 2 *******
epoch [3/50] batch [20/319] time 0.081 (0.122) data 0.000 (0.036) loss 2.2550 (2.3773) teacher_loss 1.1051 (1.2231) loss_zs_kd 0.4081 (0.6637) loss_oracle 1.0979 (1.0701) kd_loss 1.0401 (1.0472) acc 50.0000 (52.5000) lr 1.9980e-03 eta 0:31:12
epoch [3/50] batch [40/319] time 0.096 (0.103) data 0.000 (0.018) loss 2.4510 (2.4063) teacher_loss 1.2910 (1.2606) loss_zs_kd 0.6623 (0.6139) loss_oracle 1.0875 (1.0782) kd_loss 1.0512 (1.0379) acc 46.8750 (50.8594) lr 1.9980e-03 eta 0:26:12
epoch [3/50] batch [60/319] time 0.070 (0.097) data 0.000 (0.012) loss 2.2319 (2.4135) teacher_loss 1.0989 (1.2732) loss_zs_kd 0.8470 (0.6467) loss_oracle 1.0396 (1.0650) kd_loss 1.0291 (1.0337) acc 62.5000 (50.3646) lr 1.9980e-03 eta 0:24:33
epoch [3/50] batch [80/319] time 0.076 (0.092) data 0.000 (0.009) loss 2.1942 (2.4150) teacher_loss 1.0924 (1.2780) loss_zs_kd 0.8066 (0.7338) loss_oracle 1.0267 (1.0514) kd_loss 0.9991 (1.0319) acc 56.2500 (49.7266) lr 1.9980e-03 eta 0:23:17
epoch [3/50] batch [100/319] time 0.071 (0.092) data 0.000 (0.007) loss 2.4636 (2.4065) teacher_loss 1.3330 (1.2743) loss_zs_kd 1.2859 (0.8122) loss_oracle 0.9800 (1.0438) kd_loss 1.0326 (1.0279) acc 56.2500 (50.4062) lr 1.9980e-03 eta 0:23:19
epoch [3/50] batch [120/319] time 0.080 (0.090) data 0.000 (0.006) loss 2.5413 (2.4029) teacher_loss 1.4491 (1.2742) loss_zs_kd 0.7095 (0.8025) loss_oracle 1.0931 (1.0429) kd_loss 0.9829 (1.0243) acc 43.7500 (50.6510) lr 1.9980e-03 eta 0:22:41
epoch [3/50] batch [140/319] time 0.088 (0.089) data 0.000 (0.005) loss 2.3774 (2.4125) teacher_loss 1.1495 (1.2799) loss_zs_kd 0.7620 (0.8022) loss_oracle 1.1008 (1.0485) kd_loss 1.1178 (1.0277) acc 62.5000 (50.7143) lr 1.9980e-03 eta 0:22:22
epoch [3/50] batch [160/319] time 0.083 (0.088) data 0.000 (0.005) loss 2.3026 (2.4228) teacher_loss 1.1692 (1.2853) loss_zs_kd 0.6139 (0.7931) loss_oracle 1.0559 (1.0518) kd_loss 1.0278 (1.0324) acc 65.6250 (50.8594) lr 1.9980e-03 eta 0:22:13
epoch [3/50] batch [180/319] time 0.081 (0.088) data 0.000 (0.004) loss 2.3322 (2.4209) teacher_loss 1.2164 (1.2816) loss_zs_kd 0.6053 (0.7866) loss_oracle 1.0110 (1.0539) kd_loss 1.0148 (1.0339) acc 56.2500 (51.0069) lr 1.9980e-03 eta 0:22:08
epoch [3/50] batch [200/319] time 0.085 (0.088) data 0.000 (0.004) loss 2.5685 (2.4162) teacher_loss 1.4144 (1.2802) loss_zs_kd 0.8613 (0.7780) loss_oracle 1.1045 (1.0547) kd_loss 1.0437 (1.0305) acc 53.1250 (51.0312) lr 1.9980e-03 eta 0:22:05
epoch [3/50] batch [220/319] time 0.083 (0.087) data 0.000 (0.004) loss 2.2886 (2.4110) teacher_loss 1.2183 (1.2799) loss_zs_kd 0.6267 (0.7722) loss_oracle 1.0397 (1.0518) kd_loss 0.9664 (1.0260) acc 53.1250 (50.9943) lr 1.9980e-03 eta 0:21:55
epoch [3/50] batch [240/319] time 0.086 (0.087) data 0.000 (0.003) loss 2.7393 (2.4048) teacher_loss 1.6257 (1.2765) loss_zs_kd 0.8939 (0.7710) loss_oracle 1.0457 (1.0521) kd_loss 1.0090 (1.0231) acc 46.8750 (51.2500) lr 1.9980e-03 eta 0:21:50
epoch [3/50] batch [260/319] time 0.082 (0.087) data 0.000 (0.003) loss 2.2417 (2.4013) teacher_loss 1.2006 (1.2763) loss_zs_kd 0.7366 (0.7657) loss_oracle 0.9752 (1.0516) kd_loss 0.9436 (1.0199) acc 43.7500 (51.1418) lr 1.9980e-03 eta 0:21:44
epoch [3/50] batch [280/319] time 0.106 (0.087) data 0.000 (0.003) loss 2.2025 (2.3893) teacher_loss 1.0927 (1.2687) loss_zs_kd 1.0167 (0.7765) loss_oracle 1.0723 (1.0496) kd_loss 1.0025 (1.0157) acc 62.5000 (51.3393) lr 1.9980e-03 eta 0:21:47
epoch [3/50] batch [300/319] time 0.081 (0.087) data 0.000 (0.003) loss 2.1131 (2.3752) teacher_loss 1.0402 (1.2572) loss_zs_kd 0.7503 (0.7979) loss_oracle 1.0129 (1.0488) kd_loss 0.9717 (1.0131) acc 71.8750 (52.0938) lr 1.9980e-03 eta 0:21:48
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,166
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 34.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,990
* accuracy: 20.4%
* error: 79.6%
* macro_f1: 16.4%
******* Domain 2 best val acc:      49.5%, epoch: 3 *******
******* Domain 2 best val test acc: 20.4%, epoch: 3 *******
******* Domain 2 best test acc:     36.7%, epoch: 2 *******
epoch [4/50] batch [20/319] time 0.081 (0.101) data 0.000 (0.023) loss 2.6602 (2.5042) teacher_loss 1.5075 (1.3062) loss_zs_kd 0.8258 (0.6875) loss_oracle 1.1409 (1.1082) kd_loss 1.0385 (1.0872) acc 31.2500 (48.7500) lr 1.9921e-03 eta 0:25:07
epoch [4/50] batch [40/319] time 0.070 (0.090) data 0.000 (0.012) loss 2.4011 (2.5159) teacher_loss 1.2762 (1.3194) loss_zs_kd 0.5565 (0.6819) loss_oracle 1.1360 (1.1127) kd_loss 1.0113 (1.0853) acc 53.1250 (48.9062) lr 1.9921e-03 eta 0:22:32
epoch [4/50] batch [60/319] time 0.073 (0.087) data 0.000 (0.008) loss 2.5231 (2.4652) teacher_loss 1.3834 (1.2754) loss_zs_kd 1.0936 (0.7397) loss_oracle 1.0934 (1.1099) kd_loss 1.0304 (1.0787) acc 62.5000 (51.5625) lr 1.9921e-03 eta 0:21:44
epoch [4/50] batch [80/319] time 0.088 (0.086) data 0.000 (0.006) loss 2.4305 (2.4518) teacher_loss 1.3643 (1.2863) loss_zs_kd 0.9156 (0.7510) loss_oracle 0.9803 (1.0948) kd_loss 0.9682 (1.0559) acc 46.8750 (51.1719) lr 1.9921e-03 eta 0:21:19
epoch [4/50] batch [100/319] time 0.084 (0.086) data 0.000 (0.005) loss 2.4748 (2.4306) teacher_loss 1.3949 (1.2809) loss_zs_kd 1.0274 (0.8130) loss_oracle 1.0232 (1.0846) kd_loss 0.9775 (1.0412) acc 50.0000 (51.3125) lr 1.9921e-03 eta 0:21:14
epoch [4/50] batch [120/319] time 0.081 (0.086) data 0.000 (0.004) loss 2.3622 (2.4118) teacher_loss 1.2498 (1.2752) loss_zs_kd 1.2291 (0.8699) loss_oracle 1.0375 (1.0793) kd_loss 1.0086 (1.0287) acc 56.2500 (51.4323) lr 1.9921e-03 eta 0:21:14
epoch [4/50] batch [140/319] time 0.092 (0.086) data 0.000 (0.003) loss 2.3328 (2.3991) teacher_loss 1.2257 (1.2678) loss_zs_kd 1.3961 (0.9208) loss_oracle 1.1048 (1.0755) kd_loss 0.9967 (1.0238) acc 59.3750 (52.0982) lr 1.9921e-03 eta 0:21:12
epoch [4/50] batch [160/319] time 0.077 (0.086) data 0.000 (0.003) loss 2.5233 (2.3801) teacher_loss 1.4883 (1.2555) loss_zs_kd 1.3152 (0.9659) loss_oracle 1.0242 (1.0758) kd_loss 0.9326 (1.0170) acc 34.3750 (52.3828) lr 1.9921e-03 eta 0:21:09
epoch [4/50] batch [180/319] time 0.082 (0.085) data 0.000 (0.003) loss 2.2536 (2.3673) teacher_loss 1.2068 (1.2476) loss_zs_kd 1.1768 (1.0096) loss_oracle 1.0495 (1.0747) kd_loss 0.9418 (1.0122) acc 59.3750 (52.6389) lr 1.9921e-03 eta 0:21:04
epoch [4/50] batch [200/319] time 0.087 (0.085) data 0.000 (0.003) loss 2.0749 (2.3500) teacher_loss 0.9774 (1.2310) loss_zs_kd 1.4219 (1.0516) loss_oracle 1.0741 (1.0764) kd_loss 0.9900 (1.0113) acc 59.3750 (53.3125) lr 1.9921e-03 eta 0:21:00
epoch [4/50] batch [220/319] time 0.094 (0.085) data 0.000 (0.002) loss 2.1416 (2.3326) teacher_loss 1.0760 (1.2167) loss_zs_kd 1.3437 (1.0746) loss_oracle 1.1385 (1.0803) kd_loss 0.9517 (1.0079) acc 65.6250 (53.9062) lr 1.9921e-03 eta 0:21:01
epoch [4/50] batch [240/319] time 0.087 (0.086) data 0.001 (0.002) loss 2.2316 (2.3229) teacher_loss 1.2135 (1.2093) loss_zs_kd 1.3518 (1.0983) loss_oracle 1.1910 (1.0860) kd_loss 0.8989 (1.0050) acc 59.3750 (54.2708) lr 1.9921e-03 eta 0:21:03
epoch [4/50] batch [260/319] time 0.144 (0.086) data 0.001 (0.002) loss 2.2381 (2.3189) teacher_loss 1.1227 (1.2065) loss_zs_kd 1.3079 (1.1112) loss_oracle 1.1039 (1.0877) kd_loss 1.0051 (1.0036) acc 50.0000 (54.2788) lr 1.9921e-03 eta 0:21:13
epoch [4/50] batch [280/319] time 0.082 (0.087) data 0.000 (0.002) loss 2.1026 (2.3085) teacher_loss 1.0000 (1.1960) loss_zs_kd 1.3011 (1.1208) loss_oracle 1.1238 (1.0897) kd_loss 0.9903 (1.0036) acc 53.1250 (54.8661) lr 1.9921e-03 eta 0:21:13
epoch [4/50] batch [300/319] time 0.083 (0.086) data 0.000 (0.002) loss 1.9922 (2.2966) teacher_loss 0.8681 (1.1844) loss_zs_kd 1.3312 (1.1365) loss_oracle 1.1163 (1.0911) kd_loss 1.0125 (1.0031) acc 75.0000 (55.3125) lr 1.9921e-03 eta 0:21:08
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,234
* accuracy: 51.0%
* error: 49.0%
* macro_f1: 41.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,676
* accuracy: 58.3%
* error: 41.7%
* macro_f1: 23.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      51.0%, epoch: 4 *******
******* Domain 2 best val test acc: 58.3%, epoch: 4 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [5/50] batch [20/319] time 0.075 (0.126) data 0.000 (0.034) loss 2.4301 (2.2075) teacher_loss 1.2093 (1.0541) loss_zs_kd 1.0828 (1.2822) loss_oracle 1.1140 (1.1060) kd_loss 1.1094 (1.0428) acc 53.1250 (57.0312) lr 1.9823e-03 eta 0:30:39
epoch [5/50] batch [40/319] time 0.074 (0.111) data 0.000 (0.017) loss 2.0365 (2.2001) teacher_loss 0.8856 (1.0328) loss_zs_kd 1.2263 (1.3185) loss_oracle 1.1153 (1.1138) kd_loss 1.0394 (1.0559) acc 68.7500 (61.0938) lr 1.9823e-03 eta 0:26:58
epoch [5/50] batch [60/319] time 0.079 (0.100) data 0.001 (0.012) loss 2.0568 (2.2261) teacher_loss 0.8590 (1.0560) loss_zs_kd 1.0580 (1.2465) loss_oracle 1.1563 (1.1165) kd_loss 1.0822 (1.0584) acc 59.3750 (60.9375) lr 1.9823e-03 eta 0:24:23
epoch [5/50] batch [80/319] time 0.085 (0.096) data 0.000 (0.009) loss 1.9013 (2.2189) teacher_loss 0.8137 (1.0514) loss_zs_kd 0.8894 (1.1760) loss_oracle 1.0577 (1.1185) kd_loss 0.9819 (1.0557) acc 71.8750 (61.7578) lr 1.9823e-03 eta 0:23:15
epoch [5/50] batch [100/319] time 0.082 (0.093) data 0.000 (0.007) loss 2.2806 (2.2119) teacher_loss 1.1604 (1.0518) loss_zs_kd 1.1366 (1.1579) loss_oracle 1.0426 (1.1158) kd_loss 1.0159 (1.0484) acc 65.6250 (61.8125) lr 1.9823e-03 eta 0:22:39
epoch [5/50] batch [120/319] time 0.085 (0.092) data 0.000 (0.006) loss 2.2654 (2.2351) teacher_loss 1.1140 (1.0735) loss_zs_kd 1.0749 (1.1524) loss_oracle 1.0566 (1.1154) kd_loss 1.0457 (1.0500) acc 56.2500 (60.3646) lr 1.9823e-03 eta 0:22:13
epoch [5/50] batch [140/319] time 0.082 (0.090) data 0.000 (0.005) loss 2.3380 (2.2376) teacher_loss 1.2170 (1.0761) loss_zs_kd 1.3058 (1.1733) loss_oracle 1.0980 (1.1148) kd_loss 1.0111 (1.0500) acc 53.1250 (59.8884) lr 1.9823e-03 eta 0:21:54
epoch [5/50] batch [160/319] time 0.088 (0.090) data 0.000 (0.005) loss 2.2100 (2.2262) teacher_loss 1.0957 (1.0698) loss_zs_kd 1.2590 (1.2033) loss_oracle 1.0727 (1.1137) kd_loss 1.0070 (1.0450) acc 65.6250 (60.3320) lr 1.9823e-03 eta 0:21:40
epoch [5/50] batch [180/319] time 0.082 (0.089) data 0.000 (0.004) loss 1.8143 (2.2066) teacher_loss 0.6545 (1.0557) loss_zs_kd 1.2102 (1.1954) loss_oracle 1.1193 (1.1131) kd_loss 1.0479 (1.0397) acc 71.8750 (61.1979) lr 1.9823e-03 eta 0:21:29
epoch [5/50] batch [200/319] time 0.084 (0.088) data 0.000 (0.004) loss 2.0420 (2.1939) teacher_loss 0.8634 (1.0466) loss_zs_kd 1.4084 (1.1942) loss_oracle 1.1006 (1.1129) kd_loss 1.0685 (1.0360) acc 65.6250 (61.7969) lr 1.9823e-03 eta 0:21:20
epoch [5/50] batch [220/319] time 0.081 (0.088) data 0.000 (0.003) loss 1.8251 (2.1853) teacher_loss 0.7089 (1.0406) loss_zs_kd 1.1233 (1.2013) loss_oracle 1.1658 (1.1132) kd_loss 0.9996 (1.0334) acc 71.8750 (62.0739) lr 1.9823e-03 eta 0:21:07
epoch [5/50] batch [240/319] time 0.107 (0.088) data 0.000 (0.003) loss 1.8300 (2.1760) teacher_loss 0.7919 (1.0338) loss_zs_kd 1.0673 (1.1954) loss_oracle 1.1291 (1.1149) kd_loss 0.9252 (1.0307) acc 75.0000 (62.4870) lr 1.9823e-03 eta 0:21:05
epoch [5/50] batch [260/319] time 0.080 (0.087) data 0.001 (0.003) loss 2.3774 (2.1745) teacher_loss 1.2566 (1.0344) loss_zs_kd 1.1791 (1.1908) loss_oracle 1.1687 (1.1176) kd_loss 1.0039 (1.0283) acc 50.0000 (62.5721) lr 1.9823e-03 eta 0:20:59
epoch [5/50] batch [280/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.8980 (2.1712) teacher_loss 0.7580 (1.0325) loss_zs_kd 0.8878 (1.1803) loss_oracle 1.1236 (1.1187) kd_loss 1.0276 (1.0268) acc 71.8750 (62.5558) lr 1.9823e-03 eta 0:20:53
epoch [5/50] batch [300/319] time 0.083 (0.087) data 0.000 (0.003) loss 2.2339 (2.1647) teacher_loss 1.1697 (1.0280) loss_zs_kd 1.3723 (1.1846) loss_oracle 1.0982 (1.1193) kd_loss 0.9544 (1.0248) acc 59.3750 (62.7604) lr 1.9823e-03 eta 0:20:49
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,399
* accuracy: 54.8%
* error: 45.2%
* macro_f1: 47.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,486
* accuracy: 56.3%
* error: 43.7%
* macro_f1: 24.8%
******* Domain 2 best val acc:      54.8%, epoch: 5 *******
******* Domain 2 best val test acc: 56.3%, epoch: 5 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [6/50] batch [20/319] time 0.094 (0.117) data 0.000 (0.026) loss 2.2414 (2.0139) teacher_loss 1.1165 (0.9072) loss_zs_kd 1.3838 (1.2664) loss_oracle 1.1724 (1.1484) kd_loss 1.0077 (0.9919) acc 59.3750 (71.4062) lr 1.9686e-03 eta 0:27:52
epoch [6/50] batch [40/319] time 0.081 (0.100) data 0.000 (0.013) loss 2.1491 (1.9861) teacher_loss 1.0442 (0.8798) loss_zs_kd 1.3395 (1.2875) loss_oracle 1.0824 (1.1367) kd_loss 0.9966 (0.9926) acc 68.7500 (70.6250) lr 1.9686e-03 eta 0:23:58
epoch [6/50] batch [60/319] time 0.089 (0.095) data 0.001 (0.009) loss 2.1049 (2.0042) teacher_loss 1.0497 (0.9018) loss_zs_kd 1.3237 (1.3187) loss_oracle 1.0847 (1.1294) kd_loss 0.9467 (0.9895) acc 65.6250 (69.1146) lr 1.9686e-03 eta 0:22:36
epoch [6/50] batch [80/319] time 0.089 (0.092) data 0.000 (0.007) loss 2.1843 (2.0099) teacher_loss 1.0901 (0.9096) loss_zs_kd 1.2411 (1.3047) loss_oracle 1.1499 (1.1269) kd_loss 0.9792 (0.9876) acc 65.6250 (68.6719) lr 1.9686e-03 eta 0:21:56
epoch [6/50] batch [100/319] time 0.095 (0.090) data 0.000 (0.005) loss 1.8616 (2.0206) teacher_loss 0.7822 (0.9208) loss_zs_kd 1.6204 (1.3127) loss_oracle 1.0663 (1.1219) kd_loss 0.9727 (0.9877) acc 75.0000 (68.1562) lr 1.9686e-03 eta 0:21:26
epoch [6/50] batch [120/319] time 0.085 (0.090) data 0.000 (0.005) loss 2.0356 (2.0246) teacher_loss 0.8928 (0.9249) loss_zs_kd 2.0383 (1.3679) loss_oracle 1.1423 (1.1214) kd_loss 1.0286 (0.9876) acc 71.8750 (67.9688) lr 1.9686e-03 eta 0:21:16
epoch [6/50] batch [140/319] time 0.091 (0.089) data 0.000 (0.004) loss 2.1254 (2.0321) teacher_loss 1.1069 (0.9324) loss_zs_kd 1.1871 (1.3748) loss_oracle 1.1560 (1.1208) kd_loss 0.9029 (0.9877) acc 68.7500 (67.6562) lr 1.9686e-03 eta 0:20:58
epoch [6/50] batch [160/319] time 0.079 (0.088) data 0.000 (0.004) loss 2.2004 (2.0354) teacher_loss 1.0757 (0.9357) loss_zs_kd 1.2472 (1.3753) loss_oracle 1.2203 (1.1251) kd_loss 1.0026 (0.9872) acc 68.7500 (67.4219) lr 1.9686e-03 eta 0:20:50
epoch [6/50] batch [180/319] time 0.087 (0.088) data 0.000 (0.003) loss 2.2037 (2.0430) teacher_loss 1.1356 (0.9440) loss_zs_kd 1.5016 (1.3863) loss_oracle 1.1887 (1.1293) kd_loss 0.9493 (0.9861) acc 56.2500 (67.2917) lr 1.9686e-03 eta 0:20:44
epoch [6/50] batch [200/319] time 0.133 (0.089) data 0.000 (0.003) loss 2.2953 (2.0522) teacher_loss 1.1505 (0.9521) loss_zs_kd 1.1609 (1.3800) loss_oracle 1.1816 (1.1327) kd_loss 1.0266 (0.9868) acc 62.5000 (66.9688) lr 1.9686e-03 eta 0:20:57
epoch [6/50] batch [220/319] time 0.081 (0.088) data 0.000 (0.003) loss 2.1269 (2.0474) teacher_loss 1.0484 (0.9477) loss_zs_kd 1.5031 (1.4035) loss_oracle 1.0340 (1.1319) kd_loss 0.9751 (0.9865) acc 65.6250 (66.9886) lr 1.9686e-03 eta 0:20:45
epoch [6/50] batch [240/319] time 0.086 (0.088) data 0.000 (0.002) loss 2.2812 (2.0445) teacher_loss 1.2106 (0.9462) loss_zs_kd 1.7401 (1.4381) loss_oracle 1.0473 (1.1279) kd_loss 0.9659 (0.9855) acc 59.3750 (67.0312) lr 1.9686e-03 eta 0:20:39
epoch [6/50] batch [260/319] time 0.088 (0.088) data 0.000 (0.002) loss 1.8957 (2.0372) teacher_loss 0.8199 (0.9414) loss_zs_kd 1.9383 (1.4744) loss_oracle 1.1708 (1.1258) kd_loss 0.9587 (0.9832) acc 65.6250 (67.1274) lr 1.9686e-03 eta 0:20:33
epoch [6/50] batch [280/319] time 0.086 (0.088) data 0.000 (0.002) loss 1.9653 (2.0331) teacher_loss 0.9085 (0.9382) loss_zs_kd 1.4763 (1.4899) loss_oracle 1.1656 (1.1264) kd_loss 0.9403 (0.9823) acc 56.2500 (67.1094) lr 1.9686e-03 eta 0:20:33
epoch [6/50] batch [300/319] time 0.086 (0.087) data 0.000 (0.002) loss 1.7859 (2.0285) teacher_loss 0.6797 (0.9342) loss_zs_kd 1.6101 (1.4840) loss_oracle 1.2032 (1.1291) kd_loss 0.9859 (0.9813) acc 78.1250 (67.1979) lr 1.9686e-03 eta 0:20:29
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,601
* accuracy: 59.4%
* error: 40.6%
* macro_f1: 50.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,398
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 25.8%
******* Domain 2 best val acc:      59.4%, epoch: 6 *******
******* Domain 2 best val test acc: 55.4%, epoch: 6 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [7/50] batch [20/319] time 0.076 (0.109) data 0.000 (0.034) loss 1.6537 (1.9695) teacher_loss 0.6320 (0.9018) loss_zs_kd 1.5234 (1.5141) loss_oracle 1.2039 (1.1217) kd_loss 0.9013 (0.9555) acc 75.0000 (68.5938) lr 1.9511e-03 eta 0:25:28
epoch [7/50] batch [40/319] time 0.068 (0.092) data 0.000 (0.017) loss 2.2535 (1.9822) teacher_loss 1.1365 (0.9120) loss_zs_kd 1.6870 (1.5114) loss_oracle 1.1940 (1.1322) kd_loss 0.9976 (0.9570) acc 59.3750 (67.2656) lr 1.9511e-03 eta 0:21:32
epoch [7/50] batch [60/319] time 0.077 (0.087) data 0.000 (0.012) loss 1.8305 (1.9565) teacher_loss 0.7822 (0.8862) loss_zs_kd 1.5121 (1.5207) loss_oracle 1.1025 (1.1302) kd_loss 0.9381 (0.9573) acc 75.0000 (68.2812) lr 1.9511e-03 eta 0:20:22
epoch [7/50] batch [80/319] time 0.078 (0.086) data 0.000 (0.009) loss 2.0318 (1.9547) teacher_loss 0.9676 (0.8817) loss_zs_kd 1.5287 (1.5329) loss_oracle 1.1774 (1.1357) kd_loss 0.9465 (0.9595) acc 71.8750 (68.7891) lr 1.9511e-03 eta 0:19:56
epoch [7/50] batch [100/319] time 0.079 (0.085) data 0.000 (0.007) loss 2.0436 (1.9700) teacher_loss 0.9767 (0.8956) loss_zs_kd 1.3298 (1.5097) loss_oracle 1.1070 (1.1424) kd_loss 0.9561 (0.9601) acc 62.5000 (68.2188) lr 1.9511e-03 eta 0:19:43
epoch [7/50] batch [120/319] time 0.086 (0.084) data 0.000 (0.006) loss 2.4559 (1.9661) teacher_loss 1.3506 (0.8913) loss_zs_kd 1.6862 (1.5128) loss_oracle 1.1806 (1.1467) kd_loss 0.9873 (0.9602) acc 53.1250 (68.3333) lr 1.9511e-03 eta 0:19:32
epoch [7/50] batch [140/319] time 0.089 (0.084) data 0.000 (0.005) loss 2.0246 (1.9765) teacher_loss 0.9083 (0.9013) loss_zs_kd 1.6100 (1.5101) loss_oracle 1.1725 (1.1457) kd_loss 0.9990 (0.9606) acc 68.7500 (68.0804) lr 1.9511e-03 eta 0:19:30
epoch [7/50] batch [160/319] time 0.073 (0.084) data 0.000 (0.005) loss 1.8788 (1.9891) teacher_loss 0.7109 (0.9128) loss_zs_kd 1.4977 (1.5110) loss_oracle 1.1986 (1.1456) kd_loss 1.0480 (0.9617) acc 71.8750 (67.3828) lr 1.9511e-03 eta 0:19:24
epoch [7/50] batch [180/319] time 0.085 (0.084) data 0.000 (0.004) loss 2.0113 (1.9894) teacher_loss 0.9312 (0.9133) loss_zs_kd 1.6191 (1.5151) loss_oracle 1.1701 (1.1491) kd_loss 0.9631 (0.9611) acc 71.8750 (67.4132) lr 1.9511e-03 eta 0:19:23
epoch [7/50] batch [200/319] time 0.086 (0.084) data 0.001 (0.004) loss 2.3983 (1.9910) teacher_loss 1.2726 (0.9121) loss_zs_kd 1.5160 (1.5042) loss_oracle 1.1764 (1.1539) kd_loss 1.0081 (0.9635) acc 53.1250 (67.3125) lr 1.9511e-03 eta 0:19:20
epoch [7/50] batch [220/319] time 0.085 (0.084) data 0.000 (0.003) loss 2.0868 (1.9909) teacher_loss 0.9988 (0.9087) loss_zs_kd 1.3584 (1.4858) loss_oracle 1.1847 (1.1566) kd_loss 0.9695 (0.9666) acc 68.7500 (67.4716) lr 1.9511e-03 eta 0:19:18
epoch [7/50] batch [240/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.8276 (1.9928) teacher_loss 0.7819 (0.9082) loss_zs_kd 1.4496 (1.4742) loss_oracle 1.1131 (1.1592) kd_loss 0.9344 (0.9687) acc 71.8750 (67.4349) lr 1.9511e-03 eta 0:19:12
epoch [7/50] batch [260/319] time 0.086 (0.084) data 0.000 (0.003) loss 1.8926 (1.9947) teacher_loss 0.7361 (0.9093) loss_zs_kd 1.3763 (1.4722) loss_oracle 1.1169 (1.1589) kd_loss 1.0448 (0.9695) acc 75.0000 (67.3918) lr 1.9511e-03 eta 0:19:10
epoch [7/50] batch [280/319] time 0.066 (0.083) data 0.000 (0.003) loss 1.8120 (1.9959) teacher_loss 0.7589 (0.9113) loss_zs_kd 1.5135 (1.4677) loss_oracle 1.1518 (1.1571) kd_loss 0.9380 (0.9689) acc 78.1250 (67.4888) lr 1.9511e-03 eta 0:19:02
epoch [7/50] batch [300/319] time 0.064 (0.082) data 0.000 (0.003) loss 2.0487 (1.9941) teacher_loss 1.0033 (0.9094) loss_zs_kd 1.4789 (1.4618) loss_oracle 1.1562 (1.1570) kd_loss 0.9298 (0.9690) acc 50.0000 (67.5312) lr 1.9511e-03 eta 0:18:42
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,469
* accuracy: 56.4%
* error: 43.6%
* macro_f1: 50.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,420
* accuracy: 55.7%
* error: 44.3%
* macro_f1: 22.4%
******* Domain 2 best val acc:      59.4%, epoch: 6 *******
******* Domain 2 best val test acc: 55.4%, epoch: 6 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [8/50] batch [20/319] time 0.075 (0.103) data 0.000 (0.027) loss 2.4812 (2.1365) teacher_loss 1.3250 (1.0376) loss_zs_kd 1.4031 (1.4013) loss_oracle 1.1532 (1.1589) kd_loss 1.0409 (0.9831) acc 50.0000 (61.4062) lr 1.9298e-03 eta 0:23:36
epoch [8/50] batch [40/319] time 0.065 (0.090) data 0.000 (0.014) loss 1.7250 (2.0530) teacher_loss 0.7136 (0.9469) loss_zs_kd 1.4489 (1.4047) loss_oracle 1.1532 (1.1511) kd_loss 0.8961 (0.9910) acc 75.0000 (64.7656) lr 1.9298e-03 eta 0:20:24
epoch [8/50] batch [60/319] time 0.088 (0.088) data 0.001 (0.009) loss 1.9721 (2.0133) teacher_loss 0.9028 (0.9213) loss_zs_kd 1.4355 (1.4076) loss_oracle 1.1184 (1.1543) kd_loss 0.9575 (0.9766) acc 71.8750 (66.6667) lr 1.9298e-03 eta 0:19:57
epoch [8/50] batch [80/319] time 0.093 (0.087) data 0.000 (0.007) loss 1.9047 (1.9872) teacher_loss 0.8423 (0.8996) loss_zs_kd 1.1299 (1.3957) loss_oracle 1.1733 (1.1562) kd_loss 0.9451 (0.9720) acc 68.7500 (67.6172) lr 1.9298e-03 eta 0:19:51
epoch [8/50] batch [100/319] time 0.074 (0.086) data 0.000 (0.006) loss 1.9413 (2.0000) teacher_loss 0.8020 (0.9138) loss_zs_kd 1.4185 (1.3829) loss_oracle 1.2834 (1.1680) kd_loss 1.0110 (0.9694) acc 68.7500 (67.5312) lr 1.9298e-03 eta 0:19:32
epoch [8/50] batch [120/319] time 0.082 (0.085) data 0.000 (0.005) loss 2.0576 (1.9872) teacher_loss 0.9729 (0.8964) loss_zs_kd 1.6419 (1.3854) loss_oracle 1.1707 (1.1767) kd_loss 0.9676 (0.9731) acc 68.7500 (68.2812) lr 1.9298e-03 eta 0:19:20
epoch [8/50] batch [140/319] time 0.077 (0.084) data 0.000 (0.004) loss 1.9479 (1.9880) teacher_loss 0.8136 (0.8980) loss_zs_kd 1.6924 (1.3845) loss_oracle 1.2460 (1.1794) kd_loss 1.0097 (0.9720) acc 68.7500 (67.8348) lr 1.9298e-03 eta 0:18:57
epoch [8/50] batch [160/319] time 0.081 (0.084) data 0.000 (0.004) loss 2.2573 (1.9885) teacher_loss 1.1314 (0.8989) loss_zs_kd 1.2873 (1.3985) loss_oracle 1.2107 (1.1800) kd_loss 1.0048 (0.9716) acc 59.3750 (68.0273) lr 1.9298e-03 eta 0:18:54
epoch [8/50] batch [180/319] time 0.077 (0.085) data 0.000 (0.003) loss 2.1353 (1.9928) teacher_loss 1.0678 (0.9032) loss_zs_kd 1.3842 (1.4080) loss_oracle 1.2616 (1.1847) kd_loss 0.9414 (0.9712) acc 65.6250 (68.1771) lr 1.9298e-03 eta 0:19:09
epoch [8/50] batch [200/319] time 0.100 (0.085) data 0.000 (0.003) loss 1.9524 (1.9869) teacher_loss 0.8909 (0.8984) loss_zs_kd 1.5490 (1.4031) loss_oracle 1.1620 (1.1850) kd_loss 0.9453 (0.9700) acc 62.5000 (68.0781) lr 1.9298e-03 eta 0:19:03
epoch [8/50] batch [220/319] time 0.084 (0.085) data 0.000 (0.003) loss 1.5676 (1.9855) teacher_loss 0.4682 (0.8961) loss_zs_kd 1.5065 (1.4030) loss_oracle 1.1626 (1.1863) kd_loss 0.9832 (0.9708) acc 87.5000 (68.2955) lr 1.9298e-03 eta 0:19:01
epoch [8/50] batch [240/319] time 0.084 (0.085) data 0.000 (0.003) loss 2.0369 (1.9866) teacher_loss 0.9499 (0.8952) loss_zs_kd 1.3418 (1.4186) loss_oracle 1.1985 (1.1874) kd_loss 0.9672 (0.9727) acc 68.7500 (68.3073) lr 1.9298e-03 eta 0:19:00
epoch [8/50] batch [260/319] time 0.082 (0.085) data 0.000 (0.002) loss 2.2905 (1.9907) teacher_loss 1.1826 (0.8977) loss_zs_kd 1.5888 (1.4379) loss_oracle 1.1287 (1.1870) kd_loss 0.9951 (0.9743) acc 59.3750 (68.1490) lr 1.9298e-03 eta 0:18:58
epoch [8/50] batch [280/319] time 0.093 (0.085) data 0.000 (0.002) loss 2.0893 (1.9854) teacher_loss 1.0129 (0.8924) loss_zs_kd 1.4804 (1.4434) loss_oracle 1.1767 (1.1867) kd_loss 0.9587 (0.9743) acc 65.6250 (68.1920) lr 1.9298e-03 eta 0:18:55
epoch [8/50] batch [300/319] time 0.089 (0.084) data 0.000 (0.002) loss 2.1467 (1.9869) teacher_loss 1.0947 (0.8958) loss_zs_kd 1.1795 (1.4437) loss_oracle 1.2603 (1.1873) kd_loss 0.9260 (0.9724) acc 53.1250 (68.0104) lr 1.9298e-03 eta 0:18:53
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,439
* accuracy: 55.7%
* error: 44.3%
* macro_f1: 47.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,623
* accuracy: 57.8%
* error: 42.2%
* macro_f1: 25.0%
******* Domain 2 best val acc:      59.4%, epoch: 6 *******
******* Domain 2 best val test acc: 55.4%, epoch: 6 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [9/50] batch [20/319] time 0.079 (0.116) data 0.000 (0.030) loss 1.7459 (1.8955) teacher_loss 0.5923 (0.8008) loss_zs_kd 1.5811 (1.3950) loss_oracle 1.2800 (1.2213) kd_loss 1.0255 (0.9725) acc 78.1250 (70.6250) lr 1.9048e-03 eta 0:25:46
epoch [9/50] batch [40/319] time 0.084 (0.099) data 0.000 (0.015) loss 1.7821 (1.9122) teacher_loss 0.7493 (0.8166) loss_zs_kd 1.4363 (1.4019) loss_oracle 1.2098 (1.2065) kd_loss 0.9119 (0.9750) acc 75.0000 (71.6406) lr 1.9048e-03 eta 0:22:06
epoch [9/50] batch [60/319] time 0.080 (0.094) data 0.000 (0.010) loss 2.1427 (1.9458) teacher_loss 1.0993 (0.8550) loss_zs_kd 1.3818 (1.3737) loss_oracle 1.2150 (1.2065) kd_loss 0.9219 (0.9702) acc 46.8750 (70.4167) lr 1.9048e-03 eta 0:21:00
epoch [9/50] batch [80/319] time 0.083 (0.092) data 0.000 (0.008) loss 1.8059 (1.9526) teacher_loss 0.7350 (0.8674) loss_zs_kd 1.3173 (1.3956) loss_oracle 1.2003 (1.2054) kd_loss 0.9509 (0.9647) acc 65.6250 (70.1953) lr 1.9048e-03 eta 0:20:23
epoch [9/50] batch [100/319] time 0.080 (0.090) data 0.000 (0.006) loss 2.3518 (1.9632) teacher_loss 1.3016 (0.8773) loss_zs_kd 1.2378 (1.3606) loss_oracle 1.1969 (1.2064) kd_loss 0.9305 (0.9653) acc 62.5000 (69.4375) lr 1.9048e-03 eta 0:20:02
epoch [9/50] batch [120/319] time 0.080 (0.090) data 0.000 (0.005) loss 2.1948 (1.9878) teacher_loss 1.0625 (0.9009) loss_zs_kd 1.1622 (1.3376) loss_oracle 1.1740 (1.2056) kd_loss 1.0148 (0.9663) acc 65.6250 (68.3333) lr 1.9048e-03 eta 0:19:49
epoch [9/50] batch [140/319] time 0.082 (0.089) data 0.000 (0.005) loss 2.3851 (1.9992) teacher_loss 1.3666 (0.9137) loss_zs_kd 1.4237 (1.3385) loss_oracle 1.1865 (1.2038) kd_loss 0.8998 (0.9651) acc 43.7500 (67.8125) lr 1.9048e-03 eta 0:19:37
epoch [9/50] batch [160/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.8802 (1.9945) teacher_loss 0.7503 (0.9085) loss_zs_kd 1.7326 (1.3702) loss_oracle 1.2520 (1.1996) kd_loss 1.0047 (0.9661) acc 75.0000 (68.1836) lr 1.9048e-03 eta 0:19:25
epoch [9/50] batch [180/319] time 0.085 (0.088) data 0.000 (0.004) loss 1.8702 (1.9883) teacher_loss 0.7578 (0.9000) loss_zs_kd 1.7585 (1.3983) loss_oracle 1.1675 (1.1964) kd_loss 0.9957 (0.9686) acc 65.6250 (68.4375) lr 1.9048e-03 eta 0:19:17
epoch [9/50] batch [200/319] time 0.082 (0.087) data 0.000 (0.003) loss 2.2666 (1.9886) teacher_loss 1.0447 (0.8996) loss_zs_kd 1.4827 (1.4108) loss_oracle 1.1869 (1.1933) kd_loss 1.1032 (0.9696) acc 56.2500 (68.5938) lr 1.9048e-03 eta 0:19:12
epoch [9/50] batch [220/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.8660 (1.9900) teacher_loss 0.7813 (0.8987) loss_zs_kd 1.3482 (1.4189) loss_oracle 1.1578 (1.1940) kd_loss 0.9689 (0.9719) acc 65.6250 (68.2955) lr 1.9048e-03 eta 0:19:03
epoch [9/50] batch [240/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.9177 (1.9921) teacher_loss 0.8382 (0.8994) loss_zs_kd 1.6292 (1.4178) loss_oracle 1.2159 (1.1959) kd_loss 0.9580 (0.9731) acc 68.7500 (68.2682) lr 1.9048e-03 eta 0:18:58
epoch [9/50] batch [260/319] time 0.090 (0.086) data 0.000 (0.003) loss 2.1229 (1.9877) teacher_loss 1.1162 (0.8957) loss_zs_kd 1.2937 (1.4160) loss_oracle 1.1643 (1.1969) kd_loss 0.8903 (0.9723) acc 53.1250 (68.2572) lr 1.9048e-03 eta 0:18:54
epoch [9/50] batch [280/319] time 0.083 (0.086) data 0.000 (0.002) loss 1.6877 (1.9923) teacher_loss 0.6708 (0.9009) loss_zs_kd 1.4652 (1.4141) loss_oracle 1.1828 (1.1983) kd_loss 0.8986 (0.9715) acc 87.5000 (67.9911) lr 1.9048e-03 eta 0:18:51
epoch [9/50] batch [300/319] time 0.083 (0.086) data 0.000 (0.002) loss 2.3838 (1.9965) teacher_loss 1.2549 (0.9059) loss_zs_kd 1.4561 (1.4170) loss_oracle 1.1731 (1.1981) kd_loss 1.0117 (0.9708) acc 56.2500 (67.6979) lr 1.9048e-03 eta 0:18:46
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,619
* accuracy: 59.8%
* error: 40.2%
* macro_f1: 48.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,259
* accuracy: 54.0%
* error: 46.0%
* macro_f1: 23.1%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [10/50] batch [20/319] time 0.082 (0.122) data 0.000 (0.034) loss 2.1620 (2.0285) teacher_loss 1.0847 (0.9222) loss_zs_kd 1.6236 (1.3148) loss_oracle 1.1851 (1.1900) kd_loss 0.9589 (0.9873) acc 53.1250 (66.2500) lr 1.8763e-03 eta 0:26:30
epoch [10/50] batch [40/319] time 0.075 (0.102) data 0.000 (0.017) loss 2.0219 (2.0047) teacher_loss 0.8796 (0.8934) loss_zs_kd 1.3152 (1.4333) loss_oracle 1.1514 (1.1793) kd_loss 1.0271 (0.9934) acc 62.5000 (67.1875) lr 1.8763e-03 eta 0:22:09
epoch [10/50] batch [60/319] time 0.076 (0.095) data 0.000 (0.011) loss 2.1058 (1.9903) teacher_loss 0.9770 (0.8895) loss_zs_kd 1.6280 (1.4650) loss_oracle 1.2032 (1.1768) kd_loss 1.0085 (0.9831) acc 65.6250 (67.5521) lr 1.8763e-03 eta 0:20:34
epoch [10/50] batch [80/319] time 0.087 (0.091) data 0.000 (0.009) loss 1.6045 (1.9881) teacher_loss 0.5850 (0.8931) loss_zs_kd 1.4459 (1.4827) loss_oracle 1.1432 (1.1812) kd_loss 0.9052 (0.9769) acc 87.5000 (67.6562) lr 1.8763e-03 eta 0:19:45
epoch [10/50] batch [100/319] time 0.079 (0.090) data 0.000 (0.007) loss 1.7185 (1.9801) teacher_loss 0.6307 (0.8870) loss_zs_kd 1.6630 (1.5034) loss_oracle 1.2390 (1.1881) kd_loss 0.9639 (0.9743) acc 71.8750 (67.5625) lr 1.8763e-03 eta 0:19:33
epoch [10/50] batch [120/319] time 0.087 (0.088) data 0.000 (0.006) loss 1.9745 (1.9764) teacher_loss 0.8850 (0.8878) loss_zs_kd 1.4492 (1.5183) loss_oracle 1.1834 (1.1883) kd_loss 0.9712 (0.9698) acc 62.5000 (67.3438) lr 1.8763e-03 eta 0:19:03
epoch [10/50] batch [140/319] time 0.078 (0.089) data 0.000 (0.005) loss 1.7578 (1.9710) teacher_loss 0.7294 (0.8825) loss_zs_kd 1.4240 (1.5087) loss_oracle 1.2752 (1.1903) kd_loss 0.9009 (0.9695) acc 75.0000 (67.8125) lr 1.8763e-03 eta 0:19:10
epoch [10/50] batch [160/319] time 0.088 (0.088) data 0.000 (0.004) loss 1.9877 (1.9663) teacher_loss 0.9147 (0.8792) loss_zs_kd 1.6655 (1.5083) loss_oracle 1.2334 (1.1934) kd_loss 0.9496 (0.9678) acc 65.6250 (68.1836) lr 1.8763e-03 eta 0:19:00
epoch [10/50] batch [180/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.9279 (1.9720) teacher_loss 0.8952 (0.8889) loss_zs_kd 1.5590 (1.5154) loss_oracle 1.1410 (1.1897) kd_loss 0.9186 (0.9641) acc 62.5000 (68.2465) lr 1.8763e-03 eta 0:18:51
epoch [10/50] batch [200/319] time 0.084 (0.087) data 0.000 (0.004) loss 1.6666 (1.9609) teacher_loss 0.5826 (0.8798) loss_zs_kd 1.6733 (1.5196) loss_oracle 1.2145 (1.1905) kd_loss 0.9625 (0.9621) acc 84.3750 (68.6094) lr 1.8763e-03 eta 0:18:45
epoch [10/50] batch [220/319] time 0.086 (0.087) data 0.000 (0.003) loss 1.6543 (1.9514) teacher_loss 0.5754 (0.8728) loss_zs_kd 1.7245 (1.5386) loss_oracle 1.2400 (1.1894) kd_loss 0.9549 (0.9596) acc 71.8750 (69.0767) lr 1.8763e-03 eta 0:18:36
epoch [10/50] batch [240/319] time 0.088 (0.087) data 0.000 (0.003) loss 2.0956 (1.9544) teacher_loss 0.9840 (0.8771) loss_zs_kd 1.6683 (1.5436) loss_oracle 1.2273 (1.1904) kd_loss 0.9889 (0.9583) acc 65.6250 (68.8542) lr 1.8763e-03 eta 0:18:32
epoch [10/50] batch [260/319] time 0.077 (0.086) data 0.000 (0.003) loss 1.9710 (1.9542) teacher_loss 0.8842 (0.8772) loss_zs_kd 1.7609 (1.5449) loss_oracle 1.1830 (1.1903) kd_loss 0.9685 (0.9580) acc 68.7500 (68.8582) lr 1.8763e-03 eta 0:18:27
epoch [10/50] batch [280/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.7927 (1.9470) teacher_loss 0.6914 (0.8701) loss_zs_kd 1.7186 (1.5498) loss_oracle 1.2680 (1.1913) kd_loss 0.9745 (0.9578) acc 71.8750 (69.0960) lr 1.8763e-03 eta 0:18:25
epoch [10/50] batch [300/319] time 0.083 (0.086) data 0.000 (0.003) loss 2.0094 (1.9465) teacher_loss 0.9886 (0.8701) loss_zs_kd 1.4553 (1.5493) loss_oracle 1.1964 (1.1912) kd_loss 0.9011 (0.9573) acc 59.3750 (69.2396) lr 1.8763e-03 eta 0:18:21
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,485
* accuracy: 56.8%
* error: 43.2%
* macro_f1: 50.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,649
* accuracy: 58.0%
* error: 42.0%
* macro_f1: 25.5%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [11/50] batch [20/319] time 0.086 (0.118) data 0.000 (0.030) loss 1.8748 (1.8566) teacher_loss 0.8605 (0.8081) loss_zs_kd 1.5918 (1.3970) loss_oracle 1.1524 (1.1719) kd_loss 0.8990 (0.9313) acc 68.7500 (70.3125) lr 1.8443e-03 eta 0:25:02
epoch [11/50] batch [40/319] time 0.083 (0.101) data 0.000 (0.015) loss 1.6045 (1.8609) teacher_loss 0.5700 (0.8071) loss_zs_kd 1.4246 (1.5049) loss_oracle 1.1261 (1.1567) kd_loss 0.9219 (0.9381) acc 81.2500 (72.2656) lr 1.8443e-03 eta 0:21:24
epoch [11/50] batch [60/319] time 0.083 (0.097) data 0.001 (0.010) loss 1.9444 (1.8688) teacher_loss 0.9107 (0.8140) loss_zs_kd 1.6891 (1.5455) loss_oracle 1.1690 (1.1508) kd_loss 0.9168 (0.9398) acc 84.3750 (71.7708) lr 1.8443e-03 eta 0:20:26
epoch [11/50] batch [80/319] time 0.084 (0.093) data 0.000 (0.008) loss 2.1382 (1.8789) teacher_loss 1.1066 (0.8206) loss_zs_kd 1.6029 (1.5565) loss_oracle 1.2541 (1.1648) kd_loss 0.9062 (0.9419) acc 56.2500 (71.6797) lr 1.8443e-03 eta 0:19:39
epoch [11/50] batch [100/319] time 0.084 (0.091) data 0.000 (0.006) loss 1.9280 (1.8962) teacher_loss 0.8510 (0.8354) loss_zs_kd 1.4261 (1.5498) loss_oracle 1.1890 (1.1708) kd_loss 0.9581 (0.9437) acc 81.2500 (71.0938) lr 1.8443e-03 eta 0:19:14
epoch [11/50] batch [120/319] time 0.080 (0.089) data 0.000 (0.005) loss 1.9294 (1.8973) teacher_loss 0.9104 (0.8391) loss_zs_kd 1.6942 (1.5531) loss_oracle 1.1663 (1.1717) kd_loss 0.9024 (0.9410) acc 62.5000 (70.6771) lr 1.8443e-03 eta 0:18:50
epoch [11/50] batch [140/319] time 0.070 (0.087) data 0.000 (0.005) loss 2.4431 (1.9103) teacher_loss 1.4163 (0.8545) loss_zs_kd 1.5904 (1.5574) loss_oracle 1.2702 (1.1683) kd_loss 0.8998 (0.9389) acc 50.0000 (70.3125) lr 1.8443e-03 eta 0:18:23
epoch [11/50] batch [160/319] time 0.060 (0.084) data 0.000 (0.004) loss 1.5673 (1.9231) teacher_loss 0.5123 (0.8689) loss_zs_kd 1.6864 (1.5517) loss_oracle 1.1215 (1.1705) kd_loss 0.9429 (0.9372) acc 84.3750 (69.5508) lr 1.8443e-03 eta 0:17:42
epoch [11/50] batch [180/319] time 0.067 (0.082) data 0.000 (0.004) loss 2.0965 (1.9240) teacher_loss 1.0807 (0.8713) loss_zs_kd 1.3500 (1.5490) loss_oracle 1.1806 (1.1707) kd_loss 0.8977 (0.9357) acc 62.5000 (69.5139) lr 1.8443e-03 eta 0:17:10
epoch [11/50] batch [200/319] time 0.055 (0.080) data 0.000 (0.003) loss 1.9346 (1.9219) teacher_loss 0.9286 (0.8718) loss_zs_kd 1.4483 (1.5473) loss_oracle 1.1423 (1.1670) kd_loss 0.8918 (0.9334) acc 71.8750 (69.3438) lr 1.8443e-03 eta 0:16:43
epoch [11/50] batch [220/319] time 0.064 (0.078) data 0.000 (0.003) loss 2.0123 (1.9152) teacher_loss 1.0058 (0.8666) loss_zs_kd 1.4934 (1.5252) loss_oracle 1.0983 (1.1662) kd_loss 0.8966 (0.9320) acc 65.6250 (69.4602) lr 1.8443e-03 eta 0:16:21
epoch [11/50] batch [240/319] time 0.068 (0.077) data 0.000 (0.003) loss 1.8486 (1.9129) teacher_loss 0.7478 (0.8638) loss_zs_kd 1.4611 (1.5159) loss_oracle 1.2402 (1.1662) kd_loss 0.9768 (0.9325) acc 81.2500 (69.7135) lr 1.8443e-03 eta 0:16:01
epoch [11/50] batch [260/319] time 0.060 (0.076) data 0.000 (0.003) loss 1.7194 (1.9105) teacher_loss 0.7115 (0.8623) loss_zs_kd 1.8356 (1.5160) loss_oracle 1.0296 (1.1672) kd_loss 0.9049 (0.9315) acc 68.7500 (69.6875) lr 1.8443e-03 eta 0:15:45
epoch [11/50] batch [280/319] time 0.075 (0.075) data 0.000 (0.002) loss 2.1862 (1.9066) teacher_loss 1.1455 (0.8596) loss_zs_kd 1.2496 (1.5173) loss_oracle 1.2021 (1.1672) kd_loss 0.9205 (0.9303) acc 56.2500 (69.6987) lr 1.8443e-03 eta 0:15:32
epoch [11/50] batch [300/319] time 0.067 (0.074) data 0.000 (0.002) loss 2.4901 (1.9103) teacher_loss 1.4376 (0.8644) loss_zs_kd 1.3600 (1.5046) loss_oracle 1.1381 (1.1678) kd_loss 0.9387 (0.9291) acc 43.7500 (69.5417) lr 1.8443e-03 eta 0:15:22
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,474
* accuracy: 56.5%
* error: 43.5%
* macro_f1: 48.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,441
* accuracy: 55.9%
* error: 44.1%
* macro_f1: 24.2%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [12/50] batch [20/319] time 0.079 (0.117) data 0.000 (0.034) loss 1.9087 (1.8440) teacher_loss 0.8858 (0.8106) loss_zs_kd 1.5500 (1.6696) loss_oracle 1.1946 (1.1786) kd_loss 0.9035 (0.9156) acc 71.8750 (72.3438) lr 1.8090e-03 eta 0:24:15
epoch [12/50] batch [40/319] time 0.080 (0.099) data 0.000 (0.017) loss 1.6381 (1.8754) teacher_loss 0.5925 (0.8503) loss_zs_kd 1.6936 (1.6568) loss_oracle 1.1589 (1.1690) kd_loss 0.9298 (0.9082) acc 78.1250 (69.9219) lr 1.8090e-03 eta 0:20:30
epoch [12/50] batch [60/319] time 0.080 (0.093) data 0.000 (0.012) loss 1.8369 (1.8872) teacher_loss 0.8819 (0.8625) loss_zs_kd 1.6174 (1.6744) loss_oracle 1.0023 (1.1703) kd_loss 0.8548 (0.9077) acc 71.8750 (69.7396) lr 1.8090e-03 eta 0:19:15
epoch [12/50] batch [80/319] time 0.081 (0.091) data 0.000 (0.009) loss 1.8968 (1.8791) teacher_loss 0.8905 (0.8529) loss_zs_kd 1.3947 (1.6738) loss_oracle 1.1747 (1.1748) kd_loss 0.8889 (0.9087) acc 68.7500 (70.0000) lr 1.8090e-03 eta 0:18:45
epoch [12/50] batch [100/319] time 0.083 (0.090) data 0.000 (0.007) loss 1.8823 (1.8915) teacher_loss 0.8270 (0.8632) loss_zs_kd 1.8553 (1.6425) loss_oracle 1.1958 (1.1783) kd_loss 0.9358 (0.9105) acc 71.8750 (69.5938) lr 1.8090e-03 eta 0:18:25
epoch [12/50] batch [120/319] time 0.083 (0.089) data 0.000 (0.006) loss 1.8975 (1.9015) teacher_loss 0.7827 (0.8712) loss_zs_kd 1.6706 (1.6403) loss_oracle 1.1416 (1.1777) kd_loss 1.0006 (0.9125) acc 68.7500 (69.2708) lr 1.8090e-03 eta 0:18:11
epoch [12/50] batch [140/319] time 0.105 (0.090) data 0.001 (0.005) loss 1.8444 (1.8941) teacher_loss 0.8459 (0.8587) loss_zs_kd 1.5635 (1.6407) loss_oracle 1.2233 (1.1873) kd_loss 0.8762 (0.9166) acc 78.1250 (69.8214) lr 1.8090e-03 eta 0:18:30
epoch [12/50] batch [160/319] time 0.083 (0.089) data 0.000 (0.005) loss 1.9659 (1.8879) teacher_loss 0.8970 (0.8509) loss_zs_kd 1.8948 (1.6374) loss_oracle 1.1880 (1.1893) kd_loss 0.9501 (0.9181) acc 65.6250 (70.3320) lr 1.8090e-03 eta 0:18:17
epoch [12/50] batch [180/319] time 0.081 (0.089) data 0.000 (0.004) loss 1.8543 (1.8813) teacher_loss 0.8128 (0.8422) loss_zs_kd 1.4108 (1.6425) loss_oracle 1.1696 (1.1971) kd_loss 0.9245 (0.9194) acc 75.0000 (70.8160) lr 1.8090e-03 eta 0:18:07
epoch [12/50] batch [200/319] time 0.071 (0.088) data 0.000 (0.004) loss 1.8564 (1.8805) teacher_loss 0.8539 (0.8394) loss_zs_kd 1.4108 (1.6270) loss_oracle 1.2586 (1.1965) kd_loss 0.8766 (0.9215) acc 65.6250 (70.7656) lr 1.8090e-03 eta 0:17:58
epoch [12/50] batch [220/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.9450 (1.8746) teacher_loss 0.8560 (0.8321) loss_zs_kd 1.3845 (1.6139) loss_oracle 1.1497 (1.2001) kd_loss 0.9740 (0.9225) acc 75.0000 (71.1222) lr 1.8090e-03 eta 0:17:38
epoch [12/50] batch [240/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.9695 (1.8783) teacher_loss 0.8327 (0.8319) loss_zs_kd 1.6820 (1.6112) loss_oracle 1.2126 (1.2031) kd_loss 1.0155 (0.9260) acc 71.8750 (71.1198) lr 1.8090e-03 eta 0:17:34
epoch [12/50] batch [260/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.6942 (1.8755) teacher_loss 0.7032 (0.8289) loss_zs_kd 1.4560 (1.6040) loss_oracle 1.1757 (1.2021) kd_loss 0.8735 (0.9264) acc 71.8750 (71.2139) lr 1.8090e-03 eta 0:17:27
epoch [12/50] batch [280/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.5771 (1.8747) teacher_loss 0.5545 (0.8290) loss_zs_kd 1.4603 (1.6025) loss_oracle 1.1530 (1.1990) kd_loss 0.9073 (0.9259) acc 81.2500 (71.1049) lr 1.8090e-03 eta 0:17:22
epoch [12/50] batch [300/319] time 0.080 (0.086) data 0.000 (0.003) loss 1.9975 (1.8721) teacher_loss 0.8962 (0.8265) loss_zs_kd 1.4282 (1.6054) loss_oracle 1.1297 (1.1968) kd_loss 0.9883 (0.9258) acc 65.6250 (71.1875) lr 1.8090e-03 eta 0:17:18
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,610
* accuracy: 59.6%
* error: 40.4%
* macro_f1: 49.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,343
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 23.4%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [13/50] batch [20/319] time 0.081 (0.119) data 0.000 (0.032) loss 1.7815 (1.9117) teacher_loss 0.7984 (0.8851) loss_zs_kd 1.5316 (1.4787) loss_oracle 1.1089 (1.1592) kd_loss 0.8722 (0.9107) acc 62.5000 (70.7812) lr 1.7705e-03 eta 0:24:02
epoch [13/50] batch [40/319] time 0.095 (0.102) data 0.000 (0.016) loss 2.2992 (1.8631) teacher_loss 1.2505 (0.8317) loss_zs_kd 1.5580 (1.4916) loss_oracle 1.2400 (1.1589) kd_loss 0.9248 (0.9155) acc 59.3750 (71.2500) lr 1.7705e-03 eta 0:20:28
epoch [13/50] batch [60/319] time 0.073 (0.092) data 0.001 (0.011) loss 2.1316 (1.8771) teacher_loss 1.1293 (0.8442) loss_zs_kd 1.4579 (1.4647) loss_oracle 1.1872 (1.1614) kd_loss 0.8835 (0.9167) acc 62.5000 (70.8854) lr 1.7705e-03 eta 0:18:32
epoch [13/50] batch [80/319] time 0.079 (0.089) data 0.000 (0.008) loss 1.6620 (1.8742) teacher_loss 0.6758 (0.8416) loss_zs_kd 1.1989 (1.4583) loss_oracle 1.2056 (1.1638) kd_loss 0.8656 (0.9162) acc 81.2500 (70.7812) lr 1.7705e-03 eta 0:17:54
epoch [13/50] batch [100/319] time 0.078 (0.087) data 0.000 (0.007) loss 1.6392 (1.8677) teacher_loss 0.6132 (0.8359) loss_zs_kd 1.5063 (1.4517) loss_oracle 1.1677 (1.1656) kd_loss 0.9093 (0.9153) acc 84.3750 (71.1562) lr 1.7705e-03 eta 0:17:24
epoch [13/50] batch [120/319] time 0.091 (0.086) data 0.000 (0.006) loss 1.9485 (1.8702) teacher_loss 0.9257 (0.8385) loss_zs_kd 1.4515 (1.4495) loss_oracle 1.1238 (1.1649) kd_loss 0.9104 (0.9152) acc 65.6250 (71.4062) lr 1.7705e-03 eta 0:17:11
epoch [13/50] batch [140/319] time 0.080 (0.086) data 0.000 (0.005) loss 2.2213 (1.8771) teacher_loss 1.2365 (0.8448) loss_zs_kd 1.4786 (1.4505) loss_oracle 1.1608 (1.1649) kd_loss 0.8688 (0.9157) acc 62.5000 (70.9375) lr 1.7705e-03 eta 0:17:07
epoch [13/50] batch [160/319] time 0.089 (0.085) data 0.000 (0.004) loss 1.9079 (1.8774) teacher_loss 0.8434 (0.8460) loss_zs_kd 1.6163 (1.4567) loss_oracle 1.1543 (1.1639) kd_loss 0.9490 (0.9150) acc 71.8750 (70.8594) lr 1.7705e-03 eta 0:17:02
epoch [13/50] batch [180/319] time 0.077 (0.085) data 0.000 (0.004) loss 1.7911 (1.8826) teacher_loss 0.7414 (0.8508) loss_zs_kd 1.4046 (1.4696) loss_oracle 1.2216 (1.1672) kd_loss 0.9276 (0.9151) acc 81.2500 (70.8160) lr 1.7705e-03 eta 0:16:59
epoch [13/50] batch [200/319] time 0.091 (0.085) data 0.000 (0.003) loss 1.9704 (1.8794) teacher_loss 0.8825 (0.8495) loss_zs_kd 1.6137 (1.4916) loss_oracle 1.3096 (1.1723) kd_loss 0.9569 (0.9126) acc 62.5000 (70.8594) lr 1.7705e-03 eta 0:16:58
epoch [13/50] batch [220/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.8227 (1.8726) teacher_loss 0.8018 (0.8426) loss_zs_kd 1.6612 (1.4945) loss_oracle 1.2409 (1.1795) kd_loss 0.8968 (0.9121) acc 75.0000 (71.1790) lr 1.7705e-03 eta 0:16:53
epoch [13/50] batch [240/319] time 0.084 (0.085) data 0.000 (0.003) loss 1.7446 (1.8748) teacher_loss 0.7642 (0.8425) loss_zs_kd 1.5009 (1.4931) loss_oracle 1.2012 (1.1854) kd_loss 0.8603 (0.9137) acc 71.8750 (71.2240) lr 1.7705e-03 eta 0:16:52
epoch [13/50] batch [260/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.7732 (1.8759) teacher_loss 0.7371 (0.8424) loss_zs_kd 1.4838 (1.4941) loss_oracle 1.1748 (1.1884) kd_loss 0.9186 (0.9147) acc 71.8750 (70.9736) lr 1.7705e-03 eta 0:16:51
epoch [13/50] batch [280/319] time 0.081 (0.085) data 0.000 (0.003) loss 1.8162 (1.8764) teacher_loss 0.8529 (0.8438) loss_zs_kd 1.5746 (1.4907) loss_oracle 1.1231 (1.1900) kd_loss 0.8510 (0.9136) acc 75.0000 (70.9040) lr 1.7705e-03 eta 0:16:45
epoch [13/50] batch [300/319] time 0.085 (0.085) data 0.000 (0.002) loss 1.9415 (1.8734) teacher_loss 0.8658 (0.8404) loss_zs_kd 1.6281 (1.4920) loss_oracle 1.3565 (1.1917) kd_loss 0.9401 (0.9139) acc 65.6250 (70.9792) lr 1.7705e-03 eta 0:16:42
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,496
* accuracy: 57.0%
* error: 43.0%
* macro_f1: 46.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,540
* accuracy: 56.9%
* error: 43.1%
* macro_f1: 22.0%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [14/50] batch [20/319] time 0.080 (0.111) data 0.000 (0.031) loss 1.7947 (1.8719) teacher_loss 0.7389 (0.8219) loss_zs_kd 1.8042 (1.6484) loss_oracle 1.1398 (1.1990) kd_loss 0.9418 (0.9301) acc 78.1250 (71.8750) lr 1.7290e-03 eta 0:21:46
epoch [14/50] batch [40/319] time 0.074 (0.097) data 0.000 (0.016) loss 1.9143 (1.8727) teacher_loss 0.8111 (0.8163) loss_zs_kd 1.3487 (1.6206) loss_oracle 1.2689 (1.2144) kd_loss 0.9762 (0.9350) acc 75.0000 (72.1875) lr 1.7290e-03 eta 0:18:57
epoch [14/50] batch [60/319] time 0.082 (0.092) data 0.001 (0.011) loss 2.0712 (1.9086) teacher_loss 0.8741 (0.8408) loss_zs_kd 1.9716 (1.5881) loss_oracle 1.3020 (1.2339) kd_loss 1.0669 (0.9444) acc 68.7500 (70.5208) lr 1.7290e-03 eta 0:17:57
epoch [14/50] batch [80/319] time 0.079 (0.088) data 0.000 (0.008) loss 2.1919 (1.9355) teacher_loss 1.0307 (0.8519) loss_zs_kd 1.4997 (1.5476) loss_oracle 1.3375 (1.2583) kd_loss 1.0275 (0.9577) acc 59.3750 (69.8828) lr 1.7290e-03 eta 0:17:15
epoch [14/50] batch [100/319] time 0.081 (0.086) data 0.000 (0.006) loss 1.7679 (1.9474) teacher_loss 0.6222 (0.8524) loss_zs_kd 1.4545 (1.5131) loss_oracle 1.2963 (1.2624) kd_loss 1.0160 (0.9687) acc 81.2500 (69.6875) lr 1.7290e-03 eta 0:16:47
epoch [14/50] batch [120/319] time 0.076 (0.088) data 0.000 (0.005) loss 1.7185 (1.9506) teacher_loss 0.6315 (0.8524) loss_zs_kd 1.6005 (1.5040) loss_oracle 1.3251 (1.2707) kd_loss 0.9545 (0.9711) acc 78.1250 (70.0000) lr 1.7290e-03 eta 0:17:05
epoch [14/50] batch [140/319] time 0.081 (0.087) data 0.000 (0.005) loss 2.0532 (1.9502) teacher_loss 0.9533 (0.8461) loss_zs_kd 1.6622 (1.5110) loss_oracle 1.2891 (1.2792) kd_loss 0.9710 (0.9761) acc 71.8750 (70.4911) lr 1.7290e-03 eta 0:16:50
epoch [14/50] batch [160/319] time 0.084 (0.086) data 0.001 (0.004) loss 2.1953 (1.9612) teacher_loss 1.1438 (0.8558) loss_zs_kd 1.3837 (1.5165) loss_oracle 1.2507 (1.2828) kd_loss 0.9264 (0.9771) acc 62.5000 (69.8828) lr 1.7290e-03 eta 0:16:42
epoch [14/50] batch [180/319] time 0.084 (0.086) data 0.000 (0.004) loss 1.9245 (1.9585) teacher_loss 0.7943 (0.8538) loss_zs_kd 1.4982 (1.5204) loss_oracle 1.2717 (1.2844) kd_loss 1.0030 (0.9763) acc 71.8750 (70.0521) lr 1.7290e-03 eta 0:16:37
epoch [14/50] batch [200/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.9583 (1.9585) teacher_loss 0.7768 (0.8521) loss_zs_kd 1.6042 (1.5242) loss_oracle 1.4654 (1.2875) kd_loss 1.0349 (0.9776) acc 62.5000 (69.9844) lr 1.7290e-03 eta 0:16:33
epoch [14/50] batch [220/319] time 0.087 (0.086) data 0.000 (0.003) loss 1.9522 (1.9577) teacher_loss 0.8347 (0.8536) loss_zs_kd 1.4709 (1.5213) loss_oracle 1.3889 (1.2921) kd_loss 0.9787 (0.9749) acc 75.0000 (70.0000) lr 1.7290e-03 eta 0:16:31
epoch [14/50] batch [240/319] time 0.080 (0.085) data 0.000 (0.003) loss 2.0352 (1.9538) teacher_loss 0.9669 (0.8503) loss_zs_kd 1.6340 (1.5179) loss_oracle 1.3851 (1.2945) kd_loss 0.9298 (0.9740) acc 71.8750 (70.2474) lr 1.7290e-03 eta 0:16:28
epoch [14/50] batch [260/319] time 0.089 (0.085) data 0.000 (0.003) loss 1.8106 (1.9544) teacher_loss 0.8349 (0.8498) loss_zs_kd 1.3057 (1.5113) loss_oracle 1.3723 (1.2975) kd_loss 0.8385 (0.9749) acc 78.1250 (70.3726) lr 1.7290e-03 eta 0:16:21
epoch [14/50] batch [280/319] time 0.094 (0.085) data 0.000 (0.002) loss 2.1586 (1.9544) teacher_loss 0.9546 (0.8484) loss_zs_kd 1.4942 (1.5112) loss_oracle 1.3221 (1.2976) kd_loss 1.0718 (0.9762) acc 56.2500 (70.3460) lr 1.7290e-03 eta 0:16:20
epoch [14/50] batch [300/319] time 0.079 (0.085) data 0.000 (0.002) loss 2.1848 (1.9595) teacher_loss 1.0388 (0.8497) loss_zs_kd 1.5137 (1.5086) loss_oracle 1.2336 (1.2989) kd_loss 1.0227 (0.9800) acc 56.2500 (70.3438) lr 1.7290e-03 eta 0:16:20
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,436
* accuracy: 55.6%
* error: 44.4%
* macro_f1: 48.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,473
* accuracy: 56.2%
* error: 43.8%
* macro_f1: 22.6%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [15/50] batch [20/319] time 0.077 (0.108) data 0.000 (0.026) loss 2.2953 (2.0232) teacher_loss 1.2600 (0.9148) loss_zs_kd 1.4905 (1.4977) loss_oracle 1.2702 (1.2988) kd_loss 0.9083 (0.9786) acc 46.8750 (67.9688) lr 1.6845e-03 eta 0:20:40
epoch [15/50] batch [40/319] time 0.081 (0.095) data 0.000 (0.013) loss 1.5936 (1.9767) teacher_loss 0.5632 (0.8599) loss_zs_kd 1.4220 (1.5046) loss_oracle 1.2232 (1.2904) kd_loss 0.9081 (0.9878) acc 87.5000 (70.1562) lr 1.6845e-03 eta 0:18:03
epoch [15/50] batch [60/319] time 0.090 (0.091) data 0.001 (0.009) loss 2.0596 (1.9886) teacher_loss 0.9322 (0.8749) loss_zs_kd 1.6074 (1.4981) loss_oracle 1.3515 (1.2977) kd_loss 0.9922 (0.9839) acc 65.6250 (69.5312) lr 1.6845e-03 eta 0:17:19
epoch [15/50] batch [80/319] time 0.086 (0.088) data 0.000 (0.007) loss 1.8881 (1.9860) teacher_loss 0.6613 (0.8624) loss_zs_kd 1.3664 (1.4955) loss_oracle 1.2622 (1.3026) kd_loss 1.1006 (0.9934) acc 75.0000 (70.0391) lr 1.6845e-03 eta 0:16:42
epoch [15/50] batch [100/319] time 0.085 (0.087) data 0.000 (0.005) loss 1.8429 (1.9638) teacher_loss 0.7852 (0.8518) loss_zs_kd 1.2370 (1.4704) loss_oracle 1.3659 (1.3061) kd_loss 0.9211 (0.9814) acc 75.0000 (70.6250) lr 1.6845e-03 eta 0:16:27
epoch [15/50] batch [120/319] time 0.084 (0.086) data 0.000 (0.005) loss 1.8251 (1.9629) teacher_loss 0.7693 (0.8579) loss_zs_kd 1.3993 (1.4539) loss_oracle 1.3243 (1.3059) kd_loss 0.9234 (0.9744) acc 75.0000 (70.4688) lr 1.6845e-03 eta 0:16:13
epoch [15/50] batch [140/319] time 0.074 (0.085) data 0.000 (0.004) loss 1.9771 (1.9566) teacher_loss 0.8507 (0.8579) loss_zs_kd 1.6489 (1.4440) loss_oracle 1.4547 (1.3106) kd_loss 0.9809 (0.9677) acc 65.6250 (70.3795) lr 1.6845e-03 eta 0:16:03
epoch [15/50] batch [160/319] time 0.088 (0.084) data 0.000 (0.003) loss 1.7479 (1.9439) teacher_loss 0.6400 (0.8516) loss_zs_kd 1.3507 (1.4394) loss_oracle 1.3247 (1.3086) kd_loss 0.9755 (0.9614) acc 84.3750 (70.4883) lr 1.6845e-03 eta 0:15:55
epoch [15/50] batch [180/319] time 0.074 (0.084) data 0.000 (0.003) loss 1.9726 (1.9379) teacher_loss 0.8276 (0.8425) loss_zs_kd 1.3075 (1.4271) loss_oracle 1.3824 (1.3112) kd_loss 1.0068 (0.9643) acc 71.8750 (70.9201) lr 1.6845e-03 eta 0:15:52
epoch [15/50] batch [200/319] time 0.096 (0.084) data 0.001 (0.003) loss 2.3443 (1.9617) teacher_loss 1.1389 (0.8593) loss_zs_kd 1.4298 (1.4218) loss_oracle 1.3098 (1.3129) kd_loss 1.0743 (0.9711) acc 53.1250 (70.3594) lr 1.6845e-03 eta 0:15:45
epoch [15/50] batch [220/319] time 0.075 (0.084) data 0.000 (0.003) loss 2.4023 (1.9682) teacher_loss 1.2407 (0.8628) loss_zs_kd 1.4633 (1.4239) loss_oracle 1.3575 (1.3111) kd_loss 1.0259 (0.9743) acc 56.2500 (70.1705) lr 1.6845e-03 eta 0:15:44
epoch [15/50] batch [240/319] time 0.082 (0.083) data 0.000 (0.002) loss 1.8674 (1.9662) teacher_loss 0.7566 (0.8582) loss_zs_kd 1.6548 (1.4287) loss_oracle 1.4120 (1.3112) kd_loss 0.9695 (0.9769) acc 71.8750 (70.3906) lr 1.6845e-03 eta 0:15:37
epoch [15/50] batch [260/319] time 0.075 (0.083) data 0.000 (0.002) loss 2.1639 (1.9783) teacher_loss 0.9428 (0.8665) loss_zs_kd 1.4187 (1.4377) loss_oracle 1.2930 (1.3107) kd_loss 1.0918 (0.9808) acc 71.8750 (70.1202) lr 1.6845e-03 eta 0:15:35
epoch [15/50] batch [280/319] time 0.091 (0.083) data 0.000 (0.002) loss 1.8293 (1.9853) teacher_loss 0.8115 (0.8723) loss_zs_kd 1.3033 (1.4327) loss_oracle 1.3331 (1.3106) kd_loss 0.8845 (0.9820) acc 71.8750 (70.0112) lr 1.6845e-03 eta 0:15:33
epoch [15/50] batch [300/319] time 0.074 (0.084) data 0.000 (0.002) loss 2.0826 (1.9882) teacher_loss 1.0543 (0.8767) loss_zs_kd 1.1646 (1.4183) loss_oracle 1.3487 (1.3092) kd_loss 0.8934 (0.9806) acc 59.3750 (69.8021) lr 1.6845e-03 eta 0:15:39
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,515
* accuracy: 57.4%
* error: 42.6%
* macro_f1: 50.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,637
* accuracy: 57.9%
* error: 42.1%
* macro_f1: 24.5%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [16/50] batch [20/319] time 0.085 (0.116) data 0.000 (0.026) loss 1.7822 (2.0091) teacher_loss 0.6957 (0.9236) loss_zs_kd 1.3618 (1.3258) loss_oracle 1.3419 (1.2984) kd_loss 0.9523 (0.9557) acc 68.7500 (67.9688) lr 1.6374e-03 eta 0:21:32
epoch [16/50] batch [40/319] time 0.089 (0.099) data 0.000 (0.013) loss 2.2104 (2.0123) teacher_loss 1.0623 (0.9206) loss_zs_kd 1.3157 (1.3370) loss_oracle 1.3679 (1.2962) kd_loss 1.0114 (0.9621) acc 62.5000 (67.7344) lr 1.6374e-03 eta 0:18:25
epoch [16/50] batch [60/319] time 0.062 (0.092) data 0.000 (0.009) loss 1.8050 (2.0115) teacher_loss 0.6403 (0.9029) loss_zs_kd 1.3816 (1.3544) loss_oracle 1.3226 (1.3036) kd_loss 1.0324 (0.9783) acc 78.1250 (68.4896) lr 1.6374e-03 eta 0:17:04
epoch [16/50] batch [80/319] time 0.068 (0.089) data 0.000 (0.007) loss 1.8434 (2.0075) teacher_loss 0.7575 (0.8922) loss_zs_kd 1.3265 (1.3492) loss_oracle 1.2823 (1.3043) kd_loss 0.9576 (0.9849) acc 65.6250 (68.7500) lr 1.6374e-03 eta 0:16:30
epoch [16/50] batch [100/319] time 0.083 (0.087) data 0.000 (0.005) loss 2.2281 (2.0125) teacher_loss 1.0730 (0.8889) loss_zs_kd 1.2305 (1.3697) loss_oracle 1.3560 (1.3040) kd_loss 1.0194 (0.9932) acc 62.5000 (68.7812) lr 1.6374e-03 eta 0:15:58
epoch [16/50] batch [120/319] time 0.086 (0.087) data 0.000 (0.005) loss 2.0528 (2.0197) teacher_loss 0.7764 (0.8806) loss_zs_kd 1.6606 (1.3914) loss_oracle 1.2823 (1.3041) kd_loss 1.1481 (1.0088) acc 71.8750 (69.2448) lr 1.6374e-03 eta 0:15:59
epoch [16/50] batch [140/319] time 0.080 (0.087) data 0.000 (0.004) loss 1.8814 (2.0398) teacher_loss 0.7194 (0.8950) loss_zs_kd 1.7334 (1.4031) loss_oracle 1.2842 (1.3055) kd_loss 1.0336 (1.0143) acc 84.3750 (68.6384) lr 1.6374e-03 eta 0:15:53
epoch [16/50] batch [160/319] time 0.087 (0.087) data 0.000 (0.004) loss 1.8140 (2.0398) teacher_loss 0.6967 (0.8995) loss_zs_kd 1.3581 (1.4124) loss_oracle 1.3130 (1.3036) kd_loss 0.9861 (1.0099) acc 81.2500 (68.4961) lr 1.6374e-03 eta 0:15:55
epoch [16/50] batch [180/319] time 0.090 (0.087) data 0.000 (0.003) loss 1.7554 (2.0298) teacher_loss 0.7247 (0.8922) loss_zs_kd 1.3338 (1.4100) loss_oracle 1.1786 (1.3009) kd_loss 0.9128 (1.0075) acc 75.0000 (68.8194) lr 1.6374e-03 eta 0:15:52
epoch [16/50] batch [200/319] time 0.079 (0.087) data 0.000 (0.003) loss 1.7140 (2.0198) teacher_loss 0.6305 (0.8831) loss_zs_kd 1.2987 (1.4158) loss_oracle 1.3599 (1.2998) kd_loss 0.9475 (1.0067) acc 78.1250 (69.0469) lr 1.6374e-03 eta 0:15:48
epoch [16/50] batch [220/319] time 0.089 (0.086) data 0.000 (0.003) loss 1.9465 (2.0143) teacher_loss 0.8737 (0.8807) loss_zs_kd 1.3710 (1.4283) loss_oracle 1.2223 (1.2985) kd_loss 0.9506 (1.0037) acc 65.6250 (69.1761) lr 1.6374e-03 eta 0:15:44
epoch [16/50] batch [240/319] time 0.080 (0.086) data 0.000 (0.002) loss 1.8360 (2.0067) teacher_loss 0.7884 (0.8796) loss_zs_kd 1.9613 (1.4368) loss_oracle 1.2841 (1.2931) kd_loss 0.9192 (0.9977) acc 78.1250 (69.3229) lr 1.6374e-03 eta 0:15:41
epoch [16/50] batch [260/319] time 0.086 (0.086) data 0.000 (0.002) loss 1.7487 (1.9972) teacher_loss 0.6751 (0.8761) loss_zs_kd 1.3827 (1.4313) loss_oracle 1.2939 (1.2909) kd_loss 0.9442 (0.9920) acc 75.0000 (69.4111) lr 1.6374e-03 eta 0:15:39
epoch [16/50] batch [280/319] time 0.084 (0.086) data 0.000 (0.002) loss 2.1208 (1.9903) teacher_loss 0.9995 (0.8717) loss_zs_kd 1.6183 (1.4402) loss_oracle 1.1818 (1.2884) kd_loss 1.0031 (0.9897) acc 65.6250 (69.5871) lr 1.6374e-03 eta 0:15:37
epoch [16/50] batch [300/319] time 0.088 (0.086) data 0.000 (0.002) loss 1.8550 (1.9819) teacher_loss 0.8593 (0.8680) loss_zs_kd 1.6472 (1.4576) loss_oracle 1.1276 (1.2840) kd_loss 0.8830 (0.9854) acc 68.7500 (69.6667) lr 1.6374e-03 eta 0:15:34
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,449
* accuracy: 55.9%
* error: 44.1%
* macro_f1: 48.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,653
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 24.8%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [17/50] batch [20/319] time 0.077 (0.103) data 0.000 (0.023) loss 1.8706 (1.8979) teacher_loss 0.7932 (0.8204) loss_zs_kd 1.9174 (1.6193) loss_oracle 1.1320 (1.2093) kd_loss 0.9642 (0.9566) acc 75.0000 (70.9375) lr 1.5878e-03 eta 0:18:37
epoch [17/50] batch [40/319] time 0.082 (0.093) data 0.000 (0.012) loss 2.0032 (1.9373) teacher_loss 0.9064 (0.8602) loss_zs_kd 1.6953 (1.5857) loss_oracle 1.2508 (1.2206) kd_loss 0.9717 (0.9551) acc 62.5000 (69.6875) lr 1.5878e-03 eta 0:16:42
epoch [17/50] batch [60/319] time 0.081 (0.090) data 0.000 (0.008) loss 2.0729 (1.9425) teacher_loss 0.9491 (0.8594) loss_zs_kd 1.4439 (1.5679) loss_oracle 1.3102 (1.2231) kd_loss 0.9927 (0.9608) acc 59.3750 (69.2708) lr 1.5878e-03 eta 0:16:15
epoch [17/50] batch [80/319] time 0.080 (0.089) data 0.000 (0.006) loss 1.6592 (1.9182) teacher_loss 0.6259 (0.8381) loss_zs_kd 1.9608 (1.5798) loss_oracle 1.2379 (1.2175) kd_loss 0.9095 (0.9583) acc 68.7500 (69.8047) lr 1.5878e-03 eta 0:15:58
epoch [17/50] batch [100/319] time 0.088 (0.088) data 0.000 (0.005) loss 1.7355 (1.9188) teacher_loss 0.6425 (0.8418) loss_zs_kd 1.7555 (1.5959) loss_oracle 1.2127 (1.2177) kd_loss 0.9718 (0.9553) acc 84.3750 (69.7812) lr 1.5878e-03 eta 0:15:47
epoch [17/50] batch [120/319] time 0.085 (0.088) data 0.000 (0.004) loss 2.0352 (1.9516) teacher_loss 0.9471 (0.8719) loss_zs_kd 1.4956 (1.5818) loss_oracle 1.1988 (1.2158) kd_loss 0.9682 (0.9581) acc 56.2500 (68.6198) lr 1.5878e-03 eta 0:15:39
epoch [17/50] batch [140/319] time 0.085 (0.087) data 0.000 (0.004) loss 2.0959 (1.9679) teacher_loss 0.9417 (0.8847) loss_zs_kd 1.6171 (1.5627) loss_oracle 1.2495 (1.2101) kd_loss 1.0292 (0.9622) acc 59.3750 (68.2143) lr 1.5878e-03 eta 0:15:33
epoch [17/50] batch [160/319] time 0.074 (0.086) data 0.000 (0.003) loss 1.7429 (1.9727) teacher_loss 0.6934 (0.8862) loss_zs_kd 1.3939 (1.5645) loss_oracle 1.1797 (1.2099) kd_loss 0.9316 (0.9655) acc 75.0000 (68.3203) lr 1.5878e-03 eta 0:15:15
epoch [17/50] batch [180/319] time 0.085 (0.086) data 0.000 (0.003) loss 1.8348 (1.9731) teacher_loss 0.7733 (0.8838) loss_zs_kd 1.6942 (1.5686) loss_oracle 1.1206 (1.2073) kd_loss 0.9494 (0.9686) acc 71.8750 (68.5938) lr 1.5878e-03 eta 0:15:15
epoch [17/50] batch [200/319] time 0.075 (0.086) data 0.000 (0.003) loss 1.6869 (1.9761) teacher_loss 0.5789 (0.8863) loss_zs_kd 1.7606 (1.5687) loss_oracle 1.1913 (1.2068) kd_loss 0.9889 (0.9691) acc 71.8750 (68.6094) lr 1.5878e-03 eta 0:15:16
epoch [17/50] batch [220/319] time 0.090 (0.086) data 0.000 (0.002) loss 1.9755 (1.9827) teacher_loss 0.8682 (0.8926) loss_zs_kd 1.6846 (1.5750) loss_oracle 1.2304 (1.2046) kd_loss 0.9843 (0.9696) acc 62.5000 (68.5795) lr 1.5878e-03 eta 0:15:13
epoch [17/50] batch [240/319] time 0.079 (0.086) data 0.000 (0.002) loss 2.0006 (1.9777) teacher_loss 0.9091 (0.8872) loss_zs_kd 1.6488 (1.5686) loss_oracle 1.2356 (1.2053) kd_loss 0.9680 (0.9700) acc 62.5000 (68.8932) lr 1.5878e-03 eta 0:15:08
epoch [17/50] batch [260/319] time 0.081 (0.087) data 0.000 (0.002) loss 1.9813 (1.9758) teacher_loss 0.8784 (0.8826) loss_zs_kd 1.5270 (1.5620) loss_oracle 1.2659 (1.2087) kd_loss 0.9763 (0.9724) acc 71.8750 (69.0385) lr 1.5878e-03 eta 0:15:17
epoch [17/50] batch [280/319] time 0.082 (0.086) data 0.000 (0.002) loss 1.5895 (1.9723) teacher_loss 0.5066 (0.8743) loss_zs_kd 1.5296 (1.5556) loss_oracle 1.2677 (1.2122) kd_loss 0.9561 (0.9768) acc 81.2500 (69.3862) lr 1.5878e-03 eta 0:15:12
epoch [17/50] batch [300/319] time 0.083 (0.086) data 0.000 (0.002) loss 1.9133 (1.9733) teacher_loss 0.8702 (0.8733) loss_zs_kd 1.5263 (1.5501) loss_oracle 1.2194 (1.2141) kd_loss 0.9212 (0.9786) acc 68.7500 (69.3438) lr 1.5878e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,583
* accuracy: 59.0%
* error: 41.0%
* macro_f1: 49.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,273
* accuracy: 54.2%
* error: 45.8%
* macro_f1: 24.6%
******* Domain 2 best val acc:      59.8%, epoch: 9 *******
******* Domain 2 best val test acc: 54.0%, epoch: 9 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [18/50] batch [20/319] time 0.112 (0.143) data 0.000 (0.036) loss 1.8408 (1.8869) teacher_loss 0.7296 (0.8012) loss_zs_kd 1.3014 (1.3675) loss_oracle 1.1772 (1.2393) kd_loss 0.9935 (0.9617) acc 78.1250 (72.3438) lr 1.5358e-03 eta 0:24:59
epoch [18/50] batch [40/319] time 0.087 (0.114) data 0.000 (0.018) loss 1.6662 (1.8787) teacher_loss 0.6401 (0.7826) loss_zs_kd 1.5332 (1.4539) loss_oracle 1.2590 (1.2494) kd_loss 0.9003 (0.9711) acc 75.0000 (72.9688) lr 1.5358e-03 eta 0:19:59
epoch [18/50] batch [60/319] time 0.091 (0.102) data 0.000 (0.012) loss 2.0046 (1.8813) teacher_loss 0.8896 (0.7905) loss_zs_kd 1.4399 (1.4565) loss_oracle 1.2113 (1.2482) kd_loss 0.9938 (0.9659) acc 75.0000 (72.6042) lr 1.5358e-03 eta 0:17:48
epoch [18/50] batch [80/319] time 0.103 (0.099) data 0.000 (0.009) loss 1.6783 (1.8872) teacher_loss 0.6632 (0.8039) loss_zs_kd 1.1841 (1.4394) loss_oracle 1.2971 (1.2436) kd_loss 0.8854 (0.9590) acc 68.7500 (71.8359) lr 1.5358e-03 eta 0:17:11
epoch [18/50] batch [100/319] time 0.082 (0.097) data 0.000 (0.007) loss 1.6731 (1.8886) teacher_loss 0.5670 (0.8015) loss_zs_kd 1.6797 (1.4308) loss_oracle 1.2696 (1.2474) kd_loss 0.9791 (0.9624) acc 81.2500 (71.8750) lr 1.5358e-03 eta 0:16:50
epoch [18/50] batch [120/319] time 0.087 (0.095) data 0.000 (0.006) loss 1.8537 (1.8983) teacher_loss 0.7811 (0.8134) loss_zs_kd 1.8728 (1.4518) loss_oracle 1.3331 (1.2477) kd_loss 0.9393 (0.9601) acc 71.8750 (71.4062) lr 1.5358e-03 eta 0:16:30
epoch [18/50] batch [140/319] time 0.084 (0.094) data 0.000 (0.005) loss 1.8157 (1.8932) teacher_loss 0.6212 (0.8107) loss_zs_kd 1.6354 (1.4479) loss_oracle 1.2841 (1.2462) kd_loss 1.0661 (0.9579) acc 75.0000 (71.4955) lr 1.5358e-03 eta 0:16:11
epoch [18/50] batch [160/319] time 0.092 (0.092) data 0.000 (0.005) loss 1.8607 (1.8979) teacher_loss 0.8361 (0.8207) loss_zs_kd 1.3694 (1.4296) loss_oracle 1.2934 (1.2477) kd_loss 0.8953 (0.9524) acc 71.8750 (71.0938) lr 1.5358e-03 eta 0:15:58
epoch [18/50] batch [180/319] time 0.081 (0.092) data 0.000 (0.004) loss 2.0320 (1.8892) teacher_loss 0.9485 (0.8154) loss_zs_kd 1.5146 (1.4285) loss_oracle 1.2912 (1.2453) kd_loss 0.9544 (0.9493) acc 62.5000 (71.2847) lr 1.5358e-03 eta 0:15:48
epoch [18/50] batch [200/319] time 0.080 (0.091) data 0.000 (0.004) loss 1.8575 (1.8866) teacher_loss 0.8216 (0.8174) loss_zs_kd 1.5107 (1.4318) loss_oracle 1.1586 (1.2394) kd_loss 0.9201 (0.9452) acc 71.8750 (71.2031) lr 1.5358e-03 eta 0:15:39
epoch [18/50] batch [220/319] time 0.083 (0.090) data 0.000 (0.004) loss 2.1276 (1.8861) teacher_loss 1.0850 (0.8192) loss_zs_kd 1.4140 (1.4392) loss_oracle 1.2450 (1.2363) kd_loss 0.9180 (0.9433) acc 59.3750 (71.0938) lr 1.5358e-03 eta 0:15:32
epoch [18/50] batch [240/319] time 0.078 (0.090) data 0.000 (0.003) loss 1.8778 (1.8836) teacher_loss 0.7045 (0.8175) loss_zs_kd 1.3481 (1.4306) loss_oracle 1.2154 (1.2354) kd_loss 1.0517 (0.9426) acc 71.8750 (71.1458) lr 1.5358e-03 eta 0:15:25
epoch [18/50] batch [260/319] time 0.079 (0.090) data 0.000 (0.003) loss 2.1001 (1.8831) teacher_loss 0.9436 (0.8185) loss_zs_kd 1.6651 (1.4322) loss_oracle 1.1672 (1.2347) kd_loss 1.0398 (0.9412) acc 68.7500 (71.1418) lr 1.5358e-03 eta 0:15:19
epoch [18/50] batch [280/319] time 0.082 (0.089) data 0.000 (0.003) loss 2.1320 (1.8902) teacher_loss 1.0013 (0.8237) loss_zs_kd 1.3156 (1.4287) loss_oracle 1.3437 (1.2350) kd_loss 0.9963 (0.9430) acc 65.6250 (71.0826) lr 1.5358e-03 eta 0:15:15
epoch [18/50] batch [300/319] time 0.075 (0.089) data 0.000 (0.003) loss 1.5403 (1.8917) teacher_loss 0.5242 (0.8245) loss_zs_kd 1.7055 (1.4339) loss_oracle 1.1937 (1.2347) kd_loss 0.8967 (0.9437) acc 84.3750 (71.0417) lr 1.5358e-03 eta 0:15:08
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,704
* accuracy: 61.8%
* error: 38.2%
* macro_f1: 51.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,389
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 22.8%
******* Domain 2 best val acc:      61.8%, epoch: 18 *******
******* Domain 2 best val test acc: 55.4%, epoch: 18 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [19/50] batch [20/319] time 0.084 (0.121) data 0.000 (0.031) loss 1.6222 (1.8486) teacher_loss 0.5213 (0.7824) loss_zs_kd 1.2665 (1.2778) loss_oracle 1.1551 (1.2264) kd_loss 0.9854 (0.9436) acc 87.5000 (73.4375) lr 1.4818e-03 eta 0:20:32
epoch [19/50] batch [40/319] time 0.081 (0.101) data 0.000 (0.016) loss 1.8664 (1.8886) teacher_loss 0.7607 (0.8044) loss_zs_kd 1.3851 (1.3411) loss_oracle 1.2795 (1.2371) kd_loss 0.9778 (0.9604) acc 68.7500 (71.7969) lr 1.4818e-03 eta 0:17:09
epoch [19/50] batch [60/319] time 0.084 (0.096) data 0.001 (0.011) loss 1.9144 (1.8840) teacher_loss 0.8769 (0.8076) loss_zs_kd 1.1853 (1.3742) loss_oracle 1.1930 (1.2382) kd_loss 0.9182 (0.9526) acc 68.7500 (71.0938) lr 1.4818e-03 eta 0:16:11
epoch [19/50] batch [80/319] time 0.097 (0.093) data 0.000 (0.008) loss 2.0240 (1.8777) teacher_loss 0.9289 (0.8112) loss_zs_kd 1.5440 (1.3681) loss_oracle 1.1196 (1.2231) kd_loss 0.9831 (0.9442) acc 65.6250 (70.9375) lr 1.4818e-03 eta 0:15:38
epoch [19/50] batch [100/319] time 0.084 (0.092) data 0.000 (0.007) loss 1.8103 (1.8840) teacher_loss 0.7569 (0.8217) loss_zs_kd 1.5395 (1.3919) loss_oracle 1.2687 (1.2266) kd_loss 0.9266 (0.9396) acc 78.1250 (70.8750) lr 1.4818e-03 eta 0:15:32
epoch [19/50] batch [120/319] time 0.090 (0.091) data 0.000 (0.006) loss 2.1473 (1.8863) teacher_loss 1.1154 (0.8231) loss_zs_kd 1.2205 (1.4058) loss_oracle 1.1727 (1.2295) kd_loss 0.9146 (0.9402) acc 56.2500 (70.9635) lr 1.4818e-03 eta 0:15:16
epoch [19/50] batch [140/319] time 0.087 (0.090) data 0.000 (0.005) loss 1.6781 (1.8899) teacher_loss 0.6717 (0.8273) loss_zs_kd 1.3241 (1.4041) loss_oracle 1.2842 (1.2317) kd_loss 0.8780 (0.9394) acc 71.8750 (71.0045) lr 1.4818e-03 eta 0:15:06
epoch [19/50] batch [160/319] time 0.082 (0.089) data 0.000 (0.004) loss 2.0530 (1.8920) teacher_loss 0.9720 (0.8308) loss_zs_kd 1.4268 (1.4069) loss_oracle 1.2750 (1.2302) kd_loss 0.9535 (0.9381) acc 59.3750 (70.9570) lr 1.4818e-03 eta 0:14:58
epoch [19/50] batch [180/319] time 0.073 (0.090) data 0.000 (0.004) loss 1.8186 (1.8947) teacher_loss 0.7124 (0.8322) loss_zs_kd 1.5673 (1.4132) loss_oracle 1.1389 (1.2283) kd_loss 0.9923 (0.9396) acc 78.1250 (70.9549) lr 1.4818e-03 eta 0:15:05
epoch [19/50] batch [200/319] time 0.081 (0.090) data 0.000 (0.003) loss 1.7310 (1.8971) teacher_loss 0.7178 (0.8345) loss_zs_kd 1.4479 (1.4337) loss_oracle 1.1324 (1.2233) kd_loss 0.9000 (0.9402) acc 75.0000 (71.0000) lr 1.4818e-03 eta 0:14:57
epoch [19/50] batch [220/319] time 0.080 (0.089) data 0.000 (0.003) loss 2.1383 (1.8957) teacher_loss 1.0965 (0.8304) loss_zs_kd 1.4714 (1.4491) loss_oracle 1.2049 (1.2205) kd_loss 0.9213 (0.9433) acc 65.6250 (71.1222) lr 1.4818e-03 eta 0:14:47
epoch [19/50] batch [240/319] time 0.080 (0.089) data 0.000 (0.003) loss 2.0366 (1.8980) teacher_loss 0.9247 (0.8305) loss_zs_kd 1.3097 (1.4608) loss_oracle 1.2128 (1.2211) kd_loss 0.9906 (0.9454) acc 68.7500 (71.2891) lr 1.4818e-03 eta 0:14:43
epoch [19/50] batch [260/319] time 0.084 (0.088) data 0.000 (0.003) loss 2.1372 (1.9064) teacher_loss 1.1979 (0.8371) loss_zs_kd 1.1393 (1.4581) loss_oracle 1.2274 (1.2251) kd_loss 0.8165 (0.9468) acc 62.5000 (71.1298) lr 1.4818e-03 eta 0:14:38
epoch [19/50] batch [280/319] time 0.087 (0.088) data 0.000 (0.003) loss 1.7047 (1.9044) teacher_loss 0.5658 (0.8326) loss_zs_kd 1.3114 (1.4510) loss_oracle 1.1925 (1.2274) kd_loss 1.0196 (0.9491) acc 84.3750 (71.3504) lr 1.4818e-03 eta 0:14:33
epoch [19/50] batch [300/319] time 0.091 (0.088) data 0.000 (0.002) loss 2.0132 (1.9052) teacher_loss 0.9228 (0.8315) loss_zs_kd 1.2322 (1.4441) loss_oracle 1.2077 (1.2304) kd_loss 0.9696 (0.9506) acc 71.8750 (71.3021) lr 1.4818e-03 eta 0:14:29
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,708
* accuracy: 61.9%
* error: 38.1%
* macro_f1: 55.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,426
* accuracy: 55.7%
* error: 44.3%
* macro_f1: 25.9%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [20/50] batch [20/319] time 0.086 (0.115) data 0.000 (0.027) loss 1.7919 (1.9362) teacher_loss 0.7392 (0.8368) loss_zs_kd 1.3832 (1.4605) loss_oracle 1.2272 (1.2601) kd_loss 0.9300 (0.9734) acc 78.1250 (71.2500) lr 1.4258e-03 eta 0:18:58
epoch [20/50] batch [40/319] time 0.086 (0.100) data 0.000 (0.014) loss 1.8095 (1.9091) teacher_loss 0.7545 (0.8238) loss_zs_kd 1.2980 (1.4570) loss_oracle 1.3124 (1.2599) kd_loss 0.9238 (0.9592) acc 78.1250 (71.8750) lr 1.4258e-03 eta 0:16:22
epoch [20/50] batch [60/319] time 0.084 (0.095) data 0.000 (0.009) loss 1.6135 (1.9229) teacher_loss 0.5622 (0.8502) loss_zs_kd 1.1728 (1.4551) loss_oracle 1.2611 (1.2658) kd_loss 0.9252 (0.9462) acc 75.0000 (70.8333) lr 1.4258e-03 eta 0:15:31
epoch [20/50] batch [80/319] time 0.080 (0.092) data 0.000 (0.007) loss 1.9119 (1.9045) teacher_loss 0.8009 (0.8360) loss_zs_kd 1.7398 (1.4665) loss_oracle 1.3681 (1.2686) kd_loss 0.9742 (0.9416) acc 71.8750 (71.1719) lr 1.4258e-03 eta 0:15:03
epoch [20/50] batch [100/319] time 0.087 (0.090) data 0.000 (0.006) loss 1.8027 (1.8958) teacher_loss 0.6843 (0.8227) loss_zs_kd 1.5215 (1.4548) loss_oracle 1.2528 (1.2749) kd_loss 0.9931 (0.9456) acc 75.0000 (71.4688) lr 1.4258e-03 eta 0:14:44
epoch [20/50] batch [120/319] time 0.086 (0.090) data 0.000 (0.005) loss 1.7336 (1.8813) teacher_loss 0.5883 (0.8104) loss_zs_kd 1.5726 (1.4560) loss_oracle 1.3978 (1.2714) kd_loss 1.0055 (0.9438) acc 78.1250 (71.7448) lr 1.4258e-03 eta 0:14:36
epoch [20/50] batch [140/319] time 0.081 (0.089) data 0.000 (0.004) loss 1.7838 (1.8824) teacher_loss 0.7158 (0.8133) loss_zs_kd 1.4524 (1.4642) loss_oracle 1.2073 (1.2687) kd_loss 0.9473 (0.9422) acc 78.1250 (71.7857) lr 1.4258e-03 eta 0:14:27
epoch [20/50] batch [160/319] time 0.102 (0.089) data 0.000 (0.004) loss 1.8661 (1.8844) teacher_loss 0.6574 (0.8107) loss_zs_kd 1.6318 (1.4698) loss_oracle 1.3745 (1.2724) kd_loss 1.0713 (0.9465) acc 71.8750 (71.6016) lr 1.4258e-03 eta 0:14:23
epoch [20/50] batch [180/319] time 0.080 (0.089) data 0.000 (0.003) loss 2.0440 (1.9017) teacher_loss 0.9790 (0.8214) loss_zs_kd 1.5949 (1.4702) loss_oracle 1.3594 (1.2736) kd_loss 0.9291 (0.9530) acc 59.3750 (71.1111) lr 1.4258e-03 eta 0:14:21
epoch [20/50] batch [200/319] time 0.083 (0.088) data 0.000 (0.003) loss 1.8549 (1.9068) teacher_loss 0.7825 (0.8217) loss_zs_kd 1.7537 (1.4720) loss_oracle 1.2502 (1.2752) kd_loss 0.9473 (0.9575) acc 84.3750 (71.2656) lr 1.4258e-03 eta 0:14:15
epoch [20/50] batch [220/319] time 0.077 (0.088) data 0.000 (0.003) loss 1.9201 (1.9054) teacher_loss 0.8193 (0.8208) loss_zs_kd 1.5031 (1.4827) loss_oracle 1.3122 (1.2742) kd_loss 0.9696 (0.9572) acc 71.8750 (71.1506) lr 1.4258e-03 eta 0:14:10
epoch [20/50] batch [240/319] time 0.082 (0.088) data 0.000 (0.003) loss 1.9429 (1.9074) teacher_loss 0.8824 (0.8226) loss_zs_kd 1.4332 (1.4887) loss_oracle 1.1659 (1.2725) kd_loss 0.9439 (0.9575) acc 62.5000 (71.1589) lr 1.4258e-03 eta 0:14:06
epoch [20/50] batch [260/319] time 0.081 (0.087) data 0.000 (0.002) loss 2.0611 (1.9068) teacher_loss 0.9877 (0.8221) loss_zs_kd 1.2570 (1.4904) loss_oracle 1.3142 (1.2717) kd_loss 0.9419 (0.9574) acc 68.7500 (71.2981) lr 1.4258e-03 eta 0:14:02
epoch [20/50] batch [280/319] time 0.083 (0.087) data 0.000 (0.002) loss 1.8038 (1.9074) teacher_loss 0.6903 (0.8227) loss_zs_kd 1.3808 (1.4850) loss_oracle 1.3361 (1.2733) kd_loss 0.9799 (0.9574) acc 81.2500 (71.3393) lr 1.4258e-03 eta 0:13:59
epoch [20/50] batch [300/319] time 0.089 (0.087) data 0.000 (0.002) loss 2.2018 (1.9100) teacher_loss 1.0663 (0.8239) loss_zs_kd 1.6701 (1.4816) loss_oracle 1.3282 (1.2748) kd_loss 1.0028 (0.9586) acc 65.6250 (71.3438) lr 1.4258e-03 eta 0:13:56
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,653
* accuracy: 60.6%
* error: 39.4%
* macro_f1: 53.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,577
* accuracy: 57.3%
* error: 42.7%
* macro_f1: 24.1%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [21/50] batch [20/319] time 0.081 (0.115) data 0.000 (0.030) loss 1.7200 (1.8831) teacher_loss 0.5897 (0.7912) loss_zs_kd 1.6577 (1.4925) loss_oracle 1.3381 (1.2667) kd_loss 0.9966 (0.9652) acc 75.0000 (72.8125) lr 1.3681e-03 eta 0:18:22
epoch [21/50] batch [40/319] time 0.080 (0.100) data 0.000 (0.015) loss 2.0998 (1.9130) teacher_loss 1.0074 (0.8283) loss_zs_kd 1.2357 (1.4807) loss_oracle 1.2448 (1.2877) kd_loss 0.9680 (0.9560) acc 71.8750 (70.3125) lr 1.3681e-03 eta 0:15:54
epoch [21/50] batch [60/319] time 0.086 (0.094) data 0.000 (0.010) loss 1.9317 (1.9188) teacher_loss 0.7842 (0.8271) loss_zs_kd 1.5354 (1.4692) loss_oracle 1.3457 (1.2961) kd_loss 1.0129 (0.9620) acc 68.7500 (70.7812) lr 1.3681e-03 eta 0:14:58
epoch [21/50] batch [80/319] time 0.084 (0.092) data 0.000 (0.008) loss 1.7515 (1.9336) teacher_loss 0.5685 (0.8369) loss_zs_kd 1.2727 (1.4286) loss_oracle 1.2766 (1.2942) kd_loss 1.0553 (0.9673) acc 78.1250 (70.1562) lr 1.3681e-03 eta 0:14:34
epoch [21/50] batch [100/319] time 0.079 (0.089) data 0.000 (0.006) loss 1.6622 (1.9278) teacher_loss 0.6020 (0.8314) loss_zs_kd 1.5084 (1.4073) loss_oracle 1.3038 (1.2928) kd_loss 0.9299 (0.9671) acc 75.0000 (70.5625) lr 1.3681e-03 eta 0:14:05
epoch [21/50] batch [120/319] time 0.136 (0.090) data 0.001 (0.005) loss 1.6788 (1.9167) teacher_loss 0.6322 (0.8257) loss_zs_kd 1.4331 (1.4206) loss_oracle 1.3706 (1.2921) kd_loss 0.9096 (0.9618) acc 81.2500 (70.9115) lr 1.3681e-03 eta 0:14:06
epoch [21/50] batch [140/319] time 0.080 (0.089) data 0.000 (0.004) loss 1.8477 (1.9069) teacher_loss 0.8045 (0.8181) loss_zs_kd 1.7021 (1.4352) loss_oracle 1.2470 (1.2934) kd_loss 0.9186 (0.9595) acc 75.0000 (71.4955) lr 1.3681e-03 eta 0:13:58
epoch [21/50] batch [160/319] time 0.075 (0.088) data 0.000 (0.004) loss 1.7294 (1.9090) teacher_loss 0.7171 (0.8225) loss_zs_kd 1.5852 (1.4464) loss_oracle 1.0850 (1.2877) kd_loss 0.9039 (0.9577) acc 78.1250 (71.3281) lr 1.3681e-03 eta 0:13:50
epoch [21/50] batch [180/319] time 0.081 (0.088) data 0.000 (0.004) loss 2.0064 (1.9024) teacher_loss 0.9599 (0.8183) loss_zs_kd 1.5578 (1.4619) loss_oracle 1.2260 (1.2837) kd_loss 0.9239 (0.9557) acc 68.7500 (71.5278) lr 1.3681e-03 eta 0:13:43
epoch [21/50] batch [200/319] time 0.081 (0.087) data 0.000 (0.003) loss 2.2173 (1.9023) teacher_loss 1.0961 (0.8215) loss_zs_kd 1.6080 (1.4596) loss_oracle 1.3389 (1.2792) kd_loss 0.9874 (0.9529) acc 59.3750 (71.3125) lr 1.3681e-03 eta 0:13:37
epoch [21/50] batch [220/319] time 0.075 (0.087) data 0.000 (0.003) loss 1.7704 (1.9018) teacher_loss 0.7919 (0.8232) loss_zs_kd 1.2187 (1.4547) loss_oracle 1.1137 (1.2724) kd_loss 0.8672 (0.9514) acc 75.0000 (71.1932) lr 1.3681e-03 eta 0:13:31
epoch [21/50] batch [240/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.7931 (1.9018) teacher_loss 0.6991 (0.8251) loss_zs_kd 1.5855 (1.4517) loss_oracle 1.2117 (1.2723) kd_loss 0.9729 (0.9494) acc 75.0000 (71.1328) lr 1.3681e-03 eta 0:13:27
epoch [21/50] batch [260/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.8954 (1.9038) teacher_loss 0.9434 (0.8309) loss_zs_kd 1.7417 (1.4581) loss_oracle 1.1969 (1.2666) kd_loss 0.8323 (0.9463) acc 65.6250 (70.8053) lr 1.3681e-03 eta 0:13:22
epoch [21/50] batch [280/319] time 0.086 (0.086) data 0.000 (0.002) loss 1.9112 (1.9038) teacher_loss 0.8234 (0.8330) loss_zs_kd 1.4213 (1.4605) loss_oracle 1.1645 (1.2621) kd_loss 0.9713 (0.9446) acc 65.6250 (70.6696) lr 1.3681e-03 eta 0:13:18
epoch [21/50] batch [300/319] time 0.083 (0.086) data 0.000 (0.002) loss 1.7796 (1.8987) teacher_loss 0.7353 (0.8295) loss_zs_kd 1.2274 (1.4544) loss_oracle 1.3089 (1.2598) kd_loss 0.9133 (0.9433) acc 71.8750 (70.9479) lr 1.3681e-03 eta 0:13:13
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,664
* accuracy: 60.8%
* error: 39.2%
* macro_f1: 54.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,397
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 24.1%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [22/50] batch [20/319] time 0.082 (0.121) data 0.000 (0.033) loss 1.6762 (1.8422) teacher_loss 0.6990 (0.7967) loss_zs_kd 1.6529 (1.3984) loss_oracle 1.3075 (1.2236) kd_loss 0.8465 (0.9231) acc 75.0000 (74.2188) lr 1.3090e-03 eta 0:18:37
epoch [22/50] batch [40/319] time 0.080 (0.102) data 0.000 (0.017) loss 1.8135 (1.8186) teacher_loss 0.7951 (0.7714) loss_zs_kd 1.6465 (1.4080) loss_oracle 1.3031 (1.2477) kd_loss 0.8882 (0.9225) acc 75.0000 (74.2969) lr 1.3090e-03 eta 0:15:37
epoch [22/50] batch [60/319] time 0.079 (0.096) data 0.000 (0.011) loss 1.6961 (1.8275) teacher_loss 0.6884 (0.7857) loss_zs_kd 1.4029 (1.4046) loss_oracle 1.2675 (1.2409) kd_loss 0.8810 (0.9177) acc 81.2500 (74.4271) lr 1.3090e-03 eta 0:14:37
epoch [22/50] batch [80/319] time 0.083 (0.093) data 0.000 (0.008) loss 2.3427 (1.8469) teacher_loss 1.3925 (0.8033) loss_zs_kd 1.4126 (1.3964) loss_oracle 1.2542 (1.2416) kd_loss 0.8248 (0.9193) acc 50.0000 (73.1641) lr 1.3090e-03 eta 0:14:12
epoch [22/50] batch [100/319] time 0.089 (0.092) data 0.000 (0.007) loss 1.7511 (1.8571) teacher_loss 0.7259 (0.8084) loss_zs_kd 1.2580 (1.3869) loss_oracle 1.3505 (1.2480) kd_loss 0.8901 (0.9239) acc 71.8750 (72.0938) lr 1.3090e-03 eta 0:13:57
epoch [22/50] batch [120/319] time 0.090 (0.091) data 0.000 (0.006) loss 2.3161 (1.8721) teacher_loss 1.2563 (0.8201) loss_zs_kd 1.3912 (1.3904) loss_oracle 1.2810 (1.2533) kd_loss 0.9317 (0.9267) acc 65.6250 (72.0052) lr 1.3090e-03 eta 0:13:49
epoch [22/50] batch [140/319] time 0.079 (0.090) data 0.000 (0.005) loss 2.0008 (1.8842) teacher_loss 0.9523 (0.8308) loss_zs_kd 1.2076 (1.4023) loss_oracle 1.1508 (1.2553) kd_loss 0.9334 (0.9279) acc 65.6250 (71.4509) lr 1.3090e-03 eta 0:13:41
epoch [22/50] batch [160/319] time 0.082 (0.089) data 0.000 (0.004) loss 1.9656 (1.8894) teacher_loss 0.9369 (0.8357) loss_zs_kd 1.1574 (1.3919) loss_oracle 1.3780 (1.2581) kd_loss 0.8909 (0.9279) acc 81.2500 (71.4062) lr 1.3090e-03 eta 0:13:30
epoch [22/50] batch [180/319] time 0.081 (0.089) data 0.000 (0.004) loss 2.3936 (1.8839) teacher_loss 1.3453 (0.8299) loss_zs_kd 1.4336 (1.3873) loss_oracle 1.2219 (1.2608) kd_loss 0.9261 (0.9279) acc 53.1250 (71.4757) lr 1.3090e-03 eta 0:13:26
epoch [22/50] batch [200/319] time 0.073 (0.088) data 0.000 (0.004) loss 1.9011 (1.8849) teacher_loss 0.8470 (0.8301) loss_zs_kd 1.2552 (1.3760) loss_oracle 1.1915 (1.2648) kd_loss 0.9350 (0.9283) acc 78.1250 (71.5156) lr 1.3090e-03 eta 0:13:14
epoch [22/50] batch [220/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.9370 (1.8868) teacher_loss 0.8956 (0.8319) loss_zs_kd 1.1561 (1.3707) loss_oracle 1.1809 (1.2611) kd_loss 0.9233 (0.9288) acc 65.6250 (71.4205) lr 1.3090e-03 eta 0:13:08
epoch [22/50] batch [240/319] time 0.083 (0.087) data 0.000 (0.003) loss 2.1100 (1.8841) teacher_loss 1.0463 (0.8277) loss_zs_kd 1.5719 (1.3688) loss_oracle 1.1806 (1.2568) kd_loss 0.9456 (0.9307) acc 62.5000 (71.4323) lr 1.3090e-03 eta 0:13:03
epoch [22/50] batch [260/319] time 0.077 (0.087) data 0.000 (0.003) loss 1.9269 (1.8900) teacher_loss 0.7907 (0.8316) loss_zs_kd 1.2664 (1.3769) loss_oracle 1.2281 (1.2562) kd_loss 1.0134 (0.9328) acc 81.2500 (71.2981) lr 1.3090e-03 eta 0:12:59
epoch [22/50] batch [280/319] time 0.080 (0.086) data 0.000 (0.003) loss 1.6292 (1.8887) teacher_loss 0.5714 (0.8299) loss_zs_kd 1.3040 (1.3757) loss_oracle 1.3084 (1.2555) kd_loss 0.9270 (0.9333) acc 78.1250 (71.3504) lr 1.3090e-03 eta 0:12:55
epoch [22/50] batch [300/319] time 0.096 (0.087) data 0.000 (0.002) loss 2.0393 (1.8949) teacher_loss 0.9644 (0.8342) loss_zs_kd 1.5800 (1.3800) loss_oracle 1.1741 (1.2523) kd_loss 0.9575 (0.9355) acc 65.6250 (71.2812) lr 1.3090e-03 eta 0:13:02
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,621
* accuracy: 59.9%
* error: 40.1%
* macro_f1: 53.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,404
* accuracy: 55.5%
* error: 44.5%
* macro_f1: 22.6%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [23/50] batch [20/319] time 0.077 (0.115) data 0.000 (0.027) loss 2.0619 (1.9234) teacher_loss 1.0307 (0.8628) loss_zs_kd 1.3424 (1.4537) loss_oracle 1.3072 (1.2498) kd_loss 0.9005 (0.9356) acc 68.7500 (70.9375) lr 1.2487e-03 eta 0:17:04
epoch [23/50] batch [40/319] time 0.084 (0.100) data 0.000 (0.014) loss 1.8056 (1.9220) teacher_loss 0.7782 (0.8644) loss_zs_kd 1.5583 (1.4122) loss_oracle 1.2510 (1.2396) kd_loss 0.9024 (0.9337) acc 78.1250 (69.6875) lr 1.2487e-03 eta 0:14:46
epoch [23/50] batch [60/319] time 0.093 (0.095) data 0.000 (0.009) loss 2.0754 (1.9030) teacher_loss 1.0682 (0.8382) loss_zs_kd 1.4537 (1.4545) loss_oracle 1.1802 (1.2365) kd_loss 0.8892 (0.9412) acc 56.2500 (70.5729) lr 1.2487e-03 eta 0:14:01
epoch [23/50] batch [80/319] time 0.145 (0.097) data 0.000 (0.007) loss 1.5970 (1.8927) teacher_loss 0.6568 (0.8275) loss_zs_kd 1.6170 (1.4802) loss_oracle 1.3086 (1.2419) kd_loss 0.8093 (0.9411) acc 78.1250 (70.8984) lr 1.2487e-03 eta 0:14:21
epoch [23/50] batch [100/319] time 0.078 (0.094) data 0.000 (0.006) loss 1.8300 (1.9026) teacher_loss 0.6658 (0.8335) loss_zs_kd 1.6604 (1.4931) loss_oracle 1.2422 (1.2484) kd_loss 1.0400 (0.9443) acc 87.5000 (71.0312) lr 1.2487e-03 eta 0:13:52
epoch [23/50] batch [120/319] time 0.077 (0.092) data 0.000 (0.005) loss 1.7323 (1.9014) teacher_loss 0.6491 (0.8275) loss_zs_kd 1.4322 (1.4974) loss_oracle 1.3618 (1.2579) kd_loss 0.9469 (0.9480) acc 75.0000 (70.9896) lr 1.2487e-03 eta 0:13:33
epoch [23/50] batch [140/319] time 0.092 (0.091) data 0.001 (0.004) loss 1.7493 (1.9006) teacher_loss 0.7718 (0.8242) loss_zs_kd 1.4813 (1.5093) loss_oracle 1.3123 (1.2655) kd_loss 0.8463 (0.9498) acc 65.6250 (71.0268) lr 1.2487e-03 eta 0:13:23
epoch [23/50] batch [160/319] time 0.079 (0.091) data 0.000 (0.004) loss 1.7157 (1.9000) teacher_loss 0.6605 (0.8209) loss_zs_kd 1.4928 (1.5154) loss_oracle 1.3327 (1.2709) kd_loss 0.9220 (0.9520) acc 78.1250 (71.0938) lr 1.2487e-03 eta 0:13:13
epoch [23/50] batch [180/319] time 0.091 (0.090) data 0.000 (0.003) loss 2.1708 (1.8934) teacher_loss 1.0650 (0.8130) loss_zs_kd 1.5254 (1.5151) loss_oracle 1.3505 (1.2763) kd_loss 0.9708 (0.9529) acc 62.5000 (71.4583) lr 1.2487e-03 eta 0:13:06
epoch [23/50] batch [200/319] time 0.079 (0.090) data 0.000 (0.003) loss 1.5324 (1.8911) teacher_loss 0.4430 (0.8108) loss_zs_kd 1.3981 (1.5140) loss_oracle 1.3253 (1.2812) kd_loss 0.9568 (0.9522) acc 84.3750 (71.7031) lr 1.2487e-03 eta 0:13:01
epoch [23/50] batch [220/319] time 0.087 (0.089) data 0.000 (0.003) loss 2.0390 (1.8888) teacher_loss 0.9185 (0.8051) loss_zs_kd 1.5697 (1.5217) loss_oracle 1.3549 (1.2851) kd_loss 0.9850 (0.9552) acc 75.0000 (71.9460) lr 1.2487e-03 eta 0:12:56
epoch [23/50] batch [240/319] time 0.088 (0.089) data 0.000 (0.003) loss 1.5930 (1.8913) teacher_loss 0.5551 (0.8067) loss_zs_kd 1.4965 (1.5217) loss_oracle 1.2160 (1.2875) kd_loss 0.9164 (0.9559) acc 84.3750 (71.9271) lr 1.2487e-03 eta 0:12:52
epoch [23/50] batch [260/319] time 0.079 (0.089) data 0.000 (0.002) loss 1.8325 (1.8904) teacher_loss 0.8000 (0.8071) loss_zs_kd 1.5917 (1.5247) loss_oracle 1.2878 (1.2865) kd_loss 0.9037 (0.9547) acc 71.8750 (71.9351) lr 1.2487e-03 eta 0:12:47
epoch [23/50] batch [280/319] time 0.096 (0.089) data 0.001 (0.002) loss 1.7196 (1.8909) teacher_loss 0.6535 (0.8085) loss_zs_kd 1.5532 (1.5264) loss_oracle 1.1119 (1.2874) kd_loss 0.9549 (0.9536) acc 78.1250 (71.9085) lr 1.2487e-03 eta 0:12:49
epoch [23/50] batch [300/319] time 0.085 (0.089) data 0.000 (0.002) loss 2.0729 (1.8904) teacher_loss 0.9877 (0.8087) loss_zs_kd 1.4828 (1.5143) loss_oracle 1.2733 (1.2879) kd_loss 0.9579 (0.9529) acc 62.5000 (71.9479) lr 1.2487e-03 eta 0:12:47
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,643
* accuracy: 60.4%
* error: 39.6%
* macro_f1: 54.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,342
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 24.9%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [24/50] batch [20/319] time 0.083 (0.117) data 0.000 (0.031) loss 1.8180 (1.8678) teacher_loss 0.6631 (0.7933) loss_zs_kd 1.6305 (1.4557) loss_oracle 1.1610 (1.2075) kd_loss 1.0388 (0.9538) acc 81.2500 (73.5938) lr 1.1874e-03 eta 0:16:47
epoch [24/50] batch [40/319] time 0.078 (0.099) data 0.000 (0.016) loss 2.1059 (1.8454) teacher_loss 1.0968 (0.7852) loss_zs_kd 1.3473 (1.5007) loss_oracle 1.1851 (1.2251) kd_loss 0.8906 (0.9377) acc 62.5000 (73.5156) lr 1.1874e-03 eta 0:14:08
epoch [24/50] batch [60/319] time 0.079 (0.093) data 0.000 (0.011) loss 1.7950 (1.8699) teacher_loss 0.7542 (0.8196) loss_zs_kd 1.5877 (1.4692) loss_oracle 1.2651 (1.2295) kd_loss 0.9144 (0.9273) acc 71.8750 (72.6562) lr 1.1874e-03 eta 0:13:16
epoch [24/50] batch [80/319] time 0.087 (0.090) data 0.000 (0.008) loss 1.8032 (1.8550) teacher_loss 0.7702 (0.8052) loss_zs_kd 1.7644 (1.4593) loss_oracle 1.2357 (1.2370) kd_loss 0.9095 (0.9261) acc 75.0000 (73.2031) lr 1.1874e-03 eta 0:12:47
epoch [24/50] batch [100/319] time 0.079 (0.088) data 0.000 (0.006) loss 2.3655 (1.8605) teacher_loss 1.3361 (0.8092) loss_zs_kd 1.7988 (1.4763) loss_oracle 1.3175 (1.2389) kd_loss 0.8976 (0.9273) acc 50.0000 (72.9375) lr 1.1874e-03 eta 0:12:32
epoch [24/50] batch [120/319] time 0.079 (0.088) data 0.000 (0.005) loss 1.9277 (1.8705) teacher_loss 0.8643 (0.8220) loss_zs_kd 1.6233 (1.4840) loss_oracle 1.2592 (1.2354) kd_loss 0.9375 (0.9249) acc 62.5000 (71.9271) lr 1.1874e-03 eta 0:12:23
epoch [24/50] batch [140/319] time 0.085 (0.087) data 0.000 (0.005) loss 1.8270 (1.8700) teacher_loss 0.7849 (0.8206) loss_zs_kd 1.5319 (1.4842) loss_oracle 1.2964 (1.2343) kd_loss 0.9124 (0.9260) acc 68.7500 (71.8750) lr 1.1874e-03 eta 0:12:16
epoch [24/50] batch [160/319] time 0.082 (0.086) data 0.000 (0.004) loss 1.8930 (1.8660) teacher_loss 0.8795 (0.8177) loss_zs_kd 1.3610 (1.4796) loss_oracle 1.1634 (1.2333) kd_loss 0.8972 (0.9250) acc 62.5000 (71.7383) lr 1.1874e-03 eta 0:12:09
epoch [24/50] batch [180/319] time 0.086 (0.086) data 0.000 (0.004) loss 2.1500 (1.8753) teacher_loss 1.0808 (0.8280) loss_zs_kd 1.4876 (1.4849) loss_oracle 1.2302 (1.2318) kd_loss 0.9462 (0.9241) acc 62.5000 (71.3542) lr 1.1874e-03 eta 0:12:03
epoch [24/50] batch [200/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.8126 (1.8701) teacher_loss 0.8345 (0.8246) loss_zs_kd 1.5607 (1.4909) loss_oracle 1.1904 (1.2277) kd_loss 0.8590 (0.9228) acc 71.8750 (71.4531) lr 1.1874e-03 eta 0:12:00
epoch [24/50] batch [220/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.9506 (1.8695) teacher_loss 0.8767 (0.8231) loss_zs_kd 1.6863 (1.5007) loss_oracle 1.3122 (1.2257) kd_loss 0.9426 (0.9238) acc 59.3750 (71.4205) lr 1.1874e-03 eta 0:11:58
epoch [24/50] batch [240/319] time 0.076 (0.087) data 0.000 (0.003) loss 1.9816 (1.8673) teacher_loss 0.9505 (0.8190) loss_zs_kd 1.8424 (1.5119) loss_oracle 1.2983 (1.2282) kd_loss 0.9012 (0.9255) acc 59.3750 (71.5365) lr 1.1874e-03 eta 0:12:06
epoch [24/50] batch [260/319] time 0.085 (0.086) data 0.000 (0.003) loss 2.1247 (1.8716) teacher_loss 1.0366 (0.8215) loss_zs_kd 1.3872 (1.5174) loss_oracle 1.2975 (1.2303) kd_loss 0.9583 (0.9270) acc 65.6250 (71.4543) lr 1.1874e-03 eta 0:12:00
epoch [24/50] batch [280/319] time 0.084 (0.086) data 0.000 (0.002) loss 2.1000 (1.8769) teacher_loss 1.0141 (0.8263) loss_zs_kd 1.4175 (1.5219) loss_oracle 1.2925 (1.2328) kd_loss 0.9567 (0.9273) acc 56.2500 (71.2946) lr 1.1874e-03 eta 0:11:57
epoch [24/50] batch [300/319] time 0.078 (0.086) data 0.000 (0.002) loss 1.9414 (1.8772) teacher_loss 0.8501 (0.8264) loss_zs_kd 1.6827 (1.5205) loss_oracle 1.0915 (1.2328) kd_loss 0.9821 (0.9275) acc 75.0000 (71.2188) lr 1.1874e-03 eta 0:11:53
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,708
* accuracy: 61.9%
* error: 38.1%
* macro_f1: 54.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,564
* accuracy: 57.1%
* error: 42.9%
* macro_f1: 24.0%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [25/50] batch [20/319] time 0.155 (0.130) data 0.001 (0.028) loss 2.0520 (1.9156) teacher_loss 0.9653 (0.8345) loss_zs_kd 1.4003 (1.4809) loss_oracle 1.1399 (1.1851) kd_loss 0.9727 (0.9625) acc 59.3750 (70.4688) lr 1.1253e-03 eta 0:17:52
epoch [25/50] batch [40/319] time 0.073 (0.104) data 0.000 (0.014) loss 2.1983 (1.9347) teacher_loss 0.9789 (0.8578) loss_zs_kd 1.5505 (1.4828) loss_oracle 1.3120 (1.1999) kd_loss 1.0882 (0.9569) acc 62.5000 (69.6094) lr 1.1253e-03 eta 0:14:15
epoch [25/50] batch [60/319] time 0.084 (0.097) data 0.001 (0.010) loss 2.0721 (1.9069) teacher_loss 0.9680 (0.8324) loss_zs_kd 1.5219 (1.4700) loss_oracle 1.1973 (1.2265) kd_loss 0.9844 (0.9518) acc 75.0000 (70.8333) lr 1.1253e-03 eta 0:13:22
epoch [25/50] batch [80/319] time 0.084 (0.094) data 0.000 (0.007) loss 1.7092 (1.8962) teacher_loss 0.7193 (0.8281) loss_zs_kd 1.3854 (1.4712) loss_oracle 1.0742 (1.2235) kd_loss 0.8825 (0.9457) acc 75.0000 (70.7031) lr 1.1253e-03 eta 0:12:53
epoch [25/50] batch [100/319] time 0.088 (0.092) data 0.000 (0.006) loss 2.0284 (1.8884) teacher_loss 0.9932 (0.8180) loss_zs_kd 1.4351 (1.4577) loss_oracle 1.2380 (1.2261) kd_loss 0.9113 (0.9478) acc 71.8750 (71.5000) lr 1.1253e-03 eta 0:12:33
epoch [25/50] batch [120/319] time 0.076 (0.090) data 0.000 (0.005) loss 1.7562 (1.8931) teacher_loss 0.7404 (0.8223) loss_zs_kd 1.7038 (1.4497) loss_oracle 1.2276 (1.2266) kd_loss 0.8931 (0.9481) acc 71.8750 (71.4323) lr 1.1253e-03 eta 0:12:19
epoch [25/50] batch [140/319] time 0.084 (0.089) data 0.000 (0.004) loss 1.8104 (1.8927) teacher_loss 0.7229 (0.8223) loss_zs_kd 1.6821 (1.4531) loss_oracle 1.1868 (1.2259) kd_loss 0.9688 (0.9478) acc 78.1250 (71.4509) lr 1.1253e-03 eta 0:12:09
epoch [25/50] batch [160/319] time 0.079 (0.089) data 0.000 (0.004) loss 1.9442 (1.9007) teacher_loss 0.9994 (0.8318) loss_zs_kd 1.5118 (1.4518) loss_oracle 1.2258 (1.2277) kd_loss 0.8223 (0.9461) acc 56.2500 (71.0742) lr 1.1253e-03 eta 0:12:00
epoch [25/50] batch [180/319] time 0.081 (0.088) data 0.000 (0.003) loss 1.8380 (1.9009) teacher_loss 0.7495 (0.8334) loss_zs_kd 1.2304 (1.4422) loss_oracle 1.3279 (1.2305) kd_loss 0.9557 (0.9444) acc 68.7500 (70.8854) lr 1.1253e-03 eta 0:11:54
epoch [25/50] batch [200/319] time 0.085 (0.088) data 0.000 (0.003) loss 1.8196 (1.8955) teacher_loss 0.7791 (0.8281) loss_zs_kd 1.5045 (1.4468) loss_oracle 1.2425 (1.2364) kd_loss 0.9163 (0.9438) acc 65.6250 (71.1562) lr 1.1253e-03 eta 0:11:51
epoch [25/50] batch [220/319] time 0.079 (0.087) data 0.000 (0.003) loss 1.8204 (1.8964) teacher_loss 0.7449 (0.8299) loss_zs_kd 1.4564 (1.4430) loss_oracle 1.3125 (1.2406) kd_loss 0.9442 (0.9425) acc 65.6250 (71.1648) lr 1.1253e-03 eta 0:11:46
epoch [25/50] batch [240/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.8750 (1.8932) teacher_loss 0.7743 (0.8250) loss_zs_kd 1.4549 (1.4373) loss_oracle 1.3184 (1.2451) kd_loss 0.9688 (0.9437) acc 59.3750 (71.1849) lr 1.1253e-03 eta 0:11:39
epoch [25/50] batch [260/319] time 0.081 (0.087) data 0.000 (0.002) loss 1.8712 (1.8971) teacher_loss 0.7687 (0.8280) loss_zs_kd 1.4778 (1.4312) loss_oracle 1.3040 (1.2455) kd_loss 0.9720 (0.9445) acc 62.5000 (70.9976) lr 1.1253e-03 eta 0:11:35
epoch [25/50] batch [280/319] time 0.080 (0.086) data 0.000 (0.002) loss 1.9970 (1.9014) teacher_loss 1.0219 (0.8328) loss_zs_kd 1.3068 (1.4231) loss_oracle 1.1464 (1.2441) kd_loss 0.8604 (0.9442) acc 56.2500 (70.8147) lr 1.1253e-03 eta 0:11:31
epoch [25/50] batch [300/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.9568 (1.9088) teacher_loss 0.9731 (0.8403) loss_zs_kd 1.2237 (1.4175) loss_oracle 1.2425 (1.2455) kd_loss 0.8594 (0.9439) acc 68.7500 (70.4479) lr 1.1253e-03 eta 0:11:28
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,531
* accuracy: 57.8%
* error: 42.2%
* macro_f1: 54.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,623
* accuracy: 57.8%
* error: 42.2%
* macro_f1: 23.6%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [26/50] batch [20/319] time 0.083 (0.111) data 0.000 (0.029) loss 2.0394 (1.9767) teacher_loss 0.8961 (0.9135) loss_zs_kd 1.2005 (1.5126) loss_oracle 1.1844 (1.2361) kd_loss 1.0248 (0.9396) acc 65.6250 (68.1250) lr 1.0628e-03 eta 0:14:45
epoch [26/50] batch [40/319] time 0.085 (0.097) data 0.000 (0.015) loss 1.7593 (1.9407) teacher_loss 0.7220 (0.8858) loss_zs_kd 1.2706 (1.4057) loss_oracle 1.2332 (1.2489) kd_loss 0.9140 (0.9301) acc 84.3750 (68.9062) lr 1.0628e-03 eta 0:12:52
epoch [26/50] batch [60/319] time 0.087 (0.093) data 0.001 (0.010) loss 1.6952 (1.9024) teacher_loss 0.7576 (0.8531) loss_zs_kd 1.2080 (1.3872) loss_oracle 1.2498 (1.2525) kd_loss 0.8127 (0.9241) acc 78.1250 (70.2604) lr 1.0628e-03 eta 0:12:16
epoch [26/50] batch [80/319] time 0.083 (0.090) data 0.000 (0.007) loss 1.9689 (1.9111) teacher_loss 0.8534 (0.8571) loss_zs_kd 1.6551 (1.4020) loss_oracle 1.2723 (1.2650) kd_loss 0.9883 (0.9275) acc 62.5000 (70.2734) lr 1.0628e-03 eta 0:11:49
epoch [26/50] batch [100/319] time 0.079 (0.088) data 0.000 (0.006) loss 1.8531 (1.9195) teacher_loss 0.8655 (0.8655) loss_zs_kd 1.3365 (1.4129) loss_oracle 1.1879 (1.2634) kd_loss 0.8688 (0.9276) acc 71.8750 (69.6875) lr 1.0628e-03 eta 0:11:35
epoch [26/50] batch [120/319] time 0.083 (0.087) data 0.000 (0.005) loss 2.0653 (1.9149) teacher_loss 1.0405 (0.8569) loss_zs_kd 1.5384 (1.4192) loss_oracle 1.1858 (1.2616) kd_loss 0.9062 (0.9319) acc 50.0000 (69.5052) lr 1.0628e-03 eta 0:11:27
epoch [26/50] batch [140/319] time 0.076 (0.087) data 0.000 (0.004) loss 2.0013 (1.9153) teacher_loss 0.9066 (0.8580) loss_zs_kd 1.2470 (1.4139) loss_oracle 1.2637 (1.2577) kd_loss 0.9684 (0.9315) acc 62.5000 (69.3304) lr 1.0628e-03 eta 0:11:22
epoch [26/50] batch [160/319] time 0.093 (0.087) data 0.001 (0.004) loss 1.7672 (1.9075) teacher_loss 0.7618 (0.8530) loss_zs_kd 1.2556 (1.4002) loss_oracle 1.2389 (1.2574) kd_loss 0.8815 (0.9288) acc 71.8750 (69.3750) lr 1.0628e-03 eta 0:11:17
epoch [26/50] batch [180/319] time 0.087 (0.086) data 0.000 (0.003) loss 1.9185 (1.9062) teacher_loss 0.8511 (0.8515) loss_zs_kd 1.4330 (1.4050) loss_oracle 1.2435 (1.2585) kd_loss 0.9431 (0.9288) acc 71.8750 (69.4792) lr 1.0628e-03 eta 0:11:12
epoch [26/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.003) loss 2.0509 (1.9029) teacher_loss 0.9614 (0.8486) loss_zs_kd 1.2728 (1.4010) loss_oracle 1.2565 (1.2610) kd_loss 0.9639 (0.9283) acc 75.0000 (69.6875) lr 1.0628e-03 eta 0:11:08
epoch [26/50] batch [220/319] time 0.086 (0.087) data 0.000 (0.003) loss 1.6322 (1.9029) teacher_loss 0.5582 (0.8495) loss_zs_kd 1.0758 (1.3998) loss_oracle 1.2853 (1.2605) kd_loss 0.9455 (0.9274) acc 78.1250 (69.5739) lr 1.0628e-03 eta 0:11:12
epoch [26/50] batch [240/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.7571 (1.9056) teacher_loss 0.7167 (0.8511) loss_zs_kd 1.4873 (1.3980) loss_oracle 1.3214 (1.2605) kd_loss 0.9082 (0.9284) acc 78.1250 (69.5443) lr 1.0628e-03 eta 0:11:11
epoch [26/50] batch [260/319] time 0.092 (0.087) data 0.000 (0.003) loss 1.7632 (1.9002) teacher_loss 0.7120 (0.8454) loss_zs_kd 1.1625 (1.3966) loss_oracle 1.2278 (1.2596) kd_loss 0.9284 (0.9289) acc 78.1250 (69.6995) lr 1.0628e-03 eta 0:11:09
epoch [26/50] batch [280/319] time 0.076 (0.087) data 0.000 (0.002) loss 1.8664 (1.9025) teacher_loss 0.7644 (0.8464) loss_zs_kd 1.4234 (1.3976) loss_oracle 1.1925 (1.2590) kd_loss 0.9827 (0.9302) acc 62.5000 (69.7768) lr 1.0628e-03 eta 0:11:08
epoch [26/50] batch [300/319] time 0.087 (0.087) data 0.000 (0.002) loss 2.3141 (1.9082) teacher_loss 1.2771 (0.8499) loss_zs_kd 1.5027 (1.3998) loss_oracle 1.1815 (1.2579) kd_loss 0.9188 (0.9326) acc 50.0000 (69.5417) lr 1.0628e-03 eta 0:11:05
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,659
* accuracy: 60.7%
* error: 39.3%
* macro_f1: 54.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,616
* accuracy: 57.7%
* error: 42.3%
* macro_f1: 25.0%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [27/50] batch [20/319] time 0.080 (0.110) data 0.000 (0.024) loss 1.6602 (1.9067) teacher_loss 0.5264 (0.8102) loss_zs_kd 1.3496 (1.5224) loss_oracle 1.2963 (1.2680) kd_loss 1.0042 (0.9697) acc 84.3750 (70.9375) lr 1.0000e-03 eta 0:13:56
epoch [27/50] batch [40/319] time 0.085 (0.097) data 0.000 (0.012) loss 1.7239 (1.9258) teacher_loss 0.5481 (0.8223) loss_zs_kd 1.7592 (1.5501) loss_oracle 1.3490 (1.2874) kd_loss 1.0409 (0.9748) acc 84.3750 (71.0938) lr 1.0000e-03 eta 0:12:16
epoch [27/50] batch [60/319] time 0.085 (0.093) data 0.001 (0.008) loss 1.8190 (1.9084) teacher_loss 0.8321 (0.8103) loss_zs_kd 1.6623 (1.5357) loss_oracle 1.0866 (1.2803) kd_loss 0.8782 (0.9701) acc 68.7500 (71.6146) lr 1.0000e-03 eta 0:11:47
epoch [27/50] batch [80/319] time 0.089 (0.091) data 0.000 (0.006) loss 1.9605 (1.9088) teacher_loss 0.9388 (0.8132) loss_zs_kd 1.7730 (1.5363) loss_oracle 1.3381 (1.2802) kd_loss 0.8879 (0.9676) acc 56.2500 (71.3672) lr 1.0000e-03 eta 0:11:30
epoch [27/50] batch [100/319] time 0.086 (0.090) data 0.000 (0.005) loss 2.1394 (1.9080) teacher_loss 1.0491 (0.8165) loss_zs_kd 1.5123 (1.5320) loss_oracle 1.3908 (1.2786) kd_loss 0.9513 (0.9636) acc 59.3750 (70.9688) lr 1.0000e-03 eta 0:11:20
epoch [27/50] batch [120/319] time 0.077 (0.089) data 0.000 (0.004) loss 2.0023 (1.9228) teacher_loss 0.9197 (0.8315) loss_zs_kd 1.5055 (1.5148) loss_oracle 1.2815 (1.2762) kd_loss 0.9545 (0.9637) acc 65.6250 (70.5990) lr 1.0000e-03 eta 0:11:10
epoch [27/50] batch [140/319] time 0.082 (0.087) data 0.000 (0.004) loss 1.7260 (1.9232) teacher_loss 0.7021 (0.8344) loss_zs_kd 1.3313 (1.4954) loss_oracle 1.2834 (1.2784) kd_loss 0.8956 (0.9610) acc 78.1250 (70.6250) lr 1.0000e-03 eta 0:10:56
epoch [27/50] batch [160/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.6770 (1.9165) teacher_loss 0.5914 (0.8287) loss_zs_kd 1.3493 (1.4862) loss_oracle 1.2809 (1.2841) kd_loss 0.9575 (0.9593) acc 84.3750 (71.0156) lr 1.0000e-03 eta 0:10:49
epoch [27/50] batch [180/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.6806 (1.9165) teacher_loss 0.5892 (0.8283) loss_zs_kd 1.2059 (1.4761) loss_oracle 1.2787 (1.2900) kd_loss 0.9635 (0.9592) acc 84.3750 (71.1285) lr 1.0000e-03 eta 0:10:46
epoch [27/50] batch [200/319] time 0.077 (0.086) data 0.000 (0.003) loss 1.6248 (1.9134) teacher_loss 0.5535 (0.8296) loss_zs_kd 1.7292 (1.4703) loss_oracle 1.3270 (1.2900) kd_loss 0.9386 (0.9547) acc 87.5000 (71.0781) lr 1.0000e-03 eta 0:10:42
epoch [27/50] batch [220/319] time 0.078 (0.086) data 0.000 (0.002) loss 1.8809 (1.9097) teacher_loss 0.8473 (0.8265) loss_zs_kd 1.4050 (1.4721) loss_oracle 1.3357 (1.2928) kd_loss 0.9001 (0.9539) acc 62.5000 (71.3352) lr 1.0000e-03 eta 0:10:38
epoch [27/50] batch [240/319] time 0.079 (0.086) data 0.000 (0.002) loss 2.0357 (1.9137) teacher_loss 0.9913 (0.8278) loss_zs_kd 1.1609 (1.4580) loss_oracle 1.2839 (1.2965) kd_loss 0.9160 (0.9563) acc 62.5000 (71.4714) lr 1.0000e-03 eta 0:10:36
epoch [27/50] batch [260/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.8644 (1.9147) teacher_loss 0.8093 (0.8286) loss_zs_kd 1.2846 (1.4410) loss_oracle 1.2721 (1.2966) kd_loss 0.9279 (0.9565) acc 68.7500 (71.4663) lr 1.0000e-03 eta 0:10:32
epoch [27/50] batch [280/319] time 0.088 (0.085) data 0.000 (0.002) loss 2.0666 (1.9175) teacher_loss 1.0301 (0.8314) loss_zs_kd 1.3706 (1.4231) loss_oracle 1.2306 (1.2985) kd_loss 0.9134 (0.9563) acc 56.2500 (71.4062) lr 1.0000e-03 eta 0:10:30
epoch [27/50] batch [300/319] time 0.085 (0.085) data 0.000 (0.002) loss 2.3309 (1.9110) teacher_loss 1.0913 (0.8242) loss_zs_kd 1.7394 (1.4117) loss_oracle 1.3169 (1.2999) kd_loss 1.1080 (0.9568) acc 65.6250 (71.7083) lr 1.0000e-03 eta 0:10:28
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,542
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 51.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,303
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 21.2%
******* Domain 2 best val acc:      61.9%, epoch: 19 *******
******* Domain 2 best val test acc: 55.7%, epoch: 19 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [28/50] batch [20/319] time 0.084 (0.118) data 0.000 (0.033) loss 1.9924 (1.9092) teacher_loss 0.9017 (0.7990) loss_zs_kd 1.3905 (1.2856) loss_oracle 1.2491 (1.2990) kd_loss 0.9658 (0.9803) acc 62.5000 (72.0312) lr 9.3721e-04 eta 0:14:21
epoch [28/50] batch [40/319] time 0.075 (0.102) data 0.000 (0.016) loss 2.1073 (1.9306) teacher_loss 0.9785 (0.8198) loss_zs_kd 1.4958 (1.2621) loss_oracle 1.3044 (1.2946) kd_loss 0.9983 (0.9813) acc 59.3750 (70.8594) lr 9.3721e-04 eta 0:12:23
epoch [28/50] batch [60/319] time 0.087 (0.096) data 0.001 (0.011) loss 1.8318 (1.9565) teacher_loss 0.6848 (0.8467) loss_zs_kd 1.3529 (1.2856) loss_oracle 1.3815 (1.2958) kd_loss 1.0088 (0.9803) acc 84.3750 (70.1562) lr 9.3721e-04 eta 0:11:36
epoch [28/50] batch [80/319] time 0.085 (0.092) data 0.000 (0.008) loss 1.8043 (1.9320) teacher_loss 0.6557 (0.8191) loss_zs_kd 1.2455 (1.2796) loss_oracle 1.2666 (1.2922) kd_loss 1.0219 (0.9837) acc 75.0000 (70.7812) lr 9.3721e-04 eta 0:11:05
epoch [28/50] batch [100/319] time 0.083 (0.090) data 0.000 (0.007) loss 1.9102 (1.9218) teacher_loss 0.7712 (0.8097) loss_zs_kd 1.3925 (1.3040) loss_oracle 1.3070 (1.2930) kd_loss 1.0082 (0.9828) acc 68.7500 (71.3125) lr 9.3721e-04 eta 0:10:54
epoch [28/50] batch [120/319] time 0.081 (0.089) data 0.000 (0.006) loss 1.7947 (1.9041) teacher_loss 0.7216 (0.7933) loss_zs_kd 1.5966 (1.3076) loss_oracle 1.3800 (1.2956) kd_loss 0.9351 (0.9813) acc 78.1250 (72.1875) lr 9.3721e-04 eta 0:10:45
epoch [28/50] batch [140/319] time 0.085 (0.089) data 0.000 (0.005) loss 1.7356 (1.8996) teacher_loss 0.6499 (0.7920) loss_zs_kd 1.4364 (1.3172) loss_oracle 1.3345 (1.2928) kd_loss 0.9522 (0.9783) acc 68.7500 (72.1205) lr 9.3721e-04 eta 0:10:40
epoch [28/50] batch [160/319] time 0.090 (0.089) data 0.000 (0.004) loss 1.6520 (1.8977) teacher_loss 0.5137 (0.7903) loss_zs_kd 1.4996 (1.3240) loss_oracle 1.2280 (1.2887) kd_loss 1.0156 (0.9785) acc 84.3750 (72.3438) lr 9.3721e-04 eta 0:10:35
epoch [28/50] batch [180/319] time 0.084 (0.089) data 0.000 (0.004) loss 1.6496 (1.8874) teacher_loss 0.6537 (0.7838) loss_zs_kd 1.2301 (1.3210) loss_oracle 1.2067 (1.2883) kd_loss 0.8753 (0.9748) acc 81.2500 (72.4479) lr 9.3721e-04 eta 0:10:38
epoch [28/50] batch [200/319] time 0.084 (0.089) data 0.000 (0.004) loss 1.8512 (1.8856) teacher_loss 0.8058 (0.7865) loss_zs_kd 1.4581 (1.3245) loss_oracle 1.3087 (1.2894) kd_loss 0.9146 (0.9702) acc 71.8750 (72.3125) lr 9.3721e-04 eta 0:10:32
epoch [28/50] batch [220/319] time 0.095 (0.088) data 0.001 (0.003) loss 2.4366 (1.8918) teacher_loss 1.2925 (0.7924) loss_zs_kd 1.2070 (1.3342) loss_oracle 1.4159 (1.2900) kd_loss 1.0025 (0.9704) acc 50.0000 (72.1307) lr 9.3721e-04 eta 0:10:25
epoch [28/50] batch [240/319] time 0.078 (0.088) data 0.000 (0.003) loss 2.0039 (1.8938) teacher_loss 0.8169 (0.7932) loss_zs_kd 1.2070 (1.3327) loss_oracle 1.2346 (1.2897) kd_loss 1.0636 (0.9716) acc 75.0000 (72.1745) lr 9.3721e-04 eta 0:10:23
epoch [28/50] batch [260/319] time 0.087 (0.087) data 0.000 (0.003) loss 1.7281 (1.8909) teacher_loss 0.6209 (0.7900) loss_zs_kd 1.3677 (1.3330) loss_oracle 1.1691 (1.2860) kd_loss 0.9903 (0.9723) acc 87.5000 (72.3438) lr 9.3721e-04 eta 0:10:16
epoch [28/50] batch [280/319] time 0.080 (0.087) data 0.000 (0.003) loss 1.7675 (1.8882) teacher_loss 0.7288 (0.7891) loss_zs_kd 1.3749 (1.3393) loss_oracle 1.2392 (1.2845) kd_loss 0.9148 (0.9707) acc 75.0000 (72.3661) lr 9.3721e-04 eta 0:10:12
epoch [28/50] batch [300/319] time 0.075 (0.086) data 0.000 (0.002) loss 2.1510 (1.8871) teacher_loss 1.0890 (0.7885) loss_zs_kd 1.4146 (1.3462) loss_oracle 1.2785 (1.2810) kd_loss 0.9342 (0.9704) acc 65.6250 (72.4062) lr 9.3721e-04 eta 0:10:08
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,729
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 55.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,629
* accuracy: 57.8%
* error: 42.2%
* macro_f1: 24.8%
******* Domain 2 best val acc:      62.3%, epoch: 28 *******
******* Domain 2 best val test acc: 57.8%, epoch: 28 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [29/50] batch [20/319] time 0.088 (0.110) data 0.000 (0.022) loss 1.8398 (1.8246) teacher_loss 0.7728 (0.7484) loss_zs_kd 1.3310 (1.3370) loss_oracle 1.2903 (1.2546) kd_loss 0.9380 (0.9507) acc 78.1250 (74.3750) lr 8.7467e-04 eta 0:12:46
epoch [29/50] batch [40/319] time 0.076 (0.094) data 0.000 (0.011) loss 1.8390 (1.8412) teacher_loss 0.6527 (0.7592) loss_zs_kd 1.4084 (1.3600) loss_oracle 1.4705 (1.2591) kd_loss 1.0392 (0.9561) acc 84.3750 (73.4375) lr 8.7467e-04 eta 0:10:56
epoch [29/50] batch [60/319] time 0.079 (0.089) data 0.000 (0.008) loss 1.7459 (1.8544) teacher_loss 0.6147 (0.7721) loss_zs_kd 1.3988 (1.3823) loss_oracle 1.2684 (1.2635) kd_loss 1.0043 (0.9559) acc 81.2500 (72.9167) lr 8.7467e-04 eta 0:10:19
epoch [29/50] batch [80/319] time 0.086 (0.088) data 0.000 (0.006) loss 1.6515 (1.8504) teacher_loss 0.6268 (0.7692) loss_zs_kd 1.5493 (1.4008) loss_oracle 1.2241 (1.2680) kd_loss 0.9023 (0.9544) acc 81.2500 (73.2422) lr 8.7467e-04 eta 0:10:12
epoch [29/50] batch [100/319] time 0.081 (0.087) data 0.000 (0.005) loss 1.8183 (1.8515) teacher_loss 0.7247 (0.7662) loss_zs_kd 1.6426 (1.4096) loss_oracle 1.2665 (1.2721) kd_loss 0.9669 (0.9580) acc 71.8750 (73.1562) lr 8.7467e-04 eta 0:10:04
epoch [29/50] batch [120/319] time 0.092 (0.087) data 0.000 (0.004) loss 1.9206 (1.8499) teacher_loss 0.7821 (0.7635) loss_zs_kd 1.3835 (1.4263) loss_oracle 1.3399 (1.2757) kd_loss 1.0045 (0.9588) acc 78.1250 (73.4375) lr 8.7467e-04 eta 0:09:59
epoch [29/50] batch [140/319] time 0.088 (0.087) data 0.000 (0.003) loss 2.0759 (1.8521) teacher_loss 0.9201 (0.7614) loss_zs_kd 1.8016 (1.4431) loss_oracle 1.4268 (1.2750) kd_loss 1.0131 (0.9632) acc 65.6250 (73.4598) lr 8.7467e-04 eta 0:09:55
epoch [29/50] batch [160/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.9663 (1.8700) teacher_loss 0.8562 (0.7758) loss_zs_kd 1.3870 (1.4542) loss_oracle 1.3913 (1.2796) kd_loss 0.9710 (0.9663) acc 78.1250 (72.9492) lr 8.7467e-04 eta 0:09:53
epoch [29/50] batch [180/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.9012 (1.8863) teacher_loss 0.7643 (0.7860) loss_zs_kd 1.2403 (1.4617) loss_oracle 1.1509 (1.2792) kd_loss 1.0218 (0.9723) acc 71.8750 (72.4479) lr 8.7467e-04 eta 0:09:51
epoch [29/50] batch [200/319] time 0.096 (0.086) data 0.000 (0.003) loss 2.1930 (1.9052) teacher_loss 1.0012 (0.8004) loss_zs_kd 1.5638 (1.4662) loss_oracle 1.2150 (1.2795) kd_loss 1.0703 (0.9769) acc 62.5000 (72.1562) lr 8.7467e-04 eta 0:09:48
epoch [29/50] batch [220/319] time 0.086 (0.086) data 0.000 (0.002) loss 2.2757 (1.9139) teacher_loss 1.1833 (0.8068) loss_zs_kd 1.2732 (1.4562) loss_oracle 1.3459 (1.2801) kd_loss 0.9578 (0.9791) acc 50.0000 (71.9176) lr 8.7467e-04 eta 0:09:44
epoch [29/50] batch [240/319] time 0.080 (0.086) data 0.000 (0.002) loss 2.2217 (1.9262) teacher_loss 0.9599 (0.8167) loss_zs_kd 1.5810 (1.4527) loss_oracle 1.3841 (1.2796) kd_loss 1.1234 (0.9815) acc 71.8750 (71.4844) lr 8.7467e-04 eta 0:09:40
epoch [29/50] batch [260/319] time 0.090 (0.086) data 0.000 (0.002) loss 2.1349 (1.9382) teacher_loss 0.9604 (0.8266) loss_zs_kd 1.4412 (1.4440) loss_oracle 1.2547 (1.2799) kd_loss 1.0491 (0.9836) acc 71.8750 (71.0817) lr 8.7467e-04 eta 0:09:38
epoch [29/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.7623 (1.9408) teacher_loss 0.7555 (0.8297) loss_zs_kd 1.3196 (1.4349) loss_oracle 1.3148 (1.2798) kd_loss 0.8753 (0.9831) acc 78.1250 (70.9263) lr 8.7467e-04 eta 0:09:35
epoch [29/50] batch [300/319] time 0.082 (0.085) data 0.000 (0.002) loss 2.0880 (1.9449) teacher_loss 0.8983 (0.8335) loss_zs_kd 1.4338 (1.4303) loss_oracle 1.2812 (1.2785) kd_loss 1.0616 (0.9836) acc 75.0000 (70.8125) lr 8.7467e-04 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,746
* accuracy: 62.7%
* error: 37.3%
* macro_f1: 55.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,457
* accuracy: 56.0%
* error: 44.0%
* macro_f1: 22.4%
******* Domain 2 best val acc:      62.7%, epoch: 29 *******
******* Domain 2 best val test acc: 56.0%, epoch: 29 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [30/50] batch [20/319] time 0.099 (0.120) data 0.000 (0.029) loss 1.6821 (2.0029) teacher_loss 0.6080 (0.8728) loss_zs_kd 1.2203 (1.3139) loss_oracle 1.2786 (1.2642) kd_loss 0.9463 (1.0037) acc 84.3750 (69.5312) lr 8.1262e-04 eta 0:13:21
epoch [30/50] batch [40/319] time 0.084 (0.101) data 0.000 (0.015) loss 1.9005 (2.0402) teacher_loss 0.7137 (0.9002) loss_zs_kd 1.3958 (1.3557) loss_oracle 1.3659 (1.2747) kd_loss 1.0502 (1.0126) acc 68.7500 (68.7500) lr 8.1262e-04 eta 0:11:09
epoch [30/50] batch [60/319] time 0.081 (0.095) data 0.001 (0.010) loss 1.9110 (2.0508) teacher_loss 0.7801 (0.9074) loss_zs_kd 1.5153 (1.3691) loss_oracle 1.3511 (1.2797) kd_loss 0.9958 (1.0154) acc 68.7500 (68.1250) lr 8.1262e-04 eta 0:10:33
epoch [30/50] batch [80/319] time 0.083 (0.093) data 0.000 (0.008) loss 1.9146 (2.0682) teacher_loss 0.8207 (0.9133) loss_zs_kd 1.3050 (1.3912) loss_oracle 1.1576 (1.2846) kd_loss 0.9781 (1.0264) acc 65.6250 (67.8516) lr 8.1262e-04 eta 0:10:16
epoch [30/50] batch [100/319] time 0.083 (0.092) data 0.000 (0.006) loss 2.1089 (2.0779) teacher_loss 0.9615 (0.9141) loss_zs_kd 1.3084 (1.3672) loss_oracle 1.2985 (1.2861) kd_loss 1.0175 (1.0352) acc 68.7500 (68.0000) lr 8.1262e-04 eta 0:10:08
epoch [30/50] batch [120/319] time 0.114 (0.093) data 0.000 (0.005) loss 2.0416 (2.0819) teacher_loss 0.9290 (0.9249) loss_zs_kd 1.4065 (1.3601) loss_oracle 1.4077 (1.2828) kd_loss 0.9719 (1.0287) acc 62.5000 (67.5260) lr 8.1262e-04 eta 0:10:09
epoch [30/50] batch [140/319] time 0.086 (0.091) data 0.000 (0.004) loss 1.8281 (2.0662) teacher_loss 0.7332 (0.9150) loss_zs_kd 1.2563 (1.3650) loss_oracle 1.2049 (1.2807) kd_loss 0.9745 (1.0232) acc 71.8750 (67.8125) lr 8.1262e-04 eta 0:09:59
epoch [30/50] batch [160/319] time 0.078 (0.090) data 0.000 (0.004) loss 1.7706 (2.0562) teacher_loss 0.7059 (0.9121) loss_zs_kd 1.3499 (1.3792) loss_oracle 1.2867 (1.2790) kd_loss 0.9360 (1.0162) acc 71.8750 (67.6953) lr 8.1262e-04 eta 0:09:49
epoch [30/50] batch [180/319] time 0.089 (0.090) data 0.000 (0.004) loss 1.9829 (2.0527) teacher_loss 0.8485 (0.9125) loss_zs_kd 1.5653 (1.3776) loss_oracle 1.2041 (1.2710) kd_loss 1.0140 (1.0131) acc 65.6250 (67.5000) lr 8.1262e-04 eta 0:09:44
epoch [30/50] batch [200/319] time 0.088 (0.089) data 0.000 (0.003) loss 2.0964 (2.0447) teacher_loss 0.9497 (0.9087) loss_zs_kd 1.4237 (1.3829) loss_oracle 1.1469 (1.2643) kd_loss 1.0320 (1.0096) acc 65.6250 (67.6094) lr 8.1262e-04 eta 0:09:41
epoch [30/50] batch [220/319] time 0.094 (0.089) data 0.000 (0.003) loss 1.8714 (2.0406) teacher_loss 0.7769 (0.9095) loss_zs_kd 1.4275 (1.3923) loss_oracle 1.2394 (1.2603) kd_loss 0.9705 (1.0050) acc 75.0000 (67.5994) lr 8.1262e-04 eta 0:09:35
epoch [30/50] batch [240/319] time 0.081 (0.088) data 0.000 (0.003) loss 1.9770 (2.0443) teacher_loss 0.7619 (0.9151) loss_zs_kd 1.3474 (1.4008) loss_oracle 1.2422 (1.2586) kd_loss 1.0909 (1.0033) acc 78.1250 (67.2526) lr 8.1262e-04 eta 0:09:30
epoch [30/50] batch [260/319] time 0.076 (0.088) data 0.000 (0.003) loss 1.9536 (2.0399) teacher_loss 0.7673 (0.9130) loss_zs_kd 1.4407 (1.4029) loss_oracle 1.2836 (1.2580) kd_loss 1.0580 (1.0011) acc 78.1250 (67.3077) lr 8.1262e-04 eta 0:09:25
epoch [30/50] batch [280/319] time 0.087 (0.087) data 0.000 (0.002) loss 1.8818 (2.0285) teacher_loss 0.7472 (0.9060) loss_zs_kd 1.4325 (1.4051) loss_oracle 1.2971 (1.2551) kd_loss 1.0049 (0.9970) acc 81.2500 (67.6004) lr 8.1262e-04 eta 0:09:20
epoch [30/50] batch [300/319] time 0.086 (0.087) data 0.000 (0.002) loss 2.3366 (2.0273) teacher_loss 1.2285 (0.9047) loss_zs_kd 1.2412 (1.4058) loss_oracle 1.3021 (1.2550) kd_loss 0.9779 (0.9971) acc 59.3750 (67.7396) lr 8.1262e-04 eta 0:09:17
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,725
* accuracy: 62.2%
* error: 37.8%
* macro_f1: 57.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,552
* accuracy: 57.0%
* error: 43.0%
* macro_f1: 23.3%
******* Domain 2 best val acc:      62.7%, epoch: 29 *******
******* Domain 2 best val test acc: 56.0%, epoch: 29 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [31/50] batch [20/319] time 0.091 (0.114) data 0.000 (0.030) loss 1.9106 (1.9964) teacher_loss 0.7332 (0.8416) loss_zs_kd 1.5166 (1.3732) loss_oracle 1.2306 (1.2905) kd_loss 1.0544 (1.0257) acc 84.3750 (71.4062) lr 7.5131e-04 eta 0:12:05
epoch [31/50] batch [40/319] time 0.092 (0.099) data 0.000 (0.015) loss 2.1553 (2.0198) teacher_loss 0.9793 (0.8724) loss_zs_kd 1.1941 (1.3831) loss_oracle 1.3193 (1.2905) kd_loss 1.0441 (1.0184) acc 59.3750 (69.6094) lr 7.5131e-04 eta 0:10:26
epoch [31/50] batch [60/319] time 0.078 (0.095) data 0.001 (0.010) loss 2.1491 (2.0343) teacher_loss 0.9389 (0.8920) loss_zs_kd 1.3184 (1.3683) loss_oracle 1.3458 (1.2916) kd_loss 1.0756 (1.0131) acc 62.5000 (68.8021) lr 7.5131e-04 eta 0:09:57
epoch [31/50] batch [80/319] time 0.083 (0.092) data 0.000 (0.008) loss 2.1259 (2.0215) teacher_loss 0.9326 (0.8909) loss_zs_kd 1.3898 (1.3535) loss_oracle 1.3066 (1.2844) kd_loss 1.0627 (1.0022) acc 59.3750 (68.3984) lr 7.5131e-04 eta 0:09:38
epoch [31/50] batch [100/319] time 0.087 (0.090) data 0.000 (0.006) loss 2.3190 (2.0154) teacher_loss 1.0549 (0.8897) loss_zs_kd 1.5396 (1.3518) loss_oracle 1.4157 (1.2768) kd_loss 1.1226 (0.9980) acc 65.6250 (68.4375) lr 7.5131e-04 eta 0:09:26
epoch [31/50] batch [120/319] time 0.090 (0.089) data 0.000 (0.005) loss 1.8235 (2.0163) teacher_loss 0.7126 (0.8897) loss_zs_kd 1.1582 (1.3541) loss_oracle 1.2780 (1.2759) kd_loss 0.9830 (0.9991) acc 71.8750 (68.5156) lr 7.5131e-04 eta 0:09:19
epoch [31/50] batch [140/319] time 0.082 (0.088) data 0.000 (0.005) loss 1.9650 (2.0124) teacher_loss 0.8188 (0.8880) loss_zs_kd 1.4345 (1.3583) loss_oracle 1.3389 (1.2768) kd_loss 1.0124 (0.9967) acc 59.3750 (68.5045) lr 7.5131e-04 eta 0:09:11
epoch [31/50] batch [160/319] time 0.092 (0.088) data 0.000 (0.004) loss 2.0250 (2.0068) teacher_loss 0.9219 (0.8844) loss_zs_kd 1.3657 (1.3717) loss_oracle 1.2500 (1.2776) kd_loss 0.9781 (0.9946) acc 56.2500 (68.5742) lr 7.5131e-04 eta 0:09:07
epoch [31/50] batch [180/319] time 0.082 (0.088) data 0.000 (0.004) loss 2.0140 (1.9996) teacher_loss 0.9009 (0.8807) loss_zs_kd 1.2945 (1.3684) loss_oracle 1.1564 (1.2718) kd_loss 0.9975 (0.9917) acc 62.5000 (68.6632) lr 7.5131e-04 eta 0:09:02
epoch [31/50] batch [200/319] time 0.087 (0.087) data 0.000 (0.003) loss 1.9536 (1.9969) teacher_loss 0.8566 (0.8810) loss_zs_kd 1.4348 (1.3691) loss_oracle 1.3179 (1.2685) kd_loss 0.9652 (0.9890) acc 68.7500 (68.5938) lr 7.5131e-04 eta 0:08:58
epoch [31/50] batch [220/319] time 0.095 (0.087) data 0.001 (0.003) loss 1.5380 (1.9896) teacher_loss 0.4657 (0.8759) loss_zs_kd 1.6994 (1.3730) loss_oracle 1.1767 (1.2677) kd_loss 0.9547 (0.9869) acc 90.6250 (68.9631) lr 7.5131e-04 eta 0:08:58
epoch [31/50] batch [240/319] time 0.084 (0.088) data 0.000 (0.003) loss 2.0922 (1.9821) teacher_loss 0.9764 (0.8721) loss_zs_kd 1.1965 (1.3761) loss_oracle 1.2301 (1.2638) kd_loss 0.9927 (0.9836) acc 59.3750 (68.8542) lr 7.5131e-04 eta 0:08:57
epoch [31/50] batch [260/319] time 0.102 (0.088) data 0.000 (0.003) loss 1.9303 (1.9756) teacher_loss 0.8453 (0.8678) loss_zs_kd 1.4675 (1.3780) loss_oracle 1.2358 (1.2626) kd_loss 0.9615 (0.9816) acc 62.5000 (69.0986) lr 7.5131e-04 eta 0:09:00
epoch [31/50] batch [280/319] time 0.081 (0.088) data 0.000 (0.002) loss 1.8144 (1.9800) teacher_loss 0.8322 (0.8739) loss_zs_kd 1.4582 (1.3772) loss_oracle 1.2905 (1.2629) kd_loss 0.8532 (0.9798) acc 68.7500 (68.9062) lr 7.5131e-04 eta 0:08:56
epoch [31/50] batch [300/319] time 0.072 (0.089) data 0.001 (0.002) loss 1.7135 (1.9775) teacher_loss 0.6032 (0.8733) loss_zs_kd 1.2726 (1.3761) loss_oracle 1.1495 (1.2627) kd_loss 0.9953 (0.9779) acc 71.8750 (68.9896) lr 7.5131e-04 eta 0:08:58
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,734
* accuracy: 62.4%
* error: 37.6%
* macro_f1: 55.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,467
* accuracy: 56.2%
* error: 43.8%
* macro_f1: 23.4%
******* Domain 2 best val acc:      62.7%, epoch: 29 *******
******* Domain 2 best val test acc: 56.0%, epoch: 29 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [32/50] batch [20/319] time 0.080 (0.117) data 0.000 (0.031) loss 1.9460 (1.9331) teacher_loss 0.8390 (0.8504) loss_zs_kd 1.7108 (1.4932) loss_oracle 1.2582 (1.2667) kd_loss 0.9811 (0.9560) acc 65.6250 (68.4375) lr 6.9098e-04 eta 0:11:46
epoch [32/50] batch [40/319] time 0.081 (0.101) data 0.000 (0.016) loss 1.8737 (1.9292) teacher_loss 0.8167 (0.8502) loss_zs_kd 1.4970 (1.4889) loss_oracle 1.2802 (1.2590) kd_loss 0.9289 (0.9532) acc 71.8750 (69.7656) lr 6.9098e-04 eta 0:10:05
epoch [32/50] batch [60/319] time 0.086 (0.095) data 0.001 (0.010) loss 1.8776 (1.9290) teacher_loss 0.8575 (0.8494) loss_zs_kd 1.4013 (1.4801) loss_oracle 1.2884 (1.2550) kd_loss 0.8913 (0.9541) acc 65.6250 (70.1562) lr 6.9098e-04 eta 0:09:28
epoch [32/50] batch [80/319] time 0.198 (0.095) data 0.001 (0.008) loss 1.7878 (1.9261) teacher_loss 0.7637 (0.8515) loss_zs_kd 1.4059 (1.4758) loss_oracle 1.1301 (1.2487) kd_loss 0.9110 (0.9498) acc 68.7500 (69.9219) lr 6.9098e-04 eta 0:09:31
epoch [32/50] batch [100/319] time 0.078 (0.093) data 0.000 (0.006) loss 1.8005 (1.9370) teacher_loss 0.7220 (0.8649) loss_zs_kd 1.2428 (1.4672) loss_oracle 1.0817 (1.2443) kd_loss 0.9703 (0.9477) acc 78.1250 (69.5312) lr 6.9098e-04 eta 0:09:14
epoch [32/50] batch [120/319] time 0.091 (0.092) data 0.000 (0.005) loss 1.6351 (1.9252) teacher_loss 0.6333 (0.8544) loss_zs_kd 1.6714 (1.4529) loss_oracle 1.2677 (1.2451) kd_loss 0.8751 (0.9463) acc 78.1250 (70.0260) lr 6.9098e-04 eta 0:09:03
epoch [32/50] batch [140/319] time 0.092 (0.090) data 0.000 (0.005) loss 1.8812 (1.9242) teacher_loss 0.8213 (0.8567) loss_zs_kd 1.7431 (1.4538) loss_oracle 1.2251 (1.2454) kd_loss 0.9374 (0.9429) acc 68.7500 (69.8438) lr 6.9098e-04 eta 0:08:55
epoch [32/50] batch [160/319] time 0.071 (0.090) data 0.000 (0.004) loss 1.8985 (1.9259) teacher_loss 0.8058 (0.8587) loss_zs_kd 1.3577 (1.4497) loss_oracle 1.1697 (1.2439) kd_loss 0.9758 (0.9428) acc 68.7500 (69.9023) lr 6.9098e-04 eta 0:08:48
epoch [32/50] batch [180/319] time 0.085 (0.089) data 0.000 (0.004) loss 2.0704 (1.9171) teacher_loss 1.0264 (0.8519) loss_zs_kd 1.2674 (1.4495) loss_oracle 1.2449 (1.2415) kd_loss 0.9195 (0.9411) acc 56.2500 (70.0347) lr 6.9098e-04 eta 0:08:43
epoch [32/50] batch [200/319] time 0.081 (0.089) data 0.000 (0.003) loss 1.8354 (1.9171) teacher_loss 0.7914 (0.8533) loss_zs_kd 1.2812 (1.4465) loss_oracle 1.2450 (1.2396) kd_loss 0.9194 (0.9398) acc 65.6250 (69.9844) lr 6.9098e-04 eta 0:08:40
epoch [32/50] batch [220/319] time 0.083 (0.088) data 0.000 (0.003) loss 1.8356 (1.9118) teacher_loss 0.7775 (0.8476) loss_zs_kd 1.0964 (1.4297) loss_oracle 1.2982 (1.2418) kd_loss 0.9283 (0.9401) acc 75.0000 (70.2415) lr 6.9098e-04 eta 0:08:36
epoch [32/50] batch [240/319] time 0.084 (0.088) data 0.000 (0.003) loss 1.6208 (1.9104) teacher_loss 0.5686 (0.8472) loss_zs_kd 1.1375 (1.4184) loss_oracle 1.2126 (1.2434) kd_loss 0.9310 (0.9389) acc 81.2500 (70.2734) lr 6.9098e-04 eta 0:08:31
epoch [32/50] batch [260/319] time 0.086 (0.087) data 0.000 (0.003) loss 1.8115 (1.9141) teacher_loss 0.7927 (0.8482) loss_zs_kd 1.4097 (1.4165) loss_oracle 1.2011 (1.2442) kd_loss 0.8987 (0.9414) acc 84.3750 (70.2284) lr 6.9098e-04 eta 0:08:27
epoch [32/50] batch [280/319] time 0.072 (0.087) data 0.000 (0.002) loss 2.1242 (1.9164) teacher_loss 0.9951 (0.8500) loss_zs_kd 1.2397 (1.4172) loss_oracle 1.2626 (1.2425) kd_loss 1.0029 (0.9422) acc 71.8750 (70.2232) lr 6.9098e-04 eta 0:08:24
epoch [32/50] batch [300/319] time 0.075 (0.087) data 0.000 (0.002) loss 1.7491 (1.9136) teacher_loss 0.6790 (0.8471) loss_zs_kd 1.2617 (1.4220) loss_oracle 1.2025 (1.2434) kd_loss 0.9499 (0.9422) acc 78.1250 (70.1979) lr 6.9098e-04 eta 0:08:20
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,786
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 55.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,446
* accuracy: 55.9%
* error: 44.1%
* macro_f1: 23.4%
******* Domain 2 best val acc:      63.6%, epoch: 32 *******
******* Domain 2 best val test acc: 55.9%, epoch: 32 *******
******* Domain 2 best test acc:     58.3%, epoch: 4 *******
epoch [33/50] batch [20/319] time 0.090 (0.113) data 0.000 (0.032) loss 2.0870 (1.8828) teacher_loss 1.0117 (0.8020) loss_zs_kd 1.5150 (1.5372) loss_oracle 1.3268 (1.2917) kd_loss 0.9426 (0.9517) acc 59.3750 (70.0000) lr 6.3188e-04 eta 0:10:44
epoch [33/50] batch [40/319] time 0.082 (0.098) data 0.000 (0.016) loss 1.9329 (1.8969) teacher_loss 0.8069 (0.8272) loss_zs_kd 1.4323 (1.4861) loss_oracle 1.3003 (1.2768) kd_loss 0.9959 (0.9419) acc 68.7500 (70.6250) lr 6.3188e-04 eta 0:09:21
epoch [33/50] batch [60/319] time 0.077 (0.093) data 0.000 (0.011) loss 1.3816 (1.8833) teacher_loss 0.3694 (0.8129) loss_zs_kd 1.2819 (1.4453) loss_oracle 1.2949 (1.2773) kd_loss 0.8827 (0.9426) acc 93.7500 (71.6146) lr 6.3188e-04 eta 0:08:48
epoch [33/50] batch [80/319] time 0.082 (0.090) data 0.000 (0.008) loss 1.7647 (1.8779) teacher_loss 0.7351 (0.8074) loss_zs_kd 1.6598 (1.4487) loss_oracle 1.1773 (1.2636) kd_loss 0.9119 (0.9441) acc 78.1250 (71.8750) lr 6.3188e-04 eta 0:08:29
epoch [33/50] batch [100/319] time 0.088 (0.089) data 0.000 (0.007) loss 2.2322 (1.8813) teacher_loss 1.1236 (0.8092) loss_zs_kd 1.4713 (1.4642) loss_oracle 1.3373 (1.2647) kd_loss 0.9749 (0.9457) acc 65.6250 (71.7500) lr 6.3188e-04 eta 0:08:20
epoch [33/50] batch [120/319] time 0.080 (0.089) data 0.000 (0.006) loss 2.2792 (1.8913) teacher_loss 1.2902 (0.8207) loss_zs_kd 1.4004 (1.4621) loss_oracle 1.2584 (1.2615) kd_loss 0.8632 (0.9444) acc 59.3750 (71.0677) lr 6.3188e-04 eta 0:08:20
epoch [33/50] batch [140/319] time 0.085 (0.088) data 0.000 (0.005) loss 1.9111 (1.9054) teacher_loss 0.7466 (0.8312) loss_zs_kd 1.4540 (1.4449) loss_oracle 1.2244 (1.2628) kd_loss 1.0421 (0.9479) acc 75.0000 (70.8259) lr 6.3188e-04 eta 0:08:13
epoch [33/50] batch [160/319] time 0.082 (0.088) data 0.001 (0.004) loss 1.5675 (1.8985) teacher_loss 0.4979 (0.8272) loss_zs_kd 1.1333 (1.4308) loss_oracle 1.2485 (1.2625) kd_loss 0.9447 (0.9451) acc 78.1250 (70.8789) lr 6.3188e-04 eta 0:08:12
epoch [33/50] batch [180/319] time 0.087 (0.088) data 0.000 (0.004) loss 2.1164 (1.9077) teacher_loss 1.0132 (0.8376) loss_zs_kd 1.7510 (1.4140) loss_oracle 1.1594 (1.2619) kd_loss 0.9873 (0.9440) acc 62.5000 (70.7118) lr 6.3188e-04 eta 0:08:07
epoch [33/50] batch [200/319] time 0.089 (0.088) data 0.000 (0.004) loss 1.7072 (1.9052) teacher_loss 0.6202 (0.8351) loss_zs_kd 1.7669 (1.4129) loss_oracle 1.2325 (1.2614) kd_loss 0.9638 (0.9440) acc 81.2500 (70.9062) lr 6.3188e-04 eta 0:08:04
epoch [33/50] batch [220/319] time 0.087 (0.087) data 0.000 (0.003) loss 1.4939 (1.9005) teacher_loss 0.4401 (0.8311) loss_zs_kd 1.3729 (1.4073) loss_oracle 1.3127 (1.2581) kd_loss 0.9225 (0.9437) acc 87.5000 (71.0369) lr 6.3188e-04 eta 0:08:01
epoch [33/50] batch [240/319] time 0.089 (0.088) data 0.000 (0.003) loss 1.7573 (1.8957) teacher_loss 0.6675 (0.8265) loss_zs_kd 1.6230 (1.4122) loss_oracle 1.2252 (1.2587) kd_loss 0.9672 (0.9434) acc 75.0000 (71.1198) lr 6.3188e-04 eta 0:08:05
epoch [33/50] batch [260/319] time 0.078 (0.088) data 0.000 (0.003) loss 1.9378 (1.9033) teacher_loss 0.8975 (0.8333) loss_zs_kd 1.4044 (1.4170) loss_oracle 1.3541 (1.2599) kd_loss 0.9049 (0.9439) acc 65.6250 (70.9135) lr 6.3188e-04 eta 0:08:00
epoch [33/50] batch [280/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.9095 (1.8993) teacher_loss 0.8313 (0.8299) loss_zs_kd 1.2169 (1.4190) loss_oracle 1.2304 (1.2608) kd_loss 0.9552 (0.9434) acc 78.1250 (71.0156) lr 6.3188e-04 eta 0:07:57
epoch [33/50] batch [300/319] time 0.085 (0.087) data 0.000 (0.002) loss 1.7774 (1.8986) teacher_loss 0.6361 (0.8309) loss_zs_kd 1.2642 (1.4208) loss_oracle 1.2884 (1.2614) kd_loss 1.0125 (0.9416) acc 78.1250 (70.9583) lr 6.3188e-04 eta 0:07:55
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,725
* accuracy: 62.2%
* error: 37.8%
* macro_f1: 56.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,730
* accuracy: 58.9%
* error: 41.1%
* macro_f1: 25.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      63.6%, epoch: 32 *******
******* Domain 2 best val test acc: 55.9%, epoch: 32 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [34/50] batch [20/319] time 0.071 (0.109) data 0.000 (0.025) loss 1.9863 (1.8435) teacher_loss 0.8855 (0.7745) loss_zs_kd 1.6113 (1.3431) loss_oracle 1.2895 (1.3068) kd_loss 0.9719 (0.9383) acc 75.0000 (72.6562) lr 5.7422e-04 eta 0:09:51
epoch [34/50] batch [40/319] time 0.095 (0.093) data 0.000 (0.013) loss 1.7537 (1.8567) teacher_loss 0.7435 (0.7953) loss_zs_kd 1.2021 (1.3890) loss_oracle 1.2187 (1.2781) kd_loss 0.8884 (0.9335) acc 71.8750 (71.7188) lr 5.7422e-04 eta 0:08:18
epoch [34/50] batch [60/319] time 0.082 (0.087) data 0.001 (0.009) loss 2.0682 (1.8511) teacher_loss 1.0053 (0.7880) loss_zs_kd 1.4216 (1.3884) loss_oracle 1.3514 (1.2690) kd_loss 0.9277 (0.9362) acc 62.5000 (71.7708) lr 5.7422e-04 eta 0:07:49
epoch [34/50] batch [80/319] time 0.078 (0.086) data 0.000 (0.007) loss 1.8865 (1.8539) teacher_loss 0.7534 (0.7872) loss_zs_kd 1.4845 (1.3789) loss_oracle 1.4080 (1.2726) kd_loss 0.9923 (0.9394) acc 71.8750 (71.3281) lr 5.7422e-04 eta 0:07:38
epoch [34/50] batch [100/319] time 0.080 (0.085) data 0.000 (0.005) loss 1.7300 (1.8586) teacher_loss 0.5739 (0.7910) loss_zs_kd 1.6811 (1.4103) loss_oracle 1.4312 (1.2755) kd_loss 1.0130 (0.9400) acc 84.3750 (71.3750) lr 5.7422e-04 eta 0:07:33
epoch [34/50] batch [120/319] time 0.085 (0.085) data 0.000 (0.005) loss 1.9071 (1.8467) teacher_loss 0.7443 (0.7734) loss_zs_kd 1.5260 (1.4275) loss_oracle 1.2666 (1.2770) kd_loss 1.0361 (0.9456) acc 78.1250 (72.0052) lr 5.7422e-04 eta 0:07:31
epoch [34/50] batch [140/319] time 0.078 (0.085) data 0.000 (0.004) loss 1.9673 (1.8558) teacher_loss 0.8621 (0.7792) loss_zs_kd 1.5635 (1.4388) loss_oracle 1.4156 (1.2755) kd_loss 0.9636 (0.9490) acc 68.7500 (71.8080) lr 5.7422e-04 eta 0:07:28
epoch [34/50] batch [160/319] time 0.083 (0.085) data 0.000 (0.003) loss 1.8631 (1.8612) teacher_loss 0.7748 (0.7827) loss_zs_kd 1.6039 (1.4498) loss_oracle 1.3015 (1.2751) kd_loss 0.9581 (0.9510) acc 75.0000 (71.9531) lr 5.7422e-04 eta 0:07:25
epoch [34/50] batch [180/319] time 0.082 (0.084) data 0.000 (0.003) loss 1.9918 (1.8761) teacher_loss 0.9357 (0.7947) loss_zs_kd 1.7875 (1.4566) loss_oracle 1.1879 (1.2740) kd_loss 0.9372 (0.9541) acc 62.5000 (71.6493) lr 5.7422e-04 eta 0:07:22
epoch [34/50] batch [200/319] time 0.086 (0.084) data 0.000 (0.003) loss 1.9700 (1.8882) teacher_loss 0.9530 (0.8056) loss_zs_kd 1.1802 (1.4448) loss_oracle 1.2575 (1.2718) kd_loss 0.8912 (0.9555) acc 71.8750 (71.2969) lr 5.7422e-04 eta 0:07:20
epoch [34/50] batch [220/319] time 0.083 (0.084) data 0.000 (0.003) loss 1.6872 (1.8915) teacher_loss 0.5860 (0.8089) loss_zs_kd 1.4630 (1.4414) loss_oracle 1.2627 (1.2706) kd_loss 0.9749 (0.9556) acc 81.2500 (71.3068) lr 5.7422e-04 eta 0:07:19
epoch [34/50] batch [240/319] time 0.082 (0.084) data 0.000 (0.002) loss 2.0424 (1.8890) teacher_loss 0.9254 (0.8073) loss_zs_kd 1.4988 (1.4405) loss_oracle 1.2634 (1.2668) kd_loss 0.9907 (0.9550) acc 56.2500 (71.4323) lr 5.7422e-04 eta 0:07:16
epoch [34/50] batch [260/319] time 0.077 (0.084) data 0.000 (0.002) loss 1.6037 (1.8858) teacher_loss 0.6168 (0.8039) loss_zs_kd 1.2505 (1.4350) loss_oracle 1.1446 (1.2655) kd_loss 0.8725 (0.9553) acc 81.2500 (71.7188) lr 5.7422e-04 eta 0:07:14
epoch [34/50] batch [280/319] time 0.083 (0.084) data 0.000 (0.002) loss 1.8216 (1.8854) teacher_loss 0.7430 (0.8039) loss_zs_kd 1.5044 (1.4283) loss_oracle 1.2524 (1.2665) kd_loss 0.9534 (0.9548) acc 65.6250 (71.8192) lr 5.7422e-04 eta 0:07:13
epoch [34/50] batch [300/319] time 0.076 (0.084) data 0.000 (0.002) loss 1.7917 (1.8874) teacher_loss 0.7094 (0.8066) loss_zs_kd 1.3630 (1.4236) loss_oracle 1.3651 (1.2646) kd_loss 0.9457 (0.9544) acc 84.3750 (71.8542) lr 5.7422e-04 eta 0:07:09
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,749
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,518
* accuracy: 56.7%
* error: 43.3%
* macro_f1: 24.8%
******* Domain 2 best val acc:      63.6%, epoch: 32 *******
******* Domain 2 best val test acc: 55.9%, epoch: 32 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [35/50] batch [20/319] time 0.065 (0.109) data 0.000 (0.028) loss 2.0816 (1.8528) teacher_loss 0.9992 (0.7770) loss_zs_kd 1.3906 (1.3453) loss_oracle 1.3579 (1.2824) kd_loss 0.9466 (0.9476) acc 65.6250 (73.5938) lr 5.1825e-04 eta 0:09:13
epoch [35/50] batch [40/319] time 0.090 (0.095) data 0.000 (0.014) loss 1.7192 (1.8344) teacher_loss 0.6587 (0.7632) loss_zs_kd 1.5219 (1.3582) loss_oracle 1.2472 (1.2611) kd_loss 0.9358 (0.9451) acc 81.2500 (74.3750) lr 5.1825e-04 eta 0:08:02
epoch [35/50] batch [60/319] time 0.081 (0.090) data 0.001 (0.010) loss 1.8495 (1.8695) teacher_loss 0.8315 (0.8040) loss_zs_kd 1.3637 (1.3592) loss_oracle 1.1635 (1.2559) kd_loss 0.9016 (0.9398) acc 75.0000 (72.7083) lr 5.1825e-04 eta 0:07:33
epoch [35/50] batch [80/319] time 0.077 (0.088) data 0.000 (0.007) loss 2.0486 (1.8717) teacher_loss 0.9265 (0.8033) loss_zs_kd 1.4085 (1.3643) loss_oracle 1.3010 (1.2502) kd_loss 0.9920 (0.9434) acc 78.1250 (73.1641) lr 5.1825e-04 eta 0:07:21
epoch [35/50] batch [100/319] time 0.089 (0.087) data 0.000 (0.006) loss 2.0806 (1.8676) teacher_loss 1.0533 (0.7995) loss_zs_kd 1.4594 (1.3679) loss_oracle 1.2138 (1.2514) kd_loss 0.9059 (0.9430) acc 65.6250 (73.1250) lr 5.1825e-04 eta 0:07:15
epoch [35/50] batch [120/319] time 0.078 (0.085) data 0.000 (0.005) loss 2.0140 (1.8742) teacher_loss 0.9706 (0.8047) loss_zs_kd 1.3966 (1.3777) loss_oracle 1.3118 (1.2496) kd_loss 0.9122 (0.9445) acc 68.7500 (72.5000) lr 5.1825e-04 eta 0:07:05
epoch [35/50] batch [140/319] time 0.083 (0.085) data 0.000 (0.004) loss 1.9870 (1.8727) teacher_loss 0.9313 (0.8017) loss_zs_kd 1.4236 (1.3794) loss_oracle 1.3066 (1.2470) kd_loss 0.9251 (0.9463) acc 75.0000 (72.7455) lr 5.1825e-04 eta 0:07:00
epoch [35/50] batch [160/319] time 0.076 (0.084) data 0.000 (0.004) loss 2.0116 (1.8736) teacher_loss 0.9391 (0.8056) loss_zs_kd 1.3885 (1.3844) loss_oracle 1.3903 (1.2479) kd_loss 0.9334 (0.9432) acc 68.7500 (72.4609) lr 5.1825e-04 eta 0:06:56
epoch [35/50] batch [180/319] time 0.074 (0.083) data 0.000 (0.003) loss 2.2458 (1.8868) teacher_loss 1.1023 (0.8177) loss_zs_kd 1.0856 (1.3730) loss_oracle 1.1973 (1.2458) kd_loss 1.0237 (0.9445) acc 65.6250 (71.9444) lr 5.1825e-04 eta 0:06:50
epoch [35/50] batch [200/319] time 0.103 (0.084) data 0.000 (0.003) loss 1.8570 (1.8963) teacher_loss 0.7983 (0.8289) loss_zs_kd 1.1021 (1.3617) loss_oracle 1.2442 (1.2413) kd_loss 0.9343 (0.9433) acc 75.0000 (71.7344) lr 5.1825e-04 eta 0:06:49
epoch [35/50] batch [220/319] time 0.084 (0.084) data 0.000 (0.003) loss 2.2484 (1.8893) teacher_loss 1.1887 (0.8250) loss_zs_kd 1.1771 (1.3486) loss_oracle 1.2296 (1.2348) kd_loss 0.9367 (0.9408) acc 68.7500 (71.8608) lr 5.1825e-04 eta 0:06:51
epoch [35/50] batch [240/319] time 0.089 (0.084) data 0.000 (0.003) loss 1.9904 (1.8923) teacher_loss 0.9233 (0.8298) loss_zs_kd 1.2930 (1.3383) loss_oracle 1.2599 (1.2329) kd_loss 0.9411 (0.9392) acc 59.3750 (71.5885) lr 5.1825e-04 eta 0:06:49
epoch [35/50] batch [260/319] time 0.080 (0.084) data 0.000 (0.002) loss 1.7429 (1.8875) teacher_loss 0.6890 (0.8260) loss_zs_kd 1.3664 (1.3359) loss_oracle 1.1730 (1.2324) kd_loss 0.9366 (0.9382) acc 75.0000 (71.5264) lr 5.1825e-04 eta 0:06:47
epoch [35/50] batch [280/319] time 0.079 (0.084) data 0.000 (0.002) loss 1.9242 (1.8921) teacher_loss 0.8804 (0.8304) loss_zs_kd 1.4989 (1.3431) loss_oracle 1.2969 (1.2334) kd_loss 0.9141 (0.9384) acc 68.7500 (71.4955) lr 5.1825e-04 eta 0:06:44
epoch [35/50] batch [300/319] time 0.079 (0.084) data 0.000 (0.002) loss 1.8411 (1.8925) teacher_loss 0.7893 (0.8304) loss_zs_kd 1.4550 (1.3473) loss_oracle 1.2006 (1.2339) kd_loss 0.9317 (0.9387) acc 75.0000 (71.5625) lr 5.1825e-04 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,752
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 58.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,658
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 24.9%
******* Domain 2 best val acc:      63.6%, epoch: 32 *******
******* Domain 2 best val test acc: 55.9%, epoch: 32 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [36/50] batch [20/319] time 0.079 (0.094) data 0.000 (0.026) loss 1.8706 (1.9109) teacher_loss 0.8574 (0.8590) loss_zs_kd 1.0140 (1.3525) loss_oracle 1.0804 (1.2319) kd_loss 0.9052 (0.9287) acc 62.5000 (67.1875) lr 4.6417e-04 eta 0:07:28
epoch [36/50] batch [40/319] time 0.067 (0.079) data 0.000 (0.013) loss 1.9837 (1.9276) teacher_loss 0.8787 (0.8756) loss_zs_kd 1.3682 (1.3724) loss_oracle 1.2421 (1.2153) kd_loss 0.9807 (0.9305) acc 71.8750 (67.2656) lr 4.6417e-04 eta 0:06:16
epoch [36/50] batch [60/319] time 0.067 (0.075) data 0.000 (0.009) loss 2.0006 (1.9104) teacher_loss 0.8578 (0.8515) loss_zs_kd 1.6075 (1.4014) loss_oracle 1.2097 (1.2122) kd_loss 1.0218 (0.9377) acc 68.7500 (69.1146) lr 4.6417e-04 eta 0:05:54
epoch [36/50] batch [80/319] time 0.081 (0.077) data 0.000 (0.007) loss 1.8098 (1.9204) teacher_loss 0.7317 (0.8604) loss_zs_kd 1.5918 (1.4026) loss_oracle 1.2194 (1.2151) kd_loss 0.9562 (0.9385) acc 78.1250 (69.0625) lr 4.6417e-04 eta 0:06:00
epoch [36/50] batch [100/319] time 0.087 (0.078) data 0.000 (0.005) loss 1.9011 (1.9209) teacher_loss 0.6932 (0.8588) loss_zs_kd 1.5688 (1.4059) loss_oracle 1.3056 (1.2144) kd_loss 1.0774 (0.9407) acc 84.3750 (69.5312) lr 4.6417e-04 eta 0:06:06
epoch [36/50] batch [120/319] time 0.081 (0.080) data 0.000 (0.005) loss 1.7250 (1.9226) teacher_loss 0.6558 (0.8596) loss_zs_kd 1.6127 (1.4058) loss_oracle 1.2732 (1.2188) kd_loss 0.9419 (0.9411) acc 68.7500 (69.2969) lr 4.6417e-04 eta 0:06:11
epoch [36/50] batch [140/319] time 0.095 (0.080) data 0.000 (0.004) loss 1.9140 (1.9165) teacher_loss 0.9101 (0.8533) loss_zs_kd 1.2887 (1.4121) loss_oracle 1.2208 (1.2190) kd_loss 0.8818 (0.9413) acc 62.5000 (69.7768) lr 4.6417e-04 eta 0:06:12
epoch [36/50] batch [160/319] time 0.083 (0.081) data 0.000 (0.003) loss 1.8147 (1.9095) teacher_loss 0.7714 (0.8480) loss_zs_kd 1.2521 (1.4114) loss_oracle 1.2031 (1.2191) kd_loss 0.9230 (0.9396) acc 75.0000 (70.0000) lr 4.6417e-04 eta 0:06:12
epoch [36/50] batch [180/319] time 0.086 (0.081) data 0.000 (0.003) loss 1.9074 (1.9024) teacher_loss 0.8105 (0.8407) loss_zs_kd 1.5976 (1.4042) loss_oracle 1.3364 (1.2196) kd_loss 0.9632 (0.9397) acc 71.8750 (70.2431) lr 4.6417e-04 eta 0:06:12
epoch [36/50] batch [200/319] time 0.076 (0.081) data 0.000 (0.003) loss 1.7243 (1.8986) teacher_loss 0.6353 (0.8375) loss_zs_kd 1.3655 (1.4030) loss_oracle 1.3108 (1.2192) kd_loss 0.9579 (0.9392) acc 71.8750 (70.4062) lr 4.6417e-04 eta 0:06:12
epoch [36/50] batch [220/319] time 0.080 (0.081) data 0.000 (0.003) loss 1.7919 (1.8982) teacher_loss 0.7494 (0.8350) loss_zs_kd 1.5063 (1.4072) loss_oracle 1.1695 (1.2207) kd_loss 0.9255 (0.9411) acc 75.0000 (70.5966) lr 4.6417e-04 eta 0:06:08
epoch [36/50] batch [240/319] time 0.080 (0.081) data 0.000 (0.002) loss 1.8736 (1.8961) teacher_loss 0.7927 (0.8338) loss_zs_kd 1.6257 (1.4133) loss_oracle 1.1561 (1.2198) kd_loss 0.9653 (0.9403) acc 71.8750 (70.7292) lr 4.6417e-04 eta 0:06:09
epoch [36/50] batch [260/319] time 0.091 (0.082) data 0.000 (0.002) loss 2.1346 (1.8964) teacher_loss 1.0666 (0.8348) loss_zs_kd 1.1670 (1.4137) loss_oracle 1.2978 (1.2210) kd_loss 0.9382 (0.9395) acc 53.1250 (70.5288) lr 4.6417e-04 eta 0:06:10
epoch [36/50] batch [280/319] time 0.084 (0.082) data 0.000 (0.002) loss 2.0615 (1.8947) teacher_loss 1.0379 (0.8327) loss_zs_kd 1.3669 (1.4160) loss_oracle 1.2395 (1.2231) kd_loss 0.8997 (0.9396) acc 62.5000 (70.6808) lr 4.6417e-04 eta 0:06:11
epoch [36/50] batch [300/319] time 0.090 (0.083) data 0.000 (0.002) loss 2.0253 (1.8942) teacher_loss 0.9292 (0.8316) loss_zs_kd 1.3962 (1.4164) loss_oracle 1.1458 (1.2229) kd_loss 0.9816 (0.9403) acc 68.7500 (70.8021) lr 4.6417e-04 eta 0:06:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,795
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 57.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,610
* accuracy: 57.6%
* error: 42.4%
* macro_f1: 23.5%
******* Domain 2 best val acc:      63.8%, epoch: 36 *******
******* Domain 2 best val test acc: 57.6%, epoch: 36 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [37/50] batch [20/319] time 0.086 (0.110) data 0.000 (0.027) loss 1.8759 (1.8654) teacher_loss 0.8642 (0.7873) loss_zs_kd 1.5694 (1.3819) loss_oracle 1.1068 (1.2245) kd_loss 0.9011 (0.9556) acc 68.7500 (71.8750) lr 4.1221e-04 eta 0:08:07
epoch [37/50] batch [40/319] time 0.089 (0.097) data 0.000 (0.013) loss 2.0543 (1.8666) teacher_loss 1.0141 (0.7975) loss_zs_kd 1.3284 (1.3729) loss_oracle 1.1541 (1.2260) kd_loss 0.9248 (0.9465) acc 71.8750 (72.0312) lr 4.1221e-04 eta 0:07:08
epoch [37/50] batch [60/319] time 0.082 (0.093) data 0.000 (0.009) loss 1.9840 (1.9025) teacher_loss 0.9104 (0.8265) loss_zs_kd 1.5282 (1.3650) loss_oracle 1.2537 (1.2349) kd_loss 0.9482 (0.9525) acc 65.6250 (71.3542) lr 4.1221e-04 eta 0:06:50
epoch [37/50] batch [80/319] time 0.093 (0.091) data 0.001 (0.007) loss 2.1451 (1.9193) teacher_loss 0.9988 (0.8420) loss_zs_kd 1.4506 (1.3646) loss_oracle 1.2979 (1.2351) kd_loss 1.0166 (0.9538) acc 56.2500 (70.4688) lr 4.1221e-04 eta 0:06:39
epoch [37/50] batch [100/319] time 0.087 (0.090) data 0.000 (0.006) loss 1.7696 (1.9075) teacher_loss 0.7599 (0.8337) loss_zs_kd 1.5965 (1.3741) loss_oracle 1.3330 (1.2368) kd_loss 0.8764 (0.9501) acc 75.0000 (70.4375) lr 4.1221e-04 eta 0:06:32
epoch [37/50] batch [120/319] time 0.086 (0.090) data 0.000 (0.005) loss 2.1041 (1.9135) teacher_loss 0.9833 (0.8369) loss_zs_kd 1.3869 (1.3723) loss_oracle 1.4155 (1.2403) kd_loss 0.9793 (0.9526) acc 71.8750 (70.5729) lr 4.1221e-04 eta 0:06:29
epoch [37/50] batch [140/319] time 0.080 (0.089) data 0.000 (0.004) loss 1.6784 (1.9070) teacher_loss 0.6355 (0.8302) loss_zs_kd 1.4351 (1.3710) loss_oracle 1.2014 (1.2393) kd_loss 0.9228 (0.9529) acc 75.0000 (70.5804) lr 4.1221e-04 eta 0:06:24
epoch [37/50] batch [160/319] time 0.090 (0.089) data 0.000 (0.004) loss 2.1063 (1.9099) teacher_loss 0.9485 (0.8336) loss_zs_kd 1.2432 (1.3677) loss_oracle 1.2462 (1.2374) kd_loss 1.0332 (0.9526) acc 65.6250 (70.4492) lr 4.1221e-04 eta 0:06:21
epoch [37/50] batch [180/319] time 0.089 (0.090) data 0.000 (0.003) loss 1.9235 (1.9079) teacher_loss 0.8629 (0.8325) loss_zs_kd 1.6997 (1.3621) loss_oracle 1.2985 (1.2385) kd_loss 0.9308 (0.9515) acc 71.8750 (70.5903) lr 4.1221e-04 eta 0:06:24
epoch [37/50] batch [200/319] time 0.084 (0.089) data 0.000 (0.003) loss 1.9671 (1.9079) teacher_loss 0.8755 (0.8315) loss_zs_kd 1.2082 (1.3624) loss_oracle 1.1073 (1.2354) kd_loss 0.9808 (0.9529) acc 78.1250 (70.6562) lr 4.1221e-04 eta 0:06:20
epoch [37/50] batch [220/319] time 0.085 (0.089) data 0.001 (0.003) loss 2.1872 (1.9057) teacher_loss 1.0513 (0.8278) loss_zs_kd 1.2957 (1.3577) loss_oracle 1.1743 (1.2348) kd_loss 1.0185 (0.9545) acc 65.6250 (70.9375) lr 4.1221e-04 eta 0:06:16
epoch [37/50] batch [240/319] time 0.085 (0.089) data 0.000 (0.003) loss 2.0551 (1.9018) teacher_loss 0.9078 (0.8229) loss_zs_kd 1.3794 (1.3546) loss_oracle 1.2116 (1.2359) kd_loss 1.0261 (0.9553) acc 71.8750 (71.1458) lr 4.1221e-04 eta 0:06:14
epoch [37/50] batch [260/319] time 0.088 (0.088) data 0.000 (0.002) loss 2.0738 (1.9094) teacher_loss 0.9705 (0.8305) loss_zs_kd 1.3113 (1.3541) loss_oracle 1.2499 (1.2382) kd_loss 0.9783 (0.9550) acc 68.7500 (70.6971) lr 4.1221e-04 eta 0:06:11
epoch [37/50] batch [280/319] time 0.080 (0.088) data 0.000 (0.002) loss 1.9139 (1.9057) teacher_loss 0.8073 (0.8279) loss_zs_kd 1.3044 (1.3546) loss_oracle 1.3220 (1.2372) kd_loss 0.9744 (0.9541) acc 75.0000 (70.7478) lr 4.1221e-04 eta 0:06:09
epoch [37/50] batch [300/319] time 0.079 (0.088) data 0.001 (0.002) loss 1.8886 (1.9032) teacher_loss 0.7974 (0.8239) loss_zs_kd 1.4142 (1.3589) loss_oracle 1.1712 (1.2380) kd_loss 0.9741 (0.9556) acc 65.6250 (70.8958) lr 4.1221e-04 eta 0:06:05
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,763
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 58.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,601
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 24.2%
******* Domain 2 best val acc:      63.8%, epoch: 36 *******
******* Domain 2 best val test acc: 57.6%, epoch: 36 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [38/50] batch [20/319] time 0.085 (0.122) data 0.000 (0.033) loss 1.8870 (2.0094) teacher_loss 0.7612 (0.9063) loss_zs_kd 1.4438 (1.3055) loss_oracle 1.2996 (1.2256) kd_loss 0.9958 (0.9805) acc 68.7500 (68.5938) lr 3.6258e-04 eta 0:08:23
epoch [38/50] batch [40/319] time 0.087 (0.104) data 0.000 (0.017) loss 2.2455 (1.9563) teacher_loss 1.0809 (0.8597) loss_zs_kd 1.1945 (1.3203) loss_oracle 1.2603 (1.2232) kd_loss 1.0385 (0.9742) acc 59.3750 (70.1562) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [60/319] time 0.097 (0.097) data 0.001 (0.011) loss 2.1760 (1.9486) teacher_loss 1.0567 (0.8576) loss_zs_kd 1.4754 (1.3454) loss_oracle 1.2284 (1.2356) kd_loss 0.9965 (0.9675) acc 78.1250 (70.4688) lr 3.6258e-04 eta 0:06:37
epoch [38/50] batch [80/319] time 0.079 (0.093) data 0.000 (0.009) loss 2.0961 (1.9224) teacher_loss 1.0796 (0.8362) loss_zs_kd 1.9086 (1.3735) loss_oracle 1.3486 (1.2443) kd_loss 0.8816 (0.9617) acc 59.3750 (70.5859) lr 3.6258e-04 eta 0:06:16
epoch [38/50] batch [100/319] time 0.088 (0.091) data 0.000 (0.007) loss 1.8337 (1.9088) teacher_loss 0.7469 (0.8200) loss_zs_kd 1.5905 (1.3952) loss_oracle 1.2933 (1.2455) kd_loss 0.9575 (0.9642) acc 75.0000 (71.1562) lr 3.6258e-04 eta 0:06:06
epoch [38/50] batch [120/319] time 0.081 (0.089) data 0.000 (0.006) loss 1.7869 (1.9074) teacher_loss 0.6789 (0.8183) loss_zs_kd 1.4694 (1.4007) loss_oracle 1.3194 (1.2508) kd_loss 0.9761 (0.9641) acc 71.8750 (71.2760) lr 3.6258e-04 eta 0:05:58
epoch [38/50] batch [140/319] time 0.074 (0.089) data 0.000 (0.005) loss 2.0834 (1.9068) teacher_loss 0.9864 (0.8154) loss_zs_kd 1.5257 (1.4104) loss_oracle 1.4017 (1.2537) kd_loss 0.9568 (0.9660) acc 68.7500 (71.4732) lr 3.6258e-04 eta 0:05:55
epoch [38/50] batch [160/319] time 0.087 (0.088) data 0.000 (0.004) loss 1.7513 (1.8995) teacher_loss 0.7029 (0.8090) loss_zs_kd 1.3159 (1.4106) loss_oracle 1.1984 (1.2502) kd_loss 0.9285 (0.9654) acc 78.1250 (71.6797) lr 3.6258e-04 eta 0:05:49
epoch [38/50] batch [180/319] time 0.082 (0.087) data 0.000 (0.004) loss 1.9382 (1.9010) teacher_loss 0.8118 (0.8131) loss_zs_kd 1.3084 (1.4064) loss_oracle 1.2947 (1.2506) kd_loss 0.9970 (0.9629) acc 62.5000 (71.4410) lr 3.6258e-04 eta 0:05:45
epoch [38/50] batch [200/319] time 0.093 (0.087) data 0.000 (0.004) loss 2.0326 (1.9031) teacher_loss 0.9924 (0.8146) loss_zs_kd 1.4322 (1.4101) loss_oracle 1.2056 (1.2504) kd_loss 0.9196 (0.9634) acc 59.3750 (71.3281) lr 3.6258e-04 eta 0:05:44
epoch [38/50] batch [220/319] time 0.092 (0.087) data 0.000 (0.003) loss 2.0416 (1.8998) teacher_loss 0.9634 (0.8116) loss_zs_kd 1.2437 (1.4052) loss_oracle 1.0683 (1.2484) kd_loss 0.9714 (0.9633) acc 65.6250 (71.3636) lr 3.6258e-04 eta 0:05:43
epoch [38/50] batch [240/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.8573 (1.8960) teacher_loss 0.8039 (0.8069) loss_zs_kd 1.1516 (1.4082) loss_oracle 1.2212 (1.2464) kd_loss 0.9313 (0.9644) acc 68.7500 (71.4323) lr 3.6258e-04 eta 0:05:39
epoch [38/50] batch [260/319] time 0.084 (0.087) data 0.000 (0.003) loss 2.1911 (1.9007) teacher_loss 1.1510 (0.8115) loss_zs_kd 1.6820 (1.4109) loss_oracle 1.2056 (1.2458) kd_loss 0.9195 (0.9646) acc 71.8750 (71.4303) lr 3.6258e-04 eta 0:05:36
epoch [38/50] batch [280/319] time 0.093 (0.086) data 0.000 (0.003) loss 1.8202 (1.9052) teacher_loss 0.6651 (0.8140) loss_zs_kd 1.5873 (1.4161) loss_oracle 1.2179 (1.2443) kd_loss 1.0333 (0.9668) acc 75.0000 (71.3393) lr 3.6258e-04 eta 0:05:33
epoch [38/50] batch [300/319] time 0.090 (0.086) data 0.000 (0.002) loss 2.2742 (1.9127) teacher_loss 1.1863 (0.8201) loss_zs_kd 1.7366 (1.4229) loss_oracle 1.2120 (1.2428) kd_loss 0.9666 (0.9683) acc 59.3750 (71.0729) lr 3.6258e-04 eta 0:05:30
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,727
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 58.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,647
* accuracy: 58.0%
* error: 42.0%
* macro_f1: 23.7%
******* Domain 2 best val acc:      63.8%, epoch: 36 *******
******* Domain 2 best val test acc: 57.6%, epoch: 36 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [39/50] batch [20/319] time 0.076 (0.108) data 0.000 (0.028) loss 2.0034 (1.9597) teacher_loss 0.9115 (0.8574) loss_zs_kd 1.4927 (1.3959) loss_oracle 1.3279 (1.2437) kd_loss 0.9591 (0.9780) acc 68.7500 (72.8125) lr 3.1545e-04 eta 0:06:51
epoch [39/50] batch [40/319] time 0.080 (0.092) data 0.000 (0.014) loss 2.3021 (1.9518) teacher_loss 1.1846 (0.8503) loss_zs_kd 1.3611 (1.3964) loss_oracle 1.1467 (1.2500) kd_loss 1.0028 (0.9765) acc 56.2500 (72.5000) lr 3.1545e-04 eta 0:05:49
epoch [39/50] batch [60/319] time 0.081 (0.089) data 0.000 (0.010) loss 1.6406 (1.9542) teacher_loss 0.5740 (0.8461) loss_zs_kd 1.3092 (1.3947) loss_oracle 1.2938 (1.2520) kd_loss 0.9373 (0.9830) acc 87.5000 (72.1354) lr 3.1545e-04 eta 0:05:33
epoch [39/50] batch [80/319] time 0.082 (0.087) data 0.000 (0.007) loss 2.2187 (1.9495) teacher_loss 1.1294 (0.8451) loss_zs_kd 1.6554 (1.4043) loss_oracle 1.1997 (1.2500) kd_loss 0.9694 (0.9794) acc 59.3750 (71.0938) lr 3.1545e-04 eta 0:05:26
epoch [39/50] batch [100/319] time 0.077 (0.087) data 0.000 (0.006) loss 2.2048 (1.9570) teacher_loss 1.0827 (0.8514) loss_zs_kd 1.3958 (1.4018) loss_oracle 1.2816 (1.2495) kd_loss 0.9940 (0.9807) acc 62.5000 (71.1875) lr 3.1545e-04 eta 0:05:23
epoch [39/50] batch [120/319] time 0.076 (0.085) data 0.000 (0.005) loss 2.0196 (1.9464) teacher_loss 0.9427 (0.8420) loss_zs_kd 1.2009 (1.4027) loss_oracle 1.3151 (1.2446) kd_loss 0.9454 (0.9800) acc 59.3750 (71.4062) lr 3.1545e-04 eta 0:05:15
epoch [39/50] batch [140/319] time 0.080 (0.086) data 0.000 (0.004) loss 1.7957 (1.9406) teacher_loss 0.6273 (0.8355) loss_zs_kd 1.5729 (1.4039) loss_oracle 1.3357 (1.2433) kd_loss 1.0349 (0.9807) acc 75.0000 (71.8080) lr 3.1545e-04 eta 0:05:19
epoch [39/50] batch [160/319] time 0.091 (0.086) data 0.000 (0.004) loss 1.7950 (1.9357) teacher_loss 0.7195 (0.8331) loss_zs_kd 1.6243 (1.4081) loss_oracle 1.1638 (1.2382) kd_loss 0.9591 (0.9788) acc 65.6250 (71.6602) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [180/319] time 0.089 (0.086) data 0.000 (0.003) loss 1.7306 (1.9351) teacher_loss 0.7780 (0.8348) loss_zs_kd 1.4068 (1.4060) loss_oracle 1.1431 (1.2343) kd_loss 0.8383 (0.9768) acc 75.0000 (71.6667) lr 3.1545e-04 eta 0:05:13
epoch [39/50] batch [200/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.7575 (1.9302) teacher_loss 0.6407 (0.8328) loss_zs_kd 1.2037 (1.4020) loss_oracle 1.2408 (1.2329) kd_loss 0.9927 (0.9742) acc 84.3750 (71.5312) lr 3.1545e-04 eta 0:05:11
epoch [39/50] batch [220/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.8340 (1.9263) teacher_loss 0.7741 (0.8290) loss_zs_kd 1.4542 (1.4057) loss_oracle 1.2678 (1.2342) kd_loss 0.9331 (0.9739) acc 75.0000 (71.7898) lr 3.1545e-04 eta 0:05:09
epoch [39/50] batch [240/319] time 0.075 (0.085) data 0.000 (0.003) loss 2.0931 (1.9314) teacher_loss 1.0320 (0.8356) loss_zs_kd 1.3824 (1.4035) loss_oracle 1.1695 (1.2329) kd_loss 0.9442 (0.9724) acc 65.6250 (71.4844) lr 3.1545e-04 eta 0:05:06
epoch [39/50] batch [260/319] time 0.078 (0.085) data 0.000 (0.002) loss 1.7728 (1.9337) teacher_loss 0.7333 (0.8380) loss_zs_kd 1.2914 (1.4004) loss_oracle 1.1846 (1.2301) kd_loss 0.9211 (0.9726) acc 65.6250 (71.2861) lr 3.1545e-04 eta 0:05:03
epoch [39/50] batch [280/319] time 0.090 (0.085) data 0.000 (0.002) loss 2.3938 (1.9344) teacher_loss 1.2578 (0.8395) loss_zs_kd 1.3927 (1.3968) loss_oracle 1.2616 (1.2297) kd_loss 1.0098 (0.9719) acc 53.1250 (71.1830) lr 3.1545e-04 eta 0:05:02
epoch [39/50] batch [300/319] time 0.078 (0.085) data 0.000 (0.002) loss 1.9152 (1.9342) teacher_loss 0.7635 (0.8398) loss_zs_kd 1.6529 (1.3940) loss_oracle 1.3211 (1.2295) kd_loss 1.0195 (0.9715) acc 78.1250 (71.2292) lr 3.1545e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,809
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 58.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,588
* accuracy: 57.4%
* error: 42.6%
* macro_f1: 23.6%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [40/50] batch [20/319] time 0.080 (0.113) data 0.000 (0.026) loss 1.9080 (1.8878) teacher_loss 0.7517 (0.8061) loss_zs_kd 1.2765 (1.3177) loss_oracle 1.2494 (1.2159) kd_loss 1.0313 (0.9601) acc 71.8750 (71.8750) lr 2.7103e-04 eta 0:06:33
epoch [40/50] batch [40/319] time 0.091 (0.099) data 0.000 (0.013) loss 1.9450 (1.9476) teacher_loss 0.7858 (0.8615) loss_zs_kd 1.2811 (1.3412) loss_oracle 1.1909 (1.2170) kd_loss 1.0402 (0.9644) acc 75.0000 (70.3906) lr 2.7103e-04 eta 0:05:42
epoch [40/50] batch [60/319] time 0.089 (0.094) data 0.001 (0.009) loss 1.8833 (1.9351) teacher_loss 0.8221 (0.8526) loss_zs_kd 1.4464 (1.3561) loss_oracle 1.3044 (1.2161) kd_loss 0.9308 (0.9609) acc 65.6250 (70.6771) lr 2.7103e-04 eta 0:05:25
epoch [40/50] batch [80/319] time 0.074 (0.092) data 0.000 (0.007) loss 1.9779 (1.9150) teacher_loss 0.8869 (0.8336) loss_zs_kd 1.2639 (1.3670) loss_oracle 1.2557 (1.2187) kd_loss 0.9654 (0.9595) acc 65.6250 (70.9375) lr 2.7103e-04 eta 0:05:15
epoch [40/50] batch [100/319] time 0.084 (0.090) data 0.000 (0.006) loss 1.8974 (1.9130) teacher_loss 0.7997 (0.8291) loss_zs_kd 1.1423 (1.3711) loss_oracle 1.1301 (1.2191) kd_loss 0.9847 (0.9620) acc 71.8750 (71.2812) lr 2.7103e-04 eta 0:05:07
epoch [40/50] batch [120/319] time 0.081 (0.089) data 0.000 (0.005) loss 1.8001 (1.9001) teacher_loss 0.7422 (0.8196) loss_zs_kd 1.5716 (1.3778) loss_oracle 1.2146 (1.2139) kd_loss 0.9365 (0.9592) acc 75.0000 (71.9271) lr 2.7103e-04 eta 0:05:02
epoch [40/50] batch [140/319] time 0.076 (0.088) data 0.000 (0.004) loss 1.8626 (1.9066) teacher_loss 0.8088 (0.8276) loss_zs_kd 1.5436 (1.3733) loss_oracle 1.2674 (1.2147) kd_loss 0.9271 (0.9576) acc 71.8750 (71.6295) lr 2.7103e-04 eta 0:04:57
epoch [40/50] batch [160/319] time 0.087 (0.088) data 0.000 (0.004) loss 2.0214 (1.9030) teacher_loss 0.9622 (0.8214) loss_zs_kd 1.3741 (1.3860) loss_oracle 1.2310 (1.2173) kd_loss 0.9361 (0.9599) acc 62.5000 (71.9922) lr 2.7103e-04 eta 0:04:54
epoch [40/50] batch [180/319] time 0.082 (0.087) data 0.000 (0.003) loss 2.2837 (1.9016) teacher_loss 1.2000 (0.8202) loss_zs_kd 1.4108 (1.3913) loss_oracle 1.2305 (1.2191) kd_loss 0.9606 (0.9595) acc 65.6250 (72.0833) lr 2.7103e-04 eta 0:04:50
epoch [40/50] batch [200/319] time 0.082 (0.087) data 0.000 (0.003) loss 2.0798 (1.9144) teacher_loss 0.9448 (0.8322) loss_zs_kd 1.4251 (1.3952) loss_oracle 1.2533 (1.2233) kd_loss 1.0098 (0.9599) acc 71.8750 (71.8125) lr 2.7103e-04 eta 0:04:47
epoch [40/50] batch [220/319] time 0.097 (0.087) data 0.000 (0.003) loss 1.9471 (1.9176) teacher_loss 0.9256 (0.8361) loss_zs_kd 1.4137 (1.3967) loss_oracle 1.1908 (1.2226) kd_loss 0.9025 (0.9593) acc 56.2500 (71.4915) lr 2.7103e-04 eta 0:04:45
epoch [40/50] batch [240/319] time 0.076 (0.086) data 0.000 (0.002) loss 2.0878 (1.9119) teacher_loss 1.0552 (0.8320) loss_zs_kd 1.4128 (1.3952) loss_oracle 1.2145 (1.2225) kd_loss 0.9112 (0.9576) acc 62.5000 (71.5495) lr 2.7103e-04 eta 0:04:42
epoch [40/50] batch [260/319] time 0.091 (0.086) data 0.001 (0.002) loss 1.9295 (1.9124) teacher_loss 0.8252 (0.8324) loss_zs_kd 1.6814 (1.4033) loss_oracle 1.2049 (1.2233) kd_loss 0.9838 (0.9577) acc 68.7500 (71.5264) lr 2.7103e-04 eta 0:04:40
epoch [40/50] batch [280/319] time 0.086 (0.086) data 0.000 (0.002) loss 2.2316 (1.9145) teacher_loss 1.1059 (0.8340) loss_zs_kd 1.3018 (1.4029) loss_oracle 1.2531 (1.2241) kd_loss 1.0004 (0.9581) acc 59.3750 (71.3504) lr 2.7103e-04 eta 0:04:37
epoch [40/50] batch [300/319] time 0.084 (0.086) data 0.000 (0.002) loss 1.9761 (1.9189) teacher_loss 0.9780 (0.8381) loss_zs_kd 1.2409 (1.4029) loss_oracle 1.2801 (1.2232) kd_loss 0.8701 (0.9585) acc 68.7500 (71.1667) lr 2.7103e-04 eta 0:04:37
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,749
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,626
* accuracy: 57.8%
* error: 42.2%
* macro_f1: 24.1%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [41/50] batch [20/319] time 0.089 (0.123) data 0.000 (0.033) loss 2.1524 (1.8587) teacher_loss 0.9634 (0.7747) loss_zs_kd 1.5185 (1.4470) loss_oracle 1.2771 (1.2318) kd_loss 1.0613 (0.9608) acc 59.3750 (72.1875) lr 2.2949e-04 eta 0:06:28
epoch [41/50] batch [40/319] time 0.074 (0.102) data 0.000 (0.017) loss 2.0679 (1.8879) teacher_loss 0.9671 (0.8022) loss_zs_kd 1.6762 (1.4141) loss_oracle 1.2426 (1.2211) kd_loss 0.9765 (0.9636) acc 68.7500 (71.4844) lr 2.2949e-04 eta 0:05:21
epoch [41/50] batch [60/319] time 0.085 (0.095) data 0.001 (0.011) loss 1.9232 (1.9000) teacher_loss 0.8915 (0.8176) loss_zs_kd 1.4540 (1.4134) loss_oracle 1.3406 (1.2257) kd_loss 0.8977 (0.9598) acc 71.8750 (71.0417) lr 2.2949e-04 eta 0:04:57
epoch [41/50] batch [80/319] time 0.078 (0.095) data 0.000 (0.009) loss 1.7544 (1.8847) teacher_loss 0.6730 (0.8052) loss_zs_kd 1.5776 (1.4377) loss_oracle 1.1461 (1.2276) kd_loss 0.9667 (0.9568) acc 71.8750 (71.7188) lr 2.2949e-04 eta 0:04:55
epoch [41/50] batch [100/319] time 0.082 (0.092) data 0.000 (0.007) loss 1.9504 (1.8896) teacher_loss 0.8524 (0.8098) loss_zs_kd 1.4220 (1.4417) loss_oracle 1.2291 (1.2251) kd_loss 0.9750 (0.9573) acc 81.2500 (71.7188) lr 2.2949e-04 eta 0:04:45
epoch [41/50] batch [120/319] time 0.093 (0.091) data 0.000 (0.006) loss 1.6425 (1.8946) teacher_loss 0.5727 (0.8160) loss_zs_kd 1.4105 (1.4368) loss_oracle 1.2287 (1.2272) kd_loss 0.9469 (0.9559) acc 78.1250 (71.5625) lr 2.2949e-04 eta 0:04:40
epoch [41/50] batch [140/319] time 0.082 (0.090) data 0.000 (0.005) loss 1.6144 (1.8880) teacher_loss 0.5487 (0.8093) loss_zs_kd 1.4122 (1.4320) loss_oracle 1.1063 (1.2242) kd_loss 0.9551 (0.9563) acc 84.3750 (71.8973) lr 2.2949e-04 eta 0:04:34
epoch [41/50] batch [160/319] time 0.089 (0.089) data 0.000 (0.004) loss 2.1366 (1.8885) teacher_loss 0.9557 (0.8109) loss_zs_kd 1.3018 (1.4276) loss_oracle 1.1913 (1.2255) kd_loss 1.0618 (0.9551) acc 68.7500 (71.9727) lr 2.2949e-04 eta 0:04:31
epoch [41/50] batch [180/319] time 0.079 (0.089) data 0.000 (0.004) loss 1.8160 (1.8901) teacher_loss 0.7813 (0.8140) loss_zs_kd 1.3206 (1.4251) loss_oracle 1.0633 (1.2239) kd_loss 0.9283 (0.9538) acc 75.0000 (71.9097) lr 2.2949e-04 eta 0:04:28
epoch [41/50] batch [200/319] time 0.079 (0.089) data 0.000 (0.004) loss 1.7546 (1.8815) teacher_loss 0.6070 (0.8063) loss_zs_kd 1.4654 (1.4182) loss_oracle 1.2830 (1.2235) kd_loss 1.0193 (0.9529) acc 78.1250 (72.1719) lr 2.2949e-04 eta 0:04:24
epoch [41/50] batch [220/319] time 0.084 (0.088) data 0.000 (0.003) loss 1.7698 (1.8813) teacher_loss 0.8163 (0.8072) loss_zs_kd 1.4673 (1.4177) loss_oracle 1.1789 (1.2225) kd_loss 0.8356 (0.9518) acc 75.0000 (72.2727) lr 2.2949e-04 eta 0:04:21
epoch [41/50] batch [240/319] time 0.088 (0.088) data 0.000 (0.003) loss 1.9960 (1.8810) teacher_loss 0.9125 (0.8069) loss_zs_kd 1.4001 (1.4214) loss_oracle 1.1992 (1.2238) kd_loss 0.9636 (0.9517) acc 59.3750 (72.3828) lr 2.2949e-04 eta 0:04:19
epoch [41/50] batch [260/319] time 0.084 (0.088) data 0.000 (0.003) loss 1.8986 (1.8853) teacher_loss 0.8486 (0.8109) loss_zs_kd 1.3780 (1.4207) loss_oracle 1.1696 (1.2238) kd_loss 0.9330 (0.9521) acc 71.8750 (72.1394) lr 2.2949e-04 eta 0:04:17
epoch [41/50] batch [280/319] time 0.088 (0.088) data 0.001 (0.003) loss 1.7372 (1.8898) teacher_loss 0.8011 (0.8161) loss_zs_kd 1.1860 (1.4198) loss_oracle 1.2698 (1.2231) kd_loss 0.8091 (0.9514) acc 84.3750 (71.9754) lr 2.2949e-04 eta 0:04:15
epoch [41/50] batch [300/319] time 0.084 (0.088) data 0.000 (0.003) loss 1.9574 (1.8890) teacher_loss 0.9503 (0.8157) loss_zs_kd 1.2509 (1.4150) loss_oracle 1.1994 (1.2241) kd_loss 0.8872 (0.9509) acc 68.7500 (71.9479) lr 2.2949e-04 eta 0:04:12
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,733
* accuracy: 62.4%
* error: 37.6%
* macro_f1: 57.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,605
* accuracy: 57.6%
* error: 42.4%
* macro_f1: 24.2%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [42/50] batch [20/319] time 0.080 (0.123) data 0.000 (0.034) loss 1.8579 (1.9091) teacher_loss 0.8160 (0.8486) loss_zs_kd 1.6187 (1.3654) loss_oracle 1.2424 (1.2015) kd_loss 0.9176 (0.9403) acc 68.7500 (71.5625) lr 1.9098e-04 eta 0:05:51
epoch [42/50] batch [40/319] time 0.070 (0.102) data 0.000 (0.017) loss 1.5008 (1.9127) teacher_loss 0.4984 (0.8529) loss_zs_kd 1.3021 (1.3668) loss_oracle 1.2997 (1.2123) kd_loss 0.8725 (0.9386) acc 81.2500 (69.6875) lr 1.9098e-04 eta 0:04:47
epoch [42/50] batch [60/319] time 0.092 (0.096) data 0.001 (0.012) loss 1.8249 (1.9174) teacher_loss 0.7245 (0.8560) loss_zs_kd 1.2656 (1.3795) loss_oracle 1.1001 (1.2066) kd_loss 0.9903 (0.9408) acc 81.2500 (70.1562) lr 1.9098e-04 eta 0:04:29
epoch [42/50] batch [80/319] time 0.078 (0.092) data 0.001 (0.009) loss 2.0751 (1.9223) teacher_loss 1.0260 (0.8584) loss_zs_kd 1.4100 (1.3832) loss_oracle 1.1341 (1.2067) kd_loss 0.9357 (0.9432) acc 53.1250 (70.0000) lr 1.9098e-04 eta 0:04:17
epoch [42/50] batch [100/319] time 0.074 (0.087) data 0.000 (0.007) loss 2.2664 (1.9310) teacher_loss 1.1785 (0.8639) loss_zs_kd 1.5196 (1.3839) loss_oracle 1.2672 (1.2072) kd_loss 0.9612 (0.9463) acc 65.6250 (70.1562) lr 1.9098e-04 eta 0:04:02
epoch [42/50] batch [120/319] time 0.074 (0.085) data 0.000 (0.006) loss 1.9818 (1.9239) teacher_loss 0.9131 (0.8576) loss_zs_kd 1.5386 (1.3901) loss_oracle 1.2383 (1.2049) kd_loss 0.9449 (0.9459) acc 68.7500 (70.4427) lr 1.9098e-04 eta 0:03:54
epoch [42/50] batch [140/319] time 0.071 (0.082) data 0.000 (0.005) loss 1.6192 (1.9201) teacher_loss 0.5659 (0.8553) loss_zs_kd 1.3755 (1.3877) loss_oracle 1.1112 (1.2011) kd_loss 0.9421 (0.9447) acc 84.3750 (70.6027) lr 1.9098e-04 eta 0:03:45
epoch [42/50] batch [160/319] time 0.088 (0.083) data 0.000 (0.005) loss 2.3691 (1.9191) teacher_loss 1.2506 (0.8573) loss_zs_kd 1.4742 (1.3792) loss_oracle 1.3060 (1.1995) kd_loss 0.9880 (0.9418) acc 56.2500 (70.4883) lr 1.9098e-04 eta 0:03:43
epoch [42/50] batch [180/319] time 0.087 (0.083) data 0.000 (0.004) loss 1.8623 (1.9140) teacher_loss 0.7303 (0.8517) loss_zs_kd 1.4466 (1.3866) loss_oracle 1.2894 (1.2024) kd_loss 1.0030 (0.9420) acc 65.6250 (70.7639) lr 1.9098e-04 eta 0:03:43
epoch [42/50] batch [200/319] time 0.090 (0.083) data 0.000 (0.004) loss 2.0062 (1.9119) teacher_loss 0.9275 (0.8466) loss_zs_kd 1.1954 (1.3876) loss_oracle 1.1142 (1.2034) kd_loss 0.9674 (0.9449) acc 62.5000 (70.8906) lr 1.9098e-04 eta 0:03:42
epoch [42/50] batch [220/319] time 0.082 (0.084) data 0.000 (0.003) loss 1.9828 (1.9043) teacher_loss 0.9087 (0.8387) loss_zs_kd 1.2493 (1.3899) loss_oracle 1.2172 (1.2035) kd_loss 0.9523 (0.9453) acc 65.6250 (71.2074) lr 1.9098e-04 eta 0:03:41
epoch [42/50] batch [240/319] time 0.083 (0.083) data 0.000 (0.003) loss 2.0293 (1.9000) teacher_loss 0.9237 (0.8357) loss_zs_kd 1.4868 (1.3930) loss_oracle 1.1538 (1.2044) kd_loss 0.9902 (0.9439) acc 71.8750 (71.3151) lr 1.9098e-04 eta 0:03:39
epoch [42/50] batch [260/319] time 0.076 (0.084) data 0.000 (0.003) loss 1.8724 (1.8950) teacher_loss 0.7632 (0.8306) loss_zs_kd 1.5774 (1.3957) loss_oracle 1.2954 (1.2057) kd_loss 0.9797 (0.9438) acc 71.8750 (71.4423) lr 1.9098e-04 eta 0:03:39
epoch [42/50] batch [280/319] time 0.080 (0.084) data 0.000 (0.003) loss 1.8814 (1.8945) teacher_loss 0.8162 (0.8282) loss_zs_kd 1.1873 (1.3992) loss_oracle 1.2452 (1.2062) kd_loss 0.9407 (0.9457) acc 71.8750 (71.6183) lr 1.9098e-04 eta 0:03:37
epoch [42/50] batch [300/319] time 0.086 (0.084) data 0.000 (0.003) loss 1.6656 (1.8985) teacher_loss 0.6881 (0.8313) loss_zs_kd 1.4927 (1.4022) loss_oracle 1.1897 (1.2055) kd_loss 0.8585 (0.9467) acc 81.2500 (71.4375) lr 1.9098e-04 eta 0:03:35
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,762
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,555
* accuracy: 57.1%
* error: 42.9%
* macro_f1: 23.4%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [43/50] batch [20/319] time 0.083 (0.113) data 0.000 (0.029) loss 1.9775 (1.9025) teacher_loss 0.8876 (0.8260) loss_zs_kd 1.5862 (1.4068) loss_oracle 1.1485 (1.2062) kd_loss 0.9751 (0.9560) acc 71.8750 (72.8125) lr 1.5567e-04 eta 0:04:45
epoch [43/50] batch [40/319] time 0.083 (0.097) data 0.000 (0.015) loss 2.3393 (1.8888) teacher_loss 1.2857 (0.8242) loss_zs_kd 1.3527 (1.3904) loss_oracle 1.2553 (1.2114) kd_loss 0.9280 (0.9434) acc 50.0000 (71.5625) lr 1.5567e-04 eta 0:04:04
epoch [43/50] batch [60/319] time 0.074 (0.096) data 0.000 (0.010) loss 2.1139 (1.8761) teacher_loss 1.0223 (0.8066) loss_zs_kd 1.4692 (1.3863) loss_oracle 1.2572 (1.2086) kd_loss 0.9658 (0.9486) acc 62.5000 (71.1458) lr 1.5567e-04 eta 0:03:58
epoch [43/50] batch [80/319] time 0.085 (0.092) data 0.000 (0.008) loss 1.7558 (1.8901) teacher_loss 0.7540 (0.8202) loss_zs_kd 1.4016 (1.3846) loss_oracle 1.0541 (1.2045) kd_loss 0.8964 (0.9495) acc 78.1250 (71.6016) lr 1.5567e-04 eta 0:03:48
epoch [43/50] batch [100/319] time 0.076 (0.090) data 0.000 (0.006) loss 1.8164 (1.8881) teacher_loss 0.7473 (0.8173) loss_zs_kd 1.2780 (1.3772) loss_oracle 1.2842 (1.2037) kd_loss 0.9407 (0.9504) acc 68.7500 (71.5000) lr 1.5567e-04 eta 0:03:40
epoch [43/50] batch [120/319] time 0.082 (0.089) data 0.000 (0.005) loss 1.9123 (1.8900) teacher_loss 0.8506 (0.8173) loss_zs_kd 1.3644 (1.3708) loss_oracle 1.2025 (1.2015) kd_loss 0.9415 (0.9526) acc 65.6250 (71.9531) lr 1.5567e-04 eta 0:03:36
epoch [43/50] batch [140/319] time 0.069 (0.088) data 0.000 (0.004) loss 2.2582 (1.8928) teacher_loss 1.2203 (0.8212) loss_zs_kd 1.2358 (1.3811) loss_oracle 1.2583 (1.2027) kd_loss 0.9120 (0.9514) acc 62.5000 (71.8973) lr 1.5567e-04 eta 0:03:31
epoch [43/50] batch [160/319] time 0.089 (0.087) data 0.000 (0.004) loss 1.5982 (1.8889) teacher_loss 0.5836 (0.8168) loss_zs_kd 1.4897 (1.3852) loss_oracle 1.3086 (1.2094) kd_loss 0.8837 (0.9512) acc 81.2500 (71.8164) lr 1.5567e-04 eta 0:03:28
epoch [43/50] batch [180/319] time 0.088 (0.087) data 0.000 (0.004) loss 1.7064 (1.8928) teacher_loss 0.6624 (0.8214) loss_zs_kd 1.3166 (1.3817) loss_oracle 1.1235 (1.2074) kd_loss 0.9316 (0.9506) acc 75.0000 (71.7014) lr 1.5567e-04 eta 0:03:26
epoch [43/50] batch [200/319] time 0.087 (0.086) data 0.000 (0.003) loss 1.9784 (1.8974) teacher_loss 0.8957 (0.8263) loss_zs_kd 1.2479 (1.3825) loss_oracle 1.2614 (1.2094) kd_loss 0.9565 (0.9502) acc 62.5000 (71.5781) lr 1.5567e-04 eta 0:03:22
epoch [43/50] batch [220/319] time 0.088 (0.086) data 0.000 (0.003) loss 2.0248 (1.9017) teacher_loss 0.9284 (0.8317) loss_zs_kd 1.5240 (1.3753) loss_oracle 1.1772 (1.2122) kd_loss 0.9787 (0.9488) acc 68.7500 (71.2926) lr 1.5567e-04 eta 0:03:20
epoch [43/50] batch [240/319] time 0.075 (0.086) data 0.000 (0.003) loss 1.9520 (1.9005) teacher_loss 0.8530 (0.8309) loss_zs_kd 1.7208 (1.3778) loss_oracle 1.1478 (1.2114) kd_loss 0.9842 (0.9484) acc 62.5000 (71.2630) lr 1.5567e-04 eta 0:03:18
epoch [43/50] batch [260/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.7273 (1.9032) teacher_loss 0.6728 (0.8334) loss_zs_kd 1.4219 (1.3763) loss_oracle 1.2129 (1.2101) kd_loss 0.9332 (0.9488) acc 75.0000 (71.2500) lr 1.5567e-04 eta 0:03:16
epoch [43/50] batch [280/319] time 0.086 (0.085) data 0.000 (0.002) loss 1.8628 (1.8992) teacher_loss 0.8339 (0.8299) loss_zs_kd 1.4363 (1.3756) loss_oracle 1.0046 (1.2121) kd_loss 0.9284 (0.9481) acc 75.0000 (71.2835) lr 1.5567e-04 eta 0:03:14
epoch [43/50] batch [300/319] time 0.079 (0.085) data 0.000 (0.002) loss 1.9100 (1.8988) teacher_loss 0.8806 (0.8295) loss_zs_kd 1.1366 (1.3759) loss_oracle 1.2475 (1.2140) kd_loss 0.9046 (0.9479) acc 78.1250 (71.2917) lr 1.5567e-04 eta 0:03:12
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,761
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 58.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,606
* accuracy: 57.6%
* error: 42.4%
* macro_f1: 23.5%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [44/50] batch [20/319] time 0.085 (0.123) data 0.000 (0.027) loss 2.1839 (1.8620) teacher_loss 1.1538 (0.8047) loss_zs_kd 1.3603 (1.3595) loss_oracle 1.2076 (1.2098) kd_loss 0.9093 (0.9363) acc 62.5000 (73.5938) lr 1.2369e-04 eta 0:04:31
epoch [44/50] batch [40/319] time 0.093 (0.105) data 0.000 (0.013) loss 2.1325 (1.8936) teacher_loss 1.0177 (0.8273) loss_zs_kd 1.2263 (1.3843) loss_oracle 1.1967 (1.2171) kd_loss 0.9952 (0.9446) acc 59.3750 (71.4844) lr 1.2369e-04 eta 0:03:49
epoch [44/50] batch [60/319] time 0.079 (0.098) data 0.001 (0.009) loss 1.7047 (1.9119) teacher_loss 0.6492 (0.8448) loss_zs_kd 1.5020 (1.3856) loss_oracle 1.1617 (1.2185) kd_loss 0.9393 (0.9453) acc 81.2500 (70.4688) lr 1.2369e-04 eta 0:03:32
epoch [44/50] batch [80/319] time 0.085 (0.094) data 0.000 (0.007) loss 1.9498 (1.9096) teacher_loss 0.8296 (0.8417) loss_zs_kd 1.5023 (1.3880) loss_oracle 1.2814 (1.2182) kd_loss 0.9920 (0.9461) acc 68.7500 (70.6250) lr 1.2369e-04 eta 0:03:23
epoch [44/50] batch [100/319] time 0.079 (0.093) data 0.000 (0.006) loss 1.8309 (1.9168) teacher_loss 0.7536 (0.8442) loss_zs_kd 1.1731 (1.3954) loss_oracle 1.2478 (1.2146) kd_loss 0.9525 (0.9511) acc 68.7500 (70.9375) lr 1.2369e-04 eta 0:03:17
epoch [44/50] batch [120/319] time 0.082 (0.092) data 0.000 (0.005) loss 2.0322 (1.9294) teacher_loss 0.9987 (0.8603) loss_zs_kd 1.4499 (1.3858) loss_oracle 1.2124 (1.2151) kd_loss 0.9122 (0.9476) acc 65.6250 (70.5469) lr 1.2369e-04 eta 0:03:14
epoch [44/50] batch [140/319] time 0.086 (0.091) data 0.000 (0.004) loss 1.9769 (1.9397) teacher_loss 0.8427 (0.8693) loss_zs_kd 1.3061 (1.3773) loss_oracle 1.2908 (1.2123) kd_loss 1.0052 (0.9492) acc 71.8750 (70.1786) lr 1.2369e-04 eta 0:03:09
epoch [44/50] batch [160/319] time 0.087 (0.090) data 0.000 (0.004) loss 1.9687 (1.9373) teacher_loss 0.9256 (0.8687) loss_zs_kd 1.1619 (1.3788) loss_oracle 1.1931 (1.2125) kd_loss 0.9238 (0.9474) acc 68.7500 (70.2148) lr 1.2369e-04 eta 0:03:06
epoch [44/50] batch [180/319] time 0.087 (0.090) data 0.000 (0.003) loss 2.0487 (1.9407) teacher_loss 0.9140 (0.8734) loss_zs_kd 1.0833 (1.3760) loss_oracle 1.2359 (1.2124) kd_loss 1.0111 (0.9461) acc 71.8750 (70.2083) lr 1.2369e-04 eta 0:03:03
epoch [44/50] batch [200/319] time 0.091 (0.089) data 0.000 (0.003) loss 1.6033 (1.9378) teacher_loss 0.5414 (0.8725) loss_zs_kd 1.1343 (1.3809) loss_oracle 1.0856 (1.2111) kd_loss 0.9534 (0.9442) acc 84.3750 (69.9688) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [220/319] time 0.095 (0.090) data 0.000 (0.003) loss 1.9425 (1.9344) teacher_loss 0.8348 (0.8688) loss_zs_kd 1.5148 (1.3878) loss_oracle 1.2314 (1.2113) kd_loss 0.9846 (0.9444) acc 68.7500 (70.0710) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [240/319] time 0.082 (0.089) data 0.000 (0.003) loss 2.0006 (1.9289) teacher_loss 0.9209 (0.8651) loss_zs_kd 1.6513 (1.3919) loss_oracle 1.1687 (1.2083) kd_loss 0.9628 (0.9429) acc 75.0000 (70.2083) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [260/319] time 0.079 (0.089) data 0.000 (0.002) loss 1.8344 (1.9292) teacher_loss 0.7531 (0.8662) loss_zs_kd 1.2952 (1.3897) loss_oracle 1.2723 (1.2070) kd_loss 0.9540 (0.9423) acc 71.8750 (70.0721) lr 1.2369e-04 eta 0:02:55
epoch [44/50] batch [280/319] time 0.089 (0.089) data 0.000 (0.002) loss 1.8849 (1.9293) teacher_loss 0.8541 (0.8649) loss_zs_kd 1.3787 (1.3889) loss_oracle 1.2379 (1.2077) kd_loss 0.9070 (0.9436) acc 68.7500 (70.1004) lr 1.2369e-04 eta 0:02:54
epoch [44/50] batch [300/319] time 0.087 (0.089) data 0.000 (0.002) loss 1.9109 (1.9289) teacher_loss 0.8701 (0.8650) loss_zs_kd 1.5535 (1.3895) loss_oracle 1.2649 (1.2071) kd_loss 0.9144 (0.9432) acc 65.6250 (70.1458) lr 1.2369e-04 eta 0:02:51
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,751
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,577
* accuracy: 57.3%
* error: 42.7%
* macro_f1: 23.4%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [45/50] batch [20/319] time 0.086 (0.116) data 0.001 (0.026) loss 1.7013 (1.8981) teacher_loss 0.6376 (0.8291) loss_zs_kd 0.9294 (1.3726) loss_oracle 1.1459 (1.2124) kd_loss 0.9491 (0.9478) acc 81.2500 (70.3125) lr 9.5173e-05 eta 0:03:39
epoch [45/50] batch [40/319] time 0.090 (0.103) data 0.000 (0.013) loss 2.0192 (1.8966) teacher_loss 0.9646 (0.8322) loss_zs_kd 1.2837 (1.3653) loss_oracle 1.1276 (1.2116) kd_loss 0.9419 (0.9432) acc 68.7500 (71.1719) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [60/319] time 0.092 (0.096) data 0.000 (0.009) loss 2.2405 (1.9218) teacher_loss 1.2025 (0.8517) loss_zs_kd 1.5037 (1.3903) loss_oracle 1.0629 (1.2191) kd_loss 0.9317 (0.9482) acc 68.7500 (71.1458) lr 9.5173e-05 eta 0:02:58
epoch [45/50] batch [80/319] time 0.103 (0.094) data 0.000 (0.007) loss 1.9636 (1.9228) teacher_loss 0.8242 (0.8502) loss_zs_kd 1.5661 (1.3734) loss_oracle 1.1858 (1.2141) kd_loss 1.0208 (0.9512) acc 68.7500 (70.8594) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [100/319] time 0.087 (0.092) data 0.000 (0.005) loss 1.8044 (1.9167) teacher_loss 0.7542 (0.8417) loss_zs_kd 1.3992 (1.3755) loss_oracle 1.2525 (1.2140) kd_loss 0.9250 (0.9536) acc 62.5000 (70.7812) lr 9.5173e-05 eta 0:02:46
epoch [45/50] batch [120/319] time 0.097 (0.091) data 0.000 (0.005) loss 2.1275 (1.9154) teacher_loss 1.0785 (0.8420) loss_zs_kd 1.1019 (1.3651) loss_oracle 1.2233 (1.2105) kd_loss 0.9267 (0.9523) acc 56.2500 (70.5729) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [140/319] time 0.083 (0.090) data 0.000 (0.004) loss 1.8126 (1.9075) teacher_loss 0.7946 (0.8371) loss_zs_kd 1.1725 (1.3641) loss_oracle 1.1645 (1.2085) kd_loss 0.9015 (0.9495) acc 75.0000 (70.7812) lr 9.5173e-05 eta 0:02:40
epoch [45/50] batch [160/319] time 0.150 (0.090) data 0.000 (0.004) loss 1.8854 (1.9031) teacher_loss 0.8080 (0.8335) loss_zs_kd 1.1731 (1.3531) loss_oracle 1.1492 (1.2086) kd_loss 0.9625 (0.9488) acc 65.6250 (70.6445) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [180/319] time 0.091 (0.090) data 0.001 (0.003) loss 1.9881 (1.9003) teacher_loss 0.7703 (0.8311) loss_zs_kd 1.3416 (1.3553) loss_oracle 1.3790 (1.2115) kd_loss 1.0799 (0.9481) acc 68.7500 (70.8160) lr 9.5173e-05 eta 0:02:35
epoch [45/50] batch [200/319] time 0.092 (0.089) data 0.001 (0.003) loss 1.9089 (1.9018) teacher_loss 0.8397 (0.8322) loss_zs_kd 1.3853 (1.3485) loss_oracle 1.2930 (1.2157) kd_loss 0.9399 (0.9481) acc 62.5000 (70.9531) lr 9.5173e-05 eta 0:02:32
epoch [45/50] batch [220/319] time 0.085 (0.089) data 0.000 (0.003) loss 1.7861 (1.9032) teacher_loss 0.6848 (0.8344) loss_zs_kd 1.1607 (1.3417) loss_oracle 1.2844 (1.2141) kd_loss 0.9729 (0.9474) acc 75.0000 (70.8239) lr 9.5173e-05 eta 0:02:30
epoch [45/50] batch [240/319] time 0.105 (0.089) data 0.001 (0.002) loss 2.0394 (1.9021) teacher_loss 0.9670 (0.8324) loss_zs_kd 1.6205 (1.3417) loss_oracle 1.2639 (1.2145) kd_loss 0.9460 (0.9483) acc 71.8750 (70.8594) lr 9.5173e-05 eta 0:02:28
epoch [45/50] batch [260/319] time 0.086 (0.089) data 0.000 (0.002) loss 1.8300 (1.9146) teacher_loss 0.7964 (0.8437) loss_zs_kd 1.3253 (1.3401) loss_oracle 1.2393 (1.2158) kd_loss 0.9096 (0.9493) acc 65.6250 (70.4688) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [280/319] time 0.084 (0.089) data 0.000 (0.002) loss 1.7480 (1.9193) teacher_loss 0.5802 (0.8479) loss_zs_kd 1.3583 (1.3392) loss_oracle 1.2349 (1.2159) kd_loss 1.0443 (0.9498) acc 81.2500 (70.2455) lr 9.5173e-05 eta 0:02:25
epoch [45/50] batch [300/319] time 0.097 (0.089) data 0.001 (0.002) loss 1.9108 (1.9166) teacher_loss 0.8393 (0.8447) loss_zs_kd 1.1178 (1.3406) loss_oracle 1.2777 (1.2158) kd_loss 0.9438 (0.9504) acc 78.1250 (70.4479) lr 9.5173e-05 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,760
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,605
* accuracy: 57.6%
* error: 42.4%
* macro_f1: 24.0%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [46/50] batch [20/319] time 0.082 (0.111) data 0.000 (0.024) loss 1.7686 (1.8801) teacher_loss 0.6622 (0.8069) loss_zs_kd 1.3890 (1.3550) loss_oracle 1.2781 (1.2016) kd_loss 0.9785 (0.9531) acc 75.0000 (72.0312) lr 7.0224e-05 eta 0:02:54
epoch [46/50] batch [40/319] time 0.090 (0.097) data 0.000 (0.012) loss 2.1239 (1.9033) teacher_loss 1.0470 (0.8318) loss_zs_kd 1.2385 (1.3384) loss_oracle 1.2222 (1.2080) kd_loss 0.9547 (0.9507) acc 62.5000 (71.4844) lr 7.0224e-05 eta 0:02:30
epoch [46/50] batch [60/319] time 0.080 (0.093) data 0.001 (0.008) loss 1.8495 (1.8959) teacher_loss 0.7821 (0.8191) loss_zs_kd 1.3805 (1.3410) loss_oracle 1.1754 (1.1998) kd_loss 0.9498 (0.9568) acc 81.2500 (71.8229) lr 7.0224e-05 eta 0:02:22
epoch [46/50] batch [80/319] time 0.090 (0.091) data 0.000 (0.006) loss 1.7907 (1.9058) teacher_loss 0.7206 (0.8259) loss_zs_kd 1.2025 (1.3489) loss_oracle 1.1625 (1.2088) kd_loss 0.9538 (0.9590) acc 78.1250 (71.7969) lr 7.0224e-05 eta 0:02:17
epoch [46/50] batch [100/319] time 0.083 (0.090) data 0.000 (0.005) loss 1.5978 (1.8925) teacher_loss 0.5112 (0.8154) loss_zs_kd 1.2801 (1.3520) loss_oracle 1.2359 (1.2056) kd_loss 0.9630 (0.9566) acc 81.2500 (71.9375) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [120/319] time 0.096 (0.089) data 0.000 (0.004) loss 1.8722 (1.8839) teacher_loss 0.7478 (0.8082) loss_zs_kd 1.1921 (1.3470) loss_oracle 1.2157 (1.2077) kd_loss 1.0029 (0.9549) acc 68.7500 (72.1354) lr 7.0224e-05 eta 0:02:11
epoch [46/50] batch [140/319] time 0.087 (0.088) data 0.000 (0.004) loss 1.9031 (1.8996) teacher_loss 0.8576 (0.8251) loss_zs_kd 1.0562 (1.3438) loss_oracle 1.1482 (1.2080) kd_loss 0.9307 (0.9537) acc 71.8750 (71.8080) lr 7.0224e-05 eta 0:02:08
epoch [46/50] batch [160/319] time 0.088 (0.090) data 0.000 (0.003) loss 1.6197 (1.8941) teacher_loss 0.6799 (0.8206) loss_zs_kd 1.1713 (1.3460) loss_oracle 1.2051 (1.2061) kd_loss 0.8192 (0.9529) acc 81.2500 (72.0703) lr 7.0224e-05 eta 0:02:08
epoch [46/50] batch [180/319] time 0.082 (0.089) data 0.000 (0.003) loss 2.1182 (1.8963) teacher_loss 1.0148 (0.8267) loss_zs_kd 1.1182 (1.3501) loss_oracle 1.3445 (1.2074) kd_loss 0.9690 (0.9488) acc 65.6250 (71.7882) lr 7.0224e-05 eta 0:02:05
epoch [46/50] batch [200/319] time 0.083 (0.089) data 0.000 (0.003) loss 2.0117 (1.8965) teacher_loss 0.9231 (0.8264) loss_zs_kd 1.2057 (1.3511) loss_oracle 1.3662 (1.2100) kd_loss 0.9520 (0.9491) acc 68.7500 (71.6094) lr 7.0224e-05 eta 0:02:03
epoch [46/50] batch [220/319] time 0.088 (0.088) data 0.000 (0.003) loss 2.2780 (1.9059) teacher_loss 1.1463 (0.8345) loss_zs_kd 1.4066 (1.3498) loss_oracle 1.2207 (1.2114) kd_loss 1.0096 (0.9502) acc 59.3750 (71.3068) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [240/319] time 0.089 (0.088) data 0.000 (0.002) loss 1.7302 (1.9072) teacher_loss 0.6661 (0.8379) loss_zs_kd 1.3400 (1.3517) loss_oracle 1.2197 (1.2121) kd_loss 0.9421 (0.9481) acc 68.7500 (71.1068) lr 7.0224e-05 eta 0:01:58
epoch [46/50] batch [260/319] time 0.088 (0.088) data 0.000 (0.002) loss 1.9880 (1.9065) teacher_loss 0.8729 (0.8370) loss_zs_kd 1.4266 (1.3540) loss_oracle 1.1383 (1.2105) kd_loss 1.0012 (0.9484) acc 65.6250 (71.2019) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [280/319] time 0.080 (0.087) data 0.000 (0.002) loss 2.0874 (1.9114) teacher_loss 1.0035 (0.8411) loss_zs_kd 1.1848 (1.3541) loss_oracle 1.1620 (1.2108) kd_loss 0.9677 (0.9493) acc 62.5000 (71.1384) lr 7.0224e-05 eta 0:01:54
epoch [46/50] batch [300/319] time 0.087 (0.087) data 0.000 (0.002) loss 2.0795 (1.9103) teacher_loss 0.9726 (0.8391) loss_zs_kd 1.5611 (1.3553) loss_oracle 1.2465 (1.2113) kd_loss 0.9823 (0.9501) acc 62.5000 (71.1667) lr 7.0224e-05 eta 0:01:52
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,761
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,590
* accuracy: 57.4%
* error: 42.6%
* macro_f1: 24.0%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [47/50] batch [20/319] time 0.069 (0.113) data 0.000 (0.031) loss 1.6924 (1.9722) teacher_loss 0.6982 (0.8829) loss_zs_kd 1.2095 (1.3390) loss_oracle 1.1351 (1.2196) kd_loss 0.8808 (0.9674) acc 75.0000 (68.2812) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [40/319] time 0.086 (0.097) data 0.000 (0.015) loss 1.9548 (1.9552) teacher_loss 0.8864 (0.8767) loss_zs_kd 1.3448 (1.3338) loss_oracle 1.2242 (1.2163) kd_loss 0.9459 (0.9569) acc 68.7500 (69.3750) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [60/319] time 0.079 (0.092) data 0.000 (0.010) loss 2.0266 (1.9351) teacher_loss 0.9808 (0.8660) loss_zs_kd 1.5111 (1.3664) loss_oracle 1.1815 (1.2118) kd_loss 0.9277 (0.9479) acc 68.7500 (69.5312) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [80/319] time 0.088 (0.090) data 0.000 (0.008) loss 2.0489 (1.9400) teacher_loss 0.9565 (0.8678) loss_zs_kd 1.2492 (1.3493) loss_oracle 1.3091 (1.2125) kd_loss 0.9615 (0.9509) acc 65.6250 (69.4922) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [100/319] time 0.077 (0.089) data 0.000 (0.006) loss 1.7920 (1.9400) teacher_loss 0.6917 (0.8655) loss_zs_kd 1.2429 (1.3549) loss_oracle 1.1759 (1.2159) kd_loss 0.9826 (0.9530) acc 68.7500 (69.8438) lr 4.8943e-05 eta 0:01:44
epoch [47/50] batch [120/319] time 0.086 (0.088) data 0.000 (0.005) loss 1.7507 (1.9264) teacher_loss 0.7388 (0.8559) loss_zs_kd 1.2976 (1.3634) loss_oracle 1.1659 (1.2110) kd_loss 0.8953 (0.9493) acc 62.5000 (70.0781) lr 4.8943e-05 eta 0:01:41
epoch [47/50] batch [140/319] time 0.080 (0.087) data 0.000 (0.005) loss 2.1680 (1.9152) teacher_loss 1.1545 (0.8461) loss_zs_kd 1.4338 (1.3637) loss_oracle 1.2931 (1.2107) kd_loss 0.8842 (0.9480) acc 59.3750 (70.5357) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [160/319] time 0.081 (0.087) data 0.000 (0.004) loss 1.7665 (1.9080) teacher_loss 0.7304 (0.8394) loss_zs_kd 1.0507 (1.3639) loss_oracle 1.1627 (1.2127) kd_loss 0.9198 (0.9473) acc 68.7500 (70.7617) lr 4.8943e-05 eta 0:01:37
epoch [47/50] batch [180/319] time 0.095 (0.087) data 0.000 (0.004) loss 1.8429 (1.9125) teacher_loss 0.7807 (0.8417) loss_zs_kd 1.4505 (1.3658) loss_oracle 1.2829 (1.2126) kd_loss 0.9339 (0.9495) acc 71.8750 (70.6424) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [200/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.0142 (1.9035) teacher_loss 0.9286 (0.8344) loss_zs_kd 1.4533 (1.3627) loss_oracle 1.0664 (1.2101) kd_loss 0.9790 (0.9480) acc 68.7500 (70.8594) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [220/319] time 0.079 (0.086) data 0.000 (0.003) loss 1.7797 (1.9051) teacher_loss 0.7659 (0.8345) loss_zs_kd 1.2408 (1.3668) loss_oracle 1.1128 (1.2117) kd_loss 0.9025 (0.9494) acc 68.7500 (70.7670) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [240/319] time 0.086 (0.085) data 0.000 (0.003) loss 1.6092 (1.9077) teacher_loss 0.5855 (0.8380) loss_zs_kd 1.4271 (1.3674) loss_oracle 1.2090 (1.2115) kd_loss 0.9028 (0.9485) acc 78.1250 (70.7292) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [260/319] time 0.075 (0.085) data 0.000 (0.003) loss 2.0599 (1.9086) teacher_loss 0.9161 (0.8388) loss_zs_kd 1.3156 (1.3705) loss_oracle 1.2957 (1.2131) kd_loss 1.0142 (0.9485) acc 62.5000 (70.5529) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [280/319] time 0.078 (0.085) data 0.000 (0.002) loss 1.8804 (1.9079) teacher_loss 0.8603 (0.8386) loss_zs_kd 1.1841 (1.3717) loss_oracle 1.1790 (1.2133) kd_loss 0.9022 (0.9479) acc 65.6250 (70.5134) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [300/319] time 0.084 (0.085) data 0.000 (0.002) loss 1.7174 (1.9059) teacher_loss 0.6439 (0.8375) loss_zs_kd 1.2420 (1.3740) loss_oracle 1.1075 (1.2124) kd_loss 0.9627 (0.9472) acc 75.0000 (70.6146) lr 4.8943e-05 eta 0:01:22
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,751
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,601
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 23.9%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [48/50] batch [20/319] time 0.085 (0.119) data 0.000 (0.032) loss 1.8563 (1.9598) teacher_loss 0.8170 (0.8857) loss_zs_kd 1.2452 (1.3379) loss_oracle 1.2971 (1.2142) kd_loss 0.9096 (0.9527) acc 65.6250 (69.2188) lr 3.1417e-05 eta 0:01:51
epoch [48/50] batch [40/319] time 0.080 (0.101) data 0.000 (0.016) loss 1.7796 (1.9542) teacher_loss 0.7248 (0.8880) loss_zs_kd 1.2717 (1.3595) loss_oracle 1.0989 (1.2238) kd_loss 0.9449 (0.9438) acc 62.5000 (67.9688) lr 3.1417e-05 eta 0:01:32
epoch [48/50] batch [60/319] time 0.088 (0.096) data 0.001 (0.011) loss 1.8385 (1.9371) teacher_loss 0.7823 (0.8665) loss_zs_kd 1.0704 (1.3728) loss_oracle 1.2445 (1.2207) kd_loss 0.9317 (0.9485) acc 75.0000 (69.2188) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [80/319] time 0.079 (0.092) data 0.000 (0.008) loss 1.8737 (1.9193) teacher_loss 0.8070 (0.8466) loss_zs_kd 1.3022 (1.3818) loss_oracle 1.2558 (1.2184) kd_loss 0.9410 (0.9509) acc 81.2500 (70.7812) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [100/319] time 0.089 (0.089) data 0.000 (0.007) loss 1.8276 (1.9069) teacher_loss 0.8058 (0.8347) loss_zs_kd 1.2253 (1.3840) loss_oracle 1.1801 (1.2215) kd_loss 0.9038 (0.9500) acc 62.5000 (70.7188) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [120/319] time 0.093 (0.090) data 0.001 (0.006) loss 2.1127 (1.9057) teacher_loss 0.9409 (0.8300) loss_zs_kd 1.2056 (1.3824) loss_oracle 1.2862 (1.2210) kd_loss 1.0432 (0.9536) acc 71.8750 (70.9896) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [140/319] time 0.080 (0.089) data 0.000 (0.005) loss 2.1177 (1.9062) teacher_loss 1.0453 (0.8281) loss_zs_kd 1.4009 (1.3846) loss_oracle 1.2417 (1.2195) kd_loss 0.9483 (0.9562) acc 59.3750 (71.2500) lr 3.1417e-05 eta 0:01:12
epoch [48/50] batch [160/319] time 0.081 (0.088) data 0.000 (0.004) loss 1.7663 (1.9039) teacher_loss 0.6864 (0.8274) loss_zs_kd 1.4629 (1.3796) loss_oracle 1.1631 (1.2174) kd_loss 0.9636 (0.9548) acc 81.2500 (71.2695) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [180/319] time 0.083 (0.088) data 0.000 (0.004) loss 1.6838 (1.9067) teacher_loss 0.6118 (0.8320) loss_zs_kd 1.4649 (1.3742) loss_oracle 1.1357 (1.2163) kd_loss 0.9585 (0.9530) acc 78.1250 (71.1285) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [200/319] time 0.088 (0.088) data 0.000 (0.003) loss 2.2916 (1.9098) teacher_loss 1.2470 (0.8359) loss_zs_kd 1.3804 (1.3811) loss_oracle 1.2919 (1.2149) kd_loss 0.9154 (0.9523) acc 68.7500 (70.9688) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [220/319] time 0.086 (0.088) data 0.000 (0.003) loss 1.6518 (1.9055) teacher_loss 0.5907 (0.8322) loss_zs_kd 1.2222 (1.3805) loss_oracle 1.2303 (1.2134) kd_loss 0.9380 (0.9519) acc 75.0000 (71.0227) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [240/319] time 0.092 (0.087) data 0.000 (0.003) loss 2.0526 (1.9099) teacher_loss 1.0399 (0.8372) loss_zs_kd 1.3071 (1.3784) loss_oracle 1.2872 (1.2146) kd_loss 0.8839 (0.9513) acc 68.7500 (70.9245) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [260/319] time 0.089 (0.088) data 0.000 (0.003) loss 2.0792 (1.9104) teacher_loss 0.9567 (0.8375) loss_zs_kd 1.4698 (1.3811) loss_oracle 1.1912 (1.2127) kd_loss 1.0034 (0.9516) acc 68.7500 (70.9014) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [280/319] time 0.089 (0.087) data 0.000 (0.003) loss 2.4895 (1.9096) teacher_loss 1.4029 (0.8373) loss_zs_kd 1.3705 (1.3762) loss_oracle 1.2145 (1.2102) kd_loss 0.9651 (0.9512) acc 53.1250 (71.0379) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [300/319] time 0.090 (0.087) data 0.000 (0.002) loss 1.7272 (1.9081) teacher_loss 0.6982 (0.8358) loss_zs_kd 1.2905 (1.3729) loss_oracle 1.1703 (1.2113) kd_loss 0.9120 (0.9512) acc 68.7500 (71.0729) lr 3.1417e-05 eta 0:00:57
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,748
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,597
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 23.9%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [49/50] batch [20/319] time 0.090 (0.121) data 0.000 (0.032) loss 1.9714 (1.8671) teacher_loss 0.9254 (0.8170) loss_zs_kd 1.2201 (1.3836) loss_oracle 1.1587 (1.1954) kd_loss 0.9302 (0.9305) acc 71.8750 (71.2500) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [40/319] time 0.085 (0.106) data 0.000 (0.016) loss 1.8304 (1.8852) teacher_loss 0.7702 (0.8263) loss_zs_kd 1.3977 (1.3777) loss_oracle 1.1956 (1.2042) kd_loss 0.9407 (0.9384) acc 71.8750 (71.1719) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [60/319] time 0.082 (0.099) data 0.000 (0.011) loss 1.5541 (1.8892) teacher_loss 0.4507 (0.8228) loss_zs_kd 1.1318 (1.3687) loss_oracle 1.1747 (1.2057) kd_loss 0.9859 (0.9458) acc 90.6250 (71.4062) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [80/319] time 0.082 (0.095) data 0.000 (0.008) loss 2.0881 (1.8965) teacher_loss 0.9877 (0.8310) loss_zs_kd 1.4990 (1.3590) loss_oracle 1.3684 (1.2063) kd_loss 0.9635 (0.9448) acc 68.7500 (71.4453) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [100/319] time 0.086 (0.093) data 0.000 (0.007) loss 2.0384 (1.8872) teacher_loss 0.8653 (0.8234) loss_zs_kd 1.6423 (1.3543) loss_oracle 1.2256 (1.2054) kd_loss 1.0505 (0.9432) acc 65.6250 (71.2812) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [120/319] time 0.087 (0.092) data 0.000 (0.006) loss 1.7740 (1.8995) teacher_loss 0.6925 (0.8337) loss_zs_kd 1.3899 (1.3540) loss_oracle 1.2472 (1.2062) kd_loss 0.9567 (0.9453) acc 78.1250 (70.9115) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [140/319] time 0.082 (0.091) data 0.000 (0.005) loss 1.7471 (1.8942) teacher_loss 0.7327 (0.8280) loss_zs_kd 1.2297 (1.3579) loss_oracle 1.0917 (1.2058) kd_loss 0.9053 (0.9455) acc 81.2500 (71.0268) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [160/319] time 0.080 (0.090) data 0.000 (0.004) loss 1.6076 (1.8927) teacher_loss 0.6202 (0.8272) loss_zs_kd 1.4082 (1.3651) loss_oracle 1.2100 (1.2055) kd_loss 0.8665 (0.9450) acc 84.3750 (70.8984) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [180/319] time 0.087 (0.089) data 0.000 (0.004) loss 1.8339 (1.9009) teacher_loss 0.7162 (0.8330) loss_zs_kd 1.3219 (1.3689) loss_oracle 1.2452 (1.2071) kd_loss 0.9932 (0.9472) acc 81.2500 (70.9028) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [200/319] time 0.078 (0.089) data 0.000 (0.004) loss 1.9065 (1.9067) teacher_loss 0.8372 (0.8374) loss_zs_kd 1.5244 (1.3760) loss_oracle 1.3138 (1.2100) kd_loss 0.9379 (0.9483) acc 71.8750 (70.6094) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [220/319] time 0.082 (0.088) data 0.000 (0.003) loss 2.1694 (1.9080) teacher_loss 1.0858 (0.8386) loss_zs_kd 1.3151 (1.3772) loss_oracle 1.3040 (1.2113) kd_loss 0.9532 (0.9483) acc 56.2500 (70.4545) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [240/319] time 0.082 (0.088) data 0.000 (0.003) loss 1.7434 (1.9118) teacher_loss 0.5847 (0.8424) loss_zs_kd 1.5433 (1.3770) loss_oracle 1.1834 (1.2099) kd_loss 1.0403 (0.9484) acc 81.2500 (70.6510) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [260/319] time 0.089 (0.088) data 0.000 (0.003) loss 1.9003 (1.9126) teacher_loss 0.8042 (0.8419) loss_zs_kd 1.4189 (1.3762) loss_oracle 1.0686 (1.2098) kd_loss 0.9893 (0.9497) acc 68.7500 (70.7332) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [280/319] time 0.086 (0.089) data 0.000 (0.003) loss 1.7842 (1.9112) teacher_loss 0.6534 (0.8405) loss_zs_kd 1.3860 (1.3750) loss_oracle 1.2274 (1.2092) kd_loss 1.0081 (0.9497) acc 78.1250 (70.7812) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [300/319] time 0.087 (0.088) data 0.000 (0.002) loss 1.9233 (1.9055) teacher_loss 0.8833 (0.8339) loss_zs_kd 1.4439 (1.3779) loss_oracle 1.1425 (1.2087) kd_loss 0.9257 (0.9507) acc 71.8750 (71.0833) lr 1.7713e-05 eta 0:00:29
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,752
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 57.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,594
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 23.8%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
epoch [50/50] batch [20/319] time 0.085 (0.116) data 0.000 (0.029) loss 1.7851 (1.9751) teacher_loss 0.6622 (0.8994) loss_zs_kd 1.3510 (1.3406) loss_oracle 1.1548 (1.2120) kd_loss 1.0074 (0.9546) acc 68.7500 (69.6875) lr 7.8853e-06 eta 0:00:34
epoch [50/50] batch [40/319] time 0.163 (0.103) data 0.001 (0.015) loss 1.8096 (1.9415) teacher_loss 0.6335 (0.8691) loss_zs_kd 1.8478 (1.3623) loss_oracle 1.2757 (1.2016) kd_loss 1.0484 (0.9522) acc 75.0000 (69.7656) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [60/319] time 0.086 (0.100) data 0.000 (0.010) loss 1.6569 (1.9246) teacher_loss 0.6459 (0.8553) loss_zs_kd 1.3962 (1.3687) loss_oracle 1.2748 (1.1911) kd_loss 0.8835 (0.9502) acc 71.8750 (70.0000) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [80/319] time 0.086 (0.096) data 0.000 (0.007) loss 1.8859 (1.9047) teacher_loss 0.8317 (0.8362) loss_zs_kd 1.1994 (1.3626) loss_oracle 1.0563 (1.1964) kd_loss 0.9486 (0.9488) acc 62.5000 (70.7812) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [100/319] time 0.079 (0.094) data 0.000 (0.006) loss 1.9975 (1.9128) teacher_loss 0.9559 (0.8418) loss_zs_kd 1.4201 (1.3690) loss_oracle 1.2870 (1.2071) kd_loss 0.9129 (0.9503) acc 71.8750 (71.0000) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [120/319] time 0.075 (0.091) data 0.000 (0.005) loss 1.9649 (1.9118) teacher_loss 0.9509 (0.8428) loss_zs_kd 1.1807 (1.3635) loss_oracle 1.2496 (1.2104) kd_loss 0.8890 (0.9480) acc 75.0000 (70.8333) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [140/319] time 0.088 (0.090) data 0.000 (0.004) loss 1.6179 (1.9131) teacher_loss 0.5789 (0.8440) loss_zs_kd 1.2651 (1.3627) loss_oracle 1.3157 (1.2104) kd_loss 0.9074 (0.9481) acc 81.2500 (70.9375) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [160/319] time 0.075 (0.089) data 0.000 (0.004) loss 1.8371 (1.9179) teacher_loss 0.7869 (0.8472) loss_zs_kd 1.2576 (1.3682) loss_oracle 1.3048 (1.2094) kd_loss 0.9197 (0.9497) acc 71.8750 (70.7031) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [180/319] time 0.077 (0.089) data 0.000 (0.003) loss 1.8068 (1.9140) teacher_loss 0.7881 (0.8446) loss_zs_kd 1.4346 (1.3716) loss_oracle 1.1323 (1.2099) kd_loss 0.9055 (0.9484) acc 68.7500 (70.6597) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [200/319] time 0.079 (0.088) data 0.000 (0.003) loss 2.0492 (1.9232) teacher_loss 0.8888 (0.8518) loss_zs_kd 1.4071 (1.3719) loss_oracle 1.1408 (1.2081) kd_loss 1.0464 (0.9506) acc 68.7500 (70.6406) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [220/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.8024 (1.9208) teacher_loss 0.7267 (0.8490) loss_zs_kd 1.2472 (1.3752) loss_oracle 1.1782 (1.2104) kd_loss 0.9578 (0.9507) acc 81.2500 (70.9943) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [240/319] time 0.076 (0.087) data 0.000 (0.003) loss 2.2011 (1.9159) teacher_loss 1.0729 (0.8430) loss_zs_kd 1.2999 (1.3739) loss_oracle 1.2807 (1.2126) kd_loss 1.0001 (0.9516) acc 65.6250 (71.1979) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [260/319] time 0.079 (0.087) data 0.000 (0.002) loss 1.8288 (1.9178) teacher_loss 0.6455 (0.8444) loss_zs_kd 1.3484 (1.3748) loss_oracle 1.0511 (1.2108) kd_loss 1.0782 (0.9524) acc 81.2500 (71.1418) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [280/319] time 0.079 (0.086) data 0.000 (0.002) loss 2.6648 (1.9138) teacher_loss 1.5556 (0.8404) loss_zs_kd 1.2908 (1.3713) loss_oracle 1.2552 (1.2124) kd_loss 0.9837 (0.9521) acc 53.1250 (71.2054) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [300/319] time 0.082 (0.086) data 0.000 (0.002) loss 2.0259 (1.9105) teacher_loss 0.9386 (0.8375) loss_zs_kd 1.5055 (1.3726) loss_oracle 1.1674 (1.2117) kd_loss 0.9705 (0.9518) acc 59.3750 (71.2396) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,747
* accuracy: 62.7%
* error: 37.3%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,595
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 23.8%
******* Domain 2 best val acc:      64.2%, epoch: 39 *******
******* Domain 2 best val test acc: 57.4%, epoch: 39 *******
******* Domain 2 best test acc:     58.9%, epoch: 33 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:42:33

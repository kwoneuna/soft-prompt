Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_38', 'location_43', 'location_46']
Target     ['location_100']
# classes  10
# train_x  13,713
# val      5,876
# test     4,741
---------  ---------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/428] time 0.109 (0.161) data 0.000 (0.033) loss 3.4553 (3.3981) teacher_loss 2.5110 (2.4742) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0083 (0.0047) kd_loss 0.9434 (0.9234) acc 31.2500 (23.5938) lr 1.0000e-05 eta 0:57:25
epoch [1/50] batch [40/428] time 0.113 (0.134) data 0.000 (0.017) loss 3.4726 (3.3226) teacher_loss 2.4987 (2.4004) loss_zs_kd 0.0017 (0.0004) loss_oracle 0.0061 (0.0066) kd_loss 0.9733 (0.9215) acc 18.7500 (25.7812) lr 1.0000e-05 eta 0:47:32
epoch [1/50] batch [60/428] time 0.098 (0.124) data 0.000 (0.011) loss 3.4677 (3.2986) teacher_loss 2.5710 (2.3780) loss_zs_kd 0.0044 (0.0013) loss_oracle 0.0125 (0.0091) kd_loss 0.8955 (0.9197) acc 28.1250 (26.3021) lr 1.0000e-05 eta 0:44:01
epoch [1/50] batch [80/428] time 0.105 (0.118) data 0.000 (0.008) loss 3.1842 (3.2747) teacher_loss 2.2729 (2.3551) loss_zs_kd 0.0079 (0.0028) loss_oracle 0.0382 (0.0115) kd_loss 0.9075 (0.9184) acc 31.2500 (26.6406) lr 1.0000e-05 eta 0:41:47
epoch [1/50] batch [100/428] time 0.075 (0.114) data 0.000 (0.007) loss 3.2756 (3.2579) teacher_loss 2.3492 (2.3319) loss_zs_kd 0.0135 (0.0049) loss_oracle 0.1099 (0.0270) kd_loss 0.9154 (0.9233) acc 28.1250 (27.0312) lr 1.0000e-05 eta 0:40:28
epoch [1/50] batch [120/428] time 0.159 (0.114) data 0.000 (0.006) loss 3.1467 (3.2365) teacher_loss 2.2643 (2.3087) loss_zs_kd 0.0291 (0.0076) loss_oracle 0.2898 (0.0584) kd_loss 0.8534 (0.9219) acc 37.5000 (27.6823) lr 1.0000e-05 eta 0:40:34
epoch [1/50] batch [140/428] time 0.175 (0.114) data 0.000 (0.005) loss 3.2326 (3.2400) teacher_loss 2.2071 (2.3049) loss_zs_kd 0.0460 (0.0114) loss_oracle 0.4275 (0.1047) kd_loss 0.9827 (0.9246) acc 21.8750 (27.8125) lr 1.0000e-05 eta 0:40:33
epoch [1/50] batch [160/428] time 0.072 (0.114) data 0.000 (0.004) loss 3.1031 (3.2184) teacher_loss 2.0185 (2.2749) loss_zs_kd 0.1480 (0.0211) loss_oracle 0.8700 (0.1661) kd_loss 0.9976 (0.9269) acc 37.5000 (28.3984) lr 1.0000e-05 eta 0:40:20
epoch [1/50] batch [180/428] time 0.174 (0.111) data 0.000 (0.004) loss 3.3268 (3.1986) teacher_loss 2.3319 (2.2424) loss_zs_kd 0.1935 (0.0463) loss_oracle 0.7864 (0.2395) kd_loss 0.9162 (0.9322) acc 28.1250 (29.2188) lr 1.0000e-05 eta 0:39:21
epoch [1/50] batch [200/428] time 0.071 (0.111) data 0.000 (0.004) loss 3.0962 (3.1906) teacher_loss 1.9698 (2.2185) loss_zs_kd 0.3494 (0.0721) loss_oracle 1.0130 (0.3138) kd_loss 1.0251 (0.9407) acc 43.7500 (29.7344) lr 1.0000e-05 eta 0:39:11
epoch [1/50] batch [220/428] time 0.079 (0.111) data 0.000 (0.003) loss 3.4677 (3.1815) teacher_loss 2.3816 (2.1980) loss_zs_kd 0.2364 (0.0928) loss_oracle 0.7043 (0.3647) kd_loss 1.0157 (0.9470) acc 31.2500 (30.3835) lr 1.0000e-05 eta 0:39:14
epoch [1/50] batch [240/428] time 0.163 (0.112) data 0.000 (0.003) loss 3.0757 (3.1709) teacher_loss 1.9445 (2.1775) loss_zs_kd 0.3025 (0.1136) loss_oracle 0.9015 (0.4070) kd_loss 1.0410 (0.9527) acc 37.5000 (30.9115) lr 1.0000e-05 eta 0:39:25
epoch [1/50] batch [260/428] time 0.103 (0.111) data 0.000 (0.003) loss 3.5458 (3.1584) teacher_loss 2.4204 (2.1573) loss_zs_kd 0.2817 (0.1322) loss_oracle 0.9849 (0.4455) kd_loss 1.0268 (0.9566) acc 34.3750 (31.3822) lr 1.0000e-05 eta 0:39:08
epoch [1/50] batch [280/428] time 0.106 (0.110) data 0.000 (0.003) loss 2.7685 (3.1424) teacher_loss 1.6045 (2.1343) loss_zs_kd 0.4544 (0.1502) loss_oracle 1.0048 (0.4771) kd_loss 1.0636 (0.9604) acc 50.0000 (31.9531) lr 1.0000e-05 eta 0:38:49
epoch [1/50] batch [300/428] time 0.091 (0.110) data 0.000 (0.002) loss 3.3213 (3.1302) teacher_loss 2.1609 (2.1144) loss_zs_kd 0.4689 (0.1671) loss_oracle 1.0491 (0.5125) kd_loss 1.0555 (0.9645) acc 25.0000 (32.4583) lr 1.0000e-05 eta 0:38:40
epoch [1/50] batch [320/428] time 0.103 (0.110) data 0.000 (0.002) loss 2.9776 (3.1183) teacher_loss 1.7951 (2.0954) loss_zs_kd 0.4809 (0.1842) loss_oracle 1.1030 (0.5456) kd_loss 1.0722 (0.9683) acc 37.5000 (32.8711) lr 1.0000e-05 eta 0:38:29
epoch [1/50] batch [340/428] time 0.093 (0.109) data 0.000 (0.002) loss 3.1151 (3.1073) teacher_loss 1.9447 (2.0790) loss_zs_kd 0.3666 (0.1991) loss_oracle 1.0441 (0.5736) kd_loss 1.0659 (0.9709) acc 40.6250 (33.2537) lr 1.0000e-05 eta 0:38:17
epoch [1/50] batch [360/428] time 0.099 (0.109) data 0.000 (0.002) loss 2.7679 (3.0968) teacher_loss 1.5967 (2.0622) loss_zs_kd 0.4916 (0.2137) loss_oracle 1.0436 (0.5991) kd_loss 1.0668 (0.9746) acc 50.0000 (33.6111) lr 1.0000e-05 eta 0:38:04
epoch [1/50] batch [380/428] time 0.113 (0.108) data 0.000 (0.002) loss 3.2661 (3.0917) teacher_loss 2.1736 (2.0517) loss_zs_kd 0.5229 (0.2268) loss_oracle 1.0680 (0.6224) kd_loss 0.9857 (0.9778) acc 25.0000 (33.8322) lr 1.0000e-05 eta 0:37:58
epoch [1/50] batch [400/428] time 0.102 (0.108) data 0.000 (0.002) loss 2.8288 (3.0831) teacher_loss 1.6637 (2.0372) loss_zs_kd 0.6545 (0.2422) loss_oracle 1.0550 (0.6434) kd_loss 1.0596 (0.9815) acc 53.1250 (34.2109) lr 1.0000e-05 eta 0:37:53
epoch [1/50] batch [420/428] time 0.100 (0.108) data 0.000 (0.002) loss 3.2106 (3.0734) teacher_loss 2.0326 (2.0232) loss_zs_kd 0.4841 (0.2532) loss_oracle 1.0343 (0.6613) kd_loss 1.0746 (0.9841) acc 34.3750 (34.5833) lr 1.0000e-05 eta 0:37:43
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,422
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 25.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,087
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 28.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      41.2%, epoch: 1 *******
******* Domain 1 best val test acc: 44.0%, epoch: 1 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [2/50] batch [20/428] time 0.079 (0.130) data 0.000 (0.026) loss 2.8242 (3.0116) teacher_loss 1.7492 (1.8821) loss_zs_kd 0.5494 (0.3989) loss_oracle 1.0682 (1.0202) kd_loss 0.9681 (1.0275) acc 46.8750 (38.1250) lr 2.0000e-03 eta 0:45:17
epoch [2/50] batch [40/428] time 0.072 (0.101) data 0.000 (0.013) loss 2.9118 (2.8911) teacher_loss 1.7473 (1.7676) loss_zs_kd 0.7010 (0.5088) loss_oracle 1.0270 (1.0107) kd_loss 1.0618 (1.0224) acc 40.6250 (40.0000) lr 2.0000e-03 eta 0:35:23
epoch [2/50] batch [60/428] time 0.085 (0.102) data 0.000 (0.009) loss 2.6006 (2.8112) teacher_loss 1.4667 (1.6797) loss_zs_kd 0.6525 (0.5371) loss_oracle 1.0233 (1.0128) kd_loss 1.0316 (1.0302) acc 62.5000 (42.7604) lr 2.0000e-03 eta 0:35:42
epoch [2/50] batch [80/428] time 0.125 (0.105) data 0.000 (0.007) loss 2.7630 (2.7358) teacher_loss 1.6500 (1.6088) loss_zs_kd 0.7908 (0.5848) loss_oracle 1.0306 (1.0198) kd_loss 1.0099 (1.0251) acc 50.0000 (45.2734) lr 2.0000e-03 eta 0:36:28
epoch [2/50] batch [100/428] time 0.079 (0.106) data 0.000 (0.005) loss 2.6723 (2.6841) teacher_loss 1.6000 (1.5593) loss_zs_kd 0.8812 (0.6933) loss_oracle 1.0286 (1.0196) kd_loss 0.9694 (1.0228) acc 43.7500 (47.1562) lr 2.0000e-03 eta 0:36:47
epoch [2/50] batch [120/428] time 0.085 (0.105) data 0.000 (0.005) loss 2.9055 (2.6705) teacher_loss 1.8337 (1.5493) loss_zs_kd 1.0772 (0.7200) loss_oracle 1.0348 (1.0174) kd_loss 0.9683 (1.0194) acc 31.2500 (47.3438) lr 2.0000e-03 eta 0:36:24
epoch [2/50] batch [140/428] time 0.089 (0.104) data 0.000 (0.004) loss 2.1341 (2.6285) teacher_loss 1.0795 (1.5094) loss_zs_kd 1.1108 (0.7896) loss_oracle 0.9923 (1.0165) kd_loss 0.9554 (1.0174) acc 65.6250 (48.3929) lr 2.0000e-03 eta 0:36:07
epoch [2/50] batch [160/428] time 0.116 (0.104) data 0.000 (0.004) loss 2.3599 (2.6010) teacher_loss 1.1966 (1.4811) loss_zs_kd 1.1619 (0.8488) loss_oracle 1.0402 (1.0155) kd_loss 1.0593 (1.0183) acc 62.5000 (49.3555) lr 2.0000e-03 eta 0:36:13
epoch [2/50] batch [180/428] time 0.083 (0.104) data 0.000 (0.003) loss 2.1474 (2.5751) teacher_loss 1.0058 (1.4532) loss_zs_kd 1.2846 (0.8987) loss_oracle 1.0781 (1.0175) kd_loss 1.0338 (1.0201) acc 65.6250 (50.2257) lr 2.0000e-03 eta 0:35:53
epoch [2/50] batch [200/428] time 0.074 (0.104) data 0.000 (0.003) loss 2.1447 (2.5504) teacher_loss 1.0430 (1.4280) loss_zs_kd 1.1492 (0.9202) loss_oracle 1.0376 (1.0198) kd_loss 0.9979 (1.0204) acc 62.5000 (51.2812) lr 2.0000e-03 eta 0:36:08
epoch [2/50] batch [220/428] time 0.075 (0.104) data 0.000 (0.003) loss 2.0399 (2.5161) teacher_loss 0.9579 (1.3935) loss_zs_kd 1.1876 (0.9688) loss_oracle 1.0191 (1.0212) kd_loss 0.9801 (1.0205) acc 68.7500 (52.5142) lr 2.0000e-03 eta 0:35:58
epoch [2/50] batch [240/428] time 0.086 (0.102) data 0.000 (0.002) loss 1.9660 (2.4877) teacher_loss 0.8396 (1.3646) loss_zs_kd 1.4118 (1.0027) loss_oracle 1.0932 (1.0222) kd_loss 1.0171 (1.0208) acc 75.0000 (53.6328) lr 2.0000e-03 eta 0:35:11
epoch [2/50] batch [260/428] time 0.086 (0.100) data 0.000 (0.002) loss 1.9815 (2.4674) teacher_loss 0.7876 (1.3431) loss_zs_kd 1.4413 (1.0484) loss_oracle 1.1037 (1.0234) kd_loss 1.0835 (1.0219) acc 78.1250 (54.3870) lr 2.0000e-03 eta 0:34:36
epoch [2/50] batch [280/428] time 0.085 (0.099) data 0.000 (0.002) loss 2.4689 (2.4571) teacher_loss 1.3439 (1.3328) loss_zs_kd 1.4231 (1.0780) loss_oracle 1.0880 (1.0259) kd_loss 1.0163 (1.0217) acc 65.6250 (54.7545) lr 2.0000e-03 eta 0:34:08
epoch [2/50] batch [300/428] time 0.088 (0.098) data 0.000 (0.002) loss 2.5131 (2.4474) teacher_loss 1.3822 (1.3232) loss_zs_kd 1.5624 (1.1023) loss_oracle 1.0410 (1.0273) kd_loss 1.0268 (1.0214) acc 50.0000 (55.0208) lr 2.0000e-03 eta 0:33:45
epoch [2/50] batch [320/428] time 0.078 (0.097) data 0.000 (0.002) loss 2.2383 (2.4348) teacher_loss 1.1220 (1.3098) loss_zs_kd 1.5474 (1.1296) loss_oracle 1.0717 (1.0282) kd_loss 1.0092 (1.0222) acc 53.1250 (55.3027) lr 2.0000e-03 eta 0:33:26
epoch [2/50] batch [340/428] time 0.084 (0.096) data 0.000 (0.002) loss 2.0602 (2.4204) teacher_loss 0.9029 (1.2946) loss_zs_kd 1.6182 (1.1590) loss_oracle 1.0742 (1.0299) kd_loss 1.0499 (1.0228) acc 62.5000 (55.6434) lr 2.0000e-03 eta 0:33:08
epoch [2/50] batch [360/428] time 0.089 (0.096) data 0.001 (0.002) loss 1.7389 (2.4068) teacher_loss 0.6420 (1.2800) loss_zs_kd 1.1204 (1.1731) loss_oracle 0.9988 (1.0317) kd_loss 0.9970 (1.0236) acc 84.3750 (56.0243) lr 2.0000e-03 eta 0:32:50
epoch [2/50] batch [380/428] time 0.076 (0.095) data 0.001 (0.002) loss 2.1994 (2.4007) teacher_loss 1.0978 (1.2739) loss_zs_kd 1.4343 (1.1806) loss_oracle 1.0168 (1.0321) kd_loss 0.9999 (1.0236) acc 62.5000 (56.0362) lr 2.0000e-03 eta 0:32:33
epoch [2/50] batch [400/428] time 0.100 (0.094) data 0.001 (0.002) loss 2.2185 (2.3995) teacher_loss 1.1400 (1.2741) loss_zs_kd 1.4026 (1.1865) loss_oracle 1.0003 (1.0318) kd_loss 0.9785 (1.0222) acc 68.7500 (55.9062) lr 2.0000e-03 eta 0:32:22
epoch [2/50] batch [420/428] time 0.076 (0.094) data 0.000 (0.002) loss 2.1166 (2.3929) teacher_loss 1.0158 (1.2687) loss_zs_kd 1.5931 (1.2106) loss_oracle 1.0086 (1.0325) kd_loss 0.9999 (1.0210) acc 65.6250 (56.1384) lr 2.0000e-03 eta 0:32:11
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,912
* accuracy: 49.6%
* error: 50.4%
* macro_f1: 28.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,820
* accuracy: 38.4%
* error: 61.6%
* macro_f1: 25.6%
******* Domain 1 best val acc:      49.6%, epoch: 2 *******
******* Domain 1 best val test acc: 38.4%, epoch: 2 *******
******* Domain 1 best test acc:     44.0%, epoch: 1 *******
epoch [3/50] batch [20/428] time 0.078 (0.105) data 0.000 (0.025) loss 2.4190 (2.3696) teacher_loss 1.3029 (1.2796) loss_zs_kd 1.3845 (1.2911) loss_oracle 1.0547 (1.0323) kd_loss 1.0106 (0.9867) acc 59.3750 (53.9062) lr 1.9980e-03 eta 0:35:49
epoch [3/50] batch [40/428] time 0.085 (0.093) data 0.000 (0.012) loss 2.4614 (2.3554) teacher_loss 1.4032 (1.2801) loss_zs_kd 1.2356 (1.2386) loss_oracle 1.0346 (1.0201) kd_loss 0.9548 (0.9733) acc 46.8750 (53.5156) lr 1.9980e-03 eta 0:31:47
epoch [3/50] batch [60/428] time 0.088 (0.089) data 0.001 (0.008) loss 2.4907 (2.3309) teacher_loss 1.3886 (1.2590) loss_zs_kd 1.2782 (1.2724) loss_oracle 1.0540 (1.0193) kd_loss 0.9966 (0.9699) acc 50.0000 (55.2083) lr 1.9980e-03 eta 0:30:19
epoch [3/50] batch [80/428] time 0.078 (0.088) data 0.000 (0.006) loss 1.9247 (2.3118) teacher_loss 0.8765 (1.2385) loss_zs_kd 1.4709 (1.3141) loss_oracle 0.9861 (1.0245) kd_loss 0.9497 (0.9708) acc 71.8750 (55.8594) lr 1.9980e-03 eta 0:30:04
epoch [3/50] batch [100/428] time 0.082 (0.087) data 0.000 (0.005) loss 2.5796 (2.3046) teacher_loss 1.4567 (1.2272) loss_zs_kd 1.5049 (1.3135) loss_oracle 1.0473 (1.0293) kd_loss 1.0182 (0.9745) acc 53.1250 (56.6562) lr 1.9980e-03 eta 0:29:33
epoch [3/50] batch [120/428] time 0.089 (0.087) data 0.000 (0.004) loss 2.3740 (2.2865) teacher_loss 1.2310 (1.1965) loss_zs_kd 1.4634 (1.3383) loss_oracle 1.1113 (1.0401) kd_loss 1.0318 (0.9860) acc 65.6250 (57.8646) lr 1.9980e-03 eta 0:29:30
epoch [3/50] batch [140/428] time 0.080 (0.086) data 0.000 (0.004) loss 2.3122 (2.2739) teacher_loss 1.1970 (1.1793) loss_zs_kd 1.8327 (1.3678) loss_oracle 1.1031 (1.0462) kd_loss 1.0049 (0.9900) acc 50.0000 (58.4598) lr 1.9980e-03 eta 0:29:22
epoch [3/50] batch [160/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.3897 (2.2718) teacher_loss 1.3560 (1.1805) loss_zs_kd 1.4275 (1.3991) loss_oracle 0.9797 (1.0420) kd_loss 0.9358 (0.9871) acc 53.1250 (58.5547) lr 1.9980e-03 eta 0:29:17
epoch [3/50] batch [180/428] time 0.080 (0.086) data 0.000 (0.003) loss 2.0270 (2.2550) teacher_loss 0.8516 (1.1648) loss_zs_kd 1.8655 (1.4177) loss_oracle 1.0597 (1.0415) kd_loss 1.0694 (0.9861) acc 75.0000 (59.0451) lr 1.9980e-03 eta 0:29:14
epoch [3/50] batch [200/428] time 0.077 (0.086) data 0.000 (0.003) loss 2.1282 (2.2479) teacher_loss 0.9515 (1.1505) loss_zs_kd 1.4573 (1.4517) loss_oracle 1.1130 (1.0502) kd_loss 1.0654 (0.9923) acc 62.5000 (59.7500) lr 1.9980e-03 eta 0:29:07
epoch [3/50] batch [220/428] time 0.081 (0.086) data 0.000 (0.003) loss 2.1807 (2.2393) teacher_loss 1.0409 (1.1393) loss_zs_kd 1.9169 (1.4720) loss_oracle 1.0792 (1.0550) kd_loss 1.0320 (0.9945) acc 62.5000 (60.0284) lr 1.9980e-03 eta 0:29:03
epoch [3/50] batch [240/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.9445 (2.2313) teacher_loss 0.8096 (1.1281) loss_zs_kd 1.5080 (1.4729) loss_oracle 1.1349 (1.0588) kd_loss 1.0214 (0.9973) acc 78.1250 (60.4948) lr 1.9980e-03 eta 0:29:07
epoch [3/50] batch [260/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.4359 (2.2264) teacher_loss 1.2669 (1.1205) loss_zs_kd 1.4644 (1.4806) loss_oracle 1.1310 (1.0638) kd_loss 1.0559 (0.9995) acc 56.2500 (60.8534) lr 1.9980e-03 eta 0:29:00
epoch [3/50] batch [280/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.0738 (2.2278) teacher_loss 0.9154 (1.1176) loss_zs_kd 1.5858 (1.4796) loss_oracle 1.1349 (1.0679) kd_loss 1.0449 (1.0034) acc 62.5000 (61.0045) lr 1.9980e-03 eta 0:28:54
epoch [3/50] batch [300/428] time 0.104 (0.086) data 0.000 (0.002) loss 2.1291 (2.2237) teacher_loss 0.9261 (1.1087) loss_zs_kd 1.3242 (1.4735) loss_oracle 1.1011 (1.0703) kd_loss 1.0929 (1.0080) acc 71.8750 (61.4062) lr 1.9980e-03 eta 0:29:02
epoch [3/50] batch [320/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.9265 (2.2104) teacher_loss 0.7386 (1.0931) loss_zs_kd 1.3901 (1.4715) loss_oracle 1.1241 (1.0713) kd_loss 1.0755 (1.0101) acc 75.0000 (62.0215) lr 1.9980e-03 eta 0:28:59
epoch [3/50] batch [340/428] time 0.090 (0.086) data 0.000 (0.002) loss 2.1298 (2.2049) teacher_loss 0.9183 (1.0830) loss_zs_kd 1.4483 (1.4828) loss_oracle 1.1276 (1.0758) kd_loss 1.0987 (1.0143) acc 71.8750 (62.5000) lr 1.9980e-03 eta 0:28:55
epoch [3/50] batch [360/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.0976 (2.1976) teacher_loss 0.9410 (1.0720) loss_zs_kd 1.5502 (1.4899) loss_oracle 1.1567 (1.0801) kd_loss 1.0409 (1.0177) acc 71.8750 (62.8646) lr 1.9980e-03 eta 0:28:52
epoch [3/50] batch [380/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.3158 (2.1954) teacher_loss 1.1988 (1.0680) loss_zs_kd 1.3388 (1.4901) loss_oracle 1.1125 (1.0830) kd_loss 1.0058 (1.0191) acc 56.2500 (62.9194) lr 1.9980e-03 eta 0:28:48
epoch [3/50] batch [400/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.1545 (2.1905) teacher_loss 1.0040 (1.0628) loss_zs_kd 1.8720 (1.4890) loss_oracle 1.1871 (1.0854) kd_loss 1.0318 (1.0191) acc 68.7500 (63.1484) lr 1.9980e-03 eta 0:28:46
epoch [3/50] batch [420/428] time 0.081 (0.086) data 0.000 (0.001) loss 1.9409 (2.1837) teacher_loss 0.7950 (1.0547) loss_zs_kd 1.7298 (1.4947) loss_oracle 1.1058 (1.0874) kd_loss 1.0354 (1.0203) acc 75.0000 (63.4301) lr 1.9980e-03 eta 0:28:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,119
* accuracy: 53.1%
* error: 46.9%
* macro_f1: 34.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,143
* accuracy: 45.2%
* error: 54.8%
* macro_f1: 27.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      53.1%, epoch: 3 *******
******* Domain 1 best val test acc: 45.2%, epoch: 3 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [4/50] batch [20/428] time 0.088 (0.119) data 0.001 (0.027) loss 2.4472 (2.0816) teacher_loss 1.2132 (0.9277) loss_zs_kd 1.4183 (1.5193) loss_oracle 1.1426 (1.1115) kd_loss 1.1198 (1.0428) acc 50.0000 (67.0312) lr 1.9921e-03 eta 0:39:41
epoch [4/50] batch [40/428] time 0.079 (0.101) data 0.000 (0.014) loss 2.1617 (2.1075) teacher_loss 0.9570 (0.9488) loss_zs_kd 1.6202 (1.5075) loss_oracle 1.1679 (1.1260) kd_loss 1.0879 (1.0462) acc 75.0000 (67.5000) lr 1.9921e-03 eta 0:33:54
epoch [4/50] batch [60/428] time 0.081 (0.095) data 0.000 (0.009) loss 2.4733 (2.1177) teacher_loss 1.3549 (0.9644) loss_zs_kd 1.5328 (1.5229) loss_oracle 1.1231 (1.1292) kd_loss 1.0060 (1.0404) acc 56.2500 (66.4583) lr 1.9921e-03 eta 0:31:40
epoch [4/50] batch [80/428] time 0.078 (0.092) data 0.000 (0.007) loss 2.2619 (2.1205) teacher_loss 1.1535 (0.9735) loss_zs_kd 1.2122 (1.5073) loss_oracle 1.1051 (1.1286) kd_loss 0.9979 (1.0341) acc 65.6250 (66.0156) lr 1.9921e-03 eta 0:30:50
epoch [4/50] batch [100/428] time 0.081 (0.091) data 0.000 (0.006) loss 1.9377 (2.1339) teacher_loss 0.8273 (0.9861) loss_zs_kd 1.6184 (1.5068) loss_oracle 1.1332 (1.1318) kd_loss 0.9971 (1.0346) acc 71.8750 (65.5625) lr 1.9921e-03 eta 0:30:17
epoch [4/50] batch [120/428] time 0.090 (0.090) data 0.000 (0.005) loss 2.1387 (2.1304) teacher_loss 1.0868 (0.9873) loss_zs_kd 1.2467 (1.4783) loss_oracle 1.0767 (1.1305) kd_loss 0.9442 (1.0300) acc 46.8750 (65.6771) lr 1.9921e-03 eta 0:30:00
epoch [4/50] batch [140/428] time 0.090 (0.089) data 0.000 (0.004) loss 2.2108 (2.1405) teacher_loss 1.1014 (1.0039) loss_zs_kd 1.3958 (1.4432) loss_oracle 1.1392 (1.1279) kd_loss 0.9954 (1.0239) acc 62.5000 (65.4464) lr 1.9921e-03 eta 0:29:41
epoch [4/50] batch [160/428] time 0.091 (0.089) data 0.001 (0.004) loss 2.0655 (2.1568) teacher_loss 0.9121 (1.0227) loss_zs_kd 1.2211 (1.4338) loss_oracle 1.1870 (1.1268) kd_loss 1.0347 (1.0214) acc 68.7500 (64.4922) lr 1.9921e-03 eta 0:29:31
epoch [4/50] batch [180/428] time 0.089 (0.088) data 0.000 (0.003) loss 2.6060 (2.1658) teacher_loss 1.4401 (1.0310) loss_zs_kd 1.2070 (1.4110) loss_oracle 1.0601 (1.1263) kd_loss 1.0599 (1.0222) acc 43.7500 (63.9583) lr 1.9921e-03 eta 0:29:22
epoch [4/50] batch [200/428] time 0.077 (0.088) data 0.000 (0.003) loss 2.0768 (2.1655) teacher_loss 0.9785 (1.0290) loss_zs_kd 1.2054 (1.3922) loss_oracle 1.1275 (1.1275) kd_loss 0.9855 (1.0238) acc 65.6250 (64.0781) lr 1.9921e-03 eta 0:29:05
epoch [4/50] batch [220/428] time 0.096 (0.087) data 0.001 (0.003) loss 2.1035 (2.1750) teacher_loss 0.9867 (1.0368) loss_zs_kd 1.3765 (1.3913) loss_oracle 1.1474 (1.1300) kd_loss 1.0021 (1.0252) acc 62.5000 (63.8210) lr 1.9921e-03 eta 0:28:56
epoch [4/50] batch [240/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.1199 (2.1668) teacher_loss 0.9535 (1.0276) loss_zs_kd 1.4408 (1.3901) loss_oracle 1.1425 (1.1297) kd_loss 1.0522 (1.0263) acc 68.7500 (64.1406) lr 1.9921e-03 eta 0:28:56
epoch [4/50] batch [260/428] time 0.083 (0.087) data 0.000 (0.002) loss 2.1636 (2.1661) teacher_loss 1.0075 (1.0241) loss_zs_kd 1.5990 (1.4047) loss_oracle 1.1411 (1.1312) kd_loss 1.0420 (1.0288) acc 56.2500 (64.1106) lr 1.9921e-03 eta 0:28:51
epoch [4/50] batch [280/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.9709 (2.1598) teacher_loss 0.8530 (1.0183) loss_zs_kd 1.4689 (1.4067) loss_oracle 1.1332 (1.1321) kd_loss 1.0047 (1.0283) acc 75.0000 (64.4085) lr 1.9921e-03 eta 0:28:44
epoch [4/50] batch [300/428] time 0.093 (0.087) data 0.000 (0.002) loss 1.8990 (2.1568) teacher_loss 0.7758 (1.0154) loss_zs_kd 1.4929 (1.4093) loss_oracle 1.1443 (1.1330) kd_loss 1.0088 (1.0282) acc 78.1250 (64.6354) lr 1.9921e-03 eta 0:28:42
epoch [4/50] batch [320/428] time 0.088 (0.087) data 0.000 (0.002) loss 2.2031 (2.1511) teacher_loss 1.0455 (1.0078) loss_zs_kd 1.7886 (1.4198) loss_oracle 1.1241 (1.1338) kd_loss 1.0452 (1.0299) acc 62.5000 (64.9023) lr 1.9921e-03 eta 0:28:41
epoch [4/50] batch [340/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.2180 (2.1437) teacher_loss 1.0782 (0.9994) loss_zs_kd 1.7989 (1.4365) loss_oracle 1.1361 (1.1335) kd_loss 1.0262 (1.0309) acc 62.5000 (65.2849) lr 1.9921e-03 eta 0:28:31
epoch [4/50] batch [360/428] time 0.089 (0.087) data 0.000 (0.002) loss 2.0836 (2.1406) teacher_loss 0.8927 (0.9952) loss_zs_kd 1.5969 (1.4538) loss_oracle 1.1042 (1.1334) kd_loss 1.0805 (1.0320) acc 65.6250 (65.3906) lr 1.9921e-03 eta 0:28:30
epoch [4/50] batch [380/428] time 0.081 (0.086) data 0.000 (0.002) loss 2.0899 (2.1332) teacher_loss 0.9208 (0.9883) loss_zs_kd 1.8745 (1.4639) loss_oracle 1.1461 (1.1328) kd_loss 1.0545 (1.0316) acc 68.7500 (65.5921) lr 1.9921e-03 eta 0:28:25
epoch [4/50] batch [400/428] time 0.091 (0.087) data 0.000 (0.002) loss 2.0603 (2.1304) teacher_loss 0.9394 (0.9848) loss_zs_kd 1.3673 (1.4725) loss_oracle 1.1348 (1.1325) kd_loss 1.0074 (1.0323) acc 78.1250 (65.7422) lr 1.9921e-03 eta 0:28:41
epoch [4/50] batch [420/428] time 0.071 (0.087) data 0.000 (0.002) loss 2.0938 (2.1302) teacher_loss 0.9527 (0.9831) loss_zs_kd 1.7759 (1.4859) loss_oracle 1.1243 (1.1323) kd_loss 1.0288 (1.0339) acc 65.6250 (65.8557) lr 1.9921e-03 eta 0:28:33
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 2,930
* accuracy: 49.9%
* error: 50.1%
* macro_f1: 33.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,756
* accuracy: 37.0%
* error: 63.0%
* macro_f1: 25.2%
******* Domain 1 best val acc:      53.1%, epoch: 3 *******
******* Domain 1 best val test acc: 45.2%, epoch: 3 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [5/50] batch [20/428] time 0.093 (0.115) data 0.000 (0.025) loss 1.9528 (2.0344) teacher_loss 0.7910 (0.8822) loss_zs_kd 1.5559 (1.7891) loss_oracle 1.1287 (1.1183) kd_loss 1.0489 (1.0404) acc 78.1250 (69.0625) lr 1.9823e-03 eta 0:37:35
epoch [5/50] batch [40/428] time 0.079 (0.099) data 0.000 (0.013) loss 1.9703 (2.0346) teacher_loss 0.8620 (0.8841) loss_zs_kd 1.7097 (1.7842) loss_oracle 1.1162 (1.1153) kd_loss 0.9967 (1.0390) acc 65.6250 (69.5312) lr 1.9823e-03 eta 0:32:30
epoch [5/50] batch [60/428] time 0.083 (0.094) data 0.000 (0.009) loss 1.9156 (2.0060) teacher_loss 0.7648 (0.8567) loss_zs_kd 1.7552 (1.8389) loss_oracle 1.1233 (1.1159) kd_loss 1.0384 (1.0377) acc 71.8750 (70.7292) lr 1.9823e-03 eta 0:30:41
epoch [5/50] batch [80/428] time 0.086 (0.092) data 0.000 (0.007) loss 2.2147 (2.0390) teacher_loss 1.0782 (0.8866) loss_zs_kd 1.7745 (1.8262) loss_oracle 1.0598 (1.1150) kd_loss 1.0306 (1.0409) acc 59.3750 (69.5703) lr 1.9823e-03 eta 0:29:55
epoch [5/50] batch [100/428] time 0.080 (0.090) data 0.000 (0.005) loss 1.8633 (2.0565) teacher_loss 0.7525 (0.9040) loss_zs_kd 1.7224 (1.7904) loss_oracle 1.1228 (1.1176) kd_loss 0.9985 (1.0407) acc 68.7500 (69.1875) lr 1.9823e-03 eta 0:29:13
epoch [5/50] batch [120/428] time 0.165 (0.090) data 0.000 (0.004) loss 2.2665 (2.0586) teacher_loss 1.1002 (0.9076) loss_zs_kd 1.6525 (1.7616) loss_oracle 1.1274 (1.1163) kd_loss 1.0535 (1.0394) acc 56.2500 (69.1146) lr 1.9823e-03 eta 0:29:15
epoch [5/50] batch [140/428] time 0.094 (0.090) data 0.000 (0.004) loss 1.9720 (2.0609) teacher_loss 0.8480 (0.9151) loss_zs_kd 1.0609 (1.7072) loss_oracle 1.0498 (1.1143) kd_loss 1.0191 (1.0344) acc 68.7500 (68.8839) lr 1.9823e-03 eta 0:29:12
epoch [5/50] batch [160/428] time 0.086 (0.089) data 0.000 (0.003) loss 2.1877 (2.0711) teacher_loss 1.0516 (0.9264) loss_zs_kd 1.4668 (1.6950) loss_oracle 1.1055 (1.1156) kd_loss 1.0255 (1.0331) acc 62.5000 (68.4961) lr 1.9823e-03 eta 0:28:59
epoch [5/50] batch [180/428] time 0.084 (0.089) data 0.000 (0.003) loss 2.2391 (2.0756) teacher_loss 1.0679 (0.9282) loss_zs_kd 1.6700 (1.6787) loss_oracle 1.1263 (1.1168) kd_loss 1.0586 (1.0357) acc 62.5000 (68.6806) lr 1.9823e-03 eta 0:28:49
epoch [5/50] batch [200/428] time 0.082 (0.088) data 0.000 (0.003) loss 2.0326 (2.0776) teacher_loss 0.9124 (0.9316) loss_zs_kd 1.1381 (1.6590) loss_oracle 1.1022 (1.1162) kd_loss 1.0100 (1.0344) acc 75.0000 (68.6250) lr 1.9823e-03 eta 0:28:36
epoch [5/50] batch [220/428] time 0.083 (0.087) data 0.000 (0.003) loss 2.1654 (2.0890) teacher_loss 1.0740 (0.9477) loss_zs_kd 1.4346 (1.6272) loss_oracle 1.0982 (1.1141) kd_loss 0.9816 (1.0299) acc 62.5000 (67.9688) lr 1.9823e-03 eta 0:28:22
epoch [5/50] batch [240/428] time 0.085 (0.087) data 0.000 (0.002) loss 2.4838 (2.1013) teacher_loss 1.3915 (0.9660) loss_zs_kd 1.4084 (1.6100) loss_oracle 1.0926 (1.1116) kd_loss 0.9830 (1.0241) acc 53.1250 (67.0573) lr 1.9823e-03 eta 0:28:15
epoch [5/50] batch [260/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.1518 (2.1102) teacher_loss 1.0573 (0.9779) loss_zs_kd 1.4846 (1.5940) loss_oracle 1.0854 (1.1086) kd_loss 0.9860 (1.0214) acc 62.5000 (66.5024) lr 1.9823e-03 eta 0:28:15
epoch [5/50] batch [280/428] time 0.090 (0.087) data 0.000 (0.002) loss 1.9981 (2.1050) teacher_loss 0.8205 (0.9741) loss_zs_kd 1.3559 (1.5851) loss_oracle 1.0784 (1.1074) kd_loss 1.0698 (1.0201) acc 71.8750 (66.6964) lr 1.9823e-03 eta 0:28:11
epoch [5/50] batch [300/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.0317 (2.0999) teacher_loss 0.9378 (0.9692) loss_zs_kd 1.7305 (1.5869) loss_oracle 1.0698 (1.1072) kd_loss 0.9870 (1.0200) acc 65.6250 (66.9583) lr 1.9823e-03 eta 0:28:07
epoch [5/50] batch [320/428] time 0.080 (0.087) data 0.000 (0.002) loss 1.9943 (2.0948) teacher_loss 0.8917 (0.9636) loss_zs_kd 1.5146 (1.5905) loss_oracle 1.0435 (1.1062) kd_loss 0.9982 (1.0205) acc 59.3750 (67.2168) lr 1.9823e-03 eta 0:28:00
epoch [5/50] batch [340/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.9740 (2.0978) teacher_loss 0.8077 (0.9654) loss_zs_kd 1.2090 (1.5755) loss_oracle 1.1389 (1.1073) kd_loss 1.0525 (1.0217) acc 75.0000 (67.2610) lr 1.9823e-03 eta 0:27:58
epoch [5/50] batch [360/428] time 0.078 (0.087) data 0.000 (0.002) loss 1.6653 (2.0952) teacher_loss 0.5950 (0.9617) loss_zs_kd 1.3783 (1.5712) loss_oracle 1.1081 (1.1091) kd_loss 0.9595 (1.0226) acc 81.2500 (67.3785) lr 1.9823e-03 eta 0:27:53
epoch [5/50] batch [380/428] time 0.069 (0.086) data 0.000 (0.002) loss 2.1633 (2.0881) teacher_loss 1.0307 (0.9547) loss_zs_kd 2.0108 (1.5789) loss_oracle 1.0931 (1.1090) kd_loss 1.0232 (1.0225) acc 75.0000 (67.7220) lr 1.9823e-03 eta 0:27:46
epoch [5/50] batch [400/428] time 0.087 (0.086) data 0.001 (0.002) loss 2.0962 (2.0883) teacher_loss 1.0141 (0.9547) loss_zs_kd 1.2937 (1.5831) loss_oracle 1.1115 (1.1093) kd_loss 0.9710 (1.0226) acc 62.5000 (67.7500) lr 1.9823e-03 eta 0:27:42
epoch [5/50] batch [420/428] time 0.070 (0.086) data 0.000 (0.001) loss 1.8422 (2.0817) teacher_loss 0.7228 (0.9482) loss_zs_kd 1.6868 (1.5872) loss_oracle 1.1112 (1.1091) kd_loss 1.0083 (1.0225) acc 71.8750 (67.9167) lr 1.9823e-03 eta 0:27:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,139
* accuracy: 53.4%
* error: 46.6%
* macro_f1: 38.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,787
* accuracy: 37.7%
* error: 62.3%
* macro_f1: 24.9%
******* Domain 1 best val acc:      53.4%, epoch: 5 *******
******* Domain 1 best val test acc: 37.7%, epoch: 5 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [6/50] batch [20/428] time 0.077 (0.113) data 0.000 (0.025) loss 2.4417 (2.0429) teacher_loss 1.2851 (0.9017) loss_zs_kd 1.7724 (1.6019) loss_oracle 1.1678 (1.1310) kd_loss 1.0399 (1.0280) acc 62.5000 (69.2188) lr 1.9686e-03 eta 0:36:12
epoch [6/50] batch [40/428] time 0.080 (0.097) data 0.000 (0.013) loss 1.8364 (2.0315) teacher_loss 0.7245 (0.8890) loss_zs_kd 1.7221 (1.6036) loss_oracle 1.1857 (1.1383) kd_loss 0.9934 (1.0287) acc 75.0000 (69.2969) lr 1.9686e-03 eta 0:31:07
epoch [6/50] batch [60/428] time 0.076 (0.092) data 0.000 (0.009) loss 1.9853 (2.0482) teacher_loss 0.8102 (0.9043) loss_zs_kd 1.7455 (1.6342) loss_oracle 1.0890 (1.1374) kd_loss 1.0662 (1.0301) acc 81.2500 (68.8542) lr 1.9686e-03 eta 0:29:24
epoch [6/50] batch [80/428] time 0.085 (0.089) data 0.000 (0.007) loss 1.9144 (2.0645) teacher_loss 0.8624 (0.9251) loss_zs_kd 1.7594 (1.6503) loss_oracle 1.0496 (1.1294) kd_loss 0.9471 (1.0264) acc 68.7500 (68.0859) lr 1.9686e-03 eta 0:28:26
epoch [6/50] batch [100/428] time 0.087 (0.088) data 0.000 (0.005) loss 1.9159 (2.0708) teacher_loss 0.7905 (0.9371) loss_zs_kd 2.0128 (1.6484) loss_oracle 1.0897 (1.1229) kd_loss 1.0165 (1.0215) acc 71.8750 (67.2812) lr 1.9686e-03 eta 0:28:10
epoch [6/50] batch [120/428] time 0.085 (0.088) data 0.000 (0.005) loss 2.1867 (2.0545) teacher_loss 1.0493 (0.9242) loss_zs_kd 1.8196 (1.6692) loss_oracle 1.1279 (1.1166) kd_loss 1.0245 (1.0186) acc 59.3750 (67.7083) lr 1.9686e-03 eta 0:27:59
epoch [6/50] batch [140/428] time 0.083 (0.087) data 0.000 (0.004) loss 1.9786 (2.0480) teacher_loss 0.8032 (0.9175) loss_zs_kd 1.5515 (1.6633) loss_oracle 1.1453 (1.1163) kd_loss 1.0609 (1.0188) acc 78.1250 (68.3705) lr 1.9686e-03 eta 0:27:51
epoch [6/50] batch [160/428] time 0.091 (0.087) data 0.000 (0.003) loss 2.4188 (2.0457) teacher_loss 1.3153 (0.9158) loss_zs_kd 1.7586 (1.6575) loss_oracle 1.1523 (1.1166) kd_loss 0.9884 (1.0183) acc 59.3750 (68.7500) lr 1.9686e-03 eta 0:27:42
epoch [6/50] batch [180/428] time 0.085 (0.087) data 0.000 (0.003) loss 2.2213 (2.0475) teacher_loss 1.0772 (0.9190) loss_zs_kd 1.5068 (1.6492) loss_oracle 1.0168 (1.1152) kd_loss 1.0425 (1.0169) acc 59.3750 (68.6806) lr 1.9686e-03 eta 0:27:35
epoch [6/50] batch [200/428] time 0.084 (0.086) data 0.000 (0.003) loss 1.8720 (2.0418) teacher_loss 0.7264 (0.9155) loss_zs_kd 1.8322 (1.6463) loss_oracle 1.0942 (1.1124) kd_loss 1.0362 (1.0150) acc 87.5000 (68.8594) lr 1.9686e-03 eta 0:27:28
epoch [6/50] batch [220/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.3636 (2.0424) teacher_loss 1.2557 (0.9176) loss_zs_kd 1.2470 (1.6365) loss_oracle 1.0502 (1.1097) kd_loss 1.0028 (1.0138) acc 62.5000 (68.8352) lr 1.9686e-03 eta 0:27:13
epoch [6/50] batch [240/428] time 0.079 (0.086) data 0.000 (0.002) loss 1.8685 (2.0375) teacher_loss 0.7754 (0.9156) loss_zs_kd 1.6229 (1.6210) loss_oracle 1.1852 (1.1082) kd_loss 0.9746 (1.0110) acc 75.0000 (69.0365) lr 1.9686e-03 eta 0:27:19
epoch [6/50] batch [260/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.1241 (2.0343) teacher_loss 0.9998 (0.9145) loss_zs_kd 1.5579 (1.6125) loss_oracle 1.0389 (1.1055) kd_loss 1.0203 (1.0093) acc 59.3750 (68.9784) lr 1.9686e-03 eta 0:27:13
epoch [6/50] batch [280/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.0173 (2.0398) teacher_loss 0.9194 (0.9213) loss_zs_kd 1.6445 (1.6097) loss_oracle 1.0893 (1.1040) kd_loss 0.9889 (1.0081) acc 75.0000 (68.5603) lr 1.9686e-03 eta 0:27:04
epoch [6/50] batch [300/428] time 0.078 (0.085) data 0.000 (0.002) loss 2.0101 (2.0408) teacher_loss 0.8772 (0.9209) loss_zs_kd 1.6188 (1.6156) loss_oracle 1.1658 (1.1052) kd_loss 1.0163 (1.0094) acc 71.8750 (68.6042) lr 1.9686e-03 eta 0:26:52
epoch [6/50] batch [320/428] time 0.087 (0.085) data 0.000 (0.002) loss 2.2545 (2.0426) teacher_loss 1.1664 (0.9215) loss_zs_kd 1.7481 (1.6272) loss_oracle 1.0511 (1.1057) kd_loss 0.9831 (1.0105) acc 56.2500 (68.6133) lr 1.9686e-03 eta 0:26:48
epoch [6/50] batch [340/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.8363 (2.0400) teacher_loss 0.7022 (0.9196) loss_zs_kd 1.2725 (1.6134) loss_oracle 1.0830 (1.1044) kd_loss 1.0258 (1.0100) acc 75.0000 (68.7592) lr 1.9686e-03 eta 0:26:45
epoch [6/50] batch [360/428] time 0.091 (0.085) data 0.000 (0.002) loss 2.0456 (2.0412) teacher_loss 0.9145 (0.9208) loss_zs_kd 1.4940 (1.6050) loss_oracle 1.0817 (1.1033) kd_loss 1.0229 (1.0101) acc 71.8750 (68.7413) lr 1.9686e-03 eta 0:26:42
epoch [6/50] batch [380/428] time 0.072 (0.085) data 0.000 (0.002) loss 2.2307 (2.0395) teacher_loss 1.1517 (0.9205) loss_zs_kd 1.5647 (1.6019) loss_oracle 1.0484 (1.1017) kd_loss 0.9741 (1.0089) acc 62.5000 (68.7993) lr 1.9686e-03 eta 0:26:38
epoch [6/50] batch [400/428] time 0.080 (0.084) data 0.000 (0.002) loss 1.9911 (2.0343) teacher_loss 0.8601 (0.9168) loss_zs_kd 1.3025 (1.5973) loss_oracle 1.1046 (1.0987) kd_loss 1.0205 (1.0077) acc 75.0000 (68.9375) lr 1.9686e-03 eta 0:26:31
epoch [6/50] batch [420/428] time 0.076 (0.084) data 0.000 (0.002) loss 1.9375 (2.0293) teacher_loss 0.8025 (0.9129) loss_zs_kd 1.7110 (1.5971) loss_oracle 1.1240 (1.0978) kd_loss 1.0226 (1.0066) acc 68.7500 (69.1741) lr 1.9686e-03 eta 0:26:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,242
* accuracy: 55.2%
* error: 44.8%
* macro_f1: 41.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,885
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 25.9%
******* Domain 1 best val acc:      55.2%, epoch: 6 *******
******* Domain 1 best val test acc: 39.8%, epoch: 6 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [7/50] batch [20/428] time 0.081 (0.113) data 0.000 (0.024) loss 2.1318 (1.8591) teacher_loss 1.0536 (0.7460) loss_zs_kd 1.7371 (1.8148) loss_oracle 1.1055 (1.0848) kd_loss 0.9677 (1.0046) acc 62.5000 (75.6250) lr 1.9511e-03 eta 0:35:23
epoch [7/50] batch [40/428] time 0.092 (0.098) data 0.000 (0.012) loss 1.8008 (1.9139) teacher_loss 0.6527 (0.7998) loss_zs_kd 1.6579 (1.7361) loss_oracle 1.1299 (1.0912) kd_loss 1.0352 (1.0050) acc 81.2500 (73.5938) lr 1.9511e-03 eta 0:30:49
epoch [7/50] batch [60/428] time 0.083 (0.094) data 0.000 (0.008) loss 2.1758 (1.9475) teacher_loss 1.0650 (0.8381) loss_zs_kd 1.4037 (1.6401) loss_oracle 1.0895 (1.0848) kd_loss 1.0018 (1.0009) acc 65.6250 (72.1354) lr 1.9511e-03 eta 0:29:22
epoch [7/50] batch [80/428] time 0.094 (0.091) data 0.000 (0.006) loss 1.9753 (1.9400) teacher_loss 0.9144 (0.8323) loss_zs_kd 1.6861 (1.6157) loss_oracle 0.9594 (1.0793) kd_loss 0.9650 (0.9998) acc 75.0000 (72.5000) lr 1.9511e-03 eta 0:28:28
epoch [7/50] batch [100/428] time 0.095 (0.091) data 0.000 (0.005) loss 1.6113 (1.9463) teacher_loss 0.5380 (0.8419) loss_zs_kd 1.5183 (1.6247) loss_oracle 1.0654 (1.0775) kd_loss 0.9668 (0.9966) acc 84.3750 (71.8438) lr 1.9511e-03 eta 0:28:26
epoch [7/50] batch [120/428] time 0.080 (0.090) data 0.000 (0.004) loss 2.0792 (1.9472) teacher_loss 1.0170 (0.8452) loss_zs_kd 1.6753 (1.5916) loss_oracle 1.0807 (1.0777) kd_loss 0.9541 (0.9942) acc 59.3750 (71.4583) lr 1.9511e-03 eta 0:28:08
epoch [7/50] batch [140/428] time 0.079 (0.089) data 0.000 (0.004) loss 2.7490 (1.9631) teacher_loss 1.5923 (0.8623) loss_zs_kd 1.5999 (1.5713) loss_oracle 1.1011 (1.0765) kd_loss 1.0466 (0.9931) acc 43.7500 (70.8929) lr 1.9511e-03 eta 0:27:35
epoch [7/50] batch [160/428] time 0.074 (0.087) data 0.000 (0.003) loss 1.7378 (1.9530) teacher_loss 0.6443 (0.8526) loss_zs_kd 1.9452 (1.5800) loss_oracle 1.0582 (1.0768) kd_loss 0.9876 (0.9928) acc 78.1250 (71.4453) lr 1.9511e-03 eta 0:27:11
epoch [7/50] batch [180/428] time 0.079 (0.086) data 0.000 (0.003) loss 1.9823 (1.9565) teacher_loss 0.8936 (0.8555) loss_zs_kd 1.6185 (1.5793) loss_oracle 1.0939 (1.0779) kd_loss 0.9793 (0.9932) acc 65.6250 (71.2674) lr 1.9511e-03 eta 0:26:49
epoch [7/50] batch [200/428] time 0.083 (0.086) data 0.000 (0.003) loss 1.8072 (1.9650) teacher_loss 0.7127 (0.8636) loss_zs_kd 1.8516 (1.5720) loss_oracle 1.0779 (1.0801) kd_loss 0.9867 (0.9934) acc 78.1250 (70.8594) lr 1.9511e-03 eta 0:26:45
epoch [7/50] batch [220/428] time 0.063 (0.086) data 0.000 (0.002) loss 2.1342 (1.9748) teacher_loss 0.9794 (0.8721) loss_zs_kd 1.7621 (1.5729) loss_oracle 1.1429 (1.0829) kd_loss 1.0404 (0.9944) acc 65.6250 (70.4972) lr 1.9511e-03 eta 0:26:36
epoch [7/50] batch [240/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.1814 (1.9736) teacher_loss 1.0483 (0.8720) loss_zs_kd 1.6878 (1.5751) loss_oracle 1.0641 (1.0824) kd_loss 1.0267 (0.9934) acc 65.6250 (70.5469) lr 1.9511e-03 eta 0:26:30
epoch [7/50] batch [260/428] time 0.074 (0.085) data 0.000 (0.002) loss 1.8846 (1.9760) teacher_loss 0.7761 (0.8756) loss_zs_kd 1.6527 (1.5756) loss_oracle 1.0622 (1.0836) kd_loss 1.0023 (0.9921) acc 75.0000 (70.5529) lr 1.9511e-03 eta 0:26:21
epoch [7/50] batch [280/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.1497 (1.9694) teacher_loss 1.0540 (0.8695) loss_zs_kd 2.0541 (1.5853) loss_oracle 1.1174 (1.0831) kd_loss 0.9840 (0.9916) acc 62.5000 (70.7254) lr 1.9511e-03 eta 0:26:16
epoch [7/50] batch [300/428] time 0.083 (0.085) data 0.000 (0.002) loss 1.8218 (1.9683) teacher_loss 0.6615 (0.8664) loss_zs_kd 1.5441 (1.5939) loss_oracle 1.0501 (1.0834) kd_loss 1.0553 (0.9935) acc 75.0000 (71.0000) lr 1.9511e-03 eta 0:26:12
epoch [7/50] batch [320/428] time 0.071 (0.085) data 0.000 (0.002) loss 1.8679 (1.9647) teacher_loss 0.7641 (0.8630) loss_zs_kd 1.5985 (1.6049) loss_oracle 1.1085 (1.0837) kd_loss 0.9930 (0.9933) acc 71.8750 (71.1523) lr 1.9511e-03 eta 0:26:06
epoch [7/50] batch [340/428] time 0.077 (0.084) data 0.000 (0.002) loss 2.1619 (1.9657) teacher_loss 1.0775 (0.8640) loss_zs_kd 1.6502 (1.6007) loss_oracle 1.0643 (1.0843) kd_loss 0.9780 (0.9932) acc 68.7500 (71.1305) lr 1.9511e-03 eta 0:25:57
epoch [7/50] batch [360/428] time 0.090 (0.084) data 0.000 (0.002) loss 1.9278 (1.9670) teacher_loss 0.7950 (0.8663) loss_zs_kd 1.4623 (1.6018) loss_oracle 1.1810 (1.0845) kd_loss 1.0147 (0.9923) acc 71.8750 (70.9115) lr 1.9511e-03 eta 0:25:49
epoch [7/50] batch [380/428] time 0.077 (0.084) data 0.000 (0.002) loss 1.8058 (1.9631) teacher_loss 0.7000 (0.8636) loss_zs_kd 1.4391 (1.6121) loss_oracle 1.0823 (1.0859) kd_loss 0.9976 (0.9910) acc 81.2500 (71.0526) lr 1.9511e-03 eta 0:25:51
epoch [7/50] batch [400/428] time 0.078 (0.084) data 0.000 (0.001) loss 2.4699 (1.9630) teacher_loss 1.2900 (0.8637) loss_zs_kd 1.6911 (1.6193) loss_oracle 1.1016 (1.0864) kd_loss 1.0698 (0.9906) acc 40.6250 (71.0469) lr 1.9511e-03 eta 0:25:42
epoch [7/50] batch [420/428] time 0.074 (0.083) data 0.000 (0.001) loss 2.0199 (1.9682) teacher_loss 0.7410 (0.8673) loss_zs_kd 1.4205 (1.6159) loss_oracle 1.1525 (1.0865) kd_loss 1.1637 (0.9922) acc 75.0000 (71.0417) lr 1.9511e-03 eta 0:25:36
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,319
* accuracy: 56.5%
* error: 43.5%
* macro_f1: 37.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,719
* accuracy: 36.3%
* error: 63.7%
* macro_f1: 25.0%
******* Domain 1 best val acc:      56.5%, epoch: 7 *******
******* Domain 1 best val test acc: 36.3%, epoch: 7 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [8/50] batch [20/428] time 0.089 (0.112) data 0.000 (0.024) loss 2.1643 (2.3162) teacher_loss 0.9482 (1.1079) loss_zs_kd 1.0144 (1.5016) loss_oracle 1.1140 (1.0874) kd_loss 1.1047 (1.0995) acc 65.6250 (61.4062) lr 1.9298e-03 eta 0:34:26
epoch [8/50] batch [40/428] time 0.080 (0.101) data 0.000 (0.012) loss 2.3782 (2.3020) teacher_loss 1.1905 (1.0970) loss_zs_kd 1.5552 (1.4414) loss_oracle 1.1122 (1.0926) kd_loss 1.0765 (1.0957) acc 50.0000 (62.2656) lr 1.9298e-03 eta 0:30:51
epoch [8/50] batch [60/428] time 0.076 (0.095) data 0.000 (0.008) loss 1.9100 (2.2892) teacher_loss 0.8000 (1.0869) loss_zs_kd 1.3469 (1.4248) loss_oracle 1.0935 (1.0851) kd_loss 1.0006 (1.0938) acc 68.7500 (62.2917) lr 1.9298e-03 eta 0:29:06
epoch [8/50] batch [80/428] time 0.087 (0.091) data 0.000 (0.006) loss 2.3230 (2.2512) teacher_loss 1.2094 (1.0696) loss_zs_kd 1.5936 (1.4397) loss_oracle 1.0638 (1.0769) kd_loss 1.0072 (1.0739) acc 59.3750 (62.8906) lr 1.9298e-03 eta 0:27:50
epoch [8/50] batch [100/428] time 0.179 (0.092) data 0.000 (0.005) loss 1.8473 (2.2126) teacher_loss 0.7221 (1.0457) loss_zs_kd 2.0492 (1.4931) loss_oracle 1.0609 (1.0742) kd_loss 1.0191 (1.0596) acc 71.8750 (63.5938) lr 1.9298e-03 eta 0:27:58
epoch [8/50] batch [120/428] time 0.082 (0.091) data 0.000 (0.004) loss 1.9603 (2.1751) teacher_loss 0.8997 (1.0182) loss_zs_kd 1.5090 (1.5306) loss_oracle 0.9907 (1.0708) kd_loss 0.9615 (1.0498) acc 65.6250 (64.7917) lr 1.9298e-03 eta 0:27:40
epoch [8/50] batch [140/428] time 0.088 (0.089) data 0.000 (0.004) loss 2.1459 (2.1539) teacher_loss 0.9852 (1.0050) loss_zs_kd 1.7182 (1.5480) loss_oracle 1.1541 (1.0710) kd_loss 1.0453 (1.0418) acc 59.3750 (65.0893) lr 1.9298e-03 eta 0:27:10
epoch [8/50] batch [160/428] time 0.081 (0.089) data 0.000 (0.003) loss 2.1261 (2.1323) teacher_loss 0.9428 (0.9881) loss_zs_kd 1.8004 (1.5684) loss_oracle 1.1438 (1.0702) kd_loss 1.0689 (1.0373) acc 62.5000 (65.6055) lr 1.9298e-03 eta 0:26:57
epoch [8/50] batch [180/428] time 0.087 (0.088) data 0.000 (0.003) loss 2.1050 (2.1127) teacher_loss 1.0201 (0.9729) loss_zs_kd 1.6092 (1.5838) loss_oracle 1.0300 (1.0708) kd_loss 0.9820 (1.0327) acc 65.6250 (66.1632) lr 1.9298e-03 eta 0:26:48
epoch [8/50] batch [200/428] time 0.077 (0.088) data 0.000 (0.003) loss 2.1001 (2.0991) teacher_loss 0.8801 (0.9596) loss_zs_kd 1.7020 (1.5904) loss_oracle 1.1747 (1.0728) kd_loss 1.1026 (1.0322) acc 65.6250 (66.6406) lr 1.9298e-03 eta 0:26:38
epoch [8/50] batch [220/428] time 0.078 (0.087) data 0.000 (0.003) loss 1.8598 (2.0823) teacher_loss 0.6972 (0.9410) loss_zs_kd 2.1336 (1.6126) loss_oracle 1.1656 (1.0789) kd_loss 1.0460 (1.0334) acc 78.1250 (67.3011) lr 1.9298e-03 eta 0:26:28
epoch [8/50] batch [240/428] time 0.078 (0.087) data 0.000 (0.002) loss 2.0402 (2.0671) teacher_loss 0.9491 (0.9250) loss_zs_kd 1.9168 (1.6325) loss_oracle 1.0615 (1.0816) kd_loss 0.9849 (1.0339) acc 71.8750 (68.0599) lr 1.9298e-03 eta 0:26:22
epoch [8/50] batch [260/428] time 0.094 (0.087) data 0.001 (0.002) loss 1.9174 (2.0561) teacher_loss 0.8157 (0.9140) loss_zs_kd 1.8100 (1.6454) loss_oracle 1.1994 (1.0868) kd_loss 0.9817 (1.0334) acc 68.7500 (68.5216) lr 1.9298e-03 eta 0:26:14
epoch [8/50] batch [280/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.9069 (2.0493) teacher_loss 0.7363 (0.9059) loss_zs_kd 1.8147 (1.6555) loss_oracle 1.1507 (1.0902) kd_loss 1.0555 (1.0344) acc 78.1250 (68.8281) lr 1.9298e-03 eta 0:26:11
epoch [8/50] batch [300/428] time 0.096 (0.087) data 0.000 (0.002) loss 2.0097 (2.0426) teacher_loss 0.8830 (0.8985) loss_zs_kd 1.8778 (1.6688) loss_oracle 1.0420 (1.0920) kd_loss 1.0225 (1.0349) acc 65.6250 (68.9375) lr 1.9298e-03 eta 0:26:08
epoch [8/50] batch [320/428] time 0.079 (0.087) data 0.000 (0.002) loss 2.1249 (2.0331) teacher_loss 0.9475 (0.8895) loss_zs_kd 2.0497 (1.6809) loss_oracle 1.1648 (1.0927) kd_loss 1.0609 (1.0343) acc 65.6250 (69.2480) lr 1.9298e-03 eta 0:26:04
epoch [8/50] batch [340/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.7855 (2.0301) teacher_loss 0.5980 (0.8832) loss_zs_kd 2.3891 (1.6951) loss_oracle 1.1669 (1.0960) kd_loss 1.0708 (1.0373) acc 81.2500 (69.5129) lr 1.9298e-03 eta 0:26:00
epoch [8/50] batch [360/428] time 0.090 (0.086) data 0.000 (0.002) loss 1.9395 (2.0265) teacher_loss 0.8718 (0.8799) loss_zs_kd 1.4937 (1.7017) loss_oracle 1.0564 (1.0975) kd_loss 0.9620 (1.0369) acc 65.6250 (69.6962) lr 1.9298e-03 eta 0:25:58
epoch [8/50] batch [380/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.8912 (2.0217) teacher_loss 0.6504 (0.8749) loss_zs_kd 1.5229 (1.6966) loss_oracle 1.1751 (1.0981) kd_loss 1.1233 (1.0370) acc 75.0000 (69.8602) lr 1.9298e-03 eta 0:25:56
epoch [8/50] batch [400/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.5036 (2.0141) teacher_loss 0.4288 (0.8675) loss_zs_kd 1.8660 (1.6995) loss_oracle 1.0629 (1.0982) kd_loss 0.9686 (1.0368) acc 84.3750 (70.0156) lr 1.9298e-03 eta 0:25:53
epoch [8/50] batch [420/428] time 0.086 (0.086) data 0.000 (0.001) loss 2.0954 (2.0093) teacher_loss 0.9470 (0.8633) loss_zs_kd 1.5247 (1.7072) loss_oracle 1.1324 (1.0972) kd_loss 1.0352 (1.0362) acc 65.6250 (70.0893) lr 1.9298e-03 eta 0:25:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,412
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 42.9%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,726
* accuracy: 36.4%
* error: 63.6%
* macro_f1: 24.5%
******* Domain 1 best val acc:      58.1%, epoch: 8 *******
******* Domain 1 best val test acc: 36.4%, epoch: 8 *******
******* Domain 1 best test acc:     45.2%, epoch: 3 *******
epoch [9/50] batch [20/428] time 0.094 (0.119) data 0.000 (0.031) loss 1.6771 (1.9450) teacher_loss 0.5352 (0.7941) loss_zs_kd 1.7913 (1.7818) loss_oracle 1.0966 (1.0881) kd_loss 1.0322 (1.0420) acc 84.3750 (72.9688) lr 1.9048e-03 eta 0:35:33
epoch [9/50] batch [40/428] time 0.075 (0.101) data 0.000 (0.016) loss 2.1879 (1.9361) teacher_loss 1.0487 (0.7919) loss_zs_kd 1.6937 (1.7237) loss_oracle 1.0735 (1.0992) kd_loss 1.0319 (1.0344) acc 59.3750 (71.8750) lr 1.9048e-03 eta 0:30:04
epoch [9/50] batch [60/428] time 0.084 (0.094) data 0.000 (0.011) loss 1.7761 (1.9325) teacher_loss 0.6236 (0.7863) loss_zs_kd 1.5795 (1.7430) loss_oracle 1.0690 (1.1079) kd_loss 1.0456 (1.0354) acc 75.0000 (72.2396) lr 1.9048e-03 eta 0:28:02
epoch [9/50] batch [80/428] time 0.088 (0.092) data 0.000 (0.008) loss 2.1479 (1.9351) teacher_loss 0.9819 (0.7931) loss_zs_kd 1.8416 (1.7185) loss_oracle 1.1084 (1.1030) kd_loss 1.0552 (1.0317) acc 62.5000 (71.8359) lr 1.9048e-03 eta 0:27:18
epoch [9/50] batch [100/428] time 0.083 (0.090) data 0.000 (0.006) loss 2.0115 (1.9398) teacher_loss 0.8351 (0.7993) loss_zs_kd 1.6252 (1.7154) loss_oracle 1.1200 (1.1001) kd_loss 1.0644 (1.0305) acc 68.7500 (71.9062) lr 1.9048e-03 eta 0:26:48
epoch [9/50] batch [120/428] time 0.087 (0.089) data 0.000 (0.005) loss 2.3044 (1.9347) teacher_loss 1.1628 (0.7918) loss_zs_kd 1.8731 (1.7421) loss_oracle 1.0820 (1.1014) kd_loss 1.0334 (1.0327) acc 59.3750 (72.1615) lr 1.9048e-03 eta 0:26:29
epoch [9/50] batch [140/428] time 0.086 (0.089) data 0.000 (0.005) loss 2.0088 (1.9255) teacher_loss 0.9127 (0.7821) loss_zs_kd 1.7202 (1.7380) loss_oracle 1.1177 (1.1027) kd_loss 0.9843 (1.0331) acc 65.6250 (72.5893) lr 1.9048e-03 eta 0:26:21
epoch [9/50] batch [160/428] time 0.080 (0.088) data 0.000 (0.004) loss 2.1591 (1.9210) teacher_loss 1.0248 (0.7783) loss_zs_kd 1.7821 (1.7441) loss_oracle 1.1384 (1.1010) kd_loss 1.0205 (1.0326) acc 68.7500 (72.6953) lr 1.9048e-03 eta 0:26:13
epoch [9/50] batch [180/428] time 0.079 (0.087) data 0.001 (0.004) loss 1.9459 (1.9216) teacher_loss 0.7679 (0.7788) loss_zs_kd 2.2574 (1.7503) loss_oracle 1.1061 (1.0985) kd_loss 1.0674 (1.0329) acc 78.1250 (72.5174) lr 1.9048e-03 eta 0:25:55
epoch [9/50] batch [200/428] time 0.083 (0.087) data 0.000 (0.003) loss 1.8579 (1.9208) teacher_loss 0.6510 (0.7786) loss_zs_kd 1.5419 (1.7677) loss_oracle 1.0569 (1.0997) kd_loss 1.1012 (1.0321) acc 81.2500 (72.6875) lr 1.9048e-03 eta 0:25:39
epoch [9/50] batch [220/428] time 0.148 (0.087) data 0.000 (0.003) loss 1.8466 (1.9157) teacher_loss 0.7425 (0.7753) loss_zs_kd 2.2295 (1.7699) loss_oracle 1.0768 (1.0978) kd_loss 0.9964 (1.0306) acc 75.0000 (72.8835) lr 1.9048e-03 eta 0:25:47
epoch [9/50] batch [240/428] time 0.073 (0.087) data 0.000 (0.003) loss 2.0194 (1.9135) teacher_loss 0.8779 (0.7739) loss_zs_kd 2.2161 (1.7983) loss_oracle 1.0841 (1.0983) kd_loss 1.0331 (1.0298) acc 78.1250 (72.9557) lr 1.9048e-03 eta 0:25:37
epoch [9/50] batch [260/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.0939 (1.9185) teacher_loss 0.9060 (0.7778) loss_zs_kd 2.2240 (1.8078) loss_oracle 1.1077 (1.0982) kd_loss 1.0771 (1.0309) acc 56.2500 (72.7163) lr 1.9048e-03 eta 0:25:34
epoch [9/50] batch [280/428] time 0.086 (0.086) data 0.000 (0.002) loss 1.8780 (1.9208) teacher_loss 0.7215 (0.7796) loss_zs_kd 1.9308 (1.8174) loss_oracle 1.0710 (1.0968) kd_loss 1.0495 (1.0315) acc 65.6250 (72.7009) lr 1.9048e-03 eta 0:25:30
epoch [9/50] batch [300/428] time 0.078 (0.087) data 0.000 (0.002) loss 1.9155 (1.9254) teacher_loss 0.8107 (0.7856) loss_zs_kd 2.0510 (1.8269) loss_oracle 1.0636 (1.0954) kd_loss 0.9985 (1.0303) acc 81.2500 (72.7188) lr 1.9048e-03 eta 0:25:29
epoch [9/50] batch [320/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.1790 (1.9310) teacher_loss 1.0911 (0.7916) loss_zs_kd 1.5662 (1.8228) loss_oracle 1.0519 (1.0951) kd_loss 0.9827 (1.0299) acc 53.1250 (72.5195) lr 1.9048e-03 eta 0:25:26
epoch [9/50] batch [340/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.1197 (1.9347) teacher_loss 0.9651 (0.7964) loss_zs_kd 1.4788 (1.8149) loss_oracle 1.0655 (1.0935) kd_loss 1.0480 (1.0289) acc 68.7500 (72.2794) lr 1.9048e-03 eta 0:25:24
epoch [9/50] batch [360/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.0326 (1.9341) teacher_loss 0.8208 (0.7957) loss_zs_kd 1.9177 (1.8128) loss_oracle 1.0997 (1.0930) kd_loss 1.1018 (1.0291) acc 68.7500 (72.3611) lr 1.9048e-03 eta 0:25:22
epoch [9/50] batch [380/428] time 0.082 (0.086) data 0.000 (0.002) loss 2.1747 (1.9386) teacher_loss 1.0315 (0.7993) loss_zs_kd 1.7632 (1.8184) loss_oracle 1.1441 (1.0940) kd_loss 1.0288 (1.0299) acc 65.6250 (72.1053) lr 1.9048e-03 eta 0:25:19
epoch [9/50] batch [400/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.3140 (1.9431) teacher_loss 1.1864 (0.8036) loss_zs_kd 1.5897 (1.8111) loss_oracle 1.1041 (1.0952) kd_loss 1.0172 (1.0300) acc 62.5000 (71.9375) lr 1.9048e-03 eta 0:25:16
epoch [9/50] batch [420/428] time 0.079 (0.086) data 0.000 (0.002) loss 1.6024 (1.9413) teacher_loss 0.4743 (0.8018) loss_zs_kd 1.6743 (1.8028) loss_oracle 1.0857 (1.0956) kd_loss 1.0195 (1.0300) acc 81.2500 (71.9792) lr 1.9048e-03 eta 0:25:13
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,469
* accuracy: 59.0%
* error: 41.0%
* macro_f1: 44.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,207
* accuracy: 46.6%
* error: 53.4%
* macro_f1: 28.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      59.0%, epoch: 9 *******
******* Domain 1 best val test acc: 46.6%, epoch: 9 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [10/50] batch [20/428] time 0.089 (0.123) data 0.000 (0.035) loss 1.8906 (1.8933) teacher_loss 0.7465 (0.7614) loss_zs_kd 1.7204 (1.6934) loss_oracle 1.1387 (1.0981) kd_loss 1.0302 (1.0221) acc 65.6250 (72.9688) lr 1.8763e-03 eta 0:35:52
epoch [10/50] batch [40/428] time 0.091 (0.104) data 0.000 (0.018) loss 1.7635 (1.9183) teacher_loss 0.6191 (0.7804) loss_zs_kd 1.9137 (1.7629) loss_oracle 1.0885 (1.0998) kd_loss 1.0356 (1.0279) acc 75.0000 (72.1094) lr 1.8763e-03 eta 0:30:22
epoch [10/50] batch [60/428] time 0.081 (0.098) data 0.001 (0.012) loss 2.0100 (1.9091) teacher_loss 0.8040 (0.7734) loss_zs_kd 1.5829 (1.7535) loss_oracle 1.1615 (1.0987) kd_loss 1.0899 (1.0258) acc 65.6250 (72.5521) lr 1.8763e-03 eta 0:28:26
epoch [10/50] batch [80/428] time 0.082 (0.093) data 0.000 (0.009) loss 2.0105 (1.8985) teacher_loss 0.7793 (0.7622) loss_zs_kd 1.8087 (1.7836) loss_oracle 1.1425 (1.0995) kd_loss 1.1169 (1.0263) acc 68.7500 (73.0859) lr 1.8763e-03 eta 0:27:11
epoch [10/50] batch [100/428] time 0.080 (0.091) data 0.000 (0.007) loss 1.8069 (1.9071) teacher_loss 0.6407 (0.7664) loss_zs_kd 1.8155 (1.8023) loss_oracle 1.1123 (1.1014) kd_loss 1.0550 (1.0306) acc 84.3750 (72.9062) lr 1.8763e-03 eta 0:26:33
epoch [10/50] batch [120/428] time 0.092 (0.090) data 0.000 (0.006) loss 1.9869 (1.9141) teacher_loss 0.7422 (0.7667) loss_zs_kd 2.1351 (1.8236) loss_oracle 1.0950 (1.1034) kd_loss 1.1352 (1.0371) acc 75.0000 (72.9427) lr 1.8763e-03 eta 0:26:05
epoch [10/50] batch [140/428] time 0.078 (0.089) data 0.000 (0.005) loss 1.8511 (1.9105) teacher_loss 0.7052 (0.7605) loss_zs_kd 1.9500 (1.8506) loss_oracle 1.1379 (1.1069) kd_loss 1.0322 (1.0393) acc 78.1250 (73.4152) lr 1.8763e-03 eta 0:25:49
epoch [10/50] batch [160/428] time 0.080 (0.088) data 0.000 (0.005) loss 2.0531 (1.9184) teacher_loss 0.8098 (0.7656) loss_zs_kd 1.5713 (1.8636) loss_oracle 1.1550 (1.1089) kd_loss 1.1278 (1.0419) acc 62.5000 (73.0859) lr 1.8763e-03 eta 0:25:31
epoch [10/50] batch [180/428] time 0.077 (0.088) data 0.000 (0.004) loss 1.8741 (1.9216) teacher_loss 0.8007 (0.7692) loss_zs_kd 1.8567 (1.8701) loss_oracle 1.0251 (1.1099) kd_loss 0.9710 (1.0413) acc 75.0000 (73.2292) lr 1.8763e-03 eta 0:25:23
epoch [10/50] batch [200/428] time 0.082 (0.087) data 0.000 (0.004) loss 1.8581 (1.9257) teacher_loss 0.7709 (0.7721) loss_zs_kd 1.8854 (1.8630) loss_oracle 1.0493 (1.1113) kd_loss 0.9822 (1.0424) acc 68.7500 (72.9688) lr 1.8763e-03 eta 0:25:17
epoch [10/50] batch [220/428] time 0.077 (0.087) data 0.000 (0.003) loss 1.8510 (1.9356) teacher_loss 0.6434 (0.7811) loss_zs_kd 1.8039 (1.8458) loss_oracle 1.1684 (1.1105) kd_loss 1.0907 (1.0435) acc 81.2500 (72.7557) lr 1.8763e-03 eta 0:25:09
epoch [10/50] batch [240/428] time 0.088 (0.087) data 0.000 (0.003) loss 2.3242 (1.9384) teacher_loss 1.1163 (0.7842) loss_zs_kd 1.7945 (1.8452) loss_oracle 1.0830 (1.1097) kd_loss 1.0996 (1.0432) acc 62.5000 (72.8125) lr 1.8763e-03 eta 0:25:04
epoch [10/50] batch [260/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.9075 (1.9360) teacher_loss 0.7207 (0.7827) loss_zs_kd 2.1658 (1.8572) loss_oracle 1.1579 (1.1083) kd_loss 1.0710 (1.0425) acc 68.7500 (72.8606) lr 1.8763e-03 eta 0:24:59
epoch [10/50] batch [280/428] time 0.090 (0.087) data 0.000 (0.003) loss 2.0830 (1.9361) teacher_loss 0.9133 (0.7841) loss_zs_kd 1.7896 (1.8618) loss_oracle 1.1296 (1.1077) kd_loss 1.0568 (1.0413) acc 71.8750 (72.9018) lr 1.8763e-03 eta 0:24:54
epoch [10/50] batch [300/428] time 0.089 (0.086) data 0.000 (0.003) loss 1.6295 (1.9433) teacher_loss 0.4584 (0.7927) loss_zs_kd 1.6186 (1.8643) loss_oracle 1.0999 (1.1064) kd_loss 1.0612 (1.0399) acc 87.5000 (72.5312) lr 1.8763e-03 eta 0:24:51
epoch [10/50] batch [320/428] time 0.076 (0.086) data 0.000 (0.002) loss 1.6337 (1.9468) teacher_loss 0.5126 (0.7976) loss_zs_kd 1.7363 (1.8561) loss_oracle 1.0918 (1.1053) kd_loss 1.0119 (1.0386) acc 87.5000 (72.4219) lr 1.8763e-03 eta 0:24:46
epoch [10/50] batch [340/428] time 0.093 (0.087) data 0.000 (0.002) loss 2.5438 (1.9520) teacher_loss 1.4012 (0.8046) loss_zs_kd 1.5776 (1.8527) loss_oracle 1.0996 (1.1034) kd_loss 1.0326 (1.0371) acc 62.5000 (72.1599) lr 1.8763e-03 eta 0:24:52
epoch [10/50] batch [360/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.8930 (1.9516) teacher_loss 0.7765 (0.8056) loss_zs_kd 1.7947 (1.8563) loss_oracle 1.1245 (1.1027) kd_loss 1.0041 (1.0358) acc 68.7500 (72.1788) lr 1.8763e-03 eta 0:24:47
epoch [10/50] batch [380/428] time 0.080 (0.086) data 0.000 (0.002) loss 2.0932 (1.9490) teacher_loss 0.9612 (0.8052) loss_zs_kd 1.7099 (1.8473) loss_oracle 1.0813 (1.1020) kd_loss 1.0239 (1.0336) acc 68.7500 (72.3273) lr 1.8763e-03 eta 0:24:43
epoch [10/50] batch [400/428] time 0.077 (0.086) data 0.001 (0.002) loss 1.7875 (1.9463) teacher_loss 0.6350 (0.8039) loss_zs_kd 1.8329 (1.8384) loss_oracle 1.0775 (1.1006) kd_loss 1.0447 (1.0323) acc 75.0000 (72.4766) lr 1.8763e-03 eta 0:24:38
epoch [10/50] batch [420/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.7309 (1.9486) teacher_loss 0.5913 (0.8063) loss_zs_kd 1.7117 (1.8290) loss_oracle 1.0834 (1.1008) kd_loss 1.0312 (1.0322) acc 75.0000 (72.4033) lr 1.8763e-03 eta 0:24:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,355
* accuracy: 57.1%
* error: 42.9%
* macro_f1: 45.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,832
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 25.2%
******* Domain 1 best val acc:      59.0%, epoch: 9 *******
******* Domain 1 best val test acc: 46.6%, epoch: 9 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [11/50] batch [20/428] time 0.083 (0.116) data 0.000 (0.027) loss 1.9573 (1.9868) teacher_loss 0.7846 (0.7948) loss_zs_kd 1.8881 (1.7604) loss_oracle 1.1387 (1.1348) kd_loss 1.0588 (1.0785) acc 71.8750 (72.5000) lr 1.8443e-03 eta 0:33:07
epoch [11/50] batch [40/428] time 0.096 (0.100) data 0.000 (0.014) loss 1.9786 (1.9265) teacher_loss 0.8804 (0.7609) loss_zs_kd 1.9679 (1.7548) loss_oracle 1.0527 (1.1198) kd_loss 0.9929 (1.0536) acc 71.8750 (73.5938) lr 1.8443e-03 eta 0:28:26
epoch [11/50] batch [60/428] time 0.084 (0.094) data 0.000 (0.009) loss 2.0804 (1.9161) teacher_loss 0.8985 (0.7608) loss_zs_kd 2.1281 (1.8102) loss_oracle 1.1874 (1.1138) kd_loss 1.0632 (1.0439) acc 59.3750 (73.9062) lr 1.8443e-03 eta 0:26:46
epoch [11/50] batch [80/428] time 0.080 (0.094) data 0.000 (0.007) loss 1.9623 (1.9066) teacher_loss 0.8547 (0.7566) loss_zs_kd 1.4683 (1.7930) loss_oracle 1.0980 (1.1078) kd_loss 0.9979 (1.0393) acc 75.0000 (74.4141) lr 1.8443e-03 eta 0:26:40
epoch [11/50] batch [100/428] time 0.079 (0.091) data 0.000 (0.006) loss 1.7894 (1.9185) teacher_loss 0.6417 (0.7689) loss_zs_kd 1.7590 (1.7631) loss_oracle 1.0980 (1.1092) kd_loss 1.0379 (1.0386) acc 81.2500 (74.2500) lr 1.8443e-03 eta 0:25:42
epoch [11/50] batch [120/428] time 0.083 (0.091) data 0.000 (0.005) loss 1.8282 (1.9160) teacher_loss 0.7222 (0.7694) loss_zs_kd 1.8422 (1.7358) loss_oracle 1.0647 (1.1076) kd_loss 0.9995 (1.0358) acc 68.7500 (74.5052) lr 1.8443e-03 eta 0:25:49
epoch [11/50] batch [140/428] time 0.080 (0.090) data 0.000 (0.004) loss 2.3141 (1.9247) teacher_loss 1.2036 (0.7784) loss_zs_kd 1.8451 (1.7268) loss_oracle 1.0331 (1.1073) kd_loss 1.0072 (1.0356) acc 62.5000 (73.9509) lr 1.8443e-03 eta 0:25:27
epoch [11/50] batch [160/428] time 0.082 (0.089) data 0.000 (0.004) loss 2.4378 (1.9371) teacher_loss 1.2940 (0.7912) loss_zs_kd 1.6937 (1.7297) loss_oracle 1.0993 (1.1068) kd_loss 1.0338 (1.0353) acc 59.3750 (73.4961) lr 1.8443e-03 eta 0:25:14
epoch [11/50] batch [180/428] time 0.079 (0.089) data 0.000 (0.003) loss 2.1533 (1.9576) teacher_loss 0.9402 (0.8100) loss_zs_kd 1.6476 (1.7057) loss_oracle 1.1186 (1.1057) kd_loss 1.1012 (1.0371) acc 65.6250 (72.6389) lr 1.8443e-03 eta 0:25:08
epoch [11/50] batch [200/428] time 0.073 (0.088) data 0.000 (0.003) loss 2.1798 (1.9854) teacher_loss 1.0740 (0.8335) loss_zs_kd 1.3235 (1.6803) loss_oracle 1.0340 (1.1038) kd_loss 1.0024 (1.0415) acc 59.3750 (71.5469) lr 1.8443e-03 eta 0:24:46
epoch [11/50] batch [220/428] time 0.081 (0.088) data 0.000 (0.003) loss 2.0233 (1.9986) teacher_loss 0.9325 (0.8449) loss_zs_kd 1.3914 (1.6764) loss_oracle 0.9688 (1.1020) kd_loss 0.9939 (1.0435) acc 68.7500 (71.0369) lr 1.8443e-03 eta 0:24:42
epoch [11/50] batch [240/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.3923 (2.0017) teacher_loss 1.2001 (0.8469) loss_zs_kd 2.2225 (1.6818) loss_oracle 1.1729 (1.1019) kd_loss 1.0749 (1.0445) acc 68.7500 (71.1328) lr 1.8443e-03 eta 0:24:39
epoch [11/50] batch [260/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.8387 (2.0102) teacher_loss 0.7655 (0.8559) loss_zs_kd 1.7083 (1.6825) loss_oracle 1.0892 (1.1015) kd_loss 0.9643 (1.0442) acc 68.7500 (70.7212) lr 1.8443e-03 eta 0:24:32
epoch [11/50] batch [280/428] time 0.085 (0.087) data 0.000 (0.002) loss 2.1333 (2.0055) teacher_loss 0.9629 (0.8514) loss_zs_kd 1.9326 (1.6819) loss_oracle 1.1515 (1.1007) kd_loss 1.0553 (1.0440) acc 71.8750 (70.8482) lr 1.8443e-03 eta 0:24:28
epoch [11/50] batch [300/428] time 0.074 (0.087) data 0.000 (0.002) loss 2.2980 (2.0078) teacher_loss 0.9998 (0.8512) loss_zs_kd 1.9202 (1.6902) loss_oracle 1.1831 (1.1033) kd_loss 1.1799 (1.0463) acc 71.8750 (70.6042) lr 1.8443e-03 eta 0:24:24
epoch [11/50] batch [320/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.0825 (2.0199) teacher_loss 0.8373 (0.8580) loss_zs_kd 2.0427 (1.7069) loss_oracle 1.2265 (1.1078) kd_loss 1.1226 (1.0511) acc 71.8750 (70.1660) lr 1.8443e-03 eta 0:24:20
epoch [11/50] batch [340/428] time 0.088 (0.087) data 0.000 (0.002) loss 2.3302 (2.0298) teacher_loss 1.0297 (0.8619) loss_zs_kd 1.5649 (1.7096) loss_oracle 1.1440 (1.1111) kd_loss 1.1861 (1.0568) acc 56.2500 (69.9908) lr 1.8443e-03 eta 0:24:17
epoch [11/50] batch [360/428] time 0.081 (0.087) data 0.000 (0.002) loss 2.0682 (2.0300) teacher_loss 0.8858 (0.8610) loss_zs_kd 1.7244 (1.7127) loss_oracle 1.1371 (1.1139) kd_loss 1.0687 (1.0576) acc 71.8750 (69.8698) lr 1.8443e-03 eta 0:24:14
epoch [11/50] batch [380/428] time 0.089 (0.087) data 0.000 (0.002) loss 2.1224 (2.0297) teacher_loss 0.9679 (0.8619) loss_zs_kd 1.6701 (1.7133) loss_oracle 1.1169 (1.1150) kd_loss 1.0428 (1.0563) acc 65.6250 (69.8520) lr 1.8443e-03 eta 0:24:12
epoch [11/50] batch [400/428] time 0.081 (0.087) data 0.000 (0.002) loss 1.9916 (2.0326) teacher_loss 0.8573 (0.8663) loss_zs_kd 1.7917 (1.7108) loss_oracle 1.1118 (1.1143) kd_loss 1.0231 (1.0548) acc 68.7500 (69.6719) lr 1.8443e-03 eta 0:24:10
epoch [11/50] batch [420/428] time 0.073 (0.087) data 0.000 (0.002) loss 1.9212 (2.0349) teacher_loss 0.7583 (0.8694) loss_zs_kd 1.7162 (1.7131) loss_oracle 1.0609 (1.1134) kd_loss 1.0568 (1.0542) acc 71.8750 (69.5536) lr 1.8443e-03 eta 0:24:06
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,616
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 48.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,936
* accuracy: 40.8%
* error: 59.2%
* macro_f1: 27.8%
******* Domain 1 best val acc:      61.5%, epoch: 11 *******
******* Domain 1 best val test acc: 40.8%, epoch: 11 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [12/50] batch [20/428] time 0.145 (0.121) data 0.000 (0.032) loss 2.0254 (2.0001) teacher_loss 0.9478 (0.8682) loss_zs_kd 1.6332 (1.6639) loss_oracle 1.0478 (1.1040) kd_loss 0.9728 (1.0215) acc 71.8750 (70.0000) lr 1.8090e-03 eta 0:33:45
epoch [12/50] batch [40/428] time 0.095 (0.101) data 0.000 (0.016) loss 2.0554 (1.9783) teacher_loss 0.9355 (0.8404) loss_zs_kd 2.1734 (1.6746) loss_oracle 1.1439 (1.1023) kd_loss 1.0055 (1.0277) acc 65.6250 (71.4062) lr 1.8090e-03 eta 0:27:59
epoch [12/50] batch [60/428] time 0.084 (0.097) data 0.000 (0.011) loss 2.0407 (1.9908) teacher_loss 0.8954 (0.8498) loss_zs_kd 1.6033 (1.6880) loss_oracle 1.0648 (1.1049) kd_loss 1.0388 (1.0305) acc 65.6250 (70.3125) lr 1.8090e-03 eta 0:26:45
epoch [12/50] batch [80/428] time 0.082 (0.094) data 0.000 (0.008) loss 1.8123 (1.9841) teacher_loss 0.6492 (0.8403) loss_zs_kd 1.7378 (1.6895) loss_oracle 1.0981 (1.1028) kd_loss 1.0533 (1.0336) acc 84.3750 (70.5469) lr 1.8090e-03 eta 0:25:56
epoch [12/50] batch [100/428] time 0.079 (0.092) data 0.000 (0.007) loss 2.3112 (1.9820) teacher_loss 1.1829 (0.8371) loss_zs_kd 2.0893 (1.7070) loss_oracle 1.1648 (1.1059) kd_loss 1.0119 (1.0343) acc 59.3750 (70.9062) lr 1.8090e-03 eta 0:25:27
epoch [12/50] batch [120/428] time 0.072 (0.090) data 0.000 (0.006) loss 1.9854 (1.9764) teacher_loss 0.8546 (0.8309) loss_zs_kd 1.7825 (1.7633) loss_oracle 1.0867 (1.1075) kd_loss 1.0221 (1.0347) acc 75.0000 (71.1719) lr 1.8090e-03 eta 0:24:43
epoch [12/50] batch [140/428] time 0.077 (0.088) data 0.000 (0.005) loss 1.9904 (1.9749) teacher_loss 0.8305 (0.8275) loss_zs_kd 1.5688 (1.7648) loss_oracle 1.0498 (1.1047) kd_loss 1.0549 (1.0369) acc 68.7500 (71.2500) lr 1.8090e-03 eta 0:24:13
epoch [12/50] batch [160/428] time 0.074 (0.087) data 0.000 (0.004) loss 1.8428 (1.9689) teacher_loss 0.7245 (0.8217) loss_zs_kd 1.9907 (1.7677) loss_oracle 1.0945 (1.1011) kd_loss 1.0089 (1.0371) acc 75.0000 (71.3867) lr 1.8090e-03 eta 0:23:50
epoch [12/50] batch [180/428] time 0.087 (0.086) data 0.000 (0.004) loss 1.9508 (1.9594) teacher_loss 0.8121 (0.8136) loss_zs_kd 1.5421 (1.7699) loss_oracle 1.0808 (1.0962) kd_loss 1.0306 (1.0361) acc 75.0000 (71.7361) lr 1.8090e-03 eta 0:23:41
epoch [12/50] batch [200/428] time 0.077 (0.087) data 0.000 (0.003) loss 1.8051 (1.9528) teacher_loss 0.6420 (0.8081) loss_zs_kd 1.8299 (1.7732) loss_oracle 1.0671 (1.0934) kd_loss 1.0564 (1.0353) acc 78.1250 (71.9688) lr 1.8090e-03 eta 0:24:00
epoch [12/50] batch [220/428] time 0.080 (0.087) data 0.000 (0.003) loss 1.9717 (1.9521) teacher_loss 0.7753 (0.8081) loss_zs_kd 1.3992 (1.7781) loss_oracle 1.0876 (1.0930) kd_loss 1.0876 (1.0346) acc 75.0000 (71.9886) lr 1.8090e-03 eta 0:23:53
epoch [12/50] batch [240/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.0384 (1.9610) teacher_loss 0.8846 (0.8147) loss_zs_kd 1.5090 (1.7815) loss_oracle 1.1216 (1.0955) kd_loss 1.0416 (1.0368) acc 62.5000 (71.7057) lr 1.8090e-03 eta 0:23:50
epoch [12/50] batch [260/428] time 0.081 (0.087) data 0.000 (0.003) loss 1.8693 (1.9585) teacher_loss 0.7793 (0.8119) loss_zs_kd 1.4383 (1.7844) loss_oracle 1.0718 (1.0963) kd_loss 0.9829 (1.0369) acc 71.8750 (71.6587) lr 1.8090e-03 eta 0:23:46
epoch [12/50] batch [280/428] time 0.075 (0.086) data 0.000 (0.003) loss 1.7347 (1.9625) teacher_loss 0.6152 (0.8153) loss_zs_kd 1.9116 (1.7798) loss_oracle 1.1207 (1.0958) kd_loss 1.0074 (1.0376) acc 81.2500 (71.6518) lr 1.8090e-03 eta 0:23:37
epoch [12/50] batch [300/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.0604 (1.9650) teacher_loss 0.8902 (0.8178) loss_zs_kd 1.9164 (1.7832) loss_oracle 1.0956 (1.0951) kd_loss 1.0606 (1.0377) acc 71.8750 (71.6250) lr 1.8090e-03 eta 0:23:30
epoch [12/50] batch [320/428] time 0.073 (0.085) data 0.000 (0.002) loss 1.9413 (1.9742) teacher_loss 0.7451 (0.8248) loss_zs_kd 1.7527 (1.7894) loss_oracle 1.1725 (1.0968) kd_loss 1.0789 (1.0397) acc 65.6250 (71.3477) lr 1.8090e-03 eta 0:23:19
epoch [12/50] batch [340/428] time 0.081 (0.085) data 0.000 (0.002) loss 2.2960 (1.9743) teacher_loss 1.1735 (0.8248) loss_zs_kd 1.6116 (1.7837) loss_oracle 1.1755 (1.0965) kd_loss 1.0049 (1.0398) acc 53.1250 (71.2960) lr 1.8090e-03 eta 0:23:11
epoch [12/50] batch [360/428] time 0.076 (0.085) data 0.000 (0.002) loss 1.6640 (1.9719) teacher_loss 0.5510 (0.8239) loss_zs_kd 1.6815 (1.7770) loss_oracle 1.0601 (1.0950) kd_loss 1.0069 (1.0385) acc 78.1250 (71.3889) lr 1.8090e-03 eta 0:23:09
epoch [12/50] batch [380/428] time 0.077 (0.085) data 0.000 (0.002) loss 1.9461 (1.9681) teacher_loss 0.8300 (0.8222) loss_zs_kd 1.1617 (1.7581) loss_oracle 0.9892 (1.0927) kd_loss 1.0171 (1.0367) acc 75.0000 (71.3898) lr 1.8090e-03 eta 0:23:05
epoch [12/50] batch [400/428] time 0.086 (0.085) data 0.000 (0.002) loss 1.9943 (1.9663) teacher_loss 0.8792 (0.8212) loss_zs_kd 1.7670 (1.7534) loss_oracle 1.0897 (1.0912) kd_loss 1.0062 (1.0360) acc 71.8750 (71.3750) lr 1.8090e-03 eta 0:23:03
epoch [12/50] batch [420/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.0888 (1.9711) teacher_loss 0.9695 (0.8259) loss_zs_kd 1.6422 (1.7586) loss_oracle 1.0967 (1.0908) kd_loss 1.0097 (1.0361) acc 75.0000 (71.2277) lr 1.8090e-03 eta 0:23:02
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,461
* accuracy: 58.9%
* error: 41.1%
* macro_f1: 43.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,842
* accuracy: 38.9%
* error: 61.1%
* macro_f1: 24.8%
******* Domain 1 best val acc:      61.5%, epoch: 11 *******
******* Domain 1 best val test acc: 40.8%, epoch: 11 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [13/50] batch [20/428] time 0.074 (0.120) data 0.000 (0.032) loss 1.8954 (2.0705) teacher_loss 0.7113 (0.8960) loss_zs_kd 2.1843 (2.1275) loss_oracle 1.1803 (1.1288) kd_loss 1.0661 (1.0617) acc 75.0000 (67.1875) lr 1.7705e-03 eta 0:32:25
epoch [13/50] batch [40/428] time 0.093 (0.102) data 0.000 (0.016) loss 2.0087 (2.0774) teacher_loss 0.8769 (0.9106) loss_zs_kd 2.0383 (2.1077) loss_oracle 1.1127 (1.1265) kd_loss 1.0205 (1.0542) acc 71.8750 (69.1406) lr 1.7705e-03 eta 0:27:36
epoch [13/50] batch [60/428] time 0.077 (0.096) data 0.001 (0.011) loss 1.9576 (2.0356) teacher_loss 0.8397 (0.8717) loss_zs_kd 1.7948 (1.9825) loss_oracle 1.0381 (1.1163) kd_loss 1.0142 (1.0523) acc 68.7500 (69.7917) lr 1.7705e-03 eta 0:25:59
epoch [13/50] batch [80/428] time 0.079 (0.093) data 0.000 (0.008) loss 1.9642 (2.0416) teacher_loss 0.8860 (0.8831) loss_zs_kd 1.6996 (1.9403) loss_oracle 1.1334 (1.1091) kd_loss 0.9649 (1.0476) acc 75.0000 (68.9844) lr 1.7705e-03 eta 0:25:10
epoch [13/50] batch [100/428] time 0.082 (0.091) data 0.000 (0.007) loss 2.0903 (2.0360) teacher_loss 0.9450 (0.8773) loss_zs_kd 2.1189 (1.9405) loss_oracle 1.0785 (1.1102) kd_loss 1.0375 (1.0476) acc 59.3750 (69.1875) lr 1.7705e-03 eta 0:24:34
epoch [13/50] batch [120/428] time 0.079 (0.090) data 0.000 (0.006) loss 1.9780 (2.0586) teacher_loss 0.8077 (0.8958) loss_zs_kd 1.9793 (1.9594) loss_oracle 1.1045 (1.1121) kd_loss 1.0598 (1.0516) acc 75.0000 (68.6719) lr 1.7705e-03 eta 0:24:13
epoch [13/50] batch [140/428] time 0.091 (0.090) data 0.001 (0.005) loss 2.0126 (2.0643) teacher_loss 0.8043 (0.8984) loss_zs_kd 1.5986 (1.9652) loss_oracle 1.1001 (1.1110) kd_loss 1.0983 (1.0548) acc 78.1250 (68.4375) lr 1.7705e-03 eta 0:24:10
epoch [13/50] batch [160/428] time 0.081 (0.089) data 0.000 (0.004) loss 2.1610 (2.0791) teacher_loss 0.9527 (0.9114) loss_zs_kd 1.5563 (1.9401) loss_oracle 1.0890 (1.1114) kd_loss 1.0994 (1.0566) acc 65.6250 (68.1641) lr 1.7705e-03 eta 0:23:55
epoch [13/50] batch [180/428] time 0.084 (0.089) data 0.000 (0.004) loss 1.8198 (2.0665) teacher_loss 0.6959 (0.9017) loss_zs_kd 1.9346 (1.9302) loss_oracle 1.1108 (1.1098) kd_loss 1.0128 (1.0539) acc 81.2500 (68.5938) lr 1.7705e-03 eta 0:23:44
epoch [13/50] batch [200/428] time 0.087 (0.088) data 0.000 (0.003) loss 1.9509 (2.0584) teacher_loss 0.7764 (0.8945) loss_zs_kd 2.0149 (1.9125) loss_oracle 1.0752 (1.1070) kd_loss 1.0670 (1.0532) acc 75.0000 (68.7031) lr 1.7705e-03 eta 0:23:36
epoch [13/50] batch [220/428] time 0.079 (0.087) data 0.000 (0.003) loss 1.9104 (2.0535) teacher_loss 0.7891 (0.8910) loss_zs_kd 1.8851 (1.9055) loss_oracle 1.1056 (1.1053) kd_loss 1.0107 (1.0520) acc 71.8750 (68.5653) lr 1.7705e-03 eta 0:23:23
epoch [13/50] batch [240/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.1170 (2.0494) teacher_loss 0.9648 (0.8887) loss_zs_kd 1.6955 (1.8944) loss_oracle 1.0437 (1.1034) kd_loss 1.0478 (1.0503) acc 68.7500 (68.5677) lr 1.7705e-03 eta 0:23:23
epoch [13/50] batch [260/428] time 0.078 (0.087) data 0.000 (0.003) loss 1.8984 (2.0484) teacher_loss 0.7494 (0.8891) loss_zs_kd 1.7872 (1.8892) loss_oracle 1.0615 (1.1011) kd_loss 1.0429 (1.0492) acc 81.2500 (68.6298) lr 1.7705e-03 eta 0:23:17
epoch [13/50] batch [280/428] time 0.084 (0.087) data 0.000 (0.003) loss 2.0497 (2.0488) teacher_loss 0.9435 (0.8917) loss_zs_kd 1.5728 (1.8801) loss_oracle 1.0849 (1.0990) kd_loss 0.9977 (1.0472) acc 59.3750 (68.2701) lr 1.7705e-03 eta 0:23:13
epoch [13/50] batch [300/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.9585 (2.0503) teacher_loss 0.8193 (0.8944) loss_zs_kd 1.9055 (1.8734) loss_oracle 1.0688 (1.0973) kd_loss 1.0323 (1.0462) acc 68.7500 (68.0521) lr 1.7705e-03 eta 0:23:07
epoch [13/50] batch [320/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.1386 (2.0464) teacher_loss 1.0009 (0.8920) loss_zs_kd 1.6780 (1.8690) loss_oracle 1.0760 (1.0955) kd_loss 1.0301 (1.0449) acc 65.6250 (68.1543) lr 1.7705e-03 eta 0:23:13
epoch [13/50] batch [340/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.9223 (2.0484) teacher_loss 0.7563 (0.8950) loss_zs_kd 1.8960 (1.8680) loss_oracle 1.0542 (1.0932) kd_loss 1.0605 (1.0441) acc 78.1250 (67.9412) lr 1.7705e-03 eta 0:23:07
epoch [13/50] batch [360/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.2134 (2.0445) teacher_loss 1.1097 (0.8925) loss_zs_kd 1.3690 (1.8631) loss_oracle 1.0585 (1.0906) kd_loss 0.9978 (1.0430) acc 56.2500 (67.9861) lr 1.7705e-03 eta 0:23:02
epoch [13/50] batch [380/428] time 0.096 (0.087) data 0.000 (0.002) loss 2.4536 (2.0479) teacher_loss 1.2752 (0.8963) loss_zs_kd 1.7016 (1.8557) loss_oracle 1.0545 (1.0881) kd_loss 1.0730 (1.0428) acc 43.7500 (67.8125) lr 1.7705e-03 eta 0:22:57
epoch [13/50] batch [400/428] time 0.084 (0.087) data 0.000 (0.002) loss 1.9773 (2.0439) teacher_loss 0.8014 (0.8932) loss_zs_kd 1.9292 (1.8520) loss_oracle 1.0680 (1.0860) kd_loss 1.0691 (1.0421) acc 65.6250 (67.8984) lr 1.7705e-03 eta 0:22:53
epoch [13/50] batch [420/428] time 0.075 (0.086) data 0.000 (0.002) loss 2.1885 (2.0419) teacher_loss 1.0383 (0.8924) loss_zs_kd 1.5726 (1.8515) loss_oracle 1.0564 (1.0837) kd_loss 1.0446 (1.0411) acc 59.3750 (67.9836) lr 1.7705e-03 eta 0:22:46
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,689
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 50.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,839
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 27.2%
******* Domain 1 best val acc:      62.8%, epoch: 13 *******
******* Domain 1 best val test acc: 38.8%, epoch: 13 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [14/50] batch [20/428] time 0.082 (0.115) data 0.000 (0.033) loss 2.3125 (2.0737) teacher_loss 1.1517 (0.9478) loss_zs_kd 2.0908 (1.9992) loss_oracle 1.0439 (1.0361) kd_loss 1.0565 (1.0223) acc 56.2500 (66.2500) lr 1.7290e-03 eta 0:30:15
epoch [14/50] batch [40/428] time 0.068 (0.101) data 0.000 (0.017) loss 2.2970 (2.0240) teacher_loss 1.1544 (0.8978) loss_zs_kd 2.0998 (2.0084) loss_oracle 1.0086 (1.0361) kd_loss 1.0418 (1.0226) acc 62.5000 (67.8125) lr 1.7290e-03 eta 0:26:39
epoch [14/50] batch [60/428] time 0.080 (0.094) data 0.000 (0.011) loss 1.5903 (1.9992) teacher_loss 0.5176 (0.8787) loss_zs_kd 1.6595 (1.8996) loss_oracle 0.9843 (1.0318) kd_loss 0.9743 (1.0173) acc 81.2500 (68.5417) lr 1.7290e-03 eta 0:24:36
epoch [14/50] batch [80/428] time 0.082 (0.090) data 0.000 (0.009) loss 1.7026 (1.9850) teacher_loss 0.5853 (0.8622) loss_zs_kd 1.4203 (1.8542) loss_oracle 1.0159 (1.0299) kd_loss 1.0157 (1.0198) acc 78.1250 (69.4922) lr 1.7290e-03 eta 0:23:37
epoch [14/50] batch [100/428] time 0.080 (0.088) data 0.000 (0.007) loss 2.1331 (1.9792) teacher_loss 1.0532 (0.8541) loss_zs_kd 1.6003 (1.8350) loss_oracle 1.0202 (1.0286) kd_loss 0.9779 (1.0222) acc 68.7500 (69.8750) lr 1.7290e-03 eta 0:23:01
epoch [14/50] batch [120/428] time 0.083 (0.086) data 0.000 (0.006) loss 1.9319 (1.9748) teacher_loss 0.7963 (0.8510) loss_zs_kd 1.9891 (1.8669) loss_oracle 1.0396 (1.0259) kd_loss 1.0316 (1.0212) acc 71.8750 (70.0260) lr 1.7290e-03 eta 0:22:37
epoch [14/50] batch [140/428] time 0.077 (0.085) data 0.000 (0.005) loss 1.9051 (1.9731) teacher_loss 0.7906 (0.8489) loss_zs_kd 1.9481 (1.8709) loss_oracle 1.0276 (1.0263) kd_loss 1.0118 (1.0216) acc 71.8750 (70.2232) lr 1.7290e-03 eta 0:22:18
epoch [14/50] batch [160/428] time 0.075 (0.085) data 0.000 (0.004) loss 1.9986 (1.9689) teacher_loss 0.9206 (0.8442) loss_zs_kd 1.9429 (1.8724) loss_oracle 1.0449 (1.0272) kd_loss 0.9735 (1.0220) acc 71.8750 (70.3320) lr 1.7290e-03 eta 0:22:08
epoch [14/50] batch [180/428] time 0.089 (0.084) data 0.000 (0.004) loss 1.9337 (1.9708) teacher_loss 0.8002 (0.8474) loss_zs_kd 1.7990 (1.8576) loss_oracle 0.9847 (1.0259) kd_loss 1.0350 (1.0207) acc 71.8750 (70.0000) lr 1.7290e-03 eta 0:21:55
epoch [14/50] batch [200/428] time 0.080 (0.084) data 0.000 (0.004) loss 1.7434 (1.9697) teacher_loss 0.6050 (0.8458) loss_zs_kd 1.8527 (1.8545) loss_oracle 1.0639 (1.0255) kd_loss 1.0321 (1.0214) acc 81.2500 (70.2344) lr 1.7290e-03 eta 0:21:52
epoch [14/50] batch [220/428] time 0.081 (0.084) data 0.000 (0.003) loss 1.8738 (1.9750) teacher_loss 0.8136 (0.8519) loss_zs_kd 1.6529 (1.8356) loss_oracle 0.9786 (1.0254) kd_loss 0.9623 (1.0206) acc 68.7500 (70.0000) lr 1.7290e-03 eta 0:21:51
epoch [14/50] batch [240/428] time 0.081 (0.084) data 0.000 (0.003) loss 1.8014 (1.9720) teacher_loss 0.7043 (0.8502) loss_zs_kd 1.4720 (1.8212) loss_oracle 1.0466 (1.0245) kd_loss 0.9924 (1.0194) acc 68.7500 (70.0521) lr 1.7290e-03 eta 0:21:51
epoch [14/50] batch [260/428] time 0.082 (0.084) data 0.000 (0.003) loss 1.9204 (1.9746) teacher_loss 0.8708 (0.8538) loss_zs_kd 1.4992 (1.8009) loss_oracle 0.9780 (1.0229) kd_loss 0.9518 (1.0185) acc 62.5000 (69.8317) lr 1.7290e-03 eta 0:21:52
epoch [14/50] batch [280/428] time 0.092 (0.084) data 0.000 (0.003) loss 2.0167 (1.9692) teacher_loss 0.8410 (0.8490) loss_zs_kd 1.5543 (1.7964) loss_oracle 1.0578 (1.0234) kd_loss 1.0699 (1.0178) acc 65.6250 (69.9777) lr 1.7290e-03 eta 0:21:49
epoch [14/50] batch [300/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.3352 (1.9738) teacher_loss 1.2866 (0.8526) loss_zs_kd 1.8419 (1.8016) loss_oracle 0.9818 (1.0228) kd_loss 0.9505 (1.0189) acc 53.1250 (69.8125) lr 1.7290e-03 eta 0:21:49
epoch [14/50] batch [320/428] time 0.085 (0.084) data 0.000 (0.002) loss 1.8924 (1.9762) teacher_loss 0.7889 (0.8546) loss_zs_kd 1.2144 (1.7873) loss_oracle 0.9916 (1.0223) kd_loss 1.0044 (1.0194) acc 71.8750 (69.7852) lr 1.7290e-03 eta 0:21:47
epoch [14/50] batch [340/428] time 0.085 (0.084) data 0.000 (0.002) loss 1.9609 (1.9712) teacher_loss 0.8031 (0.8493) loss_zs_kd 2.0867 (1.7938) loss_oracle 1.0348 (1.0215) kd_loss 1.0543 (1.0198) acc 68.7500 (70.0827) lr 1.7290e-03 eta 0:21:45
epoch [14/50] batch [360/428] time 0.085 (0.084) data 0.000 (0.002) loss 1.8325 (1.9696) teacher_loss 0.7905 (0.8478) loss_zs_kd 1.5918 (1.7971) loss_oracle 1.0125 (1.0212) kd_loss 0.9408 (1.0197) acc 81.2500 (70.2257) lr 1.7290e-03 eta 0:21:44
epoch [14/50] batch [380/428] time 0.081 (0.084) data 0.000 (0.002) loss 2.0761 (1.9652) teacher_loss 0.9511 (0.8439) loss_zs_kd 1.7325 (1.7969) loss_oracle 1.0047 (1.0209) kd_loss 1.0245 (1.0192) acc 65.6250 (70.3618) lr 1.7290e-03 eta 0:21:41
epoch [14/50] batch [400/428] time 0.082 (0.084) data 0.000 (0.002) loss 2.2286 (1.9653) teacher_loss 1.0863 (0.8436) loss_zs_kd 1.8188 (1.7954) loss_oracle 1.0423 (1.0213) kd_loss 1.0381 (1.0196) acc 65.6250 (70.4297) lr 1.7290e-03 eta 0:21:37
epoch [14/50] batch [420/428] time 0.071 (0.084) data 0.000 (0.002) loss 2.0823 (1.9625) teacher_loss 0.8985 (0.8405) loss_zs_kd 2.2258 (1.8009) loss_oracle 1.0675 (1.0216) kd_loss 1.0771 (1.0198) acc 62.5000 (70.4836) lr 1.7290e-03 eta 0:21:32
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,639
* accuracy: 61.9%
* error: 38.1%
* macro_f1: 49.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,028
* accuracy: 42.8%
* error: 57.2%
* macro_f1: 30.5%
******* Domain 1 best val acc:      62.8%, epoch: 13 *******
******* Domain 1 best val test acc: 38.8%, epoch: 13 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [15/50] batch [20/428] time 0.075 (0.097) data 0.000 (0.026) loss 1.8976 (1.8787) teacher_loss 0.7248 (0.7237) loss_zs_kd 1.5436 (1.8500) loss_oracle 1.0558 (1.0286) kd_loss 1.0672 (1.0521) acc 75.0000 (74.0625) lr 1.6845e-03 eta 0:24:55
epoch [15/50] batch [40/428] time 0.063 (0.081) data 0.000 (0.013) loss 1.9114 (1.9211) teacher_loss 0.7932 (0.7707) loss_zs_kd 2.0407 (1.7320) loss_oracle 1.0060 (1.0288) kd_loss 1.0176 (1.0474) acc 71.8750 (72.5000) lr 1.6845e-03 eta 0:20:44
epoch [15/50] batch [60/428] time 0.065 (0.075) data 0.000 (0.009) loss 1.9498 (1.9477) teacher_loss 0.7832 (0.8016) loss_zs_kd 2.0693 (1.7288) loss_oracle 1.0336 (1.0254) kd_loss 1.0632 (1.0435) acc 65.6250 (71.5625) lr 1.6845e-03 eta 0:19:11
epoch [15/50] batch [80/428] time 0.062 (0.072) data 0.000 (0.007) loss 2.1983 (1.9406) teacher_loss 1.0505 (0.8010) loss_zs_kd 2.0156 (1.7311) loss_oracle 1.0401 (1.0228) kd_loss 1.0438 (1.0373) acc 68.7500 (72.0312) lr 1.6845e-03 eta 0:18:26
epoch [15/50] batch [100/428] time 0.063 (0.070) data 0.000 (0.005) loss 2.1430 (1.9446) teacher_loss 1.0575 (0.8087) loss_zs_kd 1.9965 (1.7625) loss_oracle 1.0237 (1.0210) kd_loss 0.9831 (1.0338) acc 68.7500 (71.6875) lr 1.6845e-03 eta 0:17:56
epoch [15/50] batch [120/428] time 0.067 (0.069) data 0.000 (0.004) loss 2.4992 (1.9524) teacher_loss 1.3994 (0.8193) loss_zs_kd 1.3394 (1.7596) loss_oracle 1.0376 (1.0210) kd_loss 0.9961 (1.0310) acc 59.3750 (71.1458) lr 1.6845e-03 eta 0:17:38
epoch [15/50] batch [140/428] time 0.073 (0.069) data 0.000 (0.004) loss 2.1984 (1.9596) teacher_loss 1.0351 (0.8265) loss_zs_kd 1.9959 (1.7448) loss_oracle 1.0149 (1.0204) kd_loss 1.0618 (1.0311) acc 62.5000 (71.0938) lr 1.6845e-03 eta 0:17:28
epoch [15/50] batch [160/428] time 0.064 (0.068) data 0.000 (0.003) loss 2.0692 (1.9652) teacher_loss 0.9720 (0.8334) loss_zs_kd 1.8023 (1.7438) loss_oracle 1.0509 (1.0194) kd_loss 0.9921 (1.0298) acc 56.2500 (70.5664) lr 1.6845e-03 eta 0:17:19
epoch [15/50] batch [180/428] time 0.063 (0.068) data 0.000 (0.003) loss 2.2251 (1.9756) teacher_loss 1.0495 (0.8419) loss_zs_kd 1.6799 (1.7294) loss_oracle 1.0155 (1.0192) kd_loss 1.0740 (1.0317) acc 62.5000 (70.1736) lr 1.6845e-03 eta 0:17:13
epoch [15/50] batch [200/428] time 0.066 (0.068) data 0.000 (0.003) loss 1.5587 (1.9736) teacher_loss 0.4455 (0.8417) loss_zs_kd 1.6953 (1.7217) loss_oracle 0.9571 (1.0185) kd_loss 1.0175 (1.0300) acc 93.7500 (70.3750) lr 1.6845e-03 eta 0:17:08
epoch [15/50] batch [220/428] time 0.070 (0.069) data 0.000 (0.003) loss 2.1568 (1.9711) teacher_loss 1.0293 (0.8397) loss_zs_kd 1.7317 (1.7354) loss_oracle 1.0655 (1.0199) kd_loss 1.0210 (1.0294) acc 68.7500 (70.5540) lr 1.6845e-03 eta 0:17:23
epoch [15/50] batch [240/428] time 0.067 (0.068) data 0.000 (0.002) loss 2.0933 (1.9684) teacher_loss 0.9216 (0.8374) loss_zs_kd 1.7827 (1.7449) loss_oracle 1.0538 (1.0204) kd_loss 1.0664 (1.0290) acc 68.7500 (70.4036) lr 1.6845e-03 eta 0:17:16
epoch [15/50] batch [260/428] time 0.065 (0.068) data 0.000 (0.002) loss 1.8583 (1.9673) teacher_loss 0.7050 (0.8349) loss_zs_kd 1.8751 (1.7403) loss_oracle 1.0583 (1.0206) kd_loss 1.0474 (1.0303) acc 68.7500 (70.4327) lr 1.6845e-03 eta 0:17:10
epoch [15/50] batch [280/428] time 0.062 (0.068) data 0.000 (0.002) loss 1.9010 (1.9620) teacher_loss 0.8198 (0.8294) loss_zs_kd 1.6396 (1.7376) loss_oracle 1.0264 (1.0203) kd_loss 0.9785 (1.0305) acc 75.0000 (70.5915) lr 1.6845e-03 eta 0:17:09
epoch [15/50] batch [300/428] time 0.065 (0.068) data 0.000 (0.002) loss 2.2287 (1.9596) teacher_loss 1.1101 (0.8269) loss_zs_kd 1.7130 (1.7464) loss_oracle 1.0215 (1.0209) kd_loss 1.0164 (1.0305) acc 59.3750 (70.6250) lr 1.6845e-03 eta 0:17:04
epoch [15/50] batch [320/428] time 0.064 (0.068) data 0.000 (0.002) loss 2.2902 (1.9592) teacher_loss 1.1701 (0.8272) loss_zs_kd 1.9656 (1.7512) loss_oracle 1.0564 (1.0214) kd_loss 1.0144 (1.0299) acc 62.5000 (70.4980) lr 1.6845e-03 eta 0:17:00
epoch [15/50] batch [340/428] time 0.066 (0.067) data 0.000 (0.002) loss 1.9253 (1.9622) teacher_loss 0.8144 (0.8310) loss_zs_kd 1.5348 (1.7567) loss_oracle 0.9833 (1.0214) kd_loss 1.0126 (1.0291) acc 71.8750 (70.4412) lr 1.6845e-03 eta 0:16:57
epoch [15/50] batch [360/428] time 0.066 (0.067) data 0.000 (0.002) loss 2.1240 (1.9587) teacher_loss 1.0880 (0.8287) loss_zs_kd 1.7632 (1.7621) loss_oracle 0.9949 (1.0201) kd_loss 0.9364 (1.0280) acc 65.6250 (70.5208) lr 1.6845e-03 eta 0:16:52
epoch [15/50] batch [380/428] time 0.063 (0.067) data 0.000 (0.002) loss 2.2991 (1.9591) teacher_loss 1.1500 (0.8298) loss_zs_kd 2.3791 (1.7828) loss_oracle 1.0255 (1.0202) kd_loss 1.0466 (1.0273) acc 56.2500 (70.4605) lr 1.6845e-03 eta 0:16:49
epoch [15/50] batch [400/428] time 0.066 (0.067) data 0.000 (0.002) loss 2.1203 (1.9607) teacher_loss 1.0344 (0.8319) loss_zs_kd 1.9108 (1.7927) loss_oracle 1.0333 (1.0201) kd_loss 0.9826 (1.0268) acc 65.6250 (70.3125) lr 1.6845e-03 eta 0:16:46
epoch [15/50] batch [420/428] time 0.080 (0.067) data 0.000 (0.001) loss 1.9894 (1.9629) teacher_loss 0.8751 (0.8339) loss_zs_kd 1.3005 (1.7847) loss_oracle 0.9962 (1.0198) kd_loss 1.0147 (1.0270) acc 65.6250 (70.2232) lr 1.6845e-03 eta 0:16:49
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,670
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 50.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,830
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 25.8%
******* Domain 1 best val acc:      62.8%, epoch: 13 *******
******* Domain 1 best val test acc: 38.8%, epoch: 13 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [16/50] batch [20/428] time 0.081 (0.118) data 0.000 (0.030) loss 2.3906 (1.9259) teacher_loss 1.1883 (0.7811) loss_zs_kd 2.2682 (1.7568) loss_oracle 0.9460 (1.0129) kd_loss 1.1078 (1.0435) acc 56.2500 (73.4375) lr 1.6374e-03 eta 0:29:23
epoch [16/50] batch [40/428] time 0.088 (0.103) data 0.000 (0.015) loss 1.8713 (1.9585) teacher_loss 0.7113 (0.8084) loss_zs_kd 1.7514 (1.8089) loss_oracle 1.0054 (1.0247) kd_loss 1.0595 (1.0476) acc 68.7500 (71.4062) lr 1.6374e-03 eta 0:25:36
epoch [16/50] batch [60/428] time 0.082 (0.097) data 0.000 (0.010) loss 2.2723 (1.9656) teacher_loss 1.1663 (0.8141) loss_zs_kd 1.6974 (1.7914) loss_oracle 1.0250 (1.0290) kd_loss 1.0034 (1.0486) acc 56.2500 (71.5104) lr 1.6374e-03 eta 0:24:14
epoch [16/50] batch [80/428] time 0.081 (0.094) data 0.000 (0.008) loss 1.6831 (1.9361) teacher_loss 0.4949 (0.7876) loss_zs_kd 1.7212 (1.8237) loss_oracle 1.0438 (1.0273) kd_loss 1.0839 (1.0459) acc 81.2500 (73.0078) lr 1.6374e-03 eta 0:23:16
epoch [16/50] batch [100/428] time 0.082 (0.092) data 0.000 (0.006) loss 2.1005 (1.9272) teacher_loss 0.9390 (0.7806) loss_zs_kd 2.3788 (1.8436) loss_oracle 0.9941 (1.0258) kd_loss 1.0621 (1.0440) acc 71.8750 (73.2812) lr 1.6374e-03 eta 0:22:53
epoch [16/50] batch [120/428] time 0.088 (0.091) data 0.000 (0.005) loss 1.7093 (1.9355) teacher_loss 0.5815 (0.7901) loss_zs_kd 1.7855 (1.8723) loss_oracle 1.0248 (1.0267) kd_loss 1.0253 (1.0428) acc 81.2500 (72.8125) lr 1.6374e-03 eta 0:22:31
epoch [16/50] batch [140/428] time 0.091 (0.090) data 0.000 (0.005) loss 1.7466 (1.9227) teacher_loss 0.6451 (0.7779) loss_zs_kd 1.8987 (1.8626) loss_oracle 1.0127 (1.0266) kd_loss 1.0003 (1.0421) acc 81.2500 (73.0134) lr 1.6374e-03 eta 0:22:15
epoch [16/50] batch [160/428] time 0.074 (0.089) data 0.000 (0.004) loss 2.1266 (1.9239) teacher_loss 0.9878 (0.7818) loss_zs_kd 1.9393 (1.8668) loss_oracle 0.9767 (1.0261) kd_loss 1.0411 (1.0394) acc 65.6250 (72.8711) lr 1.6374e-03 eta 0:22:00
epoch [16/50] batch [180/428] time 0.085 (0.088) data 0.000 (0.004) loss 1.5766 (1.9315) teacher_loss 0.4863 (0.7919) loss_zs_kd 1.7854 (1.8682) loss_oracle 1.0489 (1.0268) kd_loss 0.9854 (1.0369) acc 90.6250 (72.4132) lr 1.6374e-03 eta 0:21:40
epoch [16/50] batch [200/428] time 0.087 (0.088) data 0.000 (0.003) loss 1.8231 (1.9381) teacher_loss 0.6717 (0.8000) loss_zs_kd 1.9104 (1.8613) loss_oracle 1.0289 (1.0259) kd_loss 1.0485 (1.0355) acc 68.7500 (72.2188) lr 1.6374e-03 eta 0:21:34
epoch [16/50] batch [220/428] time 0.072 (0.087) data 0.000 (0.003) loss 1.7072 (1.9407) teacher_loss 0.6663 (0.8044) loss_zs_kd 1.7942 (1.8491) loss_oracle 1.0392 (1.0256) kd_loss 0.9370 (1.0337) acc 81.2500 (72.2159) lr 1.6374e-03 eta 0:21:26
epoch [16/50] batch [240/428] time 0.073 (0.087) data 0.000 (0.003) loss 1.8350 (1.9396) teacher_loss 0.7699 (0.8041) loss_zs_kd 1.6461 (1.8325) loss_oracle 1.0153 (1.0254) kd_loss 0.9636 (1.0330) acc 81.2500 (72.3047) lr 1.6374e-03 eta 0:21:17
epoch [16/50] batch [260/428] time 0.086 (0.086) data 0.000 (0.003) loss 2.2553 (1.9423) teacher_loss 1.0797 (0.8069) loss_zs_kd 1.5441 (1.8331) loss_oracle 1.0472 (1.0239) kd_loss 1.0709 (1.0330) acc 59.3750 (72.1875) lr 1.6374e-03 eta 0:21:11
epoch [16/50] batch [280/428] time 0.079 (0.086) data 0.000 (0.002) loss 2.1873 (1.9435) teacher_loss 1.0003 (0.8089) loss_zs_kd 1.6715 (1.8248) loss_oracle 0.9903 (1.0222) kd_loss 1.0880 (1.0323) acc 68.7500 (72.1540) lr 1.6374e-03 eta 0:21:04
epoch [16/50] batch [300/428] time 0.084 (0.086) data 0.000 (0.002) loss 2.0954 (1.9436) teacher_loss 0.9744 (0.8093) loss_zs_kd 1.7322 (1.8257) loss_oracle 1.0154 (1.0219) kd_loss 1.0194 (1.0321) acc 71.8750 (72.2083) lr 1.6374e-03 eta 0:21:01
epoch [16/50] batch [320/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.0735 (1.9415) teacher_loss 0.9429 (0.8076) loss_zs_kd 1.9617 (1.8297) loss_oracle 1.0112 (1.0213) kd_loss 1.0295 (1.0318) acc 59.3750 (72.3145) lr 1.6374e-03 eta 0:20:58
epoch [16/50] batch [340/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.9634 (1.9361) teacher_loss 0.8369 (0.8033) loss_zs_kd 1.8659 (1.8300) loss_oracle 0.9945 (1.0202) kd_loss 1.0270 (1.0308) acc 59.3750 (72.5184) lr 1.6374e-03 eta 0:20:55
epoch [16/50] batch [360/428] time 0.085 (0.086) data 0.000 (0.002) loss 2.0161 (1.9367) teacher_loss 0.8993 (0.8048) loss_zs_kd 1.7608 (1.8189) loss_oracle 1.0125 (1.0198) kd_loss 1.0155 (1.0299) acc 62.5000 (72.5434) lr 1.6374e-03 eta 0:20:51
epoch [16/50] batch [380/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.6978 (1.9330) teacher_loss 0.5344 (0.8008) loss_zs_kd 1.9707 (1.8136) loss_oracle 1.0531 (1.0196) kd_loss 1.0581 (1.0302) acc 78.1250 (72.7138) lr 1.6374e-03 eta 0:21:00
epoch [16/50] batch [400/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.8521 (1.9338) teacher_loss 0.6859 (0.8009) loss_zs_kd 1.9582 (1.8094) loss_oracle 1.0123 (1.0203) kd_loss 1.0650 (1.0308) acc 75.0000 (72.6328) lr 1.6374e-03 eta 0:20:56
epoch [16/50] batch [420/428] time 0.076 (0.086) data 0.000 (0.002) loss 1.6216 (1.9360) teacher_loss 0.5151 (0.8030) loss_zs_kd 1.9474 (1.8075) loss_oracle 1.0081 (1.0206) kd_loss 1.0057 (1.0310) acc 84.3750 (72.5595) lr 1.6374e-03 eta 0:20:51
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,709
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 51.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,066
* accuracy: 43.6%
* error: 56.4%
* macro_f1: 30.6%
******* Domain 1 best val acc:      63.1%, epoch: 16 *******
******* Domain 1 best val test acc: 43.6%, epoch: 16 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [17/50] batch [20/428] time 0.079 (0.105) data 0.000 (0.026) loss 1.8076 (1.8851) teacher_loss 0.6533 (0.7426) loss_zs_kd 1.6640 (1.6984) loss_oracle 1.0065 (1.0252) kd_loss 1.0537 (1.0399) acc 75.0000 (75.3125) lr 1.5878e-03 eta 0:25:30
epoch [17/50] batch [40/428] time 0.071 (0.092) data 0.000 (0.013) loss 2.0056 (1.8855) teacher_loss 0.8944 (0.7499) loss_zs_kd 1.7644 (1.7151) loss_oracle 1.0598 (1.0235) kd_loss 1.0052 (1.0332) acc 65.6250 (75.8594) lr 1.5878e-03 eta 0:22:12
epoch [17/50] batch [60/428] time 0.072 (0.087) data 0.000 (0.009) loss 1.6889 (1.8805) teacher_loss 0.5985 (0.7414) loss_zs_kd 1.5424 (1.7138) loss_oracle 1.0273 (1.0275) kd_loss 0.9877 (1.0364) acc 78.1250 (75.5729) lr 1.5878e-03 eta 0:21:06
epoch [17/50] batch [80/428] time 0.082 (0.085) data 0.000 (0.007) loss 1.8650 (1.8769) teacher_loss 0.7245 (0.7396) loss_zs_kd 1.7273 (1.7458) loss_oracle 1.0169 (1.0265) kd_loss 1.0388 (1.0347) acc 71.8750 (75.7812) lr 1.5878e-03 eta 0:20:33
epoch [17/50] batch [100/428] time 0.082 (0.084) data 0.000 (0.005) loss 1.5995 (1.8699) teacher_loss 0.5204 (0.7329) loss_zs_kd 1.8587 (1.7736) loss_oracle 1.0506 (1.0277) kd_loss 0.9741 (1.0343) acc 87.5000 (75.7812) lr 1.5878e-03 eta 0:20:20
epoch [17/50] batch [120/428] time 0.094 (0.086) data 0.000 (0.005) loss 2.1523 (1.8876) teacher_loss 1.0024 (0.7489) loss_zs_kd 1.8796 (1.7581) loss_oracle 1.0549 (1.0274) kd_loss 1.0444 (1.0360) acc 68.7500 (75.3906) lr 1.5878e-03 eta 0:20:43
epoch [17/50] batch [140/428] time 0.077 (0.086) data 0.000 (0.004) loss 1.5811 (1.8810) teacher_loss 0.4630 (0.7426) loss_zs_kd 1.9859 (1.7482) loss_oracle 1.0165 (1.0265) kd_loss 1.0164 (1.0357) acc 90.6250 (75.4911) lr 1.5878e-03 eta 0:20:39
epoch [17/50] batch [160/428] time 0.080 (0.085) data 0.000 (0.003) loss 1.9758 (1.8886) teacher_loss 0.8739 (0.7500) loss_zs_kd 1.8710 (1.7330) loss_oracle 1.0082 (1.0260) kd_loss 1.0011 (1.0360) acc 71.8750 (75.1562) lr 1.5878e-03 eta 0:20:27
epoch [17/50] batch [180/428] time 0.075 (0.085) data 0.000 (0.003) loss 1.9812 (1.8944) teacher_loss 0.7971 (0.7578) loss_zs_kd 1.5476 (1.7242) loss_oracle 1.0800 (1.0269) kd_loss 1.0761 (1.0339) acc 78.1250 (74.9479) lr 1.5878e-03 eta 0:20:23
epoch [17/50] batch [200/428] time 0.077 (0.085) data 0.000 (0.003) loss 1.5053 (1.8936) teacher_loss 0.3871 (0.7579) loss_zs_kd 1.6824 (1.7286) loss_oracle 1.0053 (1.0273) kd_loss 1.0177 (1.0330) acc 87.5000 (74.6094) lr 1.5878e-03 eta 0:20:13
epoch [17/50] batch [220/428] time 0.093 (0.084) data 0.000 (0.003) loss 2.0354 (1.8873) teacher_loss 0.9261 (0.7531) loss_zs_kd 2.2335 (1.7355) loss_oracle 1.0387 (1.0270) kd_loss 1.0054 (1.0316) acc 65.6250 (74.7017) lr 1.5878e-03 eta 0:20:09
epoch [17/50] batch [240/428] time 0.075 (0.084) data 0.000 (0.002) loss 1.9397 (1.8903) teacher_loss 0.7656 (0.7566) loss_zs_kd 1.8182 (1.7380) loss_oracle 1.0143 (1.0273) kd_loss 1.0727 (1.0309) acc 71.8750 (74.5182) lr 1.5878e-03 eta 0:20:04
epoch [17/50] batch [260/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.0739 (1.9005) teacher_loss 0.9291 (0.7672) loss_zs_kd 1.9314 (1.7292) loss_oracle 1.0512 (1.0270) kd_loss 1.0396 (1.0307) acc 65.6250 (74.1587) lr 1.5878e-03 eta 0:19:55
epoch [17/50] batch [280/428] time 0.076 (0.084) data 0.000 (0.002) loss 1.9269 (1.9004) teacher_loss 0.7736 (0.7671) loss_zs_kd 2.1699 (1.7381) loss_oracle 1.0138 (1.0270) kd_loss 1.0519 (1.0307) acc 71.8750 (74.0737) lr 1.5878e-03 eta 0:19:51
epoch [17/50] batch [300/428] time 0.083 (0.084) data 0.000 (0.002) loss 1.7991 (1.9017) teacher_loss 0.6795 (0.7691) loss_zs_kd 2.2267 (1.7448) loss_oracle 1.0129 (1.0268) kd_loss 1.0183 (1.0299) acc 78.1250 (74.0521) lr 1.5878e-03 eta 0:19:51
epoch [17/50] batch [320/428] time 0.089 (0.084) data 0.000 (0.002) loss 2.0289 (1.9011) teacher_loss 0.9369 (0.7689) loss_zs_kd 2.0375 (1.7453) loss_oracle 1.0209 (1.0270) kd_loss 0.9900 (1.0294) acc 71.8750 (74.0137) lr 1.5878e-03 eta 0:19:50
epoch [17/50] batch [340/428] time 0.089 (0.084) data 0.000 (0.002) loss 1.8849 (1.9047) teacher_loss 0.7706 (0.7725) loss_zs_kd 1.7123 (1.7448) loss_oracle 1.0219 (1.0266) kd_loss 1.0121 (1.0296) acc 71.8750 (73.8787) lr 1.5878e-03 eta 0:19:50
epoch [17/50] batch [360/428] time 0.070 (0.084) data 0.000 (0.002) loss 1.9083 (1.9083) teacher_loss 0.7450 (0.7756) loss_zs_kd 1.5823 (1.7434) loss_oracle 1.0784 (1.0272) kd_loss 1.0555 (1.0300) acc 75.0000 (73.8021) lr 1.5878e-03 eta 0:19:45
epoch [17/50] batch [380/428] time 0.078 (0.083) data 0.000 (0.002) loss 1.8113 (1.9105) teacher_loss 0.6622 (0.7772) loss_zs_kd 1.6865 (1.7436) loss_oracle 1.0315 (1.0271) kd_loss 1.0460 (1.0306) acc 78.1250 (73.7664) lr 1.5878e-03 eta 0:19:42
epoch [17/50] batch [400/428] time 0.081 (0.083) data 0.000 (0.002) loss 1.9893 (1.9138) teacher_loss 0.9686 (0.7808) loss_zs_kd 2.0084 (1.7375) loss_oracle 1.0288 (1.0278) kd_loss 0.9178 (1.0303) acc 68.7500 (73.6875) lr 1.5878e-03 eta 0:19:39
epoch [17/50] batch [420/428] time 0.077 (0.083) data 0.000 (0.001) loss 1.7492 (1.9160) teacher_loss 0.6343 (0.7834) loss_zs_kd 1.7668 (1.7370) loss_oracle 1.0186 (1.0277) kd_loss 1.0130 (1.0298) acc 87.5000 (73.5193) lr 1.5878e-03 eta 0:19:35
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,714
* accuracy: 63.2%
* error: 36.8%
* macro_f1: 51.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,766
* accuracy: 37.2%
* error: 62.8%
* macro_f1: 25.3%
******* Domain 1 best val acc:      63.2%, epoch: 17 *******
******* Domain 1 best val test acc: 37.2%, epoch: 17 *******
******* Domain 1 best test acc:     46.6%, epoch: 9 *******
epoch [18/50] batch [20/428] time 0.073 (0.108) data 0.000 (0.029) loss 1.9199 (1.8481) teacher_loss 0.7510 (0.7197) loss_zs_kd 1.5333 (1.8281) loss_oracle 1.0346 (1.0365) kd_loss 1.0655 (1.0247) acc 65.6250 (74.2188) lr 1.5358e-03 eta 0:25:19
epoch [18/50] batch [40/428] time 0.073 (0.089) data 0.000 (0.014) loss 1.7026 (1.8829) teacher_loss 0.5875 (0.7531) loss_zs_kd 1.6459 (1.8367) loss_oracle 1.0147 (1.0415) kd_loss 1.0136 (1.0256) acc 75.0000 (73.2031) lr 1.5358e-03 eta 0:20:57
epoch [18/50] batch [60/428] time 0.075 (0.086) data 0.000 (0.010) loss 2.1763 (1.8686) teacher_loss 1.0517 (0.7403) loss_zs_kd 2.1326 (1.8580) loss_oracle 0.9823 (1.0410) kd_loss 1.0264 (1.0242) acc 71.8750 (74.0104) lr 1.5358e-03 eta 0:20:14
epoch [18/50] batch [80/428] time 0.068 (0.084) data 0.000 (0.007) loss 2.3295 (1.9088) teacher_loss 1.1830 (0.7815) loss_zs_kd 1.5925 (1.8608) loss_oracle 1.0595 (1.0409) kd_loss 1.0406 (1.0232) acc 62.5000 (73.2812) lr 1.5358e-03 eta 0:19:43
epoch [18/50] batch [100/428] time 0.079 (0.084) data 0.001 (0.006) loss 1.5335 (1.9235) teacher_loss 0.4477 (0.7970) loss_zs_kd 1.7085 (1.8003) loss_oracle 1.0537 (1.0413) kd_loss 0.9805 (1.0223) acc 84.3750 (72.6250) lr 1.5358e-03 eta 0:19:32
epoch [18/50] batch [120/428] time 0.074 (0.084) data 0.000 (0.005) loss 1.8609 (1.9308) teacher_loss 0.7340 (0.8040) loss_zs_kd 1.5892 (1.7703) loss_oracle 1.0129 (1.0410) kd_loss 1.0256 (1.0227) acc 65.6250 (72.1094) lr 1.5358e-03 eta 0:19:30
epoch [18/50] batch [140/428] time 0.081 (0.084) data 0.000 (0.004) loss 1.8828 (1.9434) teacher_loss 0.7938 (0.8170) loss_zs_kd 1.4160 (1.7551) loss_oracle 1.0274 (1.0411) kd_loss 0.9863 (1.0223) acc 62.5000 (71.5402) lr 1.5358e-03 eta 0:19:34
epoch [18/50] batch [160/428] time 0.079 (0.084) data 0.000 (0.004) loss 1.9224 (1.9385) teacher_loss 0.7299 (0.8126) loss_zs_kd 1.6210 (1.7436) loss_oracle 1.0640 (1.0411) kd_loss 1.0861 (1.0218) acc 68.7500 (71.8359) lr 1.5358e-03 eta 0:19:28
epoch [18/50] batch [180/428] time 0.081 (0.084) data 0.000 (0.003) loss 2.1420 (1.9363) teacher_loss 1.0515 (0.8117) loss_zs_kd 1.6499 (1.7378) loss_oracle 0.9915 (1.0410) kd_loss 0.9914 (1.0205) acc 68.7500 (72.1701) lr 1.5358e-03 eta 0:19:24
epoch [18/50] batch [200/428] time 0.079 (0.083) data 0.000 (0.003) loss 1.8294 (1.9313) teacher_loss 0.6706 (0.8053) loss_zs_kd 1.5736 (1.7393) loss_oracle 1.0227 (1.0417) kd_loss 1.0565 (1.0218) acc 75.0000 (72.5781) lr 1.5358e-03 eta 0:19:16
epoch [18/50] batch [220/428] time 0.079 (0.083) data 0.000 (0.003) loss 2.1042 (1.9358) teacher_loss 0.9600 (0.8105) loss_zs_kd 1.7901 (1.7508) loss_oracle 1.0246 (1.0410) kd_loss 1.0418 (1.0212) acc 68.7500 (72.4432) lr 1.5358e-03 eta 0:19:09
epoch [18/50] batch [240/428] time 0.082 (0.082) data 0.000 (0.003) loss 1.7474 (1.9384) teacher_loss 0.6615 (0.8126) loss_zs_kd 1.4132 (1.7494) loss_oracle 1.0531 (1.0407) kd_loss 0.9806 (1.0218) acc 84.3750 (72.3047) lr 1.5358e-03 eta 0:19:01
epoch [18/50] batch [260/428] time 0.080 (0.083) data 0.000 (0.002) loss 2.1176 (1.9351) teacher_loss 0.9457 (0.8083) loss_zs_kd 2.1105 (1.7584) loss_oracle 1.0714 (1.0410) kd_loss 1.0648 (1.0227) acc 71.8750 (72.3678) lr 1.5358e-03 eta 0:19:07
epoch [18/50] batch [280/428] time 0.060 (0.082) data 0.000 (0.002) loss 1.6250 (1.9263) teacher_loss 0.4807 (0.7994) loss_zs_kd 2.0587 (1.7702) loss_oracle 1.0647 (1.0410) kd_loss 1.0378 (1.0227) acc 87.5000 (72.6786) lr 1.5358e-03 eta 0:18:57
epoch [18/50] batch [300/428] time 0.080 (0.082) data 0.000 (0.002) loss 1.7433 (1.9286) teacher_loss 0.5952 (0.8007) loss_zs_kd 2.2069 (1.7808) loss_oracle 1.0536 (1.0412) kd_loss 1.0428 (1.0238) acc 75.0000 (72.5208) lr 1.5358e-03 eta 0:18:51
epoch [18/50] batch [320/428] time 0.083 (0.082) data 0.000 (0.002) loss 1.8383 (1.9267) teacher_loss 0.6912 (0.7983) loss_zs_kd 1.9427 (1.8006) loss_oracle 1.0377 (1.0408) kd_loss 1.0433 (1.0244) acc 71.8750 (72.5879) lr 1.5358e-03 eta 0:18:46
epoch [18/50] batch [340/428] time 0.083 (0.081) data 0.000 (0.002) loss 1.8681 (1.9251) teacher_loss 0.7317 (0.7962) loss_zs_kd 1.6626 (1.8074) loss_oracle 1.0378 (1.0404) kd_loss 1.0327 (1.0249) acc 78.1250 (72.6195) lr 1.5358e-03 eta 0:18:41
epoch [18/50] batch [360/428] time 0.076 (0.081) data 0.000 (0.002) loss 2.0334 (1.9257) teacher_loss 0.8899 (0.7970) loss_zs_kd 1.4927 (1.8089) loss_oracle 1.0984 (1.0402) kd_loss 1.0336 (1.0247) acc 65.6250 (72.5694) lr 1.5358e-03 eta 0:18:39
epoch [18/50] batch [380/428] time 0.082 (0.081) data 0.000 (0.002) loss 2.3702 (1.9282) teacher_loss 1.1617 (0.7984) loss_zs_kd 1.8856 (1.8133) loss_oracle 1.0850 (1.0405) kd_loss 1.1001 (1.0258) acc 62.5000 (72.5905) lr 1.5358e-03 eta 0:18:38
epoch [18/50] batch [400/428] time 0.083 (0.082) data 0.000 (0.002) loss 2.0131 (1.9382) teacher_loss 0.7648 (0.8061) loss_zs_kd 1.4682 (1.8077) loss_oracle 1.0240 (1.0404) kd_loss 1.1459 (1.0281) acc 78.1250 (72.3125) lr 1.5358e-03 eta 0:18:39
epoch [18/50] batch [420/428] time 0.075 (0.082) data 0.000 (0.002) loss 2.2655 (1.9545) teacher_loss 1.0555 (0.8177) loss_zs_kd 1.4138 (1.7963) loss_oracle 1.0502 (1.0401) kd_loss 1.1050 (1.0328) acc 65.6250 (71.9196) lr 1.5358e-03 eta 0:18:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,541
* accuracy: 60.3%
* error: 39.7%
* macro_f1: 49.2%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,410
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 32.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 1 best val acc:      63.2%, epoch: 17 *******
******* Domain 1 best val test acc: 37.2%, epoch: 17 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [19/50] batch [20/428] time 0.082 (0.100) data 0.000 (0.025) loss 1.8957 (2.1809) teacher_loss 0.6814 (0.9557) loss_zs_kd 1.6489 (1.4473) loss_oracle 1.0195 (1.0448) kd_loss 1.1123 (1.1207) acc 81.2500 (67.5000) lr 1.4818e-03 eta 0:22:41
epoch [19/50] batch [40/428] time 0.092 (0.091) data 0.000 (0.013) loss 2.1270 (2.2174) teacher_loss 0.9027 (1.0003) loss_zs_kd 1.1181 (1.4898) loss_oracle 1.0819 (1.0528) kd_loss 1.1161 (1.1118) acc 68.7500 (66.2500) lr 1.4818e-03 eta 0:20:42
epoch [19/50] batch [60/428] time 0.078 (0.088) data 0.001 (0.009) loss 2.0438 (2.2108) teacher_loss 0.8209 (1.0003) loss_zs_kd 1.4663 (1.4841) loss_oracle 1.1036 (1.0547) kd_loss 1.1125 (1.1050) acc 65.6250 (65.8854) lr 1.4818e-03 eta 0:19:58
epoch [19/50] batch [80/428] time 0.083 (0.086) data 0.000 (0.007) loss 2.0477 (2.1717) teacher_loss 0.8928 (0.9690) loss_zs_kd 1.5367 (1.5112) loss_oracle 1.0848 (1.0551) kd_loss 1.0465 (1.0972) acc 68.7500 (67.1484) lr 1.4818e-03 eta 0:19:34
epoch [19/50] batch [100/428] time 0.075 (0.085) data 0.000 (0.005) loss 2.1659 (2.1503) teacher_loss 1.0200 (0.9563) loss_zs_kd 1.7242 (1.5740) loss_oracle 1.0490 (1.0520) kd_loss 1.0410 (1.0888) acc 59.3750 (67.5312) lr 1.4818e-03 eta 0:19:22
epoch [19/50] batch [120/428] time 0.077 (0.085) data 0.000 (0.005) loss 1.9334 (2.1194) teacher_loss 0.7647 (0.9343) loss_zs_kd 2.0278 (1.6122) loss_oracle 1.0643 (1.0514) kd_loss 1.0623 (1.0800) acc 75.0000 (68.1771) lr 1.4818e-03 eta 0:19:15
epoch [19/50] batch [140/428] time 0.082 (0.085) data 0.000 (0.004) loss 1.7567 (2.0963) teacher_loss 0.5855 (0.9173) loss_zs_kd 1.7672 (1.6571) loss_oracle 1.0160 (1.0500) kd_loss 1.0696 (1.0740) acc 87.5000 (68.7054) lr 1.4818e-03 eta 0:19:06
epoch [19/50] batch [160/428] time 0.080 (0.084) data 0.000 (0.003) loss 2.2729 (2.0697) teacher_loss 1.1171 (0.8949) loss_zs_kd 1.9231 (1.6852) loss_oracle 1.0546 (1.0493) kd_loss 1.0503 (1.0698) acc 62.5000 (69.4922) lr 1.4818e-03 eta 0:18:59
epoch [19/50] batch [180/428] time 0.077 (0.084) data 0.000 (0.003) loss 1.9039 (2.0476) teacher_loss 0.8076 (0.8774) loss_zs_kd 1.9546 (1.7221) loss_oracle 1.0401 (1.0497) kd_loss 0.9923 (1.0652) acc 75.0000 (70.0694) lr 1.4818e-03 eta 0:18:51
epoch [19/50] batch [200/428] time 0.080 (0.084) data 0.000 (0.003) loss 1.7567 (2.0373) teacher_loss 0.5808 (0.8700) loss_zs_kd 2.2694 (1.7533) loss_oracle 1.0918 (1.0497) kd_loss 1.0667 (1.0623) acc 78.1250 (70.2500) lr 1.4818e-03 eta 0:18:49
epoch [19/50] batch [220/428] time 0.081 (0.083) data 0.000 (0.003) loss 1.8809 (2.0341) teacher_loss 0.7996 (0.8695) loss_zs_kd 1.9672 (1.7730) loss_oracle 1.0506 (1.0499) kd_loss 0.9762 (1.0596) acc 71.8750 (70.2557) lr 1.4818e-03 eta 0:18:45
epoch [19/50] batch [240/428] time 0.082 (0.083) data 0.000 (0.002) loss 2.0636 (2.0298) teacher_loss 0.9149 (0.8688) loss_zs_kd 1.5313 (1.7762) loss_oracle 1.0410 (1.0500) kd_loss 1.0446 (1.0560) acc 59.3750 (70.0521) lr 1.4818e-03 eta 0:18:38
epoch [19/50] batch [260/428] time 0.081 (0.083) data 0.000 (0.002) loss 2.0107 (2.0273) teacher_loss 0.8856 (0.8676) loss_zs_kd 2.0157 (1.7767) loss_oracle 1.0476 (1.0507) kd_loss 1.0204 (1.0546) acc 62.5000 (69.8798) lr 1.4818e-03 eta 0:18:36
epoch [19/50] batch [280/428] time 0.086 (0.083) data 0.000 (0.002) loss 2.0340 (2.0216) teacher_loss 0.9499 (0.8642) loss_zs_kd 1.8366 (1.7794) loss_oracle 1.0264 (1.0500) kd_loss 0.9815 (1.0523) acc 75.0000 (70.0446) lr 1.4818e-03 eta 0:18:37
epoch [19/50] batch [300/428] time 0.083 (0.083) data 0.000 (0.002) loss 1.6556 (2.0181) teacher_loss 0.5474 (0.8631) loss_zs_kd 1.6114 (1.7832) loss_oracle 1.0456 (1.0493) kd_loss 1.0037 (1.0501) acc 81.2500 (70.0625) lr 1.4818e-03 eta 0:18:36
epoch [19/50] batch [320/428] time 0.085 (0.084) data 0.000 (0.002) loss 1.7877 (2.0134) teacher_loss 0.6612 (0.8599) loss_zs_kd 2.2548 (1.7900) loss_oracle 1.0328 (1.0491) kd_loss 1.0232 (1.0486) acc 78.1250 (70.1758) lr 1.4818e-03 eta 0:18:37
epoch [19/50] batch [340/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.1281 (2.0077) teacher_loss 0.9486 (0.8552) loss_zs_kd 2.1205 (1.8028) loss_oracle 1.0511 (1.0487) kd_loss 1.0744 (1.0477) acc 68.7500 (70.1746) lr 1.4818e-03 eta 0:18:37
epoch [19/50] batch [360/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.8611 (2.0058) teacher_loss 0.6968 (0.8547) loss_zs_kd 1.7493 (1.8130) loss_oracle 1.0459 (1.0480) kd_loss 1.0597 (1.0463) acc 71.8750 (70.2604) lr 1.4818e-03 eta 0:18:37
epoch [19/50] batch [380/428] time 0.096 (0.084) data 0.000 (0.002) loss 2.1024 (2.0019) teacher_loss 0.9690 (0.8518) loss_zs_kd 1.8678 (1.8137) loss_oracle 1.0646 (1.0469) kd_loss 1.0270 (1.0455) acc 65.6250 (70.2796) lr 1.4818e-03 eta 0:18:34
epoch [19/50] batch [400/428] time 0.086 (0.084) data 0.000 (0.002) loss 2.0212 (1.9995) teacher_loss 0.8910 (0.8500) loss_zs_kd 2.0160 (1.8105) loss_oracle 1.0592 (1.0466) kd_loss 1.0243 (1.0448) acc 65.6250 (70.2422) lr 1.4818e-03 eta 0:18:41
epoch [19/50] batch [420/428] time 0.076 (0.084) data 0.000 (0.001) loss 1.9381 (1.9983) teacher_loss 0.7811 (0.8501) loss_zs_kd 1.7579 (1.8110) loss_oracle 1.0826 (1.0457) kd_loss 1.0487 (1.0436) acc 65.6250 (70.1339) lr 1.4818e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,636
* accuracy: 61.9%
* error: 38.1%
* macro_f1: 47.7%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,984
* accuracy: 41.8%
* error: 58.2%
* macro_f1: 30.3%
******* Domain 1 best val acc:      63.2%, epoch: 17 *******
******* Domain 1 best val test acc: 37.2%, epoch: 17 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [20/50] batch [20/428] time 0.080 (0.123) data 0.000 (0.032) loss 1.8748 (1.8949) teacher_loss 0.7008 (0.7661) loss_zs_kd 1.4602 (1.6868) loss_oracle 1.0357 (1.0411) kd_loss 1.0704 (1.0247) acc 78.1250 (72.8125) lr 1.4258e-03 eta 0:27:06
epoch [20/50] batch [40/428] time 0.082 (0.102) data 0.000 (0.016) loss 2.0756 (1.8823) teacher_loss 0.9059 (0.7474) loss_zs_kd 1.9392 (1.6872) loss_oracle 1.0099 (1.0334) kd_loss 1.0686 (1.0316) acc 50.0000 (71.8750) lr 1.4258e-03 eta 0:22:29
epoch [20/50] batch [60/428] time 0.078 (0.096) data 0.000 (0.011) loss 1.7949 (1.8978) teacher_loss 0.6466 (0.7609) loss_zs_kd 1.6867 (1.7457) loss_oracle 1.0247 (1.0333) kd_loss 1.0459 (1.0335) acc 78.1250 (72.6562) lr 1.4258e-03 eta 0:21:01
epoch [20/50] batch [80/428] time 0.084 (0.093) data 0.000 (0.008) loss 2.3830 (1.9644) teacher_loss 1.2531 (0.8229) loss_zs_kd 1.7115 (1.7160) loss_oracle 1.0593 (1.0328) kd_loss 1.0240 (1.0382) acc 53.1250 (70.5078) lr 1.4258e-03 eta 0:20:20
epoch [20/50] batch [100/428] time 0.092 (0.091) data 0.000 (0.007) loss 2.2351 (2.0178) teacher_loss 1.1015 (0.8723) loss_zs_kd 1.7037 (1.6931) loss_oracle 1.0459 (1.0331) kd_loss 1.0290 (1.0422) acc 62.5000 (69.0625) lr 1.4258e-03 eta 0:19:52
epoch [20/50] batch [120/428] time 0.083 (0.091) data 0.000 (0.006) loss 1.8637 (2.0435) teacher_loss 0.6973 (0.8943) loss_zs_kd 1.4980 (1.6812) loss_oracle 1.0640 (1.0318) kd_loss 1.0599 (1.0460) acc 75.0000 (68.4635) lr 1.4258e-03 eta 0:19:56
epoch [20/50] batch [140/428] time 0.084 (0.090) data 0.000 (0.005) loss 2.0869 (2.0594) teacher_loss 1.0022 (0.9112) loss_zs_kd 1.9465 (1.6640) loss_oracle 1.0256 (1.0306) kd_loss 0.9821 (1.0451) acc 71.8750 (67.8571) lr 1.4258e-03 eta 0:19:38
epoch [20/50] batch [160/428] time 0.077 (0.089) data 0.000 (0.004) loss 1.9113 (2.0560) teacher_loss 0.8221 (0.9108) loss_zs_kd 1.7765 (1.6530) loss_oracle 1.0485 (1.0311) kd_loss 0.9844 (1.0420) acc 75.0000 (67.8711) lr 1.4258e-03 eta 0:19:28
epoch [20/50] batch [180/428] time 0.084 (0.089) data 0.000 (0.004) loss 2.1911 (2.0562) teacher_loss 1.0528 (0.9148) loss_zs_kd 1.6350 (1.6388) loss_oracle 0.9766 (1.0305) kd_loss 1.0406 (1.0384) acc 68.7500 (67.5694) lr 1.4258e-03 eta 0:19:19
epoch [20/50] batch [200/428] time 0.087 (0.088) data 0.001 (0.004) loss 1.8512 (2.0468) teacher_loss 0.7206 (0.9073) loss_zs_kd 1.4600 (1.6432) loss_oracle 1.0540 (1.0307) kd_loss 1.0251 (1.0365) acc 75.0000 (67.6719) lr 1.4258e-03 eta 0:19:12
epoch [20/50] batch [220/428] time 0.080 (0.088) data 0.000 (0.003) loss 1.8371 (2.0284) teacher_loss 0.7217 (0.8883) loss_zs_kd 1.9818 (1.6679) loss_oracle 1.0406 (1.0314) kd_loss 1.0114 (1.0369) acc 68.7500 (68.3949) lr 1.4258e-03 eta 0:19:07
epoch [20/50] batch [240/428] time 0.084 (0.088) data 0.000 (0.003) loss 2.2298 (2.0233) teacher_loss 1.0690 (0.8829) loss_zs_kd 1.7552 (1.6882) loss_oracle 1.0339 (1.0331) kd_loss 1.0575 (1.0370) acc 50.0000 (68.6458) lr 1.4258e-03 eta 0:19:02
epoch [20/50] batch [260/428] time 0.080 (0.087) data 0.000 (0.003) loss 2.1079 (2.0175) teacher_loss 1.0484 (0.8789) loss_zs_kd 1.7128 (1.6978) loss_oracle 1.0223 (1.0344) kd_loss 0.9573 (1.0352) acc 62.5000 (68.8462) lr 1.4258e-03 eta 0:18:54
epoch [20/50] batch [280/428] time 0.074 (0.087) data 0.001 (0.003) loss 2.0307 (2.0112) teacher_loss 0.9175 (0.8737) loss_zs_kd 1.6097 (1.7073) loss_oracle 1.0340 (1.0350) kd_loss 1.0098 (1.0340) acc 62.5000 (68.9286) lr 1.4258e-03 eta 0:18:48
epoch [20/50] batch [300/428] time 0.089 (0.086) data 0.001 (0.002) loss 2.0848 (2.0100) teacher_loss 0.9993 (0.8733) loss_zs_kd 2.1200 (1.7188) loss_oracle 0.9987 (1.0352) kd_loss 0.9856 (1.0332) acc 62.5000 (69.0417) lr 1.4258e-03 eta 0:18:41
epoch [20/50] batch [320/428] time 0.078 (0.086) data 0.000 (0.002) loss 1.8355 (2.0097) teacher_loss 0.7913 (0.8753) loss_zs_kd 1.5857 (1.7167) loss_oracle 1.0343 (1.0355) kd_loss 0.9407 (1.0308) acc 78.1250 (68.9941) lr 1.4258e-03 eta 0:18:36
epoch [20/50] batch [340/428] time 0.089 (0.086) data 0.000 (0.002) loss 2.0289 (2.0105) teacher_loss 0.9157 (0.8772) loss_zs_kd 1.7178 (1.7127) loss_oracle 1.0288 (1.0350) kd_loss 1.0102 (1.0298) acc 78.1250 (68.9798) lr 1.4258e-03 eta 0:18:31
epoch [20/50] batch [360/428] time 0.117 (0.086) data 0.000 (0.002) loss 2.1194 (2.0111) teacher_loss 1.0597 (0.8796) loss_zs_kd 1.6498 (1.7114) loss_oracle 1.0316 (1.0353) kd_loss 0.9565 (1.0280) acc 56.2500 (68.8889) lr 1.4258e-03 eta 0:18:29
epoch [20/50] batch [380/428] time 0.093 (0.086) data 0.000 (0.002) loss 2.0045 (2.0148) teacher_loss 0.9079 (0.8841) loss_zs_kd 1.6727 (1.7217) loss_oracle 1.0593 (1.0362) kd_loss 0.9907 (1.0271) acc 65.6250 (68.5691) lr 1.4258e-03 eta 0:18:26
epoch [20/50] batch [400/428] time 0.076 (0.086) data 0.000 (0.002) loss 2.0705 (2.0196) teacher_loss 1.0451 (0.8898) loss_zs_kd 1.6294 (1.7230) loss_oracle 1.0215 (1.0362) kd_loss 0.9233 (1.0262) acc 59.3750 (68.4141) lr 1.4258e-03 eta 0:18:23
epoch [20/50] batch [420/428] time 0.076 (0.086) data 0.000 (0.002) loss 1.9827 (2.0194) teacher_loss 0.8316 (0.8898) loss_zs_kd 1.6304 (1.7225) loss_oracle 1.0460 (1.0364) kd_loss 1.0465 (1.0259) acc 71.8750 (68.4970) lr 1.4258e-03 eta 0:18:19
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,746
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 50.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,829
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 28.1%
******* Domain 1 best val acc:      63.8%, epoch: 20 *******
******* Domain 1 best val test acc: 38.6%, epoch: 20 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [21/50] batch [20/428] time 0.078 (0.115) data 0.000 (0.025) loss 2.0220 (2.0869) teacher_loss 0.9435 (0.9584) loss_zs_kd 1.8512 (1.7418) loss_oracle 1.0549 (1.0349) kd_loss 0.9730 (1.0249) acc 65.6250 (67.5000) lr 1.3681e-03 eta 0:24:34
epoch [21/50] batch [40/428] time 0.083 (0.097) data 0.000 (0.013) loss 1.6367 (2.0161) teacher_loss 0.5553 (0.8872) loss_zs_kd 2.1150 (1.7599) loss_oracle 1.0406 (1.0418) kd_loss 0.9773 (1.0248) acc 84.3750 (70.1562) lr 1.3681e-03 eta 0:20:37
epoch [21/50] batch [60/428] time 0.083 (0.092) data 0.000 (0.009) loss 2.0622 (1.9914) teacher_loss 0.9099 (0.8620) loss_zs_kd 1.8097 (1.7638) loss_oracle 1.0659 (1.0422) kd_loss 1.0457 (1.0252) acc 65.6250 (70.8854) lr 1.3681e-03 eta 0:19:36
epoch [21/50] batch [80/428] time 0.087 (0.090) data 0.000 (0.007) loss 1.7398 (1.9760) teacher_loss 0.6025 (0.8450) loss_zs_kd 1.7903 (1.8240) loss_oracle 1.0765 (1.0441) kd_loss 1.0297 (1.0266) acc 75.0000 (71.6016) lr 1.3681e-03 eta 0:19:07
epoch [21/50] batch [100/428] time 0.076 (0.090) data 0.000 (0.005) loss 1.9826 (1.9660) teacher_loss 0.8608 (0.8352) loss_zs_kd 1.7462 (1.8153) loss_oracle 1.0149 (1.0427) kd_loss 1.0203 (1.0264) acc 71.8750 (72.1250) lr 1.3681e-03 eta 0:19:03
epoch [21/50] batch [120/428] time 0.080 (0.088) data 0.000 (0.004) loss 1.8975 (1.9629) teacher_loss 0.7859 (0.8315) loss_zs_kd 2.0313 (1.7963) loss_oracle 1.0754 (1.0428) kd_loss 1.0040 (1.0271) acc 62.5000 (72.1094) lr 1.3681e-03 eta 0:18:44
epoch [21/50] batch [140/428] time 0.076 (0.088) data 0.000 (0.004) loss 1.7237 (1.9553) teacher_loss 0.5709 (0.8239) loss_zs_kd 1.4690 (1.7795) loss_oracle 1.0494 (1.0415) kd_loss 1.0478 (1.0273) acc 84.3750 (72.5223) lr 1.3681e-03 eta 0:18:34
epoch [21/50] batch [160/428] time 0.078 (0.087) data 0.000 (0.003) loss 1.5265 (1.9499) teacher_loss 0.3987 (0.8189) loss_zs_kd 1.8607 (1.7671) loss_oracle 1.0396 (1.0412) kd_loss 1.0238 (1.0269) acc 90.6250 (72.6367) lr 1.3681e-03 eta 0:18:17
epoch [21/50] batch [180/428] time 0.079 (0.086) data 0.000 (0.003) loss 1.6194 (1.9451) teacher_loss 0.5360 (0.8148) loss_zs_kd 2.1272 (1.7764) loss_oracle 0.9939 (1.0397) kd_loss 0.9840 (1.0263) acc 84.3750 (72.6562) lr 1.3681e-03 eta 0:18:05
epoch [21/50] batch [200/428] time 0.088 (0.086) data 0.000 (0.003) loss 1.6870 (1.9346) teacher_loss 0.5050 (0.8032) loss_zs_kd 1.6846 (1.7710) loss_oracle 1.0977 (1.0406) kd_loss 1.0722 (1.0273) acc 78.1250 (72.8594) lr 1.3681e-03 eta 0:18:00
epoch [21/50] batch [220/428] time 0.080 (0.085) data 0.000 (0.003) loss 1.7920 (1.9287) teacher_loss 0.6744 (0.7974) loss_zs_kd 1.2221 (1.7578) loss_oracle 1.0118 (1.0412) kd_loss 1.0163 (1.0272) acc 75.0000 (73.0540) lr 1.3681e-03 eta 0:17:55
epoch [21/50] batch [240/428] time 0.135 (0.085) data 0.000 (0.002) loss 1.8004 (1.9285) teacher_loss 0.5977 (0.7962) loss_zs_kd 1.7805 (1.7587) loss_oracle 1.0851 (1.0420) kd_loss 1.0942 (1.0281) acc 81.2500 (73.0469) lr 1.3681e-03 eta 0:17:49
epoch [21/50] batch [260/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.6068 (1.9250) teacher_loss 0.4233 (0.7909) loss_zs_kd 1.6758 (1.7617) loss_oracle 1.0383 (1.0425) kd_loss 1.0796 (1.0299) acc 87.5000 (73.3413) lr 1.3681e-03 eta 0:17:52
epoch [21/50] batch [280/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.0639 (1.9279) teacher_loss 0.9022 (0.7942) loss_zs_kd 1.8200 (1.7597) loss_oracle 1.0468 (1.0429) kd_loss 1.0570 (1.0295) acc 65.6250 (73.1362) lr 1.3681e-03 eta 0:17:51
epoch [21/50] batch [300/428] time 0.077 (0.085) data 0.000 (0.002) loss 1.9724 (1.9270) teacher_loss 0.8269 (0.7934) loss_zs_kd 1.6719 (1.7584) loss_oracle 1.0736 (1.0436) kd_loss 1.0381 (1.0292) acc 65.6250 (73.1458) lr 1.3681e-03 eta 0:17:48
epoch [21/50] batch [320/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.8578 (1.9264) teacher_loss 0.7309 (0.7940) loss_zs_kd 1.8273 (1.7597) loss_oracle 1.0209 (1.0421) kd_loss 1.0247 (1.0282) acc 75.0000 (73.0762) lr 1.3681e-03 eta 0:17:41
epoch [21/50] batch [340/428] time 0.082 (0.084) data 0.000 (0.002) loss 2.1381 (1.9320) teacher_loss 0.9923 (0.8010) loss_zs_kd 1.7199 (1.7591) loss_oracle 0.9890 (1.0421) kd_loss 1.0469 (1.0268) acc 71.8750 (72.7390) lr 1.3681e-03 eta 0:17:36
epoch [21/50] batch [360/428] time 0.078 (0.084) data 0.001 (0.002) loss 2.2421 (1.9409) teacher_loss 1.1507 (0.8111) loss_zs_kd 1.2737 (1.7546) loss_oracle 1.0366 (1.0422) kd_loss 0.9877 (1.0256) acc 56.2500 (72.2569) lr 1.3681e-03 eta 0:17:30
epoch [21/50] batch [380/428] time 0.074 (0.084) data 0.000 (0.002) loss 2.1764 (1.9512) teacher_loss 1.0134 (0.8221) loss_zs_kd 1.8477 (1.7503) loss_oracle 1.0106 (1.0412) kd_loss 1.0620 (1.0249) acc 65.6250 (71.8586) lr 1.3681e-03 eta 0:17:25
epoch [21/50] batch [400/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.1185 (1.9567) teacher_loss 1.0063 (0.8291) loss_zs_kd 1.2363 (1.7449) loss_oracle 1.0261 (1.0405) kd_loss 1.0096 (1.0235) acc 68.7500 (71.5938) lr 1.3681e-03 eta 0:17:22
epoch [21/50] batch [420/428] time 0.078 (0.084) data 0.000 (0.001) loss 2.0805 (1.9589) teacher_loss 1.0165 (0.8327) loss_zs_kd 1.5318 (1.7305) loss_oracle 0.9924 (1.0390) kd_loss 0.9647 (1.0223) acc 62.5000 (71.3616) lr 1.3681e-03 eta 0:17:17
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,588
* accuracy: 61.1%
* error: 38.9%
* macro_f1: 48.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,006
* accuracy: 42.3%
* error: 57.7%
* macro_f1: 27.7%
******* Domain 1 best val acc:      63.8%, epoch: 20 *******
******* Domain 1 best val test acc: 38.6%, epoch: 20 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [22/50] batch [20/428] time 0.071 (0.111) data 0.000 (0.031) loss 1.7818 (2.0083) teacher_loss 0.6793 (0.9146) loss_zs_kd 1.4057 (1.5177) loss_oracle 1.0104 (1.0156) kd_loss 1.0014 (0.9921) acc 78.1250 (70.1562) lr 1.3090e-03 eta 0:22:56
epoch [22/50] batch [40/428] time 0.085 (0.098) data 0.000 (0.016) loss 1.9723 (2.0271) teacher_loss 0.8544 (0.9411) loss_zs_kd 1.7883 (1.5349) loss_oracle 0.9695 (1.0095) kd_loss 1.0209 (0.9850) acc 68.7500 (67.8906) lr 1.3090e-03 eta 0:20:11
epoch [22/50] batch [60/428] time 0.084 (0.093) data 0.000 (0.011) loss 1.9011 (2.0510) teacher_loss 0.8589 (0.9657) loss_zs_kd 1.8492 (1.5699) loss_oracle 0.9853 (1.0121) kd_loss 0.9437 (0.9840) acc 71.8750 (66.8229) lr 1.3090e-03 eta 0:19:14
epoch [22/50] batch [80/428] time 0.084 (0.091) data 0.000 (0.008) loss 1.9716 (2.0327) teacher_loss 0.8943 (0.9464) loss_zs_kd 1.8756 (1.5838) loss_oracle 1.0231 (1.0112) kd_loss 0.9750 (0.9852) acc 65.6250 (67.1875) lr 1.3090e-03 eta 0:18:36
epoch [22/50] batch [100/428] time 0.076 (0.088) data 0.000 (0.006) loss 1.7250 (2.0008) teacher_loss 0.5793 (0.9087) loss_zs_kd 2.0732 (1.6337) loss_oracle 1.0388 (1.0158) kd_loss 1.0418 (0.9905) acc 78.1250 (68.6562) lr 1.3090e-03 eta 0:18:08
epoch [22/50] batch [120/428] time 0.080 (0.087) data 0.000 (0.005) loss 1.8633 (2.0014) teacher_loss 0.6993 (0.8999) loss_zs_kd 1.6870 (1.6775) loss_oracle 1.0106 (1.0200) kd_loss 1.0629 (0.9995) acc 75.0000 (68.7500) lr 1.3090e-03 eta 0:17:52
epoch [22/50] batch [140/428] time 0.074 (0.086) data 0.000 (0.005) loss 1.8117 (1.9823) teacher_loss 0.6703 (0.8745) loss_zs_kd 1.8754 (1.7054) loss_oracle 1.0068 (1.0227) kd_loss 1.0407 (1.0055) acc 84.3750 (69.5982) lr 1.3090e-03 eta 0:17:33
epoch [22/50] batch [160/428] time 0.083 (0.086) data 0.000 (0.004) loss 1.6386 (1.9633) teacher_loss 0.5723 (0.8518) loss_zs_kd 2.0270 (1.7285) loss_oracle 1.0383 (1.0246) kd_loss 0.9624 (1.0091) acc 87.5000 (70.7227) lr 1.3090e-03 eta 0:17:29
epoch [22/50] batch [180/428] time 0.085 (0.086) data 0.000 (0.004) loss 2.0629 (1.9546) teacher_loss 1.0088 (0.8399) loss_zs_kd 2.4822 (1.7659) loss_oracle 1.0585 (1.0274) kd_loss 0.9482 (1.0120) acc 65.6250 (71.2326) lr 1.3090e-03 eta 0:17:25
epoch [22/50] batch [200/428] time 0.087 (0.085) data 0.000 (0.003) loss 1.9504 (1.9510) teacher_loss 0.7611 (0.8344) loss_zs_kd 2.2894 (1.7867) loss_oracle 1.0237 (1.0285) kd_loss 1.0869 (1.0138) acc 65.6250 (71.3750) lr 1.3090e-03 eta 0:17:22
epoch [22/50] batch [220/428] time 0.121 (0.085) data 0.000 (0.003) loss 2.2014 (1.9490) teacher_loss 1.0362 (0.8292) loss_zs_kd 1.6250 (1.8029) loss_oracle 1.0608 (1.0309) kd_loss 1.0591 (1.0167) acc 56.2500 (71.4631) lr 1.3090e-03 eta 0:17:17
epoch [22/50] batch [240/428] time 0.082 (0.085) data 0.000 (0.003) loss 2.0161 (1.9438) teacher_loss 0.8575 (0.8218) loss_zs_kd 1.7933 (1.8088) loss_oracle 1.1077 (1.0325) kd_loss 1.0478 (1.0187) acc 62.5000 (71.5625) lr 1.3090e-03 eta 0:17:18
epoch [22/50] batch [260/428] time 0.091 (0.085) data 0.000 (0.003) loss 1.9009 (1.9417) teacher_loss 0.7632 (0.8190) loss_zs_kd 1.6216 (1.8079) loss_oracle 1.0202 (1.0337) kd_loss 1.0357 (1.0193) acc 75.0000 (71.5264) lr 1.3090e-03 eta 0:17:15
epoch [22/50] batch [280/428] time 0.083 (0.085) data 0.000 (0.003) loss 2.0699 (1.9460) teacher_loss 0.9769 (0.8255) loss_zs_kd 2.0019 (1.8042) loss_oracle 1.0618 (1.0333) kd_loss 0.9868 (1.0172) acc 59.3750 (71.3616) lr 1.3090e-03 eta 0:17:13
epoch [22/50] batch [300/428] time 0.087 (0.085) data 0.000 (0.002) loss 1.8551 (1.9461) teacher_loss 0.8048 (0.8288) loss_zs_kd 2.0424 (1.7976) loss_oracle 0.9944 (1.0330) kd_loss 0.9508 (1.0139) acc 75.0000 (71.3229) lr 1.3090e-03 eta 0:17:11
epoch [22/50] batch [320/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.8812 (1.9437) teacher_loss 0.7681 (0.8277) loss_zs_kd 1.8398 (1.7988) loss_oracle 1.0790 (1.0341) kd_loss 1.0053 (1.0126) acc 65.6250 (71.4258) lr 1.3090e-03 eta 0:17:09
epoch [22/50] batch [340/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.9202 (1.9473) teacher_loss 0.8079 (0.8327) loss_zs_kd 1.8092 (1.7924) loss_oracle 1.0446 (1.0339) kd_loss 1.0079 (1.0112) acc 71.8750 (71.2132) lr 1.3090e-03 eta 0:17:05
epoch [22/50] batch [360/428] time 0.083 (0.085) data 0.000 (0.002) loss 1.7549 (1.9468) teacher_loss 0.7534 (0.8344) loss_zs_kd 1.9929 (1.7870) loss_oracle 1.0201 (1.0335) kd_loss 0.8995 (1.0091) acc 68.7500 (71.0938) lr 1.3090e-03 eta 0:17:03
epoch [22/50] batch [380/428] time 0.072 (0.085) data 0.000 (0.002) loss 1.8375 (1.9456) teacher_loss 0.7263 (0.8332) loss_zs_kd 1.6400 (1.7852) loss_oracle 1.0213 (1.0335) kd_loss 1.0091 (1.0091) acc 71.8750 (70.9704) lr 1.3090e-03 eta 0:17:08
epoch [22/50] batch [400/428] time 0.079 (0.085) data 0.000 (0.002) loss 1.9198 (1.9487) teacher_loss 0.7960 (0.8346) loss_zs_kd 1.9566 (1.7869) loss_oracle 0.9793 (1.0343) kd_loss 1.0259 (1.0107) acc 68.7500 (70.8750) lr 1.3090e-03 eta 0:17:04
epoch [22/50] batch [420/428] time 0.078 (0.085) data 0.001 (0.002) loss 1.8842 (1.9493) teacher_loss 0.7062 (0.8333) loss_zs_kd 2.2742 (1.7908) loss_oracle 1.0526 (1.0353) kd_loss 1.0727 (1.0124) acc 78.1250 (71.0268) lr 1.3090e-03 eta 0:17:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,656
* accuracy: 62.2%
* error: 37.8%
* macro_f1: 47.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,035
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 29.9%
******* Domain 1 best val acc:      63.8%, epoch: 20 *******
******* Domain 1 best val test acc: 38.6%, epoch: 20 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [23/50] batch [20/428] time 0.085 (0.116) data 0.000 (0.031) loss 1.7759 (1.9111) teacher_loss 0.6272 (0.7687) loss_zs_kd 1.9200 (1.8011) loss_oracle 1.0825 (1.0424) kd_loss 1.0404 (1.0382) acc 71.8750 (76.2500) lr 1.2487e-03 eta 0:23:13
epoch [23/50] batch [40/428] time 0.083 (0.101) data 0.000 (0.016) loss 1.8312 (1.8831) teacher_loss 0.6856 (0.7402) loss_zs_kd 1.9012 (1.8468) loss_oracle 1.0776 (1.0460) kd_loss 1.0379 (1.0383) acc 78.1250 (76.6406) lr 1.2487e-03 eta 0:20:02
epoch [23/50] batch [60/428] time 0.081 (0.096) data 0.000 (0.011) loss 1.7699 (1.8957) teacher_loss 0.6779 (0.7507) loss_zs_kd 1.9763 (1.9256) loss_oracle 1.0750 (1.0503) kd_loss 0.9845 (1.0399) acc 81.2500 (75.9375) lr 1.2487e-03 eta 0:18:59
epoch [23/50] batch [80/428] time 0.074 (0.093) data 0.000 (0.008) loss 2.1292 (1.9309) teacher_loss 0.9479 (0.7858) loss_zs_kd 1.8172 (1.9685) loss_oracle 1.0929 (1.0512) kd_loss 1.0721 (1.0400) acc 65.6250 (73.9062) lr 1.2487e-03 eta 0:18:23
epoch [23/50] batch [100/428] time 0.082 (0.090) data 0.000 (0.007) loss 1.9480 (1.9337) teacher_loss 0.8097 (0.7943) loss_zs_kd 1.9387 (1.9774) loss_oracle 1.0752 (1.0512) kd_loss 1.0308 (1.0343) acc 78.1250 (73.7188) lr 1.2487e-03 eta 0:17:49
epoch [23/50] batch [120/428] time 0.069 (0.090) data 0.000 (0.006) loss 2.0253 (1.9435) teacher_loss 0.8922 (0.8085) loss_zs_kd 1.6776 (1.9614) loss_oracle 1.0764 (1.0478) kd_loss 1.0255 (1.0302) acc 68.7500 (73.0990) lr 1.2487e-03 eta 0:17:51
epoch [23/50] batch [140/428] time 0.079 (0.089) data 0.000 (0.005) loss 2.3015 (1.9429) teacher_loss 1.2576 (0.8138) loss_zs_kd 1.8222 (1.9442) loss_oracle 1.0376 (1.0456) kd_loss 0.9401 (1.0245) acc 46.8750 (72.4554) lr 1.2487e-03 eta 0:17:29
epoch [23/50] batch [160/428] time 0.074 (0.087) data 0.000 (0.004) loss 1.8790 (1.9470) teacher_loss 0.8662 (0.8235) loss_zs_kd 1.5170 (1.9269) loss_oracle 1.0000 (1.0442) kd_loss 0.9128 (1.0191) acc 71.8750 (72.0508) lr 1.2487e-03 eta 0:17:09
epoch [23/50] batch [180/428] time 0.078 (0.086) data 0.000 (0.004) loss 1.8254 (1.9502) teacher_loss 0.7112 (0.8309) loss_zs_kd 1.9616 (1.9073) loss_oracle 1.0318 (1.0423) kd_loss 1.0111 (1.0150) acc 87.5000 (71.5278) lr 1.2487e-03 eta 0:16:54
epoch [23/50] batch [200/428] time 0.075 (0.085) data 0.000 (0.003) loss 1.8149 (1.9536) teacher_loss 0.7615 (0.8397) loss_zs_kd 1.6632 (1.8896) loss_oracle 1.0040 (1.0392) kd_loss 0.9531 (1.0100) acc 78.1250 (71.1250) lr 1.2487e-03 eta 0:16:44
epoch [23/50] batch [220/428] time 0.085 (0.085) data 0.000 (0.003) loss 2.0730 (1.9568) teacher_loss 1.0485 (0.8470) loss_zs_kd 1.6861 (1.8685) loss_oracle 1.0368 (1.0366) kd_loss 0.9209 (1.0061) acc 56.2500 (70.8097) lr 1.2487e-03 eta 0:16:36
epoch [23/50] batch [240/428] time 0.076 (0.084) data 0.000 (0.003) loss 2.1045 (1.9518) teacher_loss 0.9906 (0.8458) loss_zs_kd 1.7347 (1.8570) loss_oracle 1.0663 (1.0345) kd_loss 1.0073 (1.0025) acc 65.6250 (70.8854) lr 1.2487e-03 eta 0:16:31
epoch [23/50] batch [260/428] time 0.081 (0.084) data 0.000 (0.003) loss 1.9925 (1.9509) teacher_loss 0.8804 (0.8429) loss_zs_kd 2.0119 (1.8494) loss_oracle 1.0546 (1.0348) kd_loss 1.0066 (1.0045) acc 71.8750 (70.9014) lr 1.2487e-03 eta 0:16:26
epoch [23/50] batch [280/428] time 0.081 (0.084) data 0.000 (0.003) loss 1.5032 (1.9462) teacher_loss 0.4154 (0.8365) loss_zs_kd 1.6435 (1.8564) loss_oracle 1.0612 (1.0363) kd_loss 0.9816 (1.0060) acc 93.7500 (71.2946) lr 1.2487e-03 eta 0:16:20
epoch [23/50] batch [300/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.6397 (1.9409) teacher_loss 0.5048 (0.8291) loss_zs_kd 1.9540 (1.8556) loss_oracle 1.0307 (1.0378) kd_loss 1.0319 (1.0081) acc 81.2500 (71.5938) lr 1.2487e-03 eta 0:16:20
epoch [23/50] batch [320/428] time 0.080 (0.084) data 0.000 (0.002) loss 2.0105 (1.9427) teacher_loss 0.8465 (0.8278) loss_zs_kd 2.0060 (1.8610) loss_oracle 1.0420 (1.0395) kd_loss 1.0598 (1.0109) acc 75.0000 (71.6406) lr 1.2487e-03 eta 0:16:17
epoch [23/50] batch [340/428] time 0.072 (0.084) data 0.000 (0.002) loss 1.8206 (1.9381) teacher_loss 0.7139 (0.8217) loss_zs_kd 1.5225 (1.8560) loss_oracle 1.0420 (1.0407) kd_loss 1.0025 (1.0123) acc 84.3750 (71.9577) lr 1.2487e-03 eta 0:16:19
epoch [23/50] batch [360/428] time 0.091 (0.084) data 0.000 (0.002) loss 2.0637 (1.9345) teacher_loss 0.9793 (0.8187) loss_zs_kd 1.4890 (1.8510) loss_oracle 1.0681 (1.0408) kd_loss 0.9776 (1.0116) acc 65.6250 (72.1094) lr 1.2487e-03 eta 0:16:16
epoch [23/50] batch [380/428] time 0.080 (0.084) data 0.000 (0.002) loss 1.9646 (1.9309) teacher_loss 0.7611 (0.8140) loss_zs_kd 1.2977 (1.8392) loss_oracle 1.1006 (1.0414) kd_loss 1.0934 (1.0128) acc 78.1250 (72.2862) lr 1.2487e-03 eta 0:16:14
epoch [23/50] batch [400/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.6041 (1.9295) teacher_loss 0.4705 (0.8118) loss_zs_kd 1.7184 (1.8365) loss_oracle 1.0338 (1.0420) kd_loss 1.0302 (1.0135) acc 87.5000 (72.3906) lr 1.2487e-03 eta 0:16:11
epoch [23/50] batch [420/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.8040 (1.9295) teacher_loss 0.7148 (0.8101) loss_zs_kd 1.6962 (1.8332) loss_oracle 1.0693 (1.0434) kd_loss 0.9823 (1.0152) acc 71.8750 (72.3512) lr 1.2487e-03 eta 0:16:07
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,697
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 50.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,973
* accuracy: 41.6%
* error: 58.4%
* macro_f1: 28.4%
******* Domain 1 best val acc:      63.8%, epoch: 20 *******
******* Domain 1 best val test acc: 38.6%, epoch: 20 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [24/50] batch [20/428] time 0.082 (0.114) data 0.000 (0.027) loss 1.6209 (1.9167) teacher_loss 0.5138 (0.7829) loss_zs_kd 2.0650 (1.8247) loss_oracle 1.0734 (1.0546) kd_loss 0.9998 (1.0283) acc 87.5000 (74.2188) lr 1.1874e-03 eta 0:21:50
epoch [24/50] batch [40/428] time 0.082 (0.098) data 0.000 (0.014) loss 1.8924 (1.8831) teacher_loss 0.7729 (0.7492) loss_zs_kd 1.7832 (1.8144) loss_oracle 1.1145 (1.0566) kd_loss 1.0080 (1.0282) acc 68.7500 (75.2344) lr 1.1874e-03 eta 0:18:53
epoch [24/50] batch [60/428] time 0.094 (0.093) data 0.001 (0.009) loss 2.1291 (1.8871) teacher_loss 1.0582 (0.7632) loss_zs_kd 1.8263 (1.7964) loss_oracle 1.0503 (1.0560) kd_loss 0.9659 (1.0183) acc 56.2500 (74.3229) lr 1.1874e-03 eta 0:17:44
epoch [24/50] batch [80/428] time 0.099 (0.091) data 0.000 (0.007) loss 1.9338 (1.8951) teacher_loss 0.7913 (0.7780) loss_zs_kd 2.0852 (1.8046) loss_oracle 1.0954 (1.0536) kd_loss 1.0330 (1.0118) acc 68.7500 (73.4766) lr 1.1874e-03 eta 0:17:21
epoch [24/50] batch [100/428] time 0.091 (0.090) data 0.000 (0.006) loss 1.6991 (1.8906) teacher_loss 0.6099 (0.7782) loss_zs_kd 1.5516 (1.8032) loss_oracle 1.0404 (1.0532) kd_loss 0.9851 (1.0071) acc 84.3750 (73.0625) lr 1.1874e-03 eta 0:17:16
epoch [24/50] batch [120/428] time 0.080 (0.090) data 0.000 (0.005) loss 1.9854 (1.8988) teacher_loss 0.8647 (0.7869) loss_zs_kd 1.4846 (1.7919) loss_oracle 0.9918 (1.0511) kd_loss 1.0215 (1.0068) acc 71.8750 (72.6042) lr 1.1874e-03 eta 0:17:04
epoch [24/50] batch [140/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.1879 (1.9140) teacher_loss 1.0083 (0.8023) loss_zs_kd 1.8547 (1.7917) loss_oracle 1.0188 (1.0500) kd_loss 1.0778 (1.0066) acc 68.7500 (72.0536) lr 1.1874e-03 eta 0:16:46
epoch [24/50] batch [160/428] time 0.083 (0.088) data 0.000 (0.004) loss 1.5633 (1.9050) teacher_loss 0.4202 (0.7931) loss_zs_kd 1.7907 (1.7705) loss_oracle 1.0993 (1.0503) kd_loss 1.0332 (1.0069) acc 90.6250 (72.5977) lr 1.1874e-03 eta 0:16:45
epoch [24/50] batch [180/428] time 0.095 (0.088) data 0.000 (0.003) loss 1.7969 (1.8995) teacher_loss 0.6676 (0.7853) loss_zs_kd 2.0392 (1.7813) loss_oracle 1.0285 (1.0519) kd_loss 1.0264 (1.0091) acc 71.8750 (72.7604) lr 1.1874e-03 eta 0:16:39
epoch [24/50] batch [200/428] time 0.079 (0.088) data 0.000 (0.003) loss 1.7353 (1.8957) teacher_loss 0.5817 (0.7783) loss_zs_kd 2.1009 (1.7990) loss_oracle 1.0605 (1.0525) kd_loss 1.0476 (1.0122) acc 78.1250 (73.0156) lr 1.1874e-03 eta 0:16:37
epoch [24/50] batch [220/428] time 0.091 (0.088) data 0.000 (0.003) loss 2.1572 (1.9056) teacher_loss 0.9320 (0.7849) loss_zs_kd 1.5075 (1.8071) loss_oracle 1.0478 (1.0531) kd_loss 1.1205 (1.0154) acc 68.7500 (72.7557) lr 1.1874e-03 eta 0:16:34
epoch [24/50] batch [240/428] time 0.079 (0.087) data 0.000 (0.003) loss 2.1945 (1.9195) teacher_loss 1.0365 (0.7961) loss_zs_kd 1.6018 (1.8034) loss_oracle 1.0866 (1.0534) kd_loss 1.0493 (1.0180) acc 71.8750 (72.4219) lr 1.1874e-03 eta 0:16:29
epoch [24/50] batch [260/428] time 0.077 (0.088) data 0.000 (0.002) loss 1.9100 (1.9249) teacher_loss 0.7633 (0.7999) loss_zs_kd 1.7545 (1.8089) loss_oracle 1.0552 (1.0547) kd_loss 1.0412 (1.0196) acc 71.8750 (72.3678) lr 1.1874e-03 eta 0:16:31
epoch [24/50] batch [280/428] time 0.073 (0.087) data 0.000 (0.002) loss 1.8994 (1.9297) teacher_loss 0.7687 (0.8035) loss_zs_kd 1.7506 (1.8115) loss_oracle 1.0332 (1.0539) kd_loss 1.0273 (1.0208) acc 68.7500 (72.2210) lr 1.1874e-03 eta 0:16:23
epoch [24/50] batch [300/428] time 0.080 (0.087) data 0.000 (0.002) loss 1.6949 (1.9300) teacher_loss 0.5421 (0.8027) loss_zs_kd 1.6623 (1.8148) loss_oracle 1.0584 (1.0545) kd_loss 1.0470 (1.0219) acc 84.3750 (72.2396) lr 1.1874e-03 eta 0:16:18
epoch [24/50] batch [320/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.9160 (1.9311) teacher_loss 0.7483 (0.8019) loss_zs_kd 1.6188 (1.8196) loss_oracle 1.0862 (1.0552) kd_loss 1.0591 (1.0238) acc 84.3750 (72.2852) lr 1.1874e-03 eta 0:16:15
epoch [24/50] batch [340/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.6609 (1.9293) teacher_loss 0.5378 (0.7993) loss_zs_kd 1.5839 (1.8160) loss_oracle 1.0689 (1.0559) kd_loss 1.0161 (1.0243) acc 84.3750 (72.3989) lr 1.1874e-03 eta 0:16:13
epoch [24/50] batch [360/428] time 0.080 (0.087) data 0.001 (0.002) loss 1.7669 (1.9324) teacher_loss 0.5851 (0.8011) loss_zs_kd 1.4677 (1.8088) loss_oracle 1.0579 (1.0559) kd_loss 1.0761 (1.0257) acc 81.2500 (72.3438) lr 1.1874e-03 eta 0:16:13
epoch [24/50] batch [380/428] time 0.093 (0.086) data 0.000 (0.002) loss 1.6996 (1.9283) teacher_loss 0.5422 (0.7962) loss_zs_kd 1.8187 (1.8124) loss_oracle 1.0011 (1.0558) kd_loss 1.0573 (1.0266) acc 90.6250 (72.6151) lr 1.1874e-03 eta 0:16:05
epoch [24/50] batch [400/428] time 0.088 (0.086) data 0.000 (0.002) loss 1.9344 (1.9326) teacher_loss 0.7906 (0.8002) loss_zs_kd 1.9474 (1.8173) loss_oracle 1.0438 (1.0565) kd_loss 1.0394 (1.0268) acc 75.0000 (72.5703) lr 1.1874e-03 eta 0:16:02
epoch [24/50] batch [420/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.8755 (1.9344) teacher_loss 0.7531 (0.8018) loss_zs_kd 1.7855 (1.8233) loss_oracle 1.0614 (1.0563) kd_loss 1.0163 (1.0270) acc 75.0000 (72.4702) lr 1.1874e-03 eta 0:15:58
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,737
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,943
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 31.1%
******* Domain 1 best val acc:      63.8%, epoch: 20 *******
******* Domain 1 best val test acc: 38.6%, epoch: 20 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [25/50] batch [20/428] time 0.086 (0.108) data 0.000 (0.024) loss 2.1256 (2.0186) teacher_loss 0.9789 (0.9070) loss_zs_kd 2.3487 (1.8563) loss_oracle 1.0864 (1.0550) kd_loss 1.0380 (1.0061) acc 56.2500 (67.1875) lr 1.1253e-03 eta 0:20:02
epoch [25/50] batch [40/428] time 0.076 (0.094) data 0.000 (0.012) loss 1.9881 (1.9693) teacher_loss 0.9070 (0.8591) loss_zs_kd 1.9824 (1.9197) loss_oracle 1.0640 (1.0464) kd_loss 0.9748 (1.0056) acc 68.7500 (70.1562) lr 1.1253e-03 eta 0:17:16
epoch [25/50] batch [60/428] time 0.087 (0.090) data 0.001 (0.008) loss 2.0112 (1.9870) teacher_loss 0.8875 (0.8797) loss_zs_kd 1.4509 (1.8619) loss_oracle 0.9971 (1.0381) kd_loss 1.0240 (1.0034) acc 65.6250 (69.4792) lr 1.1253e-03 eta 0:16:35
epoch [25/50] batch [80/428] time 0.079 (0.089) data 0.000 (0.006) loss 1.8327 (1.9799) teacher_loss 0.7364 (0.8748) loss_zs_kd 1.8999 (1.8349) loss_oracle 1.0387 (1.0406) kd_loss 0.9925 (1.0010) acc 84.3750 (69.4531) lr 1.1253e-03 eta 0:16:21
epoch [25/50] batch [100/428] time 0.091 (0.088) data 0.000 (0.005) loss 2.0886 (1.9902) teacher_loss 1.0115 (0.8892) loss_zs_kd 1.9191 (1.8321) loss_oracle 1.0478 (1.0404) kd_loss 0.9723 (0.9969) acc 65.6250 (68.4375) lr 1.1253e-03 eta 0:16:11
epoch [25/50] batch [120/428] time 0.085 (0.088) data 0.000 (0.004) loss 2.3593 (1.9946) teacher_loss 1.2881 (0.8989) loss_zs_kd 1.6754 (1.8140) loss_oracle 1.0104 (1.0348) kd_loss 0.9701 (0.9923) acc 50.0000 (68.3594) lr 1.1253e-03 eta 0:16:05
epoch [25/50] batch [140/428] time 0.091 (0.087) data 0.000 (0.004) loss 2.4066 (1.9935) teacher_loss 1.3685 (0.9023) loss_zs_kd 1.7985 (1.7849) loss_oracle 1.0554 (1.0318) kd_loss 0.9326 (0.9880) acc 56.2500 (68.3259) lr 1.1253e-03 eta 0:15:56
epoch [25/50] batch [160/428] time 0.084 (0.087) data 0.000 (0.003) loss 1.9407 (1.9887) teacher_loss 0.8438 (0.8990) loss_zs_kd 1.5393 (1.7550) loss_oracle 1.0203 (1.0300) kd_loss 0.9949 (0.9866) acc 68.7500 (68.5742) lr 1.1253e-03 eta 0:15:49
epoch [25/50] batch [180/428] time 0.080 (0.086) data 0.000 (0.003) loss 1.9069 (1.9864) teacher_loss 0.8096 (0.8994) loss_zs_kd 1.9073 (1.7226) loss_oracle 1.0650 (1.0267) kd_loss 0.9908 (0.9843) acc 75.0000 (68.6458) lr 1.1253e-03 eta 0:15:40
epoch [25/50] batch [200/428] time 0.093 (0.086) data 0.001 (0.003) loss 2.1811 (1.9910) teacher_loss 1.1595 (0.9058) loss_zs_kd 1.9271 (1.7177) loss_oracle 1.0405 (1.0252) kd_loss 0.9175 (0.9827) acc 56.2500 (68.5312) lr 1.1253e-03 eta 0:15:41
epoch [25/50] batch [220/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.7915 (1.9891) teacher_loss 0.6388 (0.9028) loss_zs_kd 2.0359 (1.7285) loss_oracle 1.0593 (1.0273) kd_loss 1.0467 (0.9836) acc 81.2500 (68.5085) lr 1.1253e-03 eta 0:15:43
epoch [25/50] batch [240/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.7419 (1.9855) teacher_loss 0.6294 (0.8961) loss_zs_kd 1.8315 (1.7395) loss_oracle 1.0255 (1.0284) kd_loss 1.0100 (0.9866) acc 78.1250 (68.7891) lr 1.1253e-03 eta 0:15:41
epoch [25/50] batch [260/428] time 0.078 (0.086) data 0.000 (0.002) loss 1.7628 (1.9838) teacher_loss 0.6114 (0.8913) loss_zs_kd 1.8946 (1.7539) loss_oracle 1.0568 (1.0307) kd_loss 1.0457 (0.9894) acc 81.2500 (69.0385) lr 1.1253e-03 eta 0:15:37
epoch [25/50] batch [280/428] time 0.092 (0.086) data 0.000 (0.002) loss 2.2461 (1.9851) teacher_loss 1.1074 (0.8897) loss_zs_kd 1.6964 (1.7742) loss_oracle 1.0426 (1.0322) kd_loss 1.0345 (0.9922) acc 50.0000 (69.0179) lr 1.1253e-03 eta 0:15:33
epoch [25/50] batch [300/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.8194 (1.9836) teacher_loss 0.7016 (0.8860) loss_zs_kd 2.0056 (1.7917) loss_oracle 1.0533 (1.0334) kd_loss 1.0125 (0.9942) acc 71.8750 (69.0521) lr 1.1253e-03 eta 0:15:29
epoch [25/50] batch [320/428] time 0.087 (0.086) data 0.000 (0.002) loss 1.9262 (1.9881) teacher_loss 0.8105 (0.8877) loss_zs_kd 1.6489 (1.8058) loss_oracle 1.0653 (1.0348) kd_loss 1.0092 (0.9969) acc 75.0000 (69.0430) lr 1.1253e-03 eta 0:15:24
epoch [25/50] batch [340/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.8167 (1.9864) teacher_loss 0.7198 (0.8843) loss_zs_kd 1.9859 (1.8108) loss_oracle 1.0483 (1.0354) kd_loss 0.9920 (0.9986) acc 81.2500 (69.2004) lr 1.1253e-03 eta 0:15:21
epoch [25/50] batch [360/428] time 0.085 (0.085) data 0.000 (0.002) loss 2.0452 (1.9878) teacher_loss 0.9010 (0.8838) loss_zs_kd 1.3983 (1.8160) loss_oracle 1.0318 (1.0364) kd_loss 1.0410 (1.0004) acc 71.8750 (69.1580) lr 1.1253e-03 eta 0:15:17
epoch [25/50] batch [380/428] time 0.093 (0.085) data 0.000 (0.002) loss 2.1102 (1.9853) teacher_loss 1.0241 (0.8801) loss_zs_kd 1.8019 (1.8179) loss_oracle 0.9789 (1.0367) kd_loss 0.9882 (1.0015) acc 62.5000 (69.2681) lr 1.1253e-03 eta 0:15:14
epoch [25/50] batch [400/428] time 0.078 (0.085) data 0.000 (0.001) loss 1.9740 (1.9814) teacher_loss 0.7965 (0.8752) loss_zs_kd 1.9510 (1.8224) loss_oracle 1.0475 (1.0363) kd_loss 1.0728 (1.0026) acc 68.7500 (69.4844) lr 1.1253e-03 eta 0:15:12
epoch [25/50] batch [420/428] time 0.071 (0.085) data 0.000 (0.001) loss 2.2108 (1.9823) teacher_loss 0.9728 (0.8743) loss_zs_kd 1.5669 (1.8230) loss_oracle 1.0248 (1.0365) kd_loss 1.1355 (1.0043) acc 65.6250 (69.5759) lr 1.1253e-03 eta 0:15:07
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,777
* accuracy: 64.3%
* error: 35.7%
* macro_f1: 51.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,062
* accuracy: 43.5%
* error: 56.5%
* macro_f1: 30.2%
******* Domain 1 best val acc:      64.3%, epoch: 25 *******
******* Domain 1 best val test acc: 43.5%, epoch: 25 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [26/50] batch [20/428] time 0.077 (0.119) data 0.000 (0.031) loss 1.8469 (1.9467) teacher_loss 0.7000 (0.8006) loss_zs_kd 2.0616 (1.7766) loss_oracle 1.0688 (1.0426) kd_loss 1.0400 (1.0419) acc 71.8750 (72.0312) lr 1.0628e-03 eta 0:21:09
epoch [26/50] batch [40/428] time 0.095 (0.101) data 0.000 (0.015) loss 1.7525 (1.9543) teacher_loss 0.6337 (0.8218) loss_zs_kd 1.9060 (1.8234) loss_oracle 1.0390 (1.0307) kd_loss 1.0149 (1.0295) acc 68.7500 (70.1562) lr 1.0628e-03 eta 0:17:53
epoch [26/50] batch [60/428] time 0.085 (0.096) data 0.001 (0.010) loss 2.2658 (1.9536) teacher_loss 1.1196 (0.8194) loss_zs_kd 1.6279 (1.8343) loss_oracle 1.0682 (1.0315) kd_loss 1.0394 (1.0311) acc 59.3750 (70.5208) lr 1.0628e-03 eta 0:16:56
epoch [26/50] batch [80/428] time 0.092 (0.093) data 0.000 (0.008) loss 2.0160 (1.9549) teacher_loss 0.9083 (0.8199) loss_zs_kd 1.8313 (1.8521) loss_oracle 1.0428 (1.0322) kd_loss 1.0035 (1.0318) acc 62.5000 (70.8984) lr 1.0628e-03 eta 0:16:32
epoch [26/50] batch [100/428] time 0.082 (0.092) data 0.000 (0.006) loss 1.6286 (1.9650) teacher_loss 0.5218 (0.8324) loss_zs_kd 1.8206 (1.8318) loss_oracle 0.9950 (1.0351) kd_loss 1.0072 (1.0291) acc 87.5000 (70.6875) lr 1.0628e-03 eta 0:16:12
epoch [26/50] batch [120/428] time 0.077 (0.093) data 0.000 (0.005) loss 1.8202 (1.9648) teacher_loss 0.6763 (0.8339) loss_zs_kd 1.6451 (1.8240) loss_oracle 1.0375 (1.0359) kd_loss 1.0401 (1.0272) acc 84.3750 (70.7031) lr 1.0628e-03 eta 0:16:23
epoch [26/50] batch [140/428] time 0.083 (0.092) data 0.000 (0.005) loss 1.9718 (1.9711) teacher_loss 0.7960 (0.8406) loss_zs_kd 1.9673 (1.8312) loss_oracle 1.0383 (1.0364) kd_loss 1.0720 (1.0269) acc 75.0000 (70.0000) lr 1.0628e-03 eta 0:16:07
epoch [26/50] batch [160/428] time 0.080 (0.090) data 0.000 (0.004) loss 1.9985 (1.9655) teacher_loss 0.8979 (0.8382) loss_zs_kd 1.9018 (1.8301) loss_oracle 1.0067 (1.0349) kd_loss 1.0000 (1.0238) acc 59.3750 (70.0781) lr 1.0628e-03 eta 0:15:49
epoch [26/50] batch [180/428] time 0.093 (0.089) data 0.000 (0.004) loss 1.9976 (1.9748) teacher_loss 0.8371 (0.8484) loss_zs_kd 1.5659 (1.8242) loss_oracle 1.0459 (1.0355) kd_loss 1.0559 (1.0228) acc 71.8750 (69.5139) lr 1.0628e-03 eta 0:15:38
epoch [26/50] batch [200/428] time 0.092 (0.089) data 0.000 (0.003) loss 2.3576 (1.9834) teacher_loss 1.2226 (0.8574) loss_zs_kd 1.2000 (1.8158) loss_oracle 0.9962 (1.0357) kd_loss 1.0353 (1.0225) acc 43.7500 (69.1562) lr 1.0628e-03 eta 0:15:32
epoch [26/50] batch [220/428] time 0.092 (0.089) data 0.000 (0.003) loss 1.8942 (1.9917) teacher_loss 0.6731 (0.8652) loss_zs_kd 1.7597 (1.8090) loss_oracle 1.0266 (1.0357) kd_loss 1.1184 (1.0230) acc 81.2500 (68.7926) lr 1.0628e-03 eta 0:15:27
epoch [26/50] batch [240/428] time 0.080 (0.088) data 0.000 (0.003) loss 1.8924 (1.9895) teacher_loss 0.8071 (0.8638) loss_zs_kd 2.0764 (1.8010) loss_oracle 1.0585 (1.0355) kd_loss 0.9794 (1.0222) acc 68.7500 (68.8151) lr 1.0628e-03 eta 0:15:23
epoch [26/50] batch [260/428] time 0.091 (0.088) data 0.000 (0.003) loss 2.2836 (1.9891) teacher_loss 1.1767 (0.8661) loss_zs_kd 1.5560 (1.8037) loss_oracle 0.9626 (1.0340) kd_loss 1.0106 (1.0196) acc 62.5000 (68.7500) lr 1.0628e-03 eta 0:15:18
epoch [26/50] batch [280/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.7924 (1.9915) teacher_loss 0.6823 (0.8714) loss_zs_kd 1.8030 (1.7894) loss_oracle 1.0151 (1.0322) kd_loss 1.0086 (1.0169) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:15:09
epoch [26/50] batch [300/428] time 0.084 (0.087) data 0.000 (0.002) loss 1.7316 (1.9867) teacher_loss 0.6452 (0.8695) loss_zs_kd 1.6492 (1.7881) loss_oracle 1.0331 (1.0310) kd_loss 0.9831 (1.0142) acc 78.1250 (68.7917) lr 1.0628e-03 eta 0:15:04
epoch [26/50] batch [320/428] time 0.092 (0.087) data 0.000 (0.002) loss 1.9653 (1.9858) teacher_loss 0.8639 (0.8706) loss_zs_kd 1.5245 (1.7798) loss_oracle 1.0336 (1.0291) kd_loss 0.9980 (1.0123) acc 65.6250 (68.8867) lr 1.0628e-03 eta 0:14:58
epoch [26/50] batch [340/428] time 0.092 (0.086) data 0.000 (0.002) loss 2.0916 (1.9876) teacher_loss 1.0330 (0.8749) loss_zs_kd 1.8181 (1.7708) loss_oracle 0.9880 (1.0285) kd_loss 0.9598 (1.0098) acc 59.3750 (68.8695) lr 1.0628e-03 eta 0:14:55
epoch [26/50] batch [360/428] time 0.092 (0.086) data 0.000 (0.002) loss 1.8647 (1.9855) teacher_loss 0.8071 (0.8758) loss_zs_kd 1.7294 (1.7627) loss_oracle 1.0210 (1.0266) kd_loss 0.9555 (1.0070) acc 62.5000 (68.9149) lr 1.0628e-03 eta 0:14:53
epoch [26/50] batch [380/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.0184 (1.9868) teacher_loss 0.9083 (0.8795) loss_zs_kd 1.4798 (1.7504) loss_oracle 0.9967 (1.0254) kd_loss 1.0104 (1.0048) acc 56.2500 (68.6842) lr 1.0628e-03 eta 0:14:49
epoch [26/50] batch [400/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.8278 (1.9851) teacher_loss 0.7807 (0.8795) loss_zs_kd 1.7153 (1.7419) loss_oracle 0.9678 (1.0240) kd_loss 0.9504 (1.0032) acc 75.0000 (68.7656) lr 1.0628e-03 eta 0:14:47
epoch [26/50] batch [420/428] time 0.071 (0.086) data 0.000 (0.002) loss 1.8199 (1.9849) teacher_loss 0.7665 (0.8818) loss_zs_kd 1.5614 (1.7346) loss_oracle 1.0065 (1.0234) kd_loss 0.9527 (1.0007) acc 75.0000 (68.6161) lr 1.0628e-03 eta 0:14:42
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,553
* accuracy: 60.5%
* error: 39.5%
* macro_f1: 50.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,161
* accuracy: 45.6%
* error: 54.4%
* macro_f1: 31.9%
******* Domain 1 best val acc:      64.3%, epoch: 25 *******
******* Domain 1 best val test acc: 43.5%, epoch: 25 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [27/50] batch [20/428] time 0.082 (0.107) data 0.000 (0.028) loss 1.9459 (1.9327) teacher_loss 0.9273 (0.8750) loss_zs_kd 1.6834 (1.6093) loss_oracle 0.9643 (0.9988) kd_loss 0.9221 (0.9578) acc 62.5000 (67.8125) lr 1.0000e-03 eta 0:18:18
epoch [27/50] batch [40/428] time 0.082 (0.096) data 0.000 (0.014) loss 2.2031 (1.9197) teacher_loss 1.1140 (0.8682) loss_zs_kd 1.5363 (1.6300) loss_oracle 1.0425 (1.0101) kd_loss 0.9849 (0.9505) acc 56.2500 (69.4531) lr 1.0000e-03 eta 0:16:24
epoch [27/50] batch [60/428] time 0.089 (0.092) data 0.001 (0.009) loss 1.7913 (1.8973) teacher_loss 0.7439 (0.8458) loss_zs_kd 1.5027 (1.6120) loss_oracle 0.9974 (1.0077) kd_loss 0.9477 (0.9508) acc 65.6250 (70.9375) lr 1.0000e-03 eta 0:15:44
epoch [27/50] batch [80/428] time 0.083 (0.090) data 0.000 (0.007) loss 1.9873 (1.9171) teacher_loss 0.8628 (0.8587) loss_zs_kd 1.6074 (1.6460) loss_oracle 1.0466 (1.0078) kd_loss 1.0199 (0.9577) acc 62.5000 (69.9219) lr 1.0000e-03 eta 0:15:16
epoch [27/50] batch [100/428] time 0.078 (0.087) data 0.000 (0.006) loss 1.9794 (1.9158) teacher_loss 0.7660 (0.8443) loss_zs_kd 1.7641 (1.6698) loss_oracle 1.0554 (1.0135) kd_loss 1.1078 (0.9701) acc 71.8750 (70.4375) lr 1.0000e-03 eta 0:14:47
epoch [27/50] batch [120/428] time 0.080 (0.087) data 0.000 (0.005) loss 2.0048 (1.9184) teacher_loss 0.7736 (0.8354) loss_zs_kd 1.9889 (1.6925) loss_oracle 1.0099 (1.0180) kd_loss 1.1302 (0.9812) acc 68.7500 (70.6510) lr 1.0000e-03 eta 0:14:43
epoch [27/50] batch [140/428] time 0.079 (0.087) data 0.000 (0.004) loss 1.8718 (1.9174) teacher_loss 0.6561 (0.8278) loss_zs_kd 1.5092 (1.7237) loss_oracle 1.0742 (1.0208) kd_loss 1.1083 (0.9876) acc 71.8750 (70.8259) lr 1.0000e-03 eta 0:14:37
epoch [27/50] batch [160/428] time 0.081 (0.086) data 0.000 (0.004) loss 2.0071 (1.9171) teacher_loss 0.8306 (0.8227) loss_zs_kd 2.3041 (1.7412) loss_oracle 1.0667 (1.0217) kd_loss 1.0698 (0.9923) acc 75.0000 (70.9766) lr 1.0000e-03 eta 0:14:26
epoch [27/50] batch [180/428] time 0.084 (0.086) data 0.000 (0.003) loss 2.0989 (1.9203) teacher_loss 0.8905 (0.8207) loss_zs_kd 2.0356 (1.7740) loss_oracle 1.0313 (1.0228) kd_loss 1.1053 (0.9973) acc 68.7500 (70.9896) lr 1.0000e-03 eta 0:14:23
epoch [27/50] batch [200/428] time 0.078 (0.086) data 0.000 (0.003) loss 1.9857 (1.9310) teacher_loss 0.7848 (0.8279) loss_zs_kd 1.4858 (1.7845) loss_oracle 1.0585 (1.0237) kd_loss 1.0950 (1.0007) acc 68.7500 (70.7656) lr 1.0000e-03 eta 0:14:21
epoch [27/50] batch [220/428] time 0.088 (0.086) data 0.000 (0.003) loss 2.0243 (1.9408) teacher_loss 0.8928 (0.8354) loss_zs_kd 1.7492 (1.7987) loss_oracle 1.0785 (1.0242) kd_loss 1.0237 (1.0030) acc 75.0000 (70.6818) lr 1.0000e-03 eta 0:14:20
epoch [27/50] batch [240/428] time 0.081 (0.086) data 0.000 (0.003) loss 1.9021 (1.9409) teacher_loss 0.7732 (0.8322) loss_zs_kd 1.8346 (1.8066) loss_oracle 1.0673 (1.0249) kd_loss 1.0221 (1.0063) acc 75.0000 (70.8854) lr 1.0000e-03 eta 0:14:18
epoch [27/50] batch [260/428] time 0.068 (0.085) data 0.000 (0.002) loss 1.7631 (1.9432) teacher_loss 0.6163 (0.8304) loss_zs_kd 2.1520 (1.8148) loss_oracle 1.0279 (1.0251) kd_loss 1.0440 (1.0103) acc 84.3750 (71.0337) lr 1.0000e-03 eta 0:14:10
epoch [27/50] batch [280/428] time 0.064 (0.084) data 0.000 (0.002) loss 1.9984 (1.9434) teacher_loss 0.8083 (0.8287) loss_zs_kd 1.8589 (1.8222) loss_oracle 1.0341 (1.0258) kd_loss 1.0867 (1.0121) acc 65.6250 (71.0268) lr 1.0000e-03 eta 0:13:55
epoch [27/50] batch [300/428] time 0.079 (0.083) data 0.000 (0.002) loss 1.7987 (1.9451) teacher_loss 0.6492 (0.8264) loss_zs_kd 1.9361 (1.8249) loss_oracle 1.0583 (1.0274) kd_loss 1.0436 (1.0159) acc 78.1250 (71.0938) lr 1.0000e-03 eta 0:13:43
epoch [27/50] batch [320/428] time 0.090 (0.083) data 0.000 (0.002) loss 2.1887 (1.9452) teacher_loss 1.0628 (0.8254) loss_zs_kd 2.0580 (1.8309) loss_oracle 0.9936 (1.0272) kd_loss 1.0266 (1.0171) acc 50.0000 (71.1816) lr 1.0000e-03 eta 0:13:44
epoch [27/50] batch [340/428] time 0.085 (0.083) data 0.000 (0.002) loss 2.0908 (1.9492) teacher_loss 0.9794 (0.8289) loss_zs_kd 1.8628 (1.8344) loss_oracle 0.9319 (1.0267) kd_loss 1.0183 (1.0177) acc 62.5000 (71.0662) lr 1.0000e-03 eta 0:13:44
epoch [27/50] batch [360/428] time 0.081 (0.083) data 0.000 (0.002) loss 1.7855 (1.9484) teacher_loss 0.6635 (0.8283) loss_zs_kd 2.1599 (1.8370) loss_oracle 1.0358 (1.0266) kd_loss 1.0184 (1.0174) acc 81.2500 (71.1806) lr 1.0000e-03 eta 0:13:43
epoch [27/50] batch [380/428] time 0.083 (0.083) data 0.000 (0.002) loss 1.9867 (1.9476) teacher_loss 0.8689 (0.8276) loss_zs_kd 2.0127 (1.8355) loss_oracle 0.9932 (1.0264) kd_loss 1.0185 (1.0173) acc 71.8750 (71.2418) lr 1.0000e-03 eta 0:13:41
epoch [27/50] batch [400/428] time 0.080 (0.083) data 0.000 (0.002) loss 1.9345 (1.9478) teacher_loss 0.8458 (0.8275) loss_zs_kd 2.2693 (1.8451) loss_oracle 0.9989 (1.0256) kd_loss 0.9888 (1.0177) acc 68.7500 (71.1953) lr 1.0000e-03 eta 0:13:40
epoch [27/50] batch [420/428] time 0.081 (0.083) data 0.000 (0.002) loss 2.0305 (1.9449) teacher_loss 0.9007 (0.8238) loss_zs_kd 1.6892 (1.8522) loss_oracle 1.0395 (1.0259) kd_loss 1.0258 (1.0185) acc 62.5000 (71.3170) lr 1.0000e-03 eta 0:13:38
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,641
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 49.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 1,784
* accuracy: 37.6%
* error: 62.4%
* macro_f1: 30.6%
******* Domain 1 best val acc:      64.3%, epoch: 25 *******
******* Domain 1 best val test acc: 43.5%, epoch: 25 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [28/50] batch [20/428] time 0.078 (0.112) data 0.000 (0.031) loss 2.0433 (1.9100) teacher_loss 0.9007 (0.7638) loss_zs_kd 2.0204 (2.0697) loss_oracle 1.0033 (1.0324) kd_loss 1.0423 (1.0429) acc 62.5000 (72.9688) lr 9.3721e-04 eta 0:18:17
epoch [28/50] batch [40/428] time 0.079 (0.096) data 0.000 (0.016) loss 1.9913 (1.9205) teacher_loss 0.8947 (0.7859) loss_zs_kd 1.7892 (1.9750) loss_oracle 1.0491 (1.0254) kd_loss 0.9917 (1.0321) acc 68.7500 (72.9688) lr 9.3721e-04 eta 0:15:40
epoch [28/50] batch [60/428] time 0.088 (0.092) data 0.000 (0.011) loss 1.7465 (1.9183) teacher_loss 0.6116 (0.7842) loss_zs_kd 1.8636 (1.9305) loss_oracle 1.0089 (1.0265) kd_loss 1.0341 (1.0314) acc 78.1250 (73.2812) lr 9.3721e-04 eta 0:15:02
epoch [28/50] batch [80/428] time 0.073 (0.088) data 0.000 (0.008) loss 1.8508 (1.9211) teacher_loss 0.7417 (0.7846) loss_zs_kd 1.6916 (1.8961) loss_oracle 1.0746 (1.0331) kd_loss 1.0016 (1.0332) acc 78.1250 (73.2031) lr 9.3721e-04 eta 0:14:22
epoch [28/50] batch [100/428] time 0.087 (0.087) data 0.000 (0.007) loss 1.9192 (1.9322) teacher_loss 0.7984 (0.7968) loss_zs_kd 1.6444 (1.8719) loss_oracle 0.9778 (1.0317) kd_loss 1.0231 (1.0322) acc 68.7500 (72.5938) lr 9.3721e-04 eta 0:14:05
epoch [28/50] batch [120/428] time 0.091 (0.086) data 0.000 (0.005) loss 2.4007 (1.9341) teacher_loss 1.3108 (0.7974) loss_zs_kd 1.4857 (1.8625) loss_oracle 1.0069 (1.0279) kd_loss 0.9893 (1.0339) acc 53.1250 (72.3698) lr 9.3721e-04 eta 0:13:57
epoch [28/50] batch [140/428] time 0.075 (0.085) data 0.000 (0.005) loss 2.0372 (1.9369) teacher_loss 0.8989 (0.8009) loss_zs_kd 2.0126 (1.8641) loss_oracle 1.0161 (1.0256) kd_loss 1.0367 (1.0334) acc 71.8750 (72.4107) lr 9.3721e-04 eta 0:13:48
epoch [28/50] batch [160/428] time 0.081 (0.085) data 0.000 (0.004) loss 1.9328 (1.9353) teacher_loss 0.8624 (0.8005) loss_zs_kd 1.8145 (1.8647) loss_oracle 1.0045 (1.0249) kd_loss 0.9700 (1.0324) acc 81.2500 (72.2461) lr 9.3721e-04 eta 0:13:46
epoch [28/50] batch [180/428] time 0.085 (0.085) data 0.000 (0.004) loss 2.1357 (1.9302) teacher_loss 0.9843 (0.7941) loss_zs_kd 2.1991 (1.8792) loss_oracle 1.0510 (1.0259) kd_loss 1.0463 (1.0335) acc 62.5000 (72.4132) lr 9.3721e-04 eta 0:13:45
epoch [28/50] batch [200/428] time 0.078 (0.086) data 0.000 (0.003) loss 1.8837 (1.9272) teacher_loss 0.7655 (0.7898) loss_zs_kd 2.0416 (1.8850) loss_oracle 1.0015 (1.0269) kd_loss 1.0181 (1.0348) acc 71.8750 (72.6562) lr 9.3721e-04 eta 0:13:45
epoch [28/50] batch [220/428] time 0.072 (0.086) data 0.000 (0.003) loss 2.2807 (1.9350) teacher_loss 1.1154 (0.7962) loss_zs_kd 1.9189 (1.8835) loss_oracle 1.0095 (1.0284) kd_loss 1.0643 (1.0360) acc 68.7500 (72.6420) lr 9.3721e-04 eta 0:13:42
epoch [28/50] batch [240/428] time 0.079 (0.085) data 0.000 (0.003) loss 1.9028 (1.9311) teacher_loss 0.6933 (0.7903) loss_zs_kd 1.7900 (1.8848) loss_oracle 1.1015 (1.0303) kd_loss 1.0993 (1.0378) acc 71.8750 (72.8646) lr 9.3721e-04 eta 0:13:35
epoch [28/50] batch [260/428] time 0.092 (0.085) data 0.000 (0.003) loss 1.8241 (1.9284) teacher_loss 0.7037 (0.7869) loss_zs_kd 1.7876 (1.8754) loss_oracle 1.0095 (1.0305) kd_loss 1.0194 (1.0385) acc 81.2500 (73.0048) lr 9.3721e-04 eta 0:13:31
epoch [28/50] batch [280/428] time 0.086 (0.085) data 0.000 (0.003) loss 2.1207 (1.9260) teacher_loss 1.0088 (0.7857) loss_zs_kd 1.8093 (1.8686) loss_oracle 1.0573 (1.0312) kd_loss 1.0062 (1.0372) acc 65.6250 (73.0134) lr 9.3721e-04 eta 0:13:29
epoch [28/50] batch [300/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.9705 (1.9270) teacher_loss 0.8011 (0.7884) loss_zs_kd 1.8654 (1.8698) loss_oracle 1.0580 (1.0318) kd_loss 1.0636 (1.0355) acc 68.7500 (72.9375) lr 9.3721e-04 eta 0:13:25
epoch [28/50] batch [320/428] time 0.085 (0.084) data 0.000 (0.002) loss 1.9732 (1.9271) teacher_loss 0.9100 (0.7912) loss_zs_kd 1.8566 (1.8689) loss_oracle 1.0685 (1.0323) kd_loss 0.9563 (1.0326) acc 78.1250 (72.7734) lr 9.3721e-04 eta 0:13:23
epoch [28/50] batch [340/428] time 0.088 (0.084) data 0.000 (0.002) loss 2.0428 (1.9292) teacher_loss 0.8931 (0.7946) loss_zs_kd 1.8689 (1.8743) loss_oracle 1.0839 (1.0326) kd_loss 1.0413 (1.0313) acc 62.5000 (72.6103) lr 9.3721e-04 eta 0:13:22
epoch [28/50] batch [360/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.5383 (1.9309) teacher_loss 0.5767 (0.7989) loss_zs_kd 1.3952 (1.8725) loss_oracle 0.9926 (1.0321) kd_loss 0.8624 (1.0288) acc 78.1250 (72.5174) lr 9.3721e-04 eta 0:13:20
epoch [28/50] batch [380/428] time 0.083 (0.084) data 0.000 (0.002) loss 1.8697 (1.9370) teacher_loss 0.8294 (0.8081) loss_zs_kd 1.7692 (1.8615) loss_oracle 1.0042 (1.0313) kd_loss 0.9399 (1.0258) acc 71.8750 (72.1628) lr 9.3721e-04 eta 0:13:19
epoch [28/50] batch [400/428] time 0.075 (0.085) data 0.000 (0.002) loss 2.3496 (1.9399) teacher_loss 1.2987 (0.8149) loss_zs_kd 1.6550 (1.8521) loss_oracle 0.9720 (1.0297) kd_loss 0.9537 (1.0220) acc 50.0000 (71.8906) lr 9.3721e-04 eta 0:13:22
epoch [28/50] batch [420/428] time 0.074 (0.085) data 0.000 (0.002) loss 1.7272 (1.9424) teacher_loss 0.7009 (0.8208) loss_zs_kd 1.9326 (1.8387) loss_oracle 0.9827 (1.0284) kd_loss 0.9279 (1.0188) acc 71.8750 (71.6518) lr 9.3721e-04 eta 0:13:16
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,572
* accuracy: 60.8%
* error: 39.2%
* macro_f1: 52.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,280
* accuracy: 48.1%
* error: 51.9%
* macro_f1: 32.5%
******* Domain 1 best val acc:      64.3%, epoch: 25 *******
******* Domain 1 best val test acc: 43.5%, epoch: 25 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [29/50] batch [20/428] time 0.090 (0.118) data 0.000 (0.028) loss 1.9448 (2.0249) teacher_loss 0.9889 (0.9641) loss_zs_kd 1.7021 (1.6123) loss_oracle 1.0256 (1.0076) kd_loss 0.8534 (0.9600) acc 65.6250 (66.5625) lr 8.7467e-04 eta 0:18:27
epoch [29/50] batch [40/428] time 0.081 (0.100) data 0.000 (0.014) loss 2.0514 (2.0031) teacher_loss 1.0367 (0.9474) loss_zs_kd 1.1510 (1.5789) loss_oracle 1.0469 (1.0051) kd_loss 0.9100 (0.9553) acc 59.3750 (67.6562) lr 8.7467e-04 eta 0:15:41
epoch [29/50] batch [60/428] time 0.080 (0.095) data 0.001 (0.010) loss 2.0237 (1.9727) teacher_loss 0.9903 (0.9203) loss_zs_kd 1.3607 (1.5721) loss_oracle 1.0049 (1.0016) kd_loss 0.9329 (0.9523) acc 68.7500 (68.5938) lr 8.7467e-04 eta 0:14:45
epoch [29/50] batch [80/428] time 0.076 (0.090) data 0.000 (0.007) loss 1.7554 (1.9574) teacher_loss 0.7230 (0.9028) loss_zs_kd 1.8427 (1.6130) loss_oracle 1.0281 (1.0031) kd_loss 0.9296 (0.9543) acc 71.8750 (68.7109) lr 8.7467e-04 eta 0:14:03
epoch [29/50] batch [100/428] time 0.082 (0.089) data 0.000 (0.006) loss 1.8177 (1.9541) teacher_loss 0.7611 (0.8985) loss_zs_kd 1.8195 (1.6497) loss_oracle 1.0320 (1.0038) kd_loss 0.9535 (0.9552) acc 71.8750 (68.8125) lr 8.7467e-04 eta 0:13:46
epoch [29/50] batch [120/428] time 0.071 (0.090) data 0.000 (0.005) loss 1.9758 (1.9479) teacher_loss 0.9056 (0.8932) loss_zs_kd 1.9583 (1.6831) loss_oracle 0.9829 (1.0011) kd_loss 0.9719 (0.9546) acc 62.5000 (68.9323) lr 8.7467e-04 eta 0:13:59
epoch [29/50] batch [140/428] time 0.078 (0.089) data 0.000 (0.004) loss 1.7528 (1.9457) teacher_loss 0.6759 (0.8861) loss_zs_kd 1.6672 (1.6930) loss_oracle 1.0548 (1.0042) kd_loss 0.9714 (0.9592) acc 84.3750 (69.0848) lr 8.7467e-04 eta 0:13:44
epoch [29/50] batch [160/428] time 0.085 (0.088) data 0.000 (0.004) loss 1.9514 (1.9521) teacher_loss 0.7738 (0.8826) loss_zs_kd 2.1176 (1.7014) loss_oracle 0.9655 (1.0084) kd_loss 1.0810 (0.9687) acc 75.0000 (69.3555) lr 8.7467e-04 eta 0:13:33
epoch [29/50] batch [180/428] time 0.075 (0.087) data 0.000 (0.003) loss 1.7391 (1.9453) teacher_loss 0.5743 (0.8675) loss_zs_kd 2.0783 (1.7136) loss_oracle 1.0353 (1.0133) kd_loss 1.0612 (0.9765) acc 78.1250 (70.0174) lr 8.7467e-04 eta 0:13:26
epoch [29/50] batch [200/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.0423 (1.9486) teacher_loss 0.9049 (0.8638) loss_zs_kd 1.5567 (1.7272) loss_oracle 1.0508 (1.0173) kd_loss 1.0322 (0.9830) acc 75.0000 (70.2812) lr 8.7467e-04 eta 0:13:21
epoch [29/50] batch [220/428] time 0.078 (0.087) data 0.000 (0.003) loss 2.0577 (1.9516) teacher_loss 0.9488 (0.8630) loss_zs_kd 2.1816 (1.7215) loss_oracle 1.0312 (1.0195) kd_loss 1.0058 (0.9867) acc 53.1250 (70.1705) lr 8.7467e-04 eta 0:13:15
epoch [29/50] batch [240/428] time 0.083 (0.086) data 0.000 (0.003) loss 1.9471 (1.9524) teacher_loss 0.8597 (0.8623) loss_zs_kd 1.7993 (1.7209) loss_oracle 1.0041 (1.0199) kd_loss 0.9870 (0.9881) acc 68.7500 (70.1302) lr 8.7467e-04 eta 0:13:09
epoch [29/50] batch [260/428] time 0.076 (0.086) data 0.000 (0.002) loss 1.9240 (1.9536) teacher_loss 0.8010 (0.8594) loss_zs_kd 1.4890 (1.7168) loss_oracle 1.0087 (1.0210) kd_loss 1.0221 (0.9921) acc 68.7500 (70.2284) lr 8.7467e-04 eta 0:13:04
epoch [29/50] batch [280/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.0057 (1.9548) teacher_loss 0.9486 (0.8594) loss_zs_kd 1.6771 (1.7141) loss_oracle 1.0133 (1.0225) kd_loss 0.9558 (0.9932) acc 78.1250 (70.1897) lr 8.7467e-04 eta 0:13:00
epoch [29/50] batch [300/428] time 0.093 (0.085) data 0.000 (0.002) loss 1.9969 (1.9546) teacher_loss 0.9172 (0.8571) loss_zs_kd 2.2389 (1.7186) loss_oracle 1.0200 (1.0226) kd_loss 0.9776 (0.9952) acc 62.5000 (70.3333) lr 8.7467e-04 eta 0:12:57
epoch [29/50] batch [320/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.0232 (1.9532) teacher_loss 0.9290 (0.8544) loss_zs_kd 1.5691 (1.7203) loss_oracle 1.0620 (1.0234) kd_loss 0.9880 (0.9965) acc 65.6250 (70.4297) lr 8.7467e-04 eta 0:12:54
epoch [29/50] batch [340/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.7752 (1.9526) teacher_loss 0.7361 (0.8555) loss_zs_kd 1.7418 (1.7219) loss_oracle 0.9519 (1.0227) kd_loss 0.9439 (0.9949) acc 71.8750 (70.3676) lr 8.7467e-04 eta 0:12:52
epoch [29/50] batch [360/428] time 0.103 (0.085) data 0.000 (0.002) loss 1.8441 (1.9543) teacher_loss 0.8293 (0.8606) loss_zs_kd 1.8081 (1.7268) loss_oracle 1.0201 (1.0221) kd_loss 0.9128 (0.9915) acc 68.7500 (70.0694) lr 8.7467e-04 eta 0:12:49
epoch [29/50] batch [380/428] time 0.082 (0.085) data 0.000 (0.002) loss 2.0370 (1.9506) teacher_loss 0.9029 (0.8573) loss_zs_kd 1.5156 (1.7283) loss_oracle 1.0098 (1.0218) kd_loss 1.0331 (0.9911) acc 71.8750 (70.1645) lr 8.7467e-04 eta 0:12:46
epoch [29/50] batch [400/428] time 0.086 (0.085) data 0.000 (0.002) loss 1.9262 (1.9517) teacher_loss 0.8542 (0.8584) loss_zs_kd 1.7562 (1.7334) loss_oracle 0.9861 (1.0230) kd_loss 0.9735 (0.9910) acc 75.0000 (70.2344) lr 8.7467e-04 eta 0:12:44
epoch [29/50] batch [420/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.8346 (1.9472) teacher_loss 0.8049 (0.8538) loss_zs_kd 2.1284 (1.7364) loss_oracle 1.0345 (1.0239) kd_loss 0.9262 (0.9911) acc 68.7500 (70.4018) lr 8.7467e-04 eta 0:12:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,876
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 54.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,054
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 30.4%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [30/50] batch [20/428] time 0.083 (0.103) data 0.000 (0.024) loss 1.7518 (1.9822) teacher_loss 0.6811 (0.9241) loss_zs_kd 1.5653 (1.7652) loss_oracle 1.0035 (1.0189) kd_loss 0.9704 (0.9561) acc 81.2500 (69.6875) lr 8.1262e-04 eta 0:15:27
epoch [30/50] batch [40/428] time 0.089 (0.093) data 0.000 (0.012) loss 1.9043 (1.9686) teacher_loss 0.8650 (0.9141) loss_zs_kd 1.8109 (1.7671) loss_oracle 1.0217 (1.0120) kd_loss 0.9371 (0.9533) acc 71.8750 (68.9062) lr 8.1262e-04 eta 0:13:52
epoch [30/50] batch [60/428] time 0.077 (0.090) data 0.000 (0.008) loss 1.9337 (1.9818) teacher_loss 0.8718 (0.9234) loss_zs_kd 1.4965 (1.7483) loss_oracle 1.0546 (1.0205) kd_loss 0.9564 (0.9563) acc 68.7500 (68.1250) lr 8.1262e-04 eta 0:13:24
epoch [30/50] batch [80/428] time 0.084 (0.089) data 0.000 (0.006) loss 1.8082 (1.9628) teacher_loss 0.7640 (0.9088) loss_zs_kd 1.6214 (1.7471) loss_oracle 0.9743 (1.0182) kd_loss 0.9468 (0.9521) acc 71.8750 (68.7500) lr 8.1262e-04 eta 0:13:08
epoch [30/50] batch [100/428] time 0.083 (0.086) data 0.000 (0.005) loss 1.9239 (1.9678) teacher_loss 0.7841 (0.9073) loss_zs_kd 1.9635 (1.7588) loss_oracle 1.0551 (1.0179) kd_loss 1.0342 (0.9587) acc 68.7500 (68.3750) lr 8.1262e-04 eta 0:12:48
epoch [30/50] batch [120/428] time 0.084 (0.086) data 0.000 (0.004) loss 1.6566 (1.9590) teacher_loss 0.5096 (0.8881) loss_zs_kd 1.8654 (1.7615) loss_oracle 1.0448 (1.0214) kd_loss 1.0425 (0.9688) acc 87.5000 (69.1927) lr 8.1262e-04 eta 0:12:38
epoch [30/50] batch [140/428] time 0.090 (0.086) data 0.001 (0.004) loss 2.0707 (1.9519) teacher_loss 0.9992 (0.8760) loss_zs_kd 2.1855 (1.7675) loss_oracle 1.0597 (1.0212) kd_loss 0.9655 (0.9738) acc 56.2500 (69.4420) lr 8.1262e-04 eta 0:12:37
epoch [30/50] batch [160/428] time 0.085 (0.085) data 0.000 (0.003) loss 2.1049 (1.9546) teacher_loss 1.0009 (0.8745) loss_zs_kd 1.4761 (1.7710) loss_oracle 1.0594 (1.0229) kd_loss 0.9980 (0.9779) acc 65.6250 (69.3164) lr 8.1262e-04 eta 0:12:33
epoch [30/50] batch [180/428] time 0.085 (0.085) data 0.000 (0.003) loss 1.7525 (1.9517) teacher_loss 0.6447 (0.8686) loss_zs_kd 1.7273 (1.7883) loss_oracle 1.0062 (1.0242) kd_loss 1.0071 (0.9807) acc 87.5000 (69.4444) lr 8.1262e-04 eta 0:12:32
epoch [30/50] batch [200/428] time 0.089 (0.085) data 0.000 (0.003) loss 1.9649 (1.9546) teacher_loss 0.8290 (0.8675) loss_zs_kd 2.2148 (1.8069) loss_oracle 0.9562 (1.0252) kd_loss 1.0403 (0.9846) acc 75.0000 (69.3438) lr 8.1262e-04 eta 0:12:29
epoch [30/50] batch [220/428] time 0.087 (0.085) data 0.000 (0.002) loss 2.0801 (1.9493) teacher_loss 1.0266 (0.8592) loss_zs_kd 2.2510 (1.8196) loss_oracle 0.9975 (1.0256) kd_loss 0.9537 (0.9875) acc 56.2500 (69.5597) lr 8.1262e-04 eta 0:12:27
epoch [30/50] batch [240/428] time 0.137 (0.086) data 0.000 (0.002) loss 1.6853 (1.9538) teacher_loss 0.6016 (0.8625) loss_zs_kd 1.9587 (1.8323) loss_oracle 1.0026 (1.0257) kd_loss 0.9835 (0.9887) acc 87.5000 (69.5182) lr 8.1262e-04 eta 0:12:34
epoch [30/50] batch [260/428] time 0.078 (0.086) data 0.000 (0.002) loss 1.6929 (1.9467) teacher_loss 0.6015 (0.8530) loss_zs_kd 1.6425 (1.8314) loss_oracle 1.0207 (1.0273) kd_loss 0.9893 (0.9910) acc 78.1250 (69.7837) lr 8.1262e-04 eta 0:12:27
epoch [30/50] batch [280/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.0216 (1.9496) teacher_loss 0.9553 (0.8541) loss_zs_kd 1.7417 (1.8423) loss_oracle 1.0228 (1.0270) kd_loss 0.9640 (0.9929) acc 71.8750 (69.7545) lr 8.1262e-04 eta 0:12:24
epoch [30/50] batch [300/428] time 0.087 (0.086) data 0.001 (0.002) loss 1.8326 (1.9504) teacher_loss 0.7314 (0.8530) loss_zs_kd 1.8543 (1.8482) loss_oracle 1.0826 (1.0272) kd_loss 0.9929 (0.9947) acc 81.2500 (69.8646) lr 8.1262e-04 eta 0:12:24
epoch [30/50] batch [320/428] time 0.078 (0.086) data 0.000 (0.002) loss 1.9073 (1.9559) teacher_loss 0.8368 (0.8572) loss_zs_kd 2.3164 (1.8504) loss_oracle 1.0578 (1.0275) kd_loss 0.9647 (0.9959) acc 56.2500 (69.7461) lr 8.1262e-04 eta 0:12:21
epoch [30/50] batch [340/428] time 0.087 (0.086) data 0.000 (0.002) loss 1.7386 (1.9552) teacher_loss 0.6229 (0.8575) loss_zs_kd 1.8732 (1.8482) loss_oracle 1.0375 (1.0261) kd_loss 1.0120 (0.9951) acc 81.2500 (69.6691) lr 8.1262e-04 eta 0:12:19
epoch [30/50] batch [360/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.7373 (1.9576) teacher_loss 0.6553 (0.8596) loss_zs_kd 1.8126 (1.8461) loss_oracle 1.0229 (1.0252) kd_loss 0.9797 (0.9955) acc 81.2500 (69.6615) lr 8.1262e-04 eta 0:12:18
epoch [30/50] batch [380/428] time 0.085 (0.085) data 0.000 (0.002) loss 1.8759 (1.9573) teacher_loss 0.6976 (0.8581) loss_zs_kd 1.9881 (1.8448) loss_oracle 0.9927 (1.0261) kd_loss 1.0791 (0.9966) acc 81.2500 (69.7697) lr 8.1262e-04 eta 0:12:15
epoch [30/50] batch [400/428] time 0.080 (0.085) data 0.000 (0.001) loss 1.7748 (1.9547) teacher_loss 0.6545 (0.8547) loss_zs_kd 1.6321 (1.8428) loss_oracle 1.0498 (1.0265) kd_loss 1.0153 (0.9974) acc 78.1250 (69.8672) lr 8.1262e-04 eta 0:12:13
epoch [30/50] batch [420/428] time 0.070 (0.085) data 0.000 (0.001) loss 2.2037 (1.9553) teacher_loss 1.0122 (0.8541) loss_zs_kd 1.3593 (1.8430) loss_oracle 1.0516 (1.0271) kd_loss 1.0863 (0.9984) acc 62.5000 (69.8140) lr 8.1262e-04 eta 0:12:10
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,773
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 50.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,105
* accuracy: 44.4%
* error: 55.6%
* macro_f1: 31.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [31/50] batch [20/428] time 0.082 (0.111) data 0.000 (0.024) loss 1.8685 (1.9384) teacher_loss 0.7743 (0.8026) loss_zs_kd 2.1645 (1.9778) loss_oracle 0.9986 (1.0420) kd_loss 0.9944 (1.0316) acc 65.6250 (71.0938) lr 7.5131e-04 eta 0:15:46
epoch [31/50] batch [40/428] time 0.079 (0.097) data 0.000 (0.012) loss 1.7994 (1.9532) teacher_loss 0.6710 (0.8211) loss_zs_kd 1.5475 (1.9330) loss_oracle 0.9987 (1.0336) kd_loss 1.0285 (1.0288) acc 78.1250 (71.3281) lr 7.5131e-04 eta 0:13:45
epoch [31/50] batch [60/428] time 0.085 (0.091) data 0.001 (0.008) loss 1.8784 (1.9582) teacher_loss 0.7801 (0.8302) loss_zs_kd 1.7992 (1.9047) loss_oracle 0.9918 (1.0301) kd_loss 0.9991 (1.0250) acc 71.8750 (71.0417) lr 7.5131e-04 eta 0:12:54
epoch [31/50] batch [80/428] time 0.081 (0.090) data 0.000 (0.006) loss 1.7080 (1.9612) teacher_loss 0.6080 (0.8327) loss_zs_kd 1.7210 (1.8916) loss_oracle 1.0594 (1.0330) kd_loss 0.9941 (1.0251) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:12:40
epoch [31/50] batch [100/428] time 0.075 (0.088) data 0.000 (0.005) loss 1.8898 (1.9702) teacher_loss 0.7758 (0.8448) loss_zs_kd 1.9665 (1.8994) loss_oracle 1.0621 (1.0321) kd_loss 1.0078 (1.0223) acc 78.1250 (70.9375) lr 7.5131e-04 eta 0:12:24
epoch [31/50] batch [120/428] time 0.084 (0.087) data 0.000 (0.004) loss 1.5182 (1.9598) teacher_loss 0.4635 (0.8363) loss_zs_kd 2.0404 (1.8987) loss_oracle 0.9611 (1.0313) kd_loss 0.9586 (1.0204) acc 90.6250 (71.1198) lr 7.5131e-04 eta 0:12:13
epoch [31/50] batch [140/428] time 0.093 (0.087) data 0.000 (0.004) loss 1.8740 (1.9592) teacher_loss 0.7143 (0.8376) loss_zs_kd 1.5702 (1.9040) loss_oracle 1.0523 (1.0315) kd_loss 1.0545 (1.0184) acc 75.0000 (71.1830) lr 7.5131e-04 eta 0:12:10
epoch [31/50] batch [160/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.9681 (1.9543) teacher_loss 0.8520 (0.8333) loss_zs_kd 2.0340 (1.9010) loss_oracle 1.0447 (1.0309) kd_loss 1.0117 (1.0179) acc 68.7500 (71.3672) lr 7.5131e-04 eta 0:12:08
epoch [31/50] batch [180/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.7566 (1.9523) teacher_loss 0.6649 (0.8332) loss_zs_kd 2.0012 (1.8950) loss_oracle 1.0235 (1.0307) kd_loss 0.9894 (1.0161) acc 71.8750 (71.2674) lr 7.5131e-04 eta 0:12:05
epoch [31/50] batch [200/428] time 0.078 (0.087) data 0.000 (0.003) loss 2.1111 (1.9507) teacher_loss 0.9142 (0.8323) loss_zs_kd 1.5623 (1.8863) loss_oracle 1.0767 (1.0319) kd_loss 1.0892 (1.0152) acc 59.3750 (71.2344) lr 7.5131e-04 eta 0:12:04
epoch [31/50] batch [220/428] time 0.089 (0.087) data 0.000 (0.002) loss 2.0179 (1.9434) teacher_loss 0.9326 (0.8255) loss_zs_kd 1.8218 (1.8916) loss_oracle 0.9747 (1.0335) kd_loss 0.9878 (1.0146) acc 62.5000 (71.3068) lr 7.5131e-04 eta 0:12:03
epoch [31/50] batch [240/428] time 0.078 (0.087) data 0.000 (0.002) loss 1.8277 (1.9396) teacher_loss 0.7110 (0.8200) loss_zs_kd 2.2530 (1.8897) loss_oracle 0.9979 (1.0343) kd_loss 1.0170 (1.0163) acc 78.1250 (71.3672) lr 7.5131e-04 eta 0:12:00
epoch [31/50] batch [260/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.9295 (1.9409) teacher_loss 0.7797 (0.8195) loss_zs_kd 1.6038 (1.8868) loss_oracle 1.0762 (1.0355) kd_loss 1.0422 (1.0178) acc 75.0000 (71.4663) lr 7.5131e-04 eta 0:11:56
epoch [31/50] batch [280/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.0964 (1.9404) teacher_loss 0.9558 (0.8178) loss_zs_kd 1.8557 (1.8800) loss_oracle 1.0313 (1.0362) kd_loss 1.0374 (1.0190) acc 71.8750 (71.3839) lr 7.5131e-04 eta 0:11:52
epoch [31/50] batch [300/428] time 0.092 (0.086) data 0.000 (0.002) loss 1.7737 (1.9330) teacher_loss 0.5704 (0.8088) loss_zs_kd 1.7763 (1.8808) loss_oracle 1.1081 (1.0365) kd_loss 1.0925 (1.0206) acc 84.3750 (71.7708) lr 7.5131e-04 eta 0:11:48
epoch [31/50] batch [320/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.7911 (1.9309) teacher_loss 0.6685 (0.8070) loss_zs_kd 2.1911 (1.8852) loss_oracle 1.0454 (1.0362) kd_loss 1.0181 (1.0203) acc 78.1250 (71.8457) lr 7.5131e-04 eta 0:11:48
epoch [31/50] batch [340/428] time 0.094 (0.086) data 0.000 (0.002) loss 1.7467 (1.9294) teacher_loss 0.5774 (0.8042) loss_zs_kd 2.1156 (1.8818) loss_oracle 1.0712 (1.0367) kd_loss 1.0622 (1.0216) acc 81.2500 (72.0037) lr 7.5131e-04 eta 0:11:46
epoch [31/50] batch [360/428] time 0.076 (0.087) data 0.000 (0.002) loss 1.8705 (1.9285) teacher_loss 0.6874 (0.8013) loss_zs_kd 1.5207 (1.8748) loss_oracle 1.1182 (1.0379) kd_loss 1.0713 (1.0234) acc 71.8750 (72.0660) lr 7.5131e-04 eta 0:11:50
epoch [31/50] batch [380/428] time 0.087 (0.086) data 0.000 (0.002) loss 2.2245 (1.9289) teacher_loss 1.0864 (0.8011) loss_zs_kd 2.0791 (1.8720) loss_oracle 1.0853 (1.0378) kd_loss 1.0295 (1.0240) acc 68.7500 (72.1053) lr 7.5131e-04 eta 0:11:46
epoch [31/50] batch [400/428] time 0.086 (0.086) data 0.000 (0.002) loss 1.8319 (1.9264) teacher_loss 0.7124 (0.7977) loss_zs_kd 2.1178 (1.8693) loss_oracle 1.0832 (1.0379) kd_loss 1.0112 (1.0249) acc 75.0000 (72.2266) lr 7.5131e-04 eta 0:11:44
epoch [31/50] batch [420/428] time 0.084 (0.086) data 0.000 (0.001) loss 2.2473 (1.9267) teacher_loss 1.0574 (0.7977) loss_zs_kd 1.7695 (1.8656) loss_oracle 1.1121 (1.0382) kd_loss 1.0788 (1.0251) acc 65.6250 (72.2545) lr 7.5131e-04 eta 0:11:41
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,735
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 50.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,068
* accuracy: 43.6%
* error: 56.4%
* macro_f1: 32.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [32/50] batch [20/428] time 0.072 (0.115) data 0.000 (0.029) loss 1.6318 (1.9289) teacher_loss 0.5296 (0.8248) loss_zs_kd 1.5038 (1.7990) loss_oracle 1.0294 (1.0219) kd_loss 0.9993 (1.0018) acc 90.6250 (72.3438) lr 6.9098e-04 eta 0:15:34
epoch [32/50] batch [40/428] time 0.077 (0.098) data 0.000 (0.015) loss 2.0189 (1.9217) teacher_loss 0.9154 (0.8095) loss_zs_kd 1.7882 (1.8044) loss_oracle 0.9887 (1.0309) kd_loss 1.0046 (1.0091) acc 71.8750 (73.1250) lr 6.9098e-04 eta 0:13:09
epoch [32/50] batch [60/428] time 0.082 (0.093) data 0.000 (0.010) loss 1.9333 (1.8976) teacher_loss 0.8429 (0.7975) loss_zs_kd 1.7774 (1.8557) loss_oracle 1.0340 (1.0296) kd_loss 0.9870 (0.9972) acc 68.7500 (72.8646) lr 6.9098e-04 eta 0:12:29
epoch [32/50] batch [80/428] time 0.086 (0.090) data 0.000 (0.007) loss 1.9105 (1.8993) teacher_loss 0.8668 (0.8060) loss_zs_kd 1.8737 (1.8450) loss_oracle 1.0504 (1.0277) kd_loss 0.9387 (0.9905) acc 65.6250 (72.1875) lr 6.9098e-04 eta 0:12:08
epoch [32/50] batch [100/428] time 0.090 (0.092) data 0.000 (0.006) loss 1.8073 (1.9046) teacher_loss 0.7785 (0.8189) loss_zs_kd 2.0345 (1.8262) loss_oracle 1.0278 (1.0297) kd_loss 0.9261 (0.9827) acc 78.1250 (71.7812) lr 6.9098e-04 eta 0:12:19
epoch [32/50] batch [120/428] time 0.087 (0.091) data 0.000 (0.005) loss 2.0219 (1.9116) teacher_loss 0.9825 (0.8338) loss_zs_kd 1.3121 (1.8049) loss_oracle 0.9580 (1.0282) kd_loss 0.9437 (0.9750) acc 56.2500 (71.0156) lr 6.9098e-04 eta 0:12:08
epoch [32/50] batch [140/428] time 0.081 (0.090) data 0.000 (0.004) loss 1.9095 (1.9110) teacher_loss 0.8221 (0.8344) loss_zs_kd 1.7436 (1.8023) loss_oracle 0.9973 (1.0287) kd_loss 0.9877 (0.9737) acc 71.8750 (70.7812) lr 6.9098e-04 eta 0:11:59
epoch [32/50] batch [160/428] time 0.083 (0.089) data 0.000 (0.004) loss 1.5887 (1.9155) teacher_loss 0.5560 (0.8407) loss_zs_kd 1.6719 (1.7907) loss_oracle 1.0934 (1.0279) kd_loss 0.9233 (0.9721) acc 84.3750 (70.6055) lr 6.9098e-04 eta 0:11:53
epoch [32/50] batch [180/428] time 0.079 (0.089) data 0.000 (0.003) loss 1.9081 (1.9187) teacher_loss 0.8532 (0.8439) loss_zs_kd 1.8860 (1.7929) loss_oracle 1.0821 (1.0285) kd_loss 0.9467 (0.9720) acc 65.6250 (70.4688) lr 6.9098e-04 eta 0:11:47
epoch [32/50] batch [200/428] time 0.081 (0.089) data 0.000 (0.003) loss 1.6941 (1.9237) teacher_loss 0.5761 (0.8475) loss_zs_kd 1.7618 (1.7928) loss_oracle 1.0709 (1.0292) kd_loss 1.0109 (0.9733) acc 81.2500 (70.2500) lr 6.9098e-04 eta 0:11:43
epoch [32/50] batch [220/428] time 0.077 (0.088) data 0.000 (0.003) loss 1.9843 (1.9245) teacher_loss 0.9040 (0.8462) loss_zs_kd 1.8812 (1.7976) loss_oracle 1.0527 (1.0311) kd_loss 0.9750 (0.9751) acc 59.3750 (70.3551) lr 6.9098e-04 eta 0:11:38
epoch [32/50] batch [240/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.0896 (1.9182) teacher_loss 0.8974 (0.8374) loss_zs_kd 1.7329 (1.8007) loss_oracle 1.0985 (1.0313) kd_loss 1.0823 (0.9776) acc 68.7500 (70.6380) lr 6.9098e-04 eta 0:11:35
epoch [32/50] batch [260/428] time 0.078 (0.088) data 0.000 (0.003) loss 1.7299 (1.9186) teacher_loss 0.5703 (0.8368) loss_zs_kd 1.8031 (1.8019) loss_oracle 1.0445 (1.0317) kd_loss 1.0552 (0.9787) acc 78.1250 (70.5288) lr 6.9098e-04 eta 0:11:31
epoch [32/50] batch [280/428] time 0.095 (0.088) data 0.000 (0.002) loss 2.5299 (1.9200) teacher_loss 1.3986 (0.8363) loss_zs_kd 1.5644 (1.8060) loss_oracle 1.0656 (1.0325) kd_loss 1.0247 (0.9804) acc 43.7500 (70.5134) lr 6.9098e-04 eta 0:11:30
epoch [32/50] batch [300/428] time 0.087 (0.088) data 0.000 (0.002) loss 1.9087 (1.9226) teacher_loss 0.8097 (0.8363) loss_zs_kd 1.5590 (1.8006) loss_oracle 1.0162 (1.0319) kd_loss 0.9974 (0.9831) acc 71.8750 (70.5833) lr 6.9098e-04 eta 0:11:27
epoch [32/50] batch [320/428] time 0.078 (0.088) data 0.000 (0.002) loss 2.0247 (1.9232) teacher_loss 0.8653 (0.8345) loss_zs_kd 1.7545 (1.7995) loss_oracle 1.0504 (1.0323) kd_loss 1.0544 (0.9855) acc 65.6250 (70.5566) lr 6.9098e-04 eta 0:11:24
epoch [32/50] batch [340/428] time 0.081 (0.088) data 0.000 (0.002) loss 1.6576 (1.9241) teacher_loss 0.5215 (0.8322) loss_zs_kd 1.6532 (1.8026) loss_oracle 1.1129 (1.0330) kd_loss 1.0247 (0.9886) acc 81.2500 (70.6985) lr 6.9098e-04 eta 0:11:23
epoch [32/50] batch [360/428] time 0.083 (0.088) data 0.000 (0.002) loss 1.9604 (1.9252) teacher_loss 0.9193 (0.8311) loss_zs_kd 1.6285 (1.7985) loss_oracle 1.0521 (1.0342) kd_loss 0.9359 (0.9906) acc 59.3750 (70.6597) lr 6.9098e-04 eta 0:11:21
epoch [32/50] batch [380/428] time 0.085 (0.088) data 0.000 (0.002) loss 2.2229 (1.9262) teacher_loss 1.1322 (0.8309) loss_zs_kd 1.2260 (1.7991) loss_oracle 1.0210 (1.0344) kd_loss 0.9886 (0.9918) acc 56.2500 (70.7155) lr 6.9098e-04 eta 0:11:18
epoch [32/50] batch [400/428] time 0.080 (0.087) data 0.000 (0.002) loss 2.1964 (1.9261) teacher_loss 1.0667 (0.8295) loss_zs_kd 1.7717 (1.8020) loss_oracle 1.1209 (1.0354) kd_loss 1.0176 (0.9931) acc 68.7500 (70.7734) lr 6.9098e-04 eta 0:11:15
epoch [32/50] batch [420/428] time 0.075 (0.087) data 0.000 (0.002) loss 1.8234 (1.9308) teacher_loss 0.6704 (0.8325) loss_zs_kd 1.5200 (1.8016) loss_oracle 1.1136 (1.0356) kd_loss 1.0417 (0.9947) acc 75.0000 (70.7143) lr 6.9098e-04 eta 0:11:11
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,781
* accuracy: 64.3%
* error: 35.7%
* macro_f1: 51.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,010
* accuracy: 42.4%
* error: 57.6%
* macro_f1: 30.1%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [33/50] batch [20/428] time 0.075 (0.120) data 0.000 (0.032) loss 2.0238 (1.9719) teacher_loss 0.9232 (0.8687) loss_zs_kd 1.3801 (1.6720) loss_oracle 1.0105 (1.0397) kd_loss 0.9995 (0.9992) acc 62.5000 (69.2188) lr 6.3188e-04 eta 0:15:23
epoch [33/50] batch [40/428] time 0.083 (0.100) data 0.000 (0.016) loss 1.9451 (1.9506) teacher_loss 0.8188 (0.8473) loss_zs_kd 1.6535 (1.7295) loss_oracle 1.0538 (1.0372) kd_loss 1.0209 (0.9997) acc 68.7500 (70.4688) lr 6.3188e-04 eta 0:12:48
epoch [33/50] batch [60/428] time 0.104 (0.096) data 0.001 (0.011) loss 1.9717 (1.9430) teacher_loss 0.9523 (0.8349) loss_zs_kd 1.7389 (1.7833) loss_oracle 1.0201 (1.0374) kd_loss 0.9173 (1.0044) acc 62.5000 (71.1458) lr 6.3188e-04 eta 0:12:12
epoch [33/50] batch [80/428] time 0.084 (0.093) data 0.000 (0.008) loss 1.9791 (1.9667) teacher_loss 0.8013 (0.8590) loss_zs_kd 1.4481 (1.7880) loss_oracle 1.1242 (1.0410) kd_loss 1.0654 (1.0036) acc 62.5000 (70.1562) lr 6.3188e-04 eta 0:11:46
epoch [33/50] batch [100/428] time 0.077 (0.091) data 0.000 (0.007) loss 2.2458 (1.9612) teacher_loss 1.1033 (0.8553) loss_zs_kd 1.6040 (1.7908) loss_oracle 0.9884 (1.0404) kd_loss 1.0437 (1.0018) acc 65.6250 (70.6875) lr 6.3188e-04 eta 0:11:31
epoch [33/50] batch [120/428] time 0.086 (0.089) data 0.000 (0.006) loss 1.8267 (1.9630) teacher_loss 0.6996 (0.8567) loss_zs_kd 1.7574 (1.7998) loss_oracle 1.0506 (1.0372) kd_loss 1.0221 (1.0026) acc 75.0000 (70.3906) lr 6.3188e-04 eta 0:11:18
epoch [33/50] batch [140/428] time 0.082 (0.089) data 0.000 (0.005) loss 1.9785 (1.9540) teacher_loss 0.7489 (0.8447) loss_zs_kd 1.6200 (1.8044) loss_oracle 1.0766 (1.0363) kd_loss 1.1219 (1.0057) acc 65.6250 (70.8929) lr 6.3188e-04 eta 0:11:11
epoch [33/50] batch [160/428] time 0.090 (0.089) data 0.000 (0.004) loss 1.9324 (1.9476) teacher_loss 0.7559 (0.8340) loss_zs_kd 2.0260 (1.8125) loss_oracle 1.1093 (1.0380) kd_loss 1.0656 (1.0098) acc 71.8750 (71.4453) lr 6.3188e-04 eta 0:11:08
epoch [33/50] batch [180/428] time 0.081 (0.088) data 0.000 (0.004) loss 2.1085 (1.9546) teacher_loss 0.9399 (0.8374) loss_zs_kd 2.1011 (1.8212) loss_oracle 1.0435 (1.0394) kd_loss 1.0643 (1.0133) acc 68.7500 (71.2500) lr 6.3188e-04 eta 0:11:03
epoch [33/50] batch [200/428] time 0.083 (0.088) data 0.000 (0.003) loss 2.0636 (1.9524) teacher_loss 0.9512 (0.8320) loss_zs_kd 1.6665 (1.8211) loss_oracle 1.0214 (1.0408) kd_loss 1.0103 (1.0163) acc 78.1250 (71.4531) lr 6.3188e-04 eta 0:10:58
epoch [33/50] batch [220/428] time 0.078 (0.088) data 0.000 (0.003) loss 2.1301 (1.9536) teacher_loss 1.0019 (0.8328) loss_zs_kd 1.7404 (1.8178) loss_oracle 1.0244 (1.0410) kd_loss 1.0257 (1.0166) acc 68.7500 (71.4773) lr 6.3188e-04 eta 0:11:01
epoch [33/50] batch [240/428] time 0.090 (0.088) data 0.000 (0.003) loss 1.8642 (1.9529) teacher_loss 0.8743 (0.8323) loss_zs_kd 2.0567 (1.8171) loss_oracle 1.0198 (1.0394) kd_loss 0.8880 (1.0167) acc 75.0000 (71.4974) lr 6.3188e-04 eta 0:10:57
epoch [33/50] batch [260/428] time 0.082 (0.088) data 0.000 (0.003) loss 1.7352 (1.9496) teacher_loss 0.6110 (0.8274) loss_zs_kd 1.6423 (1.8207) loss_oracle 1.0505 (1.0400) kd_loss 1.0191 (1.0182) acc 75.0000 (71.6346) lr 6.3188e-04 eta 0:10:54
epoch [33/50] batch [280/428] time 0.085 (0.088) data 0.000 (0.003) loss 1.9754 (1.9514) teacher_loss 0.8025 (0.8283) loss_zs_kd 1.8168 (1.8268) loss_oracle 1.0754 (1.0413) kd_loss 1.0653 (1.0190) acc 68.7500 (71.5960) lr 6.3188e-04 eta 0:10:51
epoch [33/50] batch [300/428] time 0.081 (0.087) data 0.000 (0.002) loss 2.0819 (1.9514) teacher_loss 0.9730 (0.8271) loss_zs_kd 2.0970 (1.8273) loss_oracle 1.0032 (1.0414) kd_loss 1.0085 (1.0202) acc 68.7500 (71.6354) lr 6.3188e-04 eta 0:10:47
epoch [33/50] batch [320/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.0078 (1.9503) teacher_loss 0.9074 (0.8262) loss_zs_kd 1.8223 (1.8326) loss_oracle 1.0338 (1.0415) kd_loss 0.9970 (1.0199) acc 68.7500 (71.6797) lr 6.3188e-04 eta 0:10:45
epoch [33/50] batch [340/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.7776 (1.9524) teacher_loss 0.6901 (0.8297) loss_zs_kd 1.7962 (1.8343) loss_oracle 1.0685 (1.0411) kd_loss 0.9806 (1.0186) acc 71.8750 (71.4062) lr 6.3188e-04 eta 0:10:42
epoch [33/50] batch [360/428] time 0.091 (0.087) data 0.000 (0.002) loss 1.7518 (1.9500) teacher_loss 0.6495 (0.8283) loss_zs_kd 1.9295 (1.8362) loss_oracle 1.0538 (1.0404) kd_loss 0.9970 (1.0176) acc 71.8750 (71.4149) lr 6.3188e-04 eta 0:10:39
epoch [33/50] batch [380/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.6847 (1.9489) teacher_loss 0.6520 (0.8272) loss_zs_kd 2.0498 (1.8372) loss_oracle 1.0702 (1.0397) kd_loss 0.9257 (1.0177) acc 81.2500 (71.4885) lr 6.3188e-04 eta 0:10:36
epoch [33/50] batch [400/428] time 0.086 (0.087) data 0.000 (0.002) loss 2.0866 (1.9484) teacher_loss 0.9331 (0.8272) loss_zs_kd 1.8605 (1.8380) loss_oracle 1.0356 (1.0396) kd_loss 1.0500 (1.0173) acc 71.8750 (71.5625) lr 6.3188e-04 eta 0:10:34
epoch [33/50] batch [420/428] time 0.076 (0.087) data 0.000 (0.002) loss 1.8507 (1.9457) teacher_loss 0.6843 (0.8257) loss_zs_kd 2.0806 (1.8408) loss_oracle 1.0300 (1.0387) kd_loss 1.0634 (1.0162) acc 75.0000 (71.5327) lr 6.3188e-04 eta 0:10:31
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,787
* accuracy: 64.4%
* error: 35.6%
* macro_f1: 51.5%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,024
* accuracy: 42.7%
* error: 57.3%
* macro_f1: 30.9%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [34/50] batch [20/428] time 0.074 (0.112) data 0.000 (0.034) loss 1.7114 (1.9197) teacher_loss 0.5167 (0.7773) loss_zs_kd 1.8879 (1.8671) loss_oracle 1.0521 (1.0315) kd_loss 1.0895 (1.0392) acc 87.5000 (73.2812) lr 5.7422e-04 eta 0:13:29
epoch [34/50] batch [40/428] time 0.079 (0.095) data 0.000 (0.017) loss 1.9901 (1.9211) teacher_loss 0.9171 (0.7949) loss_zs_kd 2.1396 (1.8764) loss_oracle 1.0252 (1.0368) kd_loss 0.9705 (1.0225) acc 65.6250 (71.2500) lr 5.7422e-04 eta 0:11:27
epoch [34/50] batch [60/428] time 0.074 (0.089) data 0.001 (0.012) loss 1.8057 (1.9022) teacher_loss 0.6583 (0.7781) loss_zs_kd 1.9360 (1.8823) loss_oracle 1.0716 (1.0374) kd_loss 1.0403 (1.0204) acc 81.2500 (72.2396) lr 5.7422e-04 eta 0:10:40
epoch [34/50] batch [80/428] time 0.084 (0.087) data 0.000 (0.009) loss 1.9545 (1.8936) teacher_loss 0.7790 (0.7690) loss_zs_kd 2.0454 (1.8998) loss_oracle 1.0570 (1.0385) kd_loss 1.0697 (1.0207) acc 71.8750 (72.9297) lr 5.7422e-04 eta 0:10:25
epoch [34/50] batch [100/428] time 0.087 (0.085) data 0.000 (0.007) loss 1.8963 (1.8940) teacher_loss 0.8013 (0.7680) loss_zs_kd 2.1457 (1.9053) loss_oracle 1.0370 (1.0352) kd_loss 0.9912 (1.0225) acc 71.8750 (72.6250) lr 5.7422e-04 eta 0:10:10
epoch [34/50] batch [120/428] time 0.070 (0.084) data 0.000 (0.006) loss 1.9031 (1.9080) teacher_loss 0.7927 (0.7818) loss_zs_kd 1.7030 (1.8980) loss_oracle 1.0042 (1.0354) kd_loss 1.0101 (1.0226) acc 68.7500 (71.8750) lr 5.7422e-04 eta 0:10:02
epoch [34/50] batch [140/428] time 0.081 (0.084) data 0.000 (0.005) loss 1.6960 (1.9148) teacher_loss 0.5746 (0.7906) loss_zs_kd 1.9787 (1.8987) loss_oracle 1.0204 (1.0346) kd_loss 1.0194 (1.0208) acc 78.1250 (71.9643) lr 5.7422e-04 eta 0:09:56
epoch [34/50] batch [160/428] time 0.097 (0.084) data 0.000 (0.004) loss 2.2259 (1.9193) teacher_loss 1.1716 (0.7964) loss_zs_kd 1.7101 (1.9085) loss_oracle 1.0965 (1.0346) kd_loss 0.9446 (1.0194) acc 59.3750 (71.7969) lr 5.7422e-04 eta 0:09:54
epoch [34/50] batch [180/428] time 0.077 (0.084) data 0.000 (0.004) loss 1.7739 (1.9244) teacher_loss 0.6516 (0.8024) loss_zs_kd 1.9145 (1.9092) loss_oracle 1.0071 (1.0353) kd_loss 1.0215 (1.0185) acc 68.7500 (71.4931) lr 5.7422e-04 eta 0:09:54
epoch [34/50] batch [200/428] time 0.082 (0.083) data 0.000 (0.004) loss 2.1183 (1.9256) teacher_loss 0.9873 (0.8039) loss_zs_kd 1.6239 (1.9011) loss_oracle 1.0582 (1.0350) kd_loss 1.0252 (1.0182) acc 62.5000 (71.3906) lr 5.7422e-04 eta 0:09:49
epoch [34/50] batch [220/428] time 0.086 (0.084) data 0.000 (0.003) loss 2.0816 (1.9256) teacher_loss 0.9390 (0.8047) loss_zs_kd 2.2872 (1.9033) loss_oracle 1.0309 (1.0349) kd_loss 1.0395 (1.0174) acc 62.5000 (71.2500) lr 5.7422e-04 eta 0:09:49
epoch [34/50] batch [240/428] time 0.086 (0.084) data 0.000 (0.003) loss 1.9047 (1.9228) teacher_loss 0.7688 (0.8009) loss_zs_kd 1.9431 (1.9017) loss_oracle 1.0503 (1.0356) kd_loss 1.0309 (1.0184) acc 65.6250 (71.3151) lr 5.7422e-04 eta 0:09:49
epoch [34/50] batch [260/428] time 0.095 (0.083) data 0.000 (0.003) loss 1.6172 (1.9203) teacher_loss 0.4229 (0.7967) loss_zs_kd 1.6771 (1.9054) loss_oracle 1.1171 (1.0368) kd_loss 1.0826 (1.0199) acc 87.5000 (71.6106) lr 5.7422e-04 eta 0:09:45
epoch [34/50] batch [280/428] time 0.088 (0.084) data 0.000 (0.003) loss 2.2096 (1.9281) teacher_loss 1.0630 (0.8033) loss_zs_kd 1.4516 (1.9037) loss_oracle 1.0069 (1.0377) kd_loss 1.0460 (1.0211) acc 59.3750 (71.4732) lr 5.7422e-04 eta 0:09:44
epoch [34/50] batch [300/428] time 0.086 (0.083) data 0.000 (0.003) loss 1.8541 (1.9250) teacher_loss 0.7254 (0.7978) loss_zs_kd 1.7790 (1.9000) loss_oracle 1.0335 (1.0394) kd_loss 1.0254 (1.0232) acc 78.1250 (71.6667) lr 5.7422e-04 eta 0:09:41
epoch [34/50] batch [320/428] time 0.086 (0.083) data 0.000 (0.002) loss 1.6925 (1.9242) teacher_loss 0.5651 (0.7982) loss_zs_kd 1.8419 (1.8964) loss_oracle 1.0443 (1.0394) kd_loss 1.0230 (1.0220) acc 84.3750 (71.6602) lr 5.7422e-04 eta 0:09:40
epoch [34/50] batch [340/428] time 0.155 (0.083) data 0.000 (0.002) loss 2.1072 (1.9241) teacher_loss 1.0114 (0.7988) loss_zs_kd 1.9215 (1.9021) loss_oracle 1.0335 (1.0394) kd_loss 0.9925 (1.0213) acc 65.6250 (71.7923) lr 5.7422e-04 eta 0:09:37
epoch [34/50] batch [360/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.8765 (1.9232) teacher_loss 0.7069 (0.7983) loss_zs_kd 1.7987 (1.9028) loss_oracle 1.1060 (1.0391) kd_loss 1.0590 (1.0210) acc 75.0000 (71.7535) lr 5.7422e-04 eta 0:09:38
epoch [34/50] batch [380/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.8086 (1.9237) teacher_loss 0.6631 (0.7995) loss_zs_kd 1.8927 (1.8990) loss_oracle 1.0382 (1.0387) kd_loss 1.0417 (1.0203) acc 71.8750 (71.7188) lr 5.7422e-04 eta 0:09:36
epoch [34/50] batch [400/428] time 0.095 (0.084) data 0.000 (0.002) loss 1.9574 (1.9230) teacher_loss 0.8486 (0.7991) loss_zs_kd 1.7527 (1.8885) loss_oracle 1.0090 (1.0380) kd_loss 1.0079 (1.0202) acc 78.1250 (71.8516) lr 5.7422e-04 eta 0:09:35
epoch [34/50] batch [420/428] time 0.078 (0.084) data 0.000 (0.002) loss 1.7583 (1.9217) teacher_loss 0.7175 (0.7993) loss_zs_kd 1.6099 (1.8886) loss_oracle 1.0198 (1.0381) kd_loss 0.9389 (1.0186) acc 75.0000 (71.8378) lr 5.7422e-04 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,725
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 49.8%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,122
* accuracy: 44.8%
* error: 55.2%
* macro_f1: 31.6%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [35/50] batch [20/428] time 0.066 (0.089) data 0.000 (0.026) loss 1.7793 (1.9656) teacher_loss 0.6468 (0.8483) loss_zs_kd 1.5456 (1.9269) loss_oracle 1.0747 (1.0401) kd_loss 1.0251 (1.0133) acc 81.2500 (69.0625) lr 5.1825e-04 eta 0:10:10
epoch [35/50] batch [40/428] time 0.064 (0.077) data 0.000 (0.013) loss 1.8661 (1.9474) teacher_loss 0.7034 (0.8234) loss_zs_kd 1.8642 (1.8516) loss_oracle 1.0804 (1.0364) kd_loss 1.0546 (1.0203) acc 68.7500 (70.8594) lr 5.1825e-04 eta 0:08:41
epoch [35/50] batch [60/428] time 0.063 (0.072) data 0.000 (0.009) loss 1.7651 (1.9126) teacher_loss 0.6441 (0.7902) loss_zs_kd 1.8804 (1.8676) loss_oracle 1.0026 (1.0339) kd_loss 1.0208 (1.0190) acc 78.1250 (72.6562) lr 5.1825e-04 eta 0:08:09
epoch [35/50] batch [80/428] time 0.065 (0.070) data 0.000 (0.007) loss 1.8770 (1.9093) teacher_loss 0.8086 (0.7855) loss_zs_kd 2.2753 (1.8901) loss_oracle 1.0466 (1.0312) kd_loss 0.9638 (1.0206) acc 75.0000 (72.8906) lr 5.1825e-04 eta 0:07:54
epoch [35/50] batch [100/428] time 0.122 (0.071) data 0.000 (0.005) loss 1.8496 (1.9075) teacher_loss 0.7472 (0.7826) loss_zs_kd 1.5815 (1.8910) loss_oracle 1.0736 (1.0321) kd_loss 0.9950 (1.0217) acc 68.7500 (72.6250) lr 5.1825e-04 eta 0:07:57
epoch [35/50] batch [120/428] time 0.060 (0.071) data 0.000 (0.005) loss 2.4755 (1.8901) teacher_loss 1.3076 (0.7642) loss_zs_kd 2.2680 (1.8910) loss_oracle 1.0077 (1.0349) kd_loss 1.0672 (1.0224) acc 62.5000 (73.4375) lr 5.1825e-04 eta 0:07:58
epoch [35/50] batch [140/428] time 0.083 (0.072) data 0.000 (0.004) loss 1.6165 (1.8971) teacher_loss 0.5520 (0.7727) loss_zs_kd 1.6105 (1.8895) loss_oracle 1.0258 (1.0340) kd_loss 0.9618 (1.0210) acc 84.3750 (73.1250) lr 5.1825e-04 eta 0:08:02
epoch [35/50] batch [160/428] time 0.091 (0.073) data 0.000 (0.003) loss 1.9990 (1.9033) teacher_loss 0.8599 (0.7806) loss_zs_kd 1.6577 (1.8715) loss_oracle 1.0604 (1.0357) kd_loss 1.0331 (1.0191) acc 75.0000 (72.6953) lr 5.1825e-04 eta 0:08:09
epoch [35/50] batch [180/428] time 0.082 (0.075) data 0.000 (0.003) loss 1.9749 (1.9049) teacher_loss 0.8855 (0.7857) loss_zs_kd 2.1643 (1.8591) loss_oracle 1.0272 (1.0336) kd_loss 0.9867 (1.0158) acc 62.5000 (72.4306) lr 5.1825e-04 eta 0:08:18
epoch [35/50] batch [200/428] time 0.084 (0.076) data 0.000 (0.003) loss 1.9075 (1.9124) teacher_loss 0.7302 (0.7937) loss_zs_kd 1.7850 (1.8650) loss_oracle 1.0214 (1.0338) kd_loss 1.0751 (1.0153) acc 71.8750 (72.1406) lr 5.1825e-04 eta 0:08:23
epoch [35/50] batch [220/428] time 0.079 (0.076) data 0.000 (0.003) loss 1.6474 (1.9178) teacher_loss 0.5340 (0.7998) loss_zs_kd 2.0977 (1.8652) loss_oracle 1.0458 (1.0349) kd_loss 1.0088 (1.0145) acc 84.3750 (71.9886) lr 5.1825e-04 eta 0:08:26
epoch [35/50] batch [240/428] time 0.079 (0.077) data 0.000 (0.002) loss 2.1617 (1.9190) teacher_loss 1.0804 (0.8006) loss_zs_kd 2.0867 (1.8622) loss_oracle 1.0503 (1.0352) kd_loss 0.9763 (1.0149) acc 56.2500 (72.0312) lr 5.1825e-04 eta 0:08:28
epoch [35/50] batch [260/428] time 0.081 (0.077) data 0.000 (0.002) loss 1.7406 (1.9202) teacher_loss 0.5561 (0.8018) loss_zs_kd 1.9787 (1.8527) loss_oracle 1.0687 (1.0364) kd_loss 1.0776 (1.0148) acc 81.2500 (72.1154) lr 5.1825e-04 eta 0:08:30
epoch [35/50] batch [280/428] time 0.087 (0.078) data 0.000 (0.002) loss 1.6915 (1.9160) teacher_loss 0.5948 (0.7976) loss_zs_kd 1.8572 (1.8547) loss_oracle 1.0417 (1.0375) kd_loss 0.9925 (1.0146) acc 81.2500 (72.2768) lr 5.1825e-04 eta 0:08:31
epoch [35/50] batch [300/428] time 0.083 (0.078) data 0.000 (0.002) loss 1.7465 (1.9198) teacher_loss 0.6189 (0.8016) loss_zs_kd 1.8100 (1.8574) loss_oracle 1.0215 (1.0380) kd_loss 1.0255 (1.0144) acc 84.3750 (72.1562) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [320/428] time 0.086 (0.079) data 0.000 (0.002) loss 1.9424 (1.9218) teacher_loss 0.8505 (0.8039) loss_zs_kd 1.5993 (1.8620) loss_oracle 1.0049 (1.0377) kd_loss 0.9914 (1.0141) acc 71.8750 (71.9922) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [340/428] time 0.086 (0.079) data 0.000 (0.002) loss 1.9280 (1.9239) teacher_loss 0.8317 (0.8052) loss_zs_kd 1.8354 (1.8501) loss_oracle 1.0375 (1.0374) kd_loss 0.9925 (1.0150) acc 65.6250 (71.8566) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [360/428] time 0.081 (0.079) data 0.000 (0.002) loss 2.2132 (1.9270) teacher_loss 1.0459 (0.8073) loss_zs_kd 2.0786 (1.8473) loss_oracle 1.0644 (1.0379) kd_loss 1.0608 (1.0159) acc 56.2500 (71.6146) lr 5.1825e-04 eta 0:08:33
epoch [35/50] batch [380/428] time 0.079 (0.079) data 0.000 (0.002) loss 1.8597 (1.9246) teacher_loss 0.7124 (0.8038) loss_zs_kd 1.8847 (1.8424) loss_oracle 1.0311 (1.0385) kd_loss 1.0442 (1.0170) acc 78.1250 (71.7516) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [400/428] time 0.082 (0.079) data 0.000 (0.002) loss 1.8662 (1.9237) teacher_loss 0.7440 (0.8022) loss_zs_kd 1.8686 (1.8440) loss_oracle 0.9955 (1.0390) kd_loss 1.0227 (1.0177) acc 75.0000 (71.8047) lr 5.1825e-04 eta 0:08:32
epoch [35/50] batch [420/428] time 0.082 (0.080) data 0.000 (0.001) loss 1.9440 (1.9281) teacher_loss 0.8297 (0.8069) loss_zs_kd 1.8548 (1.8429) loss_oracle 1.0686 (1.0396) kd_loss 1.0074 (1.0172) acc 71.8750 (71.5551) lr 5.1825e-04 eta 0:08:31
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,757
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 50.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,085
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 30.8%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [36/50] batch [20/428] time 0.082 (0.115) data 0.000 (0.027) loss 2.0009 (1.9598) teacher_loss 0.8286 (0.8348) loss_zs_kd 1.7855 (1.8164) loss_oracle 1.0921 (1.0523) kd_loss 1.0632 (1.0198) acc 81.2500 (70.4688) lr 4.6417e-04 eta 0:12:13
epoch [36/50] batch [40/428] time 0.085 (0.099) data 0.000 (0.013) loss 1.7090 (1.9505) teacher_loss 0.5419 (0.8351) loss_zs_kd 1.6181 (1.8054) loss_oracle 0.9982 (1.0429) kd_loss 1.0672 (1.0111) acc 87.5000 (70.8594) lr 4.6417e-04 eta 0:10:34
epoch [36/50] batch [60/428] time 0.093 (0.094) data 0.001 (0.009) loss 2.1134 (1.9487) teacher_loss 0.9664 (0.8365) loss_zs_kd 1.7599 (1.7747) loss_oracle 1.0632 (1.0441) kd_loss 1.0406 (1.0078) acc 65.6250 (70.2604) lr 4.6417e-04 eta 0:09:59
epoch [36/50] batch [80/428] time 0.082 (0.092) data 0.000 (0.007) loss 1.9483 (1.9316) teacher_loss 0.8544 (0.8176) loss_zs_kd 2.3696 (1.7729) loss_oracle 1.0470 (1.0463) kd_loss 0.9893 (1.0093) acc 65.6250 (70.7422) lr 4.6417e-04 eta 0:09:42
epoch [36/50] batch [100/428] time 0.077 (0.089) data 0.001 (0.006) loss 2.0591 (1.9258) teacher_loss 0.8839 (0.8097) loss_zs_kd 1.7421 (1.7703) loss_oracle 1.0588 (1.0461) kd_loss 1.0694 (1.0115) acc 65.6250 (71.1875) lr 4.6417e-04 eta 0:09:22
epoch [36/50] batch [120/428] time 0.085 (0.088) data 0.000 (0.005) loss 2.0447 (1.9302) teacher_loss 0.9428 (0.8139) loss_zs_kd 1.8813 (1.7690) loss_oracle 1.0378 (1.0454) kd_loss 0.9981 (1.0117) acc 62.5000 (70.9896) lr 4.6417e-04 eta 0:09:16
epoch [36/50] batch [140/428] time 0.081 (0.088) data 0.000 (0.004) loss 2.1986 (1.9300) teacher_loss 1.0831 (0.8157) loss_zs_kd 2.0282 (1.7720) loss_oracle 0.9937 (1.0425) kd_loss 1.0161 (1.0100) acc 59.3750 (70.9375) lr 4.6417e-04 eta 0:09:10
epoch [36/50] batch [160/428] time 0.076 (0.087) data 0.000 (0.004) loss 1.5720 (1.9216) teacher_loss 0.4508 (0.8072) loss_zs_kd 2.2258 (1.7797) loss_oracle 1.0228 (1.0413) kd_loss 1.0189 (1.0102) acc 84.3750 (71.3477) lr 4.6417e-04 eta 0:09:04
epoch [36/50] batch [180/428] time 0.080 (0.086) data 0.000 (0.003) loss 1.7175 (1.9218) teacher_loss 0.5770 (0.8078) loss_zs_kd 1.7478 (1.7788) loss_oracle 1.0901 (1.0400) kd_loss 1.0316 (1.0099) acc 71.8750 (71.3715) lr 4.6417e-04 eta 0:08:58
epoch [36/50] batch [200/428] time 0.082 (0.086) data 0.000 (0.003) loss 1.8288 (1.9212) teacher_loss 0.7032 (0.8069) loss_zs_kd 1.7513 (1.7839) loss_oracle 1.1016 (1.0417) kd_loss 1.0154 (1.0101) acc 81.2500 (71.5781) lr 4.6417e-04 eta 0:08:56
epoch [36/50] batch [220/428] time 0.161 (0.087) data 0.000 (0.003) loss 2.1956 (1.9236) teacher_loss 1.0343 (0.8086) loss_zs_kd 1.9438 (1.7818) loss_oracle 1.0276 (1.0397) kd_loss 1.0586 (1.0110) acc 59.3750 (71.4205) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [240/428] time 0.089 (0.087) data 0.000 (0.002) loss 1.8462 (1.9274) teacher_loss 0.7896 (0.8123) loss_zs_kd 1.6974 (1.7886) loss_oracle 1.0149 (1.0405) kd_loss 0.9551 (1.0111) acc 87.5000 (71.3542) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [260/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.9118 (1.9270) teacher_loss 0.7698 (0.8119) loss_zs_kd 2.0066 (1.7969) loss_oracle 1.0623 (1.0408) kd_loss 1.0358 (1.0111) acc 71.8750 (71.4423) lr 4.6417e-04 eta 0:08:55
epoch [36/50] batch [280/428] time 0.076 (0.087) data 0.000 (0.002) loss 1.9809 (1.9226) teacher_loss 0.8570 (0.8076) loss_zs_kd 1.5506 (1.8064) loss_oracle 1.0608 (1.0415) kd_loss 1.0179 (1.0108) acc 75.0000 (71.6518) lr 4.6417e-04 eta 0:08:52
epoch [36/50] batch [300/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.9802 (1.9246) teacher_loss 0.9361 (0.8115) loss_zs_kd 1.6992 (1.8105) loss_oracle 0.9749 (1.0413) kd_loss 0.9466 (1.0089) acc 75.0000 (71.6458) lr 4.6417e-04 eta 0:08:48
epoch [36/50] batch [320/428] time 0.088 (0.086) data 0.000 (0.002) loss 1.7168 (1.9271) teacher_loss 0.6530 (0.8150) loss_zs_kd 2.0712 (1.8124) loss_oracle 1.0693 (1.0407) kd_loss 0.9569 (1.0081) acc 78.1250 (71.5723) lr 4.6417e-04 eta 0:08:45
epoch [36/50] batch [340/428] time 0.096 (0.086) data 0.000 (0.002) loss 1.8467 (1.9278) teacher_loss 0.8070 (0.8168) loss_zs_kd 2.1928 (1.8140) loss_oracle 1.0017 (1.0405) kd_loss 0.9395 (1.0070) acc 65.6250 (71.4522) lr 4.6417e-04 eta 0:08:43
epoch [36/50] batch [360/428] time 0.089 (0.086) data 0.001 (0.002) loss 2.0283 (1.9305) teacher_loss 0.9442 (0.8203) loss_zs_kd 1.7254 (1.8141) loss_oracle 1.0376 (1.0407) kd_loss 0.9803 (1.0061) acc 68.7500 (71.3455) lr 4.6417e-04 eta 0:08:41
epoch [36/50] batch [380/428] time 0.080 (0.086) data 0.000 (0.002) loss 2.3477 (1.9341) teacher_loss 1.2337 (0.8251) loss_zs_kd 1.5110 (1.8091) loss_oracle 1.0241 (1.0400) kd_loss 1.0116 (1.0050) acc 62.5000 (71.1266) lr 4.6417e-04 eta 0:08:38
epoch [36/50] batch [400/428] time 0.086 (0.086) data 0.000 (0.002) loss 2.0053 (1.9337) teacher_loss 0.9014 (0.8243) loss_zs_kd 1.7584 (1.8021) loss_oracle 1.0636 (1.0397) kd_loss 0.9975 (1.0054) acc 65.6250 (71.0547) lr 4.6417e-04 eta 0:08:35
epoch [36/50] batch [420/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.9736 (1.9360) teacher_loss 0.8716 (0.8260) loss_zs_kd 2.2306 (1.8016) loss_oracle 1.0281 (1.0403) kd_loss 0.9992 (1.0059) acc 65.6250 (70.9226) lr 4.6417e-04 eta 0:08:33
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,728
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 51.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,294
* accuracy: 48.4%
* error: 51.6%
* macro_f1: 31.9%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [37/50] batch [20/428] time 0.087 (0.112) data 0.000 (0.027) loss 1.7512 (1.8669) teacher_loss 0.5681 (0.7419) loss_zs_kd 2.0002 (1.8125) loss_oracle 1.0267 (1.0321) kd_loss 1.0805 (1.0218) acc 81.2500 (73.1250) lr 4.1221e-04 eta 0:11:11
epoch [37/50] batch [40/428] time 0.079 (0.098) data 0.000 (0.014) loss 2.1067 (1.9494) teacher_loss 0.9464 (0.8252) loss_zs_kd 1.5720 (1.8464) loss_oracle 1.0332 (1.0316) kd_loss 1.0569 (1.0210) acc 65.6250 (70.4688) lr 4.1221e-04 eta 0:09:45
epoch [37/50] batch [60/428] time 0.087 (0.094) data 0.001 (0.009) loss 1.8138 (1.9550) teacher_loss 0.7392 (0.8303) loss_zs_kd 2.2586 (1.8527) loss_oracle 0.9800 (1.0289) kd_loss 0.9766 (1.0218) acc 71.8750 (70.6250) lr 4.1221e-04 eta 0:09:16
epoch [37/50] batch [80/428] time 0.087 (0.092) data 0.000 (0.007) loss 2.4049 (1.9504) teacher_loss 1.3959 (0.8287) loss_zs_kd 2.4600 (1.8785) loss_oracle 1.0442 (1.0302) kd_loss 0.9045 (1.0187) acc 59.3750 (71.0547) lr 4.1221e-04 eta 0:09:02
epoch [37/50] batch [100/428] time 0.076 (0.090) data 0.000 (0.006) loss 1.9223 (1.9459) teacher_loss 0.7924 (0.8228) loss_zs_kd 2.0213 (1.8829) loss_oracle 0.9752 (1.0348) kd_loss 1.0324 (1.0196) acc 75.0000 (71.5000) lr 4.1221e-04 eta 0:08:49
epoch [37/50] batch [120/428] time 0.086 (0.088) data 0.000 (0.005) loss 2.1877 (1.9500) teacher_loss 1.0093 (0.8267) loss_zs_kd 2.4753 (1.8683) loss_oracle 1.0687 (1.0356) kd_loss 1.0715 (1.0198) acc 65.6250 (71.2760) lr 4.1221e-04 eta 0:08:35
epoch [37/50] batch [140/428] time 0.099 (0.088) data 0.001 (0.004) loss 2.1136 (1.9537) teacher_loss 1.0009 (0.8277) loss_zs_kd 2.0120 (1.8601) loss_oracle 1.0883 (1.0366) kd_loss 1.0039 (1.0224) acc 62.5000 (70.9821) lr 4.1221e-04 eta 0:08:32
epoch [37/50] batch [160/428] time 0.091 (0.088) data 0.000 (0.004) loss 1.8381 (1.9436) teacher_loss 0.7482 (0.8175) loss_zs_kd 1.5154 (1.8573) loss_oracle 1.0400 (1.0381) kd_loss 0.9859 (1.0223) acc 71.8750 (71.4648) lr 4.1221e-04 eta 0:08:30
epoch [37/50] batch [180/428] time 0.083 (0.088) data 0.000 (0.003) loss 2.3176 (1.9419) teacher_loss 1.1767 (0.8170) loss_zs_kd 2.1481 (1.8635) loss_oracle 1.0183 (1.0382) kd_loss 1.0391 (1.0211) acc 50.0000 (71.3889) lr 4.1221e-04 eta 0:08:29
epoch [37/50] batch [200/428] time 0.087 (0.088) data 0.000 (0.003) loss 1.7840 (1.9428) teacher_loss 0.6202 (0.8187) loss_zs_kd 1.8247 (1.8694) loss_oracle 1.0695 (1.0378) kd_loss 1.0569 (1.0204) acc 78.1250 (71.2969) lr 4.1221e-04 eta 0:08:28
epoch [37/50] batch [220/428] time 0.089 (0.088) data 0.000 (0.003) loss 1.9967 (1.9410) teacher_loss 0.8807 (0.8165) loss_zs_kd 2.1299 (1.8671) loss_oracle 1.0479 (1.0385) kd_loss 1.0112 (1.0207) acc 65.6250 (71.5341) lr 4.1221e-04 eta 0:08:25
epoch [37/50] batch [240/428] time 0.084 (0.087) data 0.000 (0.003) loss 1.7707 (1.9371) teacher_loss 0.6588 (0.8132) loss_zs_kd 1.6889 (1.8596) loss_oracle 1.0351 (1.0384) kd_loss 1.0083 (1.0200) acc 75.0000 (71.7578) lr 4.1221e-04 eta 0:08:22
epoch [37/50] batch [260/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.9938 (1.9335) teacher_loss 0.7987 (0.8081) loss_zs_kd 1.4113 (1.8526) loss_oracle 1.0604 (1.0388) kd_loss 1.0891 (1.0215) acc 71.8750 (71.8990) lr 4.1221e-04 eta 0:08:20
epoch [37/50] batch [280/428] time 0.091 (0.087) data 0.000 (0.002) loss 1.6314 (1.9303) teacher_loss 0.4943 (0.8051) loss_zs_kd 2.1595 (1.8606) loss_oracle 1.0235 (1.0395) kd_loss 1.0347 (1.0213) acc 84.3750 (72.0312) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [300/428] time 0.095 (0.087) data 0.000 (0.002) loss 1.8985 (1.9315) teacher_loss 0.8001 (0.8062) loss_zs_kd 1.8591 (1.8608) loss_oracle 1.0642 (1.0403) kd_loss 0.9920 (1.0213) acc 71.8750 (71.9167) lr 4.1221e-04 eta 0:08:15
epoch [37/50] batch [320/428] time 0.092 (0.087) data 0.000 (0.002) loss 2.0069 (1.9312) teacher_loss 0.9323 (0.8067) loss_zs_kd 1.6942 (1.8645) loss_oracle 1.0081 (1.0405) kd_loss 0.9738 (1.0205) acc 75.0000 (71.9434) lr 4.1221e-04 eta 0:08:12
epoch [37/50] batch [340/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.4930 (1.9341) teacher_loss 0.3888 (0.8090) loss_zs_kd 2.0287 (1.8638) loss_oracle 1.0000 (1.0402) kd_loss 1.0042 (1.0211) acc 87.5000 (71.8382) lr 4.1221e-04 eta 0:08:14
epoch [37/50] batch [360/428] time 0.084 (0.087) data 0.000 (0.002) loss 2.0296 (1.9339) teacher_loss 0.9658 (0.8087) loss_zs_kd 1.8745 (1.8641) loss_oracle 1.0209 (1.0405) kd_loss 0.9617 (1.0212) acc 68.7500 (71.8837) lr 4.1221e-04 eta 0:08:11
epoch [37/50] batch [380/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.8673 (1.9387) teacher_loss 0.8128 (0.8141) loss_zs_kd 1.7727 (1.8613) loss_oracle 1.0416 (1.0408) kd_loss 0.9503 (1.0204) acc 71.8750 (71.6694) lr 4.1221e-04 eta 0:08:08
epoch [37/50] batch [400/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.8307 (1.9313) teacher_loss 0.6614 (0.8072) loss_zs_kd 1.5712 (1.8584) loss_oracle 1.0344 (1.0406) kd_loss 1.0658 (1.0201) acc 75.0000 (71.9453) lr 4.1221e-04 eta 0:08:06
epoch [37/50] batch [420/428] time 0.082 (0.087) data 0.000 (0.002) loss 2.0599 (1.9322) teacher_loss 0.8984 (0.8080) loss_zs_kd 1.8536 (1.8567) loss_oracle 1.0374 (1.0411) kd_loss 1.0578 (1.0201) acc 68.7500 (72.0238) lr 4.1221e-04 eta 0:08:03
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,774
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 50.3%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,188
* accuracy: 46.2%
* error: 53.8%
* macro_f1: 30.9%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [38/50] batch [20/428] time 0.087 (0.120) data 0.000 (0.031) loss 2.0539 (1.8881) teacher_loss 0.9119 (0.7753) loss_zs_kd 1.5162 (1.7505) loss_oracle 1.0455 (1.0501) kd_loss 1.0374 (1.0078) acc 71.8750 (72.6562) lr 3.6258e-04 eta 0:11:05
epoch [38/50] batch [40/428] time 0.080 (0.102) data 0.000 (0.016) loss 1.8897 (1.8913) teacher_loss 0.7514 (0.7755) loss_zs_kd 1.8239 (1.8101) loss_oracle 1.0453 (1.0445) kd_loss 1.0338 (1.0113) acc 65.6250 (72.5000) lr 3.6258e-04 eta 0:09:20
epoch [38/50] batch [60/428] time 0.074 (0.098) data 0.000 (0.011) loss 2.2827 (1.8989) teacher_loss 1.1676 (0.7798) loss_zs_kd 1.8948 (1.8138) loss_oracle 0.9889 (1.0424) kd_loss 1.0162 (1.0148) acc 65.6250 (72.4479) lr 3.6258e-04 eta 0:09:02
epoch [38/50] batch [80/428] time 0.088 (0.095) data 0.000 (0.008) loss 2.3982 (1.9101) teacher_loss 1.3380 (0.7888) loss_zs_kd 1.7437 (1.8267) loss_oracle 1.0112 (1.0415) kd_loss 0.9591 (1.0171) acc 53.1250 (71.6406) lr 3.6258e-04 eta 0:08:38
epoch [38/50] batch [100/428] time 0.079 (0.093) data 0.000 (0.006) loss 1.5793 (1.9097) teacher_loss 0.4268 (0.7882) loss_zs_kd 1.9353 (1.8322) loss_oracle 1.0579 (1.0405) kd_loss 1.0466 (1.0174) acc 84.3750 (71.9688) lr 3.6258e-04 eta 0:08:25
epoch [38/50] batch [120/428] time 0.080 (0.091) data 0.000 (0.005) loss 1.8261 (1.9027) teacher_loss 0.7434 (0.7847) loss_zs_kd 1.5154 (1.8573) loss_oracle 0.9740 (1.0383) kd_loss 0.9853 (1.0142) acc 75.0000 (72.3958) lr 3.6258e-04 eta 0:08:16
epoch [38/50] batch [140/428] time 0.084 (0.090) data 0.000 (0.005) loss 1.7231 (1.9073) teacher_loss 0.6091 (0.7903) loss_zs_kd 2.0556 (1.8739) loss_oracle 1.0365 (1.0385) kd_loss 1.0104 (1.0131) acc 81.2500 (72.3438) lr 3.6258e-04 eta 0:08:05
epoch [38/50] batch [160/428] time 0.089 (0.089) data 0.000 (0.004) loss 1.7679 (1.9126) teacher_loss 0.6678 (0.7961) loss_zs_kd 2.1327 (1.8758) loss_oracle 1.0530 (1.0376) kd_loss 0.9947 (1.0127) acc 75.0000 (71.9922) lr 3.6258e-04 eta 0:07:59
epoch [38/50] batch [180/428] time 0.091 (0.088) data 0.000 (0.004) loss 1.8462 (1.9124) teacher_loss 0.6727 (0.7959) loss_zs_kd 1.8843 (1.8704) loss_oracle 1.0691 (1.0364) kd_loss 1.0665 (1.0128) acc 71.8750 (72.0660) lr 3.6258e-04 eta 0:07:55
epoch [38/50] batch [200/428] time 0.077 (0.088) data 0.000 (0.003) loss 1.9877 (1.9247) teacher_loss 0.8581 (0.8083) loss_zs_kd 1.6247 (1.8684) loss_oracle 0.9933 (1.0349) kd_loss 1.0303 (1.0128) acc 68.7500 (71.7188) lr 3.6258e-04 eta 0:07:51
epoch [38/50] batch [220/428] time 0.082 (0.087) data 0.000 (0.003) loss 1.9847 (1.9206) teacher_loss 0.8255 (0.8045) loss_zs_kd 1.8933 (1.8692) loss_oracle 1.0545 (1.0332) kd_loss 1.0537 (1.0128) acc 78.1250 (71.9176) lr 3.6258e-04 eta 0:07:45
epoch [38/50] batch [240/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.8751 (1.9208) teacher_loss 0.7307 (0.8053) loss_zs_kd 1.6850 (1.8707) loss_oracle 1.0055 (1.0319) kd_loss 1.0439 (1.0123) acc 75.0000 (71.8750) lr 3.6258e-04 eta 0:07:42
epoch [38/50] batch [260/428] time 0.084 (0.087) data 0.000 (0.003) loss 1.7658 (1.9184) teacher_loss 0.6280 (0.8020) loss_zs_kd 2.2774 (1.8699) loss_oracle 1.0411 (1.0316) kd_loss 1.0336 (1.0132) acc 78.1250 (71.7909) lr 3.6258e-04 eta 0:07:39
epoch [38/50] batch [280/428] time 0.081 (0.087) data 0.000 (0.003) loss 1.8611 (1.9199) teacher_loss 0.7607 (0.8031) loss_zs_kd 2.0612 (1.8710) loss_oracle 1.0013 (1.0321) kd_loss 1.0003 (1.0136) acc 78.1250 (71.7522) lr 3.6258e-04 eta 0:07:37
epoch [38/50] batch [300/428] time 0.073 (0.086) data 0.000 (0.002) loss 1.6747 (1.9224) teacher_loss 0.4968 (0.8053) loss_zs_kd 1.8910 (1.8709) loss_oracle 1.0753 (1.0318) kd_loss 1.0704 (1.0139) acc 93.7500 (71.6875) lr 3.6258e-04 eta 0:07:34
epoch [38/50] batch [320/428] time 0.073 (0.086) data 0.000 (0.002) loss 1.9759 (1.9214) teacher_loss 0.8407 (0.8037) loss_zs_kd 1.8223 (1.8715) loss_oracle 1.0116 (1.0319) kd_loss 1.0340 (1.0146) acc 65.6250 (71.7969) lr 3.6258e-04 eta 0:07:30
epoch [38/50] batch [340/428] time 0.083 (0.086) data 0.000 (0.002) loss 2.1358 (1.9242) teacher_loss 1.0529 (0.8075) loss_zs_kd 1.5655 (1.8671) loss_oracle 1.0227 (1.0317) kd_loss 0.9806 (1.0135) acc 59.3750 (71.7555) lr 3.6258e-04 eta 0:07:28
epoch [38/50] batch [360/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.6520 (1.9276) teacher_loss 0.5289 (0.8109) loss_zs_kd 1.6846 (1.8702) loss_oracle 1.0032 (1.0318) kd_loss 1.0228 (1.0135) acc 84.3750 (71.7014) lr 3.6258e-04 eta 0:07:25
epoch [38/50] batch [380/428] time 0.088 (0.086) data 0.000 (0.002) loss 2.1958 (1.9292) teacher_loss 1.1401 (0.8126) loss_zs_kd 1.7517 (1.8717) loss_oracle 1.0585 (1.0317) kd_loss 0.9498 (1.0134) acc 53.1250 (71.5954) lr 3.6258e-04 eta 0:07:23
epoch [38/50] batch [400/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.7619 (1.9345) teacher_loss 0.5836 (0.8174) loss_zs_kd 1.8911 (1.8732) loss_oracle 1.0530 (1.0312) kd_loss 1.0731 (1.0139) acc 90.6250 (71.5000) lr 3.6258e-04 eta 0:07:20
epoch [38/50] batch [420/428] time 0.072 (0.085) data 0.000 (0.002) loss 1.5852 (1.9319) teacher_loss 0.4664 (0.8147) loss_zs_kd 1.7036 (1.8695) loss_oracle 1.0494 (1.0309) kd_loss 1.0138 (1.0141) acc 87.5000 (71.6369) lr 3.6258e-04 eta 0:07:16
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,143
* accuracy: 45.2%
* error: 54.8%
* macro_f1: 31.4%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [39/50] batch [20/428] time 0.079 (0.116) data 0.000 (0.033) loss 1.9133 (1.9186) teacher_loss 0.7409 (0.8006) loss_zs_kd 1.9954 (1.7967) loss_oracle 1.0146 (1.0097) kd_loss 1.0710 (1.0170) acc 68.7500 (70.1562) lr 3.1545e-04 eta 0:09:55
epoch [39/50] batch [40/428] time 0.063 (0.090) data 0.000 (0.017) loss 2.0165 (1.9468) teacher_loss 0.8547 (0.8271) loss_zs_kd 1.6573 (1.8097) loss_oracle 1.0400 (1.0161) kd_loss 1.0578 (1.0182) acc 75.0000 (70.3125) lr 3.1545e-04 eta 0:07:41
epoch [39/50] batch [60/428] time 0.058 (0.081) data 0.000 (0.011) loss 2.1252 (1.9466) teacher_loss 0.9891 (0.8233) loss_zs_kd 1.8406 (1.8267) loss_oracle 1.0333 (1.0219) kd_loss 1.0327 (1.0211) acc 71.8750 (69.8438) lr 3.1545e-04 eta 0:06:51
epoch [39/50] batch [80/428] time 0.066 (0.076) data 0.000 (0.009) loss 2.2035 (1.9534) teacher_loss 1.0743 (0.8286) loss_zs_kd 2.0289 (1.8430) loss_oracle 0.9947 (1.0256) kd_loss 1.0297 (1.0222) acc 59.3750 (69.8047) lr 3.1545e-04 eta 0:06:24
epoch [39/50] batch [100/428] time 0.062 (0.073) data 0.000 (0.007) loss 1.7039 (1.9498) teacher_loss 0.6197 (0.8289) loss_zs_kd 1.8195 (1.8283) loss_oracle 1.0020 (1.0282) kd_loss 0.9840 (1.0180) acc 75.0000 (69.9688) lr 3.1545e-04 eta 0:06:08
epoch [39/50] batch [120/428] time 0.066 (0.071) data 0.000 (0.006) loss 2.0771 (1.9565) teacher_loss 0.9505 (0.8352) loss_zs_kd 1.5405 (1.8182) loss_oracle 1.0112 (1.0293) kd_loss 1.0255 (1.0183) acc 65.6250 (69.8958) lr 3.1545e-04 eta 0:05:58
epoch [39/50] batch [140/428] time 0.088 (0.073) data 0.000 (0.005) loss 1.9094 (1.9521) teacher_loss 0.7951 (0.8332) loss_zs_kd 1.8608 (1.8184) loss_oracle 1.0809 (1.0298) kd_loss 1.0062 (1.0160) acc 71.8750 (70.2232) lr 3.1545e-04 eta 0:06:03
epoch [39/50] batch [160/428] time 0.087 (0.074) data 0.000 (0.004) loss 1.9494 (1.9435) teacher_loss 0.8629 (0.8257) loss_zs_kd 1.6035 (1.8254) loss_oracle 1.0197 (1.0274) kd_loss 0.9846 (1.0150) acc 71.8750 (70.3711) lr 3.1545e-04 eta 0:06:07
epoch [39/50] batch [180/428] time 0.083 (0.075) data 0.000 (0.004) loss 1.6512 (1.9389) teacher_loss 0.5326 (0.8226) loss_zs_kd 1.7055 (1.8236) loss_oracle 1.0555 (1.0282) kd_loss 1.0131 (1.0135) acc 84.3750 (70.5208) lr 3.1545e-04 eta 0:06:11
epoch [39/50] batch [200/428] time 0.081 (0.076) data 0.000 (0.004) loss 2.1052 (1.9349) teacher_loss 0.9474 (0.8199) loss_zs_kd 1.9525 (1.8345) loss_oracle 1.0034 (1.0280) kd_loss 1.0574 (1.0122) acc 65.6250 (70.7344) lr 3.1545e-04 eta 0:06:14
epoch [39/50] batch [220/428] time 0.080 (0.078) data 0.000 (0.003) loss 1.8138 (1.9381) teacher_loss 0.6855 (0.8231) loss_zs_kd 1.8423 (1.8325) loss_oracle 1.0330 (1.0278) kd_loss 1.0251 (1.0122) acc 78.1250 (70.6108) lr 3.1545e-04 eta 0:06:21
epoch [39/50] batch [240/428] time 0.084 (0.078) data 0.000 (0.003) loss 2.2696 (1.9377) teacher_loss 1.1114 (0.8233) loss_zs_kd 1.8838 (1.8321) loss_oracle 1.0703 (1.0279) kd_loss 1.0511 (1.0116) acc 68.7500 (70.5729) lr 3.1545e-04 eta 0:06:22
epoch [39/50] batch [260/428] time 0.079 (0.078) data 0.000 (0.003) loss 1.9475 (1.9328) teacher_loss 0.8233 (0.8195) loss_zs_kd 1.8069 (1.8318) loss_oracle 1.0621 (1.0279) kd_loss 1.0180 (1.0105) acc 65.6250 (70.7212) lr 3.1545e-04 eta 0:06:22
epoch [39/50] batch [280/428] time 0.074 (0.079) data 0.000 (0.003) loss 1.9247 (1.9301) teacher_loss 0.8174 (0.8177) loss_zs_kd 1.9241 (1.8313) loss_oracle 0.9219 (1.0278) kd_loss 1.0151 (1.0096) acc 71.8750 (70.8371) lr 3.1545e-04 eta 0:06:21
epoch [39/50] batch [300/428] time 0.081 (0.079) data 0.000 (0.002) loss 2.0010 (1.9348) teacher_loss 0.8363 (0.8217) loss_zs_kd 1.6226 (1.8252) loss_oracle 1.0154 (1.0279) kd_loss 1.0631 (1.0103) acc 68.7500 (70.7604) lr 3.1545e-04 eta 0:06:20
epoch [39/50] batch [320/428] time 0.076 (0.079) data 0.000 (0.002) loss 1.8181 (1.9326) teacher_loss 0.6431 (0.8189) loss_zs_kd 1.4652 (1.8252) loss_oracle 1.0476 (1.0285) kd_loss 1.0703 (1.0109) acc 78.1250 (71.0156) lr 3.1545e-04 eta 0:06:21
epoch [39/50] batch [340/428] time 0.081 (0.079) data 0.000 (0.002) loss 2.0125 (1.9336) teacher_loss 0.8649 (0.8185) loss_zs_kd 2.3796 (1.8288) loss_oracle 1.0685 (1.0287) kd_loss 1.0407 (1.0122) acc 62.5000 (70.9743) lr 3.1545e-04 eta 0:06:20
epoch [39/50] batch [360/428] time 0.089 (0.080) data 0.000 (0.002) loss 1.8694 (1.9289) teacher_loss 0.7418 (0.8140) loss_zs_kd 1.9663 (1.8343) loss_oracle 1.0162 (1.0295) kd_loss 1.0260 (1.0119) acc 78.1250 (71.2587) lr 3.1545e-04 eta 0:06:20
epoch [39/50] batch [380/428] time 0.082 (0.080) data 0.000 (0.002) loss 2.1201 (1.9294) teacher_loss 1.0398 (0.8147) loss_zs_kd 2.0173 (1.8333) loss_oracle 0.9852 (1.0298) kd_loss 0.9818 (1.0118) acc 68.7500 (71.3898) lr 3.1545e-04 eta 0:06:19
epoch [39/50] batch [400/428] time 0.085 (0.080) data 0.000 (0.002) loss 2.0860 (1.9311) teacher_loss 0.9758 (0.8162) loss_zs_kd 1.7804 (1.8356) loss_oracle 1.0136 (1.0307) kd_loss 1.0088 (1.0118) acc 62.5000 (71.4375) lr 3.1545e-04 eta 0:06:18
epoch [39/50] batch [420/428] time 0.082 (0.080) data 0.000 (0.002) loss 2.3836 (1.9326) teacher_loss 1.2898 (0.8176) loss_zs_kd 1.9082 (1.8328) loss_oracle 0.9825 (1.0312) kd_loss 0.9955 (1.0119) acc 53.1250 (71.3318) lr 3.1545e-04 eta 0:06:18
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,800
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 51.6%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,115
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 31.4%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [40/50] batch [20/428] time 0.089 (0.117) data 0.000 (0.033) loss 1.9695 (1.8716) teacher_loss 0.8980 (0.7627) loss_zs_kd 1.6265 (1.8693) loss_oracle 1.0478 (1.0401) kd_loss 0.9667 (1.0049) acc 75.0000 (74.2188) lr 2.7103e-04 eta 0:09:08
epoch [40/50] batch [40/428] time 0.083 (0.100) data 0.000 (0.017) loss 2.1286 (1.8639) teacher_loss 0.9800 (0.7490) loss_zs_kd 1.5430 (1.9179) loss_oracle 1.0348 (1.0329) kd_loss 1.0451 (1.0116) acc 65.6250 (74.2188) lr 2.7103e-04 eta 0:07:48
epoch [40/50] batch [60/428] time 0.080 (0.094) data 0.000 (0.011) loss 2.0476 (1.8730) teacher_loss 0.9448 (0.7565) loss_zs_kd 1.4237 (1.9026) loss_oracle 1.0256 (1.0344) kd_loss 1.0003 (1.0131) acc 65.6250 (73.1771) lr 2.7103e-04 eta 0:07:16
epoch [40/50] batch [80/428] time 0.082 (0.091) data 0.000 (0.008) loss 1.8927 (1.8862) teacher_loss 0.7757 (0.7730) loss_zs_kd 2.1456 (1.9155) loss_oracle 1.0448 (1.0367) kd_loss 1.0125 (1.0095) acc 65.6250 (72.8125) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [100/428] time 0.084 (0.089) data 0.000 (0.007) loss 1.7994 (1.8823) teacher_loss 0.6931 (0.7683) loss_zs_kd 1.6521 (1.9078) loss_oracle 1.0662 (1.0389) kd_loss 0.9996 (1.0101) acc 71.8750 (72.7812) lr 2.7103e-04 eta 0:06:49
epoch [40/50] batch [120/428] time 0.076 (0.088) data 0.000 (0.006) loss 1.9796 (1.8889) teacher_loss 0.9152 (0.7770) loss_zs_kd 1.7669 (1.9051) loss_oracle 1.0815 (1.0394) kd_loss 0.9563 (1.0079) acc 68.7500 (72.5521) lr 2.7103e-04 eta 0:06:42
epoch [40/50] batch [140/428] time 0.080 (0.088) data 0.000 (0.005) loss 1.7252 (1.8901) teacher_loss 0.6598 (0.7792) loss_zs_kd 1.8233 (1.8965) loss_oracle 1.0610 (1.0393) kd_loss 0.9593 (1.0070) acc 71.8750 (72.5670) lr 2.7103e-04 eta 0:06:39
epoch [40/50] batch [160/428] time 0.084 (0.087) data 0.001 (0.004) loss 2.4163 (1.8995) teacher_loss 1.3180 (0.7884) loss_zs_kd 2.0530 (1.8917) loss_oracle 1.0347 (1.0396) kd_loss 0.9949 (1.0071) acc 50.0000 (72.1484) lr 2.7103e-04 eta 0:06:36
epoch [40/50] batch [180/428] time 0.078 (0.087) data 0.000 (0.004) loss 2.1479 (1.8982) teacher_loss 1.0805 (0.7865) loss_zs_kd 1.8885 (1.8983) loss_oracle 1.0617 (1.0395) kd_loss 0.9613 (1.0078) acc 65.6250 (72.1528) lr 2.7103e-04 eta 0:06:32
epoch [40/50] batch [200/428] time 0.095 (0.086) data 0.001 (0.004) loss 2.0322 (1.9020) teacher_loss 0.9696 (0.7895) loss_zs_kd 2.1436 (1.9000) loss_oracle 1.0274 (1.0389) kd_loss 0.9598 (1.0086) acc 68.7500 (71.8438) lr 2.7103e-04 eta 0:06:29
epoch [40/50] batch [220/428] time 0.076 (0.086) data 0.000 (0.003) loss 1.7440 (1.9045) teacher_loss 0.6584 (0.7924) loss_zs_kd 2.0572 (1.9037) loss_oracle 1.0610 (1.0386) kd_loss 0.9795 (1.0083) acc 81.2500 (71.8182) lr 2.7103e-04 eta 0:06:24
epoch [40/50] batch [240/428] time 0.084 (0.085) data 0.000 (0.003) loss 2.0216 (1.9067) teacher_loss 1.0010 (0.7958) loss_zs_kd 1.5732 (1.9035) loss_oracle 1.0249 (1.0376) kd_loss 0.9180 (1.0072) acc 62.5000 (71.7448) lr 2.7103e-04 eta 0:06:21
epoch [40/50] batch [260/428] time 0.079 (0.085) data 0.000 (0.003) loss 1.9658 (1.9084) teacher_loss 0.7982 (0.7975) loss_zs_kd 1.5130 (1.9076) loss_oracle 1.0303 (1.0370) kd_loss 1.0646 (1.0072) acc 71.8750 (71.6947) lr 2.7103e-04 eta 0:06:19
epoch [40/50] batch [280/428] time 0.090 (0.085) data 0.000 (0.003) loss 1.9472 (1.9095) teacher_loss 0.8271 (0.7999) loss_zs_kd 1.9250 (1.9030) loss_oracle 1.0598 (1.0368) kd_loss 1.0141 (1.0059) acc 71.8750 (71.5737) lr 2.7103e-04 eta 0:06:16
epoch [40/50] batch [300/428] time 0.080 (0.085) data 0.000 (0.002) loss 2.0116 (1.9108) teacher_loss 0.8807 (0.8013) loss_zs_kd 1.8088 (1.8971) loss_oracle 1.0021 (1.0374) kd_loss 1.0307 (1.0057) acc 71.8750 (71.5938) lr 2.7103e-04 eta 0:06:13
epoch [40/50] batch [320/428] time 0.087 (0.084) data 0.001 (0.002) loss 2.0606 (1.9106) teacher_loss 0.9489 (0.8014) loss_zs_kd 1.6473 (1.8983) loss_oracle 1.0070 (1.0375) kd_loss 1.0110 (1.0054) acc 68.7500 (71.8066) lr 2.7103e-04 eta 0:06:10
epoch [40/50] batch [340/428] time 0.070 (0.085) data 0.000 (0.002) loss 2.0029 (1.9100) teacher_loss 0.9187 (0.8013) loss_zs_kd 1.8843 (1.8945) loss_oracle 1.0210 (1.0378) kd_loss 0.9820 (1.0049) acc 71.8750 (71.8474) lr 2.7103e-04 eta 0:06:10
epoch [40/50] batch [360/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.9971 (1.9070) teacher_loss 0.8827 (0.7981) loss_zs_kd 1.9761 (1.9031) loss_oracle 0.9696 (1.0388) kd_loss 1.0174 (1.0050) acc 65.6250 (71.9618) lr 2.7103e-04 eta 0:06:08
epoch [40/50] batch [380/428] time 0.078 (0.085) data 0.000 (0.002) loss 1.9749 (1.9069) teacher_loss 0.9393 (0.7992) loss_zs_kd 1.7415 (1.9026) loss_oracle 1.0600 (1.0391) kd_loss 0.9295 (1.0039) acc 65.6250 (71.9655) lr 2.7103e-04 eta 0:06:05
epoch [40/50] batch [400/428] time 0.076 (0.084) data 0.000 (0.002) loss 1.8408 (1.9073) teacher_loss 0.7584 (0.8009) loss_zs_kd 1.8392 (1.9000) loss_oracle 1.0180 (1.0388) kd_loss 0.9806 (1.0025) acc 78.1250 (71.9531) lr 2.7103e-04 eta 0:06:03
epoch [40/50] batch [420/428] time 0.070 (0.084) data 0.000 (0.002) loss 1.9072 (1.9079) teacher_loss 0.8231 (0.8022) loss_zs_kd 1.8475 (1.8997) loss_oracle 1.0057 (1.0387) kd_loss 0.9835 (1.0019) acc 71.8750 (71.9196) lr 2.7103e-04 eta 0:06:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,805
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,085
* accuracy: 44.0%
* error: 56.0%
* macro_f1: 31.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [41/50] batch [20/428] time 0.078 (0.117) data 0.000 (0.030) loss 1.8711 (1.8554) teacher_loss 0.8017 (0.7781) loss_zs_kd 1.4732 (1.8461) loss_oracle 1.0334 (1.0350) kd_loss 0.9660 (0.9738) acc 68.7500 (73.1250) lr 2.2949e-04 eta 0:08:19
epoch [41/50] batch [40/428] time 0.088 (0.099) data 0.000 (0.015) loss 1.6914 (1.8776) teacher_loss 0.5837 (0.7932) loss_zs_kd 2.2602 (1.8665) loss_oracle 1.0517 (1.0361) kd_loss 1.0025 (0.9808) acc 84.3750 (72.1875) lr 2.2949e-04 eta 0:06:58
epoch [41/50] batch [60/428] time 0.079 (0.094) data 0.000 (0.010) loss 1.7660 (1.9058) teacher_loss 0.6634 (0.8201) loss_zs_kd 1.9604 (1.8947) loss_oracle 1.0559 (1.0324) kd_loss 0.9970 (0.9824) acc 84.3750 (71.2500) lr 2.2949e-04 eta 0:06:35
epoch [41/50] batch [80/428] time 0.077 (0.092) data 0.000 (0.008) loss 2.0789 (1.9099) teacher_loss 0.9666 (0.8216) loss_zs_kd 2.0646 (1.9041) loss_oracle 1.0370 (1.0331) kd_loss 1.0085 (0.9850) acc 68.7500 (70.7031) lr 2.2949e-04 eta 0:06:28
epoch [41/50] batch [100/428] time 0.080 (0.089) data 0.000 (0.006) loss 1.8757 (1.9101) teacher_loss 0.7456 (0.8181) loss_zs_kd 1.8810 (1.8968) loss_oracle 0.9726 (1.0327) kd_loss 1.0328 (0.9887) acc 68.7500 (70.8125) lr 2.2949e-04 eta 0:06:13
epoch [41/50] batch [120/428] time 0.081 (0.088) data 0.000 (0.005) loss 1.6732 (1.9131) teacher_loss 0.6221 (0.8194) loss_zs_kd 1.7565 (1.8861) loss_oracle 1.0396 (1.0323) kd_loss 0.9471 (0.9905) acc 78.1250 (71.2240) lr 2.2949e-04 eta 0:06:04
epoch [41/50] batch [140/428] time 0.085 (0.087) data 0.000 (0.005) loss 2.1494 (1.9124) teacher_loss 1.0868 (0.8157) loss_zs_kd 2.1905 (1.8902) loss_oracle 1.0440 (1.0336) kd_loss 0.9582 (0.9933) acc 62.5000 (71.0714) lr 2.2949e-04 eta 0:06:00
epoch [41/50] batch [160/428] time 0.084 (0.087) data 0.000 (0.004) loss 1.9312 (1.9124) teacher_loss 0.7718 (0.8151) loss_zs_kd 1.6603 (1.8794) loss_oracle 1.0855 (1.0328) kd_loss 1.0509 (0.9940) acc 75.0000 (70.9766) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [180/428] time 0.083 (0.087) data 0.000 (0.004) loss 1.7853 (1.9104) teacher_loss 0.6548 (0.8117) loss_zs_kd 1.6846 (1.8764) loss_oracle 1.0763 (1.0325) kd_loss 1.0229 (0.9954) acc 78.1250 (71.2153) lr 2.2949e-04 eta 0:05:54
epoch [41/50] batch [200/428] time 0.083 (0.086) data 0.000 (0.003) loss 1.7609 (1.9094) teacher_loss 0.6613 (0.8100) loss_zs_kd 2.3098 (1.8733) loss_oracle 1.1156 (1.0318) kd_loss 0.9881 (0.9962) acc 78.1250 (71.2344) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [220/428] time 0.086 (0.086) data 0.000 (0.003) loss 2.0631 (1.9120) teacher_loss 0.9895 (0.8117) loss_zs_kd 1.8110 (1.8672) loss_oracle 1.0384 (1.0326) kd_loss 0.9698 (0.9970) acc 75.0000 (71.3068) lr 2.2949e-04 eta 0:05:49
epoch [41/50] batch [240/428] time 0.086 (0.085) data 0.000 (0.003) loss 1.6437 (1.9091) teacher_loss 0.5652 (0.8096) loss_zs_kd 1.8011 (1.8609) loss_oracle 1.0328 (1.0335) kd_loss 0.9752 (0.9962) acc 87.5000 (71.3021) lr 2.2949e-04 eta 0:05:44
epoch [41/50] batch [260/428] time 0.091 (0.085) data 0.000 (0.003) loss 2.2550 (1.9123) teacher_loss 1.1787 (0.8107) loss_zs_kd 1.7432 (1.8598) loss_oracle 1.0701 (1.0339) kd_loss 0.9692 (0.9982) acc 62.5000 (71.2620) lr 2.2949e-04 eta 0:05:43
epoch [41/50] batch [280/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.8930 (1.9150) teacher_loss 0.7877 (0.8134) loss_zs_kd 1.4830 (1.8521) loss_oracle 0.9905 (1.0346) kd_loss 1.0062 (0.9981) acc 75.0000 (71.3393) lr 2.2949e-04 eta 0:05:41
epoch [41/50] batch [300/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.9842 (1.9179) teacher_loss 0.8986 (0.8150) loss_zs_kd 1.8148 (1.8459) loss_oracle 1.0236 (1.0342) kd_loss 0.9833 (0.9994) acc 62.5000 (71.2708) lr 2.2949e-04 eta 0:05:39
epoch [41/50] batch [320/428] time 0.076 (0.085) data 0.000 (0.002) loss 1.8969 (1.9179) teacher_loss 0.7732 (0.8146) loss_zs_kd 1.8938 (1.8348) loss_oracle 1.0279 (1.0340) kd_loss 1.0209 (0.9999) acc 71.8750 (71.2988) lr 2.2949e-04 eta 0:05:35
epoch [41/50] batch [340/428] time 0.078 (0.084) data 0.000 (0.002) loss 1.9647 (1.9175) teacher_loss 0.7370 (0.8127) loss_zs_kd 1.6386 (1.8382) loss_oracle 1.0902 (1.0336) kd_loss 1.1187 (1.0014) acc 71.8750 (71.4890) lr 2.2949e-04 eta 0:05:31
epoch [41/50] batch [360/428] time 0.083 (0.084) data 0.000 (0.002) loss 1.6626 (1.9130) teacher_loss 0.4903 (0.8078) loss_zs_kd 1.5294 (1.8341) loss_oracle 1.0529 (1.0336) kd_loss 1.0671 (1.0018) acc 87.5000 (71.7014) lr 2.2949e-04 eta 0:05:29
epoch [41/50] batch [380/428] time 0.094 (0.084) data 0.000 (0.002) loss 1.8421 (1.9111) teacher_loss 0.7437 (0.8064) loss_zs_kd 1.3558 (1.8338) loss_oracle 1.0467 (1.0333) kd_loss 0.9937 (1.0014) acc 68.7500 (71.7516) lr 2.2949e-04 eta 0:05:28
epoch [41/50] batch [400/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.7435 (1.9145) teacher_loss 0.6412 (0.8096) loss_zs_kd 1.8411 (1.8321) loss_oracle 0.9595 (1.0332) kd_loss 1.0064 (1.0015) acc 71.8750 (71.6172) lr 2.2949e-04 eta 0:05:26
epoch [41/50] batch [420/428] time 0.078 (0.084) data 0.000 (0.002) loss 1.9606 (1.9195) teacher_loss 0.8278 (0.8140) loss_zs_kd 2.0923 (1.8357) loss_oracle 1.0525 (1.0332) kd_loss 1.0275 (1.0022) acc 68.7500 (71.4360) lr 2.2949e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 52.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,175
* accuracy: 45.9%
* error: 54.1%
* macro_f1: 31.6%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [42/50] batch [20/428] time 0.082 (0.111) data 0.000 (0.027) loss 1.9833 (1.8680) teacher_loss 0.8684 (0.7520) loss_zs_kd 1.2148 (1.8052) loss_oracle 1.0258 (1.0235) kd_loss 1.0123 (1.0137) acc 62.5000 (74.2188) lr 1.9098e-04 eta 0:07:04
epoch [42/50] batch [40/428] time 0.084 (0.097) data 0.000 (0.014) loss 1.8853 (1.9043) teacher_loss 0.8612 (0.7811) loss_zs_kd 1.9823 (1.7906) loss_oracle 1.0260 (1.0338) kd_loss 0.9215 (1.0199) acc 68.7500 (73.4375) lr 1.9098e-04 eta 0:06:08
epoch [42/50] batch [60/428] time 0.088 (0.093) data 0.000 (0.009) loss 2.2390 (1.9176) teacher_loss 1.1509 (0.7953) loss_zs_kd 1.9367 (1.8095) loss_oracle 1.0070 (1.0375) kd_loss 0.9874 (1.0186) acc 56.2500 (71.8750) lr 1.9098e-04 eta 0:05:51
epoch [42/50] batch [80/428] time 0.082 (0.091) data 0.000 (0.007) loss 1.7855 (1.9261) teacher_loss 0.6726 (0.8014) loss_zs_kd 1.8479 (1.8013) loss_oracle 1.0797 (1.0386) kd_loss 1.0050 (1.0208) acc 71.8750 (71.9531) lr 1.9098e-04 eta 0:05:41
epoch [42/50] batch [100/428] time 0.077 (0.089) data 0.000 (0.006) loss 2.0098 (1.9263) teacher_loss 0.8758 (0.8024) loss_zs_kd 1.6088 (1.8023) loss_oracle 1.0463 (1.0415) kd_loss 1.0293 (1.0198) acc 68.7500 (71.5312) lr 1.9098e-04 eta 0:05:34
epoch [42/50] batch [120/428] time 0.089 (0.088) data 0.000 (0.005) loss 2.1239 (1.9229) teacher_loss 0.9094 (0.7997) loss_zs_kd 1.4961 (1.8111) loss_oracle 1.0927 (1.0416) kd_loss 1.1052 (1.0190) acc 68.7500 (71.8490) lr 1.9098e-04 eta 0:05:29
epoch [42/50] batch [140/428] time 0.093 (0.088) data 0.000 (0.004) loss 2.0318 (1.9309) teacher_loss 0.8771 (0.8087) loss_zs_kd 1.4369 (1.8077) loss_oracle 1.0442 (1.0408) kd_loss 1.0503 (1.0182) acc 68.7500 (71.4062) lr 1.9098e-04 eta 0:05:25
epoch [42/50] batch [160/428] time 0.083 (0.087) data 0.000 (0.004) loss 1.9604 (1.9301) teacher_loss 0.8276 (0.8093) loss_zs_kd 2.1563 (1.8115) loss_oracle 1.0454 (1.0397) kd_loss 1.0282 (1.0168) acc 68.7500 (71.5234) lr 1.9098e-04 eta 0:05:20
epoch [42/50] batch [180/428] time 0.097 (0.087) data 0.001 (0.003) loss 1.9698 (1.9268) teacher_loss 0.8825 (0.8072) loss_zs_kd 1.6849 (1.8159) loss_oracle 0.9591 (1.0392) kd_loss 0.9914 (1.0157) acc 68.7500 (71.4583) lr 1.9098e-04 eta 0:05:18
epoch [42/50] batch [200/428] time 0.106 (0.087) data 0.000 (0.003) loss 1.7588 (1.9210) teacher_loss 0.5882 (0.8017) loss_zs_kd 1.4150 (1.8162) loss_oracle 1.0498 (1.0396) kd_loss 1.0657 (1.0154) acc 81.2500 (71.7344) lr 1.9098e-04 eta 0:05:19
epoch [42/50] batch [220/428] time 0.089 (0.087) data 0.000 (0.003) loss 1.7363 (1.9170) teacher_loss 0.6176 (0.7986) loss_zs_kd 1.7679 (1.8208) loss_oracle 1.0346 (1.0402) kd_loss 1.0152 (1.0144) acc 81.2500 (72.0455) lr 1.9098e-04 eta 0:05:17
epoch [42/50] batch [240/428] time 0.091 (0.087) data 0.000 (0.003) loss 1.8966 (1.9171) teacher_loss 0.7898 (0.7994) loss_zs_kd 1.4896 (1.8167) loss_oracle 1.0475 (1.0403) kd_loss 1.0020 (1.0137) acc 78.1250 (72.0833) lr 1.9098e-04 eta 0:05:15
epoch [42/50] batch [260/428] time 0.092 (0.087) data 0.001 (0.002) loss 2.2002 (1.9145) teacher_loss 1.0608 (0.7973) loss_zs_kd 1.7700 (1.8171) loss_oracle 1.0145 (1.0405) kd_loss 1.0380 (1.0132) acc 68.7500 (72.2236) lr 1.9098e-04 eta 0:05:13
epoch [42/50] batch [280/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.9915 (1.9175) teacher_loss 0.9097 (0.8001) loss_zs_kd 1.7488 (1.8208) loss_oracle 1.0228 (1.0410) kd_loss 0.9795 (1.0132) acc 62.5000 (72.1987) lr 1.9098e-04 eta 0:05:10
epoch [42/50] batch [300/428] time 0.094 (0.087) data 0.001 (0.002) loss 1.8985 (1.9182) teacher_loss 0.7788 (0.8013) loss_zs_kd 1.6675 (1.8208) loss_oracle 0.9983 (1.0402) kd_loss 1.0199 (1.0130) acc 71.8750 (71.9792) lr 1.9098e-04 eta 0:05:09
epoch [42/50] batch [320/428] time 0.085 (0.087) data 0.000 (0.002) loss 2.1124 (1.9211) teacher_loss 0.9692 (0.8040) loss_zs_kd 1.9897 (1.8168) loss_oracle 1.0283 (1.0397) kd_loss 1.0404 (1.0131) acc 62.5000 (71.9141) lr 1.9098e-04 eta 0:05:07
epoch [42/50] batch [340/428] time 0.086 (0.087) data 0.000 (0.002) loss 1.7382 (1.9201) teacher_loss 0.5500 (0.8037) loss_zs_kd 1.9354 (1.8188) loss_oracle 1.0641 (1.0385) kd_loss 1.0819 (1.0125) acc 78.1250 (71.9210) lr 1.9098e-04 eta 0:05:04
epoch [42/50] batch [360/428] time 0.083 (0.087) data 0.000 (0.002) loss 1.6968 (1.9173) teacher_loss 0.5582 (0.8016) loss_zs_kd 1.9283 (1.8216) loss_oracle 0.9839 (1.0379) kd_loss 1.0402 (1.0119) acc 84.3750 (71.9271) lr 1.9098e-04 eta 0:05:02
epoch [42/50] batch [380/428] time 0.090 (0.087) data 0.001 (0.002) loss 1.8602 (1.9174) teacher_loss 0.6881 (0.8006) loss_zs_kd 1.7795 (1.8161) loss_oracle 0.9871 (1.0379) kd_loss 1.0734 (1.0129) acc 68.7500 (71.8997) lr 1.9098e-04 eta 0:05:00
epoch [42/50] batch [400/428] time 0.077 (0.087) data 0.000 (0.002) loss 1.9719 (1.9146) teacher_loss 0.8040 (0.7978) loss_zs_kd 1.9157 (1.8153) loss_oracle 1.0592 (1.0377) kd_loss 1.0620 (1.0130) acc 62.5000 (71.9531) lr 1.9098e-04 eta 0:04:58
epoch [42/50] batch [420/428] time 0.071 (0.086) data 0.000 (0.002) loss 1.7731 (1.9139) teacher_loss 0.6676 (0.7960) loss_zs_kd 1.6960 (1.8120) loss_oracle 1.0476 (1.0383) kd_loss 1.0008 (1.0140) acc 78.1250 (72.0833) lr 1.9098e-04 eta 0:04:56
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,812
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,153
* accuracy: 45.4%
* error: 54.6%
* macro_f1: 30.0%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [43/50] batch [20/428] time 0.077 (0.120) data 0.000 (0.032) loss 2.1084 (1.9061) teacher_loss 0.9997 (0.7804) loss_zs_kd 1.9694 (1.8267) loss_oracle 1.0163 (1.0417) kd_loss 1.0071 (1.0215) acc 56.2500 (74.8438) lr 1.5567e-04 eta 0:06:50
epoch [43/50] batch [40/428] time 0.072 (0.100) data 0.000 (0.016) loss 2.1095 (1.9081) teacher_loss 0.9797 (0.7851) loss_zs_kd 1.7321 (1.8136) loss_oracle 1.0725 (1.0460) kd_loss 1.0226 (1.0185) acc 71.8750 (74.2969) lr 1.5567e-04 eta 0:05:38
epoch [43/50] batch [60/428] time 0.074 (0.095) data 0.000 (0.011) loss 1.8689 (1.8832) teacher_loss 0.7602 (0.7635) loss_zs_kd 1.4705 (1.8130) loss_oracle 0.9982 (1.0456) kd_loss 1.0089 (1.0151) acc 71.8750 (74.2708) lr 1.5567e-04 eta 0:05:18
epoch [43/50] batch [80/428] time 0.093 (0.090) data 0.000 (0.008) loss 1.8588 (1.9014) teacher_loss 0.8179 (0.7834) loss_zs_kd 1.9887 (1.8402) loss_oracle 0.9703 (1.0407) kd_loss 0.9438 (1.0140) acc 68.7500 (73.2422) lr 1.5567e-04 eta 0:05:02
epoch [43/50] batch [100/428] time 0.083 (0.089) data 0.000 (0.007) loss 2.2170 (1.9043) teacher_loss 1.0703 (0.7863) loss_zs_kd 1.7851 (1.8430) loss_oracle 1.0418 (1.0413) kd_loss 1.0425 (1.0138) acc 65.6250 (73.1250) lr 1.5567e-04 eta 0:04:56
epoch [43/50] batch [120/428] time 0.085 (0.089) data 0.000 (0.006) loss 1.9852 (1.9080) teacher_loss 0.8201 (0.7900) loss_zs_kd 1.6917 (1.8533) loss_oracle 1.0579 (1.0392) kd_loss 1.0593 (1.0140) acc 71.8750 (72.5781) lr 1.5567e-04 eta 0:04:53
epoch [43/50] batch [140/428] time 0.081 (0.088) data 0.000 (0.005) loss 2.2221 (1.9095) teacher_loss 1.0386 (0.7919) loss_zs_kd 2.2606 (1.8462) loss_oracle 1.1050 (1.0405) kd_loss 1.0730 (1.0135) acc 62.5000 (72.5000) lr 1.5567e-04 eta 0:04:49
epoch [43/50] batch [160/428] time 0.081 (0.088) data 0.000 (0.004) loss 1.9181 (1.9103) teacher_loss 0.7878 (0.7905) loss_zs_kd 1.5040 (1.8420) loss_oracle 1.0182 (1.0394) kd_loss 1.0285 (1.0158) acc 68.7500 (72.4219) lr 1.5567e-04 eta 0:04:46
epoch [43/50] batch [180/428] time 0.085 (0.088) data 0.000 (0.004) loss 1.9361 (1.9132) teacher_loss 0.7758 (0.7922) loss_zs_kd 1.6288 (1.8390) loss_oracle 1.0133 (1.0399) kd_loss 1.0590 (1.0170) acc 71.8750 (72.1875) lr 1.5567e-04 eta 0:04:43
epoch [43/50] batch [200/428] time 0.082 (0.087) data 0.000 (0.003) loss 2.0907 (1.9094) teacher_loss 0.9564 (0.7904) loss_zs_kd 1.6898 (1.8400) loss_oracle 1.0234 (1.0398) kd_loss 1.0319 (1.0150) acc 62.5000 (72.1562) lr 1.5567e-04 eta 0:04:40
epoch [43/50] batch [220/428] time 0.075 (0.086) data 0.000 (0.003) loss 2.0910 (1.9145) teacher_loss 0.9662 (0.7957) loss_zs_kd 1.6772 (1.8390) loss_oracle 1.0148 (1.0391) kd_loss 1.0233 (1.0149) acc 65.6250 (72.2727) lr 1.5567e-04 eta 0:04:36
epoch [43/50] batch [240/428] time 0.086 (0.086) data 0.000 (0.003) loss 1.9565 (1.9117) teacher_loss 0.7479 (0.7928) loss_zs_kd 1.6706 (1.8413) loss_oracle 1.1060 (1.0397) kd_loss 1.0981 (1.0149) acc 78.1250 (72.3568) lr 1.5567e-04 eta 0:04:33
epoch [43/50] batch [260/428] time 0.084 (0.086) data 0.000 (0.003) loss 1.8970 (1.9157) teacher_loss 0.7367 (0.7965) loss_zs_kd 1.5453 (1.8445) loss_oracle 0.9900 (1.0392) kd_loss 1.0613 (1.0153) acc 65.6250 (72.2716) lr 1.5567e-04 eta 0:04:32
epoch [43/50] batch [280/428] time 0.084 (0.086) data 0.001 (0.003) loss 2.0226 (1.9205) teacher_loss 0.9495 (0.8015) loss_zs_kd 1.7461 (1.8422) loss_oracle 1.0369 (1.0386) kd_loss 0.9694 (1.0152) acc 68.7500 (71.9754) lr 1.5567e-04 eta 0:04:30
epoch [43/50] batch [300/428] time 0.086 (0.086) data 0.000 (0.002) loss 1.7569 (1.9194) teacher_loss 0.6634 (0.7997) loss_zs_kd 2.0915 (1.8411) loss_oracle 1.0596 (1.0385) kd_loss 0.9875 (1.0158) acc 78.1250 (72.0729) lr 1.5567e-04 eta 0:04:27
epoch [43/50] batch [320/428] time 0.077 (0.086) data 0.000 (0.002) loss 2.0229 (1.9180) teacher_loss 0.8822 (0.7977) loss_zs_kd 1.5801 (1.8404) loss_oracle 1.0652 (1.0387) kd_loss 1.0342 (1.0165) acc 68.7500 (72.1680) lr 1.5567e-04 eta 0:04:28
epoch [43/50] batch [340/428] time 0.090 (0.086) data 0.000 (0.002) loss 1.8172 (1.9135) teacher_loss 0.6529 (0.7936) loss_zs_kd 1.8578 (1.8402) loss_oracle 1.0587 (1.0387) kd_loss 1.0584 (1.0161) acc 75.0000 (72.3346) lr 1.5567e-04 eta 0:04:25
epoch [43/50] batch [360/428] time 0.085 (0.086) data 0.000 (0.002) loss 1.8736 (1.9128) teacher_loss 0.8376 (0.7931) loss_zs_kd 1.5215 (1.8389) loss_oracle 1.0455 (1.0385) kd_loss 0.9313 (1.0158) acc 71.8750 (72.3264) lr 1.5567e-04 eta 0:04:23
epoch [43/50] batch [380/428] time 0.080 (0.086) data 0.000 (0.002) loss 1.8669 (1.9129) teacher_loss 0.8019 (0.7935) loss_zs_kd 1.7458 (1.8377) loss_oracle 1.0484 (1.0383) kd_loss 0.9601 (1.0156) acc 75.0000 (72.2862) lr 1.5567e-04 eta 0:04:20
epoch [43/50] batch [400/428] time 0.082 (0.086) data 0.000 (0.002) loss 1.7536 (1.9119) teacher_loss 0.6555 (0.7928) loss_zs_kd 1.6921 (1.8377) loss_oracle 1.0339 (1.0377) kd_loss 0.9947 (1.0154) acc 78.1250 (72.2344) lr 1.5567e-04 eta 0:04:19
epoch [43/50] batch [420/428] time 0.076 (0.086) data 0.000 (0.002) loss 1.9820 (1.9102) teacher_loss 0.8663 (0.7907) loss_zs_kd 1.9095 (1.8335) loss_oracle 0.9919 (1.0378) kd_loss 1.0165 (1.0156) acc 62.5000 (72.4107) lr 1.5567e-04 eta 0:04:17
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,800
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 51.4%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,162
* accuracy: 45.6%
* error: 54.4%
* macro_f1: 31.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [44/50] batch [20/428] time 0.076 (0.106) data 0.000 (0.023) loss 1.9937 (1.9248) teacher_loss 0.8829 (0.8179) loss_zs_kd 1.8483 (1.8483) loss_oracle 1.0416 (1.0463) kd_loss 1.0066 (1.0022) acc 65.6250 (70.3125) lr 1.2369e-04 eta 0:05:15
epoch [44/50] batch [40/428] time 0.082 (0.094) data 0.000 (0.012) loss 1.9274 (1.9024) teacher_loss 0.8388 (0.7861) loss_zs_kd 2.2475 (1.8361) loss_oracle 0.9998 (1.0397) kd_loss 0.9887 (1.0123) acc 75.0000 (72.7344) lr 1.2369e-04 eta 0:04:38
epoch [44/50] batch [60/428] time 0.150 (0.094) data 0.002 (0.008) loss 1.8346 (1.8993) teacher_loss 0.7385 (0.7861) loss_zs_kd 1.5105 (1.8527) loss_oracle 1.0571 (1.0355) kd_loss 0.9905 (1.0096) acc 78.1250 (72.5521) lr 1.2369e-04 eta 0:04:36
epoch [44/50] batch [80/428] time 0.072 (0.090) data 0.000 (0.006) loss 2.1725 (1.8999) teacher_loss 1.0496 (0.7834) loss_zs_kd 1.6481 (1.8414) loss_oracle 1.0500 (1.0359) kd_loss 1.0179 (1.0129) acc 71.8750 (73.3203) lr 1.2369e-04 eta 0:04:22
epoch [44/50] batch [100/428] time 0.083 (0.088) data 0.000 (0.005) loss 1.8625 (1.8997) teacher_loss 0.7312 (0.7822) loss_zs_kd 1.5324 (1.8306) loss_oracle 1.0221 (1.0344) kd_loss 1.0290 (1.0141) acc 62.5000 (73.3750) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [120/428] time 0.089 (0.087) data 0.000 (0.004) loss 2.0982 (1.9111) teacher_loss 0.9822 (0.7937) loss_zs_kd 1.4770 (1.8275) loss_oracle 1.0152 (1.0362) kd_loss 1.0144 (1.0138) acc 68.7500 (73.0208) lr 1.2369e-04 eta 0:04:10
epoch [44/50] batch [140/428] time 0.079 (0.087) data 0.000 (0.004) loss 1.7504 (1.9092) teacher_loss 0.6417 (0.7930) loss_zs_kd 2.2202 (1.8320) loss_oracle 0.9934 (1.0353) kd_loss 1.0093 (1.0127) acc 78.1250 (72.9018) lr 1.2369e-04 eta 0:04:09
epoch [44/50] batch [160/428] time 0.085 (0.087) data 0.000 (0.003) loss 1.8380 (1.9060) teacher_loss 0.6932 (0.7898) loss_zs_kd 1.6516 (1.8437) loss_oracle 1.0495 (1.0347) kd_loss 1.0399 (1.0128) acc 75.0000 (73.0664) lr 1.2369e-04 eta 0:04:06
epoch [44/50] batch [180/428] time 0.090 (0.087) data 0.001 (0.003) loss 1.8779 (1.9121) teacher_loss 0.7890 (0.7971) loss_zs_kd 1.5805 (1.8486) loss_oracle 1.0197 (1.0350) kd_loss 0.9870 (1.0116) acc 68.7500 (72.7083) lr 1.2369e-04 eta 0:04:03
epoch [44/50] batch [200/428] time 0.088 (0.087) data 0.000 (0.003) loss 1.8790 (1.9146) teacher_loss 0.8510 (0.8006) loss_zs_kd 1.7412 (1.8490) loss_oracle 1.0360 (1.0336) kd_loss 0.9244 (1.0106) acc 75.0000 (72.6406) lr 1.2369e-04 eta 0:04:02
epoch [44/50] batch [220/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.8112 (1.9095) teacher_loss 0.6905 (0.7957) loss_zs_kd 2.1530 (1.8494) loss_oracle 1.0487 (1.0347) kd_loss 1.0157 (1.0103) acc 75.0000 (72.6278) lr 1.2369e-04 eta 0:03:59
epoch [44/50] batch [240/428] time 0.098 (0.086) data 0.000 (0.002) loss 1.8782 (1.9094) teacher_loss 0.7564 (0.7947) loss_zs_kd 1.8721 (1.8504) loss_oracle 0.9760 (1.0352) kd_loss 1.0243 (1.0111) acc 62.5000 (72.4089) lr 1.2369e-04 eta 0:03:57
epoch [44/50] batch [260/428] time 0.078 (0.086) data 0.001 (0.002) loss 1.8340 (1.9107) teacher_loss 0.7561 (0.7976) loss_zs_kd 1.5086 (1.8470) loss_oracle 0.9761 (1.0340) kd_loss 0.9803 (1.0098) acc 75.0000 (72.3798) lr 1.2369e-04 eta 0:03:55
epoch [44/50] batch [280/428] time 0.093 (0.086) data 0.000 (0.002) loss 1.7216 (1.9107) teacher_loss 0.6595 (0.7980) loss_zs_kd 1.6212 (1.8486) loss_oracle 1.0066 (1.0340) kd_loss 0.9615 (1.0093) acc 78.1250 (72.2433) lr 1.2369e-04 eta 0:03:53
epoch [44/50] batch [300/428] time 0.077 (0.086) data 0.000 (0.002) loss 1.9442 (1.9114) teacher_loss 0.8163 (0.7983) loss_zs_kd 1.4548 (1.8404) loss_oracle 0.9641 (1.0335) kd_loss 1.0315 (1.0098) acc 59.3750 (72.2604) lr 1.2369e-04 eta 0:03:50
epoch [44/50] batch [320/428] time 0.079 (0.085) data 0.000 (0.002) loss 2.1125 (1.9104) teacher_loss 1.0358 (0.7973) loss_zs_kd 1.4189 (1.8339) loss_oracle 1.0144 (1.0337) kd_loss 0.9753 (1.0098) acc 71.8750 (72.4512) lr 1.2369e-04 eta 0:03:48
epoch [44/50] batch [340/428] time 0.077 (0.085) data 0.000 (0.002) loss 1.9200 (1.9093) teacher_loss 0.7723 (0.7970) loss_zs_kd 1.9829 (1.8352) loss_oracle 1.0762 (1.0335) kd_loss 1.0401 (1.0089) acc 68.7500 (72.4265) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [360/428] time 0.098 (0.085) data 0.000 (0.002) loss 1.8608 (1.9126) teacher_loss 0.7738 (0.8001) loss_zs_kd 1.9717 (1.8314) loss_oracle 1.0514 (1.0339) kd_loss 0.9819 (1.0091) acc 75.0000 (72.3611) lr 1.2369e-04 eta 0:03:44
epoch [44/50] batch [380/428] time 0.090 (0.085) data 0.000 (0.001) loss 1.5599 (1.9126) teacher_loss 0.5002 (0.8000) loss_zs_kd 1.9914 (1.8346) loss_oracle 1.0170 (1.0346) kd_loss 0.9581 (1.0092) acc 90.6250 (72.4013) lr 1.2369e-04 eta 0:03:43
epoch [44/50] batch [400/428] time 0.080 (0.085) data 0.000 (0.001) loss 1.9012 (1.9115) teacher_loss 0.7440 (0.7986) loss_zs_kd 1.9362 (1.8346) loss_oracle 1.0518 (1.0346) kd_loss 1.0521 (1.0095) acc 75.0000 (72.4844) lr 1.2369e-04 eta 0:03:41
epoch [44/50] batch [420/428] time 0.071 (0.085) data 0.000 (0.001) loss 1.8018 (1.9109) teacher_loss 0.6906 (0.7988) loss_zs_kd 1.6925 (1.8392) loss_oracle 0.9950 (1.0349) kd_loss 1.0117 (1.0086) acc 78.1250 (72.5521) lr 1.2369e-04 eta 0:03:39
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,815
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.1%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,108
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.2%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [45/50] batch [20/428] time 0.078 (0.102) data 0.000 (0.028) loss 1.7254 (1.8755) teacher_loss 0.6779 (0.7596) loss_zs_kd 1.7344 (1.8156) loss_oracle 0.9783 (1.0160) kd_loss 0.9497 (1.0143) acc 84.3750 (72.3438) lr 9.5173e-05 eta 0:04:19
epoch [45/50] batch [40/428] time 0.080 (0.090) data 0.000 (0.014) loss 1.8964 (1.8914) teacher_loss 0.7659 (0.7804) loss_zs_kd 1.6646 (1.7925) loss_oracle 0.9630 (1.0234) kd_loss 1.0342 (1.0087) acc 75.0000 (71.3281) lr 9.5173e-05 eta 0:03:48
epoch [45/50] batch [60/428] time 0.088 (0.088) data 0.001 (0.009) loss 2.0011 (1.9117) teacher_loss 0.8743 (0.7952) loss_zs_kd 2.1926 (1.8135) loss_oracle 1.0923 (1.0265) kd_loss 1.0175 (1.0139) acc 78.1250 (71.6146) lr 9.5173e-05 eta 0:03:41
epoch [45/50] batch [80/428] time 0.083 (0.087) data 0.000 (0.007) loss 1.8371 (1.8996) teacher_loss 0.7711 (0.7858) loss_zs_kd 1.4891 (1.8006) loss_oracle 1.0983 (1.0277) kd_loss 0.9562 (1.0111) acc 75.0000 (71.9922) lr 9.5173e-05 eta 0:03:37
epoch [45/50] batch [100/428] time 0.086 (0.087) data 0.000 (0.006) loss 2.0579 (1.8977) teacher_loss 0.9169 (0.7830) loss_zs_kd 1.9515 (1.8027) loss_oracle 1.0164 (1.0299) kd_loss 1.0393 (1.0117) acc 71.8750 (72.6250) lr 9.5173e-05 eta 0:03:34
epoch [45/50] batch [120/428] time 0.077 (0.086) data 0.000 (0.005) loss 1.8784 (1.8937) teacher_loss 0.7624 (0.7783) loss_zs_kd 1.7135 (1.8070) loss_oracle 1.0240 (1.0309) kd_loss 1.0135 (1.0123) acc 68.7500 (73.0729) lr 9.5173e-05 eta 0:03:30
epoch [45/50] batch [140/428] time 0.081 (0.086) data 0.000 (0.004) loss 1.8512 (1.9020) teacher_loss 0.7399 (0.7877) loss_zs_kd 1.8973 (1.8109) loss_oracle 1.0099 (1.0312) kd_loss 1.0103 (1.0112) acc 68.7500 (72.5893) lr 9.5173e-05 eta 0:03:28
epoch [45/50] batch [160/428] time 0.084 (0.086) data 0.000 (0.004) loss 1.8584 (1.9075) teacher_loss 0.7608 (0.7916) loss_zs_kd 1.9602 (1.8103) loss_oracle 1.0059 (1.0318) kd_loss 0.9970 (1.0127) acc 71.8750 (72.4609) lr 9.5173e-05 eta 0:03:26
epoch [45/50] batch [180/428] time 0.088 (0.086) data 0.000 (0.003) loss 1.8785 (1.9119) teacher_loss 0.8116 (0.7946) loss_zs_kd 1.5664 (1.8087) loss_oracle 1.0320 (1.0344) kd_loss 0.9637 (1.0139) acc 75.0000 (72.3611) lr 9.5173e-05 eta 0:03:24
epoch [45/50] batch [200/428] time 0.079 (0.087) data 0.000 (0.003) loss 1.9274 (1.9098) teacher_loss 0.7890 (0.7944) loss_zs_kd 1.8761 (1.8113) loss_oracle 1.0618 (1.0327) kd_loss 1.0323 (1.0122) acc 71.8750 (72.3750) lr 9.5173e-05 eta 0:03:25
epoch [45/50] batch [220/428] time 0.082 (0.087) data 0.000 (0.003) loss 1.8907 (1.9062) teacher_loss 0.8032 (0.7923) loss_zs_kd 1.7922 (1.8171) loss_oracle 1.0718 (1.0313) kd_loss 0.9804 (1.0108) acc 78.1250 (72.4290) lr 9.5173e-05 eta 0:03:23
epoch [45/50] batch [240/428] time 0.086 (0.086) data 0.000 (0.003) loss 1.7851 (1.9076) teacher_loss 0.7100 (0.7929) loss_zs_kd 1.7685 (1.8151) loss_oracle 1.0050 (1.0317) kd_loss 0.9746 (1.0115) acc 71.8750 (72.2786) lr 9.5173e-05 eta 0:03:21
epoch [45/50] batch [260/428] time 0.088 (0.086) data 0.000 (0.002) loss 1.8336 (1.9071) teacher_loss 0.7177 (0.7926) loss_zs_kd 1.6122 (1.8134) loss_oracle 0.9706 (1.0318) kd_loss 1.0188 (1.0113) acc 78.1250 (72.3317) lr 9.5173e-05 eta 0:03:18
epoch [45/50] batch [280/428] time 0.066 (0.085) data 0.000 (0.002) loss 1.6964 (1.9053) teacher_loss 0.5666 (0.7912) loss_zs_kd 2.0384 (1.8128) loss_oracle 1.0677 (1.0318) kd_loss 1.0231 (1.0108) acc 81.2500 (72.4107) lr 9.5173e-05 eta 0:03:14
epoch [45/50] batch [300/428] time 0.061 (0.084) data 0.000 (0.002) loss 2.0125 (1.9052) teacher_loss 0.8372 (0.7910) loss_zs_kd 1.5278 (1.8095) loss_oracle 0.9619 (1.0320) kd_loss 1.0791 (1.0110) acc 68.7500 (72.4271) lr 9.5173e-05 eta 0:03:09
epoch [45/50] batch [320/428] time 0.061 (0.082) data 0.000 (0.002) loss 2.1299 (1.9031) teacher_loss 1.0030 (0.7889) loss_zs_kd 1.4144 (1.8129) loss_oracle 1.0609 (1.0323) kd_loss 1.0208 (1.0110) acc 71.8750 (72.4805) lr 9.5173e-05 eta 0:03:05
epoch [45/50] batch [340/428] time 0.066 (0.081) data 0.000 (0.002) loss 1.7195 (1.9031) teacher_loss 0.6374 (0.7894) loss_zs_kd 1.9880 (1.8120) loss_oracle 1.0816 (1.0332) kd_loss 0.9740 (1.0104) acc 81.2500 (72.4540) lr 9.5173e-05 eta 0:03:00
epoch [45/50] batch [360/428] time 0.069 (0.080) data 0.000 (0.002) loss 2.0607 (1.9044) teacher_loss 0.9280 (0.7899) loss_zs_kd 1.6369 (1.8122) loss_oracle 1.0638 (1.0334) kd_loss 1.0263 (1.0111) acc 56.2500 (72.3524) lr 9.5173e-05 eta 0:02:57
epoch [45/50] batch [380/428] time 0.060 (0.079) data 0.000 (0.002) loss 1.9907 (1.9030) teacher_loss 0.8476 (0.7885) loss_zs_kd 1.8718 (1.8148) loss_oracle 1.0032 (1.0339) kd_loss 1.0428 (1.0111) acc 71.8750 (72.3849) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [400/428] time 0.062 (0.078) data 0.000 (0.002) loss 2.0610 (1.9034) teacher_loss 0.9562 (0.7884) loss_zs_kd 1.8173 (1.8179) loss_oracle 1.0686 (1.0343) kd_loss 0.9979 (1.0116) acc 68.7500 (72.3047) lr 9.5173e-05 eta 0:02:49
epoch [45/50] batch [420/428] time 0.080 (0.078) data 0.000 (0.002) loss 1.7033 (1.9048) teacher_loss 0.5532 (0.7898) loss_zs_kd 1.7112 (1.8175) loss_oracle 1.0978 (1.0340) kd_loss 1.0403 (1.0116) acc 84.3750 (72.2470) lr 9.5173e-05 eta 0:02:47
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,814
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,099
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 31.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [46/50] batch [20/428] time 0.082 (0.117) data 0.000 (0.029) loss 1.9085 (1.9149) teacher_loss 0.8064 (0.7978) loss_zs_kd 1.7725 (1.8686) loss_oracle 1.0372 (1.0459) kd_loss 0.9984 (1.0125) acc 62.5000 (72.9688) lr 7.0224e-05 eta 0:04:08
epoch [46/50] batch [40/428] time 0.078 (0.097) data 0.000 (0.014) loss 2.1091 (1.9111) teacher_loss 0.9715 (0.7969) loss_zs_kd 1.8228 (1.8918) loss_oracle 1.0271 (1.0413) kd_loss 1.0349 (1.0101) acc 68.7500 (72.6562) lr 7.0224e-05 eta 0:03:22
epoch [46/50] batch [60/428] time 0.078 (0.093) data 0.001 (0.010) loss 1.8692 (1.8785) teacher_loss 0.7553 (0.7636) loss_zs_kd 2.0480 (1.8728) loss_oracle 1.0613 (1.0413) kd_loss 1.0078 (1.0107) acc 71.8750 (74.3750) lr 7.0224e-05 eta 0:03:13
epoch [46/50] batch [80/428] time 0.080 (0.091) data 0.000 (0.007) loss 1.7330 (1.8879) teacher_loss 0.5740 (0.7703) loss_zs_kd 1.9516 (1.8480) loss_oracle 1.0388 (1.0410) kd_loss 1.0551 (1.0135) acc 78.1250 (73.6719) lr 7.0224e-05 eta 0:03:07
epoch [46/50] batch [100/428] time 0.083 (0.090) data 0.000 (0.006) loss 1.9252 (1.8928) teacher_loss 0.8154 (0.7755) loss_zs_kd 1.8452 (1.8495) loss_oracle 1.0020 (1.0411) kd_loss 1.0096 (1.0132) acc 81.2500 (73.1875) lr 7.0224e-05 eta 0:03:02
epoch [46/50] batch [120/428] time 0.073 (0.090) data 0.000 (0.005) loss 2.1477 (1.8987) teacher_loss 1.0218 (0.7826) loss_zs_kd 1.9100 (1.8418) loss_oracle 1.0830 (1.0389) kd_loss 1.0176 (1.0123) acc 59.3750 (72.8385) lr 7.0224e-05 eta 0:03:00
epoch [46/50] batch [140/428] time 0.081 (0.089) data 0.000 (0.004) loss 1.9168 (1.9091) teacher_loss 0.8207 (0.7915) loss_zs_kd 1.8123 (1.8511) loss_oracle 1.0277 (1.0401) kd_loss 0.9934 (1.0136) acc 65.6250 (72.4554) lr 7.0224e-05 eta 0:02:57
epoch [46/50] batch [160/428] time 0.083 (0.088) data 0.000 (0.004) loss 2.1408 (1.9131) teacher_loss 0.9778 (0.7956) loss_zs_kd 1.6968 (1.8427) loss_oracle 1.0359 (1.0371) kd_loss 1.0594 (1.0138) acc 59.3750 (72.3438) lr 7.0224e-05 eta 0:02:54
epoch [46/50] batch [180/428] time 0.086 (0.088) data 0.000 (0.003) loss 2.2047 (1.9204) teacher_loss 1.0919 (0.8017) loss_zs_kd 1.9533 (1.8376) loss_oracle 1.0682 (1.0371) kd_loss 1.0059 (1.0150) acc 53.1250 (72.1875) lr 7.0224e-05 eta 0:02:52
epoch [46/50] batch [200/428] time 0.076 (0.088) data 0.000 (0.003) loss 1.5642 (1.9215) teacher_loss 0.5072 (0.8031) loss_zs_kd 1.7847 (1.8369) loss_oracle 1.0448 (1.0357) kd_loss 0.9525 (1.0148) acc 78.1250 (71.8750) lr 7.0224e-05 eta 0:02:50
epoch [46/50] batch [220/428] time 0.087 (0.087) data 0.000 (0.003) loss 2.1527 (1.9217) teacher_loss 1.0327 (0.8046) loss_zs_kd 1.9600 (1.8323) loss_oracle 1.0405 (1.0341) kd_loss 1.0160 (1.0137) acc 53.1250 (71.6193) lr 7.0224e-05 eta 0:02:47
epoch [46/50] batch [240/428] time 0.091 (0.087) data 0.001 (0.003) loss 2.5114 (1.9210) teacher_loss 1.3688 (0.8027) loss_zs_kd 1.7056 (1.8329) loss_oracle 1.0071 (1.0347) kd_loss 1.0419 (1.0148) acc 56.2500 (71.6927) lr 7.0224e-05 eta 0:02:45
epoch [46/50] batch [260/428] time 0.094 (0.087) data 0.000 (0.002) loss 1.8801 (1.9199) teacher_loss 0.7730 (0.8009) loss_zs_kd 1.9654 (1.8330) loss_oracle 1.0889 (1.0356) kd_loss 0.9982 (1.0154) acc 75.0000 (71.8630) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [280/428] time 0.084 (0.087) data 0.000 (0.002) loss 1.9823 (1.9171) teacher_loss 0.8820 (0.7984) loss_zs_kd 2.0309 (1.8282) loss_oracle 0.9460 (1.0347) kd_loss 1.0057 (1.0152) acc 78.1250 (72.0647) lr 7.0224e-05 eta 0:02:41
epoch [46/50] batch [300/428] time 0.090 (0.087) data 0.000 (0.002) loss 1.6535 (1.9155) teacher_loss 0.4788 (0.7967) loss_zs_kd 1.9417 (1.8233) loss_oracle 1.0621 (1.0360) kd_loss 1.0685 (1.0151) acc 78.1250 (72.1250) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [320/428] time 0.068 (0.086) data 0.000 (0.002) loss 2.2728 (1.9148) teacher_loss 1.1054 (0.7956) loss_zs_kd 1.5274 (1.8201) loss_oracle 1.0882 (1.0364) kd_loss 1.0585 (1.0155) acc 65.6250 (72.2461) lr 7.0224e-05 eta 0:02:37
epoch [46/50] batch [340/428] time 0.088 (0.087) data 0.000 (0.002) loss 1.8968 (1.9159) teacher_loss 0.8100 (0.7968) loss_zs_kd 1.8159 (1.8226) loss_oracle 1.0345 (1.0367) kd_loss 0.9834 (1.0154) acc 65.6250 (72.1967) lr 7.0224e-05 eta 0:02:35
epoch [46/50] batch [360/428] time 0.089 (0.087) data 0.000 (0.002) loss 1.9067 (1.9186) teacher_loss 0.7433 (0.7996) loss_zs_kd 1.6050 (1.8207) loss_oracle 1.0218 (1.0373) kd_loss 1.0612 (1.0153) acc 65.6250 (72.1441) lr 7.0224e-05 eta 0:02:34
epoch [46/50] batch [380/428] time 0.085 (0.087) data 0.000 (0.002) loss 1.7983 (1.9164) teacher_loss 0.6396 (0.7972) loss_zs_kd 1.7388 (1.8202) loss_oracle 1.0846 (1.0368) kd_loss 1.0502 (1.0155) acc 75.0000 (72.0724) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [400/428] time 0.091 (0.087) data 0.000 (0.002) loss 2.0827 (1.9164) teacher_loss 0.9702 (0.7969) loss_zs_kd 1.6360 (1.8230) loss_oracle 1.0160 (1.0368) kd_loss 1.0109 (1.0158) acc 68.7500 (72.0078) lr 7.0224e-05 eta 0:02:31
epoch [46/50] batch [420/428] time 0.071 (0.087) data 0.000 (0.002) loss 1.7166 (1.9156) teacher_loss 0.5907 (0.7960) loss_zs_kd 1.4137 (1.8225) loss_oracle 1.0787 (1.0365) kd_loss 1.0180 (1.0159) acc 81.2500 (71.9717) lr 7.0224e-05 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,814
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,108
* accuracy: 44.5%
* error: 55.5%
* macro_f1: 31.2%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [47/50] batch [20/428] time 0.081 (0.113) data 0.000 (0.027) loss 2.0374 (1.9713) teacher_loss 0.8707 (0.8650) loss_zs_kd 1.9367 (1.7216) loss_oracle 1.0790 (1.0325) kd_loss 1.0588 (1.0030) acc 62.5000 (68.1250) lr 4.8943e-05 eta 0:03:10
epoch [47/50] batch [40/428] time 0.082 (0.098) data 0.000 (0.013) loss 1.9230 (1.9500) teacher_loss 0.8643 (0.8440) loss_zs_kd 1.8616 (1.7891) loss_oracle 1.0409 (1.0372) kd_loss 0.9546 (1.0022) acc 65.6250 (69.2188) lr 4.8943e-05 eta 0:02:44
epoch [47/50] batch [60/428] time 0.078 (0.093) data 0.000 (0.009) loss 1.9533 (1.9509) teacher_loss 0.8461 (0.8359) loss_zs_kd 1.3894 (1.7774) loss_oracle 1.0984 (1.0416) kd_loss 0.9973 (1.0108) acc 68.7500 (70.4167) lr 4.8943e-05 eta 0:02:34
epoch [47/50] batch [80/428] time 0.088 (0.091) data 0.000 (0.007) loss 2.1044 (1.9470) teacher_loss 1.0033 (0.8335) loss_zs_kd 1.7227 (1.8111) loss_oracle 1.0788 (1.0410) kd_loss 0.9932 (1.0094) acc 56.2500 (70.0000) lr 4.8943e-05 eta 0:02:28
epoch [47/50] batch [100/428] time 0.083 (0.091) data 0.000 (0.006) loss 2.0806 (1.9284) teacher_loss 1.0068 (0.8161) loss_zs_kd 1.8938 (1.8190) loss_oracle 1.0988 (1.0403) kd_loss 0.9639 (1.0082) acc 65.6250 (70.7812) lr 4.8943e-05 eta 0:02:26
epoch [47/50] batch [120/428] time 0.081 (0.089) data 0.000 (0.005) loss 1.8143 (1.9316) teacher_loss 0.6482 (0.8179) loss_zs_kd 1.6687 (1.8237) loss_oracle 1.0626 (1.0399) kd_loss 1.0598 (1.0096) acc 78.1250 (70.9635) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [140/428] time 0.089 (0.088) data 0.000 (0.004) loss 1.7915 (1.9255) teacher_loss 0.6751 (0.8107) loss_zs_kd 1.4684 (1.8136) loss_oracle 0.9868 (1.0397) kd_loss 1.0176 (1.0109) acc 68.7500 (71.2723) lr 4.8943e-05 eta 0:02:17
epoch [47/50] batch [160/428] time 0.080 (0.087) data 0.000 (0.004) loss 1.7767 (1.9203) teacher_loss 0.6486 (0.8053) loss_zs_kd 1.7389 (1.8151) loss_oracle 1.0526 (1.0389) kd_loss 1.0229 (1.0111) acc 81.2500 (71.7383) lr 4.8943e-05 eta 0:02:15
epoch [47/50] batch [180/428] time 0.093 (0.087) data 0.001 (0.003) loss 1.8206 (1.9159) teacher_loss 0.6912 (0.7995) loss_zs_kd 1.8006 (1.8207) loss_oracle 1.0497 (1.0395) kd_loss 1.0245 (1.0124) acc 71.8750 (71.8403) lr 4.8943e-05 eta 0:02:12
epoch [47/50] batch [200/428] time 0.082 (0.086) data 0.000 (0.003) loss 2.0332 (1.9116) teacher_loss 0.9133 (0.7957) loss_zs_kd 1.7884 (1.8233) loss_oracle 1.0133 (1.0402) kd_loss 1.0186 (1.0119) acc 62.5000 (71.9844) lr 4.8943e-05 eta 0:02:10
epoch [47/50] batch [220/428] time 0.080 (0.086) data 0.000 (0.003) loss 1.6850 (1.9036) teacher_loss 0.5079 (0.7884) loss_zs_kd 1.8162 (1.8237) loss_oracle 1.0183 (1.0399) kd_loss 1.0753 (1.0113) acc 87.5000 (72.2869) lr 4.8943e-05 eta 0:02:08
epoch [47/50] batch [240/428] time 0.083 (0.086) data 0.000 (0.002) loss 1.9037 (1.9030) teacher_loss 0.8306 (0.7887) loss_zs_kd 2.1566 (1.8238) loss_oracle 1.0842 (1.0398) kd_loss 0.9647 (1.0104) acc 78.1250 (72.3828) lr 4.8943e-05 eta 0:02:06
epoch [47/50] batch [260/428] time 0.080 (0.085) data 0.000 (0.002) loss 1.8539 (1.9022) teacher_loss 0.7864 (0.7871) loss_zs_kd 1.6200 (1.8269) loss_oracle 1.0532 (1.0403) kd_loss 0.9622 (1.0111) acc 68.7500 (72.4159) lr 4.8943e-05 eta 0:02:03
epoch [47/50] batch [280/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.8088 (1.9015) teacher_loss 0.7501 (0.7869) loss_zs_kd 2.0820 (1.8370) loss_oracle 1.0034 (1.0393) kd_loss 0.9583 (1.0106) acc 81.2500 (72.5781) lr 4.8943e-05 eta 0:02:01
epoch [47/50] batch [300/428] time 0.093 (0.085) data 0.000 (0.002) loss 2.0819 (1.8982) teacher_loss 0.9790 (0.7826) loss_zs_kd 1.8573 (1.8381) loss_oracle 0.9927 (1.0394) kd_loss 1.0036 (1.0116) acc 68.7500 (72.7188) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [320/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.8535 (1.8950) teacher_loss 0.7408 (0.7801) loss_zs_kd 1.8780 (1.8446) loss_oracle 0.9805 (1.0393) kd_loss 1.0147 (1.0110) acc 78.1250 (72.8125) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [340/428] time 0.082 (0.085) data 0.000 (0.002) loss 1.8326 (1.8968) teacher_loss 0.7856 (0.7824) loss_zs_kd 2.3707 (1.8508) loss_oracle 0.9639 (1.0388) kd_loss 0.9507 (1.0105) acc 75.0000 (72.7574) lr 4.8943e-05 eta 0:01:56
epoch [47/50] batch [360/428] time 0.087 (0.084) data 0.000 (0.002) loss 1.8886 (1.8982) teacher_loss 0.7710 (0.7839) loss_zs_kd 1.4993 (1.8465) loss_oracle 1.0495 (1.0382) kd_loss 1.0127 (1.0105) acc 68.7500 (72.6910) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [380/428] time 0.073 (0.084) data 0.000 (0.002) loss 1.8668 (1.8944) teacher_loss 0.7464 (0.7803) loss_zs_kd 2.0822 (1.8456) loss_oracle 0.9940 (1.0380) kd_loss 1.0210 (1.0103) acc 71.8750 (72.8618) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [400/428] time 0.074 (0.084) data 0.000 (0.002) loss 1.8258 (1.8943) teacher_loss 0.6962 (0.7800) loss_zs_kd 1.9109 (1.8473) loss_oracle 1.0371 (1.0382) kd_loss 1.0259 (1.0105) acc 78.1250 (72.9062) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [420/428] time 0.074 (0.084) data 0.000 (0.002) loss 1.9165 (1.8958) teacher_loss 0.7662 (0.7822) loss_zs_kd 2.2030 (1.8450) loss_oracle 0.9838 (1.0377) kd_loss 1.0520 (1.0098) acc 75.0000 (72.8199) lr 4.8943e-05 eta 0:01:48
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,100
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 31.3%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [48/50] batch [20/428] time 0.079 (0.114) data 0.000 (0.027) loss 1.8426 (1.8281) teacher_loss 0.7649 (0.7177) loss_zs_kd 1.4158 (1.7766) loss_oracle 0.9962 (1.0333) kd_loss 0.9781 (1.0071) acc 71.8750 (75.6250) lr 3.1417e-05 eta 0:02:23
epoch [48/50] batch [40/428] time 0.074 (0.098) data 0.000 (0.014) loss 1.8729 (1.8990) teacher_loss 0.8327 (0.7860) loss_zs_kd 1.5471 (1.8080) loss_oracle 1.0278 (1.0329) kd_loss 0.9374 (1.0097) acc 65.6250 (72.5781) lr 3.1417e-05 eta 0:02:02
epoch [48/50] batch [60/428] time 0.078 (0.089) data 0.001 (0.009) loss 1.7434 (1.8926) teacher_loss 0.6223 (0.7797) loss_zs_kd 1.7186 (1.8073) loss_oracle 1.0849 (1.0356) kd_loss 1.0126 (1.0093) acc 81.2500 (72.8125) lr 3.1417e-05 eta 0:01:49
epoch [48/50] batch [80/428] time 0.083 (0.088) data 0.000 (0.007) loss 1.7324 (1.8926) teacher_loss 0.5863 (0.7789) loss_zs_kd 1.2050 (1.8032) loss_oracle 1.0064 (1.0373) kd_loss 1.0455 (1.0100) acc 75.0000 (73.2812) lr 3.1417e-05 eta 0:01:46
epoch [48/50] batch [100/428] time 0.079 (0.087) data 0.000 (0.006) loss 1.8301 (1.9073) teacher_loss 0.7209 (0.7950) loss_zs_kd 1.9660 (1.7840) loss_oracle 1.0544 (1.0364) kd_loss 1.0038 (1.0086) acc 71.8750 (72.3750) lr 3.1417e-05 eta 0:01:42
epoch [48/50] batch [120/428] time 0.075 (0.085) data 0.000 (0.005) loss 1.6534 (1.9093) teacher_loss 0.5372 (0.7940) loss_zs_kd 1.6516 (1.7896) loss_oracle 1.0369 (1.0385) kd_loss 1.0125 (1.0115) acc 84.3750 (72.3958) lr 3.1417e-05 eta 0:01:39
epoch [48/50] batch [140/428] time 0.085 (0.085) data 0.000 (0.004) loss 1.8223 (1.9081) teacher_loss 0.7287 (0.7945) loss_zs_kd 2.1125 (1.8020) loss_oracle 1.0244 (1.0381) kd_loss 0.9912 (1.0098) acc 78.1250 (72.3438) lr 3.1417e-05 eta 0:01:37
epoch [48/50] batch [160/428] time 0.070 (0.084) data 0.000 (0.004) loss 1.9531 (1.9049) teacher_loss 0.8601 (0.7942) loss_zs_kd 1.9915 (1.8096) loss_oracle 1.0085 (1.0360) kd_loss 0.9922 (1.0071) acc 65.6250 (72.3828) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [180/428] time 0.076 (0.084) data 0.000 (0.003) loss 1.6364 (1.9027) teacher_loss 0.5677 (0.7922) loss_zs_kd 2.2903 (1.8137) loss_oracle 1.0049 (1.0360) kd_loss 0.9682 (1.0069) acc 84.3750 (72.6389) lr 3.1417e-05 eta 0:01:32
epoch [48/50] batch [200/428] time 0.092 (0.084) data 0.000 (0.003) loss 1.8545 (1.9042) teacher_loss 0.6941 (0.7926) loss_zs_kd 1.8493 (1.8291) loss_oracle 1.0616 (1.0358) kd_loss 1.0542 (1.0081) acc 75.0000 (72.4375) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [220/428] time 0.130 (0.085) data 0.001 (0.003) loss 1.8402 (1.9022) teacher_loss 0.7580 (0.7916) loss_zs_kd 1.9834 (1.8285) loss_oracle 1.0045 (1.0350) kd_loss 0.9817 (1.0071) acc 75.0000 (72.6420) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [240/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.9483 (1.9036) teacher_loss 0.8586 (0.7938) loss_zs_kd 2.2388 (1.8361) loss_oracle 1.0047 (1.0347) kd_loss 0.9893 (1.0064) acc 62.5000 (72.4349) lr 3.1417e-05 eta 0:01:27
epoch [48/50] batch [260/428] time 0.083 (0.084) data 0.001 (0.002) loss 2.0891 (1.9066) teacher_loss 0.9723 (0.7957) loss_zs_kd 1.9680 (1.8356) loss_oracle 1.1227 (1.0351) kd_loss 1.0046 (1.0074) acc 62.5000 (72.3197) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [280/428] time 0.084 (0.084) data 0.000 (0.002) loss 1.9802 (1.9069) teacher_loss 0.9187 (0.7955) loss_zs_kd 1.9791 (1.8372) loss_oracle 0.9821 (1.0353) kd_loss 0.9633 (1.0079) acc 68.7500 (72.4107) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [300/428] time 0.079 (0.084) data 0.000 (0.002) loss 1.6495 (1.9051) teacher_loss 0.5811 (0.7929) loss_zs_kd 1.9713 (1.8357) loss_oracle 1.0839 (1.0361) kd_loss 0.9600 (1.0085) acc 81.2500 (72.3750) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [320/428] time 0.082 (0.084) data 0.000 (0.002) loss 1.7670 (1.9064) teacher_loss 0.6676 (0.7938) loss_zs_kd 2.3390 (1.8462) loss_oracle 1.0356 (1.0364) kd_loss 0.9959 (1.0089) acc 81.2500 (72.4121) lr 3.1417e-05 eta 0:01:21
epoch [48/50] batch [340/428] time 0.082 (0.084) data 0.001 (0.002) loss 1.7772 (1.9058) teacher_loss 0.6492 (0.7922) loss_zs_kd 1.8857 (1.8453) loss_oracle 1.0955 (1.0360) kd_loss 1.0184 (1.0100) acc 81.2500 (72.3713) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [360/428] time 0.091 (0.084) data 0.000 (0.002) loss 1.8614 (1.9034) teacher_loss 0.7370 (0.7903) loss_zs_kd 1.5839 (1.8433) loss_oracle 1.0562 (1.0355) kd_loss 1.0188 (1.0095) acc 68.7500 (72.4219) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [380/428] time 0.079 (0.084) data 0.000 (0.002) loss 2.0184 (1.9014) teacher_loss 0.9182 (0.7884) loss_zs_kd 2.1916 (1.8436) loss_oracle 1.0575 (1.0359) kd_loss 0.9944 (1.0094) acc 65.6250 (72.4589) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [400/428] time 0.074 (0.084) data 0.000 (0.002) loss 1.8392 (1.9032) teacher_loss 0.7243 (0.7902) loss_zs_kd 1.9035 (1.8447) loss_oracle 1.0198 (1.0355) kd_loss 1.0129 (1.0094) acc 68.7500 (72.3359) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [420/428] time 0.086 (0.084) data 0.000 (0.002) loss 1.8242 (1.9029) teacher_loss 0.7340 (0.7904) loss_zs_kd 1.8497 (1.8456) loss_oracle 1.0129 (1.0355) kd_loss 0.9890 (1.0090) acc 68.7500 (72.3289) lr 3.1417e-05 eta 0:01:12
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,809
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,099
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 31.1%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [49/50] batch [20/428] time 0.080 (0.105) data 0.000 (0.024) loss 1.6716 (1.9248) teacher_loss 0.6157 (0.8106) loss_zs_kd 1.6923 (1.8792) loss_oracle 1.0639 (1.0331) kd_loss 0.9495 (1.0109) acc 84.3750 (72.8125) lr 1.7713e-05 eta 0:01:28
epoch [49/50] batch [40/428] time 0.086 (0.095) data 0.000 (0.012) loss 1.5528 (1.9318) teacher_loss 0.4860 (0.8179) loss_zs_kd 2.1711 (1.8744) loss_oracle 1.0768 (1.0336) kd_loss 0.9591 (1.0105) acc 87.5000 (70.7031) lr 1.7713e-05 eta 0:01:17
epoch [49/50] batch [60/428] time 0.085 (0.091) data 0.001 (0.008) loss 1.6813 (1.9316) teacher_loss 0.5362 (0.8174) loss_zs_kd 1.7395 (1.8445) loss_oracle 1.0840 (1.0348) kd_loss 1.0367 (1.0107) acc 87.5000 (71.3021) lr 1.7713e-05 eta 0:01:12
epoch [49/50] batch [80/428] time 0.078 (0.090) data 0.000 (0.006) loss 2.1922 (1.9424) teacher_loss 1.0491 (0.8263) loss_zs_kd 1.8660 (1.8278) loss_oracle 1.0647 (1.0359) kd_loss 1.0367 (1.0125) acc 71.8750 (71.3672) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [100/428] time 0.084 (0.087) data 0.000 (0.005) loss 1.8218 (1.9494) teacher_loss 0.6930 (0.8326) loss_zs_kd 1.8470 (1.8301) loss_oracle 1.0483 (1.0348) kd_loss 1.0240 (1.0133) acc 71.8750 (71.3438) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [120/428] time 0.082 (0.087) data 0.000 (0.004) loss 1.8967 (1.9442) teacher_loss 0.7683 (0.8303) loss_zs_kd 1.7233 (1.8125) loss_oracle 1.0478 (1.0345) kd_loss 1.0236 (1.0105) acc 75.0000 (71.1458) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [140/428] time 0.073 (0.086) data 0.000 (0.004) loss 2.1322 (1.9499) teacher_loss 1.0227 (0.8352) loss_zs_kd 1.8982 (1.8120) loss_oracle 1.0907 (1.0357) kd_loss 1.0004 (1.0111) acc 65.6250 (70.7812) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [160/428] time 0.077 (0.086) data 0.000 (0.003) loss 1.8495 (1.9347) teacher_loss 0.7635 (0.8195) loss_zs_kd 2.1145 (1.8180) loss_oracle 1.0489 (1.0365) kd_loss 0.9811 (1.0115) acc 78.1250 (71.5039) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [180/428] time 0.096 (0.086) data 0.000 (0.003) loss 1.8387 (1.9319) teacher_loss 0.7002 (0.8156) loss_zs_kd 1.9400 (1.8145) loss_oracle 1.0763 (1.0374) kd_loss 1.0309 (1.0126) acc 75.0000 (71.7014) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [200/428] time 0.081 (0.086) data 0.000 (0.003) loss 1.9225 (1.9237) teacher_loss 0.7891 (0.8085) loss_zs_kd 1.8373 (1.8168) loss_oracle 1.0023 (1.0361) kd_loss 1.0332 (1.0115) acc 65.6250 (72.0156) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [220/428] time 0.081 (0.086) data 0.000 (0.002) loss 1.5740 (1.9152) teacher_loss 0.4507 (0.8006) loss_zs_kd 1.9688 (1.8183) loss_oracle 1.0754 (1.0370) kd_loss 1.0157 (1.0109) acc 87.5000 (72.2727) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [240/428] time 0.091 (0.085) data 0.000 (0.002) loss 1.8494 (1.9103) teacher_loss 0.7269 (0.7960) loss_zs_kd 1.8647 (1.8160) loss_oracle 1.0502 (1.0374) kd_loss 1.0175 (1.0105) acc 71.8750 (72.2786) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [260/428] time 0.080 (0.085) data 0.000 (0.002) loss 1.8966 (1.9084) teacher_loss 0.8314 (0.7940) loss_zs_kd 1.8824 (1.8201) loss_oracle 1.0140 (1.0372) kd_loss 0.9638 (1.0108) acc 75.0000 (72.3558) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [280/428] time 0.081 (0.085) data 0.000 (0.002) loss 1.7458 (1.9095) teacher_loss 0.6521 (0.7949) loss_zs_kd 1.8040 (1.8267) loss_oracle 1.0428 (1.0364) kd_loss 0.9894 (1.0109) acc 84.3750 (72.4777) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [300/428] time 0.079 (0.085) data 0.000 (0.002) loss 1.6312 (1.9069) teacher_loss 0.5021 (0.7921) loss_zs_kd 2.1074 (1.8277) loss_oracle 1.0716 (1.0370) kd_loss 1.0219 (1.0111) acc 87.5000 (72.5208) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [320/428] time 0.086 (0.085) data 0.000 (0.002) loss 1.9127 (1.9067) teacher_loss 0.8002 (0.7921) loss_zs_kd 1.8233 (1.8263) loss_oracle 0.9906 (1.0378) kd_loss 1.0134 (1.0108) acc 71.8750 (72.4219) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [340/428] time 0.084 (0.085) data 0.000 (0.002) loss 1.5893 (1.9041) teacher_loss 0.4764 (0.7889) loss_zs_kd 2.3425 (1.8345) loss_oracle 1.1208 (1.0380) kd_loss 1.0008 (1.0114) acc 84.3750 (72.5092) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [360/428] time 0.084 (0.086) data 0.000 (0.002) loss 1.6175 (1.9034) teacher_loss 0.5093 (0.7883) loss_zs_kd 1.7454 (1.8347) loss_oracle 0.9964 (1.0376) kd_loss 1.0086 (1.0114) acc 87.5000 (72.5000) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [380/428] time 0.089 (0.085) data 0.000 (0.002) loss 1.5161 (1.9048) teacher_loss 0.3889 (0.7900) loss_zs_kd 1.5161 (1.8379) loss_oracle 1.0139 (1.0371) kd_loss 1.0258 (1.0111) acc 84.3750 (72.5082) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [400/428] time 0.085 (0.085) data 0.000 (0.001) loss 1.9485 (1.9013) teacher_loss 0.8536 (0.7860) loss_zs_kd 1.6253 (1.8408) loss_oracle 1.0471 (1.0374) kd_loss 0.9902 (1.0115) acc 71.8750 (72.5234) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [420/428] time 0.084 (0.085) data 0.000 (0.001) loss 1.7249 (1.9016) teacher_loss 0.6760 (0.7870) loss_zs_kd 1.8897 (1.8421) loss_oracle 1.0101 (1.0373) kd_loss 0.9480 (1.0109) acc 78.1250 (72.5446) lr 1.7713e-05 eta 0:00:37
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,807
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 51.9%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,098
* accuracy: 44.3%
* error: 55.7%
* macro_f1: 31.1%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
epoch [50/50] batch [20/428] time 0.086 (0.107) data 0.000 (0.023) loss 2.0549 (1.9106) teacher_loss 0.9317 (0.8005) loss_zs_kd 1.6874 (1.7164) loss_oracle 1.0381 (1.0320) kd_loss 1.0194 (1.0069) acc 68.7500 (72.8125) lr 7.8853e-06 eta 0:00:43
epoch [50/50] batch [40/428] time 0.083 (0.097) data 0.000 (0.012) loss 2.0346 (1.9111) teacher_loss 0.8879 (0.8037) loss_zs_kd 2.0760 (1.7944) loss_oracle 1.0606 (1.0265) kd_loss 1.0407 (1.0047) acc 65.6250 (71.8750) lr 7.8853e-06 eta 0:00:37
epoch [50/50] batch [60/428] time 0.082 (0.092) data 0.001 (0.008) loss 1.6835 (1.9143) teacher_loss 0.5246 (0.8072) loss_zs_kd 1.6462 (1.8046) loss_oracle 1.0434 (1.0320) kd_loss 1.0546 (1.0039) acc 84.3750 (72.2396) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [80/428] time 0.151 (0.091) data 0.001 (0.006) loss 2.0232 (1.9143) teacher_loss 0.9153 (0.8049) loss_zs_kd 1.9530 (1.8127) loss_oracle 1.0534 (1.0319) kd_loss 1.0026 (1.0061) acc 62.5000 (72.4219) lr 7.8853e-06 eta 0:00:31
epoch [50/50] batch [100/428] time 0.087 (0.091) data 0.000 (0.005) loss 1.9519 (1.9093) teacher_loss 0.8675 (0.7981) loss_zs_kd 1.8916 (1.8153) loss_oracle 0.9895 (1.0332) kd_loss 0.9855 (1.0079) acc 65.6250 (72.5000) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [120/428] time 0.084 (0.090) data 0.000 (0.004) loss 1.6555 (1.8990) teacher_loss 0.5439 (0.7880) loss_zs_kd 2.0757 (1.8243) loss_oracle 1.0204 (1.0349) kd_loss 1.0096 (1.0075) acc 84.3750 (72.8906) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [140/428] time 0.083 (0.089) data 0.000 (0.004) loss 2.2353 (1.9065) teacher_loss 1.1221 (0.7946) loss_zs_kd 1.8408 (1.8259) loss_oracle 1.0180 (1.0358) kd_loss 1.0115 (1.0083) acc 62.5000 (72.7679) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [160/428] time 0.087 (0.089) data 0.000 (0.003) loss 1.8962 (1.9101) teacher_loss 0.8349 (0.7985) loss_zs_kd 2.2214 (1.8344) loss_oracle 1.0323 (1.0348) kd_loss 0.9581 (1.0080) acc 71.8750 (72.8125) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [180/428] time 0.114 (0.088) data 0.000 (0.003) loss 2.0757 (1.9141) teacher_loss 0.8835 (0.8018) loss_zs_kd 1.4994 (1.8282) loss_oracle 1.0085 (1.0339) kd_loss 1.0913 (1.0089) acc 68.7500 (72.4132) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [200/428] time 0.082 (0.088) data 0.000 (0.003) loss 1.8983 (1.9137) teacher_loss 0.7382 (0.8009) loss_zs_kd 1.9205 (1.8281) loss_oracle 1.0175 (1.0350) kd_loss 1.0584 (1.0093) acc 75.0000 (72.4688) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [220/428] time 0.085 (0.088) data 0.000 (0.002) loss 1.8166 (1.9162) teacher_loss 0.6830 (0.8031) loss_zs_kd 1.4724 (1.8243) loss_oracle 1.0974 (1.0348) kd_loss 1.0238 (1.0096) acc 87.5000 (72.2017) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [240/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.9147 (1.9170) teacher_loss 0.7605 (0.8029) loss_zs_kd 1.8202 (1.8266) loss_oracle 1.0307 (1.0351) kd_loss 1.0511 (1.0106) acc 68.7500 (72.1224) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [260/428] time 0.082 (0.087) data 0.000 (0.002) loss 1.8662 (1.9208) teacher_loss 0.7697 (0.8077) loss_zs_kd 1.7572 (1.8199) loss_oracle 0.9717 (1.0346) kd_loss 0.9993 (1.0096) acc 59.3750 (71.8990) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [280/428] time 0.079 (0.087) data 0.000 (0.002) loss 1.7761 (1.9137) teacher_loss 0.6854 (0.8010) loss_zs_kd 2.4263 (1.8238) loss_oracle 0.9925 (1.0349) kd_loss 0.9915 (1.0092) acc 68.7500 (72.0982) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [300/428] time 0.071 (0.086) data 0.000 (0.002) loss 2.0866 (1.9130) teacher_loss 0.9358 (0.7994) loss_zs_kd 1.3412 (1.8246) loss_oracle 1.0428 (1.0348) kd_loss 1.0465 (1.0102) acc 65.6250 (72.1562) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [320/428] time 0.078 (0.086) data 0.000 (0.002) loss 2.3436 (1.9138) teacher_loss 1.2145 (0.8003) loss_zs_kd 1.9023 (1.8257) loss_oracle 1.0269 (1.0350) kd_loss 1.0264 (1.0099) acc 68.7500 (72.1387) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [340/428] time 0.088 (0.085) data 0.000 (0.002) loss 2.2999 (1.9171) teacher_loss 1.2225 (0.8044) loss_zs_kd 1.7629 (1.8253) loss_oracle 1.0393 (1.0352) kd_loss 0.9735 (1.0092) acc 50.0000 (71.9301) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [360/428] time 0.089 (0.085) data 0.000 (0.002) loss 1.7092 (1.9167) teacher_loss 0.5808 (0.8044) loss_zs_kd 1.9349 (1.8251) loss_oracle 1.0618 (1.0353) kd_loss 1.0223 (1.0087) acc 71.8750 (71.9271) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [380/428] time 0.082 (0.085) data 0.000 (0.001) loss 2.1493 (1.9144) teacher_loss 1.0730 (0.8026) loss_zs_kd 1.5998 (1.8286) loss_oracle 1.0395 (1.0359) kd_loss 0.9724 (1.0082) acc 71.8750 (71.9737) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [400/428] time 0.086 (0.085) data 0.000 (0.001) loss 1.9853 (1.9089) teacher_loss 0.8742 (0.7970) loss_zs_kd 1.9372 (1.8322) loss_oracle 1.0110 (1.0361) kd_loss 1.0100 (1.0083) acc 71.8750 (72.2031) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [420/428] time 0.083 (0.085) data 0.000 (0.001) loss 1.7675 (1.9081) teacher_loss 0.6211 (0.7967) loss_zs_kd 1.8107 (1.8341) loss_oracle 0.9828 (1.0359) kd_loss 1.0482 (1.0079) acc 78.1250 (72.2321) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,876
* correct: 3,808
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 52.0%
Evaluate on the *test* set
=> result
* total: 4,741
* correct: 2,097
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 31.2%
******* Domain 1 best val acc:      66.0%, epoch: 29 *******
******* Domain 1 best val test acc: 43.3%, epoch: 29 *******
******* Domain 1 best test acc:     50.8%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/1/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:45:57

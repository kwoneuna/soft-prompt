Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_38', 'location_43']
Target     ['location_46']
# classes  10
# train_x  12,912
# val      5,535
# test     5,883
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/403] time 0.079 (0.134) data 0.000 (0.036) loss 3.1156 (3.0887) teacher_loss 2.2064 (2.1821) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0058 (0.0030) kd_loss 0.9086 (0.9062) acc 34.3750 (32.1875) lr 1.0000e-05 eta 0:44:54
epoch [1/50] batch [40/403] time 0.080 (0.107) data 0.000 (0.018) loss 3.2361 (3.1286) teacher_loss 2.4283 (2.2298) loss_zs_kd 0.0027 (0.0007) loss_oracle 0.0218 (0.0081) kd_loss 0.8057 (0.8980) acc 31.2500 (31.7969) lr 1.0000e-05 eta 0:35:43
epoch [1/50] batch [60/403] time 0.090 (0.098) data 0.001 (0.012) loss 3.1567 (3.1084) teacher_loss 2.3251 (2.2063) loss_zs_kd 0.0083 (0.0021) loss_oracle 0.0183 (0.0130) kd_loss 0.8297 (0.9008) acc 18.7500 (32.7083) lr 1.0000e-05 eta 0:32:49
epoch [1/50] batch [80/403] time 0.081 (0.094) data 0.000 (0.009) loss 3.4315 (3.0794) teacher_loss 2.4683 (2.1758) loss_zs_kd 0.0179 (0.0044) loss_oracle 0.0121 (0.0134) kd_loss 0.9619 (0.9023) acc 31.2500 (33.2812) lr 1.0000e-05 eta 0:31:30
epoch [1/50] batch [100/403] time 0.071 (0.089) data 0.000 (0.007) loss 3.4643 (3.0774) teacher_loss 2.4934 (2.1698) loss_zs_kd 0.0316 (0.0081) loss_oracle 0.0224 (0.0137) kd_loss 0.9687 (0.9063) acc 25.0000 (33.2500) lr 1.0000e-05 eta 0:29:52
epoch [1/50] batch [120/403] time 0.069 (0.088) data 0.000 (0.006) loss 3.2694 (3.0576) teacher_loss 2.3225 (2.1514) loss_zs_kd 0.0571 (0.0140) loss_oracle 0.1828 (0.0205) kd_loss 0.9286 (0.9041) acc 28.1250 (33.5417) lr 1.0000e-05 eta 0:29:32
epoch [1/50] batch [140/403] time 0.073 (0.087) data 0.000 (0.005) loss 2.6341 (3.0259) teacher_loss 1.5717 (2.1099) loss_zs_kd 0.1094 (0.0260) loss_oracle 0.6868 (0.0941) kd_loss 0.9937 (0.9067) acc 56.2500 (34.4196) lr 1.0000e-05 eta 0:28:55
epoch [1/50] batch [160/403] time 0.074 (0.086) data 0.000 (0.005) loss 3.1594 (2.9904) teacher_loss 2.1212 (2.0676) loss_zs_kd 0.4260 (0.0538) loss_oracle 0.4985 (0.1369) kd_loss 0.9884 (0.9091) acc 31.2500 (35.3906) lr 1.0000e-05 eta 0:28:40
epoch [1/50] batch [180/403] time 0.064 (0.084) data 0.000 (0.004) loss 2.7548 (2.9630) teacher_loss 1.6189 (2.0306) loss_zs_kd 0.6865 (0.0949) loss_oracle 0.9961 (0.1980) kd_loss 1.0363 (0.9126) acc 46.8750 (36.1458) lr 1.0000e-05 eta 0:28:05
epoch [1/50] batch [200/403] time 0.070 (0.083) data 0.000 (0.004) loss 2.5966 (2.9424) teacher_loss 1.7221 (1.9972) loss_zs_kd 0.5586 (0.1396) loss_oracle 0.9023 (0.2735) kd_loss 0.7843 (0.9178) acc 37.5000 (36.7188) lr 1.0000e-05 eta 0:27:38
epoch [1/50] batch [220/403] time 0.070 (0.083) data 0.000 (0.004) loss 2.5388 (2.9133) teacher_loss 1.5322 (1.9628) loss_zs_kd 0.6259 (0.1739) loss_oracle 0.8437 (0.3140) kd_loss 0.9222 (0.9191) acc 43.7500 (37.3438) lr 1.0000e-05 eta 0:27:25
epoch [1/50] batch [240/403] time 0.059 (0.081) data 0.000 (0.003) loss 2.5861 (2.8948) teacher_loss 1.4947 (1.9369) loss_zs_kd 0.7889 (0.2083) loss_oracle 0.9272 (0.3605) kd_loss 0.9987 (0.9219) acc 34.3750 (37.7865) lr 1.0000e-05 eta 0:26:55
epoch [1/50] batch [260/403] time 0.072 (0.080) data 0.000 (0.003) loss 3.1316 (2.8814) teacher_loss 2.0637 (1.9113) loss_zs_kd 0.7987 (0.2465) loss_oracle 0.9872 (0.4101) kd_loss 0.9692 (0.9291) acc 34.3750 (38.1490) lr 1.0000e-05 eta 0:26:30
epoch [1/50] batch [280/403] time 0.068 (0.079) data 0.000 (0.003) loss 2.7570 (2.8745) teacher_loss 1.6492 (1.8952) loss_zs_kd 0.7888 (0.2798) loss_oracle 1.0504 (0.4498) kd_loss 1.0027 (0.9343) acc 46.8750 (38.5826) lr 1.0000e-05 eta 0:26:09
epoch [1/50] batch [300/403] time 0.079 (0.079) data 0.000 (0.003) loss 2.9536 (2.8641) teacher_loss 1.8072 (1.8761) loss_zs_kd 0.4809 (0.3017) loss_oracle 0.9305 (0.4899) kd_loss 1.0533 (0.9391) acc 37.5000 (39.0208) lr 1.0000e-05 eta 0:26:06
epoch [1/50] batch [320/403] time 0.086 (0.079) data 0.001 (0.003) loss 2.8253 (2.8643) teacher_loss 1.7901 (1.8703) loss_zs_kd 0.5391 (0.3093) loss_oracle 0.7151 (0.5112) kd_loss 0.9636 (0.9429) acc 34.3750 (39.0918) lr 1.0000e-05 eta 0:26:06
epoch [1/50] batch [340/403] time 0.083 (0.079) data 0.000 (0.002) loss 2.5433 (2.8539) teacher_loss 1.3568 (1.8533) loss_zs_kd 0.7474 (0.3214) loss_oracle 1.0943 (0.5334) kd_loss 1.0771 (0.9472) acc 53.1250 (39.4026) lr 1.0000e-05 eta 0:26:08
epoch [1/50] batch [360/403] time 0.067 (0.079) data 0.000 (0.002) loss 2.5044 (2.8539) teacher_loss 1.5233 (1.8475) loss_zs_kd 0.5092 (0.3332) loss_oracle 0.6316 (0.5558) kd_loss 0.9179 (0.9508) acc 43.7500 (39.5226) lr 1.0000e-05 eta 0:26:01
epoch [1/50] batch [380/403] time 0.089 (0.079) data 0.000 (0.002) loss 2.4099 (2.8486) teacher_loss 1.3912 (1.8386) loss_zs_kd 0.4454 (0.3391) loss_oracle 0.8405 (0.5725) kd_loss 0.9346 (0.9527) acc 46.8750 (39.6217) lr 1.0000e-05 eta 0:26:02
epoch [1/50] batch [400/403] time 0.067 (0.079) data 0.000 (0.002) loss 3.0039 (2.8434) teacher_loss 1.9040 (1.8281) loss_zs_kd 0.6594 (0.3488) loss_oracle 1.0053 (0.5932) kd_loss 0.9994 (0.9559) acc 34.3750 (39.8203) lr 1.0000e-05 eta 0:25:58
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 2,537
* accuracy: 45.8%
* error: 54.2%
* macro_f1: 32.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,920
* accuracy: 32.6%
* error: 67.4%
* macro_f1: 23.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      45.8%, epoch: 1 *******
******* Domain 4 best val test acc: 32.6%, epoch: 1 *******
******* Domain 4 best test acc:     32.6%, epoch: 1 *******
epoch [2/50] batch [20/403] time 0.075 (0.108) data 0.000 (0.030) loss 2.3117 (2.6026) teacher_loss 1.1315 (1.4653) loss_zs_kd 1.4862 (0.9160) loss_oracle 1.0787 (1.0159) kd_loss 1.0723 (1.0358) acc 65.6250 (50.0000) lr 2.0000e-03 eta 0:35:40
epoch [2/50] batch [40/403] time 0.079 (0.094) data 0.000 (0.015) loss 2.5830 (2.5877) teacher_loss 1.4212 (1.4409) loss_zs_kd 0.8127 (0.9696) loss_oracle 1.0736 (1.0370) kd_loss 1.0545 (1.0430) acc 37.5000 (51.7188) lr 2.0000e-03 eta 0:30:51
epoch [2/50] batch [60/403] time 0.079 (0.089) data 0.000 (0.010) loss 2.3753 (2.5528) teacher_loss 1.2469 (1.4054) loss_zs_kd 0.5978 (0.8901) loss_oracle 1.0539 (1.0439) kd_loss 1.0230 (1.0430) acc 59.3750 (52.2917) lr 2.0000e-03 eta 0:29:15
epoch [2/50] batch [80/403] time 0.089 (0.088) data 0.001 (0.008) loss 2.5381 (2.5519) teacher_loss 1.4041 (1.4068) loss_zs_kd 0.5722 (0.8203) loss_oracle 1.0324 (1.0438) kd_loss 1.0308 (1.0408) acc 34.3750 (52.0312) lr 2.0000e-03 eta 0:28:50
epoch [2/50] batch [100/403] time 0.074 (0.086) data 0.000 (0.006) loss 3.2365 (2.5284) teacher_loss 2.1256 (1.3900) loss_zs_kd 0.6425 (0.8104) loss_oracle 1.0121 (1.0388) kd_loss 1.0097 (1.0345) acc 28.1250 (52.4062) lr 2.0000e-03 eta 0:28:09
epoch [2/50] batch [120/403] time 0.083 (0.085) data 0.000 (0.005) loss 2.4508 (2.4847) teacher_loss 1.3545 (1.3558) loss_zs_kd 0.6699 (0.7786) loss_oracle 0.9906 (1.0320) kd_loss 0.9973 (1.0257) acc 46.8750 (53.2552) lr 2.0000e-03 eta 0:27:55
epoch [2/50] batch [140/403] time 0.075 (0.084) data 0.000 (0.005) loss 2.2238 (2.4541) teacher_loss 1.1611 (1.3338) loss_zs_kd 0.5390 (0.7559) loss_oracle 0.9732 (1.0244) kd_loss 0.9654 (1.0179) acc 53.1250 (54.0179) lr 2.0000e-03 eta 0:27:32
epoch [2/50] batch [160/403] time 0.092 (0.084) data 0.000 (0.004) loss 2.0044 (2.4245) teacher_loss 0.9431 (1.3126) loss_zs_kd 0.7141 (0.7353) loss_oracle 0.9543 (1.0165) kd_loss 0.9659 (1.0103) acc 68.7500 (54.6094) lr 2.0000e-03 eta 0:27:27
epoch [2/50] batch [180/403] time 0.082 (0.084) data 0.000 (0.004) loss 2.0926 (2.3992) teacher_loss 1.0644 (1.2959) loss_zs_kd 0.5435 (0.7210) loss_oracle 0.9438 (1.0085) kd_loss 0.9339 (1.0025) acc 53.1250 (55.2951) lr 2.0000e-03 eta 0:27:17
epoch [2/50] batch [200/403] time 0.086 (0.083) data 0.000 (0.003) loss 2.2605 (2.3761) teacher_loss 1.2560 (1.2817) loss_zs_kd 0.9197 (0.7126) loss_oracle 0.9171 (1.0002) kd_loss 0.9128 (0.9944) acc 53.1250 (55.7812) lr 2.0000e-03 eta 0:27:06
epoch [2/50] batch [220/403] time 0.081 (0.083) data 0.000 (0.003) loss 2.2410 (2.3525) teacher_loss 1.2576 (1.2677) loss_zs_kd 0.6494 (0.7051) loss_oracle 0.8894 (0.9918) kd_loss 0.8945 (0.9856) acc 62.5000 (56.2642) lr 2.0000e-03 eta 0:27:04
epoch [2/50] batch [240/403] time 0.084 (0.083) data 0.000 (0.003) loss 2.0474 (2.3315) teacher_loss 1.0822 (1.2564) loss_zs_kd 0.5244 (0.6957) loss_oracle 0.8928 (0.9836) kd_loss 0.8759 (0.9767) acc 56.2500 (56.4453) lr 2.0000e-03 eta 0:27:06
epoch [2/50] batch [260/403] time 0.083 (0.083) data 0.000 (0.003) loss 2.0889 (2.3163) teacher_loss 1.1355 (1.2505) loss_zs_kd 0.6431 (0.6893) loss_oracle 0.8776 (0.9752) kd_loss 0.8656 (0.9683) acc 62.5000 (56.6707) lr 2.0000e-03 eta 0:27:06
epoch [2/50] batch [280/403] time 0.075 (0.083) data 0.000 (0.002) loss 1.9689 (2.3012) teacher_loss 1.0295 (1.2449) loss_zs_kd 0.5915 (0.6837) loss_oracle 0.8487 (0.9666) kd_loss 0.8545 (0.9596) acc 62.5000 (56.7969) lr 2.0000e-03 eta 0:27:02
epoch [2/50] batch [300/403] time 0.082 (0.083) data 0.000 (0.002) loss 1.8561 (2.2801) teacher_loss 0.9680 (1.2329) loss_zs_kd 0.8305 (0.6886) loss_oracle 0.8341 (0.9585) kd_loss 0.8047 (0.9513) acc 68.7500 (57.1667) lr 2.0000e-03 eta 0:27:00
epoch [2/50] batch [320/403] time 0.078 (0.083) data 0.000 (0.002) loss 2.5168 (2.2647) teacher_loss 1.6562 (1.2267) loss_zs_kd 0.8287 (0.7017) loss_oracle 0.8187 (0.9508) kd_loss 0.7787 (0.9429) acc 46.8750 (57.4316) lr 2.0000e-03 eta 0:26:56
epoch [2/50] batch [340/403] time 0.088 (0.083) data 0.000 (0.002) loss 2.2721 (2.2504) teacher_loss 1.3931 (1.2208) loss_zs_kd 0.4661 (0.6980) loss_oracle 0.8163 (0.9426) kd_loss 0.7974 (0.9353) acc 53.1250 (57.5551) lr 2.0000e-03 eta 0:26:51
epoch [2/50] batch [360/403] time 0.086 (0.083) data 0.000 (0.002) loss 1.8570 (2.2386) teacher_loss 0.9944 (1.2175) loss_zs_kd 0.4323 (0.6915) loss_oracle 0.7904 (0.9345) kd_loss 0.7835 (0.9276) acc 62.5000 (57.7083) lr 2.0000e-03 eta 0:26:52
epoch [2/50] batch [380/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.8090 (2.2238) teacher_loss 0.9568 (1.2110) loss_zs_kd 0.6616 (0.6853) loss_oracle 0.7758 (0.9265) kd_loss 0.7746 (0.9202) acc 62.5000 (57.9030) lr 2.0000e-03 eta 0:27:05
epoch [2/50] batch [400/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.0347 (2.2090) teacher_loss 1.2143 (1.2047) loss_zs_kd 0.5163 (0.6809) loss_oracle 0.7623 (0.9187) kd_loss 0.7441 (0.9125) acc 56.2500 (58.0938) lr 2.0000e-03 eta 0:26:59
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,265
* accuracy: 59.0%
* error: 41.0%
* macro_f1: 43.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,904
* accuracy: 32.4%
* error: 67.6%
* macro_f1: 25.8%
******* Domain 4 best val acc:      59.0%, epoch: 2 *******
******* Domain 4 best val test acc: 32.4%, epoch: 2 *******
******* Domain 4 best test acc:     32.6%, epoch: 1 *******
epoch [3/50] batch [20/403] time 0.080 (0.118) data 0.000 (0.032) loss 1.9820 (1.8697) teacher_loss 1.1594 (1.0376) loss_zs_kd 0.7770 (0.6513) loss_oracle 0.7485 (0.7548) kd_loss 0.7478 (0.7566) acc 62.5000 (63.4375) lr 1.9980e-03 eta 0:38:02
epoch [3/50] batch [40/403] time 0.083 (0.100) data 0.000 (0.016) loss 1.9245 (1.8849) teacher_loss 1.0960 (1.0560) loss_zs_kd 0.7027 (0.6297) loss_oracle 0.7367 (0.7487) kd_loss 0.7548 (0.7540) acc 56.2500 (62.0312) lr 1.9980e-03 eta 0:32:10
epoch [3/50] batch [60/403] time 0.080 (0.094) data 0.000 (0.011) loss 1.5794 (1.8580) teacher_loss 0.7685 (1.0333) loss_zs_kd 0.4978 (0.6413) loss_oracle 0.7256 (0.7426) kd_loss 0.7383 (0.7504) acc 68.7500 (62.7083) lr 1.9980e-03 eta 0:30:08
epoch [3/50] batch [80/403] time 0.063 (0.089) data 0.000 (0.008) loss 2.0252 (1.8500) teacher_loss 1.1797 (1.0294) loss_zs_kd 0.5451 (0.6465) loss_oracle 0.7142 (0.7370) kd_loss 0.7740 (0.7469) acc 62.5000 (63.1641) lr 1.9980e-03 eta 0:28:41
epoch [3/50] batch [100/403] time 0.078 (0.085) data 0.000 (0.007) loss 1.6697 (1.8539) teacher_loss 0.8804 (1.0409) loss_zs_kd 0.5051 (0.6472) loss_oracle 0.7051 (0.7315) kd_loss 0.7188 (0.7398) acc 75.0000 (63.2812) lr 1.9980e-03 eta 0:27:17
epoch [3/50] batch [120/403] time 0.076 (0.084) data 0.000 (0.006) loss 1.7956 (1.8565) teacher_loss 1.0023 (1.0495) loss_zs_kd 0.6677 (0.6430) loss_oracle 0.6951 (0.7262) kd_loss 0.7238 (0.7344) acc 59.3750 (62.6823) lr 1.9980e-03 eta 0:26:59
epoch [3/50] batch [140/403] time 0.083 (0.087) data 0.000 (0.005) loss 1.4307 (1.8447) teacher_loss 0.6721 (1.0443) loss_zs_kd 0.7146 (0.6439) loss_oracle 0.6859 (0.7211) kd_loss 0.6900 (0.7284) acc 71.8750 (62.9464) lr 1.9980e-03 eta 0:27:43
epoch [3/50] batch [160/403] time 0.083 (0.086) data 0.001 (0.004) loss 1.9309 (1.8437) teacher_loss 1.1775 (1.0479) loss_zs_kd 0.7171 (0.6428) loss_oracle 0.6792 (0.7164) kd_loss 0.6855 (0.7242) acc 65.6250 (62.8516) lr 1.9980e-03 eta 0:27:33
epoch [3/50] batch [180/403] time 0.078 (0.085) data 0.000 (0.004) loss 1.8517 (1.8331) teacher_loss 1.1187 (1.0433) loss_zs_kd 0.7192 (0.6485) loss_oracle 0.6700 (0.7117) kd_loss 0.6660 (0.7186) acc 59.3750 (62.9167) lr 1.9980e-03 eta 0:27:10
epoch [3/50] batch [200/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.0246 (1.8343) teacher_loss 1.2967 (1.0489) loss_zs_kd 0.6546 (0.6496) loss_oracle 0.6625 (0.7073) kd_loss 0.6617 (0.7146) acc 62.5000 (62.9844) lr 1.9980e-03 eta 0:26:57
epoch [3/50] batch [220/403] time 0.078 (0.084) data 0.000 (0.003) loss 1.6265 (1.8360) teacher_loss 0.9061 (1.0555) loss_zs_kd 0.6453 (0.6465) loss_oracle 0.6562 (0.7029) kd_loss 0.6548 (0.7103) acc 62.5000 (62.5142) lr 1.9980e-03 eta 0:26:53
epoch [3/50] batch [240/403] time 0.090 (0.084) data 0.000 (0.003) loss 1.8310 (1.8343) teacher_loss 1.1271 (1.0583) loss_zs_kd 0.6362 (0.6453) loss_oracle 0.6500 (0.6987) kd_loss 0.6389 (0.7061) acc 62.5000 (62.3047) lr 1.9980e-03 eta 0:26:47
epoch [3/50] batch [260/403] time 0.084 (0.084) data 0.000 (0.003) loss 2.0466 (1.8292) teacher_loss 1.3138 (1.0575) loss_zs_kd 0.5293 (0.6398) loss_oracle 0.6443 (0.6947) kd_loss 0.6683 (0.7022) acc 46.8750 (62.2596) lr 1.9980e-03 eta 0:26:46
epoch [3/50] batch [280/403] time 0.086 (0.084) data 0.000 (0.003) loss 1.2946 (1.8162) teacher_loss 0.5472 (1.0484) loss_zs_kd 0.6097 (0.6385) loss_oracle 0.6627 (0.6909) kd_loss 0.6811 (0.6987) acc 81.2500 (62.5558) lr 1.9980e-03 eta 0:26:38
epoch [3/50] batch [300/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.8070 (1.8098) teacher_loss 1.0877 (1.0461) loss_zs_kd 0.7895 (0.6447) loss_oracle 0.6279 (0.6873) kd_loss 0.6565 (0.6950) acc 65.6250 (62.5833) lr 1.9980e-03 eta 0:26:36
epoch [3/50] batch [320/403] time 0.073 (0.084) data 0.000 (0.002) loss 1.6082 (1.8085) teacher_loss 0.8926 (1.0485) loss_zs_kd 0.5511 (0.6489) loss_oracle 0.6281 (0.6839) kd_loss 0.6527 (0.6916) acc 68.7500 (62.5684) lr 1.9980e-03 eta 0:26:31
epoch [3/50] batch [340/403] time 0.085 (0.084) data 0.001 (0.002) loss 1.6772 (1.8041) teacher_loss 0.9914 (1.0469) loss_zs_kd 0.7832 (0.6543) loss_oracle 0.6241 (0.6807) kd_loss 0.6234 (0.6891) acc 62.5000 (62.6287) lr 1.9980e-03 eta 0:26:27
epoch [3/50] batch [360/403] time 0.086 (0.083) data 0.000 (0.002) loss 1.8121 (1.8002) teacher_loss 1.1218 (1.0461) loss_zs_kd 0.7436 (0.6564) loss_oracle 0.6209 (0.6775) kd_loss 0.6282 (0.6864) acc 65.6250 (62.8733) lr 1.9980e-03 eta 0:26:24
epoch [3/50] batch [380/403] time 0.094 (0.084) data 0.000 (0.002) loss 1.7719 (1.7944) teacher_loss 1.1068 (1.0436) loss_zs_kd 0.6437 (0.6536) loss_oracle 0.6011 (0.6744) kd_loss 0.6049 (0.6834) acc 56.2500 (62.9852) lr 1.9980e-03 eta 0:26:24
epoch [3/50] batch [400/403] time 0.078 (0.083) data 0.000 (0.002) loss 1.9252 (1.7887) teacher_loss 1.2346 (1.0409) loss_zs_kd 0.7954 (0.6563) loss_oracle 0.6130 (0.6719) kd_loss 0.6293 (0.6806) acc 53.1250 (63.0703) lr 1.9980e-03 eta 0:26:16
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,325
* accuracy: 60.1%
* error: 39.9%
* macro_f1: 45.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,844
* accuracy: 31.3%
* error: 68.7%
* macro_f1: 23.3%
******* Domain 4 best val acc:      60.1%, epoch: 3 *******
******* Domain 4 best val test acc: 31.3%, epoch: 3 *******
******* Domain 4 best test acc:     32.6%, epoch: 1 *******
epoch [4/50] batch [20/403] time 0.073 (0.111) data 0.000 (0.025) loss 1.6324 (1.6580) teacher_loss 0.9089 (0.9576) loss_zs_kd 0.6080 (0.6907) loss_oracle 0.6368 (0.6268) kd_loss 0.6598 (0.6378) acc 65.6250 (66.4062) lr 1.9921e-03 eta 0:34:56
epoch [4/50] batch [40/403] time 0.086 (0.097) data 0.000 (0.012) loss 1.7859 (1.6939) teacher_loss 1.0923 (0.9890) loss_zs_kd 0.7677 (0.7420) loss_oracle 0.5936 (0.6183) kd_loss 0.6342 (0.6430) acc 59.3750 (65.3906) lr 1.9921e-03 eta 0:30:25
epoch [4/50] batch [60/403] time 0.076 (0.092) data 0.000 (0.008) loss 1.8078 (1.7178) teacher_loss 1.1448 (1.0155) loss_zs_kd 0.9814 (0.8041) loss_oracle 0.6040 (0.6148) kd_loss 0.6026 (0.6409) acc 59.3750 (64.8958) lr 1.9921e-03 eta 0:28:50
epoch [4/50] batch [80/403] time 0.085 (0.090) data 0.000 (0.006) loss 1.3301 (1.7128) teacher_loss 0.6540 (1.0112) loss_zs_kd 0.9794 (0.8439) loss_oracle 0.6020 (0.6125) kd_loss 0.6159 (0.6404) acc 81.2500 (65.1172) lr 1.9921e-03 eta 0:28:21
epoch [4/50] batch [100/403] time 0.086 (0.089) data 0.000 (0.005) loss 2.0179 (1.7336) teacher_loss 1.3457 (1.0302) loss_zs_kd 0.7296 (0.8307) loss_oracle 0.5996 (0.6107) kd_loss 0.6122 (0.6423) acc 53.1250 (64.5000) lr 1.9921e-03 eta 0:28:03
epoch [4/50] batch [120/403] time 0.085 (0.088) data 0.000 (0.004) loss 1.8244 (1.7290) teacher_loss 1.1160 (1.0263) loss_zs_kd 0.7148 (0.8197) loss_oracle 0.5980 (0.6094) kd_loss 0.6486 (0.6418) acc 68.7500 (64.7917) lr 1.9921e-03 eta 0:27:35
epoch [4/50] batch [140/403] time 0.080 (0.087) data 0.000 (0.004) loss 1.7521 (1.7271) teacher_loss 1.0187 (1.0283) loss_zs_kd 0.7544 (0.8147) loss_oracle 0.5959 (0.6089) kd_loss 0.6738 (0.6380) acc 75.0000 (64.8438) lr 1.9921e-03 eta 0:27:19
epoch [4/50] batch [160/403] time 0.083 (0.087) data 0.001 (0.003) loss 1.7953 (1.7260) teacher_loss 1.1278 (1.0302) loss_zs_kd 0.5581 (0.7999) loss_oracle 0.6049 (0.6083) kd_loss 0.6071 (0.6350) acc 65.6250 (64.8047) lr 1.9921e-03 eta 0:27:05
epoch [4/50] batch [180/403] time 0.079 (0.086) data 0.000 (0.003) loss 1.4781 (1.7264) teacher_loss 0.8359 (1.0325) loss_zs_kd 0.8796 (0.8023) loss_oracle 0.5923 (0.6067) kd_loss 0.5830 (0.6332) acc 71.8750 (64.4792) lr 1.9921e-03 eta 0:26:50
epoch [4/50] batch [200/403] time 0.079 (0.085) data 0.000 (0.003) loss 1.6681 (1.7236) teacher_loss 1.0369 (1.0320) loss_zs_kd 0.6378 (0.7977) loss_oracle 0.5904 (0.6053) kd_loss 0.5721 (0.6311) acc 62.5000 (64.3281) lr 1.9921e-03 eta 0:26:34
epoch [4/50] batch [220/403] time 0.086 (0.084) data 0.000 (0.002) loss 1.4616 (1.7149) teacher_loss 0.7706 (1.0236) loss_zs_kd 0.9291 (0.7949) loss_oracle 0.5736 (0.6040) kd_loss 0.6336 (0.6309) acc 75.0000 (64.4176) lr 1.9921e-03 eta 0:26:21
epoch [4/50] batch [240/403] time 0.094 (0.085) data 0.000 (0.002) loss 1.6676 (1.7154) teacher_loss 1.0218 (1.0238) loss_zs_kd 0.9025 (0.7990) loss_oracle 0.5872 (0.6036) kd_loss 0.5871 (0.6312) acc 65.6250 (64.3490) lr 1.9921e-03 eta 0:26:24
epoch [4/50] batch [260/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.5418 (1.7076) teacher_loss 0.8251 (1.0164) loss_zs_kd 0.9752 (0.8095) loss_oracle 0.5859 (0.6027) kd_loss 0.6581 (0.6309) acc 71.8750 (64.6394) lr 1.9921e-03 eta 0:26:13
epoch [4/50] batch [280/403] time 0.077 (0.084) data 0.000 (0.002) loss 2.0098 (1.7006) teacher_loss 1.2696 (1.0091) loss_zs_kd 1.0718 (0.8156) loss_oracle 0.6136 (0.6039) kd_loss 0.6788 (0.6312) acc 62.5000 (64.9442) lr 1.9921e-03 eta 0:26:08
epoch [4/50] batch [300/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.0647 (1.6997) teacher_loss 1.3478 (1.0082) loss_zs_kd 0.8371 (0.8200) loss_oracle 0.6339 (0.6055) kd_loss 0.6535 (0.6310) acc 37.5000 (64.8438) lr 1.9921e-03 eta 0:26:22
epoch [4/50] batch [320/403] time 0.082 (0.085) data 0.000 (0.002) loss 1.5077 (1.7000) teacher_loss 0.8537 (1.0087) loss_zs_kd 0.6779 (0.8248) loss_oracle 0.6080 (0.6070) kd_loss 0.5932 (0.6306) acc 75.0000 (64.7949) lr 1.9921e-03 eta 0:26:20
epoch [4/50] batch [340/403] time 0.074 (0.085) data 0.000 (0.002) loss 1.9743 (1.7016) teacher_loss 1.2609 (1.0102) loss_zs_kd 0.9727 (0.8283) loss_oracle 0.6682 (0.6074) kd_loss 0.6467 (0.6308) acc 68.7500 (64.6875) lr 1.9921e-03 eta 0:26:12
epoch [4/50] batch [360/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.9148 (1.6968) teacher_loss 1.1861 (1.0047) loss_zs_kd 1.0459 (0.8336) loss_oracle 0.6636 (0.6086) kd_loss 0.6624 (0.6312) acc 62.5000 (64.9306) lr 1.9921e-03 eta 0:26:04
epoch [4/50] batch [380/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.8460 (1.6990) teacher_loss 1.1309 (1.0063) loss_zs_kd 1.1983 (0.8428) loss_oracle 0.7379 (0.6114) kd_loss 0.6413 (0.6315) acc 56.2500 (64.8931) lr 1.9921e-03 eta 0:25:57
epoch [4/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.001) loss 2.2074 (1.6994) teacher_loss 1.5106 (1.0051) loss_zs_kd 0.7212 (0.8448) loss_oracle 0.7374 (0.6180) kd_loss 0.6231 (0.6325) acc 46.8750 (65.0391) lr 1.9921e-03 eta 0:25:49
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,510
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 50.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,008
* accuracy: 34.1%
* error: 65.9%
* macro_f1: 24.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      63.4%, epoch: 4 *******
******* Domain 4 best val test acc: 34.1%, epoch: 4 *******
******* Domain 4 best test acc:     34.1%, epoch: 4 *******
epoch [5/50] batch [20/403] time 0.084 (0.113) data 0.000 (0.034) loss 1.9024 (1.7618) teacher_loss 1.0297 (1.0229) loss_zs_kd 0.9702 (0.8212) loss_oracle 0.8368 (0.7634) kd_loss 0.7890 (0.6626) acc 68.7500 (65.0000) lr 1.9823e-03 eta 0:35:01
epoch [5/50] batch [40/403] time 0.193 (0.103) data 0.001 (0.017) loss 1.9850 (1.7450) teacher_loss 1.1614 (0.9994) loss_zs_kd 0.9332 (0.8898) loss_oracle 0.8543 (0.7802) kd_loss 0.7381 (0.6675) acc 46.8750 (64.9219) lr 1.9823e-03 eta 0:31:50
epoch [5/50] batch [60/403] time 0.080 (0.099) data 0.000 (0.011) loss 1.7074 (1.7285) teacher_loss 0.9083 (0.9813) loss_zs_kd 0.9218 (0.9286) loss_oracle 0.7824 (0.7862) kd_loss 0.7209 (0.6686) acc 71.8750 (66.2500) lr 1.9823e-03 eta 0:30:23
epoch [5/50] batch [80/403] time 0.094 (0.094) data 0.000 (0.009) loss 1.6468 (1.7127) teacher_loss 0.8855 (0.9705) loss_zs_kd 1.1467 (0.9441) loss_oracle 0.6620 (0.7723) kd_loss 0.6951 (0.6650) acc 65.6250 (66.9141) lr 1.9823e-03 eta 0:28:52
epoch [5/50] batch [100/403] time 0.091 (0.091) data 0.000 (0.007) loss 1.4543 (1.7031) teacher_loss 0.7959 (0.9670) loss_zs_kd 1.0822 (0.9730) loss_oracle 0.5945 (0.7542) kd_loss 0.5989 (0.6607) acc 71.8750 (66.4688) lr 1.9823e-03 eta 0:27:58
epoch [5/50] batch [120/403] time 0.084 (0.088) data 0.000 (0.006) loss 1.7993 (1.6945) teacher_loss 1.1154 (0.9676) loss_zs_kd 0.8573 (0.9716) loss_oracle 0.6525 (0.7361) kd_loss 0.6186 (0.6533) acc 62.5000 (66.3281) lr 1.9823e-03 eta 0:27:07
epoch [5/50] batch [140/403] time 0.081 (0.087) data 0.000 (0.005) loss 1.9587 (1.6999) teacher_loss 1.1789 (0.9756) loss_zs_kd 1.1269 (0.9686) loss_oracle 0.6474 (0.7223) kd_loss 0.7150 (0.6521) acc 56.2500 (66.0938) lr 1.9823e-03 eta 0:26:40
epoch [5/50] batch [160/403] time 0.081 (0.086) data 0.000 (0.004) loss 1.9494 (1.7022) teacher_loss 1.2868 (0.9815) loss_zs_kd 0.9629 (0.9700) loss_oracle 0.6825 (0.7116) kd_loss 0.5943 (0.6495) acc 53.1250 (65.9180) lr 1.9823e-03 eta 0:26:27
epoch [5/50] batch [180/403] time 0.090 (0.086) data 0.000 (0.004) loss 1.3525 (1.6927) teacher_loss 0.6592 (0.9775) loss_zs_kd 0.7934 (0.9616) loss_oracle 0.6388 (0.7047) kd_loss 0.6294 (0.6448) acc 81.2500 (65.9722) lr 1.9823e-03 eta 0:26:17
epoch [5/50] batch [200/403] time 0.083 (0.086) data 0.000 (0.004) loss 1.7781 (1.6963) teacher_loss 1.0063 (0.9800) loss_zs_kd 0.7103 (0.9567) loss_oracle 0.6896 (0.7053) kd_loss 0.7028 (0.6458) acc 75.0000 (65.5312) lr 1.9823e-03 eta 0:26:13
epoch [5/50] batch [220/403] time 0.080 (0.086) data 0.000 (0.003) loss 1.6906 (1.6922) teacher_loss 0.9126 (0.9760) loss_zs_kd 0.9457 (0.9586) loss_oracle 0.6747 (0.7023) kd_loss 0.7105 (0.6460) acc 65.6250 (65.6676) lr 1.9823e-03 eta 0:26:08
epoch [5/50] batch [240/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.6557 (1.6961) teacher_loss 0.8249 (0.9759) loss_zs_kd 1.1142 (0.9663) loss_oracle 0.6997 (0.7015) kd_loss 0.7608 (0.6501) acc 71.8750 (65.5208) lr 1.9823e-03 eta 0:26:08
epoch [5/50] batch [260/403] time 0.083 (0.085) data 0.000 (0.003) loss 1.6053 (1.6978) teacher_loss 0.7650 (0.9696) loss_zs_kd 1.0532 (0.9725) loss_oracle 0.6616 (0.7003) kd_loss 0.7741 (0.6582) acc 68.7500 (65.9495) lr 1.9823e-03 eta 0:25:58
epoch [5/50] batch [280/403] time 0.081 (0.085) data 0.000 (0.003) loss 1.6043 (1.7000) teacher_loss 0.7595 (0.9652) loss_zs_kd 1.2250 (0.9839) loss_oracle 0.7475 (0.7011) kd_loss 0.7700 (0.6646) acc 71.8750 (66.1384) lr 1.9823e-03 eta 0:25:53
epoch [5/50] batch [300/403] time 0.074 (0.085) data 0.000 (0.003) loss 1.5838 (1.6975) teacher_loss 0.8353 (0.9579) loss_zs_kd 1.1097 (0.9905) loss_oracle 0.6984 (0.7019) kd_loss 0.6787 (0.6694) acc 68.7500 (66.5417) lr 1.9823e-03 eta 0:25:47
epoch [5/50] batch [320/403] time 0.082 (0.085) data 0.000 (0.002) loss 1.9147 (1.6968) teacher_loss 1.0933 (0.9573) loss_zs_kd 1.1928 (0.9987) loss_oracle 0.7283 (0.7008) kd_loss 0.7485 (0.6695) acc 71.8750 (66.6309) lr 1.9823e-03 eta 0:25:45
epoch [5/50] batch [340/403] time 0.072 (0.084) data 0.000 (0.002) loss 1.3408 (1.6966) teacher_loss 0.6404 (0.9576) loss_zs_kd 0.9026 (1.0064) loss_oracle 0.6948 (0.7018) kd_loss 0.6309 (0.6688) acc 87.5000 (66.7463) lr 1.9823e-03 eta 0:25:37
epoch [5/50] batch [360/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.9944 (1.6921) teacher_loss 1.1593 (0.9537) loss_zs_kd 0.8593 (1.0046) loss_oracle 0.6881 (0.7037) kd_loss 0.7663 (0.6680) acc 59.3750 (66.9184) lr 1.9823e-03 eta 0:25:33
epoch [5/50] batch [380/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.6053 (1.6956) teacher_loss 0.7481 (0.9527) loss_zs_kd 1.1739 (1.0074) loss_oracle 0.7969 (0.7069) kd_loss 0.7775 (0.6722) acc 75.0000 (66.9079) lr 1.9823e-03 eta 0:25:30
epoch [5/50] batch [400/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.7269 (1.7017) teacher_loss 1.0406 (0.9523) loss_zs_kd 1.3166 (1.0166) loss_oracle 0.7093 (0.7077) kd_loss 0.6153 (0.6786) acc 65.6250 (66.9844) lr 1.9823e-03 eta 0:25:22
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,618
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 51.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,920
* accuracy: 32.6%
* error: 67.4%
* macro_f1: 24.7%
******* Domain 4 best val acc:      65.4%, epoch: 5 *******
******* Domain 4 best val test acc: 32.6%, epoch: 5 *******
******* Domain 4 best test acc:     34.1%, epoch: 4 *******
epoch [6/50] batch [20/403] time 0.077 (0.117) data 0.000 (0.034) loss 1.5038 (1.7274) teacher_loss 0.6884 (0.8647) loss_zs_kd 1.1739 (1.2316) loss_oracle 0.8204 (0.8348) kd_loss 0.7333 (0.7792) acc 71.8750 (69.2188) lr 1.9686e-03 eta 0:35:27
epoch [6/50] batch [40/403] time 0.079 (0.097) data 0.000 (0.017) loss 1.6833 (1.7819) teacher_loss 0.9325 (0.9065) loss_zs_kd 1.2051 (1.2379) loss_oracle 0.8102 (0.8267) kd_loss 0.6698 (0.7928) acc 65.6250 (67.9688) lr 1.9686e-03 eta 0:29:23
epoch [6/50] batch [60/403] time 0.083 (0.091) data 0.001 (0.011) loss 2.3987 (1.8713) teacher_loss 1.2065 (0.9580) loss_zs_kd 1.0078 (1.1836) loss_oracle 1.1535 (0.8320) kd_loss 1.0769 (0.8301) acc 59.3750 (65.8333) lr 1.9686e-03 eta 0:27:19
epoch [6/50] batch [80/403] time 0.078 (0.088) data 0.000 (0.009) loss 1.9168 (1.9236) teacher_loss 0.9765 (0.9589) loss_zs_kd 1.1039 (1.1839) loss_oracle 1.0013 (0.8666) kd_loss 0.8402 (0.8780) acc 75.0000 (66.4062) lr 1.9686e-03 eta 0:26:37
epoch [6/50] batch [100/403] time 0.075 (0.087) data 0.000 (0.007) loss 1.6649 (1.9145) teacher_loss 0.8281 (0.9609) loss_zs_kd 1.2072 (1.1959) loss_oracle 0.7921 (0.8699) kd_loss 0.7576 (0.8666) acc 75.0000 (66.5000) lr 1.9686e-03 eta 0:26:04
epoch [6/50] batch [120/403] time 0.072 (0.086) data 0.000 (0.006) loss 1.6280 (1.9085) teacher_loss 0.8216 (0.9716) loss_zs_kd 1.1983 (1.2042) loss_oracle 0.8560 (0.8567) kd_loss 0.7208 (0.8512) acc 78.1250 (66.0156) lr 1.9686e-03 eta 0:25:41
epoch [6/50] batch [140/403] time 0.077 (0.084) data 0.000 (0.005) loss 2.0344 (1.9181) teacher_loss 0.9227 (0.9650) loss_zs_kd 1.1539 (1.1818) loss_oracle 0.9390 (0.8688) kd_loss 1.0178 (0.8662) acc 62.5000 (66.2277) lr 1.9686e-03 eta 0:25:12
epoch [6/50] batch [160/403] time 0.079 (0.084) data 0.000 (0.004) loss 2.0510 (1.9203) teacher_loss 1.1189 (0.9663) loss_zs_kd 1.2005 (1.1712) loss_oracle 0.8278 (0.8667) kd_loss 0.8493 (0.8673) acc 56.2500 (66.1523) lr 1.9686e-03 eta 0:25:04
epoch [6/50] batch [180/403] time 0.076 (0.083) data 0.000 (0.004) loss 2.1616 (1.9116) teacher_loss 1.2446 (0.9637) loss_zs_kd 1.1608 (1.1706) loss_oracle 1.0326 (0.8685) kd_loss 0.8137 (0.8610) acc 59.3750 (66.3542) lr 1.9686e-03 eta 0:24:54
epoch [6/50] batch [200/403] time 0.087 (0.083) data 0.000 (0.004) loss 1.7733 (1.8945) teacher_loss 0.9879 (0.9557) loss_zs_kd 1.2584 (1.1611) loss_oracle 0.7917 (0.8659) kd_loss 0.7062 (0.8522) acc 65.6250 (66.5156) lr 1.9686e-03 eta 0:24:44
epoch [6/50] batch [220/403] time 0.084 (0.084) data 0.001 (0.003) loss 1.7971 (1.8916) teacher_loss 0.7376 (0.9558) loss_zs_kd 1.1459 (1.1596) loss_oracle 1.1370 (0.8711) kd_loss 0.9458 (0.8487) acc 71.8750 (66.5483) lr 1.9686e-03 eta 0:25:00
epoch [6/50] batch [240/403] time 0.079 (0.083) data 0.000 (0.003) loss 2.0420 (1.8953) teacher_loss 1.0290 (0.9579) loss_zs_kd 1.0576 (1.1585) loss_oracle 0.8689 (0.8778) kd_loss 0.9261 (0.8496) acc 59.3750 (66.3021) lr 1.9686e-03 eta 0:24:49
epoch [6/50] batch [260/403] time 0.091 (0.083) data 0.000 (0.003) loss 1.9552 (1.8989) teacher_loss 1.1160 (0.9626) loss_zs_kd 0.9990 (1.1480) loss_oracle 0.8178 (0.8819) kd_loss 0.7574 (0.8481) acc 62.5000 (65.9615) lr 1.9686e-03 eta 0:24:45
epoch [6/50] batch [280/403] time 0.084 (0.083) data 0.000 (0.003) loss 2.0373 (1.9008) teacher_loss 1.0024 (0.9591) loss_zs_kd 1.2129 (1.1488) loss_oracle 1.0070 (0.8893) kd_loss 0.9343 (0.8528) acc 53.1250 (65.9710) lr 1.9686e-03 eta 0:24:47
epoch [6/50] batch [300/403] time 0.087 (0.083) data 0.001 (0.002) loss 1.7623 (1.8976) teacher_loss 0.8755 (0.9538) loss_zs_kd 1.1560 (1.1459) loss_oracle 0.9745 (0.8968) kd_loss 0.7894 (0.8541) acc 62.5000 (66.3125) lr 1.9686e-03 eta 0:24:48
epoch [6/50] batch [320/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.9670 (1.8960) teacher_loss 0.9155 (0.9546) loss_zs_kd 0.8999 (1.1353) loss_oracle 0.8762 (0.8945) kd_loss 0.9638 (0.8520) acc 68.7500 (66.2207) lr 1.9686e-03 eta 0:24:49
epoch [6/50] batch [340/403] time 0.088 (0.084) data 0.000 (0.002) loss 1.3810 (1.8939) teacher_loss 0.5679 (0.9522) loss_zs_kd 1.4954 (1.1477) loss_oracle 0.7228 (0.8927) kd_loss 0.7408 (0.8524) acc 81.2500 (66.3603) lr 1.9686e-03 eta 0:24:48
epoch [6/50] batch [360/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.4948 (1.8980) teacher_loss 1.4711 (0.9558) loss_zs_kd 1.4419 (1.1565) loss_oracle 1.2137 (0.8956) kd_loss 0.9023 (0.8527) acc 50.0000 (66.2674) lr 1.9686e-03 eta 0:24:46
epoch [6/50] batch [380/403] time 0.082 (0.083) data 0.000 (0.002) loss 1.9683 (1.8935) teacher_loss 1.0468 (0.9536) loss_zs_kd 1.1700 (1.1539) loss_oracle 0.9419 (0.9017) kd_loss 0.8273 (0.8497) acc 75.0000 (66.4556) lr 1.9686e-03 eta 0:24:40
epoch [6/50] batch [400/403] time 0.070 (0.083) data 0.000 (0.002) loss 1.5446 (1.8901) teacher_loss 0.5591 (0.9530) loss_zs_kd 1.3585 (1.1575) loss_oracle 0.9699 (0.9032) kd_loss 0.8885 (0.8468) acc 87.5000 (66.5625) lr 1.9686e-03 eta 0:24:32
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,434
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 48.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,740
* accuracy: 29.6%
* error: 70.4%
* macro_f1: 21.6%
******* Domain 4 best val acc:      65.4%, epoch: 5 *******
******* Domain 4 best val test acc: 32.6%, epoch: 5 *******
******* Domain 4 best test acc:     34.1%, epoch: 4 *******
epoch [7/50] batch [20/403] time 0.079 (0.113) data 0.000 (0.033) loss 1.6596 (1.9001) teacher_loss 0.6760 (0.8865) loss_zs_kd 1.3688 (1.3316) loss_oracle 1.0648 (0.9902) kd_loss 0.8771 (0.9146) acc 71.8750 (70.6250) lr 1.9511e-03 eta 0:33:25
epoch [7/50] batch [40/403] time 0.082 (0.098) data 0.000 (0.017) loss 1.7737 (1.8698) teacher_loss 0.8934 (0.8716) loss_zs_kd 1.1416 (1.2811) loss_oracle 0.8397 (0.9777) kd_loss 0.7964 (0.9004) acc 68.7500 (71.4844) lr 1.9511e-03 eta 0:28:50
epoch [7/50] batch [60/403] time 0.075 (0.091) data 0.000 (0.011) loss 1.7139 (1.8620) teacher_loss 0.9157 (0.8986) loss_zs_kd 0.9725 (1.2479) loss_oracle 0.8187 (0.9582) kd_loss 0.7164 (0.8676) acc 62.5000 (69.5312) lr 1.9511e-03 eta 0:26:49
epoch [7/50] batch [80/403] time 0.080 (0.089) data 0.000 (0.008) loss 1.6325 (1.8510) teacher_loss 0.8045 (0.9059) loss_zs_kd 1.1416 (1.2311) loss_oracle 0.9711 (0.9611) kd_loss 0.7310 (0.8490) acc 75.0000 (68.8281) lr 1.9511e-03 eta 0:26:10
epoch [7/50] batch [100/403] time 0.075 (0.086) data 0.000 (0.007) loss 2.0022 (1.8238) teacher_loss 1.2477 (0.9082) loss_zs_kd 1.2941 (1.1972) loss_oracle 0.9733 (0.9380) kd_loss 0.6572 (0.8218) acc 59.3750 (69.0000) lr 1.9511e-03 eta 0:25:24
epoch [7/50] batch [120/403] time 0.086 (0.085) data 0.000 (0.006) loss 1.9021 (1.8100) teacher_loss 1.1509 (0.9147) loss_zs_kd 1.2140 (1.1845) loss_oracle 1.0591 (0.9304) kd_loss 0.6453 (0.8023) acc 65.6250 (68.7240) lr 1.9511e-03 eta 0:25:02
epoch [7/50] batch [140/403] time 0.078 (0.085) data 0.000 (0.005) loss 1.6936 (1.7949) teacher_loss 0.8746 (0.9195) loss_zs_kd 1.4110 (1.1911) loss_oracle 0.8798 (0.9214) kd_loss 0.7310 (0.7833) acc 68.7500 (68.7277) lr 1.9511e-03 eta 0:24:49
epoch [7/50] batch [160/403] time 0.081 (0.084) data 0.000 (0.004) loss 1.5727 (1.7834) teacher_loss 0.6534 (0.9057) loss_zs_kd 1.2248 (1.1916) loss_oracle 0.7952 (0.9141) kd_loss 0.8398 (0.7864) acc 75.0000 (69.0820) lr 1.9511e-03 eta 0:24:36
epoch [7/50] batch [180/403] time 0.090 (0.084) data 0.000 (0.004) loss 1.8384 (1.7812) teacher_loss 0.9048 (0.9035) loss_zs_kd 1.4090 (1.1951) loss_oracle 0.8533 (0.9081) kd_loss 0.8482 (0.7869) acc 71.8750 (68.9236) lr 1.9511e-03 eta 0:24:37
epoch [7/50] batch [200/403] time 0.071 (0.084) data 0.000 (0.004) loss 1.2427 (1.7808) teacher_loss 0.4548 (0.9050) loss_zs_kd 1.0437 (1.1911) loss_oracle 0.9388 (0.9071) kd_loss 0.6940 (0.7850) acc 90.6250 (68.9219) lr 1.9511e-03 eta 0:24:31
epoch [7/50] batch [220/403] time 0.085 (0.083) data 0.000 (0.003) loss 1.8255 (1.7812) teacher_loss 0.8662 (0.9043) loss_zs_kd 1.3554 (1.1977) loss_oracle 1.0539 (0.9158) kd_loss 0.8539 (0.7853) acc 71.8750 (68.7784) lr 1.9511e-03 eta 0:24:21
epoch [7/50] batch [240/403] time 0.077 (0.084) data 0.000 (0.003) loss 1.7039 (1.7845) teacher_loss 0.8385 (0.9065) loss_zs_kd 1.5055 (1.1977) loss_oracle 1.0385 (0.9222) kd_loss 0.7615 (0.7858) acc 56.2500 (68.5286) lr 1.9511e-03 eta 0:24:21
epoch [7/50] batch [260/403] time 0.092 (0.083) data 0.000 (0.003) loss 1.8853 (1.7852) teacher_loss 0.9401 (0.9052) loss_zs_kd 1.2448 (1.1977) loss_oracle 1.0030 (0.9300) kd_loss 0.8449 (0.7870) acc 65.6250 (68.5938) lr 1.9511e-03 eta 0:24:13
epoch [7/50] batch [280/403] time 0.081 (0.083) data 0.000 (0.003) loss 1.6662 (1.7835) teacher_loss 0.7580 (0.9004) loss_zs_kd 1.2231 (1.2062) loss_oracle 1.0734 (0.9391) kd_loss 0.8009 (0.7891) acc 78.1250 (68.7054) lr 1.9511e-03 eta 0:24:14
epoch [7/50] batch [300/403] time 0.076 (0.083) data 0.000 (0.002) loss 1.5552 (1.7844) teacher_loss 0.6933 (0.9025) loss_zs_kd 1.1235 (1.2081) loss_oracle 1.1476 (0.9437) kd_loss 0.7471 (0.7875) acc 75.0000 (68.5625) lr 1.9511e-03 eta 0:24:09
epoch [7/50] batch [320/403] time 0.080 (0.083) data 0.000 (0.002) loss 1.7697 (1.7802) teacher_loss 0.8010 (0.8994) loss_zs_kd 1.2781 (1.2166) loss_oracle 0.9798 (0.9468) kd_loss 0.8707 (0.7861) acc 75.0000 (68.6621) lr 1.9511e-03 eta 0:24:08
epoch [7/50] batch [340/403] time 0.083 (0.083) data 0.000 (0.002) loss 1.6971 (1.7774) teacher_loss 0.7684 (0.8967) loss_zs_kd 1.2064 (1.2191) loss_oracle 0.9977 (0.9466) kd_loss 0.8289 (0.7861) acc 68.7500 (68.7684) lr 1.9511e-03 eta 0:24:08
epoch [7/50] batch [360/403] time 0.074 (0.083) data 0.000 (0.002) loss 2.0788 (1.7800) teacher_loss 1.2293 (0.8991) loss_zs_kd 1.1817 (1.2269) loss_oracle 0.8937 (0.9469) kd_loss 0.7601 (0.7862) acc 65.6250 (68.6111) lr 1.9511e-03 eta 0:24:08
epoch [7/50] batch [380/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.8826 (1.7796) teacher_loss 1.0449 (0.9001) loss_zs_kd 1.0683 (1.2281) loss_oracle 0.8048 (0.9464) kd_loss 0.7573 (0.7848) acc 68.7500 (68.5033) lr 1.9511e-03 eta 0:24:17
epoch [7/50] batch [400/403] time 0.073 (0.083) data 0.000 (0.002) loss 1.8944 (1.7792) teacher_loss 1.1550 (0.9039) loss_zs_kd 1.1245 (1.2280) loss_oracle 0.8979 (0.9442) kd_loss 0.6496 (0.7809) acc 53.1250 (68.3516) lr 1.9511e-03 eta 0:24:07
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,738
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 51.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,151
* accuracy: 36.6%
* error: 63.4%
* macro_f1: 27.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      67.5%, epoch: 7 *******
******* Domain 4 best val test acc: 36.6%, epoch: 7 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [8/50] batch [20/403] time 0.090 (0.122) data 0.000 (0.034) loss 1.9075 (1.7603) teacher_loss 1.0736 (0.9714) loss_zs_kd 1.2469 (1.1752) loss_oracle 0.9507 (0.8988) kd_loss 0.7388 (0.6990) acc 68.7500 (65.7812) lr 1.9298e-03 eta 0:35:18
epoch [8/50] batch [40/403] time 0.079 (0.101) data 0.000 (0.017) loss 1.5736 (1.7946) teacher_loss 0.8002 (0.9976) loss_zs_kd 1.0845 (1.1650) loss_oracle 0.9772 (0.8689) kd_loss 0.6757 (0.7102) acc 71.8750 (65.4688) lr 1.9298e-03 eta 0:29:10
epoch [8/50] batch [60/403] time 0.085 (0.094) data 0.001 (0.012) loss 2.0233 (1.7685) teacher_loss 1.0980 (0.9621) loss_zs_kd 1.0146 (1.1212) loss_oracle 0.9646 (0.8842) kd_loss 0.8288 (0.7180) acc 56.2500 (66.3542) lr 1.9298e-03 eta 0:27:05
epoch [8/50] batch [80/403] time 0.076 (0.090) data 0.000 (0.009) loss 2.0227 (1.7728) teacher_loss 1.0116 (0.9548) loss_zs_kd 1.3502 (1.1238) loss_oracle 0.9838 (0.9014) kd_loss 0.9127 (0.7279) acc 65.6250 (66.7188) lr 1.9298e-03 eta 0:25:51
epoch [8/50] batch [100/403] time 0.086 (0.088) data 0.002 (0.007) loss 2.0981 (1.7715) teacher_loss 1.1359 (0.9455) loss_zs_kd 1.4419 (1.1436) loss_oracle 1.0610 (0.9125) kd_loss 0.8561 (0.7347) acc 59.3750 (66.9688) lr 1.9298e-03 eta 0:25:11
epoch [8/50] batch [120/403] time 0.077 (0.086) data 0.000 (0.006) loss 1.7973 (1.7659) teacher_loss 0.9296 (0.9343) loss_zs_kd 1.2244 (1.1543) loss_oracle 0.9562 (0.9184) kd_loss 0.7720 (0.7398) acc 68.7500 (67.6302) lr 1.9298e-03 eta 0:24:42
epoch [8/50] batch [140/403] time 0.077 (0.088) data 0.000 (0.005) loss 1.4475 (1.7604) teacher_loss 0.6667 (0.9246) loss_zs_kd 1.0206 (1.1589) loss_oracle 1.0163 (0.9221) kd_loss 0.6791 (0.7436) acc 75.0000 (67.8795) lr 1.9298e-03 eta 0:25:17
epoch [8/50] batch [160/403] time 0.082 (0.088) data 0.000 (0.005) loss 1.6950 (1.7604) teacher_loss 0.8387 (0.9167) loss_zs_kd 1.3884 (1.1794) loss_oracle 0.9728 (0.9377) kd_loss 0.7590 (0.7500) acc 71.8750 (68.0469) lr 1.9298e-03 eta 0:25:07
epoch [8/50] batch [180/403] time 0.085 (0.088) data 0.000 (0.004) loss 1.6066 (1.7628) teacher_loss 0.7139 (0.9151) loss_zs_kd 1.1154 (1.1857) loss_oracle 0.8954 (0.9473) kd_loss 0.8032 (0.7530) acc 75.0000 (68.1250) lr 1.9298e-03 eta 0:25:01
epoch [8/50] batch [200/403] time 0.081 (0.087) data 0.000 (0.004) loss 1.9642 (1.7588) teacher_loss 0.9675 (0.9091) loss_zs_kd 0.9808 (1.1900) loss_oracle 1.0094 (0.9447) kd_loss 0.8957 (0.7553) acc 62.5000 (68.3750) lr 1.9298e-03 eta 0:24:53
epoch [8/50] batch [220/403] time 0.084 (0.087) data 0.000 (0.003) loss 1.8785 (1.7576) teacher_loss 1.0088 (0.9055) loss_zs_kd 1.3631 (1.1957) loss_oracle 0.8739 (0.9395) kd_loss 0.7823 (0.7582) acc 62.5000 (68.6506) lr 1.9298e-03 eta 0:24:50
epoch [8/50] batch [240/403] time 0.079 (0.087) data 0.000 (0.003) loss 1.7757 (1.7607) teacher_loss 0.8564 (0.9029) loss_zs_kd 1.2955 (1.2116) loss_oracle 1.0034 (0.9438) kd_loss 0.8189 (0.7635) acc 71.8750 (68.9453) lr 1.9298e-03 eta 0:24:42
epoch [8/50] batch [260/403] time 0.083 (0.086) data 0.000 (0.003) loss 1.8298 (1.7612) teacher_loss 1.0202 (0.9080) loss_zs_kd 1.3668 (1.2073) loss_oracle 0.9837 (0.9432) kd_loss 0.7113 (0.7589) acc 68.7500 (68.7380) lr 1.9298e-03 eta 0:24:35
epoch [8/50] batch [280/403] time 0.084 (0.086) data 0.000 (0.003) loss 1.5244 (1.7563) teacher_loss 0.7121 (0.9073) loss_zs_kd 1.4562 (1.2111) loss_oracle 0.9687 (0.9486) kd_loss 0.7154 (0.7541) acc 71.8750 (68.6607) lr 1.9298e-03 eta 0:24:23
epoch [8/50] batch [300/403] time 0.082 (0.086) data 0.000 (0.003) loss 1.8697 (1.7538) teacher_loss 1.1449 (0.9084) loss_zs_kd 1.1274 (1.2237) loss_oracle 0.9703 (0.9545) kd_loss 0.6277 (0.7500) acc 65.6250 (68.4583) lr 1.9298e-03 eta 0:24:18
epoch [8/50] batch [320/403] time 0.075 (0.086) data 0.000 (0.002) loss 1.9286 (1.7524) teacher_loss 1.0988 (0.9077) loss_zs_kd 1.1349 (1.2170) loss_oracle 0.9780 (0.9532) kd_loss 0.7320 (0.7493) acc 62.5000 (68.3887) lr 1.9298e-03 eta 0:24:16
epoch [8/50] batch [340/403] time 0.091 (0.086) data 0.000 (0.002) loss 1.8485 (1.7632) teacher_loss 0.7906 (0.9116) loss_zs_kd 1.2768 (1.2193) loss_oracle 0.9370 (0.9535) kd_loss 0.9641 (0.7563) acc 68.7500 (68.1526) lr 1.9298e-03 eta 0:24:13
epoch [8/50] batch [360/403] time 0.082 (0.085) data 0.000 (0.002) loss 1.8726 (1.7739) teacher_loss 0.8727 (0.9133) loss_zs_kd 1.5135 (1.2206) loss_oracle 1.0632 (0.9560) kd_loss 0.8936 (0.7650) acc 65.6250 (67.9688) lr 1.9298e-03 eta 0:24:10
epoch [8/50] batch [380/403] time 0.094 (0.085) data 0.000 (0.002) loss 1.9024 (1.7764) teacher_loss 0.9075 (0.9119) loss_zs_kd 1.3157 (1.2221) loss_oracle 1.0749 (0.9623) kd_loss 0.8874 (0.7683) acc 62.5000 (67.9276) lr 1.9298e-03 eta 0:24:08
epoch [8/50] batch [400/403] time 0.074 (0.085) data 0.000 (0.002) loss 1.9493 (1.7777) teacher_loss 0.9494 (0.9081) loss_zs_kd 1.2317 (1.2305) loss_oracle 1.1415 (0.9672) kd_loss 0.8857 (0.7729) acc 71.8750 (68.1719) lr 1.9298e-03 eta 0:24:01
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,797
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 54.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,082
* accuracy: 35.4%
* error: 64.6%
* macro_f1: 26.3%
******* Domain 4 best val acc:      68.6%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [9/50] batch [20/403] time 0.082 (0.116) data 0.000 (0.029) loss 1.7668 (1.8340) teacher_loss 0.6493 (0.7884) loss_zs_kd 1.2068 (1.5065) loss_oracle 1.0596 (1.1198) kd_loss 1.0115 (0.9336) acc 81.2500 (75.3125) lr 1.9048e-03 eta 0:32:49
epoch [9/50] batch [40/403] time 0.084 (0.101) data 0.000 (0.015) loss 2.0691 (1.9023) teacher_loss 0.9553 (0.8554) loss_zs_kd 1.3855 (1.4567) loss_oracle 1.2617 (1.1345) kd_loss 0.9876 (0.9335) acc 65.6250 (72.5000) lr 1.9048e-03 eta 0:28:26
epoch [9/50] batch [60/403] time 0.083 (0.095) data 0.000 (0.010) loss 1.9180 (1.9101) teacher_loss 0.8615 (0.8588) loss_zs_kd 1.4902 (1.4366) loss_oracle 1.1159 (1.1418) kd_loss 0.9449 (0.9372) acc 65.6250 (71.4062) lr 1.9048e-03 eta 0:26:50
epoch [9/50] batch [80/403] time 0.086 (0.093) data 0.000 (0.007) loss 1.7938 (1.9117) teacher_loss 0.7811 (0.8625) loss_zs_kd 1.4619 (1.4261) loss_oracle 1.0588 (1.1365) kd_loss 0.9069 (0.9355) acc 71.8750 (70.9766) lr 1.9048e-03 eta 0:26:01
epoch [9/50] batch [100/403] time 0.086 (0.091) data 0.000 (0.006) loss 2.1049 (1.9292) teacher_loss 0.8301 (0.8762) loss_zs_kd 1.8319 (1.4273) loss_oracle 1.2054 (1.1414) kd_loss 1.1543 (0.9389) acc 59.3750 (69.9062) lr 1.9048e-03 eta 0:25:31
epoch [9/50] batch [120/403] time 0.072 (0.089) data 0.000 (0.005) loss 1.9905 (1.9658) teacher_loss 0.8334 (0.8971) loss_zs_kd 1.4477 (1.4321) loss_oracle 1.0637 (1.1423) kd_loss 1.0507 (0.9545) acc 75.0000 (69.1667) lr 1.9048e-03 eta 0:24:50
epoch [9/50] batch [140/403] time 0.085 (0.088) data 0.000 (0.004) loss 1.6498 (1.9621) teacher_loss 0.6664 (0.8947) loss_zs_kd 1.5914 (1.4503) loss_oracle 1.0548 (1.1406) kd_loss 0.8780 (0.9534) acc 81.2500 (69.2857) lr 1.9048e-03 eta 0:24:37
epoch [9/50] batch [160/403] time 0.088 (0.089) data 0.000 (0.004) loss 1.6731 (1.9597) teacher_loss 0.8198 (0.9009) loss_zs_kd 1.5923 (1.4668) loss_oracle 1.0293 (1.1342) kd_loss 0.7504 (0.9454) acc 71.8750 (68.9844) lr 1.9048e-03 eta 0:24:47
epoch [9/50] batch [180/403] time 0.084 (0.089) data 0.000 (0.003) loss 1.8095 (1.9366) teacher_loss 0.8339 (0.8944) loss_zs_kd 1.2094 (1.4672) loss_oracle 1.0040 (1.1210) kd_loss 0.8752 (0.9300) acc 59.3750 (69.3056) lr 1.9048e-03 eta 0:24:44
epoch [9/50] batch [200/403] time 0.090 (0.089) data 0.000 (0.003) loss 1.8969 (1.9253) teacher_loss 0.9490 (0.8918) loss_zs_kd 1.4217 (1.4570) loss_oracle 0.9656 (1.1131) kd_loss 0.8513 (0.9222) acc 62.5000 (69.2812) lr 1.9048e-03 eta 0:24:41
epoch [9/50] batch [220/403] time 0.090 (0.088) data 0.000 (0.003) loss 2.0086 (1.9157) teacher_loss 0.9039 (0.8878) loss_zs_kd 1.5399 (1.4677) loss_oracle 1.0391 (1.1030) kd_loss 1.0008 (0.9177) acc 65.6250 (69.4602) lr 1.9048e-03 eta 0:24:37
epoch [9/50] batch [240/403] time 0.086 (0.088) data 0.000 (0.003) loss 1.7514 (1.9123) teacher_loss 0.6702 (0.8842) loss_zs_kd 1.2421 (1.4774) loss_oracle 1.1381 (1.1005) kd_loss 0.9674 (0.9181) acc 71.8750 (69.5573) lr 1.9048e-03 eta 0:24:32
epoch [9/50] batch [260/403] time 0.131 (0.089) data 0.001 (0.002) loss 1.9764 (1.9029) teacher_loss 1.0963 (0.8790) loss_zs_kd 1.6090 (1.4787) loss_oracle 1.0186 (1.0979) kd_loss 0.7782 (0.9141) acc 62.5000 (69.8197) lr 1.9048e-03 eta 0:24:48
epoch [9/50] batch [280/403] time 0.069 (0.089) data 0.000 (0.002) loss 1.3407 (1.8979) teacher_loss 0.4978 (0.8785) loss_zs_kd 1.3397 (1.4783) loss_oracle 0.9272 (1.0923) kd_loss 0.7501 (0.9102) acc 84.3750 (69.9107) lr 1.9048e-03 eta 0:24:35
epoch [9/50] batch [300/403] time 0.076 (0.088) data 0.000 (0.002) loss 1.7444 (1.8863) teacher_loss 0.7961 (0.8721) loss_zs_kd 1.5635 (1.4807) loss_oracle 0.9487 (1.0865) kd_loss 0.8535 (0.9056) acc 65.6250 (70.1875) lr 1.9048e-03 eta 0:24:15
epoch [9/50] batch [320/403] time 0.086 (0.087) data 0.000 (0.002) loss 1.6340 (1.8769) teacher_loss 0.7517 (0.8678) loss_zs_kd 1.5891 (1.4821) loss_oracle 1.0056 (1.0820) kd_loss 0.7817 (0.9008) acc 75.0000 (70.3809) lr 1.9048e-03 eta 0:24:02
epoch [9/50] batch [340/403] time 0.079 (0.086) data 0.000 (0.002) loss 1.8173 (1.8700) teacher_loss 0.7996 (0.8625) loss_zs_kd 1.5776 (1.4844) loss_oracle 1.0677 (1.0811) kd_loss 0.9110 (0.8994) acc 68.7500 (70.4779) lr 1.9048e-03 eta 0:23:53
epoch [9/50] batch [360/403] time 0.079 (0.086) data 0.000 (0.002) loss 1.6953 (1.8659) teacher_loss 0.6258 (0.8596) loss_zs_kd 1.1769 (1.4846) loss_oracle 0.9801 (1.0788) kd_loss 0.9715 (0.8984) acc 71.8750 (70.6076) lr 1.9048e-03 eta 0:23:51
epoch [9/50] batch [380/403] time 0.082 (0.086) data 0.000 (0.002) loss 1.5846 (1.8597) teacher_loss 0.6191 (0.8566) loss_zs_kd 1.4471 (1.4878) loss_oracle 1.0982 (1.0760) kd_loss 0.8556 (0.8955) acc 78.1250 (70.7648) lr 1.9048e-03 eta 0:23:45
epoch [9/50] batch [400/403] time 0.074 (0.086) data 0.000 (0.002) loss 1.6707 (1.8551) teacher_loss 0.8676 (0.8547) loss_zs_kd 1.4754 (1.4873) loss_oracle 0.9149 (1.0711) kd_loss 0.7116 (0.8933) acc 62.5000 (70.7891) lr 1.9048e-03 eta 0:23:37
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,726
* accuracy: 67.3%
* error: 32.7%
* macro_f1: 51.0%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 1,955
* accuracy: 33.2%
* error: 66.8%
* macro_f1: 24.9%
******* Domain 4 best val acc:      68.6%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [10/50] batch [20/403] time 0.086 (0.129) data 0.000 (0.027) loss 1.7449 (1.7871) teacher_loss 0.7667 (0.8410) loss_zs_kd 1.6044 (1.4943) loss_oracle 1.0665 (1.0055) kd_loss 0.8716 (0.8455) acc 75.0000 (71.4062) lr 1.8763e-03 eta 0:35:21
epoch [10/50] batch [40/403] time 0.087 (0.104) data 0.000 (0.013) loss 1.8282 (1.7694) teacher_loss 0.8324 (0.8291) loss_zs_kd 1.5307 (1.4910) loss_oracle 1.2111 (1.0210) kd_loss 0.8747 (0.8382) acc 65.6250 (71.7188) lr 1.8763e-03 eta 0:28:26
epoch [10/50] batch [60/403] time 0.080 (0.096) data 0.001 (0.009) loss 1.5440 (1.7636) teacher_loss 0.5032 (0.8016) loss_zs_kd 1.6928 (1.5096) loss_oracle 1.1684 (1.0401) kd_loss 0.9240 (0.8581) acc 84.3750 (72.6042) lr 1.8763e-03 eta 0:26:16
epoch [10/50] batch [80/403] time 0.082 (0.092) data 0.000 (0.007) loss 2.1712 (1.7879) teacher_loss 1.1120 (0.8167) loss_zs_kd 1.3126 (1.5313) loss_oracle 1.0921 (1.0379) kd_loss 0.9500 (0.8675) acc 59.3750 (72.2266) lr 1.8763e-03 eta 0:25:18
epoch [10/50] batch [100/403] time 0.089 (0.090) data 0.000 (0.006) loss 1.8349 (1.7995) teacher_loss 0.7496 (0.8140) loss_zs_kd 1.5905 (1.5279) loss_oracle 0.9941 (1.0377) kd_loss 0.9859 (0.8818) acc 78.1250 (72.0625) lr 1.8763e-03 eta 0:24:36
epoch [10/50] batch [120/403] time 0.078 (0.088) data 0.000 (0.005) loss 1.8102 (1.8477) teacher_loss 0.6392 (0.8352) loss_zs_kd 1.8060 (1.5285) loss_oracle 1.0918 (1.0507) kd_loss 1.0618 (0.9074) acc 78.1250 (71.5104) lr 1.8763e-03 eta 0:24:09
epoch [10/50] batch [140/403] time 0.080 (0.087) data 0.000 (0.004) loss 2.0376 (1.8860) teacher_loss 0.8999 (0.8511) loss_zs_kd 1.5037 (1.5343) loss_oracle 1.0433 (1.0594) kd_loss 1.0334 (0.9290) acc 62.5000 (70.7143) lr 1.8763e-03 eta 0:23:47
epoch [10/50] batch [160/403] time 0.083 (0.087) data 0.000 (0.004) loss 2.0006 (1.8877) teacher_loss 0.8543 (0.8498) loss_zs_kd 1.8381 (1.5279) loss_oracle 1.1109 (1.0616) kd_loss 1.0352 (0.9317) acc 68.7500 (70.7617) lr 1.8763e-03 eta 0:23:38
epoch [10/50] batch [180/403] time 0.077 (0.086) data 0.000 (0.003) loss 2.3307 (1.8947) teacher_loss 1.2700 (0.8525) loss_zs_kd 2.0107 (1.5296) loss_oracle 1.2400 (1.0705) kd_loss 0.9367 (0.9351) acc 65.6250 (70.7812) lr 1.8763e-03 eta 0:23:30
epoch [10/50] batch [200/403] time 0.086 (0.086) data 0.000 (0.003) loss 1.7556 (1.8944) teacher_loss 0.7574 (0.8524) loss_zs_kd 1.2011 (1.5263) loss_oracle 1.1624 (1.0818) kd_loss 0.8820 (0.9338) acc 71.8750 (70.8594) lr 1.8763e-03 eta 0:23:16
epoch [10/50] batch [220/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.9204 (1.8858) teacher_loss 0.8885 (0.8478) loss_zs_kd 1.2201 (1.5206) loss_oracle 1.1564 (1.0872) kd_loss 0.9163 (0.9293) acc 68.7500 (71.0511) lr 1.8763e-03 eta 0:23:05
epoch [10/50] batch [240/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.1280 (1.8758) teacher_loss 1.1932 (0.8467) loss_zs_kd 1.4982 (1.5144) loss_oracle 1.0495 (1.0852) kd_loss 0.8299 (0.9206) acc 56.2500 (71.0156) lr 1.8763e-03 eta 0:23:02
epoch [10/50] batch [260/403] time 0.076 (0.085) data 0.000 (0.002) loss 1.8312 (1.8692) teacher_loss 0.7807 (0.8459) loss_zs_kd 1.2860 (1.5005) loss_oracle 1.1257 (1.0823) kd_loss 0.9379 (0.9151) acc 78.1250 (71.0337) lr 1.8763e-03 eta 0:22:55
epoch [10/50] batch [280/403] time 0.095 (0.085) data 0.000 (0.002) loss 2.0031 (1.8682) teacher_loss 0.8302 (0.8441) loss_zs_kd 2.0357 (1.5035) loss_oracle 1.2633 (1.0854) kd_loss 1.0465 (0.9156) acc 75.0000 (70.9933) lr 1.8763e-03 eta 0:22:56
epoch [10/50] batch [300/403] time 0.081 (0.085) data 0.000 (0.002) loss 1.9326 (1.8699) teacher_loss 0.8938 (0.8487) loss_zs_kd 1.3123 (1.5049) loss_oracle 0.9937 (1.0844) kd_loss 0.9395 (0.9127) acc 65.6250 (70.8125) lr 1.8763e-03 eta 0:22:53
epoch [10/50] batch [320/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.8150 (1.8707) teacher_loss 0.7461 (0.8515) loss_zs_kd 1.4646 (1.5022) loss_oracle 1.0680 (1.0820) kd_loss 0.9621 (0.9110) acc 75.0000 (70.8887) lr 1.8763e-03 eta 0:22:49
epoch [10/50] batch [340/403] time 0.079 (0.084) data 0.000 (0.002) loss 2.0976 (1.8679) teacher_loss 0.9809 (0.8503) loss_zs_kd 1.3161 (1.4953) loss_oracle 1.2598 (1.0797) kd_loss 0.9907 (0.9096) acc 62.5000 (70.8732) lr 1.8763e-03 eta 0:22:41
epoch [10/50] batch [360/403] time 0.084 (0.084) data 0.000 (0.002) loss 2.4767 (1.8666) teacher_loss 1.4698 (0.8472) loss_zs_kd 2.1252 (1.4962) loss_oracle 1.0618 (1.0804) kd_loss 0.9008 (0.9113) acc 62.5000 (71.0851) lr 1.8763e-03 eta 0:22:37
epoch [10/50] batch [380/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.7175 (1.8722) teacher_loss 0.8026 (0.8485) loss_zs_kd 1.6216 (1.4983) loss_oracle 1.1555 (1.0852) kd_loss 0.7994 (0.9152) acc 78.1250 (71.1431) lr 1.8763e-03 eta 0:22:36
epoch [10/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.002) loss 1.8421 (1.8749) teacher_loss 1.0082 (0.8495) loss_zs_kd 1.5977 (1.5031) loss_oracle 1.0330 (1.0892) kd_loss 0.7306 (0.9165) acc 56.2500 (71.1016) lr 1.8763e-03 eta 0:22:31
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,750
* accuracy: 67.8%
* error: 32.2%
* macro_f1: 52.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,032
* accuracy: 34.5%
* error: 65.5%
* macro_f1: 26.2%
******* Domain 4 best val acc:      68.6%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [11/50] batch [20/403] time 0.087 (0.108) data 0.001 (0.026) loss 2.1759 (1.8395) teacher_loss 1.1609 (0.8459) loss_zs_kd 1.6938 (1.5966) loss_oracle 1.1782 (1.1476) kd_loss 0.8972 (0.8788) acc 65.6250 (69.2188) lr 1.8443e-03 eta 0:29:04
epoch [11/50] batch [40/403] time 0.081 (0.095) data 0.000 (0.013) loss 1.6265 (1.8404) teacher_loss 0.6430 (0.8474) loss_zs_kd 1.5136 (1.6107) loss_oracle 1.0583 (1.1572) kd_loss 0.8776 (0.8772) acc 75.0000 (70.9375) lr 1.8443e-03 eta 0:25:26
epoch [11/50] batch [60/403] time 0.080 (0.090) data 0.000 (0.009) loss 1.8937 (1.8330) teacher_loss 0.6983 (0.8299) loss_zs_kd 1.2991 (1.5080) loss_oracle 1.1678 (1.1537) kd_loss 1.0787 (0.8877) acc 78.1250 (71.2500) lr 1.8443e-03 eta 0:24:02
epoch [11/50] batch [80/403] time 0.081 (0.088) data 0.000 (0.007) loss 1.7845 (1.8233) teacher_loss 0.8507 (0.8178) loss_zs_kd 1.5923 (1.4683) loss_oracle 1.0853 (1.1453) kd_loss 0.8253 (0.8910) acc 71.8750 (71.6016) lr 1.8443e-03 eta 0:23:26
epoch [11/50] batch [100/403] time 0.088 (0.087) data 0.000 (0.005) loss 1.9172 (1.8398) teacher_loss 0.8617 (0.8252) loss_zs_kd 1.4108 (1.4914) loss_oracle 1.2546 (1.1540) kd_loss 0.9301 (0.8992) acc 75.0000 (71.6250) lr 1.8443e-03 eta 0:23:20
epoch [11/50] batch [120/403] time 0.083 (0.087) data 0.000 (0.005) loss 1.7915 (1.8290) teacher_loss 0.8595 (0.8140) loss_zs_kd 1.6012 (1.5020) loss_oracle 0.9848 (1.1476) kd_loss 0.8336 (0.9003) acc 75.0000 (72.1354) lr 1.8443e-03 eta 0:23:05
epoch [11/50] batch [140/403] time 0.080 (0.085) data 0.000 (0.004) loss 1.5254 (1.8256) teacher_loss 0.4784 (0.8093) loss_zs_kd 1.7594 (1.5071) loss_oracle 1.0829 (1.1485) kd_loss 0.9387 (0.9015) acc 84.3750 (72.2321) lr 1.8443e-03 eta 0:22:44
epoch [11/50] batch [160/403] time 0.087 (0.085) data 0.000 (0.003) loss 1.8562 (1.8395) teacher_loss 0.7684 (0.8130) loss_zs_kd 2.1206 (1.5179) loss_oracle 1.1854 (1.1587) kd_loss 0.9693 (0.9106) acc 68.7500 (71.8359) lr 1.8443e-03 eta 0:22:35
epoch [11/50] batch [180/403] time 0.077 (0.087) data 0.000 (0.003) loss 1.7901 (1.8424) teacher_loss 0.7260 (0.8121) loss_zs_kd 1.5539 (1.5205) loss_oracle 1.0678 (1.1617) kd_loss 0.9573 (0.9141) acc 68.7500 (71.7188) lr 1.8443e-03 eta 0:23:04
epoch [11/50] batch [200/403] time 0.094 (0.087) data 0.000 (0.003) loss 1.8505 (1.8401) teacher_loss 0.9671 (0.8118) loss_zs_kd 1.7829 (1.5197) loss_oracle 1.1486 (1.1594) kd_loss 0.7686 (0.9124) acc 68.7500 (71.7031) lr 1.8443e-03 eta 0:22:57
epoch [11/50] batch [220/403] time 0.093 (0.086) data 0.000 (0.003) loss 1.9624 (1.8500) teacher_loss 0.8957 (0.8196) loss_zs_kd 1.1972 (1.5159) loss_oracle 1.0794 (1.1606) kd_loss 0.9588 (0.9144) acc 59.3750 (71.3778) lr 1.8443e-03 eta 0:22:45
epoch [11/50] batch [240/403] time 0.093 (0.086) data 0.000 (0.002) loss 2.3450 (1.8582) teacher_loss 1.2622 (0.8257) loss_zs_kd 1.4620 (1.4983) loss_oracle 1.2247 (1.1649) kd_loss 0.9603 (0.9160) acc 53.1250 (71.1719) lr 1.8443e-03 eta 0:22:43
epoch [11/50] batch [260/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.8120 (1.8605) teacher_loss 0.6614 (0.8237) loss_zs_kd 1.6726 (1.4963) loss_oracle 1.2539 (1.1705) kd_loss 1.0252 (0.9197) acc 75.0000 (71.4543) lr 1.8443e-03 eta 0:22:35
epoch [11/50] batch [280/403] time 0.080 (0.085) data 0.000 (0.002) loss 1.3715 (1.8576) teacher_loss 0.3870 (0.8219) loss_zs_kd 2.0103 (1.5071) loss_oracle 1.0617 (1.1699) kd_loss 0.8783 (0.9187) acc 90.6250 (71.5179) lr 1.8443e-03 eta 0:22:31
epoch [11/50] batch [300/403] time 0.102 (0.085) data 0.000 (0.002) loss 1.9047 (1.8577) teacher_loss 0.8035 (0.8231) loss_zs_kd 1.0644 (1.5148) loss_oracle 1.2338 (1.1711) kd_loss 0.9779 (0.9175) acc 71.8750 (71.6354) lr 1.8443e-03 eta 0:22:29
epoch [11/50] batch [320/403] time 0.095 (0.085) data 0.000 (0.002) loss 2.1187 (1.8546) teacher_loss 1.1761 (0.8238) loss_zs_kd 1.5139 (1.5115) loss_oracle 1.2345 (1.1691) kd_loss 0.8192 (0.9139) acc 62.5000 (71.6113) lr 1.8443e-03 eta 0:22:27
epoch [11/50] batch [340/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.8767 (1.8540) teacher_loss 0.9699 (0.8252) loss_zs_kd 1.8221 (1.5091) loss_oracle 1.1429 (1.1681) kd_loss 0.7924 (0.9119) acc 65.6250 (71.7096) lr 1.8443e-03 eta 0:22:23
epoch [11/50] batch [360/403] time 0.090 (0.085) data 0.000 (0.002) loss 1.6509 (1.8479) teacher_loss 0.7079 (0.8217) loss_zs_kd 1.5763 (1.5092) loss_oracle 1.2330 (1.1696) kd_loss 0.8196 (0.9092) acc 78.1250 (71.8490) lr 1.8443e-03 eta 0:22:20
epoch [11/50] batch [380/403] time 0.082 (0.085) data 0.000 (0.002) loss 2.1449 (1.8459) teacher_loss 1.0976 (0.8245) loss_zs_kd 1.5224 (1.5018) loss_oracle 1.1634 (1.1693) kd_loss 0.9310 (0.9045) acc 59.3750 (71.7352) lr 1.8443e-03 eta 0:22:15
epoch [11/50] batch [400/403] time 0.080 (0.085) data 0.000 (0.002) loss 1.7448 (1.8453) teacher_loss 0.8374 (0.8271) loss_zs_kd 1.4678 (1.5015) loss_oracle 1.0417 (1.1681) kd_loss 0.8032 (0.9014) acc 68.7500 (71.6875) lr 1.8443e-03 eta 0:22:12
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,765
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 52.2%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,072
* accuracy: 35.2%
* error: 64.8%
* macro_f1: 25.6%
******* Domain 4 best val acc:      68.6%, epoch: 8 *******
******* Domain 4 best val test acc: 35.4%, epoch: 8 *******
******* Domain 4 best test acc:     36.6%, epoch: 7 *******
epoch [12/50] batch [20/403] time 0.078 (0.119) data 0.000 (0.032) loss 1.9834 (1.8351) teacher_loss 0.9639 (0.8673) loss_zs_kd 1.4244 (1.3730) loss_oracle 1.1664 (1.1114) kd_loss 0.9029 (0.8567) acc 59.3750 (69.8438) lr 1.8090e-03 eta 0:31:08
epoch [12/50] batch [40/403] time 0.085 (0.099) data 0.000 (0.016) loss 2.3677 (1.8335) teacher_loss 1.3348 (0.8739) loss_zs_kd 1.6182 (1.4125) loss_oracle 1.1152 (1.1006) kd_loss 0.9214 (0.8496) acc 43.7500 (70.3125) lr 1.8090e-03 eta 0:25:53
epoch [12/50] batch [60/403] time 0.084 (0.093) data 0.001 (0.011) loss 1.8532 (1.8039) teacher_loss 0.8364 (0.8556) loss_zs_kd 1.3509 (1.4064) loss_oracle 1.1014 (1.0887) kd_loss 0.9066 (0.8394) acc 75.0000 (70.9896) lr 1.8090e-03 eta 0:24:13
epoch [12/50] batch [80/403] time 0.084 (0.090) data 0.000 (0.008) loss 2.2347 (1.8106) teacher_loss 1.1707 (0.8467) loss_zs_kd 1.3964 (1.4068) loss_oracle 1.0732 (1.1035) kd_loss 0.9566 (0.8535) acc 65.6250 (70.9766) lr 1.8090e-03 eta 0:23:29
epoch [12/50] batch [100/403] time 0.080 (0.089) data 0.000 (0.007) loss 1.7555 (1.8206) teacher_loss 0.6861 (0.8500) loss_zs_kd 1.1831 (1.3868) loss_oracle 1.0807 (1.1030) kd_loss 0.9614 (0.8603) acc 78.1250 (70.4688) lr 1.8090e-03 eta 0:23:11
epoch [12/50] batch [120/403] time 0.094 (0.089) data 0.001 (0.006) loss 2.1883 (1.8272) teacher_loss 1.2069 (0.8531) loss_zs_kd 1.5175 (1.3858) loss_oracle 1.2009 (1.1143) kd_loss 0.8613 (0.8627) acc 53.1250 (70.2604) lr 1.8090e-03 eta 0:23:01
epoch [12/50] batch [140/403] time 0.083 (0.088) data 0.000 (0.005) loss 2.0887 (1.8382) teacher_loss 0.9877 (0.8599) loss_zs_kd 1.4666 (1.3898) loss_oracle 1.2385 (1.1252) kd_loss 0.9771 (0.8657) acc 65.6250 (70.1786) lr 1.8090e-03 eta 0:22:56
epoch [12/50] batch [160/403] time 0.088 (0.088) data 0.000 (0.004) loss 1.9364 (1.8579) teacher_loss 0.8081 (0.8702) loss_zs_kd 1.4428 (1.3860) loss_oracle 1.2254 (1.1293) kd_loss 1.0058 (0.8748) acc 75.0000 (70.0977) lr 1.8090e-03 eta 0:22:49
epoch [12/50] batch [180/403] time 0.080 (0.088) data 0.000 (0.004) loss 1.9930 (1.8801) teacher_loss 0.9425 (0.8786) loss_zs_kd 2.1555 (1.3878) loss_oracle 1.2448 (1.1378) kd_loss 0.9260 (0.8877) acc 59.3750 (69.7222) lr 1.8090e-03 eta 0:22:42
epoch [12/50] batch [200/403] time 0.081 (0.087) data 0.000 (0.003) loss 2.2901 (1.8893) teacher_loss 0.9785 (0.8788) loss_zs_kd 1.6313 (1.3919) loss_oracle 1.3135 (1.1492) kd_loss 1.1803 (0.8956) acc 65.6250 (69.6562) lr 1.8090e-03 eta 0:22:25
epoch [12/50] batch [220/403] time 0.078 (0.086) data 0.000 (0.003) loss 1.6664 (1.8895) teacher_loss 0.6811 (0.8703) loss_zs_kd 1.4887 (1.4098) loss_oracle 1.2302 (1.1585) kd_loss 0.8624 (0.9033) acc 81.2500 (70.0284) lr 1.8090e-03 eta 0:22:10
epoch [12/50] batch [240/403] time 0.079 (0.086) data 0.000 (0.003) loss 2.2398 (1.9064) teacher_loss 1.0352 (0.8751) loss_zs_kd 1.6641 (1.4220) loss_oracle 1.2960 (1.1651) kd_loss 1.0750 (0.9148) acc 56.2500 (69.7266) lr 1.8090e-03 eta 0:22:06
epoch [12/50] batch [260/403] time 0.080 (0.086) data 0.000 (0.003) loss 2.2698 (1.9226) teacher_loss 1.0529 (0.8798) loss_zs_kd 1.1938 (1.4251) loss_oracle 1.2232 (1.1702) kd_loss 1.0946 (0.9257) acc 62.5000 (69.6514) lr 1.8090e-03 eta 0:22:05
epoch [12/50] batch [280/403] time 0.087 (0.086) data 0.000 (0.003) loss 1.8922 (1.9283) teacher_loss 0.7720 (0.8773) loss_zs_kd 1.6369 (1.4261) loss_oracle 1.1830 (1.1737) kd_loss 1.0018 (0.9336) acc 71.8750 (69.7321) lr 1.8090e-03 eta 0:22:03
epoch [12/50] batch [300/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.8678 (1.9333) teacher_loss 0.7950 (0.8787) loss_zs_kd 1.4486 (1.4284) loss_oracle 1.2011 (1.1749) kd_loss 0.9527 (0.9371) acc 68.7500 (69.6875) lr 1.8090e-03 eta 0:21:55
epoch [12/50] batch [320/403] time 0.100 (0.085) data 0.000 (0.002) loss 1.8472 (1.9293) teacher_loss 0.7944 (0.8756) loss_zs_kd 1.8540 (1.4318) loss_oracle 1.1957 (1.1747) kd_loss 0.9332 (0.9362) acc 75.0000 (69.8047) lr 1.8090e-03 eta 0:21:49
epoch [12/50] batch [340/403] time 0.078 (0.086) data 0.000 (0.002) loss 1.7207 (1.9292) teacher_loss 0.8201 (0.8749) loss_zs_kd 1.7973 (1.4418) loss_oracle 1.2814 (1.1761) kd_loss 0.7725 (0.9367) acc 68.7500 (70.0000) lr 1.8090e-03 eta 0:22:03
epoch [12/50] batch [360/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.7966 (1.9262) teacher_loss 0.9349 (0.8723) loss_zs_kd 1.2033 (1.4516) loss_oracle 1.1803 (1.1778) kd_loss 0.7437 (0.9361) acc 75.0000 (70.0781) lr 1.8090e-03 eta 0:21:56
epoch [12/50] batch [380/403] time 0.064 (0.085) data 0.000 (0.002) loss 1.7597 (1.9204) teacher_loss 0.8021 (0.8704) loss_zs_kd 1.8502 (1.4553) loss_oracle 1.2073 (1.1778) kd_loss 0.8369 (0.9322) acc 78.1250 (70.2220) lr 1.8090e-03 eta 0:21:50
epoch [12/50] batch [400/403] time 0.074 (0.085) data 0.000 (0.002) loss 2.3198 (1.9184) teacher_loss 1.2702 (0.8689) loss_zs_kd 1.3949 (1.4564) loss_oracle 1.1795 (1.1757) kd_loss 0.9317 (0.9320) acc 50.0000 (70.3359) lr 1.8090e-03 eta 0:21:37
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,801
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 53.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,178
* accuracy: 37.0%
* error: 63.0%
* macro_f1: 27.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      68.7%, epoch: 12 *******
******* Domain 4 best val test acc: 37.0%, epoch: 12 *******
******* Domain 4 best test acc:     37.0%, epoch: 12 *******
epoch [13/50] batch [20/403] time 0.082 (0.107) data 0.000 (0.024) loss 1.6780 (1.7991) teacher_loss 0.7115 (0.8092) loss_zs_kd 1.5648 (1.4280) loss_oracle 1.0393 (1.0987) kd_loss 0.8625 (0.8800) acc 75.0000 (71.2500) lr 1.7705e-03 eta 0:27:12
epoch [13/50] batch [40/403] time 0.073 (0.092) data 0.000 (0.012) loss 1.7376 (1.8058) teacher_loss 0.7775 (0.8116) loss_zs_kd 1.5537 (1.4960) loss_oracle 0.9806 (1.1036) kd_loss 0.8620 (0.8838) acc 78.1250 (73.1250) lr 1.7705e-03 eta 0:23:32
epoch [13/50] batch [60/403] time 0.096 (0.088) data 0.001 (0.008) loss 2.3435 (1.8207) teacher_loss 1.4570 (0.8228) loss_zs_kd 1.6723 (1.4787) loss_oracle 1.0383 (1.1062) kd_loss 0.7826 (0.8872) acc 56.2500 (72.7083) lr 1.7705e-03 eta 0:22:24
epoch [13/50] batch [80/403] time 0.068 (0.091) data 0.000 (0.006) loss 1.9433 (1.8238) teacher_loss 0.9173 (0.8227) loss_zs_kd 1.3874 (1.4575) loss_oracle 1.1237 (1.1144) kd_loss 0.9136 (0.8896) acc 65.6250 (71.9141) lr 1.7705e-03 eta 0:23:12
epoch [13/50] batch [100/403] time 0.083 (0.089) data 0.000 (0.005) loss 1.8134 (1.8376) teacher_loss 0.7648 (0.8333) loss_zs_kd 1.2205 (1.4691) loss_oracle 1.0319 (1.1166) kd_loss 0.9454 (0.8927) acc 78.1250 (71.8750) lr 1.7705e-03 eta 0:22:26
epoch [13/50] batch [120/403] time 0.076 (0.088) data 0.000 (0.004) loss 1.9517 (1.8325) teacher_loss 0.8776 (0.8287) loss_zs_kd 1.5918 (1.4800) loss_oracle 1.0669 (1.1105) kd_loss 0.9675 (0.8928) acc 71.8750 (72.0052) lr 1.7705e-03 eta 0:22:14
epoch [13/50] batch [140/403] time 0.082 (0.086) data 0.001 (0.004) loss 1.7059 (1.8182) teacher_loss 0.6474 (0.8188) loss_zs_kd 1.3037 (1.5033) loss_oracle 1.0299 (1.1018) kd_loss 0.9555 (0.8893) acc 75.0000 (72.4554) lr 1.7705e-03 eta 0:21:50
epoch [13/50] batch [160/403] time 0.089 (0.086) data 0.000 (0.003) loss 1.6103 (1.8163) teacher_loss 0.5342 (0.8157) loss_zs_kd 1.5659 (1.4894) loss_oracle 1.0313 (1.0983) kd_loss 0.9729 (0.8907) acc 87.5000 (72.6367) lr 1.7705e-03 eta 0:21:44
epoch [13/50] batch [180/403] time 0.082 (0.086) data 0.000 (0.003) loss 1.6815 (1.8054) teacher_loss 0.6677 (0.8117) loss_zs_kd 1.3875 (1.4704) loss_oracle 1.1213 (1.0941) kd_loss 0.9016 (0.8844) acc 81.2500 (72.9340) lr 1.7705e-03 eta 0:21:43
epoch [13/50] batch [200/403] time 0.087 (0.086) data 0.000 (0.003) loss 1.8098 (1.8056) teacher_loss 0.7917 (0.8143) loss_zs_kd 1.4588 (1.4573) loss_oracle 1.0876 (1.0926) kd_loss 0.9093 (0.8821) acc 71.8750 (72.6406) lr 1.7705e-03 eta 0:21:40
epoch [13/50] batch [220/403] time 0.092 (0.086) data 0.000 (0.002) loss 1.8128 (1.8066) teacher_loss 0.8780 (0.8169) loss_zs_kd 1.1799 (1.4554) loss_oracle 1.0077 (1.0900) kd_loss 0.8340 (0.8807) acc 71.8750 (72.2727) lr 1.7705e-03 eta 0:21:34
epoch [13/50] batch [240/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.5693 (1.8105) teacher_loss 0.5928 (0.8217) loss_zs_kd 1.4060 (1.4588) loss_oracle 1.1153 (1.0898) kd_loss 0.8649 (0.8799) acc 81.2500 (72.2786) lr 1.7705e-03 eta 0:21:33
epoch [13/50] batch [260/403] time 0.076 (0.086) data 0.000 (0.002) loss 1.4493 (1.8063) teacher_loss 0.5905 (0.8201) loss_zs_kd 1.2139 (1.4506) loss_oracle 1.1219 (1.0910) kd_loss 0.7466 (0.8771) acc 71.8750 (72.1274) lr 1.7705e-03 eta 0:21:34
epoch [13/50] batch [280/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.7331 (1.8060) teacher_loss 0.9029 (0.8225) loss_zs_kd 1.5594 (1.4442) loss_oracle 0.9590 (1.0921) kd_loss 0.7344 (0.8743) acc 71.8750 (71.9866) lr 1.7705e-03 eta 0:21:28
epoch [13/50] batch [300/403] time 0.076 (0.086) data 0.000 (0.002) loss 1.4024 (1.8004) teacher_loss 0.6314 (0.8218) loss_zs_kd 1.0162 (1.4395) loss_oracle 0.8415 (1.0880) kd_loss 0.6869 (0.8698) acc 78.1250 (72.0417) lr 1.7705e-03 eta 0:21:25
epoch [13/50] batch [320/403] time 0.071 (0.085) data 0.000 (0.002) loss 1.8182 (1.8059) teacher_loss 0.8639 (0.8283) loss_zs_kd 1.1252 (1.4324) loss_oracle 0.9324 (1.0843) kd_loss 0.8611 (0.8691) acc 59.3750 (71.8066) lr 1.7705e-03 eta 0:21:21
epoch [13/50] batch [340/403] time 0.087 (0.085) data 0.000 (0.002) loss 1.6772 (1.8002) teacher_loss 0.5956 (0.8216) loss_zs_kd 1.4503 (1.4325) loss_oracle 1.0536 (1.0831) kd_loss 0.9763 (0.8703) acc 71.8750 (72.0221) lr 1.7705e-03 eta 0:21:14
epoch [13/50] batch [360/403] time 0.081 (0.085) data 0.000 (0.002) loss 2.2635 (1.8031) teacher_loss 1.2015 (0.8229) loss_zs_kd 1.3273 (1.4405) loss_oracle 1.1247 (1.0863) kd_loss 0.9496 (0.8716) acc 56.2500 (71.9965) lr 1.7705e-03 eta 0:21:10
epoch [13/50] batch [380/403] time 0.081 (0.084) data 0.000 (0.002) loss 1.9238 (1.8014) teacher_loss 0.8621 (0.8225) loss_zs_kd 1.5493 (1.4468) loss_oracle 1.1939 (1.0883) kd_loss 0.9423 (0.8701) acc 71.8750 (71.9901) lr 1.7705e-03 eta 0:21:01
epoch [13/50] batch [400/403] time 0.072 (0.084) data 0.000 (0.001) loss 1.7572 (1.8030) teacher_loss 0.8519 (0.8235) loss_zs_kd 1.5623 (1.4452) loss_oracle 1.0249 (1.0898) kd_loss 0.8028 (0.8705) acc 71.8750 (71.9375) lr 1.7705e-03 eta 0:20:54
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,725
* accuracy: 67.3%
* error: 32.7%
* macro_f1: 53.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,121
* accuracy: 36.1%
* error: 63.9%
* macro_f1: 27.4%
******* Domain 4 best val acc:      68.7%, epoch: 12 *******
******* Domain 4 best val test acc: 37.0%, epoch: 12 *******
******* Domain 4 best test acc:     37.0%, epoch: 12 *******
epoch [14/50] batch [20/403] time 0.083 (0.123) data 0.000 (0.034) loss 1.8463 (1.8300) teacher_loss 0.8244 (0.8693) loss_zs_kd 1.1507 (1.5346) loss_oracle 1.0287 (1.0197) kd_loss 0.9191 (0.8588) acc 71.8750 (68.7500) lr 1.7290e-03 eta 0:30:24
epoch [14/50] batch [40/403] time 0.079 (0.103) data 0.000 (0.017) loss 1.5121 (1.8421) teacher_loss 0.5553 (0.8965) loss_zs_kd 1.6259 (1.5143) loss_oracle 1.0260 (1.0233) kd_loss 0.8542 (0.8433) acc 84.3750 (67.8125) lr 1.7290e-03 eta 0:25:35
epoch [14/50] batch [60/403] time 0.079 (0.096) data 0.000 (0.011) loss 1.7283 (1.8241) teacher_loss 0.8046 (0.8772) loss_zs_kd 1.6119 (1.5005) loss_oracle 1.1351 (1.0357) kd_loss 0.8102 (0.8433) acc 75.0000 (69.5312) lr 1.7290e-03 eta 0:23:53
epoch [14/50] batch [80/403] time 0.080 (0.092) data 0.000 (0.009) loss 1.6017 (1.8046) teacher_loss 0.6951 (0.8675) loss_zs_kd 1.6182 (1.5070) loss_oracle 1.0415 (1.0325) kd_loss 0.8025 (0.8338) acc 78.1250 (69.6875) lr 1.7290e-03 eta 0:22:49
epoch [14/50] batch [100/403] time 0.083 (0.090) data 0.000 (0.007) loss 1.7679 (1.7988) teacher_loss 0.9087 (0.8595) loss_zs_kd 1.5675 (1.5025) loss_oracle 1.0137 (1.0355) kd_loss 0.7579 (0.8358) acc 65.6250 (70.0938) lr 1.7290e-03 eta 0:22:16
epoch [14/50] batch [120/403] time 0.085 (0.089) data 0.000 (0.006) loss 1.7698 (1.7907) teacher_loss 0.8353 (0.8520) loss_zs_kd 1.2824 (1.5061) loss_oracle 1.0044 (1.0369) kd_loss 0.8340 (0.8350) acc 68.7500 (70.4427) lr 1.7290e-03 eta 0:21:49
epoch [14/50] batch [140/403] time 0.078 (0.088) data 0.000 (0.005) loss 1.6367 (1.7820) teacher_loss 0.6565 (0.8426) loss_zs_kd 1.7947 (1.5152) loss_oracle 1.1135 (1.0375) kd_loss 0.8689 (0.8357) acc 75.0000 (70.7812) lr 1.7290e-03 eta 0:21:38
epoch [14/50] batch [160/403] time 0.087 (0.087) data 0.000 (0.004) loss 2.0242 (1.7932) teacher_loss 0.9877 (0.8498) loss_zs_kd 1.3909 (1.4975) loss_oracle 1.0869 (1.0364) kd_loss 0.9277 (0.8398) acc 59.3750 (70.5469) lr 1.7290e-03 eta 0:21:20
epoch [14/50] batch [180/403] time 0.073 (0.086) data 0.000 (0.004) loss 2.0050 (1.8118) teacher_loss 0.9337 (0.8499) loss_zs_kd 1.1393 (1.4934) loss_oracle 1.1313 (1.0466) kd_loss 0.9582 (0.8572) acc 71.8750 (70.5903) lr 1.7290e-03 eta 0:21:09
epoch [14/50] batch [200/403] time 0.077 (0.086) data 0.000 (0.004) loss 2.0002 (1.8262) teacher_loss 0.8896 (0.8537) loss_zs_kd 1.3693 (1.4879) loss_oracle 1.1446 (1.0512) kd_loss 0.9962 (0.8674) acc 71.8750 (70.6406) lr 1.7290e-03 eta 0:20:58
epoch [14/50] batch [220/403] time 0.084 (0.085) data 0.000 (0.003) loss 2.0953 (1.8319) teacher_loss 1.1311 (0.8565) loss_zs_kd 1.6275 (1.4914) loss_oracle 1.1018 (1.0517) kd_loss 0.8540 (0.8703) acc 59.3750 (70.8239) lr 1.7290e-03 eta 0:20:49
epoch [14/50] batch [240/403] time 0.136 (0.086) data 0.000 (0.003) loss 2.2901 (1.8324) teacher_loss 1.1956 (0.8544) loss_zs_kd 1.2092 (1.4973) loss_oracle 0.9853 (1.0496) kd_loss 0.9960 (0.8730) acc 59.3750 (70.8984) lr 1.7290e-03 eta 0:20:59
epoch [14/50] batch [260/403] time 0.086 (0.086) data 0.000 (0.003) loss 2.2016 (1.8336) teacher_loss 1.2473 (0.8548) loss_zs_kd 1.6620 (1.4917) loss_oracle 1.0135 (1.0488) kd_loss 0.8529 (0.8739) acc 56.2500 (70.8173) lr 1.7290e-03 eta 0:21:03
epoch [14/50] batch [280/403] time 0.080 (0.086) data 0.000 (0.003) loss 1.6718 (1.8291) teacher_loss 0.6378 (0.8495) loss_zs_kd 1.6111 (1.4904) loss_oracle 1.0929 (1.0497) kd_loss 0.9247 (0.8746) acc 78.1250 (71.1384) lr 1.7290e-03 eta 0:20:58
epoch [14/50] batch [300/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.8807 (1.8305) teacher_loss 0.8299 (0.8485) loss_zs_kd 1.2944 (1.4885) loss_oracle 1.0326 (1.0508) kd_loss 0.9476 (0.8770) acc 62.5000 (71.1042) lr 1.7290e-03 eta 0:20:45
epoch [14/50] batch [320/403] time 0.079 (0.085) data 0.000 (0.002) loss 2.1087 (1.8290) teacher_loss 1.0248 (0.8441) loss_zs_kd 2.1714 (1.4865) loss_oracle 1.1077 (1.0516) kd_loss 0.9731 (0.8797) acc 65.6250 (71.2891) lr 1.7290e-03 eta 0:20:40
epoch [14/50] batch [340/403] time 0.087 (0.085) data 0.000 (0.002) loss 1.6359 (1.8317) teacher_loss 0.6844 (0.8420) loss_zs_kd 2.0193 (1.4931) loss_oracle 0.9778 (1.0520) kd_loss 0.8537 (0.8846) acc 78.1250 (71.3787) lr 1.7290e-03 eta 0:20:36
epoch [14/50] batch [360/403] time 0.085 (0.085) data 0.000 (0.002) loss 2.2751 (1.8379) teacher_loss 1.2101 (0.8445) loss_zs_kd 1.6298 (1.4928) loss_oracle 1.0962 (1.0510) kd_loss 0.9554 (0.8883) acc 53.1250 (71.2587) lr 1.7290e-03 eta 0:20:33
epoch [14/50] batch [380/403] time 0.071 (0.085) data 0.000 (0.002) loss 1.9248 (1.8353) teacher_loss 0.7632 (0.8404) loss_zs_kd 1.2590 (1.4934) loss_oracle 1.0433 (1.0478) kd_loss 1.0573 (0.8902) acc 75.0000 (71.3487) lr 1.7290e-03 eta 0:20:28
epoch [14/50] batch [400/403] time 0.073 (0.084) data 0.000 (0.002) loss 1.7651 (1.8327) teacher_loss 0.7583 (0.8359) loss_zs_kd 1.4520 (1.4966) loss_oracle 0.8899 (1.0449) kd_loss 0.9179 (0.8923) acc 84.3750 (71.5625) lr 1.7290e-03 eta 0:20:21
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,891
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 56.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,252
* accuracy: 38.3%
* error: 61.7%
* macro_f1: 27.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.3%, epoch: 14 *******
******* Domain 4 best val test acc: 38.3%, epoch: 14 *******
******* Domain 4 best test acc:     38.3%, epoch: 14 *******
epoch [15/50] batch [20/403] time 0.081 (0.114) data 0.000 (0.027) loss 1.9775 (1.8776) teacher_loss 0.9585 (0.8457) loss_zs_kd 1.8202 (1.6525) loss_oracle 0.9840 (0.9964) kd_loss 0.9207 (0.9323) acc 59.3750 (71.5625) lr 1.6845e-03 eta 0:27:25
epoch [15/50] batch [40/403] time 0.080 (0.098) data 0.000 (0.014) loss 1.6727 (1.8393) teacher_loss 0.6840 (0.8095) loss_zs_kd 1.9880 (1.6847) loss_oracle 1.1297 (1.0124) kd_loss 0.8757 (0.9286) acc 81.2500 (73.9844) lr 1.6845e-03 eta 0:23:33
epoch [15/50] batch [60/403] time 0.080 (0.094) data 0.000 (0.009) loss 1.8210 (1.8310) teacher_loss 0.8346 (0.8028) loss_zs_kd 1.4446 (1.6475) loss_oracle 0.9097 (1.0131) kd_loss 0.8954 (0.9269) acc 75.0000 (73.8021) lr 1.6845e-03 eta 0:22:32
epoch [15/50] batch [80/403] time 0.074 (0.090) data 0.000 (0.007) loss 1.6978 (1.8453) teacher_loss 0.7947 (0.8162) loss_zs_kd 1.3460 (1.6316) loss_oracle 0.9638 (1.0195) kd_loss 0.8067 (0.9271) acc 78.1250 (72.8516) lr 1.6845e-03 eta 0:21:42
epoch [15/50] batch [100/403] time 0.090 (0.088) data 0.001 (0.006) loss 2.0657 (1.8568) teacher_loss 1.0483 (0.8320) loss_zs_kd 1.5745 (1.6121) loss_oracle 1.0344 (1.0174) kd_loss 0.9139 (0.9231) acc 62.5000 (72.0938) lr 1.6845e-03 eta 0:21:03
epoch [15/50] batch [120/403] time 0.086 (0.086) data 0.000 (0.005) loss 1.9608 (1.8412) teacher_loss 0.8318 (0.8215) loss_zs_kd 1.3474 (1.5948) loss_oracle 1.0716 (1.0193) kd_loss 1.0218 (0.9178) acc 65.6250 (72.4479) lr 1.6845e-03 eta 0:20:42
epoch [15/50] batch [140/403] time 0.089 (0.086) data 0.000 (0.004) loss 2.0317 (1.8485) teacher_loss 1.0606 (0.8282) loss_zs_kd 1.4807 (1.5924) loss_oracle 1.0429 (1.0212) kd_loss 0.8668 (0.9181) acc 56.2500 (72.2321) lr 1.6845e-03 eta 0:20:40
epoch [15/50] batch [160/403] time 0.082 (0.086) data 0.000 (0.004) loss 1.7326 (1.8489) teacher_loss 0.5897 (0.8256) loss_zs_kd 1.3411 (1.5995) loss_oracle 1.0572 (1.0231) kd_loss 1.0372 (0.9210) acc 84.3750 (72.1484) lr 1.6845e-03 eta 0:20:37
epoch [15/50] batch [180/403] time 0.076 (0.086) data 0.000 (0.003) loss 1.8284 (1.8502) teacher_loss 0.7273 (0.8262) loss_zs_kd 1.9484 (1.6190) loss_oracle 1.0551 (1.0248) kd_loss 0.9956 (0.9215) acc 75.0000 (71.9792) lr 1.6845e-03 eta 0:20:27
epoch [15/50] batch [200/403] time 0.086 (0.085) data 0.000 (0.003) loss 1.7905 (1.8472) teacher_loss 0.6622 (0.8235) loss_zs_kd 1.8739 (1.6156) loss_oracle 0.9467 (1.0242) kd_loss 1.0336 (0.9213) acc 78.1250 (72.1406) lr 1.6845e-03 eta 0:20:21
epoch [15/50] batch [220/403] time 0.082 (0.085) data 0.000 (0.003) loss 2.0155 (1.8471) teacher_loss 0.8989 (0.8235) loss_zs_kd 1.6652 (1.6165) loss_oracle 1.0594 (1.0232) kd_loss 1.0106 (0.9214) acc 59.3750 (72.1307) lr 1.6845e-03 eta 0:20:12
epoch [15/50] batch [240/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.8246 (1.8427) teacher_loss 0.7825 (0.8180) loss_zs_kd 1.2723 (1.6162) loss_oracle 0.9737 (1.0211) kd_loss 0.9448 (0.9226) acc 78.1250 (72.3047) lr 1.6845e-03 eta 0:20:03
epoch [15/50] batch [260/403] time 0.091 (0.084) data 0.000 (0.002) loss 2.1988 (1.8393) teacher_loss 1.0723 (0.8136) loss_zs_kd 1.8926 (1.6079) loss_oracle 1.0886 (1.0184) kd_loss 1.0176 (0.9238) acc 50.0000 (72.4519) lr 1.6845e-03 eta 0:19:56
epoch [15/50] batch [280/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.7017 (1.8331) teacher_loss 0.6350 (0.8071) loss_zs_kd 1.5703 (1.6139) loss_oracle 0.9469 (1.0161) kd_loss 0.9720 (0.9244) acc 78.1250 (72.7121) lr 1.6845e-03 eta 0:19:54
epoch [15/50] batch [300/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.9472 (1.8415) teacher_loss 0.9930 (0.8130) loss_zs_kd 1.5682 (1.6219) loss_oracle 1.0360 (1.0145) kd_loss 0.8507 (0.9270) acc 68.7500 (72.6042) lr 1.6845e-03 eta 0:19:53
epoch [15/50] batch [320/403] time 0.078 (0.084) data 0.001 (0.002) loss 2.0210 (1.8463) teacher_loss 1.0048 (0.8138) loss_zs_kd 1.3753 (1.6217) loss_oracle 0.9409 (1.0125) kd_loss 0.9221 (0.9312) acc 53.1250 (72.4219) lr 1.6845e-03 eta 0:19:48
epoch [15/50] batch [340/403] time 0.071 (0.083) data 0.000 (0.002) loss 1.9066 (1.8569) teacher_loss 0.8392 (0.8190) loss_zs_kd 1.5483 (1.6194) loss_oracle 0.9139 (1.0114) kd_loss 0.9760 (0.9368) acc 65.6250 (72.2610) lr 1.6845e-03 eta 0:19:41
epoch [15/50] batch [360/403] time 0.086 (0.083) data 0.000 (0.002) loss 1.4600 (1.8535) teacher_loss 0.4605 (0.8140) loss_zs_kd 1.2194 (1.6173) loss_oracle 0.9275 (1.0076) kd_loss 0.9068 (0.9387) acc 87.5000 (72.5087) lr 1.6845e-03 eta 0:19:38
epoch [15/50] batch [380/403] time 0.130 (0.084) data 0.001 (0.002) loss 2.0587 (1.8570) teacher_loss 1.0244 (0.8165) loss_zs_kd 1.4870 (1.6172) loss_oracle 0.9401 (1.0053) kd_loss 0.9403 (0.9400) acc 59.3750 (72.4013) lr 1.6845e-03 eta 0:19:50
epoch [15/50] batch [400/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.6486 (1.8525) teacher_loss 0.6374 (0.8140) loss_zs_kd 1.4065 (1.6145) loss_oracle 0.9626 (1.0048) kd_loss 0.9150 (0.9380) acc 78.1250 (72.4688) lr 1.6845e-03 eta 0:19:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,818
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 56.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,277
* accuracy: 38.7%
* error: 61.3%
* macro_f1: 25.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.3%, epoch: 14 *******
******* Domain 4 best val test acc: 38.3%, epoch: 14 *******
******* Domain 4 best test acc:     38.7%, epoch: 15 *******
epoch [16/50] batch [20/403] time 0.082 (0.114) data 0.000 (0.028) loss 1.7667 (1.9290) teacher_loss 0.7095 (0.8427) loss_zs_kd 1.4431 (1.4906) loss_oracle 0.9616 (1.0035) kd_loss 0.9610 (0.9860) acc 75.0000 (72.5000) lr 1.6374e-03 eta 0:26:43
epoch [16/50] batch [40/403] time 0.089 (0.099) data 0.000 (0.014) loss 1.6091 (1.9196) teacher_loss 0.5057 (0.8596) loss_zs_kd 1.5831 (1.5650) loss_oracle 1.0344 (0.9951) kd_loss 1.0000 (0.9605) acc 81.2500 (72.7344) lr 1.6374e-03 eta 0:23:18
epoch [16/50] batch [60/403] time 0.085 (0.095) data 0.000 (0.010) loss 1.8940 (1.8622) teacher_loss 0.8277 (0.8112) loss_zs_kd 1.9150 (1.6309) loss_oracle 0.9799 (0.9960) kd_loss 0.9682 (0.9514) acc 65.6250 (73.6979) lr 1.6374e-03 eta 0:22:07
epoch [16/50] batch [80/403] time 0.093 (0.091) data 0.000 (0.007) loss 1.6386 (1.8556) teacher_loss 0.6487 (0.8071) loss_zs_kd 1.3153 (1.6017) loss_oracle 0.9455 (0.9938) kd_loss 0.8953 (0.9491) acc 84.3750 (73.5547) lr 1.6374e-03 eta 0:21:19
epoch [16/50] batch [100/403] time 0.076 (0.089) data 0.000 (0.006) loss 1.8478 (1.8446) teacher_loss 0.8485 (0.8001) loss_zs_kd 1.7350 (1.6008) loss_oracle 0.9434 (0.9890) kd_loss 0.9049 (0.9456) acc 68.7500 (73.3750) lr 1.6374e-03 eta 0:20:44
epoch [16/50] batch [120/403] time 0.079 (0.087) data 0.000 (0.005) loss 1.5549 (1.8445) teacher_loss 0.5249 (0.7989) loss_zs_kd 1.4038 (1.6089) loss_oracle 0.9703 (0.9914) kd_loss 0.9330 (0.9465) acc 78.1250 (73.1250) lr 1.6374e-03 eta 0:20:16
epoch [16/50] batch [140/403] time 0.131 (0.089) data 0.001 (0.004) loss 2.0441 (1.8487) teacher_loss 0.9428 (0.7987) loss_zs_kd 1.4537 (1.6093) loss_oracle 0.9788 (0.9890) kd_loss 1.0034 (0.9512) acc 71.8750 (73.0357) lr 1.6374e-03 eta 0:20:37
epoch [16/50] batch [160/403] time 0.088 (0.088) data 0.000 (0.004) loss 2.2233 (1.8534) teacher_loss 1.1947 (0.8062) loss_zs_kd 1.4406 (1.5920) loss_oracle 1.0489 (0.9896) kd_loss 0.9236 (0.9482) acc 62.5000 (72.7734) lr 1.6374e-03 eta 0:20:29
epoch [16/50] batch [180/403] time 0.078 (0.087) data 0.000 (0.003) loss 1.8280 (1.8600) teacher_loss 0.7936 (0.8107) loss_zs_kd 1.5960 (1.5786) loss_oracle 0.9653 (0.9879) kd_loss 0.9378 (0.9505) acc 75.0000 (72.5868) lr 1.6374e-03 eta 0:20:17
epoch [16/50] batch [200/403] time 0.089 (0.087) data 0.000 (0.003) loss 2.0482 (1.8625) teacher_loss 1.0531 (0.8132) loss_zs_kd 1.9064 (1.5829) loss_oracle 0.9961 (0.9894) kd_loss 0.8955 (0.9504) acc 59.3750 (72.4375) lr 1.6374e-03 eta 0:20:06
epoch [16/50] batch [220/403] time 0.080 (0.087) data 0.000 (0.003) loss 1.7547 (1.8601) teacher_loss 0.6915 (0.8138) loss_zs_kd 1.2956 (1.5780) loss_oracle 1.0377 (0.9885) kd_loss 0.9594 (0.9475) acc 71.8750 (72.5142) lr 1.6374e-03 eta 0:20:02
epoch [16/50] batch [240/403] time 0.082 (0.086) data 0.000 (0.003) loss 1.5779 (1.8533) teacher_loss 0.4859 (0.8074) loss_zs_kd 1.5993 (1.5880) loss_oracle 0.9952 (0.9872) kd_loss 0.9925 (0.9471) acc 81.2500 (72.7083) lr 1.6374e-03 eta 0:19:51
epoch [16/50] batch [260/403] time 0.072 (0.086) data 0.000 (0.002) loss 1.8539 (1.8553) teacher_loss 0.7850 (0.8117) loss_zs_kd 1.3684 (1.5936) loss_oracle 0.9789 (0.9852) kd_loss 0.9709 (0.9451) acc 75.0000 (72.5481) lr 1.6374e-03 eta 0:19:43
epoch [16/50] batch [280/403] time 0.077 (0.085) data 0.000 (0.002) loss 2.0489 (1.8545) teacher_loss 0.9822 (0.8128) loss_zs_kd 1.9818 (1.5954) loss_oracle 0.9855 (0.9830) kd_loss 0.9682 (0.9434) acc 71.8750 (72.4554) lr 1.6374e-03 eta 0:19:36
epoch [16/50] batch [300/403] time 0.079 (0.085) data 0.000 (0.002) loss 1.9458 (1.8495) teacher_loss 0.8871 (0.8099) loss_zs_kd 1.5498 (1.5902) loss_oracle 0.9319 (0.9810) kd_loss 0.9654 (0.9415) acc 75.0000 (72.4375) lr 1.6374e-03 eta 0:19:33
epoch [16/50] batch [320/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.8715 (1.8487) teacher_loss 0.6737 (0.8083) loss_zs_kd 1.4936 (1.5825) loss_oracle 0.9740 (0.9794) kd_loss 1.1004 (0.9425) acc 81.2500 (72.3828) lr 1.6374e-03 eta 0:19:26
epoch [16/50] batch [340/403] time 0.089 (0.084) data 0.001 (0.002) loss 1.6743 (1.8456) teacher_loss 0.6924 (0.8050) loss_zs_kd 1.6924 (1.5894) loss_oracle 0.9056 (0.9793) kd_loss 0.8913 (0.9427) acc 75.0000 (72.4449) lr 1.6374e-03 eta 0:19:21
epoch [16/50] batch [360/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.0028 (1.8445) teacher_loss 1.0589 (0.8048) loss_zs_kd 1.4670 (1.5923) loss_oracle 0.9352 (0.9789) kd_loss 0.8503 (0.9417) acc 59.3750 (72.4392) lr 1.6374e-03 eta 0:19:12
epoch [16/50] batch [380/403] time 0.066 (0.083) data 0.000 (0.002) loss 1.8108 (1.8463) teacher_loss 0.6855 (0.8057) loss_zs_kd 1.6044 (1.5959) loss_oracle 0.9947 (0.9793) kd_loss 1.0258 (0.9426) acc 71.8750 (72.3355) lr 1.6374e-03 eta 0:19:01
epoch [16/50] batch [400/403] time 0.073 (0.083) data 0.000 (0.002) loss 1.7735 (1.8455) teacher_loss 0.6651 (0.8050) loss_zs_kd 1.7207 (1.6033) loss_oracle 1.0255 (0.9797) kd_loss 1.0058 (0.9425) acc 78.1250 (72.4609) lr 1.6374e-03 eta 0:18:54
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,883
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 56.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,206
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 27.1%
******* Domain 4 best val acc:      70.3%, epoch: 14 *******
******* Domain 4 best val test acc: 38.3%, epoch: 14 *******
******* Domain 4 best test acc:     38.7%, epoch: 15 *******
epoch [17/50] batch [20/403] time 0.080 (0.110) data 0.000 (0.026) loss 1.6462 (1.7667) teacher_loss 0.5882 (0.7211) loss_zs_kd 1.5870 (1.6335) loss_oracle 0.9647 (0.9884) kd_loss 0.9616 (0.9467) acc 78.1250 (73.7500) lr 1.5878e-03 eta 0:25:04
epoch [17/50] batch [40/403] time 0.080 (0.096) data 0.000 (0.013) loss 2.4689 (1.8333) teacher_loss 1.3717 (0.7809) loss_zs_kd 2.0103 (1.6149) loss_oracle 1.0664 (0.9897) kd_loss 0.9906 (0.9534) acc 59.3750 (73.2812) lr 1.5878e-03 eta 0:21:52
epoch [17/50] batch [60/403] time 0.082 (0.092) data 0.001 (0.009) loss 1.6864 (1.8123) teacher_loss 0.6251 (0.7582) loss_zs_kd 1.6070 (1.6488) loss_oracle 0.9290 (0.9823) kd_loss 0.9685 (0.9558) acc 78.1250 (74.0625) lr 1.5878e-03 eta 0:20:51
epoch [17/50] batch [80/403] time 0.086 (0.089) data 0.000 (0.007) loss 2.3244 (1.8240) teacher_loss 1.3166 (0.7723) loss_zs_kd 1.5384 (1.6404) loss_oracle 0.9717 (0.9788) kd_loss 0.9107 (0.9538) acc 59.3750 (73.6328) lr 1.5878e-03 eta 0:20:17
epoch [17/50] batch [100/403] time 0.070 (0.087) data 0.000 (0.005) loss 1.8781 (1.8342) teacher_loss 0.8182 (0.7775) loss_zs_kd 1.6396 (1.6544) loss_oracle 1.0465 (0.9769) kd_loss 0.9553 (0.9590) acc 75.0000 (73.4688) lr 1.5878e-03 eta 0:19:46
epoch [17/50] batch [120/403] time 0.085 (0.086) data 0.000 (0.005) loss 1.7624 (1.8301) teacher_loss 0.7031 (0.7791) loss_zs_kd 1.2757 (1.6643) loss_oracle 0.9879 (0.9794) kd_loss 0.9605 (0.9530) acc 78.1250 (73.3073) lr 1.5878e-03 eta 0:19:30
epoch [17/50] batch [140/403] time 0.083 (0.086) data 0.000 (0.004) loss 1.8480 (1.8286) teacher_loss 0.7872 (0.7856) loss_zs_kd 1.3245 (1.6722) loss_oracle 0.9729 (0.9768) kd_loss 0.9635 (0.9454) acc 68.7500 (72.9911) lr 1.5878e-03 eta 0:19:26
epoch [17/50] batch [160/403] time 0.078 (0.085) data 0.000 (0.003) loss 1.8788 (1.8261) teacher_loss 0.7323 (0.7850) loss_zs_kd 1.6243 (1.6571) loss_oracle 1.0544 (0.9780) kd_loss 1.0411 (0.9433) acc 78.1250 (73.3008) lr 1.5878e-03 eta 0:19:17
epoch [17/50] batch [180/403] time 0.081 (0.085) data 0.000 (0.003) loss 2.1055 (1.8215) teacher_loss 0.9663 (0.7837) loss_zs_kd 1.4046 (1.6338) loss_oracle 1.0830 (0.9817) kd_loss 1.0309 (0.9395) acc 68.7500 (73.4375) lr 1.5878e-03 eta 0:19:08
epoch [17/50] batch [200/403] time 0.075 (0.084) data 0.000 (0.003) loss 1.5172 (1.8224) teacher_loss 0.5739 (0.7844) loss_zs_kd 1.4113 (1.6103) loss_oracle 0.9950 (0.9845) kd_loss 0.8438 (0.9395) acc 78.1250 (73.3750) lr 1.5878e-03 eta 0:19:00
epoch [17/50] batch [220/403] time 0.091 (0.084) data 0.000 (0.003) loss 1.6887 (1.8264) teacher_loss 0.6879 (0.7870) loss_zs_kd 1.7147 (1.6125) loss_oracle 1.0276 (0.9896) kd_loss 0.8981 (0.9404) acc 68.7500 (73.2386) lr 1.5878e-03 eta 0:18:57
epoch [17/50] batch [240/403] time 0.067 (0.084) data 0.000 (0.002) loss 1.5052 (1.8238) teacher_loss 0.5589 (0.7859) loss_zs_kd 1.4035 (1.6065) loss_oracle 1.0125 (0.9909) kd_loss 0.8451 (0.9388) acc 78.1250 (73.2812) lr 1.5878e-03 eta 0:18:50
epoch [17/50] batch [260/403] time 0.097 (0.084) data 0.000 (0.002) loss 1.6430 (1.8274) teacher_loss 0.6344 (0.7893) loss_zs_kd 1.5192 (1.6048) loss_oracle 1.0121 (0.9912) kd_loss 0.9073 (0.9390) acc 81.2500 (73.2572) lr 1.5878e-03 eta 0:18:46
epoch [17/50] batch [280/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.7601 (1.8271) teacher_loss 0.7676 (0.7903) loss_zs_kd 1.5752 (1.6046) loss_oracle 0.9424 (0.9898) kd_loss 0.8983 (0.9379) acc 71.8750 (73.2701) lr 1.5878e-03 eta 0:18:43
epoch [17/50] batch [300/403] time 0.181 (0.085) data 0.000 (0.002) loss 1.7697 (1.8289) teacher_loss 0.7512 (0.7936) loss_zs_kd 1.5272 (1.5990) loss_oracle 0.9823 (0.9881) kd_loss 0.9202 (0.9365) acc 68.7500 (73.0625) lr 1.5878e-03 eta 0:18:55
epoch [17/50] batch [320/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.7004 (1.8249) teacher_loss 0.7311 (0.7914) loss_zs_kd 1.5100 (1.5987) loss_oracle 1.0074 (0.9878) kd_loss 0.8686 (0.9347) acc 71.8750 (73.1934) lr 1.5878e-03 eta 0:18:53
epoch [17/50] batch [340/403] time 0.091 (0.085) data 0.000 (0.002) loss 1.8428 (1.8243) teacher_loss 0.7413 (0.7916) loss_zs_kd 1.4210 (1.5963) loss_oracle 1.0044 (0.9877) kd_loss 1.0010 (0.9339) acc 71.8750 (73.2077) lr 1.5878e-03 eta 0:18:51
epoch [17/50] batch [360/403] time 0.085 (0.084) data 0.000 (0.002) loss 1.7492 (1.8241) teacher_loss 0.6547 (0.7915) loss_zs_kd 1.6320 (1.6010) loss_oracle 0.9607 (0.9872) kd_loss 0.9984 (0.9339) acc 75.0000 (73.2639) lr 1.5878e-03 eta 0:18:45
epoch [17/50] batch [380/403] time 0.096 (0.084) data 0.000 (0.002) loss 2.0512 (1.8234) teacher_loss 0.9280 (0.7920) loss_zs_kd 1.4222 (1.5984) loss_oracle 0.9646 (0.9852) kd_loss 1.0268 (0.9330) acc 75.0000 (73.2812) lr 1.5878e-03 eta 0:18:42
epoch [17/50] batch [400/403] time 0.072 (0.084) data 0.000 (0.002) loss 1.9249 (1.8265) teacher_loss 0.8750 (0.7960) loss_zs_kd 1.8219 (1.6004) loss_oracle 1.0255 (0.9848) kd_loss 0.9474 (0.9321) acc 68.7500 (73.0078) lr 1.5878e-03 eta 0:18:34
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,897
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 57.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,303
* accuracy: 39.1%
* error: 60.9%
* macro_f1: 28.1%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      70.4%, epoch: 17 *******
******* Domain 4 best val test acc: 39.1%, epoch: 17 *******
******* Domain 4 best test acc:     39.1%, epoch: 17 *******
epoch [18/50] batch [20/403] time 0.081 (0.121) data 0.000 (0.034) loss 1.8071 (1.8021) teacher_loss 0.8498 (0.8120) loss_zs_kd 1.3287 (1.5542) loss_oracle 1.0030 (0.9784) kd_loss 0.8570 (0.8923) acc 71.8750 (72.3438) lr 1.5358e-03 eta 0:26:50
epoch [18/50] batch [40/403] time 0.141 (0.107) data 0.000 (0.017) loss 1.8286 (1.8431) teacher_loss 0.7585 (0.8290) loss_zs_kd 1.6641 (1.5979) loss_oracle 0.9944 (0.9948) kd_loss 0.9706 (0.9146) acc 71.8750 (71.4062) lr 1.5358e-03 eta 0:23:35
epoch [18/50] batch [60/403] time 0.068 (0.102) data 0.000 (0.011) loss 1.8797 (1.8432) teacher_loss 0.8024 (0.8249) loss_zs_kd 1.4361 (1.5777) loss_oracle 0.9750 (0.9895) kd_loss 0.9798 (0.9194) acc 78.1250 (72.1354) lr 1.5358e-03 eta 0:22:33
epoch [18/50] batch [80/403] time 0.080 (0.097) data 0.000 (0.009) loss 2.0084 (1.8605) teacher_loss 0.8907 (0.8251) loss_zs_kd 1.5989 (1.5858) loss_oracle 1.0807 (1.0032) kd_loss 1.0096 (0.9350) acc 71.8750 (71.6016) lr 1.5358e-03 eta 0:21:18
epoch [18/50] batch [100/403] time 0.090 (0.094) data 0.000 (0.007) loss 1.7699 (1.8643) teacher_loss 0.7890 (0.8282) loss_zs_kd 1.7509 (1.5945) loss_oracle 0.8921 (1.0016) kd_loss 0.8917 (0.9359) acc 78.1250 (71.4062) lr 1.5358e-03 eta 0:20:41
epoch [18/50] batch [120/403] time 0.067 (0.093) data 0.000 (0.006) loss 1.7395 (1.8584) teacher_loss 0.5866 (0.8205) loss_zs_kd 1.7793 (1.6212) loss_oracle 0.9800 (1.0015) kd_loss 1.0549 (0.9378) acc 90.6250 (72.0052) lr 1.5358e-03 eta 0:20:20
epoch [18/50] batch [140/403] time 0.079 (0.092) data 0.000 (0.005) loss 1.8397 (1.8606) teacher_loss 0.7258 (0.8194) loss_zs_kd 1.4680 (1.6200) loss_oracle 1.0773 (1.0006) kd_loss 1.0062 (0.9411) acc 78.1250 (71.9866) lr 1.5358e-03 eta 0:20:04
epoch [18/50] batch [160/403] time 0.090 (0.090) data 0.000 (0.004) loss 2.0407 (1.8612) teacher_loss 0.9886 (0.8199) loss_zs_kd 1.8495 (1.6473) loss_oracle 0.9854 (0.9994) kd_loss 0.9536 (0.9414) acc 62.5000 (71.8359) lr 1.5358e-03 eta 0:19:47
epoch [18/50] batch [180/403] time 0.085 (0.090) data 0.000 (0.004) loss 1.9013 (1.8594) teacher_loss 0.9331 (0.8196) loss_zs_kd 1.6554 (1.6517) loss_oracle 0.9378 (0.9954) kd_loss 0.8744 (0.9403) acc 71.8750 (71.8576) lr 1.5358e-03 eta 0:19:37
epoch [18/50] batch [200/403] time 0.082 (0.089) data 0.000 (0.004) loss 1.6382 (1.8634) teacher_loss 0.5097 (0.8216) loss_zs_kd 1.5656 (1.6516) loss_oracle 1.1071 (0.9941) kd_loss 1.0178 (0.9424) acc 78.1250 (71.7656) lr 1.5358e-03 eta 0:19:29
epoch [18/50] batch [220/403] time 0.086 (0.089) data 0.000 (0.003) loss 1.6556 (1.8627) teacher_loss 0.6586 (0.8182) loss_zs_kd 1.5878 (1.6446) loss_oracle 0.9974 (0.9912) kd_loss 0.8973 (0.9454) acc 68.7500 (72.0312) lr 1.5358e-03 eta 0:19:21
epoch [18/50] batch [240/403] time 0.079 (0.089) data 0.000 (0.003) loss 1.3941 (1.8564) teacher_loss 0.5408 (0.8115) loss_zs_kd 1.3990 (1.6402) loss_oracle 0.8863 (0.9903) kd_loss 0.7646 (0.9458) acc 81.2500 (72.3698) lr 1.5358e-03 eta 0:19:17
epoch [18/50] batch [260/403] time 0.091 (0.088) data 0.000 (0.003) loss 1.7795 (1.8630) teacher_loss 0.8172 (0.8176) loss_zs_kd 1.6440 (1.6380) loss_oracle 0.9491 (0.9907) kd_loss 0.8673 (0.9463) acc 78.1250 (72.3438) lr 1.5358e-03 eta 0:19:13
epoch [18/50] batch [280/403] time 0.080 (0.088) data 0.001 (0.003) loss 1.7729 (1.8574) teacher_loss 0.7784 (0.8118) loss_zs_kd 1.1536 (1.6292) loss_oracle 0.9492 (0.9896) kd_loss 0.8996 (0.9466) acc 71.8750 (72.5446) lr 1.5358e-03 eta 0:19:04
epoch [18/50] batch [300/403] time 0.082 (0.088) data 0.000 (0.003) loss 1.9049 (1.8537) teacher_loss 0.8299 (0.8101) loss_zs_kd 1.5903 (1.6239) loss_oracle 1.0400 (0.9872) kd_loss 0.9710 (0.9448) acc 65.6250 (72.5729) lr 1.5358e-03 eta 0:18:59
epoch [18/50] batch [320/403] time 0.078 (0.088) data 0.000 (0.002) loss 1.8810 (1.8552) teacher_loss 0.9584 (0.8128) loss_zs_kd 1.5341 (1.6212) loss_oracle 0.9241 (0.9867) kd_loss 0.8302 (0.9438) acc 75.0000 (72.4414) lr 1.5358e-03 eta 0:18:56
epoch [18/50] batch [340/403] time 0.075 (0.087) data 0.000 (0.002) loss 2.2991 (1.8542) teacher_loss 1.2598 (0.8126) loss_zs_kd 1.8723 (1.6236) loss_oracle 0.9520 (0.9870) kd_loss 0.9440 (0.9429) acc 62.5000 (72.4173) lr 1.5358e-03 eta 0:18:48
epoch [18/50] batch [360/403] time 0.081 (0.087) data 0.000 (0.002) loss 1.8640 (1.8493) teacher_loss 0.8416 (0.8085) loss_zs_kd 1.8253 (1.6246) loss_oracle 1.0100 (0.9887) kd_loss 0.9214 (0.9419) acc 65.6250 (72.5174) lr 1.5358e-03 eta 0:18:44
epoch [18/50] batch [380/403] time 0.086 (0.087) data 0.000 (0.002) loss 1.8752 (1.8497) teacher_loss 0.8559 (0.8094) loss_zs_kd 1.6892 (1.6306) loss_oracle 0.9095 (0.9895) kd_loss 0.9283 (0.9413) acc 62.5000 (72.5000) lr 1.5358e-03 eta 0:18:41
epoch [18/50] batch [400/403] time 0.076 (0.087) data 0.000 (0.002) loss 1.7723 (1.8480) teacher_loss 0.7484 (0.8066) loss_zs_kd 1.6318 (1.6351) loss_oracle 0.9870 (0.9906) kd_loss 0.9252 (0.9423) acc 81.2500 (72.5469) lr 1.5358e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,843
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 54.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,265
* accuracy: 38.5%
* error: 61.5%
* macro_f1: 27.5%
******* Domain 4 best val acc:      70.4%, epoch: 17 *******
******* Domain 4 best val test acc: 39.1%, epoch: 17 *******
******* Domain 4 best test acc:     39.1%, epoch: 17 *******
epoch [19/50] batch [20/403] time 0.079 (0.117) data 0.000 (0.031) loss 1.8226 (1.8944) teacher_loss 0.8058 (0.8634) loss_zs_kd 1.4911 (1.6411) loss_oracle 1.0048 (0.9918) kd_loss 0.9163 (0.9318) acc 81.2500 (70.7812) lr 1.4818e-03 eta 0:25:06
epoch [19/50] batch [40/403] time 0.076 (0.098) data 0.000 (0.015) loss 1.6447 (1.8763) teacher_loss 0.7119 (0.8550) loss_zs_kd 1.6531 (1.6483) loss_oracle 0.9504 (0.9887) kd_loss 0.8377 (0.9224) acc 71.8750 (71.2500) lr 1.4818e-03 eta 0:20:57
epoch [19/50] batch [60/403] time 0.082 (0.091) data 0.000 (0.010) loss 1.5767 (1.8242) teacher_loss 0.6995 (0.8139) loss_zs_kd 1.7165 (1.6435) loss_oracle 0.9588 (0.9894) kd_loss 0.7813 (0.9113) acc 75.0000 (72.4479) lr 1.4818e-03 eta 0:19:32
epoch [19/50] batch [80/403] time 0.083 (0.088) data 0.000 (0.008) loss 1.6270 (1.7959) teacher_loss 0.6221 (0.7946) loss_zs_kd 1.2801 (1.6306) loss_oracle 0.9988 (0.9872) kd_loss 0.9050 (0.9026) acc 81.2500 (72.7344) lr 1.4818e-03 eta 0:18:53
epoch [19/50] batch [100/403] time 0.084 (0.087) data 0.000 (0.006) loss 1.5798 (1.8065) teacher_loss 0.6130 (0.8036) loss_zs_kd 2.2723 (1.6207) loss_oracle 1.0158 (0.9883) kd_loss 0.8652 (0.9042) acc 84.3750 (72.4375) lr 1.4818e-03 eta 0:18:36
epoch [19/50] batch [120/403] time 0.079 (0.086) data 0.001 (0.005) loss 1.8395 (1.8153) teacher_loss 0.7530 (0.8074) loss_zs_kd 2.0379 (1.6363) loss_oracle 0.9883 (0.9905) kd_loss 0.9876 (0.9089) acc 78.1250 (72.2396) lr 1.4818e-03 eta 0:18:21
epoch [19/50] batch [140/403] time 0.083 (0.086) data 0.000 (0.005) loss 1.8775 (1.8122) teacher_loss 0.9323 (0.8022) loss_zs_kd 2.2020 (1.6357) loss_oracle 0.8916 (0.9913) kd_loss 0.8561 (0.9109) acc 59.3750 (72.1429) lr 1.4818e-03 eta 0:18:11
epoch [19/50] batch [160/403] time 0.087 (0.085) data 0.000 (0.004) loss 1.8946 (1.8038) teacher_loss 0.9258 (0.7954) loss_zs_kd 1.1779 (1.6185) loss_oracle 0.9680 (0.9891) kd_loss 0.8720 (0.9095) acc 68.7500 (72.7344) lr 1.4818e-03 eta 0:18:03
epoch [19/50] batch [180/403] time 0.087 (0.084) data 0.000 (0.004) loss 1.9540 (1.7945) teacher_loss 0.8638 (0.7889) loss_zs_kd 1.3116 (1.6114) loss_oracle 0.9389 (0.9890) kd_loss 0.9963 (0.9068) acc 78.1250 (73.0035) lr 1.4818e-03 eta 0:17:54
epoch [19/50] batch [200/403] time 0.070 (0.086) data 0.000 (0.003) loss 1.9276 (1.7935) teacher_loss 0.9430 (0.7900) loss_zs_kd 1.5773 (1.6003) loss_oracle 0.9164 (0.9855) kd_loss 0.8929 (0.9050) acc 62.5000 (72.8125) lr 1.4818e-03 eta 0:18:13
epoch [19/50] batch [220/403] time 0.088 (0.086) data 0.000 (0.003) loss 1.7126 (1.7894) teacher_loss 0.7237 (0.7861) loss_zs_kd 1.4956 (1.5983) loss_oracle 0.9876 (0.9845) kd_loss 0.8901 (0.9048) acc 78.1250 (72.9545) lr 1.4818e-03 eta 0:18:04
epoch [19/50] batch [240/403] time 0.078 (0.085) data 0.000 (0.003) loss 1.8749 (1.8046) teacher_loss 0.8733 (0.7992) loss_zs_kd 1.7148 (1.5931) loss_oracle 1.0172 (0.9864) kd_loss 0.8998 (0.9068) acc 68.7500 (72.4740) lr 1.4818e-03 eta 0:17:59
epoch [19/50] batch [260/403] time 0.089 (0.085) data 0.000 (0.003) loss 1.7937 (1.8138) teacher_loss 0.7895 (0.8079) loss_zs_kd 2.0369 (1.5947) loss_oracle 0.9798 (0.9866) kd_loss 0.9062 (0.9073) acc 71.8750 (72.1154) lr 1.4818e-03 eta 0:17:51
epoch [19/50] batch [280/403] time 0.081 (0.084) data 0.000 (0.002) loss 1.8026 (1.8150) teacher_loss 0.8027 (0.8093) loss_zs_kd 1.0352 (1.5885) loss_oracle 0.9537 (0.9861) kd_loss 0.9045 (0.9071) acc 78.1250 (72.2433) lr 1.4818e-03 eta 0:17:43
epoch [19/50] batch [300/403] time 0.087 (0.084) data 0.000 (0.002) loss 1.5165 (1.8101) teacher_loss 0.5388 (0.8049) loss_zs_kd 1.7569 (1.5883) loss_oracle 0.9676 (0.9839) kd_loss 0.8809 (0.9067) acc 78.1250 (72.3854) lr 1.4818e-03 eta 0:17:42
epoch [19/50] batch [320/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.8830 (1.8114) teacher_loss 0.8252 (0.8066) loss_zs_kd 1.6401 (1.5838) loss_oracle 0.9836 (0.9825) kd_loss 0.9594 (0.9066) acc 68.7500 (72.3047) lr 1.4818e-03 eta 0:17:39
epoch [19/50] batch [340/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.8052 (1.8111) teacher_loss 0.8103 (0.8088) loss_zs_kd 1.3644 (1.5743) loss_oracle 0.8905 (0.9805) kd_loss 0.9059 (0.9043) acc 68.7500 (72.1599) lr 1.4818e-03 eta 0:17:35
epoch [19/50] batch [360/403] time 0.075 (0.084) data 0.000 (0.002) loss 1.7757 (1.8108) teacher_loss 0.7388 (0.8103) loss_zs_kd 1.5063 (1.5617) loss_oracle 1.0350 (0.9794) kd_loss 0.9334 (0.9026) acc 71.8750 (72.0833) lr 1.4818e-03 eta 0:17:29
epoch [19/50] batch [380/403] time 0.094 (0.084) data 0.000 (0.002) loss 1.7979 (1.8122) teacher_loss 0.8163 (0.8115) loss_zs_kd 1.5363 (1.5486) loss_oracle 0.8957 (0.9788) kd_loss 0.8920 (0.9028) acc 75.0000 (72.1135) lr 1.4818e-03 eta 0:17:29
epoch [19/50] batch [400/403] time 0.071 (0.084) data 0.000 (0.002) loss 1.9484 (1.8144) teacher_loss 0.9772 (0.8132) loss_zs_kd 1.7795 (1.5477) loss_oracle 1.0309 (0.9783) kd_loss 0.8681 (0.9033) acc 68.7500 (72.0234) lr 1.4818e-03 eta 0:17:25
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,784
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 53.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,173
* accuracy: 36.9%
* error: 63.1%
* macro_f1: 26.6%
******* Domain 4 best val acc:      70.4%, epoch: 17 *******
******* Domain 4 best val test acc: 39.1%, epoch: 17 *******
******* Domain 4 best test acc:     39.1%, epoch: 17 *******
epoch [20/50] batch [20/403] time 0.082 (0.109) data 0.000 (0.025) loss 1.9256 (1.9197) teacher_loss 0.9276 (0.8835) loss_zs_kd 1.8385 (1.6301) loss_oracle 0.8995 (0.9463) kd_loss 0.9080 (0.9416) acc 71.8750 (68.5938) lr 1.4258e-03 eta 0:22:36
epoch [20/50] batch [40/403] time 0.088 (0.098) data 0.001 (0.013) loss 1.6248 (1.8509) teacher_loss 0.5909 (0.8168) loss_zs_kd 1.1331 (1.6225) loss_oracle 0.9687 (0.9554) kd_loss 0.9371 (0.9385) acc 75.0000 (71.5625) lr 1.4258e-03 eta 0:20:15
epoch [20/50] batch [60/403] time 0.076 (0.091) data 0.000 (0.009) loss 1.7453 (1.8476) teacher_loss 0.7619 (0.8161) loss_zs_kd 1.6088 (1.6521) loss_oracle 0.9066 (0.9630) kd_loss 0.8927 (0.9352) acc 68.7500 (72.1354) lr 1.4258e-03 eta 0:18:55
epoch [20/50] batch [80/403] time 0.082 (0.089) data 0.000 (0.007) loss 1.7631 (1.8308) teacher_loss 0.8192 (0.8032) loss_zs_kd 1.5293 (1.6360) loss_oracle 0.9419 (0.9610) kd_loss 0.8497 (0.9316) acc 68.7500 (72.7344) lr 1.4258e-03 eta 0:18:26
epoch [20/50] batch [100/403] time 0.089 (0.088) data 0.000 (0.005) loss 2.0077 (1.8491) teacher_loss 0.9952 (0.8231) loss_zs_kd 1.8933 (1.6277) loss_oracle 0.9781 (0.9632) kd_loss 0.9147 (0.9297) acc 53.1250 (72.1250) lr 1.4258e-03 eta 0:18:06
epoch [20/50] batch [120/403] time 0.076 (0.086) data 0.000 (0.004) loss 1.7308 (1.8416) teacher_loss 0.9043 (0.8206) loss_zs_kd 1.4026 (1.6067) loss_oracle 0.8130 (0.9628) kd_loss 0.7452 (0.9247) acc 75.0000 (72.5260) lr 1.4258e-03 eta 0:17:46
epoch [20/50] batch [140/403] time 0.084 (0.085) data 0.000 (0.004) loss 2.1411 (1.8405) teacher_loss 1.0845 (0.8227) loss_zs_kd 2.4415 (1.6148) loss_oracle 0.9824 (0.9628) kd_loss 0.9584 (0.9215) acc 65.6250 (72.5223) lr 1.4258e-03 eta 0:17:34
epoch [20/50] batch [160/403] time 0.083 (0.085) data 0.000 (0.003) loss 2.2177 (1.8367) teacher_loss 1.1787 (0.8232) loss_zs_kd 1.9539 (1.6281) loss_oracle 0.9356 (0.9653) kd_loss 0.9454 (0.9170) acc 50.0000 (72.1680) lr 1.4258e-03 eta 0:17:31
epoch [20/50] batch [180/403] time 0.089 (0.085) data 0.000 (0.003) loss 1.6052 (1.8390) teacher_loss 0.5998 (0.8260) loss_zs_kd 1.4943 (1.6323) loss_oracle 0.9179 (0.9676) kd_loss 0.9136 (0.9162) acc 87.5000 (72.2569) lr 1.4258e-03 eta 0:17:22
epoch [20/50] batch [200/403] time 0.086 (0.084) data 0.000 (0.003) loss 1.5590 (1.8344) teacher_loss 0.6729 (0.8249) loss_zs_kd 2.0335 (1.6414) loss_oracle 0.9548 (0.9689) kd_loss 0.7906 (0.9126) acc 75.0000 (72.1406) lr 1.4258e-03 eta 0:17:16
epoch [20/50] batch [220/403] time 0.084 (0.084) data 0.000 (0.003) loss 2.0480 (1.8315) teacher_loss 1.0759 (0.8242) loss_zs_kd 1.6309 (1.6319) loss_oracle 0.9513 (0.9685) kd_loss 0.8770 (0.9105) acc 65.6250 (72.1165) lr 1.4258e-03 eta 0:17:14
epoch [20/50] batch [240/403] time 0.088 (0.084) data 0.000 (0.002) loss 1.8244 (1.8275) teacher_loss 0.8451 (0.8211) loss_zs_kd 1.9053 (1.6312) loss_oracle 0.9289 (0.9684) kd_loss 0.8865 (0.9096) acc 71.8750 (72.2005) lr 1.4258e-03 eta 0:17:11
epoch [20/50] batch [260/403] time 0.095 (0.084) data 0.000 (0.002) loss 1.8816 (1.8280) teacher_loss 0.8608 (0.8205) loss_zs_kd 1.1648 (1.6297) loss_oracle 0.9241 (0.9681) kd_loss 0.9284 (0.9107) acc 65.6250 (72.1514) lr 1.4258e-03 eta 0:17:09
epoch [20/50] batch [280/403] time 0.071 (0.084) data 0.000 (0.002) loss 1.6965 (1.8268) teacher_loss 0.7998 (0.8195) loss_zs_kd 1.8436 (1.6277) loss_oracle 0.9444 (0.9685) kd_loss 0.8022 (0.9104) acc 71.8750 (72.2321) lr 1.4258e-03 eta 0:17:06
epoch [20/50] batch [300/403] time 0.087 (0.084) data 0.000 (0.002) loss 1.4618 (1.8228) teacher_loss 0.5144 (0.8174) loss_zs_kd 2.0359 (1.6375) loss_oracle 0.9431 (0.9680) kd_loss 0.8532 (0.9086) acc 81.2500 (72.2708) lr 1.4258e-03 eta 0:17:02
epoch [20/50] batch [320/403] time 0.072 (0.084) data 0.000 (0.002) loss 1.5716 (1.8173) teacher_loss 0.5863 (0.8129) loss_zs_kd 1.3980 (1.6448) loss_oracle 0.9595 (0.9680) kd_loss 0.8893 (0.9076) acc 81.2500 (72.4805) lr 1.4258e-03 eta 0:16:57
epoch [20/50] batch [340/403] time 0.095 (0.083) data 0.000 (0.002) loss 1.7524 (1.8135) teacher_loss 0.7848 (0.8104) loss_zs_kd 1.6966 (1.6525) loss_oracle 1.0115 (0.9674) kd_loss 0.8665 (0.9064) acc 68.7500 (72.5368) lr 1.4258e-03 eta 0:16:50
epoch [20/50] batch [360/403] time 0.074 (0.084) data 0.000 (0.002) loss 1.7050 (1.8104) teacher_loss 0.6740 (0.8071) loss_zs_kd 1.6185 (1.6509) loss_oracle 1.0898 (0.9670) kd_loss 0.9220 (0.9066) acc 78.1250 (72.6128) lr 1.4258e-03 eta 0:16:59
epoch [20/50] batch [380/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.9014 (1.8083) teacher_loss 0.9398 (0.8037) loss_zs_kd 1.1337 (1.6486) loss_oracle 0.9525 (0.9657) kd_loss 0.8664 (0.9080) acc 71.8750 (72.7056) lr 1.4258e-03 eta 0:16:57
epoch [20/50] batch [400/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.9455 (1.8111) teacher_loss 0.8696 (0.8061) loss_zs_kd 1.7774 (1.6490) loss_oracle 1.0027 (0.9647) kd_loss 0.9757 (0.9086) acc 78.1250 (72.4688) lr 1.4258e-03 eta 0:16:52
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,768
* accuracy: 68.1%
* error: 31.9%
* macro_f1: 55.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,271
* accuracy: 38.6%
* error: 61.4%
* macro_f1: 27.1%
******* Domain 4 best val acc:      70.4%, epoch: 17 *******
******* Domain 4 best val test acc: 39.1%, epoch: 17 *******
******* Domain 4 best test acc:     39.1%, epoch: 17 *******
epoch [21/50] batch [20/403] time 0.073 (0.106) data 0.000 (0.029) loss 1.7879 (1.8069) teacher_loss 0.8185 (0.7995) loss_zs_kd 1.8011 (1.6967) loss_oracle 0.9525 (0.9482) kd_loss 0.8741 (0.9126) acc 78.1250 (72.5000) lr 1.3681e-03 eta 0:21:24
epoch [21/50] batch [40/403] time 0.080 (0.095) data 0.000 (0.015) loss 2.1033 (1.8537) teacher_loss 1.1428 (0.8510) loss_zs_kd 1.5523 (1.6897) loss_oracle 1.0235 (0.9628) kd_loss 0.8581 (0.9064) acc 62.5000 (70.8594) lr 1.3681e-03 eta 0:19:02
epoch [21/50] batch [60/403] time 0.075 (0.091) data 0.000 (0.010) loss 1.8010 (1.8523) teacher_loss 0.7930 (0.8552) loss_zs_kd 1.6011 (1.6735) loss_oracle 0.9467 (0.9634) kd_loss 0.9134 (0.9008) acc 68.7500 (70.1042) lr 1.3681e-03 eta 0:18:15
epoch [21/50] batch [80/403] time 0.082 (0.088) data 0.000 (0.007) loss 1.6533 (1.8248) teacher_loss 0.6808 (0.8287) loss_zs_kd 1.8196 (1.6633) loss_oracle 0.9068 (0.9611) kd_loss 0.8818 (0.8999) acc 75.0000 (71.3672) lr 1.3681e-03 eta 0:17:39
epoch [21/50] batch [100/403] time 0.077 (0.087) data 0.000 (0.006) loss 1.5784 (1.8270) teacher_loss 0.5269 (0.8291) loss_zs_kd 1.3408 (1.6575) loss_oracle 0.8642 (0.9606) kd_loss 0.9651 (0.9018) acc 81.2500 (71.5938) lr 1.3681e-03 eta 0:17:23
epoch [21/50] batch [120/403] time 0.081 (0.089) data 0.000 (0.005) loss 1.9266 (1.8247) teacher_loss 0.9716 (0.8281) loss_zs_kd 1.5170 (1.6533) loss_oracle 0.9192 (0.9566) kd_loss 0.8631 (0.9010) acc 56.2500 (71.5885) lr 1.3681e-03 eta 0:17:48
epoch [21/50] batch [140/403] time 0.092 (0.088) data 0.000 (0.004) loss 1.8495 (1.8458) teacher_loss 0.8421 (0.8504) loss_zs_kd 1.1835 (1.6474) loss_oracle 0.9806 (0.9537) kd_loss 0.9094 (0.9001) acc 65.6250 (70.8482) lr 1.3681e-03 eta 0:17:31
epoch [21/50] batch [160/403] time 0.079 (0.088) data 0.000 (0.004) loss 1.9794 (1.8409) teacher_loss 0.8595 (0.8451) loss_zs_kd 1.6352 (1.6354) loss_oracle 1.0631 (0.9550) kd_loss 1.0136 (0.9003) acc 75.0000 (71.0938) lr 1.3681e-03 eta 0:17:26
epoch [21/50] batch [180/403] time 0.078 (0.087) data 0.000 (0.003) loss 1.9052 (1.8390) teacher_loss 0.8270 (0.8416) loss_zs_kd 1.5609 (1.6354) loss_oracle 0.9011 (0.9542) kd_loss 0.9881 (0.9020) acc 65.6250 (71.2153) lr 1.3681e-03 eta 0:17:12
epoch [21/50] batch [200/403] time 0.070 (0.086) data 0.000 (0.003) loss 1.6442 (1.8217) teacher_loss 0.6430 (0.8293) loss_zs_kd 1.1533 (1.6273) loss_oracle 0.9494 (0.9505) kd_loss 0.9062 (0.8974) acc 68.7500 (71.5781) lr 1.3681e-03 eta 0:16:58
epoch [21/50] batch [220/403] time 0.076 (0.085) data 0.000 (0.003) loss 1.6261 (1.8130) teacher_loss 0.7052 (0.8228) loss_zs_kd 1.4166 (1.6262) loss_oracle 0.8828 (0.9475) kd_loss 0.8327 (0.8955) acc 75.0000 (71.9318) lr 1.3681e-03 eta 0:16:50
epoch [21/50] batch [240/403] time 0.079 (0.085) data 0.000 (0.003) loss 1.9934 (1.8177) teacher_loss 0.9083 (0.8265) loss_zs_kd 1.6215 (1.6192) loss_oracle 0.9541 (0.9458) kd_loss 0.9898 (0.8966) acc 68.7500 (71.8620) lr 1.3681e-03 eta 0:16:45
epoch [21/50] batch [260/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.5695 (1.8173) teacher_loss 0.5790 (0.8278) loss_zs_kd 1.5682 (1.6124) loss_oracle 0.9505 (0.9449) kd_loss 0.8955 (0.8951) acc 71.8750 (71.8389) lr 1.3681e-03 eta 0:16:41
epoch [21/50] batch [280/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.9364 (1.8165) teacher_loss 0.8932 (0.8275) loss_zs_kd 1.2822 (1.6022) loss_oracle 0.9747 (0.9439) kd_loss 0.9457 (0.8945) acc 59.3750 (71.7522) lr 1.3681e-03 eta 0:16:36
epoch [21/50] batch [300/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.9480 (1.8110) teacher_loss 0.9748 (0.8249) loss_zs_kd 1.7689 (1.6013) loss_oracle 0.9452 (0.9427) kd_loss 0.8786 (0.8918) acc 62.5000 (71.7083) lr 1.3681e-03 eta 0:16:32
epoch [21/50] batch [320/403] time 0.083 (0.084) data 0.000 (0.002) loss 1.7125 (1.8121) teacher_loss 0.7586 (0.8284) loss_zs_kd 1.6102 (1.5941) loss_oracle 0.9340 (0.9420) kd_loss 0.8605 (0.8895) acc 71.8750 (71.6797) lr 1.3681e-03 eta 0:16:28
epoch [21/50] batch [340/403] time 0.081 (0.084) data 0.000 (0.002) loss 1.8517 (1.8137) teacher_loss 0.8623 (0.8305) loss_zs_kd 1.9629 (1.5910) loss_oracle 0.9006 (0.9410) kd_loss 0.8994 (0.8891) acc 71.8750 (71.4338) lr 1.3681e-03 eta 0:16:23
epoch [21/50] batch [360/403] time 0.080 (0.083) data 0.000 (0.002) loss 1.8865 (1.8143) teacher_loss 0.9669 (0.8315) loss_zs_kd 1.4234 (1.5909) loss_oracle 0.9209 (0.9405) kd_loss 0.8274 (0.8887) acc 75.0000 (71.3628) lr 1.3681e-03 eta 0:16:18
epoch [21/50] batch [380/403] time 0.082 (0.083) data 0.000 (0.002) loss 2.1161 (1.8211) teacher_loss 1.1250 (0.8368) loss_zs_kd 1.8326 (1.6008) loss_oracle 0.9535 (0.9408) kd_loss 0.8958 (0.8902) acc 68.7500 (71.2582) lr 1.3681e-03 eta 0:16:12
epoch [21/50] batch [400/403] time 0.080 (0.083) data 0.000 (0.002) loss 1.7828 (1.8236) teacher_loss 0.7072 (0.8376) loss_zs_kd 2.1000 (1.6027) loss_oracle 0.8959 (0.9409) kd_loss 0.9860 (0.8919) acc 75.0000 (71.2500) lr 1.3681e-03 eta 0:16:09
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,857
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 55.2%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,303
* accuracy: 39.1%
* error: 60.9%
* macro_f1: 27.8%
******* Domain 4 best val acc:      70.4%, epoch: 17 *******
******* Domain 4 best val test acc: 39.1%, epoch: 17 *******
******* Domain 4 best test acc:     39.1%, epoch: 17 *******
epoch [22/50] batch [20/403] time 0.084 (0.109) data 0.000 (0.024) loss 1.8791 (1.8666) teacher_loss 0.8761 (0.8668) loss_zs_kd 1.7091 (1.6136) loss_oracle 0.8666 (0.9399) kd_loss 0.9164 (0.9058) acc 68.7500 (67.9688) lr 1.3090e-03 eta 0:21:10
epoch [22/50] batch [40/403] time 0.082 (0.096) data 0.000 (0.012) loss 2.2121 (1.8501) teacher_loss 1.2385 (0.8563) loss_zs_kd 1.8366 (1.6227) loss_oracle 0.8922 (0.9263) kd_loss 0.8844 (0.9012) acc 59.3750 (68.6719) lr 1.3090e-03 eta 0:18:42
epoch [22/50] batch [60/403] time 0.075 (0.090) data 0.000 (0.008) loss 1.8500 (1.8661) teacher_loss 0.7418 (0.8599) loss_zs_kd 2.0041 (1.6240) loss_oracle 0.9046 (0.9230) kd_loss 1.0178 (0.9139) acc 78.1250 (68.7500) lr 1.3090e-03 eta 0:17:27
epoch [22/50] batch [80/403] time 0.079 (0.088) data 0.000 (0.006) loss 1.9114 (1.8689) teacher_loss 0.8686 (0.8571) loss_zs_kd 1.4340 (1.6188) loss_oracle 0.9889 (0.9315) kd_loss 0.9439 (0.9186) acc 65.6250 (69.2188) lr 1.3090e-03 eta 0:16:59
epoch [22/50] batch [100/403] time 0.084 (0.087) data 0.000 (0.005) loss 1.7043 (1.8598) teacher_loss 0.7013 (0.8415) loss_zs_kd 1.5827 (1.5925) loss_oracle 0.9111 (0.9343) kd_loss 0.9119 (0.9249) acc 75.0000 (69.7188) lr 1.3090e-03 eta 0:16:48
epoch [22/50] batch [120/403] time 0.090 (0.086) data 0.000 (0.004) loss 1.7297 (1.8391) teacher_loss 0.7714 (0.8254) loss_zs_kd 1.6285 (1.5945) loss_oracle 0.9675 (0.9353) kd_loss 0.8615 (0.9201) acc 65.6250 (70.2604) lr 1.3090e-03 eta 0:16:33
epoch [22/50] batch [140/403] time 0.068 (0.085) data 0.000 (0.004) loss 2.0020 (1.8406) teacher_loss 0.9564 (0.8258) loss_zs_kd 1.5206 (1.6056) loss_oracle 0.9510 (0.9364) kd_loss 0.9504 (0.9212) acc 71.8750 (70.3348) lr 1.3090e-03 eta 0:16:18
epoch [22/50] batch [160/403] time 0.081 (0.084) data 0.000 (0.003) loss 1.5695 (1.8369) teacher_loss 0.5333 (0.8239) loss_zs_kd 1.6714 (1.6072) loss_oracle 0.9694 (0.9360) kd_loss 0.9392 (0.9194) acc 81.2500 (70.4883) lr 1.3090e-03 eta 0:16:13
epoch [22/50] batch [180/403] time 0.073 (0.084) data 0.000 (0.003) loss 2.0090 (1.8364) teacher_loss 0.9705 (0.8257) loss_zs_kd 1.2964 (1.6082) loss_oracle 0.8864 (0.9354) kd_loss 0.9499 (0.9171) acc 71.8750 (70.5729) lr 1.3090e-03 eta 0:16:06
epoch [22/50] batch [200/403] time 0.078 (0.084) data 0.000 (0.003) loss 2.3379 (1.8423) teacher_loss 1.1701 (0.8281) loss_zs_kd 1.9191 (1.6186) loss_oracle 1.0250 (0.9364) kd_loss 1.0653 (0.9206) acc 56.2500 (70.5938) lr 1.3090e-03 eta 0:16:01
epoch [22/50] batch [220/403] time 0.072 (0.083) data 0.000 (0.002) loss 1.7582 (1.8440) teacher_loss 0.7483 (0.8271) loss_zs_kd 1.3197 (1.6252) loss_oracle 0.9215 (0.9358) kd_loss 0.9177 (0.9233) acc 78.1250 (70.6534) lr 1.3090e-03 eta 0:15:57
epoch [22/50] batch [240/403] time 0.080 (0.083) data 0.000 (0.002) loss 1.7205 (1.8445) teacher_loss 0.7041 (0.8267) loss_zs_kd 1.7578 (1.6248) loss_oracle 0.9546 (0.9364) kd_loss 0.9210 (0.9241) acc 78.1250 (70.6901) lr 1.3090e-03 eta 0:15:48
epoch [22/50] batch [260/403] time 0.083 (0.083) data 0.000 (0.002) loss 1.4313 (1.8382) teacher_loss 0.4788 (0.8238) loss_zs_kd 1.6999 (1.6289) loss_oracle 0.8977 (0.9351) kd_loss 0.8628 (0.9209) acc 87.5000 (70.9014) lr 1.3090e-03 eta 0:15:47
epoch [22/50] batch [280/403] time 0.074 (0.084) data 0.000 (0.002) loss 1.8347 (1.8366) teacher_loss 0.9146 (0.8263) loss_zs_kd 1.7224 (1.6267) loss_oracle 0.8770 (0.9349) kd_loss 0.8324 (0.9167) acc 59.3750 (70.8036) lr 1.3090e-03 eta 0:15:59
epoch [22/50] batch [300/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.3371 (1.8337) teacher_loss 0.3848 (0.8258) loss_zs_kd 1.6757 (1.6248) loss_oracle 0.8879 (0.9336) kd_loss 0.8635 (0.9145) acc 84.3750 (70.9583) lr 1.3090e-03 eta 0:15:53
epoch [22/50] batch [320/403] time 0.092 (0.084) data 0.000 (0.002) loss 1.7929 (1.8309) teacher_loss 0.8142 (0.8258) loss_zs_kd 1.6342 (1.6182) loss_oracle 0.9327 (0.9340) kd_loss 0.8854 (0.9117) acc 75.0000 (71.0645) lr 1.3090e-03 eta 0:15:49
epoch [22/50] batch [340/403] time 0.076 (0.083) data 0.000 (0.002) loss 1.9123 (1.8312) teacher_loss 0.9164 (0.8267) loss_zs_kd 1.6052 (1.6208) loss_oracle 0.8909 (0.9335) kd_loss 0.9069 (0.9111) acc 71.8750 (71.0570) lr 1.3090e-03 eta 0:15:42
epoch [22/50] batch [360/403] time 0.078 (0.083) data 0.000 (0.002) loss 1.7205 (1.8347) teacher_loss 0.7434 (0.8317) loss_zs_kd 2.0233 (1.6247) loss_oracle 0.9901 (0.9328) kd_loss 0.8781 (0.9098) acc 78.1250 (70.8420) lr 1.3090e-03 eta 0:15:37
epoch [22/50] batch [380/403] time 0.093 (0.083) data 0.000 (0.002) loss 1.4119 (1.8350) teacher_loss 0.4578 (0.8328) loss_zs_kd 1.4833 (1.6255) loss_oracle 0.9129 (0.9325) kd_loss 0.8628 (0.9090) acc 84.3750 (70.8717) lr 1.3090e-03 eta 0:15:33
epoch [22/50] batch [400/403] time 0.072 (0.082) data 0.000 (0.001) loss 1.4020 (1.8333) teacher_loss 0.4458 (0.8311) loss_zs_kd 1.6244 (1.6229) loss_oracle 0.9463 (0.9328) kd_loss 0.8615 (0.9089) acc 84.3750 (70.9688) lr 1.3090e-03 eta 0:15:27
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,937
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 58.0%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,357
* accuracy: 40.1%
* error: 59.9%
* macro_f1: 29.6%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.1%, epoch: 22 *******
******* Domain 4 best val test acc: 40.1%, epoch: 22 *******
******* Domain 4 best test acc:     40.1%, epoch: 22 *******
epoch [23/50] batch [20/403] time 0.084 (0.104) data 0.000 (0.024) loss 1.4264 (1.8028) teacher_loss 0.4762 (0.7965) loss_zs_kd 1.6955 (1.7008) loss_oracle 0.9744 (0.9426) kd_loss 0.8527 (0.9120) acc 87.5000 (72.0312) lr 1.2487e-03 eta 0:19:29
epoch [23/50] batch [40/403] time 0.074 (0.100) data 0.000 (0.012) loss 1.4323 (1.8191) teacher_loss 0.5317 (0.8136) loss_zs_kd 1.6879 (1.7401) loss_oracle 0.8658 (0.9288) kd_loss 0.8140 (0.9127) acc 87.5000 (71.6406) lr 1.2487e-03 eta 0:18:40
epoch [23/50] batch [60/403] time 0.080 (0.094) data 0.001 (0.008) loss 1.7789 (1.8206) teacher_loss 0.8841 (0.8155) loss_zs_kd 1.3896 (1.7235) loss_oracle 0.9091 (0.9318) kd_loss 0.8038 (0.9119) acc 75.0000 (71.6146) lr 1.2487e-03 eta 0:17:30
epoch [23/50] batch [80/403] time 0.079 (0.089) data 0.000 (0.006) loss 1.8849 (1.8082) teacher_loss 0.8335 (0.8057) loss_zs_kd 1.6626 (1.7158) loss_oracle 0.9306 (0.9291) kd_loss 0.9583 (0.9097) acc 71.8750 (71.6406) lr 1.2487e-03 eta 0:16:42
epoch [23/50] batch [100/403] time 0.080 (0.088) data 0.000 (0.005) loss 1.5778 (1.8047) teacher_loss 0.6069 (0.8000) loss_zs_kd 1.5154 (1.7148) loss_oracle 0.8593 (0.9315) kd_loss 0.8850 (0.9116) acc 81.2500 (72.2188) lr 1.2487e-03 eta 0:16:19
epoch [23/50] batch [120/403] time 0.077 (0.086) data 0.000 (0.004) loss 1.9047 (1.8122) teacher_loss 0.9049 (0.8074) loss_zs_kd 1.7090 (1.7203) loss_oracle 0.8771 (0.9308) kd_loss 0.9121 (0.9116) acc 71.8750 (71.7448) lr 1.2487e-03 eta 0:15:58
epoch [23/50] batch [140/403] time 0.091 (0.085) data 0.000 (0.004) loss 1.7524 (1.8209) teacher_loss 0.7643 (0.8139) loss_zs_kd 1.8758 (1.7068) loss_oracle 0.9604 (0.9304) kd_loss 0.8921 (0.9139) acc 75.0000 (71.8750) lr 1.2487e-03 eta 0:15:48
epoch [23/50] batch [160/403] time 0.080 (0.085) data 0.000 (0.003) loss 1.7102 (1.8187) teacher_loss 0.6187 (0.8128) loss_zs_kd 1.6691 (1.7027) loss_oracle 0.9212 (0.9278) kd_loss 0.9993 (0.9131) acc 81.2500 (72.0117) lr 1.2487e-03 eta 0:15:45
epoch [23/50] batch [180/403] time 0.089 (0.085) data 0.000 (0.003) loss 1.6470 (1.8244) teacher_loss 0.7153 (0.8192) loss_zs_kd 1.9586 (1.6849) loss_oracle 0.9339 (0.9274) kd_loss 0.8383 (0.9124) acc 68.7500 (71.7535) lr 1.2487e-03 eta 0:15:38
epoch [23/50] batch [200/403] time 0.085 (0.085) data 0.000 (0.003) loss 1.8114 (1.8247) teacher_loss 0.6968 (0.8184) loss_zs_kd 2.0018 (1.6740) loss_oracle 0.9410 (0.9269) kd_loss 1.0205 (0.9135) acc 75.0000 (71.7969) lr 1.2487e-03 eta 0:15:37
epoch [23/50] batch [220/403] time 0.093 (0.085) data 0.000 (0.002) loss 1.6010 (1.8227) teacher_loss 0.6794 (0.8187) loss_zs_kd 1.7467 (1.6644) loss_oracle 0.9313 (0.9275) kd_loss 0.8285 (0.9112) acc 87.5000 (71.8750) lr 1.2487e-03 eta 0:15:35
epoch [23/50] batch [240/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.4893 (1.8123) teacher_loss 0.5429 (0.8104) loss_zs_kd 1.5153 (1.6576) loss_oracle 0.9146 (0.9245) kd_loss 0.8549 (0.9094) acc 75.0000 (72.1094) lr 1.2487e-03 eta 0:15:30
epoch [23/50] batch [260/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.6534 (1.8091) teacher_loss 0.7500 (0.8085) loss_zs_kd 1.4499 (1.6633) loss_oracle 0.9037 (0.9235) kd_loss 0.8131 (0.9082) acc 71.8750 (72.0913) lr 1.2487e-03 eta 0:15:27
epoch [23/50] batch [280/403] time 0.071 (0.084) data 0.000 (0.002) loss 1.6855 (1.8095) teacher_loss 0.7250 (0.8106) loss_zs_kd 1.6393 (1.6572) loss_oracle 0.9428 (0.9214) kd_loss 0.8662 (0.9068) acc 78.1250 (72.0759) lr 1.2487e-03 eta 0:15:19
epoch [23/50] batch [300/403] time 0.067 (0.083) data 0.000 (0.002) loss 1.4788 (1.8090) teacher_loss 0.5137 (0.8111) loss_zs_kd 2.0228 (1.6581) loss_oracle 0.8660 (0.9210) kd_loss 0.8785 (0.9058) acc 87.5000 (71.9271) lr 1.2487e-03 eta 0:15:12
epoch [23/50] batch [320/403] time 0.088 (0.083) data 0.000 (0.002) loss 2.1320 (1.8066) teacher_loss 1.1081 (0.8084) loss_zs_kd 1.4289 (1.6567) loss_oracle 0.9620 (0.9220) kd_loss 0.9277 (0.9060) acc 50.0000 (71.9434) lr 1.2487e-03 eta 0:15:05
epoch [23/50] batch [340/403] time 0.077 (0.082) data 0.000 (0.002) loss 1.5787 (1.8080) teacher_loss 0.6420 (0.8114) loss_zs_kd 1.7658 (1.6618) loss_oracle 0.9323 (0.9220) kd_loss 0.8434 (0.9045) acc 81.2500 (71.9577) lr 1.2487e-03 eta 0:15:00
epoch [23/50] batch [360/403] time 0.078 (0.082) data 0.000 (0.002) loss 1.4907 (1.8080) teacher_loss 0.5741 (0.8111) loss_zs_kd 1.6561 (1.6596) loss_oracle 0.9464 (0.9220) kd_loss 0.8220 (0.9048) acc 78.1250 (71.9878) lr 1.2487e-03 eta 0:14:55
epoch [23/50] batch [380/403] time 0.072 (0.082) data 0.000 (0.002) loss 1.8089 (1.8065) teacher_loss 0.7224 (0.8100) loss_zs_kd 1.4057 (1.6544) loss_oracle 0.9365 (0.9221) kd_loss 0.9929 (0.9043) acc 71.8750 (72.1382) lr 1.2487e-03 eta 0:14:51
epoch [23/50] batch [400/403] time 0.068 (0.081) data 0.000 (0.001) loss 1.8585 (1.8083) teacher_loss 0.8219 (0.8118) loss_zs_kd 1.6853 (1.6457) loss_oracle 0.8753 (0.9209) kd_loss 0.9491 (0.9044) acc 71.8750 (72.0625) lr 1.2487e-03 eta 0:14:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,937
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 57.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,416
* accuracy: 41.1%
* error: 58.9%
* macro_f1: 30.2%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.1%, epoch: 22 *******
******* Domain 4 best val test acc: 40.1%, epoch: 22 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [24/50] batch [20/403] time 0.084 (0.117) data 0.000 (0.030) loss 1.7560 (1.7994) teacher_loss 0.7739 (0.8171) loss_zs_kd 1.8247 (1.5269) loss_oracle 0.8650 (0.9024) kd_loss 0.8956 (0.8920) acc 75.0000 (70.1562) lr 1.1874e-03 eta 0:21:13
epoch [24/50] batch [40/403] time 0.084 (0.100) data 0.000 (0.015) loss 1.5526 (1.7900) teacher_loss 0.5760 (0.8002) loss_zs_kd 1.2868 (1.4949) loss_oracle 0.8487 (0.8998) kd_loss 0.8918 (0.8998) acc 75.0000 (71.0156) lr 1.1874e-03 eta 0:18:05
epoch [24/50] batch [60/403] time 0.089 (0.095) data 0.001 (0.010) loss 1.9037 (1.7835) teacher_loss 0.8507 (0.7953) loss_zs_kd 1.2999 (1.5385) loss_oracle 0.9065 (0.8985) kd_loss 0.9623 (0.8983) acc 75.0000 (71.9792) lr 1.1874e-03 eta 0:17:10
epoch [24/50] batch [80/403] time 0.092 (0.093) data 0.000 (0.008) loss 2.1983 (1.7900) teacher_loss 1.2263 (0.8060) loss_zs_kd 1.8049 (1.5449) loss_oracle 0.9064 (0.8963) kd_loss 0.8813 (0.8944) acc 53.1250 (71.2500) lr 1.1874e-03 eta 0:16:48
epoch [24/50] batch [100/403] time 0.086 (0.092) data 0.000 (0.006) loss 1.8674 (1.7865) teacher_loss 0.7620 (0.7984) loss_zs_kd 1.2959 (1.5298) loss_oracle 0.9046 (0.8947) kd_loss 1.0149 (0.8986) acc 78.1250 (71.7812) lr 1.1874e-03 eta 0:16:28
epoch [24/50] batch [120/403] time 0.090 (0.091) data 0.000 (0.005) loss 1.6486 (1.7866) teacher_loss 0.6205 (0.7956) loss_zs_kd 1.7437 (1.5224) loss_oracle 0.9138 (0.8936) kd_loss 0.9368 (0.9015) acc 81.2500 (71.6667) lr 1.1874e-03 eta 0:16:17
epoch [24/50] batch [140/403] time 0.069 (0.088) data 0.000 (0.005) loss 1.8091 (1.7792) teacher_loss 0.8287 (0.7895) loss_zs_kd 2.0272 (1.5466) loss_oracle 0.8810 (0.8931) kd_loss 0.8922 (0.9004) acc 68.7500 (71.7857) lr 1.1874e-03 eta 0:15:46
epoch [24/50] batch [160/403] time 0.064 (0.085) data 0.000 (0.004) loss 1.7129 (1.7718) teacher_loss 0.7889 (0.7857) loss_zs_kd 1.7208 (1.5624) loss_oracle 0.9487 (0.8943) kd_loss 0.8292 (0.8967) acc 71.8750 (72.2266) lr 1.1874e-03 eta 0:15:15
epoch [24/50] batch [180/403] time 0.069 (0.083) data 0.000 (0.004) loss 1.9346 (1.7795) teacher_loss 0.9166 (0.7919) loss_zs_kd 1.8352 (1.5721) loss_oracle 0.8570 (0.8970) kd_loss 0.9322 (0.8979) acc 68.7500 (71.8403) lr 1.1874e-03 eta 0:14:53
epoch [24/50] batch [200/403] time 0.075 (0.083) data 0.000 (0.003) loss 1.8142 (1.7747) teacher_loss 0.8277 (0.7861) loss_zs_kd 1.9526 (1.5814) loss_oracle 0.8918 (0.8983) kd_loss 0.8973 (0.8987) acc 71.8750 (72.0625) lr 1.1874e-03 eta 0:14:51
epoch [24/50] batch [220/403] time 0.065 (0.082) data 0.000 (0.003) loss 1.7450 (1.7852) teacher_loss 0.7975 (0.7944) loss_zs_kd 1.7226 (1.5930) loss_oracle 0.9027 (0.8995) kd_loss 0.8573 (0.9009) acc 71.8750 (71.7898) lr 1.1874e-03 eta 0:14:32
epoch [24/50] batch [240/403] time 0.064 (0.080) data 0.000 (0.003) loss 1.4338 (1.7789) teacher_loss 0.4745 (0.7886) loss_zs_kd 1.3283 (1.6063) loss_oracle 0.9022 (0.9008) kd_loss 0.8691 (0.9002) acc 84.3750 (72.0573) lr 1.1874e-03 eta 0:14:16
epoch [24/50] batch [260/403] time 0.070 (0.079) data 0.000 (0.003) loss 2.1032 (1.7783) teacher_loss 1.0497 (0.7895) loss_zs_kd 1.8254 (1.6126) loss_oracle 0.9009 (0.9017) kd_loss 0.9634 (0.8986) acc 59.3750 (72.0553) lr 1.1874e-03 eta 0:14:03
epoch [24/50] batch [280/403] time 0.063 (0.078) data 0.000 (0.002) loss 1.8787 (1.7791) teacher_loss 0.8649 (0.7891) loss_zs_kd 1.8840 (1.6199) loss_oracle 1.0748 (0.9045) kd_loss 0.9063 (0.8996) acc 65.6250 (72.1763) lr 1.1874e-03 eta 0:13:51
epoch [24/50] batch [300/403] time 0.062 (0.077) data 0.000 (0.002) loss 1.7051 (1.7846) teacher_loss 0.6885 (0.7929) loss_zs_kd 1.6812 (1.6329) loss_oracle 0.9722 (0.9074) kd_loss 0.9194 (0.9010) acc 68.7500 (72.0729) lr 1.1874e-03 eta 0:13:39
epoch [24/50] batch [320/403] time 0.066 (0.077) data 0.000 (0.002) loss 2.1577 (1.7871) teacher_loss 1.1894 (0.7951) loss_zs_kd 1.7895 (1.6455) loss_oracle 0.8244 (0.9057) kd_loss 0.8858 (0.9014) acc 65.6250 (72.0605) lr 1.1874e-03 eta 0:13:31
epoch [24/50] batch [340/403] time 0.069 (0.076) data 0.001 (0.002) loss 1.7228 (1.7871) teacher_loss 0.6921 (0.7947) loss_zs_kd 2.0284 (1.6594) loss_oracle 0.9726 (0.9058) kd_loss 0.9335 (0.9017) acc 75.0000 (72.0864) lr 1.1874e-03 eta 0:13:22
epoch [24/50] batch [360/403] time 0.063 (0.076) data 0.000 (0.002) loss 1.6835 (1.7894) teacher_loss 0.7445 (0.7972) loss_zs_kd 1.5967 (1.6625) loss_oracle 0.9193 (0.9070) kd_loss 0.8471 (0.9015) acc 81.2500 (71.9705) lr 1.1874e-03 eta 0:13:14
epoch [24/50] batch [380/403] time 0.069 (0.075) data 0.000 (0.002) loss 1.8098 (1.7898) teacher_loss 0.8434 (0.7977) loss_zs_kd 1.7050 (1.6610) loss_oracle 0.8358 (0.9064) kd_loss 0.8828 (0.9015) acc 71.8750 (71.9490) lr 1.1874e-03 eta 0:13:08
epoch [24/50] batch [400/403] time 0.085 (0.075) data 0.000 (0.002) loss 1.8562 (1.7940) teacher_loss 0.8057 (0.8016) loss_zs_kd 1.2385 (1.6638) loss_oracle 0.9423 (0.9082) kd_loss 0.9562 (0.9016) acc 68.7500 (71.8359) lr 1.1874e-03 eta 0:13:05
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,834
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 55.2%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,250
* accuracy: 38.2%
* error: 61.8%
* macro_f1: 28.2%
******* Domain 4 best val acc:      71.1%, epoch: 22 *******
******* Domain 4 best val test acc: 40.1%, epoch: 22 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [25/50] batch [20/403] time 0.076 (0.117) data 0.000 (0.032) loss 1.6760 (1.8466) teacher_loss 0.6726 (0.8304) loss_zs_kd 1.6493 (1.6227) loss_oracle 0.9135 (0.9050) kd_loss 0.9120 (0.9257) acc 81.2500 (71.4062) lr 1.1253e-03 eta 0:20:22
epoch [25/50] batch [40/403] time 0.083 (0.098) data 0.000 (0.016) loss 1.6671 (1.8733) teacher_loss 0.6556 (0.8575) loss_zs_kd 1.4496 (1.6254) loss_oracle 0.8963 (0.9094) kd_loss 0.9219 (0.9248) acc 75.0000 (70.2344) lr 1.1253e-03 eta 0:17:06
epoch [25/50] batch [60/403] time 0.101 (0.093) data 0.001 (0.011) loss 2.0467 (1.8523) teacher_loss 1.0435 (0.8444) loss_zs_kd 1.6630 (1.6304) loss_oracle 0.8857 (0.9125) kd_loss 0.9146 (0.9167) acc 71.8750 (70.6250) lr 1.1253e-03 eta 0:16:11
epoch [25/50] batch [80/403] time 0.082 (0.090) data 0.000 (0.008) loss 1.9863 (1.8450) teacher_loss 0.9387 (0.8411) loss_zs_kd 1.1751 (1.6433) loss_oracle 0.8678 (0.9129) kd_loss 0.9608 (0.9126) acc 65.6250 (70.3906) lr 1.1253e-03 eta 0:15:34
epoch [25/50] batch [100/403] time 0.074 (0.087) data 0.000 (0.007) loss 1.5320 (1.8357) teacher_loss 0.6535 (0.8350) loss_zs_kd 1.5509 (1.6604) loss_oracle 0.9310 (0.9152) kd_loss 0.7854 (0.9092) acc 81.2500 (70.5938) lr 1.1253e-03 eta 0:15:06
epoch [25/50] batch [120/403] time 0.078 (0.086) data 0.000 (0.006) loss 1.7648 (1.8197) teacher_loss 0.7545 (0.8202) loss_zs_kd 1.9372 (1.6733) loss_oracle 0.9147 (0.9125) kd_loss 0.9188 (0.9083) acc 75.0000 (71.5365) lr 1.1253e-03 eta 0:14:53
epoch [25/50] batch [140/403] time 0.076 (0.085) data 0.000 (0.005) loss 1.6656 (1.8181) teacher_loss 0.6428 (0.8184) loss_zs_kd 1.8481 (1.6951) loss_oracle 0.8612 (0.9108) kd_loss 0.9367 (0.9086) acc 81.2500 (71.3839) lr 1.1253e-03 eta 0:14:39
epoch [25/50] batch [160/403] time 0.086 (0.084) data 0.000 (0.004) loss 2.0441 (1.8160) teacher_loss 1.0726 (0.8174) loss_zs_kd 1.2843 (1.6881) loss_oracle 0.8839 (0.9100) kd_loss 0.8832 (0.9076) acc 71.8750 (71.5234) lr 1.1253e-03 eta 0:14:29
epoch [25/50] batch [180/403] time 0.096 (0.084) data 0.000 (0.004) loss 1.8122 (1.8163) teacher_loss 0.9106 (0.8162) loss_zs_kd 1.6636 (1.6801) loss_oracle 0.9070 (0.9123) kd_loss 0.8110 (0.9088) acc 62.5000 (71.6840) lr 1.1253e-03 eta 0:14:27
epoch [25/50] batch [200/403] time 0.075 (0.084) data 0.000 (0.003) loss 1.4201 (1.8223) teacher_loss 0.4790 (0.8195) loss_zs_kd 1.4807 (1.6764) loss_oracle 0.8883 (0.9165) kd_loss 0.8523 (0.9112) acc 90.6250 (71.6094) lr 1.1253e-03 eta 0:14:24
epoch [25/50] batch [220/403] time 0.076 (0.084) data 0.000 (0.003) loss 2.5316 (1.8266) teacher_loss 1.5336 (0.8216) loss_zs_kd 1.4418 (1.6705) loss_oracle 0.8725 (0.9209) kd_loss 0.9107 (0.9129) acc 40.6250 (71.7330) lr 1.1253e-03 eta 0:14:16
epoch [25/50] batch [240/403] time 0.096 (0.083) data 0.000 (0.003) loss 1.6625 (1.8247) teacher_loss 0.6337 (0.8187) loss_zs_kd 1.4446 (1.6723) loss_oracle 0.9483 (0.9231) kd_loss 0.9340 (0.9137) acc 81.2500 (71.8750) lr 1.1253e-03 eta 0:14:12
epoch [25/50] batch [260/403] time 0.079 (0.083) data 0.000 (0.003) loss 1.8019 (1.8193) teacher_loss 0.7783 (0.8137) loss_zs_kd 1.8683 (1.6727) loss_oracle 0.9617 (0.9233) kd_loss 0.9274 (0.9133) acc 78.1250 (72.2476) lr 1.1253e-03 eta 0:14:08
epoch [25/50] batch [280/403] time 0.077 (0.083) data 0.000 (0.003) loss 1.9073 (1.8162) teacher_loss 0.9175 (0.8118) loss_zs_kd 1.6875 (1.6775) loss_oracle 0.8510 (0.9221) kd_loss 0.9047 (0.9122) acc 62.5000 (72.2545) lr 1.1253e-03 eta 0:14:03
epoch [25/50] batch [300/403] time 0.086 (0.082) data 0.000 (0.002) loss 1.8737 (1.8152) teacher_loss 0.9283 (0.8121) loss_zs_kd 1.8034 (1.6825) loss_oracle 0.8309 (0.9217) kd_loss 0.8623 (0.9109) acc 65.6250 (72.1667) lr 1.1253e-03 eta 0:13:59
epoch [25/50] batch [320/403] time 0.089 (0.082) data 0.000 (0.002) loss 1.5060 (1.8139) teacher_loss 0.4676 (0.8119) loss_zs_kd 1.3405 (1.6829) loss_oracle 0.8928 (0.9204) kd_loss 0.9491 (0.9100) acc 84.3750 (72.1191) lr 1.1253e-03 eta 0:13:57
epoch [25/50] batch [340/403] time 0.063 (0.082) data 0.000 (0.002) loss 1.8459 (1.8130) teacher_loss 0.8762 (0.8115) loss_zs_kd 1.9307 (1.6807) loss_oracle 0.9207 (0.9206) kd_loss 0.8777 (0.9095) acc 65.6250 (72.0772) lr 1.1253e-03 eta 0:13:55
epoch [25/50] batch [360/403] time 0.075 (0.082) data 0.000 (0.002) loss 1.8060 (1.8098) teacher_loss 0.7425 (0.8092) loss_zs_kd 2.2178 (1.6801) loss_oracle 0.9110 (0.9206) kd_loss 0.9724 (0.9086) acc 71.8750 (72.0486) lr 1.1253e-03 eta 0:13:51
epoch [25/50] batch [380/403] time 0.081 (0.082) data 0.000 (0.002) loss 1.8936 (1.8097) teacher_loss 0.8997 (0.8086) loss_zs_kd 1.6377 (1.6756) loss_oracle 0.8908 (0.9211) kd_loss 0.9048 (0.9090) acc 62.5000 (72.0559) lr 1.1253e-03 eta 0:13:49
epoch [25/50] batch [400/403] time 0.061 (0.082) data 0.000 (0.002) loss 1.7933 (1.8094) teacher_loss 0.8238 (0.8085) loss_zs_kd 1.7027 (1.6744) loss_oracle 0.9346 (0.9211) kd_loss 0.8760 (0.9088) acc 78.1250 (72.0078) lr 1.1253e-03 eta 0:13:50
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,939
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 57.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,344
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 29.4%
******* Domain 4 best val acc:      71.2%, epoch: 25 *******
******* Domain 4 best val test acc: 39.8%, epoch: 25 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [26/50] batch [20/403] time 0.069 (0.091) data 0.000 (0.025) loss 1.6871 (1.8529) teacher_loss 0.7158 (0.8522) loss_zs_kd 1.9720 (1.6788) loss_oracle 0.8953 (0.9489) kd_loss 0.8818 (0.9058) acc 71.8750 (73.1250) lr 1.0628e-03 eta 0:15:17
epoch [26/50] batch [40/403] time 0.072 (0.076) data 0.000 (0.012) loss 1.4802 (1.8364) teacher_loss 0.5064 (0.8309) loss_zs_kd 1.5903 (1.6222) loss_oracle 0.8605 (0.9357) kd_loss 0.8878 (0.9119) acc 81.2500 (72.1094) lr 1.0628e-03 eta 0:12:46
epoch [26/50] batch [60/403] time 0.079 (0.078) data 0.001 (0.008) loss 1.7656 (1.8290) teacher_loss 0.7272 (0.8180) loss_zs_kd 1.8067 (1.6666) loss_oracle 0.9399 (0.9377) kd_loss 0.9445 (0.9172) acc 75.0000 (72.1875) lr 1.0628e-03 eta 0:12:56
epoch [26/50] batch [80/403] time 0.085 (0.078) data 0.000 (0.006) loss 1.7814 (1.8232) teacher_loss 0.7609 (0.8222) loss_zs_kd 1.9789 (1.6867) loss_oracle 0.9246 (0.9328) kd_loss 0.9281 (0.9077) acc 75.0000 (72.1875) lr 1.0628e-03 eta 0:12:57
epoch [26/50] batch [100/403] time 0.078 (0.077) data 0.001 (0.005) loss 1.8587 (1.8210) teacher_loss 0.9008 (0.8182) loss_zs_kd 1.3438 (1.7185) loss_oracle 0.8945 (0.9279) kd_loss 0.8684 (0.9100) acc 62.5000 (72.5938) lr 1.0628e-03 eta 0:12:51
epoch [26/50] batch [120/403] time 0.077 (0.078) data 0.000 (0.004) loss 2.0457 (1.8200) teacher_loss 1.0503 (0.8176) loss_zs_kd 1.9529 (1.7464) loss_oracle 0.8890 (0.9260) kd_loss 0.9065 (0.9097) acc 62.5000 (72.2135) lr 1.0628e-03 eta 0:12:55
epoch [26/50] batch [140/403] time 0.080 (0.079) data 0.000 (0.004) loss 1.5491 (1.8165) teacher_loss 0.6191 (0.8169) loss_zs_kd 2.0054 (1.7420) loss_oracle 0.8967 (0.9203) kd_loss 0.8403 (0.9076) acc 87.5000 (72.1652) lr 1.0628e-03 eta 0:13:05
epoch [26/50] batch [160/403] time 0.149 (0.082) data 0.001 (0.003) loss 1.7030 (1.8102) teacher_loss 0.7659 (0.8139) loss_zs_kd 1.8629 (1.7538) loss_oracle 0.9208 (0.9169) kd_loss 0.8450 (0.9046) acc 62.5000 (72.3047) lr 1.0628e-03 eta 0:13:35
epoch [26/50] batch [180/403] time 0.089 (0.083) data 0.000 (0.003) loss 1.8286 (1.8020) teacher_loss 0.8001 (0.8068) loss_zs_kd 1.5927 (1.7493) loss_oracle 0.8615 (0.9145) kd_loss 0.9423 (0.9038) acc 68.7500 (72.5521) lr 1.0628e-03 eta 0:13:38
epoch [26/50] batch [200/403] time 0.077 (0.083) data 0.000 (0.003) loss 1.4585 (1.7924) teacher_loss 0.5343 (0.8000) loss_zs_kd 1.3301 (1.7381) loss_oracle 0.9646 (0.9131) kd_loss 0.8278 (0.9011) acc 81.2500 (72.8594) lr 1.0628e-03 eta 0:13:35
epoch [26/50] batch [220/403] time 0.085 (0.082) data 0.000 (0.002) loss 1.5441 (1.7898) teacher_loss 0.5884 (0.7959) loss_zs_kd 1.8736 (1.7394) loss_oracle 0.8838 (0.9118) kd_loss 0.8674 (0.9028) acc 84.3750 (72.8977) lr 1.0628e-03 eta 0:13:31
epoch [26/50] batch [240/403] time 0.081 (0.082) data 0.000 (0.002) loss 1.5835 (1.7846) teacher_loss 0.5761 (0.7915) loss_zs_kd 1.7276 (1.7404) loss_oracle 0.9650 (0.9112) kd_loss 0.9110 (0.9020) acc 87.5000 (73.1250) lr 1.0628e-03 eta 0:13:30
epoch [26/50] batch [260/403] time 0.078 (0.082) data 0.000 (0.002) loss 1.8250 (1.7879) teacher_loss 0.7898 (0.7923) loss_zs_kd 1.4586 (1.7362) loss_oracle 0.9442 (0.9112) kd_loss 0.9408 (0.9045) acc 75.0000 (73.1851) lr 1.0628e-03 eta 0:13:28
epoch [26/50] batch [280/403] time 0.079 (0.082) data 0.000 (0.002) loss 1.6135 (1.7847) teacher_loss 0.6289 (0.7897) loss_zs_kd 1.6777 (1.7300) loss_oracle 0.8409 (0.9100) kd_loss 0.9006 (0.9040) acc 75.0000 (73.2143) lr 1.0628e-03 eta 0:13:24
epoch [26/50] batch [300/403] time 0.073 (0.082) data 0.000 (0.002) loss 1.8206 (1.7893) teacher_loss 0.7290 (0.7926) loss_zs_kd 1.5816 (1.7290) loss_oracle 0.9372 (0.9102) kd_loss 0.9979 (0.9057) acc 71.8750 (73.1562) lr 1.0628e-03 eta 0:13:21
epoch [26/50] batch [320/403] time 0.077 (0.082) data 0.000 (0.002) loss 2.0675 (1.7865) teacher_loss 1.0369 (0.7918) loss_zs_kd 1.6167 (1.7243) loss_oracle 0.9002 (0.9092) kd_loss 0.9405 (0.9038) acc 65.6250 (73.2520) lr 1.0628e-03 eta 0:13:20
epoch [26/50] batch [340/403] time 0.075 (0.082) data 0.000 (0.002) loss 1.4594 (1.7884) teacher_loss 0.4991 (0.7924) loss_zs_kd 1.6413 (1.7228) loss_oracle 0.9123 (0.9084) kd_loss 0.8691 (0.9052) acc 78.1250 (73.1158) lr 1.0628e-03 eta 0:13:17
epoch [26/50] batch [360/403] time 0.088 (0.082) data 0.000 (0.002) loss 1.9369 (1.7946) teacher_loss 0.9337 (0.7965) loss_zs_kd 2.0121 (1.7249) loss_oracle 0.8841 (0.9086) kd_loss 0.9148 (0.9072) acc 53.1250 (72.9601) lr 1.0628e-03 eta 0:13:17
epoch [26/50] batch [380/403] time 0.078 (0.082) data 0.000 (0.002) loss 1.9037 (1.7940) teacher_loss 0.9085 (0.7962) loss_zs_kd 1.4945 (1.7234) loss_oracle 0.9284 (0.9089) kd_loss 0.9023 (0.9069) acc 71.8750 (73.0345) lr 1.0628e-03 eta 0:13:17
epoch [26/50] batch [400/403] time 0.075 (0.082) data 0.000 (0.001) loss 1.7973 (1.7961) teacher_loss 0.8109 (0.7977) loss_zs_kd 1.9591 (1.7234) loss_oracle 1.0150 (0.9095) kd_loss 0.8848 (0.9075) acc 81.2500 (72.9844) lr 1.0628e-03 eta 0:13:12
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,911
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,379
* accuracy: 40.4%
* error: 59.6%
* macro_f1: 29.8%
******* Domain 4 best val acc:      71.2%, epoch: 25 *******
******* Domain 4 best val test acc: 39.8%, epoch: 25 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [27/50] batch [20/403] time 0.077 (0.102) data 0.000 (0.029) loss 1.9134 (1.7865) teacher_loss 0.9401 (0.7891) loss_zs_kd 1.5873 (1.7532) loss_oracle 0.8930 (0.9138) kd_loss 0.8840 (0.9059) acc 62.5000 (71.8750) lr 1.0000e-03 eta 0:16:28
epoch [27/50] batch [40/403] time 0.089 (0.092) data 0.000 (0.015) loss 1.6712 (1.7543) teacher_loss 0.6706 (0.7680) loss_zs_kd 1.9859 (1.7214) loss_oracle 0.9067 (0.9021) kd_loss 0.9099 (0.8961) acc 78.1250 (74.0625) lr 1.0000e-03 eta 0:14:47
epoch [27/50] batch [60/403] time 0.079 (0.088) data 0.000 (0.010) loss 1.7682 (1.7541) teacher_loss 0.8260 (0.7696) loss_zs_kd 1.6735 (1.7668) loss_oracle 0.8621 (0.8992) kd_loss 0.8560 (0.8946) acc 68.7500 (73.9062) lr 1.0000e-03 eta 0:14:07
epoch [27/50] batch [80/403] time 0.062 (0.086) data 0.000 (0.007) loss 1.9110 (1.7516) teacher_loss 0.9721 (0.7713) loss_zs_kd 2.0935 (1.7456) loss_oracle 0.8454 (0.8974) kd_loss 0.8544 (0.8905) acc 62.5000 (73.9453) lr 1.0000e-03 eta 0:13:40
epoch [27/50] batch [100/403] time 0.088 (0.082) data 0.000 (0.006) loss 1.9485 (1.7473) teacher_loss 0.9061 (0.7650) loss_zs_kd 1.7489 (1.7505) loss_oracle 0.9227 (0.8962) kd_loss 0.9501 (0.8927) acc 62.5000 (73.8125) lr 1.0000e-03 eta 0:13:07
epoch [27/50] batch [120/403] time 0.084 (0.083) data 0.000 (0.005) loss 2.1700 (1.7512) teacher_loss 1.1188 (0.7674) loss_zs_kd 1.8795 (1.7675) loss_oracle 0.9279 (0.8941) kd_loss 0.9584 (0.8944) acc 65.6250 (73.8281) lr 1.0000e-03 eta 0:13:10
epoch [27/50] batch [140/403] time 0.093 (0.083) data 0.000 (0.004) loss 2.0299 (1.7636) teacher_loss 0.9756 (0.7791) loss_zs_kd 1.6162 (1.7809) loss_oracle 0.8498 (0.8948) kd_loss 0.9694 (0.8950) acc 65.6250 (73.1920) lr 1.0000e-03 eta 0:13:14
epoch [27/50] batch [160/403] time 0.087 (0.083) data 0.000 (0.004) loss 1.8967 (1.7632) teacher_loss 0.9513 (0.7807) loss_zs_kd 1.4547 (1.7717) loss_oracle 0.9231 (0.8942) kd_loss 0.8531 (0.8930) acc 78.1250 (73.2812) lr 1.0000e-03 eta 0:13:12
epoch [27/50] batch [180/403] time 0.085 (0.083) data 0.000 (0.003) loss 2.1452 (1.7606) teacher_loss 1.0851 (0.7792) loss_zs_kd 1.7164 (1.7698) loss_oracle 0.8797 (0.8932) kd_loss 0.9721 (0.8921) acc 68.7500 (73.4375) lr 1.0000e-03 eta 0:13:12
epoch [27/50] batch [200/403] time 0.077 (0.083) data 0.000 (0.003) loss 1.7831 (1.7623) teacher_loss 0.7707 (0.7808) loss_zs_kd 1.8851 (1.7796) loss_oracle 0.8937 (0.8924) kd_loss 0.9230 (0.8923) acc 68.7500 (73.2969) lr 1.0000e-03 eta 0:13:06
epoch [27/50] batch [220/403] time 0.079 (0.083) data 0.000 (0.003) loss 1.7724 (1.7752) teacher_loss 0.7470 (0.7900) loss_zs_kd 1.3142 (1.7844) loss_oracle 0.8636 (0.8913) kd_loss 0.9391 (0.8960) acc 78.1250 (72.7273) lr 1.0000e-03 eta 0:13:03
epoch [27/50] batch [240/403] time 0.091 (0.083) data 0.000 (0.003) loss 2.1140 (1.7767) teacher_loss 1.0823 (0.7920) loss_zs_kd 1.4411 (1.7737) loss_oracle 0.9232 (0.8912) kd_loss 0.9394 (0.8956) acc 65.6250 (72.6042) lr 1.0000e-03 eta 0:12:58
epoch [27/50] batch [260/403] time 0.077 (0.083) data 0.000 (0.002) loss 1.9059 (1.7795) teacher_loss 0.9316 (0.7947) loss_zs_kd 1.4781 (1.7712) loss_oracle 0.8556 (0.8913) kd_loss 0.8888 (0.8956) acc 71.8750 (72.4639) lr 1.0000e-03 eta 0:12:57
epoch [27/50] batch [280/403] time 0.093 (0.083) data 0.000 (0.002) loss 1.7379 (1.7788) teacher_loss 0.7934 (0.7931) loss_zs_kd 1.9558 (1.7729) loss_oracle 0.9255 (0.8916) kd_loss 0.8520 (0.8966) acc 81.2500 (72.6674) lr 1.0000e-03 eta 0:12:54
epoch [27/50] batch [300/403] time 0.074 (0.082) data 0.000 (0.002) loss 1.7749 (1.7794) teacher_loss 0.8391 (0.7918) loss_zs_kd 1.6558 (1.7723) loss_oracle 0.8567 (0.8913) kd_loss 0.8501 (0.8985) acc 78.1250 (72.6042) lr 1.0000e-03 eta 0:12:51
epoch [27/50] batch [320/403] time 0.086 (0.082) data 0.000 (0.002) loss 1.4574 (1.7764) teacher_loss 0.5488 (0.7887) loss_zs_kd 1.8258 (1.7685) loss_oracle 0.8684 (0.8901) kd_loss 0.8217 (0.8987) acc 81.2500 (72.7441) lr 1.0000e-03 eta 0:12:48
epoch [27/50] batch [340/403] time 0.069 (0.083) data 0.000 (0.002) loss 1.9982 (1.7818) teacher_loss 0.9592 (0.7942) loss_zs_kd 1.5670 (1.7626) loss_oracle 0.9380 (0.8897) kd_loss 0.9452 (0.8986) acc 81.2500 (72.6471) lr 1.0000e-03 eta 0:12:55
epoch [27/50] batch [360/403] time 0.079 (0.083) data 0.000 (0.002) loss 2.0336 (1.7774) teacher_loss 1.0482 (0.7914) loss_zs_kd 2.0469 (1.7587) loss_oracle 0.9365 (0.8891) kd_loss 0.8917 (0.8971) acc 65.6250 (72.8906) lr 1.0000e-03 eta 0:12:52
epoch [27/50] batch [380/403] time 0.076 (0.083) data 0.000 (0.002) loss 1.8062 (1.7768) teacher_loss 0.7293 (0.7909) loss_zs_kd 1.8215 (1.7572) loss_oracle 0.8392 (0.8883) kd_loss 0.9930 (0.8970) acc 78.1250 (72.9194) lr 1.0000e-03 eta 0:12:50
epoch [27/50] batch [400/403] time 0.072 (0.083) data 0.000 (0.002) loss 1.7515 (1.7772) teacher_loss 0.8704 (0.7917) loss_zs_kd 2.0503 (1.7523) loss_oracle 0.8701 (0.8875) kd_loss 0.7941 (0.8968) acc 71.8750 (72.9297) lr 1.0000e-03 eta 0:12:45
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,871
* accuracy: 69.9%
* error: 30.1%
* macro_f1: 56.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,339
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 28.5%
******* Domain 4 best val acc:      71.2%, epoch: 25 *******
******* Domain 4 best val test acc: 39.8%, epoch: 25 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [28/50] batch [20/403] time 0.066 (0.108) data 0.000 (0.025) loss 1.7197 (1.7584) teacher_loss 0.7090 (0.7792) loss_zs_kd 2.2106 (1.7387) loss_oracle 0.8863 (0.8830) kd_loss 0.9221 (0.8909) acc 75.0000 (73.5938) lr 9.3721e-04 eta 0:16:41
epoch [28/50] batch [40/403] time 0.056 (0.090) data 0.000 (0.013) loss 2.1931 (1.7982) teacher_loss 1.1532 (0.8041) loss_zs_kd 1.6505 (1.7717) loss_oracle 0.8958 (0.8846) kd_loss 0.9504 (0.9056) acc 65.6250 (72.6562) lr 9.3721e-04 eta 0:13:51
epoch [28/50] batch [60/403] time 0.083 (0.085) data 0.001 (0.009) loss 1.8327 (1.8273) teacher_loss 0.8226 (0.8304) loss_zs_kd 1.8345 (1.7731) loss_oracle 0.8944 (0.8878) kd_loss 0.9207 (0.9081) acc 62.5000 (71.5625) lr 9.3721e-04 eta 0:13:02
epoch [28/50] batch [80/403] time 0.083 (0.083) data 0.000 (0.006) loss 2.0927 (1.8045) teacher_loss 1.0304 (0.8050) loss_zs_kd 1.8889 (1.7622) loss_oracle 0.9256 (0.8948) kd_loss 0.9697 (0.9100) acc 53.1250 (72.2656) lr 9.3721e-04 eta 0:12:42
epoch [28/50] batch [100/403] time 0.140 (0.087) data 0.001 (0.005) loss 1.8782 (1.8161) teacher_loss 0.8554 (0.8157) loss_zs_kd 1.4514 (1.7617) loss_oracle 0.9333 (0.9036) kd_loss 0.9294 (0.9100) acc 75.0000 (71.9062) lr 9.3721e-04 eta 0:13:13
epoch [28/50] batch [120/403] time 0.087 (0.085) data 0.000 (0.004) loss 2.1162 (1.8121) teacher_loss 1.0658 (0.8101) loss_zs_kd 1.6304 (1.7534) loss_oracle 0.9532 (0.9046) kd_loss 0.9551 (0.9115) acc 59.3750 (72.2135) lr 9.3721e-04 eta 0:12:59
epoch [28/50] batch [140/403] time 0.084 (0.085) data 0.000 (0.004) loss 1.6528 (1.8055) teacher_loss 0.6600 (0.8053) loss_zs_kd 1.7012 (1.7424) loss_oracle 0.9004 (0.9043) kd_loss 0.9028 (0.9097) acc 71.8750 (72.3214) lr 9.3721e-04 eta 0:12:55
epoch [28/50] batch [160/403] time 0.081 (0.085) data 0.000 (0.003) loss 1.5844 (1.8107) teacher_loss 0.5276 (0.8107) loss_zs_kd 1.6508 (1.7433) loss_oracle 0.8815 (0.9036) kd_loss 0.9686 (0.9097) acc 78.1250 (71.8555) lr 9.3721e-04 eta 0:12:53
epoch [28/50] batch [180/403] time 0.074 (0.085) data 0.000 (0.003) loss 2.0200 (1.8101) teacher_loss 0.9533 (0.8095) loss_zs_kd 1.7237 (1.7497) loss_oracle 0.8945 (0.9037) kd_loss 0.9773 (0.9102) acc 65.6250 (71.8576) lr 9.3721e-04 eta 0:12:51
epoch [28/50] batch [200/403] time 0.072 (0.084) data 0.000 (0.003) loss 1.7963 (1.8082) teacher_loss 0.7932 (0.8048) loss_zs_kd 1.8647 (1.7534) loss_oracle 0.9357 (0.9035) kd_loss 0.9095 (0.9131) acc 62.5000 (71.8594) lr 9.3721e-04 eta 0:12:43
epoch [28/50] batch [220/403] time 0.086 (0.084) data 0.000 (0.003) loss 2.0067 (1.8141) teacher_loss 0.9737 (0.8084) loss_zs_kd 2.1527 (1.7594) loss_oracle 0.8628 (0.9016) kd_loss 0.9467 (0.9155) acc 65.6250 (71.7472) lr 9.3721e-04 eta 0:12:42
epoch [28/50] batch [240/403] time 0.072 (0.084) data 0.000 (0.002) loss 1.6909 (1.8196) teacher_loss 0.6228 (0.8146) loss_zs_kd 1.8480 (1.7573) loss_oracle 0.9314 (0.9000) kd_loss 0.9750 (0.9151) acc 81.2500 (71.4844) lr 9.3721e-04 eta 0:12:36
epoch [28/50] batch [260/403] time 0.090 (0.084) data 0.000 (0.002) loss 1.7676 (1.8183) teacher_loss 0.7212 (0.8140) loss_zs_kd 1.5743 (1.7503) loss_oracle 0.8873 (0.8982) kd_loss 0.9576 (0.9145) acc 75.0000 (71.6587) lr 9.3721e-04 eta 0:12:34
epoch [28/50] batch [280/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.4845 (1.8169) teacher_loss 0.5351 (0.8136) loss_zs_kd 1.7612 (1.7442) loss_oracle 0.8852 (0.8976) kd_loss 0.8609 (0.9135) acc 87.5000 (71.6295) lr 9.3721e-04 eta 0:12:34
epoch [28/50] batch [300/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.7882 (1.8136) teacher_loss 0.8186 (0.8119) loss_zs_kd 1.8984 (1.7419) loss_oracle 0.8406 (0.8968) kd_loss 0.8856 (0.9119) acc 68.7500 (71.6146) lr 9.3721e-04 eta 0:12:32
epoch [28/50] batch [320/403] time 0.092 (0.084) data 0.000 (0.002) loss 1.6661 (1.8133) teacher_loss 0.7324 (0.8133) loss_zs_kd 1.2949 (1.7413) loss_oracle 0.8878 (0.8950) kd_loss 0.8449 (0.9106) acc 71.8750 (71.5820) lr 9.3721e-04 eta 0:12:31
epoch [28/50] batch [340/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.7074 (1.8126) teacher_loss 0.6817 (0.8129) loss_zs_kd 1.5111 (1.7428) loss_oracle 0.9053 (0.8943) kd_loss 0.9351 (0.9103) acc 71.8750 (71.7371) lr 9.3721e-04 eta 0:12:27
epoch [28/50] batch [360/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.8309 (1.8149) teacher_loss 0.8038 (0.8144) loss_zs_kd 1.3955 (1.7423) loss_oracle 0.9020 (0.8943) kd_loss 0.9369 (0.9111) acc 71.8750 (71.7014) lr 9.3721e-04 eta 0:12:25
epoch [28/50] batch [380/403] time 0.083 (0.084) data 0.000 (0.002) loss 1.8932 (1.8172) teacher_loss 0.8255 (0.8168) loss_zs_kd 1.6675 (1.7365) loss_oracle 0.9007 (0.8938) kd_loss 0.9777 (0.9110) acc 71.8750 (71.7188) lr 9.3721e-04 eta 0:12:22
epoch [28/50] batch [400/403] time 0.074 (0.083) data 0.000 (0.002) loss 1.9912 (1.8168) teacher_loss 0.9267 (0.8165) loss_zs_kd 1.8286 (1.7414) loss_oracle 0.8657 (0.8941) kd_loss 0.9779 (0.9109) acc 75.0000 (71.5938) lr 9.3721e-04 eta 0:12:17
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,922
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 57.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,262
* accuracy: 38.4%
* error: 61.6%
* macro_f1: 27.4%
******* Domain 4 best val acc:      71.2%, epoch: 25 *******
******* Domain 4 best val test acc: 39.8%, epoch: 25 *******
******* Domain 4 best test acc:     41.1%, epoch: 23 *******
epoch [29/50] batch [20/403] time 0.073 (0.113) data 0.000 (0.033) loss 1.6367 (1.7834) teacher_loss 0.6041 (0.7956) loss_zs_kd 1.6159 (2.0151) loss_oracle 0.8985 (0.9060) kd_loss 0.9427 (0.8972) acc 84.3750 (75.6250) lr 8.7467e-04 eta 0:16:38
epoch [29/50] batch [40/403] time 0.084 (0.098) data 0.000 (0.016) loss 1.7904 (1.8013) teacher_loss 0.8109 (0.7999) loss_zs_kd 1.4307 (1.9638) loss_oracle 0.8678 (0.9002) kd_loss 0.8927 (0.9114) acc 71.8750 (74.2969) lr 8.7467e-04 eta 0:14:23
epoch [29/50] batch [60/403] time 0.084 (0.093) data 0.001 (0.011) loss 1.7702 (1.7993) teacher_loss 0.7701 (0.7982) loss_zs_kd 1.8958 (1.8704) loss_oracle 0.9080 (0.9011) kd_loss 0.9093 (0.9111) acc 78.1250 (73.4896) lr 8.7467e-04 eta 0:13:35
epoch [29/50] batch [80/403] time 0.083 (0.090) data 0.000 (0.008) loss 2.1047 (1.7945) teacher_loss 1.0691 (0.7941) loss_zs_kd 2.0025 (1.8624) loss_oracle 0.9030 (0.9004) kd_loss 0.9453 (0.9104) acc 59.3750 (73.5938) lr 8.7467e-04 eta 0:13:10
epoch [29/50] batch [100/403] time 0.076 (0.088) data 0.000 (0.007) loss 1.8420 (1.7972) teacher_loss 0.8763 (0.7908) loss_zs_kd 1.6835 (1.8210) loss_oracle 0.8448 (0.8952) kd_loss 0.8813 (0.9168) acc 59.3750 (73.7812) lr 8.7467e-04 eta 0:12:53
epoch [29/50] batch [120/403] time 0.081 (0.088) data 0.000 (0.006) loss 1.7037 (1.8200) teacher_loss 0.7501 (0.8043) loss_zs_kd 1.5030 (1.8182) loss_oracle 0.9081 (0.8942) kd_loss 0.8627 (0.9263) acc 68.7500 (73.0729) lr 8.7467e-04 eta 0:12:47
epoch [29/50] batch [140/403] time 0.078 (0.086) data 0.000 (0.005) loss 1.7780 (1.8094) teacher_loss 0.7700 (0.7949) loss_zs_kd 2.0309 (1.8128) loss_oracle 0.9043 (0.8939) kd_loss 0.9176 (0.9251) acc 81.2500 (73.7500) lr 8.7467e-04 eta 0:12:34
epoch [29/50] batch [160/403] time 0.079 (0.085) data 0.000 (0.004) loss 1.5334 (1.8078) teacher_loss 0.5273 (0.7916) loss_zs_kd 2.1301 (1.8131) loss_oracle 0.8760 (0.8908) kd_loss 0.9185 (0.9271) acc 84.3750 (73.6914) lr 8.7467e-04 eta 0:12:23
epoch [29/50] batch [180/403] time 0.076 (0.085) data 0.000 (0.004) loss 1.4747 (1.8086) teacher_loss 0.4102 (0.7902) loss_zs_kd 2.1856 (1.8237) loss_oracle 0.8596 (0.8914) kd_loss 0.9785 (0.9292) acc 81.2500 (73.5243) lr 8.7467e-04 eta 0:12:19
epoch [29/50] batch [200/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.4335 (1.8060) teacher_loss 0.4489 (0.7881) loss_zs_kd 2.4924 (1.8453) loss_oracle 0.9217 (0.8913) kd_loss 0.8925 (0.9287) acc 90.6250 (73.7344) lr 8.7467e-04 eta 0:12:17
epoch [29/50] batch [220/403] time 0.079 (0.085) data 0.000 (0.003) loss 1.7207 (1.8082) teacher_loss 0.8044 (0.7915) loss_zs_kd 1.7985 (1.8442) loss_oracle 0.9109 (0.8926) kd_loss 0.8252 (0.9274) acc 75.0000 (73.4659) lr 8.7467e-04 eta 0:12:13
epoch [29/50] batch [240/403] time 0.080 (0.085) data 0.000 (0.003) loss 2.0172 (1.8124) teacher_loss 0.9116 (0.7926) loss_zs_kd 2.2098 (1.8428) loss_oracle 0.8433 (0.8918) kd_loss 1.0213 (0.9306) acc 65.6250 (73.1771) lr 8.7467e-04 eta 0:12:11
epoch [29/50] batch [260/403] time 0.088 (0.084) data 0.000 (0.003) loss 1.7459 (1.8153) teacher_loss 0.6641 (0.7935) loss_zs_kd 1.7903 (1.8466) loss_oracle 0.9462 (0.8945) kd_loss 0.9872 (0.9323) acc 78.1250 (72.9928) lr 8.7467e-04 eta 0:12:06
epoch [29/50] batch [280/403] time 0.064 (0.085) data 0.000 (0.003) loss 1.6163 (1.8162) teacher_loss 0.5736 (0.7931) loss_zs_kd 2.1368 (1.8467) loss_oracle 0.9374 (0.8950) kd_loss 0.9490 (0.9336) acc 84.3750 (72.9129) lr 8.7467e-04 eta 0:12:10
epoch [29/50] batch [300/403] time 0.078 (0.085) data 0.000 (0.002) loss 2.0094 (1.8178) teacher_loss 1.0083 (0.7949) loss_zs_kd 2.1089 (1.8490) loss_oracle 0.8249 (0.8946) kd_loss 0.9187 (0.9334) acc 68.7500 (72.9062) lr 8.7467e-04 eta 0:12:05
epoch [29/50] batch [320/403] time 0.088 (0.085) data 0.000 (0.002) loss 2.0667 (1.8194) teacher_loss 0.9603 (0.7974) loss_zs_kd 1.6094 (1.8495) loss_oracle 0.9067 (0.8940) kd_loss 1.0157 (0.9326) acc 62.5000 (72.7539) lr 8.7467e-04 eta 0:12:04
epoch [29/50] batch [340/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.8282 (1.8241) teacher_loss 0.8278 (0.8026) loss_zs_kd 1.9071 (1.8467) loss_oracle 0.8274 (0.8939) kd_loss 0.9177 (0.9321) acc 68.7500 (72.5643) lr 8.7467e-04 eta 0:12:01
epoch [29/50] batch [360/403] time 0.089 (0.084) data 0.000 (0.002) loss 2.3596 (1.8241) teacher_loss 1.3313 (0.8032) loss_zs_kd 1.6664 (1.8413) loss_oracle 0.8748 (0.8942) kd_loss 0.9409 (0.9314) acc 56.2500 (72.5174) lr 8.7467e-04 eta 0:11:57
epoch [29/50] batch [380/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.7424 (1.8303) teacher_loss 0.7137 (0.8089) loss_zs_kd 1.9210 (1.8380) loss_oracle 0.9173 (0.8948) kd_loss 0.9370 (0.9319) acc 68.7500 (72.2615) lr 8.7467e-04 eta 0:11:54
epoch [29/50] batch [400/403] time 0.068 (0.084) data 0.000 (0.002) loss 1.9642 (1.8296) teacher_loss 0.9600 (0.8095) loss_zs_kd 1.6109 (1.8280) loss_oracle 0.8438 (0.8944) kd_loss 0.9198 (0.9306) acc 62.5000 (72.2422) lr 8.7467e-04 eta 0:11:48
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,971
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 58.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,464
* accuracy: 41.9%
* error: 58.1%
* macro_f1: 30.7%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      71.7%, epoch: 29 *******
******* Domain 4 best val test acc: 41.9%, epoch: 29 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [30/50] batch [20/403] time 0.081 (0.129) data 0.000 (0.048) loss 1.8586 (1.8584) teacher_loss 0.7669 (0.8306) loss_zs_kd 1.4012 (1.7086) loss_oracle 0.9386 (0.8881) kd_loss 0.9979 (0.9390) acc 75.0000 (70.6250) lr 8.1262e-04 eta 0:18:08
epoch [30/50] batch [40/403] time 0.084 (0.107) data 0.000 (0.024) loss 1.4342 (1.8465) teacher_loss 0.5450 (0.8420) loss_zs_kd 1.6076 (1.6985) loss_oracle 0.8169 (0.8873) kd_loss 0.8075 (0.9157) acc 84.3750 (70.6250) lr 8.1262e-04 eta 0:15:03
epoch [30/50] batch [60/403] time 0.077 (0.098) data 0.001 (0.016) loss 1.6947 (1.8341) teacher_loss 0.8032 (0.8314) loss_zs_kd 1.6288 (1.7047) loss_oracle 0.9072 (0.8895) kd_loss 0.8008 (0.9138) acc 68.7500 (71.5625) lr 8.1262e-04 eta 0:13:40
epoch [30/50] batch [80/403] time 0.083 (0.093) data 0.000 (0.012) loss 1.6933 (1.8156) teacher_loss 0.7005 (0.8072) loss_zs_kd 1.5931 (1.7167) loss_oracle 0.8262 (0.8913) kd_loss 0.9102 (0.9192) acc 75.0000 (72.4219) lr 8.1262e-04 eta 0:12:57
epoch [30/50] batch [100/403] time 0.083 (0.090) data 0.000 (0.010) loss 1.7625 (1.8048) teacher_loss 0.7792 (0.7931) loss_zs_kd 2.0141 (1.7308) loss_oracle 0.8522 (0.8910) kd_loss 0.8981 (0.9225) acc 75.0000 (72.6562) lr 8.1262e-04 eta 0:12:31
epoch [30/50] batch [120/403] time 0.073 (0.088) data 0.000 (0.008) loss 2.1415 (1.7993) teacher_loss 1.0541 (0.7854) loss_zs_kd 1.6952 (1.7578) loss_oracle 0.8930 (0.8914) kd_loss 0.9981 (0.9247) acc 56.2500 (72.8646) lr 8.1262e-04 eta 0:12:11
epoch [30/50] batch [140/403] time 0.087 (0.087) data 0.000 (0.007) loss 1.6806 (1.7966) teacher_loss 0.7335 (0.7854) loss_zs_kd 1.5588 (1.7676) loss_oracle 0.8722 (0.8901) kd_loss 0.8599 (0.9223) acc 71.8750 (72.6786) lr 8.1262e-04 eta 0:12:04
epoch [30/50] batch [160/403] time 0.081 (0.086) data 0.000 (0.006) loss 2.0541 (1.8000) teacher_loss 0.9523 (0.7874) loss_zs_kd 2.0099 (1.7794) loss_oracle 0.9120 (0.8879) kd_loss 1.0106 (0.9238) acc 65.6250 (72.6758) lr 8.1262e-04 eta 0:11:55
epoch [30/50] batch [180/403] time 0.076 (0.086) data 0.000 (0.006) loss 1.7114 (1.8045) teacher_loss 0.6614 (0.7906) loss_zs_kd 1.9641 (1.7939) loss_oracle 0.9637 (0.8881) kd_loss 0.9536 (0.9251) acc 75.0000 (72.6389) lr 8.1262e-04 eta 0:11:49
epoch [30/50] batch [200/403] time 0.084 (0.085) data 0.000 (0.005) loss 1.8661 (1.8052) teacher_loss 0.8273 (0.7901) loss_zs_kd 1.5059 (1.7943) loss_oracle 0.9153 (0.8884) kd_loss 0.9473 (0.9262) acc 56.2500 (72.3750) lr 8.1262e-04 eta 0:11:45
epoch [30/50] batch [220/403] time 0.097 (0.085) data 0.000 (0.005) loss 1.8670 (1.8085) teacher_loss 0.9027 (0.7935) loss_zs_kd 2.0176 (1.8035) loss_oracle 0.8848 (0.8899) kd_loss 0.8758 (0.9260) acc 71.8750 (72.1165) lr 8.1262e-04 eta 0:11:41
epoch [30/50] batch [240/403] time 0.081 (0.085) data 0.000 (0.004) loss 1.9317 (1.8155) teacher_loss 0.8709 (0.8014) loss_zs_kd 1.6333 (1.7948) loss_oracle 0.8755 (0.8917) kd_loss 0.9733 (0.9249) acc 75.0000 (72.0703) lr 8.1262e-04 eta 0:11:41
epoch [30/50] batch [260/403] time 0.087 (0.085) data 0.000 (0.004) loss 1.6216 (1.8144) teacher_loss 0.6704 (0.8019) loss_zs_kd 1.7266 (1.7950) loss_oracle 0.8565 (0.8913) kd_loss 0.8656 (0.9233) acc 81.2500 (72.0553) lr 8.1262e-04 eta 0:11:35
epoch [30/50] batch [280/403] time 0.078 (0.085) data 0.000 (0.004) loss 1.9727 (1.8202) teacher_loss 0.9778 (0.8072) loss_zs_kd 1.7641 (1.7934) loss_oracle 0.8892 (0.8917) kd_loss 0.9060 (0.9238) acc 62.5000 (71.9643) lr 8.1262e-04 eta 0:11:33
epoch [30/50] batch [300/403] time 0.087 (0.085) data 0.000 (0.003) loss 1.8544 (1.8232) teacher_loss 0.9389 (0.8114) loss_zs_kd 1.9127 (1.7953) loss_oracle 0.9444 (0.8926) kd_loss 0.8210 (0.9225) acc 65.6250 (71.8021) lr 8.1262e-04 eta 0:11:31
epoch [30/50] batch [320/403] time 0.083 (0.085) data 0.000 (0.003) loss 2.0978 (1.8230) teacher_loss 1.0265 (0.8107) loss_zs_kd 1.8621 (1.7830) loss_oracle 0.8992 (0.8942) kd_loss 0.9814 (0.9228) acc 62.5000 (71.7969) lr 8.1262e-04 eta 0:11:29
epoch [30/50] batch [340/403] time 0.058 (0.085) data 0.000 (0.003) loss 1.6949 (1.8246) teacher_loss 0.6948 (0.8117) loss_zs_kd 1.6962 (1.7758) loss_oracle 0.8635 (0.8967) kd_loss 0.9138 (0.9233) acc 78.1250 (71.7923) lr 8.1262e-04 eta 0:11:27
epoch [30/50] batch [360/403] time 0.074 (0.084) data 0.000 (0.003) loss 1.8073 (1.8226) teacher_loss 0.7389 (0.8097) loss_zs_kd 1.5823 (1.7755) loss_oracle 0.8890 (0.8998) kd_loss 0.9795 (0.9230) acc 78.1250 (71.9010) lr 8.1262e-04 eta 0:11:22
epoch [30/50] batch [380/403] time 0.074 (0.084) data 0.000 (0.003) loss 1.6802 (1.8224) teacher_loss 0.6176 (0.8102) loss_zs_kd 1.6506 (1.7764) loss_oracle 0.9453 (0.9006) kd_loss 0.9681 (0.9222) acc 78.1250 (71.9161) lr 8.1262e-04 eta 0:11:18
epoch [30/50] batch [400/403] time 0.118 (0.084) data 0.001 (0.003) loss 1.8670 (1.8201) teacher_loss 0.8026 (0.8080) loss_zs_kd 2.0832 (1.7781) loss_oracle 0.8841 (0.9017) kd_loss 0.9760 (0.9220) acc 62.5000 (71.8984) lr 8.1262e-04 eta 0:11:18
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,956
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 58.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,439
* accuracy: 41.5%
* error: 58.5%
* macro_f1: 30.1%
******* Domain 4 best val acc:      71.7%, epoch: 29 *******
******* Domain 4 best val test acc: 41.9%, epoch: 29 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [31/50] batch [20/403] time 0.076 (0.109) data 0.000 (0.030) loss 1.8287 (1.7999) teacher_loss 0.8572 (0.7975) loss_zs_kd 1.4194 (1.8069) loss_oracle 0.8939 (0.9040) kd_loss 0.8821 (0.9120) acc 68.7500 (71.0938) lr 7.5131e-04 eta 0:14:40
epoch [31/50] batch [40/403] time 0.082 (0.097) data 0.000 (0.015) loss 1.7532 (1.8132) teacher_loss 0.8064 (0.8106) loss_zs_kd 1.7052 (1.8340) loss_oracle 0.9802 (0.9034) kd_loss 0.8488 (0.9122) acc 68.7500 (71.6406) lr 7.5131e-04 eta 0:12:57
epoch [31/50] batch [60/403] time 0.084 (0.092) data 0.000 (0.010) loss 1.6064 (1.8395) teacher_loss 0.6466 (0.8233) loss_zs_kd 1.6406 (1.8212) loss_oracle 0.9173 (0.9025) kd_loss 0.8680 (0.9259) acc 78.1250 (70.8854) lr 7.5131e-04 eta 0:12:19
epoch [31/50] batch [80/403] time 0.083 (0.090) data 0.000 (0.008) loss 2.0771 (1.8322) teacher_loss 0.9484 (0.8216) loss_zs_kd 1.6425 (1.7812) loss_oracle 0.9334 (0.9058) kd_loss 1.0354 (0.9200) acc 68.7500 (71.0938) lr 7.5131e-04 eta 0:11:58
epoch [31/50] batch [100/403] time 0.085 (0.089) data 0.000 (0.006) loss 1.6915 (1.8401) teacher_loss 0.6270 (0.8261) loss_zs_kd 1.6250 (1.7633) loss_oracle 0.9496 (0.9030) kd_loss 0.9696 (0.9237) acc 81.2500 (71.1250) lr 7.5131e-04 eta 0:11:48
epoch [31/50] batch [120/403] time 0.080 (0.087) data 0.000 (0.005) loss 1.8298 (1.8354) teacher_loss 0.7100 (0.8213) loss_zs_kd 1.7289 (1.7566) loss_oracle 0.9100 (0.9014) kd_loss 1.0288 (0.9240) acc 78.1250 (71.4583) lr 7.5131e-04 eta 0:11:34
epoch [31/50] batch [140/403] time 0.086 (0.087) data 0.000 (0.005) loss 2.0466 (1.8346) teacher_loss 1.0477 (0.8270) loss_zs_kd 1.4983 (1.7490) loss_oracle 0.8573 (0.8990) kd_loss 0.9132 (0.9178) acc 65.6250 (71.3393) lr 7.5131e-04 eta 0:11:30
epoch [31/50] batch [160/403] time 0.082 (0.089) data 0.000 (0.004) loss 1.8502 (1.8350) teacher_loss 0.7693 (0.8289) loss_zs_kd 1.5445 (1.7641) loss_oracle 0.8889 (0.9001) kd_loss 0.9920 (0.9161) acc 68.7500 (71.4258) lr 7.5131e-04 eta 0:11:46
epoch [31/50] batch [180/403] time 0.075 (0.088) data 0.000 (0.004) loss 1.9025 (1.8312) teacher_loss 0.8957 (0.8270) loss_zs_kd 1.9753 (1.7567) loss_oracle 0.8925 (0.8998) kd_loss 0.9175 (0.9142) acc 62.5000 (71.3542) lr 7.5131e-04 eta 0:11:33
epoch [31/50] batch [200/403] time 0.081 (0.087) data 0.000 (0.003) loss 1.9625 (1.8287) teacher_loss 0.8918 (0.8245) loss_zs_kd 1.5533 (1.7636) loss_oracle 0.8911 (0.8990) kd_loss 0.9816 (0.9143) acc 65.6250 (71.6250) lr 7.5131e-04 eta 0:11:27
epoch [31/50] batch [220/403] time 0.090 (0.087) data 0.000 (0.003) loss 1.7511 (1.8233) teacher_loss 0.7950 (0.8194) loss_zs_kd 1.7915 (1.7640) loss_oracle 0.9769 (0.8999) kd_loss 0.8585 (0.9139) acc 71.8750 (71.7898) lr 7.5131e-04 eta 0:11:23
epoch [31/50] batch [240/403] time 0.079 (0.087) data 0.000 (0.003) loss 1.5602 (1.8227) teacher_loss 0.5561 (0.8192) loss_zs_kd 1.8804 (1.7619) loss_oracle 0.9010 (0.9005) kd_loss 0.9141 (0.9134) acc 81.2500 (71.7318) lr 7.5131e-04 eta 0:11:20
epoch [31/50] batch [260/403] time 0.084 (0.087) data 0.000 (0.003) loss 1.7142 (1.8264) teacher_loss 0.7061 (0.8227) loss_zs_kd 1.9107 (1.7597) loss_oracle 0.9502 (0.9004) kd_loss 0.9131 (0.9137) acc 78.1250 (71.6827) lr 7.5131e-04 eta 0:11:17
epoch [31/50] batch [280/403] time 0.086 (0.087) data 0.000 (0.002) loss 1.7252 (1.8293) teacher_loss 0.6921 (0.8250) loss_zs_kd 1.6863 (1.7566) loss_oracle 0.9355 (0.9014) kd_loss 0.9395 (0.9142) acc 75.0000 (71.5067) lr 7.5131e-04 eta 0:11:13
epoch [31/50] batch [300/403] time 0.080 (0.087) data 0.000 (0.002) loss 1.8855 (1.8321) teacher_loss 0.9037 (0.8257) loss_zs_kd 1.7985 (1.7581) loss_oracle 0.9202 (0.9006) kd_loss 0.8898 (0.9163) acc 65.6250 (71.5417) lr 7.5131e-04 eta 0:11:11
epoch [31/50] batch [320/403] time 0.094 (0.086) data 0.000 (0.002) loss 1.6941 (1.8317) teacher_loss 0.7335 (0.8246) loss_zs_kd 1.6393 (1.7490) loss_oracle 0.8742 (0.9010) kd_loss 0.8732 (0.9170) acc 75.0000 (71.5430) lr 7.5131e-04 eta 0:11:06
epoch [31/50] batch [340/403] time 0.088 (0.086) data 0.000 (0.002) loss 1.7236 (1.8314) teacher_loss 0.6748 (0.8239) loss_zs_kd 1.8362 (1.7435) loss_oracle 0.9057 (0.9002) kd_loss 0.9582 (0.9175) acc 75.0000 (71.5257) lr 7.5131e-04 eta 0:11:04
epoch [31/50] batch [360/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.9660 (1.8348) teacher_loss 0.8872 (0.8258) loss_zs_kd 2.2521 (1.7490) loss_oracle 0.9296 (0.9002) kd_loss 0.9859 (0.9190) acc 56.2500 (71.3889) lr 7.5131e-04 eta 0:11:02
epoch [31/50] batch [380/403] time 0.085 (0.086) data 0.000 (0.002) loss 2.1096 (1.8360) teacher_loss 1.0447 (0.8269) loss_zs_kd 1.6484 (1.7496) loss_oracle 0.9465 (0.9008) kd_loss 0.9703 (0.9190) acc 59.3750 (71.3651) lr 7.5131e-04 eta 0:10:59
epoch [31/50] batch [400/403] time 0.076 (0.086) data 0.000 (0.002) loss 1.9952 (1.8353) teacher_loss 0.9487 (0.8264) loss_zs_kd 1.6638 (1.7519) loss_oracle 0.9336 (0.9015) kd_loss 0.9532 (0.9188) acc 65.6250 (71.4062) lr 7.5131e-04 eta 0:10:55
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,948
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 58.1%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,435
* accuracy: 41.4%
* error: 58.6%
* macro_f1: 29.7%
******* Domain 4 best val acc:      71.7%, epoch: 29 *******
******* Domain 4 best val test acc: 41.9%, epoch: 29 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [32/50] batch [20/403] time 0.068 (0.110) data 0.000 (0.026) loss 1.6103 (1.8221) teacher_loss 0.7177 (0.7965) loss_zs_kd 1.8312 (1.7703) loss_oracle 0.8786 (0.9354) kd_loss 0.8048 (0.9321) acc 75.0000 (71.5625) lr 6.9098e-04 eta 0:14:01
epoch [32/50] batch [40/403] time 0.083 (0.097) data 0.000 (0.013) loss 1.8323 (1.7954) teacher_loss 0.8005 (0.7739) loss_zs_kd 2.0252 (1.7464) loss_oracle 0.8967 (0.9253) kd_loss 0.9421 (0.9290) acc 75.0000 (71.8750) lr 6.9098e-04 eta 0:12:17
epoch [32/50] batch [60/403] time 0.081 (0.092) data 0.000 (0.009) loss 1.6923 (1.8127) teacher_loss 0.6343 (0.7851) loss_zs_kd 2.1039 (1.8079) loss_oracle 0.9139 (0.9219) kd_loss 0.9665 (0.9354) acc 78.1250 (71.3021) lr 6.9098e-04 eta 0:11:36
epoch [32/50] batch [80/403] time 0.082 (0.090) data 0.000 (0.007) loss 1.7706 (1.8109) teacher_loss 0.6428 (0.7800) loss_zs_kd 1.7554 (1.7987) loss_oracle 0.9536 (0.9235) kd_loss 1.0325 (0.9386) acc 81.2500 (71.9531) lr 6.9098e-04 eta 0:11:21
epoch [32/50] batch [100/403] time 0.081 (0.088) data 0.000 (0.005) loss 1.6511 (1.8064) teacher_loss 0.6204 (0.7762) loss_zs_kd 1.5841 (1.8293) loss_oracle 0.8890 (0.9209) kd_loss 0.9417 (0.9382) acc 81.2500 (72.3750) lr 6.9098e-04 eta 0:11:04
epoch [32/50] batch [120/403] time 0.070 (0.087) data 0.000 (0.004) loss 1.8578 (1.8114) teacher_loss 0.7901 (0.7768) loss_zs_kd 2.0203 (1.8295) loss_oracle 0.8830 (0.9179) kd_loss 0.9794 (0.9428) acc 68.7500 (72.6823) lr 6.9098e-04 eta 0:10:54
epoch [32/50] batch [140/403] time 0.086 (0.086) data 0.000 (0.004) loss 1.8627 (1.8015) teacher_loss 0.8961 (0.7710) loss_zs_kd 1.8561 (1.8465) loss_oracle 0.8567 (0.9144) kd_loss 0.8810 (0.9390) acc 75.0000 (73.1920) lr 6.9098e-04 eta 0:10:42
epoch [32/50] batch [160/403] time 0.089 (0.086) data 0.000 (0.003) loss 1.8536 (1.8008) teacher_loss 0.8326 (0.7741) loss_zs_kd 1.9600 (1.8447) loss_oracle 0.8640 (0.9108) kd_loss 0.9346 (0.9356) acc 84.3750 (73.2422) lr 6.9098e-04 eta 0:10:42
epoch [32/50] batch [180/403] time 0.074 (0.085) data 0.000 (0.003) loss 1.6374 (1.8001) teacher_loss 0.6369 (0.7763) loss_zs_kd 1.4921 (1.8368) loss_oracle 0.9211 (0.9086) kd_loss 0.9083 (0.9329) acc 84.3750 (73.1076) lr 6.9098e-04 eta 0:10:38
epoch [32/50] batch [200/403] time 0.078 (0.085) data 0.000 (0.003) loss 1.5162 (1.8009) teacher_loss 0.5459 (0.7780) loss_zs_kd 1.8405 (1.8449) loss_oracle 0.9016 (0.9069) kd_loss 0.8801 (0.9322) acc 84.3750 (72.9375) lr 6.9098e-04 eta 0:10:33
epoch [32/50] batch [220/403] time 0.077 (0.084) data 0.000 (0.003) loss 1.6947 (1.7948) teacher_loss 0.7258 (0.7727) loss_zs_kd 1.9767 (1.8493) loss_oracle 0.9360 (0.9065) kd_loss 0.8753 (0.9315) acc 78.1250 (73.1960) lr 6.9098e-04 eta 0:10:26
epoch [32/50] batch [240/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.5796 (1.7975) teacher_loss 0.6860 (0.7758) loss_zs_kd 1.7461 (1.8509) loss_oracle 0.8620 (0.9043) kd_loss 0.8074 (0.9313) acc 75.0000 (73.1771) lr 6.9098e-04 eta 0:10:21
epoch [32/50] batch [260/403] time 0.088 (0.083) data 0.000 (0.002) loss 1.8686 (1.8032) teacher_loss 0.8034 (0.7799) loss_zs_kd 1.8357 (1.8605) loss_oracle 0.9689 (0.9035) kd_loss 0.9683 (0.9330) acc 65.6250 (72.9688) lr 6.9098e-04 eta 0:10:16
epoch [32/50] batch [280/403] time 0.084 (0.083) data 0.000 (0.002) loss 2.0265 (1.7995) teacher_loss 0.9978 (0.7766) loss_zs_kd 1.9241 (1.8634) loss_oracle 0.8793 (0.9032) kd_loss 0.9408 (0.9326) acc 75.0000 (73.0915) lr 6.9098e-04 eta 0:10:11
epoch [32/50] batch [300/403] time 0.087 (0.083) data 0.000 (0.002) loss 2.0283 (1.7919) teacher_loss 0.8626 (0.7708) loss_zs_kd 2.0531 (1.8679) loss_oracle 0.8666 (0.9021) kd_loss 1.0791 (0.9309) acc 68.7500 (73.2708) lr 6.9098e-04 eta 0:10:08
epoch [32/50] batch [320/403] time 0.080 (0.084) data 0.000 (0.002) loss 2.0227 (1.7914) teacher_loss 1.0733 (0.7708) loss_zs_kd 1.6306 (1.8670) loss_oracle 0.9241 (0.9013) kd_loss 0.8570 (0.9305) acc 62.5000 (73.2031) lr 6.9098e-04 eta 0:10:14
epoch [32/50] batch [340/403] time 0.077 (0.083) data 0.000 (0.002) loss 1.8710 (1.7913) teacher_loss 0.8459 (0.7709) loss_zs_kd 1.5658 (1.8645) loss_oracle 0.8645 (0.9016) kd_loss 0.9386 (0.9302) acc 78.1250 (73.3088) lr 6.9098e-04 eta 0:10:10
epoch [32/50] batch [360/403] time 0.073 (0.083) data 0.000 (0.002) loss 1.7961 (1.7899) teacher_loss 0.6840 (0.7704) loss_zs_kd 1.9227 (1.8640) loss_oracle 0.9475 (0.9006) kd_loss 1.0174 (0.9295) acc 81.2500 (73.4549) lr 6.9098e-04 eta 0:10:08
epoch [32/50] batch [380/403] time 0.081 (0.083) data 0.000 (0.002) loss 1.8534 (1.7936) teacher_loss 0.8445 (0.7743) loss_zs_kd 1.6239 (1.8653) loss_oracle 0.9556 (0.9002) kd_loss 0.9134 (0.9292) acc 71.8750 (73.3553) lr 6.9098e-04 eta 0:10:05
epoch [32/50] batch [400/403] time 0.074 (0.083) data 0.000 (0.002) loss 1.8640 (1.7898) teacher_loss 0.8469 (0.7722) loss_zs_kd 2.2379 (1.8678) loss_oracle 0.9243 (0.8996) kd_loss 0.9246 (0.9277) acc 81.2500 (73.5469) lr 6.9098e-04 eta 0:10:03
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,979
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 58.3%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,349
* accuracy: 39.9%
* error: 60.1%
* macro_f1: 30.6%
******* Domain 4 best val acc:      71.9%, epoch: 32 *******
******* Domain 4 best val test acc: 39.9%, epoch: 32 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [33/50] batch [20/403] time 0.080 (0.121) data 0.000 (0.032) loss 2.0058 (1.8020) teacher_loss 1.0078 (0.8252) loss_zs_kd 1.8231 (1.8277) loss_oracle 0.8470 (0.8976) kd_loss 0.9133 (0.8871) acc 78.1250 (73.2812) lr 6.3188e-04 eta 0:14:32
epoch [33/50] batch [40/403] time 0.087 (0.101) data 0.000 (0.016) loss 1.7360 (1.7784) teacher_loss 0.6605 (0.7838) loss_zs_kd 2.2057 (1.8887) loss_oracle 0.8799 (0.9026) kd_loss 0.9876 (0.9043) acc 71.8750 (73.6719) lr 6.3188e-04 eta 0:12:11
epoch [33/50] batch [60/403] time 0.079 (0.102) data 0.000 (0.011) loss 1.4785 (1.7586) teacher_loss 0.6265 (0.7714) loss_zs_kd 1.5491 (1.8877) loss_oracle 0.8749 (0.8925) kd_loss 0.7645 (0.8980) acc 81.2500 (73.5417) lr 6.3188e-04 eta 0:12:10
epoch [33/50] batch [80/403] time 0.084 (0.096) data 0.000 (0.008) loss 1.6768 (1.7685) teacher_loss 0.6741 (0.7782) loss_zs_kd 2.1555 (1.8854) loss_oracle 0.8921 (0.8889) kd_loss 0.9135 (0.9015) acc 68.7500 (73.5938) lr 6.3188e-04 eta 0:11:30
epoch [33/50] batch [100/403] time 0.096 (0.094) data 0.000 (0.007) loss 2.1594 (1.7698) teacher_loss 1.1878 (0.7767) loss_zs_kd 2.3329 (1.8824) loss_oracle 0.8458 (0.8879) kd_loss 0.8870 (0.9043) acc 62.5000 (73.3750) lr 6.3188e-04 eta 0:11:10
epoch [33/50] batch [120/403] time 0.084 (0.092) data 0.000 (0.006) loss 1.8366 (1.7684) teacher_loss 0.7598 (0.7755) loss_zs_kd 1.8902 (1.8688) loss_oracle 0.8444 (0.8896) kd_loss 0.9923 (0.9040) acc 68.7500 (73.4115) lr 6.3188e-04 eta 0:10:59
epoch [33/50] batch [140/403] time 0.081 (0.091) data 0.000 (0.005) loss 1.3295 (1.7547) teacher_loss 0.3625 (0.7649) loss_zs_kd 1.4962 (1.8637) loss_oracle 0.8846 (0.8896) kd_loss 0.8786 (0.9008) acc 93.7500 (73.7277) lr 6.3188e-04 eta 0:10:50
epoch [33/50] batch [160/403] time 0.078 (0.090) data 0.000 (0.004) loss 1.6752 (1.7701) teacher_loss 0.7624 (0.7795) loss_zs_kd 1.6683 (1.8517) loss_oracle 0.9419 (0.8897) kd_loss 0.8186 (0.9016) acc 75.0000 (73.1445) lr 6.3188e-04 eta 0:10:41
epoch [33/50] batch [180/403] time 0.081 (0.089) data 0.000 (0.004) loss 1.9358 (1.7726) teacher_loss 0.9056 (0.7799) loss_zs_kd 2.2029 (1.8498) loss_oracle 0.8974 (0.8913) kd_loss 0.9404 (0.9036) acc 68.7500 (73.1771) lr 6.3188e-04 eta 0:10:33
epoch [33/50] batch [200/403] time 0.076 (0.089) data 0.000 (0.003) loss 1.6278 (1.7737) teacher_loss 0.6941 (0.7789) loss_zs_kd 1.8847 (1.8390) loss_oracle 0.8568 (0.8943) kd_loss 0.8480 (0.9054) acc 78.1250 (73.1094) lr 6.3188e-04 eta 0:10:26
epoch [33/50] batch [220/403] time 0.085 (0.088) data 0.000 (0.003) loss 1.9240 (1.7793) teacher_loss 0.8802 (0.7837) loss_zs_kd 1.7585 (1.8370) loss_oracle 0.9608 (0.8962) kd_loss 0.9478 (0.9059) acc 71.8750 (72.9261) lr 6.3188e-04 eta 0:10:19
epoch [33/50] batch [240/403] time 0.076 (0.088) data 0.000 (0.003) loss 1.7911 (1.7771) teacher_loss 0.6508 (0.7811) loss_zs_kd 1.7940 (1.8293) loss_oracle 0.9472 (0.8970) kd_loss 1.0456 (0.9063) acc 81.2500 (72.9948) lr 6.3188e-04 eta 0:10:17
epoch [33/50] batch [260/403] time 0.080 (0.088) data 0.000 (0.003) loss 1.6708 (1.7758) teacher_loss 0.6326 (0.7807) loss_zs_kd 1.4373 (1.8265) loss_oracle 0.9260 (0.8989) kd_loss 0.9455 (0.9052) acc 84.3750 (73.1851) lr 6.3188e-04 eta 0:10:12
epoch [33/50] batch [280/403] time 0.067 (0.087) data 0.000 (0.003) loss 1.9259 (1.7791) teacher_loss 0.9567 (0.7851) loss_zs_kd 1.9044 (1.8288) loss_oracle 0.8488 (0.8976) kd_loss 0.8843 (0.9043) acc 65.6250 (73.0469) lr 6.3188e-04 eta 0:10:04
epoch [33/50] batch [300/403] time 0.070 (0.086) data 0.000 (0.002) loss 1.4303 (1.7800) teacher_loss 0.4682 (0.7868) loss_zs_kd 2.1211 (1.8290) loss_oracle 0.9004 (0.8976) kd_loss 0.8721 (0.9035) acc 81.2500 (72.8125) lr 6.3188e-04 eta 0:09:55
epoch [33/50] batch [320/403] time 0.066 (0.085) data 0.000 (0.002) loss 1.9134 (1.7796) teacher_loss 0.8504 (0.7855) loss_zs_kd 1.5971 (1.8206) loss_oracle 0.9449 (0.8975) kd_loss 0.9685 (0.9043) acc 68.7500 (72.7051) lr 6.3188e-04 eta 0:09:47
epoch [33/50] batch [340/403] time 0.068 (0.084) data 0.000 (0.002) loss 1.4556 (1.7800) teacher_loss 0.4825 (0.7854) loss_zs_kd 1.7304 (1.8163) loss_oracle 0.8481 (0.8981) kd_loss 0.8883 (0.9048) acc 84.3750 (72.7206) lr 6.3188e-04 eta 0:09:40
epoch [33/50] batch [360/403] time 0.062 (0.083) data 0.000 (0.002) loss 1.8851 (1.7834) teacher_loss 0.8118 (0.7889) loss_zs_kd 1.7471 (1.8124) loss_oracle 0.8727 (0.8992) kd_loss 0.9860 (0.9045) acc 75.0000 (72.6128) lr 6.3188e-04 eta 0:09:31
epoch [33/50] batch [380/403] time 0.059 (0.082) data 0.000 (0.002) loss 1.4721 (1.7845) teacher_loss 0.4755 (0.7896) loss_zs_kd 2.0847 (1.8162) loss_oracle 0.9495 (0.8995) kd_loss 0.9017 (0.9049) acc 84.3750 (72.7385) lr 6.3188e-04 eta 0:09:22
epoch [33/50] batch [400/403] time 0.078 (0.081) data 0.000 (0.002) loss 1.5761 (1.7821) teacher_loss 0.6002 (0.7865) loss_zs_kd 1.5997 (1.8162) loss_oracle 0.8990 (0.9007) kd_loss 0.8860 (0.9055) acc 75.0000 (72.8281) lr 6.3188e-04 eta 0:09:16
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,965
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 57.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,419
* accuracy: 41.1%
* error: 58.9%
* macro_f1: 31.2%
******* Domain 4 best val acc:      71.9%, epoch: 32 *******
******* Domain 4 best val test acc: 39.9%, epoch: 32 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [34/50] batch [20/403] time 0.070 (0.093) data 0.000 (0.026) loss 1.6678 (1.7996) teacher_loss 0.6537 (0.7841) loss_zs_kd 1.7632 (1.9197) loss_oracle 0.8912 (0.9105) kd_loss 0.9250 (0.9244) acc 75.0000 (71.8750) lr 5.7422e-04 eta 0:10:36
epoch [34/50] batch [40/403] time 0.064 (0.079) data 0.000 (0.013) loss 1.8752 (1.7884) teacher_loss 0.8271 (0.7827) loss_zs_kd 2.2630 (1.9580) loss_oracle 0.9756 (0.9192) kd_loss 0.9506 (0.9138) acc 75.0000 (72.9688) lr 5.7422e-04 eta 0:08:55
epoch [34/50] batch [60/403] time 0.061 (0.074) data 0.001 (0.009) loss 1.7105 (1.7707) teacher_loss 0.6960 (0.7655) loss_zs_kd 1.4691 (1.9070) loss_oracle 0.8671 (0.9161) kd_loss 0.9278 (0.9135) acc 71.8750 (73.4375) lr 5.7422e-04 eta 0:08:19
epoch [34/50] batch [80/403] time 0.065 (0.070) data 0.000 (0.007) loss 2.0202 (1.7771) teacher_loss 1.0194 (0.7726) loss_zs_kd 1.9275 (1.9190) loss_oracle 0.8661 (0.9144) kd_loss 0.9142 (0.9131) acc 75.0000 (73.6328) lr 5.7422e-04 eta 0:07:56
epoch [34/50] batch [100/403] time 0.063 (0.069) data 0.000 (0.005) loss 1.5904 (1.7832) teacher_loss 0.6279 (0.7748) loss_zs_kd 1.5402 (1.9087) loss_oracle 0.9176 (0.9137) kd_loss 0.8707 (0.9171) acc 84.3750 (73.4375) lr 5.7422e-04 eta 0:07:45
epoch [34/50] batch [120/403] time 0.087 (0.071) data 0.000 (0.005) loss 1.9604 (1.7911) teacher_loss 0.8664 (0.7800) loss_zs_kd 2.2609 (1.8833) loss_oracle 1.0019 (0.9172) kd_loss 0.9938 (0.9194) acc 71.8750 (73.2552) lr 5.7422e-04 eta 0:07:57
epoch [34/50] batch [140/403] time 0.073 (0.072) data 0.000 (0.004) loss 1.6571 (1.7855) teacher_loss 0.6595 (0.7738) loss_zs_kd 1.7983 (1.8879) loss_oracle 0.9066 (0.9181) kd_loss 0.9069 (0.9199) acc 75.0000 (73.3929) lr 5.7422e-04 eta 0:08:02
epoch [34/50] batch [160/403] time 0.080 (0.073) data 0.000 (0.003) loss 1.8823 (1.7878) teacher_loss 0.8380 (0.7743) loss_zs_kd 1.7295 (1.8957) loss_oracle 0.9090 (0.9172) kd_loss 0.9534 (0.9218) acc 71.8750 (73.3789) lr 5.7422e-04 eta 0:08:09
epoch [34/50] batch [180/403] time 0.084 (0.074) data 0.000 (0.003) loss 2.0458 (1.7835) teacher_loss 1.0151 (0.7706) loss_zs_kd 2.2533 (1.8977) loss_oracle 0.9815 (0.9151) kd_loss 0.9326 (0.9214) acc 65.6250 (73.4375) lr 5.7422e-04 eta 0:08:16
epoch [34/50] batch [200/403] time 0.086 (0.076) data 0.000 (0.003) loss 1.4283 (1.7770) teacher_loss 0.5402 (0.7649) loss_zs_kd 1.6477 (1.9000) loss_oracle 0.8623 (0.9143) kd_loss 0.8018 (0.9207) acc 75.0000 (73.8281) lr 5.7422e-04 eta 0:08:22
epoch [34/50] batch [220/403] time 0.090 (0.076) data 0.000 (0.003) loss 1.8531 (1.7840) teacher_loss 0.8169 (0.7709) loss_zs_kd 2.1629 (1.8974) loss_oracle 0.9908 (0.9145) kd_loss 0.9371 (0.9217) acc 65.6250 (73.5938) lr 5.7422e-04 eta 0:08:26
epoch [34/50] batch [240/403] time 0.083 (0.077) data 0.000 (0.002) loss 2.0837 (1.7857) teacher_loss 1.1268 (0.7721) loss_zs_kd 1.8687 (1.8894) loss_oracle 0.8790 (0.9125) kd_loss 0.8690 (0.9224) acc 50.0000 (73.4766) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [260/403] time 0.087 (0.079) data 0.000 (0.002) loss 1.7458 (1.7890) teacher_loss 0.7400 (0.7761) loss_zs_kd 1.7276 (1.8813) loss_oracle 0.9179 (0.9132) kd_loss 0.9139 (0.9215) acc 78.1250 (73.3293) lr 5.7422e-04 eta 0:08:39
epoch [34/50] batch [280/403] time 0.073 (0.078) data 0.000 (0.002) loss 1.7225 (1.7864) teacher_loss 0.7645 (0.7739) loss_zs_kd 1.7523 (1.8710) loss_oracle 0.9503 (0.9133) kd_loss 0.8630 (0.9212) acc 71.8750 (73.5379) lr 5.7422e-04 eta 0:08:35
epoch [34/50] batch [300/403] time 0.087 (0.079) data 0.000 (0.002) loss 1.8454 (1.7864) teacher_loss 0.8915 (0.7755) loss_zs_kd 1.5682 (1.8670) loss_oracle 0.9104 (0.9126) kd_loss 0.8628 (0.9196) acc 68.7500 (73.5104) lr 5.7422e-04 eta 0:08:35
epoch [34/50] batch [320/403] time 0.073 (0.079) data 0.000 (0.002) loss 1.7255 (1.7835) teacher_loss 0.6480 (0.7728) loss_zs_kd 1.7606 (1.8611) loss_oracle 0.9456 (0.9123) kd_loss 0.9829 (0.9195) acc 75.0000 (73.6230) lr 5.7422e-04 eta 0:08:36
epoch [34/50] batch [340/403] time 0.090 (0.079) data 0.001 (0.002) loss 2.0517 (1.7876) teacher_loss 1.0709 (0.7769) loss_zs_kd 1.6683 (1.8544) loss_oracle 0.8405 (0.9125) kd_loss 0.8967 (0.9195) acc 65.6250 (73.4926) lr 5.7422e-04 eta 0:08:35
epoch [34/50] batch [360/403] time 0.091 (0.080) data 0.000 (0.002) loss 1.6253 (1.7857) teacher_loss 0.5626 (0.7735) loss_zs_kd 1.9734 (1.8578) loss_oracle 0.9681 (0.9126) kd_loss 0.9659 (0.9209) acc 84.3750 (73.5851) lr 5.7422e-04 eta 0:08:36
epoch [34/50] batch [380/403] time 0.085 (0.080) data 0.000 (0.002) loss 1.8734 (1.7865) teacher_loss 0.9384 (0.7726) loss_zs_kd 1.6658 (1.8567) loss_oracle 0.9194 (0.9124) kd_loss 0.8431 (0.9227) acc 68.7500 (73.6678) lr 5.7422e-04 eta 0:08:36
epoch [34/50] batch [400/403] time 0.075 (0.080) data 0.000 (0.002) loss 1.6239 (1.7844) teacher_loss 0.5618 (0.7707) loss_zs_kd 1.8157 (1.8580) loss_oracle 0.8940 (0.9112) kd_loss 0.9727 (0.9226) acc 78.1250 (73.7109) lr 5.7422e-04 eta 0:08:35
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,983
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 58.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,387
* accuracy: 40.6%
* error: 59.4%
* macro_f1: 29.9%
******* Domain 4 best val acc:      72.0%, epoch: 34 *******
******* Domain 4 best val test acc: 40.6%, epoch: 34 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [35/50] batch [20/403] time 0.081 (0.114) data 0.000 (0.030) loss 1.7176 (1.7860) teacher_loss 0.6534 (0.7449) loss_zs_kd 2.0468 (1.9230) loss_oracle 0.8716 (0.9002) kd_loss 0.9770 (0.9511) acc 75.0000 (71.4062) lr 5.1825e-04 eta 0:12:13
epoch [35/50] batch [40/403] time 0.072 (0.094) data 0.000 (0.015) loss 1.3509 (1.7949) teacher_loss 0.4743 (0.7641) loss_zs_kd 1.4381 (1.8778) loss_oracle 0.8294 (0.8971) kd_loss 0.7936 (0.9411) acc 87.5000 (72.6562) lr 5.1825e-04 eta 0:10:03
epoch [35/50] batch [60/403] time 0.088 (0.088) data 0.001 (0.010) loss 1.5626 (1.8051) teacher_loss 0.5500 (0.7743) loss_zs_kd 1.4392 (1.8674) loss_oracle 0.8882 (0.8974) kd_loss 0.9237 (0.9411) acc 81.2500 (72.5000) lr 5.1825e-04 eta 0:09:22
epoch [35/50] batch [80/403] time 0.088 (0.086) data 0.000 (0.008) loss 2.2332 (1.7918) teacher_loss 1.2966 (0.7668) loss_zs_kd 1.8863 (1.8798) loss_oracle 0.9016 (0.9000) kd_loss 0.8464 (0.9350) acc 59.3750 (73.3594) lr 5.1825e-04 eta 0:09:08
epoch [35/50] batch [100/403] time 0.081 (0.085) data 0.000 (0.006) loss 1.9103 (1.8054) teacher_loss 0.8758 (0.7846) loss_zs_kd 1.8633 (1.8789) loss_oracle 0.8457 (0.8963) kd_loss 0.9499 (0.9312) acc 75.0000 (72.9688) lr 5.1825e-04 eta 0:08:58
epoch [35/50] batch [120/403] time 0.078 (0.084) data 0.000 (0.005) loss 2.2143 (1.8036) teacher_loss 1.1289 (0.7887) loss_zs_kd 2.1823 (1.8989) loss_oracle 0.9377 (0.8960) kd_loss 0.9916 (0.9253) acc 68.7500 (72.9427) lr 5.1825e-04 eta 0:08:50
epoch [35/50] batch [140/403] time 0.098 (0.083) data 0.000 (0.005) loss 1.6297 (1.8022) teacher_loss 0.7518 (0.7897) loss_zs_kd 1.6833 (1.8756) loss_oracle 0.8928 (0.8967) kd_loss 0.7886 (0.9228) acc 75.0000 (73.0134) lr 5.1825e-04 eta 0:08:46
epoch [35/50] batch [160/403] time 0.082 (0.083) data 0.000 (0.004) loss 1.9335 (1.7981) teacher_loss 0.9698 (0.7871) loss_zs_kd 1.8676 (1.8688) loss_oracle 0.8028 (0.8964) kd_loss 0.8834 (0.9213) acc 71.8750 (72.9492) lr 5.1825e-04 eta 0:08:40
epoch [35/50] batch [180/403] time 0.081 (0.083) data 0.000 (0.004) loss 1.7192 (1.7899) teacher_loss 0.6734 (0.7800) loss_zs_kd 2.1132 (1.8714) loss_oracle 0.8908 (0.8952) kd_loss 0.9567 (0.9204) acc 78.1250 (73.1076) lr 5.1825e-04 eta 0:08:40
epoch [35/50] batch [200/403] time 0.081 (0.083) data 0.000 (0.003) loss 1.9756 (1.7835) teacher_loss 0.9845 (0.7741) loss_zs_kd 1.8711 (1.8798) loss_oracle 0.9050 (0.8943) kd_loss 0.9007 (0.9199) acc 62.5000 (73.1406) lr 5.1825e-04 eta 0:08:39
epoch [35/50] batch [220/403] time 0.094 (0.083) data 0.001 (0.003) loss 1.5134 (1.7840) teacher_loss 0.5645 (0.7731) loss_zs_kd 1.5392 (1.8861) loss_oracle 0.8714 (0.8947) kd_loss 0.8618 (0.9214) acc 75.0000 (73.1818) lr 5.1825e-04 eta 0:08:38
epoch [35/50] batch [240/403] time 0.072 (0.083) data 0.000 (0.003) loss 1.9577 (1.7839) teacher_loss 1.0046 (0.7735) loss_zs_kd 1.9300 (1.8750) loss_oracle 0.9726 (0.8948) kd_loss 0.8558 (0.9209) acc 62.5000 (73.0729) lr 5.1825e-04 eta 0:08:37
epoch [35/50] batch [260/403] time 0.073 (0.083) data 0.000 (0.003) loss 1.5178 (1.7913) teacher_loss 0.5580 (0.7807) loss_zs_kd 1.7046 (1.8711) loss_oracle 0.9408 (0.8960) kd_loss 0.8657 (0.9211) acc 81.2500 (72.8005) lr 5.1825e-04 eta 0:08:33
epoch [35/50] batch [280/403] time 0.086 (0.083) data 0.000 (0.002) loss 1.6797 (1.7949) teacher_loss 0.6962 (0.7843) loss_zs_kd 1.7284 (1.8689) loss_oracle 0.8487 (0.8972) kd_loss 0.8986 (0.9208) acc 75.0000 (72.6228) lr 5.1825e-04 eta 0:08:31
epoch [35/50] batch [300/403] time 0.080 (0.083) data 0.000 (0.002) loss 1.8767 (1.7942) teacher_loss 0.8414 (0.7837) loss_zs_kd 1.9220 (1.8693) loss_oracle 0.9117 (0.8973) kd_loss 0.9442 (0.9208) acc 71.8750 (72.6979) lr 5.1825e-04 eta 0:08:30
epoch [35/50] batch [320/403] time 0.088 (0.083) data 0.000 (0.002) loss 1.7476 (1.7948) teacher_loss 0.7492 (0.7839) loss_zs_kd 1.9447 (1.8692) loss_oracle 0.9208 (0.8979) kd_loss 0.9063 (0.9211) acc 78.1250 (72.7930) lr 5.1825e-04 eta 0:08:29
epoch [35/50] batch [340/403] time 0.081 (0.083) data 0.000 (0.002) loss 1.6398 (1.7937) teacher_loss 0.6843 (0.7830) loss_zs_kd 2.1067 (1.8675) loss_oracle 0.8514 (0.8989) kd_loss 0.8704 (0.9208) acc 78.1250 (72.8676) lr 5.1825e-04 eta 0:08:28
epoch [35/50] batch [360/403] time 0.089 (0.083) data 0.000 (0.002) loss 1.7631 (1.7959) teacher_loss 0.8015 (0.7849) loss_zs_kd 1.6310 (1.8743) loss_oracle 0.9384 (0.8993) kd_loss 0.8678 (0.9210) acc 68.7500 (72.8212) lr 5.1825e-04 eta 0:08:25
epoch [35/50] batch [380/403] time 0.064 (0.083) data 0.000 (0.002) loss 2.1799 (1.7998) teacher_loss 1.0338 (0.7880) loss_zs_kd 2.2454 (1.8786) loss_oracle 0.9281 (0.9006) kd_loss 1.0532 (0.9217) acc 65.6250 (72.7467) lr 5.1825e-04 eta 0:08:23
epoch [35/50] batch [400/403] time 0.077 (0.083) data 0.000 (0.002) loss 1.8566 (1.8044) teacher_loss 0.8070 (0.7921) loss_zs_kd 1.4342 (1.8700) loss_oracle 0.8827 (0.9015) kd_loss 0.9613 (0.9222) acc 71.8750 (72.6250) lr 5.1825e-04 eta 0:08:23
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,019
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 59.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,445
* accuracy: 41.6%
* error: 58.4%
* macro_f1: 31.1%
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     41.9%, epoch: 29 *******
epoch [36/50] batch [20/403] time 0.094 (0.112) data 0.000 (0.024) loss 1.5788 (1.8565) teacher_loss 0.6328 (0.8462) loss_zs_kd 2.0877 (1.7324) loss_oracle 0.8896 (0.9225) kd_loss 0.8571 (0.9180) acc 81.2500 (69.2188) lr 4.6417e-04 eta 0:11:12
epoch [36/50] batch [40/403] time 0.083 (0.096) data 0.000 (0.012) loss 2.3396 (1.8570) teacher_loss 1.3387 (0.8423) loss_zs_kd 1.9879 (1.7969) loss_oracle 0.9519 (0.9216) kd_loss 0.9056 (0.9225) acc 53.1250 (69.3750) lr 4.6417e-04 eta 0:09:36
epoch [36/50] batch [60/403] time 0.091 (0.090) data 0.000 (0.008) loss 1.9185 (1.8325) teacher_loss 0.8605 (0.8189) loss_zs_kd 1.8744 (1.8006) loss_oracle 0.8298 (0.9176) kd_loss 0.9750 (0.9219) acc 71.8750 (69.9479) lr 4.6417e-04 eta 0:08:58
epoch [36/50] batch [80/403] time 0.090 (0.089) data 0.000 (0.006) loss 1.7312 (1.8121) teacher_loss 0.7380 (0.8023) loss_zs_kd 2.1879 (1.8009) loss_oracle 0.8833 (0.9138) kd_loss 0.9049 (0.9185) acc 68.7500 (70.7812) lr 4.6417e-04 eta 0:08:51
epoch [36/50] batch [100/403] time 0.087 (0.088) data 0.000 (0.005) loss 1.6344 (1.8127) teacher_loss 0.6768 (0.8039) loss_zs_kd 1.8541 (1.8136) loss_oracle 0.8675 (0.9121) kd_loss 0.8709 (0.9177) acc 75.0000 (70.7500) lr 4.6417e-04 eta 0:08:43
epoch [36/50] batch [120/403] time 0.081 (0.087) data 0.000 (0.004) loss 1.2750 (1.8184) teacher_loss 0.2860 (0.8134) loss_zs_kd 1.5944 (1.8273) loss_oracle 0.8655 (0.9106) kd_loss 0.9024 (0.9139) acc 90.6250 (70.9635) lr 4.6417e-04 eta 0:08:34
epoch [36/50] batch [140/403] time 0.075 (0.088) data 0.000 (0.004) loss 1.5919 (1.8096) teacher_loss 0.6020 (0.8034) loss_zs_kd 2.1853 (1.8404) loss_oracle 0.9380 (0.9101) kd_loss 0.8961 (0.9152) acc 81.2500 (71.3170) lr 4.6417e-04 eta 0:08:42
epoch [36/50] batch [160/403] time 0.083 (0.088) data 0.000 (0.003) loss 1.7001 (1.8070) teacher_loss 0.6674 (0.8034) loss_zs_kd 1.6638 (1.8340) loss_oracle 0.8844 (0.9072) kd_loss 0.9442 (0.9128) acc 71.8750 (71.6016) lr 4.6417e-04 eta 0:08:36
epoch [36/50] batch [180/403] time 0.089 (0.088) data 0.000 (0.003) loss 1.7880 (1.8076) teacher_loss 0.7991 (0.8028) loss_zs_kd 1.5731 (1.8410) loss_oracle 0.8930 (0.9085) kd_loss 0.8996 (0.9139) acc 75.0000 (71.6840) lr 4.6417e-04 eta 0:08:34
epoch [36/50] batch [200/403] time 0.084 (0.087) data 0.000 (0.003) loss 1.6837 (1.8045) teacher_loss 0.7767 (0.7964) loss_zs_kd 1.6170 (1.8529) loss_oracle 0.9492 (0.9085) kd_loss 0.8121 (0.9172) acc 62.5000 (71.8750) lr 4.6417e-04 eta 0:08:30
epoch [36/50] batch [220/403] time 0.082 (0.087) data 0.000 (0.002) loss 1.5286 (1.7983) teacher_loss 0.5329 (0.7884) loss_zs_kd 1.9396 (1.8642) loss_oracle 0.8983 (0.9090) kd_loss 0.9058 (0.9190) acc 75.0000 (72.1449) lr 4.6417e-04 eta 0:08:28
epoch [36/50] batch [240/403] time 0.079 (0.087) data 0.000 (0.002) loss 1.6722 (1.7965) teacher_loss 0.7756 (0.7867) loss_zs_kd 1.9894 (1.8758) loss_oracle 0.8473 (0.9087) kd_loss 0.8119 (0.9190) acc 81.2500 (72.2396) lr 4.6417e-04 eta 0:08:26
epoch [36/50] batch [260/403] time 0.082 (0.087) data 0.000 (0.002) loss 1.6990 (1.7931) teacher_loss 0.6576 (0.7835) loss_zs_kd 1.7679 (1.8678) loss_oracle 0.8888 (0.9082) kd_loss 0.9526 (0.9188) acc 71.8750 (72.2476) lr 4.6417e-04 eta 0:08:24
epoch [36/50] batch [280/403] time 0.080 (0.087) data 0.000 (0.002) loss 1.9401 (1.7945) teacher_loss 0.9277 (0.7843) loss_zs_kd 2.2059 (1.8686) loss_oracle 0.9407 (0.9084) kd_loss 0.9183 (0.9194) acc 71.8750 (72.2545) lr 4.6417e-04 eta 0:08:22
epoch [36/50] batch [300/403] time 0.085 (0.087) data 0.000 (0.002) loss 1.6708 (1.7932) teacher_loss 0.6565 (0.7835) loss_zs_kd 1.5806 (1.8629) loss_oracle 0.9553 (0.9076) kd_loss 0.9188 (0.9190) acc 81.2500 (72.2917) lr 4.6417e-04 eta 0:08:18
epoch [36/50] batch [320/403] time 0.079 (0.086) data 0.000 (0.002) loss 1.7867 (1.7962) teacher_loss 0.6463 (0.7858) loss_zs_kd 1.6751 (1.8617) loss_oracle 0.9282 (0.9073) kd_loss 1.0477 (0.9197) acc 75.0000 (72.2559) lr 4.6417e-04 eta 0:08:14
epoch [36/50] batch [340/403] time 0.080 (0.086) data 0.000 (0.002) loss 1.6826 (1.7938) teacher_loss 0.7320 (0.7857) loss_zs_kd 1.5000 (1.8604) loss_oracle 0.8555 (0.9059) kd_loss 0.8650 (0.9175) acc 78.1250 (72.4908) lr 4.6417e-04 eta 0:08:12
epoch [36/50] batch [360/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.6055 (1.7907) teacher_loss 0.6349 (0.7844) loss_zs_kd 2.1604 (1.8608) loss_oracle 0.8927 (0.9053) kd_loss 0.8813 (0.9158) acc 75.0000 (72.5000) lr 4.6417e-04 eta 0:08:10
epoch [36/50] batch [380/403] time 0.082 (0.086) data 0.000 (0.002) loss 1.5553 (1.7879) teacher_loss 0.5743 (0.7828) loss_zs_kd 2.2343 (1.8625) loss_oracle 0.9878 (0.9046) kd_loss 0.8822 (0.9146) acc 81.2500 (72.5329) lr 4.6417e-04 eta 0:08:06
epoch [36/50] batch [400/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.3731 (1.7873) teacher_loss 0.4419 (0.7819) loss_zs_kd 1.9322 (1.8638) loss_oracle 0.8735 (0.9040) kd_loss 0.8438 (0.9150) acc 84.3750 (72.6250) lr 4.6417e-04 eta 0:08:03
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,986
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 58.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,508
* accuracy: 42.6%
* error: 57.4%
* macro_f1: 31.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     42.6%, epoch: 36 *******
epoch [37/50] batch [20/403] time 0.079 (0.109) data 0.000 (0.030) loss 1.6360 (1.8047) teacher_loss 0.7285 (0.8062) loss_zs_kd 1.8794 (1.9016) loss_oracle 0.8326 (0.9078) kd_loss 0.8243 (0.9077) acc 75.0000 (72.1875) lr 4.1221e-04 eta 0:10:10
epoch [37/50] batch [40/403] time 0.082 (0.098) data 0.000 (0.015) loss 1.8241 (1.7968) teacher_loss 0.9369 (0.7949) loss_zs_kd 1.6370 (1.8999) loss_oracle 0.9237 (0.9076) kd_loss 0.7948 (0.9111) acc 71.8750 (72.3438) lr 4.1221e-04 eta 0:09:08
epoch [37/50] batch [60/403] time 0.089 (0.095) data 0.001 (0.010) loss 1.5266 (1.7942) teacher_loss 0.5838 (0.7942) loss_zs_kd 2.3825 (1.9317) loss_oracle 0.8214 (0.8981) kd_loss 0.8606 (0.9102) acc 75.0000 (72.6042) lr 4.1221e-04 eta 0:08:48
epoch [37/50] batch [80/403] time 0.074 (0.092) data 0.000 (0.008) loss 1.8283 (1.7983) teacher_loss 0.8682 (0.7972) loss_zs_kd 1.7313 (1.9408) loss_oracle 0.8296 (0.8978) kd_loss 0.8771 (0.9113) acc 65.6250 (72.3438) lr 4.1221e-04 eta 0:08:29
epoch [37/50] batch [100/403] time 0.075 (0.090) data 0.000 (0.006) loss 2.0211 (1.7998) teacher_loss 0.9820 (0.7970) loss_zs_kd 2.1850 (1.9179) loss_oracle 0.8972 (0.8937) kd_loss 0.9494 (0.9135) acc 65.6250 (72.4375) lr 4.1221e-04 eta 0:08:16
epoch [37/50] batch [120/403] time 0.084 (0.088) data 0.000 (0.005) loss 1.7000 (1.7909) teacher_loss 0.6337 (0.7863) loss_zs_kd 1.6910 (1.9001) loss_oracle 0.9272 (0.8945) kd_loss 0.9736 (0.9152) acc 75.0000 (73.1510) lr 4.1221e-04 eta 0:08:07
epoch [37/50] batch [140/403] time 0.085 (0.088) data 0.000 (0.005) loss 2.4172 (1.7831) teacher_loss 1.3420 (0.7794) loss_zs_kd 1.6715 (1.9062) loss_oracle 0.8207 (0.8952) kd_loss 0.9931 (0.9142) acc 43.7500 (73.2366) lr 4.1221e-04 eta 0:08:02
epoch [37/50] batch [160/403] time 0.093 (0.087) data 0.000 (0.004) loss 1.8126 (1.7841) teacher_loss 0.8552 (0.7786) loss_zs_kd 1.5886 (1.8929) loss_oracle 0.9006 (0.8944) kd_loss 0.8673 (0.9161) acc 68.7500 (73.3398) lr 4.1221e-04 eta 0:07:59
epoch [37/50] batch [180/403] time 0.082 (0.087) data 0.000 (0.004) loss 1.7680 (1.7880) teacher_loss 0.7550 (0.7816) loss_zs_kd 1.7283 (1.8825) loss_oracle 0.9127 (0.8953) kd_loss 0.9217 (0.9169) acc 71.8750 (73.1944) lr 4.1221e-04 eta 0:07:53
epoch [37/50] batch [200/403] time 0.075 (0.086) data 0.000 (0.003) loss 1.6983 (1.7877) teacher_loss 0.6413 (0.7810) loss_zs_kd 1.8724 (1.8759) loss_oracle 0.9288 (0.8948) kd_loss 0.9641 (0.9173) acc 81.2500 (73.4531) lr 4.1221e-04 eta 0:07:48
epoch [37/50] batch [220/403] time 0.081 (0.086) data 0.000 (0.003) loss 1.7304 (1.7880) teacher_loss 0.7614 (0.7824) loss_zs_kd 1.9597 (1.8719) loss_oracle 0.8976 (0.8959) kd_loss 0.8792 (0.9160) acc 65.6250 (73.2528) lr 4.1221e-04 eta 0:07:46
epoch [37/50] batch [240/403] time 0.081 (0.086) data 0.000 (0.003) loss 1.5556 (1.7818) teacher_loss 0.5727 (0.7776) loss_zs_kd 1.7957 (1.8722) loss_oracle 0.9325 (0.8973) kd_loss 0.8897 (0.9144) acc 81.2500 (73.3984) lr 4.1221e-04 eta 0:07:44
epoch [37/50] batch [260/403] time 0.081 (0.086) data 0.000 (0.003) loss 1.8737 (1.7801) teacher_loss 0.8607 (0.7772) loss_zs_kd 1.6891 (1.8694) loss_oracle 0.9133 (0.8978) kd_loss 0.9216 (0.9131) acc 65.6250 (73.3894) lr 4.1221e-04 eta 0:07:40
epoch [37/50] batch [280/403] time 0.150 (0.087) data 0.001 (0.002) loss 2.1755 (1.7769) teacher_loss 1.2091 (0.7749) loss_zs_kd 1.7105 (1.8693) loss_oracle 0.8996 (0.8976) kd_loss 0.8764 (0.9122) acc 59.3750 (73.3817) lr 4.1221e-04 eta 0:07:45
epoch [37/50] batch [300/403] time 0.086 (0.087) data 0.000 (0.002) loss 1.8364 (1.7767) teacher_loss 0.8772 (0.7728) loss_zs_kd 1.5602 (1.8639) loss_oracle 0.9444 (0.8985) kd_loss 0.8647 (0.9141) acc 65.6250 (73.4271) lr 4.1221e-04 eta 0:07:42
epoch [37/50] batch [320/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.7019 (1.7773) teacher_loss 0.7323 (0.7751) loss_zs_kd 2.2138 (1.8562) loss_oracle 0.9984 (0.8980) kd_loss 0.8698 (0.9124) acc 71.8750 (73.2520) lr 4.1221e-04 eta 0:07:39
epoch [37/50] batch [340/403] time 0.090 (0.086) data 0.000 (0.002) loss 1.6258 (1.7755) teacher_loss 0.6959 (0.7735) loss_zs_kd 1.5177 (1.8537) loss_oracle 0.8864 (0.8985) kd_loss 0.8413 (0.9122) acc 78.1250 (73.1893) lr 4.1221e-04 eta 0:07:37
epoch [37/50] batch [360/403] time 0.085 (0.086) data 0.000 (0.002) loss 1.9567 (1.7753) teacher_loss 0.8307 (0.7715) loss_zs_kd 1.9247 (1.8541) loss_oracle 0.9152 (0.8996) kd_loss 1.0345 (0.9139) acc 71.8750 (73.2205) lr 4.1221e-04 eta 0:07:35
epoch [37/50] batch [380/403] time 0.084 (0.086) data 0.000 (0.002) loss 1.8891 (1.7787) teacher_loss 0.7931 (0.7729) loss_zs_kd 2.2407 (1.8605) loss_oracle 0.8688 (0.8991) kd_loss 1.0091 (0.9159) acc 71.8750 (73.0592) lr 4.1221e-04 eta 0:07:32
epoch [37/50] batch [400/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.8346 (1.7801) teacher_loss 0.7080 (0.7741) loss_zs_kd 2.0200 (1.8614) loss_oracle 0.9276 (0.8996) kd_loss 1.0338 (0.9160) acc 68.7500 (73.0234) lr 4.1221e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,987
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 59.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,461
* accuracy: 41.8%
* error: 58.2%
* macro_f1: 31.0%
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     42.6%, epoch: 36 *******
epoch [38/50] batch [20/403] time 0.077 (0.113) data 0.000 (0.029) loss 1.8665 (1.8529) teacher_loss 0.8303 (0.8197) loss_zs_kd 1.7807 (1.8828) loss_oracle 0.8433 (0.9204) kd_loss 0.9519 (0.9412) acc 78.1250 (72.1875) lr 3.6258e-04 eta 0:09:51
epoch [38/50] batch [40/403] time 0.135 (0.099) data 0.000 (0.015) loss 2.1035 (1.8537) teacher_loss 0.9801 (0.8149) loss_zs_kd 2.0364 (1.9056) loss_oracle 0.8959 (0.9212) kd_loss 1.0337 (0.9466) acc 62.5000 (71.8750) lr 3.6258e-04 eta 0:08:36
epoch [38/50] batch [60/403] time 0.082 (0.100) data 0.001 (0.010) loss 1.5355 (1.8368) teacher_loss 0.4863 (0.7997) loss_zs_kd 1.8715 (1.9010) loss_oracle 0.8605 (0.9079) kd_loss 0.9631 (0.9463) acc 81.2500 (71.5625) lr 3.6258e-04 eta 0:08:36
epoch [38/50] batch [80/403] time 0.080 (0.095) data 0.000 (0.007) loss 1.7728 (1.8296) teacher_loss 0.7616 (0.7902) loss_zs_kd 1.5921 (1.9305) loss_oracle 0.8739 (0.9112) kd_loss 0.9238 (0.9483) acc 78.1250 (72.3047) lr 3.6258e-04 eta 0:08:09
epoch [38/50] batch [100/403] time 0.081 (0.091) data 0.001 (0.006) loss 1.7003 (1.8193) teacher_loss 0.7988 (0.7865) loss_zs_kd 1.8187 (1.8934) loss_oracle 0.9016 (0.9112) kd_loss 0.8113 (0.9417) acc 78.1250 (72.7500) lr 3.6258e-04 eta 0:07:49
epoch [38/50] batch [120/403] time 0.083 (0.089) data 0.000 (0.005) loss 1.8784 (1.8202) teacher_loss 0.9103 (0.7879) loss_zs_kd 1.6107 (1.8816) loss_oracle 0.8829 (0.9081) kd_loss 0.8799 (0.9415) acc 65.6250 (72.4740) lr 3.6258e-04 eta 0:07:37
epoch [38/50] batch [140/403] time 0.083 (0.088) data 0.000 (0.004) loss 1.7180 (1.8070) teacher_loss 0.7417 (0.7806) loss_zs_kd 1.7648 (1.8602) loss_oracle 0.8720 (0.9054) kd_loss 0.8891 (0.9359) acc 65.6250 (72.9241) lr 3.6258e-04 eta 0:07:30
epoch [38/50] batch [160/403] time 0.077 (0.087) data 0.000 (0.004) loss 1.2998 (1.8084) teacher_loss 0.4312 (0.7845) loss_zs_kd 2.0777 (1.8536) loss_oracle 0.8375 (0.9056) kd_loss 0.7848 (0.9334) acc 81.2500 (72.8516) lr 3.6258e-04 eta 0:07:22
epoch [38/50] batch [180/403] time 0.085 (0.087) data 0.000 (0.003) loss 1.4019 (1.7985) teacher_loss 0.4472 (0.7783) loss_zs_kd 1.7074 (1.8438) loss_oracle 0.9237 (0.9027) kd_loss 0.8623 (0.9299) acc 93.7500 (73.1076) lr 3.6258e-04 eta 0:07:19
epoch [38/50] batch [200/403] time 0.084 (0.087) data 0.000 (0.003) loss 1.8972 (1.7952) teacher_loss 0.9293 (0.7770) loss_zs_kd 1.6700 (1.8409) loss_oracle 0.9864 (0.9033) kd_loss 0.8692 (0.9279) acc 68.7500 (73.1250) lr 3.6258e-04 eta 0:07:18
epoch [38/50] batch [220/403] time 0.081 (0.087) data 0.000 (0.003) loss 2.0087 (1.7929) teacher_loss 1.0067 (0.7761) loss_zs_kd 1.6079 (1.8400) loss_oracle 0.8883 (0.9030) kd_loss 0.9131 (0.9265) acc 71.8750 (73.3949) lr 3.6258e-04 eta 0:07:14
epoch [38/50] batch [240/403] time 0.079 (0.086) data 0.000 (0.003) loss 1.8932 (1.7964) teacher_loss 0.8898 (0.7797) loss_zs_kd 1.9998 (1.8376) loss_oracle 0.8536 (0.9020) kd_loss 0.9180 (0.9264) acc 62.5000 (73.3203) lr 3.6258e-04 eta 0:07:09
epoch [38/50] batch [260/403] time 0.088 (0.086) data 0.000 (0.002) loss 1.7379 (1.7960) teacher_loss 0.7329 (0.7799) loss_zs_kd 2.0967 (1.8403) loss_oracle 0.9405 (0.9019) kd_loss 0.9109 (0.9259) acc 71.8750 (73.2692) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [280/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.5690 (1.7952) teacher_loss 0.5391 (0.7802) loss_zs_kd 1.7700 (1.8346) loss_oracle 0.9465 (0.9026) kd_loss 0.9353 (0.9247) acc 81.2500 (73.3594) lr 3.6258e-04 eta 0:07:05
epoch [38/50] batch [300/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.6819 (1.7945) teacher_loss 0.6320 (0.7788) loss_zs_kd 1.6256 (1.8382) loss_oracle 0.9221 (0.9041) kd_loss 0.9576 (0.9253) acc 75.0000 (73.4583) lr 3.6258e-04 eta 0:07:02
epoch [38/50] batch [320/403] time 0.080 (0.085) data 0.000 (0.002) loss 1.8755 (1.7989) teacher_loss 0.8989 (0.7829) loss_zs_kd 1.6899 (1.8257) loss_oracle 0.9130 (0.9042) kd_loss 0.8853 (0.9256) acc 62.5000 (73.1934) lr 3.6258e-04 eta 0:06:59
epoch [38/50] batch [340/403] time 0.071 (0.085) data 0.000 (0.002) loss 2.0074 (1.8052) teacher_loss 1.0500 (0.7891) loss_zs_kd 1.2519 (1.8206) loss_oracle 0.8832 (0.9053) kd_loss 0.8691 (0.9256) acc 68.7500 (72.9228) lr 3.6258e-04 eta 0:06:56
epoch [38/50] batch [360/403] time 0.076 (0.085) data 0.000 (0.002) loss 1.7049 (1.8106) teacher_loss 0.7745 (0.7937) loss_zs_kd 2.0111 (1.8199) loss_oracle 0.9565 (0.9053) kd_loss 0.8347 (0.9263) acc 71.8750 (72.7257) lr 3.6258e-04 eta 0:06:52
epoch [38/50] batch [380/403] time 0.084 (0.085) data 0.000 (0.002) loss 2.0568 (1.8086) teacher_loss 1.0808 (0.7928) loss_zs_kd 2.0869 (1.8199) loss_oracle 0.8967 (0.9048) kd_loss 0.8864 (0.9253) acc 62.5000 (72.7632) lr 3.6258e-04 eta 0:06:50
epoch [38/50] batch [400/403] time 0.068 (0.084) data 0.000 (0.002) loss 1.7590 (1.8082) teacher_loss 0.7337 (0.7933) loss_zs_kd 1.8003 (1.8192) loss_oracle 0.9341 (0.9042) kd_loss 0.9319 (0.9245) acc 75.0000 (72.6953) lr 3.6258e-04 eta 0:06:47
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,008
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 58.9%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,521
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 31.8%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     42.9%, epoch: 38 *******
epoch [39/50] batch [20/403] time 0.080 (0.130) data 0.000 (0.040) loss 2.2565 (1.8189) teacher_loss 1.1298 (0.8097) loss_zs_kd 1.6456 (1.7715) loss_oracle 1.0220 (0.9006) kd_loss 1.0245 (0.9191) acc 59.3750 (73.2812) lr 3.1545e-04 eta 0:10:26
epoch [39/50] batch [40/403] time 0.076 (0.105) data 0.000 (0.020) loss 1.6186 (1.8405) teacher_loss 0.6511 (0.8251) loss_zs_kd 1.6019 (1.7873) loss_oracle 0.9912 (0.9014) kd_loss 0.8683 (0.9252) acc 75.0000 (72.5781) lr 3.1545e-04 eta 0:08:24
epoch [39/50] batch [60/403] time 0.074 (0.096) data 0.000 (0.014) loss 1.6292 (1.8210) teacher_loss 0.5975 (0.8049) loss_zs_kd 2.0026 (1.7949) loss_oracle 0.9003 (0.9008) kd_loss 0.9416 (0.9260) acc 87.5000 (73.2812) lr 3.1545e-04 eta 0:07:36
epoch [39/50] batch [80/403] time 0.079 (0.093) data 0.000 (0.010) loss 1.7053 (1.8256) teacher_loss 0.6607 (0.8072) loss_zs_kd 2.0969 (1.8202) loss_oracle 0.9833 (0.9026) kd_loss 0.9462 (0.9282) acc 78.1250 (72.8906) lr 3.1545e-04 eta 0:07:20
epoch [39/50] batch [100/403] time 0.084 (0.091) data 0.000 (0.008) loss 2.0610 (1.8158) teacher_loss 0.9519 (0.7992) loss_zs_kd 1.8333 (1.8142) loss_oracle 0.9948 (0.9021) kd_loss 1.0096 (0.9264) acc 68.7500 (73.0312) lr 3.1545e-04 eta 0:07:11
epoch [39/50] batch [120/403] time 0.073 (0.088) data 0.000 (0.007) loss 2.1081 (1.8026) teacher_loss 1.0712 (0.7888) loss_zs_kd 2.1013 (1.8207) loss_oracle 0.9282 (0.9001) kd_loss 0.9440 (0.9239) acc 53.1250 (73.5677) lr 3.1545e-04 eta 0:06:56
epoch [39/50] batch [140/403] time 0.096 (0.088) data 0.000 (0.006) loss 1.8939 (1.8042) teacher_loss 0.8183 (0.7909) loss_zs_kd 1.8675 (1.8164) loss_oracle 0.8446 (0.8974) kd_loss 0.9912 (0.9236) acc 71.8750 (73.1027) lr 3.1545e-04 eta 0:06:51
epoch [39/50] batch [160/403] time 0.072 (0.086) data 0.000 (0.005) loss 1.4717 (1.8000) teacher_loss 0.5326 (0.7900) loss_zs_kd 1.6529 (1.8014) loss_oracle 0.9166 (0.8979) kd_loss 0.8475 (0.9202) acc 75.0000 (72.9102) lr 3.1545e-04 eta 0:06:44
epoch [39/50] batch [180/403] time 0.088 (0.086) data 0.000 (0.005) loss 1.8694 (1.8041) teacher_loss 0.7383 (0.7923) loss_zs_kd 1.7659 (1.7995) loss_oracle 0.8893 (0.8979) kd_loss 1.0422 (0.9220) acc 81.2500 (72.7778) lr 3.1545e-04 eta 0:06:39
epoch [39/50] batch [200/403] time 0.088 (0.086) data 0.000 (0.004) loss 1.7974 (1.8015) teacher_loss 0.8645 (0.7905) loss_zs_kd 1.7930 (1.7988) loss_oracle 0.8756 (0.8973) kd_loss 0.8454 (0.9213) acc 68.7500 (72.7969) lr 3.1545e-04 eta 0:06:36
epoch [39/50] batch [220/403] time 0.073 (0.087) data 0.000 (0.004) loss 1.7456 (1.7992) teacher_loss 0.7066 (0.7868) loss_zs_kd 1.6514 (1.8048) loss_oracle 0.8851 (0.8972) kd_loss 0.9505 (0.9227) acc 68.7500 (72.9972) lr 3.1545e-04 eta 0:06:41
epoch [39/50] batch [240/403] time 0.083 (0.086) data 0.000 (0.004) loss 2.0239 (1.7994) teacher_loss 0.9581 (0.7858) loss_zs_kd 1.7632 (1.8035) loss_oracle 0.8542 (0.8977) kd_loss 0.9804 (0.9238) acc 68.7500 (73.0339) lr 3.1545e-04 eta 0:06:36
epoch [39/50] batch [260/403] time 0.089 (0.086) data 0.000 (0.003) loss 1.9198 (1.7962) teacher_loss 0.9089 (0.7837) loss_zs_kd 1.7578 (1.8067) loss_oracle 0.9529 (0.8972) kd_loss 0.9156 (0.9227) acc 75.0000 (73.0529) lr 3.1545e-04 eta 0:06:34
epoch [39/50] batch [280/403] time 0.085 (0.086) data 0.000 (0.003) loss 1.7284 (1.7968) teacher_loss 0.7644 (0.7837) loss_zs_kd 1.7399 (1.8111) loss_oracle 0.9401 (0.8982) kd_loss 0.8700 (0.9233) acc 71.8750 (72.9576) lr 3.1545e-04 eta 0:06:33
epoch [39/50] batch [300/403] time 0.090 (0.086) data 0.000 (0.003) loss 1.9582 (1.7955) teacher_loss 0.8371 (0.7818) loss_zs_kd 1.7492 (1.8124) loss_oracle 0.9041 (0.8991) kd_loss 1.0306 (0.9238) acc 71.8750 (72.8646) lr 3.1545e-04 eta 0:06:31
epoch [39/50] batch [320/403] time 0.077 (0.086) data 0.000 (0.003) loss 1.7453 (1.7994) teacher_loss 0.5934 (0.7845) loss_zs_kd 1.7885 (1.8125) loss_oracle 0.8623 (0.8990) kd_loss 1.0657 (0.9250) acc 78.1250 (72.7246) lr 3.1545e-04 eta 0:06:28
epoch [39/50] batch [340/403] time 0.096 (0.086) data 0.000 (0.003) loss 2.2002 (1.7996) teacher_loss 1.1256 (0.7840) loss_zs_kd 1.6073 (1.8141) loss_oracle 0.8995 (0.8999) kd_loss 0.9847 (0.9256) acc 62.5000 (72.7941) lr 3.1545e-04 eta 0:06:26
epoch [39/50] batch [360/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.7661 (1.7945) teacher_loss 0.7007 (0.7806) loss_zs_kd 1.7083 (1.8099) loss_oracle 0.9314 (0.9000) kd_loss 0.9722 (0.9239) acc 75.0000 (72.7865) lr 3.1545e-04 eta 0:06:23
epoch [39/50] batch [380/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.8526 (1.7916) teacher_loss 0.6899 (0.7774) loss_zs_kd 2.0417 (1.8127) loss_oracle 0.9939 (0.9003) kd_loss 1.0633 (0.9241) acc 75.0000 (72.8783) lr 3.1545e-04 eta 0:06:20
epoch [39/50] batch [400/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.7210 (1.7913) teacher_loss 0.6682 (0.7769) loss_zs_kd 1.9224 (1.8184) loss_oracle 0.9132 (0.8998) kd_loss 0.9615 (0.9244) acc 81.2500 (72.8672) lr 3.1545e-04 eta 0:06:16
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,978
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,563
* accuracy: 43.6%
* error: 56.4%
* macro_f1: 32.5%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [40/50] batch [20/403] time 0.088 (0.116) data 0.000 (0.031) loss 1.8948 (1.7835) teacher_loss 0.7717 (0.7554) loss_zs_kd 2.2401 (1.9118) loss_oracle 1.0319 (0.9038) kd_loss 1.0199 (0.9377) acc 68.7500 (72.6562) lr 2.7103e-04 eta 0:08:30
epoch [40/50] batch [40/403] time 0.091 (0.101) data 0.000 (0.016) loss 2.1638 (1.8263) teacher_loss 0.9247 (0.7758) loss_zs_kd 2.2677 (1.9510) loss_oracle 0.9404 (0.8984) kd_loss 1.1450 (0.9607) acc 56.2500 (72.1094) lr 2.7103e-04 eta 0:07:23
epoch [40/50] batch [60/403] time 0.066 (0.093) data 0.000 (0.010) loss 1.6404 (1.8238) teacher_loss 0.5998 (0.7804) loss_zs_kd 2.1569 (1.9824) loss_oracle 0.8540 (0.8968) kd_loss 0.9551 (0.9538) acc 78.1250 (71.7188) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [80/403] time 0.079 (0.089) data 0.000 (0.008) loss 1.6832 (1.8202) teacher_loss 0.6490 (0.7787) loss_zs_kd 1.7798 (1.9490) loss_oracle 0.9099 (0.8976) kd_loss 0.9432 (0.9518) acc 84.3750 (71.7578) lr 2.7103e-04 eta 0:06:28
epoch [40/50] batch [100/403] time 0.077 (0.087) data 0.000 (0.006) loss 1.6016 (1.8104) teacher_loss 0.5503 (0.7722) loss_zs_kd 2.2544 (1.9527) loss_oracle 0.9025 (0.8983) kd_loss 0.9611 (0.9484) acc 81.2500 (72.2188) lr 2.7103e-04 eta 0:06:16
epoch [40/50] batch [120/403] time 0.087 (0.087) data 0.000 (0.005) loss 1.8507 (1.8135) teacher_loss 0.8482 (0.7797) loss_zs_kd 1.7688 (1.9548) loss_oracle 0.9233 (0.8977) kd_loss 0.9101 (0.9441) acc 78.1250 (72.1615) lr 2.7103e-04 eta 0:06:13
epoch [40/50] batch [140/403] time 0.084 (0.086) data 0.000 (0.005) loss 2.2752 (1.8284) teacher_loss 1.1741 (0.7961) loss_zs_kd 2.2092 (1.9466) loss_oracle 0.8438 (0.8968) kd_loss 1.0167 (0.9426) acc 59.3750 (71.8527) lr 2.7103e-04 eta 0:06:08
epoch [40/50] batch [160/403] time 0.074 (0.085) data 0.000 (0.004) loss 1.7056 (1.8152) teacher_loss 0.7115 (0.7862) loss_zs_kd 2.0204 (1.9335) loss_oracle 0.9227 (0.8965) kd_loss 0.9019 (0.9394) acc 78.1250 (72.3438) lr 2.7103e-04 eta 0:06:04
epoch [40/50] batch [180/403] time 0.081 (0.085) data 0.000 (0.004) loss 1.4868 (1.8077) teacher_loss 0.4407 (0.7789) loss_zs_kd 1.4863 (1.9187) loss_oracle 0.8205 (0.8953) kd_loss 0.9640 (0.9393) acc 81.2500 (72.7431) lr 2.7103e-04 eta 0:06:01
epoch [40/50] batch [200/403] time 0.090 (0.085) data 0.000 (0.003) loss 1.7088 (1.8132) teacher_loss 0.7167 (0.7839) loss_zs_kd 1.6455 (1.9200) loss_oracle 0.8969 (0.8957) kd_loss 0.9024 (0.9397) acc 65.6250 (72.6875) lr 2.7103e-04 eta 0:05:59
epoch [40/50] batch [220/403] time 0.090 (0.085) data 0.000 (0.003) loss 1.8144 (1.8171) teacher_loss 0.7134 (0.7889) loss_zs_kd 1.9678 (1.9131) loss_oracle 0.8489 (0.8945) kd_loss 1.0161 (0.9387) acc 68.7500 (72.6562) lr 2.7103e-04 eta 0:05:57
epoch [40/50] batch [240/403] time 0.082 (0.085) data 0.001 (0.003) loss 1.9247 (1.8142) teacher_loss 0.9835 (0.7896) loss_zs_kd 1.6868 (1.8938) loss_oracle 0.8736 (0.8952) kd_loss 0.8539 (0.9350) acc 62.5000 (72.5391) lr 2.7103e-04 eta 0:05:54
epoch [40/50] batch [260/403] time 0.079 (0.084) data 0.000 (0.003) loss 1.7000 (1.8120) teacher_loss 0.6530 (0.7880) loss_zs_kd 1.5063 (1.8922) loss_oracle 0.8674 (0.8941) kd_loss 0.9603 (0.9346) acc 78.1250 (72.6322) lr 2.7103e-04 eta 0:05:50
epoch [40/50] batch [280/403] time 0.087 (0.084) data 0.000 (0.002) loss 1.7957 (1.8132) teacher_loss 0.7438 (0.7898) loss_zs_kd 2.5050 (1.8879) loss_oracle 0.8860 (0.8933) kd_loss 0.9633 (0.9341) acc 65.6250 (72.6562) lr 2.7103e-04 eta 0:05:49
epoch [40/50] batch [300/403] time 0.076 (0.084) data 0.000 (0.002) loss 1.5328 (1.8120) teacher_loss 0.5978 (0.7888) loss_zs_kd 1.8829 (1.8868) loss_oracle 0.9264 (0.8943) kd_loss 0.8423 (0.9337) acc 81.2500 (72.7188) lr 2.7103e-04 eta 0:05:46
epoch [40/50] batch [320/403] time 0.084 (0.083) data 0.000 (0.002) loss 1.7393 (1.8086) teacher_loss 0.6909 (0.7867) loss_zs_kd 1.9853 (1.8858) loss_oracle 0.8687 (0.8941) kd_loss 0.9615 (0.9325) acc 68.7500 (72.6855) lr 2.7103e-04 eta 0:05:43
epoch [40/50] batch [340/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.6365 (1.8074) teacher_loss 0.6612 (0.7856) loss_zs_kd 1.4274 (1.8863) loss_oracle 0.8182 (0.8927) kd_loss 0.8934 (0.9325) acc 81.2500 (72.7941) lr 2.7103e-04 eta 0:05:41
epoch [40/50] batch [360/403] time 0.087 (0.084) data 0.000 (0.002) loss 2.0443 (1.8040) teacher_loss 0.9643 (0.7830) loss_zs_kd 1.9840 (1.8839) loss_oracle 0.9083 (0.8925) kd_loss 0.9892 (0.9317) acc 65.6250 (72.9514) lr 2.7103e-04 eta 0:05:40
epoch [40/50] batch [380/403] time 0.087 (0.085) data 0.000 (0.002) loss 1.6237 (1.8030) teacher_loss 0.6692 (0.7821) loss_zs_kd 2.0759 (1.8858) loss_oracle 0.9022 (0.8933) kd_loss 0.8642 (0.9316) acc 84.3750 (72.9770) lr 2.7103e-04 eta 0:05:44
epoch [40/50] batch [400/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.8043 (1.8036) teacher_loss 0.7871 (0.7822) loss_zs_kd 2.1100 (1.8861) loss_oracle 0.9196 (0.8929) kd_loss 0.9253 (0.9322) acc 71.8750 (73.0234) lr 2.7103e-04 eta 0:05:41
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,018
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,499
* accuracy: 42.5%
* error: 57.5%
* macro_f1: 32.6%
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [41/50] batch [20/403] time 0.075 (0.116) data 0.001 (0.035) loss 1.7988 (1.8541) teacher_loss 0.7811 (0.8465) loss_zs_kd 1.9794 (1.8430) loss_oracle 0.8912 (0.8944) kd_loss 0.9286 (0.9181) acc 78.1250 (70.9375) lr 2.2949e-04 eta 0:07:45
epoch [41/50] batch [40/403] time 0.074 (0.095) data 0.000 (0.018) loss 1.3977 (1.8189) teacher_loss 0.4768 (0.8145) loss_zs_kd 1.7637 (1.8417) loss_oracle 0.9233 (0.8929) kd_loss 0.8286 (0.9151) acc 87.5000 (71.9531) lr 2.2949e-04 eta 0:06:20
epoch [41/50] batch [60/403] time 0.085 (0.091) data 0.000 (0.012) loss 1.7881 (1.8289) teacher_loss 0.7002 (0.8170) loss_zs_kd 1.7206 (1.8557) loss_oracle 0.9475 (0.8984) kd_loss 0.9932 (0.9220) acc 78.1250 (71.5104) lr 2.2949e-04 eta 0:06:00
epoch [41/50] batch [80/403] time 0.074 (0.088) data 0.000 (0.009) loss 1.9138 (1.8230) teacher_loss 0.9567 (0.8114) loss_zs_kd 1.9799 (1.8696) loss_oracle 0.8495 (0.8933) kd_loss 0.8722 (0.9223) acc 65.6250 (71.6797) lr 2.2949e-04 eta 0:05:48
epoch [41/50] batch [100/403] time 0.083 (0.087) data 0.000 (0.007) loss 2.2065 (1.8330) teacher_loss 1.1644 (0.8184) loss_zs_kd 2.2136 (1.8636) loss_oracle 0.8928 (0.8978) kd_loss 0.9528 (0.9249) acc 56.2500 (71.3125) lr 2.2949e-04 eta 0:05:41
epoch [41/50] batch [120/403] time 0.085 (0.087) data 0.000 (0.006) loss 1.6037 (1.8249) teacher_loss 0.5876 (0.8134) loss_zs_kd 1.8848 (1.8614) loss_oracle 0.8742 (0.8993) kd_loss 0.9286 (0.9216) acc 71.8750 (71.4844) lr 2.2949e-04 eta 0:05:38
epoch [41/50] batch [140/403] time 0.087 (0.089) data 0.000 (0.005) loss 1.8994 (1.8185) teacher_loss 0.9161 (0.8070) loss_zs_kd 1.7900 (1.8517) loss_oracle 0.8311 (0.9003) kd_loss 0.9002 (0.9215) acc 59.3750 (71.5179) lr 2.2949e-04 eta 0:05:46
epoch [41/50] batch [160/403] time 0.082 (0.089) data 0.000 (0.005) loss 1.3955 (1.8129) teacher_loss 0.4129 (0.8027) loss_zs_kd 1.5751 (1.8450) loss_oracle 0.8526 (0.9003) kd_loss 0.8973 (0.9202) acc 87.5000 (71.6797) lr 2.2949e-04 eta 0:05:42
epoch [41/50] batch [180/403] time 0.087 (0.088) data 0.000 (0.004) loss 1.6029 (1.8055) teacher_loss 0.5804 (0.7972) loss_zs_kd 2.2332 (1.8531) loss_oracle 0.8937 (0.9010) kd_loss 0.9331 (0.9182) acc 75.0000 (71.8229) lr 2.2949e-04 eta 0:05:39
epoch [41/50] batch [200/403] time 0.072 (0.087) data 0.000 (0.004) loss 1.7385 (1.8050) teacher_loss 0.7606 (0.7944) loss_zs_kd 1.5533 (1.8615) loss_oracle 0.8627 (0.8999) kd_loss 0.8916 (0.9206) acc 68.7500 (71.8281) lr 2.2949e-04 eta 0:05:34
epoch [41/50] batch [220/403] time 0.087 (0.087) data 0.000 (0.003) loss 1.8701 (1.8076) teacher_loss 0.9682 (0.7966) loss_zs_kd 1.9992 (1.8533) loss_oracle 0.9085 (0.8998) kd_loss 0.8111 (0.9211) acc 59.3750 (71.6193) lr 2.2949e-04 eta 0:05:30
epoch [41/50] batch [240/403] time 0.085 (0.086) data 0.000 (0.003) loss 1.6028 (1.8054) teacher_loss 0.6244 (0.7934) loss_zs_kd 1.7486 (1.8501) loss_oracle 0.8831 (0.8995) kd_loss 0.8901 (0.9221) acc 84.3750 (71.7188) lr 2.2949e-04 eta 0:05:26
epoch [41/50] batch [260/403] time 0.089 (0.086) data 0.000 (0.003) loss 1.8661 (1.8029) teacher_loss 0.8403 (0.7908) loss_zs_kd 1.9072 (1.8509) loss_oracle 0.9158 (0.8990) kd_loss 0.9342 (0.9222) acc 81.2500 (71.7909) lr 2.2949e-04 eta 0:05:25
epoch [41/50] batch [280/403] time 0.085 (0.086) data 0.001 (0.003) loss 1.8056 (1.8039) teacher_loss 0.7489 (0.7904) loss_zs_kd 1.5809 (1.8558) loss_oracle 0.8465 (0.8977) kd_loss 0.9720 (0.9237) acc 68.7500 (71.7857) lr 2.2949e-04 eta 0:05:23
epoch [41/50] batch [300/403] time 0.075 (0.086) data 0.000 (0.003) loss 2.0357 (1.8029) teacher_loss 0.8696 (0.7887) loss_zs_kd 1.5972 (1.8493) loss_oracle 0.8857 (0.8976) kd_loss 1.0775 (0.9244) acc 65.6250 (71.8542) lr 2.2949e-04 eta 0:05:20
epoch [41/50] batch [320/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.9036 (1.8020) teacher_loss 0.8190 (0.7868) loss_zs_kd 2.1984 (1.8501) loss_oracle 0.9358 (0.8980) kd_loss 0.9909 (0.9255) acc 68.7500 (71.9434) lr 2.2949e-04 eta 0:05:17
epoch [41/50] batch [340/403] time 0.093 (0.085) data 0.000 (0.002) loss 1.6014 (1.8005) teacher_loss 0.5585 (0.7852) loss_zs_kd 1.7559 (1.8543) loss_oracle 0.8677 (0.8972) kd_loss 0.9561 (0.9256) acc 75.0000 (71.9945) lr 2.2949e-04 eta 0:05:15
epoch [41/50] batch [360/403] time 0.081 (0.085) data 0.000 (0.002) loss 1.5538 (1.7985) teacher_loss 0.6331 (0.7835) loss_zs_kd 1.3884 (1.8548) loss_oracle 0.8855 (0.8975) kd_loss 0.8322 (0.9253) acc 71.8750 (72.0312) lr 2.2949e-04 eta 0:05:12
epoch [41/50] batch [380/403] time 0.082 (0.085) data 0.000 (0.002) loss 1.5959 (1.7983) teacher_loss 0.6470 (0.7838) loss_zs_kd 2.0826 (1.8556) loss_oracle 0.8980 (0.8973) kd_loss 0.8591 (0.9247) acc 81.2500 (72.0970) lr 2.2949e-04 eta 0:05:11
epoch [41/50] batch [400/403] time 0.075 (0.085) data 0.000 (0.002) loss 1.7573 (1.8012) teacher_loss 0.8254 (0.7857) loss_zs_kd 2.0827 (1.8575) loss_oracle 0.8828 (0.8973) kd_loss 0.8437 (0.9258) acc 78.1250 (72.1719) lr 2.2949e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,010
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 60.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,526
* accuracy: 42.9%
* error: 57.1%
* macro_f1: 32.7%
******* Domain 4 best val acc:      72.6%, epoch: 35 *******
******* Domain 4 best val test acc: 41.6%, epoch: 35 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [42/50] batch [20/403] time 0.086 (0.115) data 0.000 (0.025) loss 2.0409 (1.7751) teacher_loss 0.9495 (0.7743) loss_zs_kd 1.7459 (1.8859) loss_oracle 0.8421 (0.8930) kd_loss 1.0071 (0.9114) acc 65.6250 (75.1562) lr 1.9098e-04 eta 0:06:54
epoch [42/50] batch [40/403] time 0.082 (0.099) data 0.000 (0.012) loss 1.8041 (1.7771) teacher_loss 0.7615 (0.7793) loss_zs_kd 1.9770 (1.8777) loss_oracle 0.8689 (0.9068) kd_loss 0.9557 (0.9070) acc 78.1250 (73.9844) lr 1.9098e-04 eta 0:05:55
epoch [42/50] batch [60/403] time 0.086 (0.094) data 0.001 (0.008) loss 1.8898 (1.8021) teacher_loss 0.8568 (0.8014) loss_zs_kd 1.9025 (1.9088) loss_oracle 0.8641 (0.9104) kd_loss 0.9466 (0.9097) acc 62.5000 (72.7604) lr 1.9098e-04 eta 0:05:36
epoch [42/50] batch [80/403] time 0.095 (0.091) data 0.000 (0.006) loss 2.3656 (1.8200) teacher_loss 1.3241 (0.8212) loss_zs_kd 2.0041 (1.9010) loss_oracle 0.9263 (0.9074) kd_loss 0.9488 (0.9081) acc 46.8750 (71.9141) lr 1.9098e-04 eta 0:05:22
epoch [42/50] batch [100/403] time 0.089 (0.089) data 0.000 (0.005) loss 1.6342 (1.8167) teacher_loss 0.6491 (0.8157) loss_zs_kd 1.9111 (1.9101) loss_oracle 0.8778 (0.9059) kd_loss 0.8973 (0.9104) acc 81.2500 (71.8438) lr 1.9098e-04 eta 0:05:14
epoch [42/50] batch [120/403] time 0.084 (0.088) data 0.000 (0.004) loss 1.8861 (1.8044) teacher_loss 0.9089 (0.8017) loss_zs_kd 1.6041 (1.8982) loss_oracle 0.8808 (0.9034) kd_loss 0.8892 (0.9123) acc 78.1250 (72.2917) lr 1.9098e-04 eta 0:05:07
epoch [42/50] batch [140/403] time 0.083 (0.087) data 0.000 (0.004) loss 1.8219 (1.8049) teacher_loss 0.7708 (0.7953) loss_zs_kd 1.8436 (1.8938) loss_oracle 0.8962 (0.9026) kd_loss 0.9615 (0.9193) acc 75.0000 (72.3214) lr 1.9098e-04 eta 0:05:04
epoch [42/50] batch [160/403] time 0.082 (0.086) data 0.000 (0.003) loss 2.1676 (1.8095) teacher_loss 1.0462 (0.7973) loss_zs_kd 1.6369 (1.8970) loss_oracle 0.9180 (0.9034) kd_loss 1.0295 (0.9218) acc 59.3750 (72.3242) lr 1.9098e-04 eta 0:04:59
epoch [42/50] batch [180/403] time 0.070 (0.085) data 0.000 (0.003) loss 1.5531 (1.8148) teacher_loss 0.6289 (0.8029) loss_zs_kd 1.3343 (1.9000) loss_oracle 0.8389 (0.9018) kd_loss 0.8402 (0.9216) acc 81.2500 (72.2917) lr 1.9098e-04 eta 0:04:54
epoch [42/50] batch [200/403] time 0.091 (0.085) data 0.000 (0.003) loss 1.7880 (1.8131) teacher_loss 0.7481 (0.7974) loss_zs_kd 2.1178 (1.8966) loss_oracle 1.0314 (0.9006) kd_loss 0.9368 (0.9257) acc 75.0000 (72.5000) lr 1.9098e-04 eta 0:04:52
epoch [42/50] batch [220/403] time 0.077 (0.085) data 0.000 (0.003) loss 1.5503 (1.8045) teacher_loss 0.5960 (0.7905) loss_zs_kd 2.3218 (1.8836) loss_oracle 0.9214 (0.8990) kd_loss 0.8622 (0.9241) acc 87.5000 (72.8409) lr 1.9098e-04 eta 0:04:49
epoch [42/50] batch [240/403] time 0.076 (0.085) data 0.000 (0.002) loss 2.2231 (1.7993) teacher_loss 1.1762 (0.7845) loss_zs_kd 1.9041 (1.8844) loss_oracle 0.9488 (0.8985) kd_loss 0.9520 (0.9250) acc 62.5000 (72.9557) lr 1.9098e-04 eta 0:04:46
epoch [42/50] batch [260/403] time 0.088 (0.084) data 0.000 (0.002) loss 1.6134 (1.7963) teacher_loss 0.6076 (0.7816) loss_zs_kd 1.9274 (1.8846) loss_oracle 0.8540 (0.8977) kd_loss 0.9204 (0.9249) acc 71.8750 (73.1010) lr 1.9098e-04 eta 0:04:44
epoch [42/50] batch [280/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.7744 (1.7962) teacher_loss 0.6530 (0.7786) loss_zs_kd 2.0696 (1.8859) loss_oracle 0.9734 (0.8984) kd_loss 1.0241 (0.9278) acc 71.8750 (73.1027) lr 1.9098e-04 eta 0:04:42
epoch [42/50] batch [300/403] time 0.082 (0.086) data 0.000 (0.002) loss 1.4377 (1.7858) teacher_loss 0.4295 (0.7693) loss_zs_kd 1.6918 (1.8848) loss_oracle 0.8781 (0.8975) kd_loss 0.9204 (0.9268) acc 93.7500 (73.4062) lr 1.9098e-04 eta 0:04:44
epoch [42/50] batch [320/403] time 0.094 (0.085) data 0.000 (0.002) loss 2.2249 (1.7922) teacher_loss 1.1536 (0.7739) loss_zs_kd 2.3549 (1.8857) loss_oracle 0.9391 (0.8973) kd_loss 0.9774 (0.9286) acc 62.5000 (73.3789) lr 1.9098e-04 eta 0:04:42
epoch [42/50] batch [340/403] time 0.085 (0.085) data 0.000 (0.002) loss 1.8977 (1.7933) teacher_loss 0.8760 (0.7741) loss_zs_kd 2.2273 (1.8879) loss_oracle 0.8360 (0.8959) kd_loss 0.9381 (0.9296) acc 78.1250 (73.3732) lr 1.9098e-04 eta 0:04:40
epoch [42/50] batch [360/403] time 0.083 (0.085) data 0.000 (0.002) loss 1.6735 (1.7976) teacher_loss 0.6300 (0.7781) loss_zs_kd 1.4588 (1.8863) loss_oracle 0.8877 (0.8959) kd_loss 0.9547 (0.9299) acc 81.2500 (73.2639) lr 1.9098e-04 eta 0:04:38
epoch [42/50] batch [380/403] time 0.080 (0.085) data 0.000 (0.002) loss 1.6946 (1.7965) teacher_loss 0.6055 (0.7775) loss_zs_kd 1.6542 (1.8855) loss_oracle 0.8394 (0.8960) kd_loss 1.0052 (0.9294) acc 84.3750 (73.3388) lr 1.9098e-04 eta 0:04:36
epoch [42/50] batch [400/403] time 0.074 (0.085) data 0.000 (0.002) loss 1.7135 (1.8008) teacher_loss 0.7584 (0.7807) loss_zs_kd 1.6549 (1.8871) loss_oracle 0.9257 (0.8959) kd_loss 0.8626 (0.9305) acc 75.0000 (73.1016) lr 1.9098e-04 eta 0:04:34
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,032
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 61.4%
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,537
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.9%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [43/50] batch [20/403] time 0.072 (0.108) data 0.000 (0.027) loss 2.2750 (1.7941) teacher_loss 1.1090 (0.7680) loss_zs_kd 2.1222 (1.8278) loss_oracle 0.9478 (0.8926) kd_loss 1.0712 (0.9368) acc 59.3750 (75.0000) lr 1.5567e-04 eta 0:05:47
epoch [43/50] batch [40/403] time 0.088 (0.094) data 0.000 (0.014) loss 1.8255 (1.8087) teacher_loss 0.9003 (0.7811) loss_zs_kd 1.4998 (1.8040) loss_oracle 0.8647 (0.8893) kd_loss 0.8387 (0.9386) acc 65.6250 (72.5781) lr 1.5567e-04 eta 0:05:00
epoch [43/50] batch [60/403] time 0.088 (0.095) data 0.000 (0.009) loss 2.0056 (1.7846) teacher_loss 1.0171 (0.7593) loss_zs_kd 1.8001 (1.8280) loss_oracle 0.9178 (0.8904) kd_loss 0.8967 (0.9363) acc 71.8750 (73.6979) lr 1.5567e-04 eta 0:05:02
epoch [43/50] batch [80/403] time 0.082 (0.093) data 0.000 (0.007) loss 1.7624 (1.7876) teacher_loss 0.7063 (0.7648) loss_zs_kd 1.5456 (1.8052) loss_oracle 0.8871 (0.8921) kd_loss 0.9675 (0.9336) acc 78.1250 (73.2031) lr 1.5567e-04 eta 0:04:51
epoch [43/50] batch [100/403] time 0.078 (0.091) data 0.000 (0.006) loss 1.6119 (1.8058) teacher_loss 0.6749 (0.7755) loss_zs_kd 1.9490 (1.8270) loss_oracle 0.8810 (0.8919) kd_loss 0.8489 (0.9410) acc 81.2500 (72.7188) lr 1.5567e-04 eta 0:04:45
epoch [43/50] batch [120/403] time 0.082 (0.090) data 0.000 (0.005) loss 2.1858 (1.8105) teacher_loss 1.1124 (0.7826) loss_zs_kd 1.7862 (1.8293) loss_oracle 0.8968 (0.8913) kd_loss 0.9837 (0.9387) acc 53.1250 (72.1094) lr 1.5567e-04 eta 0:04:38
epoch [43/50] batch [140/403] time 0.082 (0.089) data 0.000 (0.004) loss 1.9486 (1.8105) teacher_loss 0.8633 (0.7842) loss_zs_kd 1.9397 (1.8277) loss_oracle 0.9462 (0.8920) kd_loss 0.9907 (0.9371) acc 59.3750 (71.8527) lr 1.5567e-04 eta 0:04:32
epoch [43/50] batch [160/403] time 0.088 (0.088) data 0.000 (0.004) loss 1.7743 (1.8070) teacher_loss 0.7435 (0.7849) loss_zs_kd 2.1771 (1.8376) loss_oracle 0.8818 (0.8915) kd_loss 0.9425 (0.9330) acc 75.0000 (71.8164) lr 1.5567e-04 eta 0:04:29
epoch [43/50] batch [180/403] time 0.075 (0.087) data 0.000 (0.003) loss 1.8036 (1.8068) teacher_loss 0.8138 (0.7851) loss_zs_kd 2.1161 (1.8413) loss_oracle 0.9295 (0.8901) kd_loss 0.8969 (0.9326) acc 71.8750 (71.6493) lr 1.5567e-04 eta 0:04:24
epoch [43/50] batch [200/403] time 0.081 (0.086) data 0.000 (0.003) loss 1.8758 (1.8100) teacher_loss 0.8420 (0.7859) loss_zs_kd 1.6434 (1.8311) loss_oracle 0.8716 (0.8903) kd_loss 0.9466 (0.9352) acc 68.7500 (71.7656) lr 1.5567e-04 eta 0:04:20
epoch [43/50] batch [220/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.4804 (1.8111) teacher_loss 0.4628 (0.7855) loss_zs_kd 1.9872 (1.8344) loss_oracle 0.9260 (0.8911) kd_loss 0.9250 (0.9365) acc 81.2500 (71.8892) lr 1.5567e-04 eta 0:04:16
epoch [43/50] batch [240/403] time 0.083 (0.085) data 0.000 (0.003) loss 1.9032 (1.8148) teacher_loss 0.9658 (0.7906) loss_zs_kd 1.9557 (1.8412) loss_oracle 0.8449 (0.8912) kd_loss 0.8529 (0.9351) acc 56.2500 (71.7839) lr 1.5567e-04 eta 0:04:13
epoch [43/50] batch [260/403] time 0.080 (0.085) data 0.000 (0.002) loss 2.0136 (1.8130) teacher_loss 0.9577 (0.7899) loss_zs_kd 2.1398 (1.8419) loss_oracle 0.9273 (0.8905) kd_loss 0.9631 (0.9341) acc 65.6250 (71.8149) lr 1.5567e-04 eta 0:04:11
epoch [43/50] batch [280/403] time 0.078 (0.084) data 0.000 (0.002) loss 2.0464 (1.8094) teacher_loss 1.0899 (0.7871) loss_zs_kd 1.9085 (1.8440) loss_oracle 0.8673 (0.8903) kd_loss 0.8698 (0.9333) acc 62.5000 (71.9196) lr 1.5567e-04 eta 0:04:08
epoch [43/50] batch [300/403] time 0.087 (0.084) data 0.000 (0.002) loss 1.7386 (1.8094) teacher_loss 0.6464 (0.7880) loss_zs_kd 1.9178 (1.8418) loss_oracle 0.9393 (0.8901) kd_loss 0.9982 (0.9324) acc 78.1250 (72.0312) lr 1.5567e-04 eta 0:04:06
epoch [43/50] batch [320/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.8075 (1.8147) teacher_loss 0.7746 (0.7925) loss_zs_kd 2.2022 (1.8470) loss_oracle 0.8759 (0.8912) kd_loss 0.9453 (0.9331) acc 71.8750 (71.9531) lr 1.5567e-04 eta 0:04:04
epoch [43/50] batch [340/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.7290 (1.8171) teacher_loss 0.8767 (0.7955) loss_zs_kd 1.9594 (1.8436) loss_oracle 0.8736 (0.8913) kd_loss 0.7649 (0.9325) acc 71.8750 (71.8474) lr 1.5567e-04 eta 0:04:02
epoch [43/50] batch [360/403] time 0.092 (0.084) data 0.000 (0.002) loss 1.7245 (1.8160) teacher_loss 0.7040 (0.7949) loss_zs_kd 2.3680 (1.8440) loss_oracle 0.8857 (0.8911) kd_loss 0.9319 (0.9320) acc 75.0000 (71.8490) lr 1.5567e-04 eta 0:04:00
epoch [43/50] batch [380/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.9318 (1.8176) teacher_loss 0.8334 (0.7965) loss_zs_kd 2.3644 (1.8443) loss_oracle 0.9404 (0.8913) kd_loss 1.0044 (0.9319) acc 65.6250 (71.7845) lr 1.5567e-04 eta 0:03:58
epoch [43/50] batch [400/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.9016 (1.8193) teacher_loss 0.8372 (0.7975) loss_zs_kd 1.7348 (1.8393) loss_oracle 0.8960 (0.8909) kd_loss 0.9748 (0.9327) acc 75.0000 (71.7500) lr 1.5567e-04 eta 0:03:56
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,017
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 60.8%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,554
* accuracy: 43.4%
* error: 56.6%
* macro_f1: 32.8%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [44/50] batch [20/403] time 0.085 (0.107) data 0.000 (0.025) loss 1.5783 (1.8051) teacher_loss 0.6079 (0.7936) loss_zs_kd 1.6302 (1.7260) loss_oracle 0.8402 (0.8962) kd_loss 0.8864 (0.9219) acc 78.1250 (72.0312) lr 1.2369e-04 eta 0:04:59
epoch [44/50] batch [40/403] time 0.083 (0.096) data 0.000 (0.012) loss 1.6594 (1.8196) teacher_loss 0.6445 (0.8007) loss_zs_kd 1.6511 (1.7558) loss_oracle 0.9207 (0.8905) kd_loss 0.9228 (0.9298) acc 78.1250 (71.7188) lr 1.2369e-04 eta 0:04:26
epoch [44/50] batch [60/403] time 0.075 (0.092) data 0.001 (0.008) loss 1.7551 (1.8050) teacher_loss 0.6681 (0.7865) loss_zs_kd 1.7022 (1.7299) loss_oracle 0.9214 (0.8877) kd_loss 0.9948 (0.9296) acc 84.3750 (72.0833) lr 1.2369e-04 eta 0:04:13
epoch [44/50] batch [80/403] time 0.078 (0.089) data 0.000 (0.006) loss 1.9009 (1.8136) teacher_loss 0.9140 (0.7918) loss_zs_kd 1.5435 (1.7490) loss_oracle 0.9035 (0.8901) kd_loss 0.8966 (0.9327) acc 62.5000 (72.6562) lr 1.2369e-04 eta 0:04:03
epoch [44/50] batch [100/403] time 0.080 (0.087) data 0.000 (0.005) loss 1.8971 (1.7996) teacher_loss 0.8627 (0.7823) loss_zs_kd 2.0123 (1.7655) loss_oracle 0.8907 (0.8889) kd_loss 0.9453 (0.9284) acc 65.6250 (72.7500) lr 1.2369e-04 eta 0:03:57
epoch [44/50] batch [120/403] time 0.078 (0.086) data 0.000 (0.004) loss 1.8357 (1.8011) teacher_loss 0.7911 (0.7850) loss_zs_kd 2.3397 (1.7901) loss_oracle 0.8960 (0.8890) kd_loss 0.9550 (0.9272) acc 71.8750 (72.4219) lr 1.2369e-04 eta 0:03:51
epoch [44/50] batch [140/403] time 0.078 (0.084) data 0.000 (0.004) loss 1.4081 (1.8074) teacher_loss 0.5110 (0.7899) loss_zs_kd 1.7170 (1.7955) loss_oracle 0.8578 (0.8870) kd_loss 0.8114 (0.9288) acc 87.5000 (72.4107) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [160/403] time 0.087 (0.085) data 0.000 (0.003) loss 1.6779 (1.7978) teacher_loss 0.6282 (0.7825) loss_zs_kd 1.6098 (1.8098) loss_oracle 0.9579 (0.8869) kd_loss 0.9540 (0.9266) acc 75.0000 (72.5586) lr 1.2369e-04 eta 0:03:44
epoch [44/50] batch [180/403] time 0.082 (0.085) data 0.000 (0.003) loss 1.7854 (1.7991) teacher_loss 0.6649 (0.7827) loss_zs_kd 1.8553 (1.8110) loss_oracle 0.9913 (0.8873) kd_loss 1.0214 (0.9277) acc 71.8750 (72.5000) lr 1.2369e-04 eta 0:03:43
epoch [44/50] batch [200/403] time 0.079 (0.084) data 0.000 (0.003) loss 2.0090 (1.8018) teacher_loss 1.0460 (0.7817) loss_zs_kd 1.7642 (1.8097) loss_oracle 0.8410 (0.8874) kd_loss 0.8789 (0.9313) acc 75.0000 (72.4688) lr 1.2369e-04 eta 0:03:40
epoch [44/50] batch [220/403] time 0.102 (0.085) data 0.001 (0.002) loss 1.6169 (1.8027) teacher_loss 0.6083 (0.7841) loss_zs_kd 2.0266 (1.8120) loss_oracle 0.9593 (0.8870) kd_loss 0.9127 (0.9299) acc 78.1250 (72.3438) lr 1.2369e-04 eta 0:03:41
epoch [44/50] batch [240/403] time 0.073 (0.085) data 0.000 (0.002) loss 1.7040 (1.8037) teacher_loss 0.7375 (0.7857) loss_zs_kd 1.7479 (1.8143) loss_oracle 0.9346 (0.8878) kd_loss 0.8730 (0.9293) acc 62.5000 (72.2656) lr 1.2369e-04 eta 0:03:38
epoch [44/50] batch [260/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.6396 (1.8047) teacher_loss 0.7219 (0.7861) loss_zs_kd 1.9701 (1.8259) loss_oracle 0.8412 (0.8889) kd_loss 0.8336 (0.9297) acc 75.0000 (72.2837) lr 1.2369e-04 eta 0:03:36
epoch [44/50] batch [280/403] time 0.084 (0.084) data 0.000 (0.002) loss 1.7309 (1.8071) teacher_loss 0.7551 (0.7886) loss_zs_kd 1.6786 (1.8245) loss_oracle 0.8568 (0.8885) kd_loss 0.8901 (0.9297) acc 65.6250 (72.1429) lr 1.2369e-04 eta 0:03:34
epoch [44/50] batch [300/403] time 0.086 (0.084) data 0.000 (0.002) loss 1.7373 (1.8024) teacher_loss 0.6904 (0.7852) loss_zs_kd 2.0859 (1.8209) loss_oracle 0.8898 (0.8886) kd_loss 0.9579 (0.9283) acc 75.0000 (72.5000) lr 1.2369e-04 eta 0:03:32
epoch [44/50] batch [320/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.6856 (1.8027) teacher_loss 0.7297 (0.7863) loss_zs_kd 1.6060 (1.8245) loss_oracle 0.8425 (0.8885) kd_loss 0.8716 (0.9275) acc 78.1250 (72.5391) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [340/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.5449 (1.8018) teacher_loss 0.5787 (0.7874) loss_zs_kd 1.6525 (1.8264) loss_oracle 0.8979 (0.8880) kd_loss 0.8764 (0.9257) acc 81.2500 (72.5643) lr 1.2369e-04 eta 0:03:28
epoch [44/50] batch [360/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.8021 (1.8020) teacher_loss 0.7246 (0.7876) loss_zs_kd 1.9812 (1.8295) loss_oracle 0.8674 (0.8884) kd_loss 0.9907 (0.9256) acc 62.5000 (72.4826) lr 1.2369e-04 eta 0:03:25
epoch [44/50] batch [380/403] time 0.068 (0.083) data 0.000 (0.002) loss 1.7392 (1.8009) teacher_loss 0.6475 (0.7862) loss_zs_kd 1.5882 (1.8275) loss_oracle 0.8887 (0.8884) kd_loss 1.0028 (0.9259) acc 71.8750 (72.5164) lr 1.2369e-04 eta 0:03:23
epoch [44/50] batch [400/403] time 0.072 (0.083) data 0.000 (0.001) loss 1.7093 (1.8010) teacher_loss 0.6308 (0.7862) loss_zs_kd 1.7319 (1.8269) loss_oracle 0.8799 (0.8885) kd_loss 0.9906 (0.9259) acc 78.1250 (72.4688) lr 1.2369e-04 eta 0:03:20
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,995
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 59.6%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,503
* accuracy: 42.5%
* error: 57.5%
* macro_f1: 32.4%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [45/50] batch [20/403] time 0.082 (0.114) data 0.000 (0.028) loss 1.8000 (1.7897) teacher_loss 0.8292 (0.7991) loss_zs_kd 2.0179 (1.8859) loss_oracle 0.8583 (0.8865) kd_loss 0.8850 (0.9020) acc 65.6250 (72.5000) lr 9.5173e-05 eta 0:04:32
epoch [45/50] batch [40/403] time 0.079 (0.097) data 0.000 (0.014) loss 1.7417 (1.7759) teacher_loss 0.6942 (0.7764) loss_zs_kd 1.7904 (1.8352) loss_oracle 0.8746 (0.8837) kd_loss 0.9600 (0.9111) acc 78.1250 (73.3594) lr 9.5173e-05 eta 0:03:50
epoch [45/50] batch [60/403] time 0.087 (0.092) data 0.001 (0.009) loss 1.7205 (1.7872) teacher_loss 0.7506 (0.7859) loss_zs_kd 2.0632 (1.8454) loss_oracle 0.8208 (0.8861) kd_loss 0.8877 (0.9127) acc 78.1250 (73.3333) lr 9.5173e-05 eta 0:03:36
epoch [45/50] batch [80/403] time 0.077 (0.089) data 0.000 (0.007) loss 1.9512 (1.7999) teacher_loss 0.7622 (0.7987) loss_zs_kd 1.7177 (1.8499) loss_oracle 0.9585 (0.8887) kd_loss 1.0931 (0.9123) acc 78.1250 (72.8906) lr 9.5173e-05 eta 0:03:28
epoch [45/50] batch [100/403] time 0.078 (0.087) data 0.000 (0.006) loss 1.8377 (1.7924) teacher_loss 0.8477 (0.7873) loss_zs_kd 1.8189 (1.8458) loss_oracle 0.8911 (0.8879) kd_loss 0.9009 (0.9163) acc 71.8750 (73.2812) lr 9.5173e-05 eta 0:03:22
epoch [45/50] batch [120/403] time 0.088 (0.087) data 0.000 (0.005) loss 1.7956 (1.7886) teacher_loss 0.7701 (0.7829) loss_zs_kd 2.2377 (1.8472) loss_oracle 0.8949 (0.8898) kd_loss 0.9360 (0.9168) acc 75.0000 (73.5156) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [140/403] time 0.080 (0.086) data 0.000 (0.004) loss 1.7978 (1.7892) teacher_loss 0.6919 (0.7800) loss_zs_kd 1.8706 (1.8410) loss_oracle 0.8850 (0.8890) kd_loss 1.0174 (0.9203) acc 78.1250 (73.3705) lr 9.5173e-05 eta 0:03:15
epoch [45/50] batch [160/403] time 0.084 (0.086) data 0.000 (0.004) loss 1.9703 (1.8008) teacher_loss 0.8748 (0.7908) loss_zs_kd 2.0806 (1.8514) loss_oracle 0.8706 (0.8898) kd_loss 1.0084 (0.9211) acc 65.6250 (72.7734) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [180/403] time 0.080 (0.085) data 0.000 (0.003) loss 1.6578 (1.8003) teacher_loss 0.7290 (0.7908) loss_zs_kd 1.7364 (1.8546) loss_oracle 0.9729 (0.8896) kd_loss 0.8316 (0.9205) acc 75.0000 (72.7951) lr 9.5173e-05 eta 0:03:10
epoch [45/50] batch [200/403] time 0.079 (0.085) data 0.000 (0.003) loss 2.1470 (1.7955) teacher_loss 0.9985 (0.7848) loss_zs_kd 1.4739 (1.8643) loss_oracle 0.9563 (0.8909) kd_loss 1.0529 (0.9217) acc 53.1250 (72.8438) lr 9.5173e-05 eta 0:03:08
epoch [45/50] batch [220/403] time 0.072 (0.084) data 0.000 (0.003) loss 1.4953 (1.7987) teacher_loss 0.5345 (0.7867) loss_zs_kd 2.0397 (1.8671) loss_oracle 0.9088 (0.8908) kd_loss 0.8699 (0.9230) acc 87.5000 (72.9119) lr 9.5173e-05 eta 0:03:05
epoch [45/50] batch [240/403] time 0.080 (0.084) data 0.000 (0.003) loss 1.8053 (1.8004) teacher_loss 0.7177 (0.7880) loss_zs_kd 1.7596 (1.8656) loss_oracle 0.9247 (0.8906) kd_loss 0.9951 (0.9234) acc 71.8750 (72.8255) lr 9.5173e-05 eta 0:03:02
epoch [45/50] batch [260/403] time 0.094 (0.084) data 0.000 (0.002) loss 1.8200 (1.8011) teacher_loss 0.8644 (0.7882) loss_zs_kd 1.8500 (1.8716) loss_oracle 0.8546 (0.8894) kd_loss 0.8701 (0.9239) acc 75.0000 (72.8486) lr 9.5173e-05 eta 0:03:00
epoch [45/50] batch [280/403] time 0.087 (0.084) data 0.000 (0.002) loss 1.9587 (1.8058) teacher_loss 0.9689 (0.7916) loss_zs_kd 1.9964 (1.8720) loss_oracle 0.9476 (0.8905) kd_loss 0.8951 (0.9251) acc 59.3750 (72.7344) lr 9.5173e-05 eta 0:02:59
epoch [45/50] batch [300/403] time 0.091 (0.084) data 0.000 (0.002) loss 1.9131 (1.8061) teacher_loss 0.7417 (0.7920) loss_zs_kd 1.9671 (1.8733) loss_oracle 0.8915 (0.8899) kd_loss 1.0822 (0.9252) acc 78.1250 (72.8229) lr 9.5173e-05 eta 0:02:57
epoch [45/50] batch [320/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.8683 (1.8050) teacher_loss 0.8570 (0.7905) loss_zs_kd 2.0038 (1.8660) loss_oracle 0.9565 (0.8898) kd_loss 0.9156 (0.9256) acc 71.8750 (72.8320) lr 9.5173e-05 eta 0:02:55
epoch [45/50] batch [340/403] time 0.096 (0.084) data 0.000 (0.002) loss 1.9121 (1.8033) teacher_loss 0.8485 (0.7879) loss_zs_kd 2.2308 (1.8683) loss_oracle 0.8796 (0.8911) kd_loss 0.9757 (0.9263) acc 65.6250 (72.8768) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [360/403] time 0.077 (0.084) data 0.000 (0.002) loss 1.6865 (1.8000) teacher_loss 0.7172 (0.7850) loss_zs_kd 1.4336 (1.8703) loss_oracle 0.8795 (0.8910) kd_loss 0.8813 (0.9259) acc 75.0000 (72.9948) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [380/403] time 0.114 (0.084) data 0.001 (0.002) loss 1.7781 (1.8006) teacher_loss 0.6915 (0.7846) loss_zs_kd 1.9893 (1.8678) loss_oracle 0.8996 (0.8912) kd_loss 0.9966 (0.9269) acc 71.8750 (72.8783) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [400/403] time 0.074 (0.084) data 0.000 (0.002) loss 1.8450 (1.7991) teacher_loss 0.8516 (0.7831) loss_zs_kd 1.8866 (1.8610) loss_oracle 0.8319 (0.8912) kd_loss 0.9102 (0.9269) acc 68.7500 (72.8984) lr 9.5173e-05 eta 0:02:49
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,000
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.7%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,545
* accuracy: 43.3%
* error: 56.7%
* macro_f1: 32.9%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [46/50] batch [20/403] time 0.088 (0.110) data 0.000 (0.025) loss 1.6108 (1.8025) teacher_loss 0.5971 (0.7742) loss_zs_kd 1.6452 (1.7724) loss_oracle 0.8579 (0.8762) kd_loss 0.9279 (0.9407) acc 75.0000 (71.7188) lr 7.0224e-05 eta 0:03:38
epoch [46/50] batch [40/403] time 0.087 (0.098) data 0.000 (0.013) loss 1.5174 (1.7742) teacher_loss 0.4900 (0.7569) loss_zs_kd 1.9567 (1.8484) loss_oracle 0.8827 (0.8824) kd_loss 0.9391 (0.9290) acc 84.3750 (72.5781) lr 7.0224e-05 eta 0:03:12
epoch [46/50] batch [60/403] time 0.074 (0.092) data 0.001 (0.009) loss 1.6293 (1.7651) teacher_loss 0.6436 (0.7520) loss_zs_kd 1.8990 (1.8276) loss_oracle 0.9141 (0.8866) kd_loss 0.8943 (0.9244) acc 78.1250 (72.6042) lr 7.0224e-05 eta 0:02:59
epoch [46/50] batch [80/403] time 0.078 (0.089) data 0.000 (0.006) loss 1.9092 (1.7787) teacher_loss 0.8340 (0.7657) loss_zs_kd 1.8590 (1.8576) loss_oracle 0.9205 (0.8883) kd_loss 0.9832 (0.9241) acc 65.6250 (72.1875) lr 7.0224e-05 eta 0:02:51
epoch [46/50] batch [100/403] time 0.089 (0.088) data 0.000 (0.005) loss 1.5887 (1.7785) teacher_loss 0.5979 (0.7617) loss_zs_kd 2.2701 (1.8677) loss_oracle 0.9473 (0.8865) kd_loss 0.8961 (0.9281) acc 84.3750 (72.8438) lr 7.0224e-05 eta 0:02:47
epoch [46/50] batch [120/403] time 0.087 (0.087) data 0.000 (0.004) loss 1.7474 (1.7831) teacher_loss 0.6527 (0.7674) loss_zs_kd 1.7673 (1.8657) loss_oracle 0.8982 (0.8856) kd_loss 1.0049 (0.9272) acc 75.0000 (72.9167) lr 7.0224e-05 eta 0:02:44
epoch [46/50] batch [140/403] time 0.071 (0.089) data 0.001 (0.004) loss 1.7538 (1.7830) teacher_loss 0.6839 (0.7686) loss_zs_kd 1.9831 (1.8601) loss_oracle 0.9065 (0.8865) kd_loss 0.9793 (0.9257) acc 78.1250 (72.9241) lr 7.0224e-05 eta 0:02:47
epoch [46/50] batch [160/403] time 0.080 (0.088) data 0.000 (0.003) loss 1.9093 (1.7845) teacher_loss 0.8320 (0.7701) loss_zs_kd 1.7302 (1.8623) loss_oracle 0.9531 (0.8871) kd_loss 0.9820 (0.9257) acc 62.5000 (72.8125) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [180/403] time 0.089 (0.088) data 0.000 (0.003) loss 1.7776 (1.7865) teacher_loss 0.6970 (0.7704) loss_zs_kd 1.5283 (1.8601) loss_oracle 0.8716 (0.8866) kd_loss 0.9935 (0.9274) acc 78.1250 (72.9167) lr 7.0224e-05 eta 0:02:40
epoch [46/50] batch [200/403] time 0.086 (0.088) data 0.000 (0.003) loss 1.7572 (1.7777) teacher_loss 0.7112 (0.7631) loss_zs_kd 1.8889 (1.8538) loss_oracle 0.9175 (0.8861) kd_loss 0.9542 (0.9260) acc 71.8750 (73.3438) lr 7.0224e-05 eta 0:02:38
epoch [46/50] batch [220/403] time 0.091 (0.087) data 0.000 (0.003) loss 1.8891 (1.7847) teacher_loss 0.7885 (0.7674) loss_zs_kd 2.1227 (1.8538) loss_oracle 0.8571 (0.8865) kd_loss 1.0149 (0.9287) acc 65.6250 (73.1818) lr 7.0224e-05 eta 0:02:36
epoch [46/50] batch [240/403] time 0.080 (0.087) data 0.000 (0.002) loss 1.7093 (1.7830) teacher_loss 0.6651 (0.7663) loss_zs_kd 2.2168 (1.8596) loss_oracle 0.8424 (0.8862) kd_loss 0.9600 (0.9281) acc 71.8750 (73.2292) lr 7.0224e-05 eta 0:02:33
epoch [46/50] batch [260/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.8025 (1.7908) teacher_loss 0.7504 (0.7731) loss_zs_kd 1.9302 (1.8569) loss_oracle 0.8447 (0.8861) kd_loss 0.9676 (0.9290) acc 71.8750 (72.9447) lr 7.0224e-05 eta 0:02:31
epoch [46/50] batch [280/403] time 0.083 (0.086) data 0.000 (0.002) loss 1.9448 (1.7901) teacher_loss 0.8673 (0.7739) loss_zs_kd 1.7370 (1.8499) loss_oracle 0.9305 (0.8863) kd_loss 0.9845 (0.9275) acc 71.8750 (72.9799) lr 7.0224e-05 eta 0:02:29
epoch [46/50] batch [300/403] time 0.081 (0.086) data 0.000 (0.002) loss 1.8343 (1.7899) teacher_loss 0.8304 (0.7737) loss_zs_kd 1.9284 (1.8545) loss_oracle 0.9036 (0.8859) kd_loss 0.9135 (0.9276) acc 78.1250 (73.0104) lr 7.0224e-05 eta 0:02:27
epoch [46/50] batch [320/403] time 0.081 (0.086) data 0.000 (0.002) loss 2.2565 (1.7932) teacher_loss 1.3168 (0.7769) loss_zs_kd 1.7339 (1.8536) loss_oracle 0.8972 (0.8858) kd_loss 0.8500 (0.9277) acc 53.1250 (72.8418) lr 7.0224e-05 eta 0:02:25
epoch [46/50] batch [340/403] time 0.078 (0.086) data 0.000 (0.002) loss 1.6614 (1.7917) teacher_loss 0.5658 (0.7733) loss_zs_kd 2.2662 (1.8533) loss_oracle 0.9160 (0.8869) kd_loss 1.0040 (0.9296) acc 84.3750 (73.0515) lr 7.0224e-05 eta 0:02:23
epoch [46/50] batch [360/403] time 0.093 (0.086) data 0.000 (0.002) loss 1.8183 (1.7911) teacher_loss 0.7665 (0.7737) loss_zs_kd 1.9783 (1.8546) loss_oracle 0.9081 (0.8869) kd_loss 0.9610 (0.9287) acc 68.7500 (73.1250) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [380/403] time 0.080 (0.085) data 0.000 (0.002) loss 1.7443 (1.7954) teacher_loss 0.7040 (0.7786) loss_zs_kd 1.8436 (1.8536) loss_oracle 0.8970 (0.8875) kd_loss 0.9506 (0.9280) acc 75.0000 (72.8947) lr 7.0224e-05 eta 0:02:19
epoch [46/50] batch [400/403] time 0.074 (0.085) data 0.000 (0.002) loss 1.8857 (1.7967) teacher_loss 0.8613 (0.7793) loss_zs_kd 1.9845 (1.8541) loss_oracle 0.8874 (0.8883) kd_loss 0.9357 (0.9286) acc 65.6250 (72.8672) lr 7.0224e-05 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,000
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,538
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [47/50] batch [20/403] time 0.053 (0.113) data 0.000 (0.031) loss 2.0727 (1.7940) teacher_loss 1.0860 (0.7519) loss_zs_kd 2.2520 (2.0435) loss_oracle 0.8656 (0.8892) kd_loss 0.9001 (0.9532) acc 65.6250 (73.9062) lr 4.8943e-05 eta 0:02:59
epoch [47/50] batch [40/403] time 0.072 (0.093) data 0.000 (0.016) loss 1.5347 (1.7815) teacher_loss 0.5568 (0.7565) loss_zs_kd 1.5604 (1.9347) loss_oracle 0.8411 (0.8979) kd_loss 0.8938 (0.9352) acc 81.2500 (73.6719) lr 4.8943e-05 eta 0:02:25
epoch [47/50] batch [60/403] time 0.078 (0.088) data 0.000 (0.011) loss 1.6185 (1.7940) teacher_loss 0.7044 (0.7713) loss_zs_kd 1.8924 (1.9099) loss_oracle 0.9265 (0.8929) kd_loss 0.8215 (0.9335) acc 75.0000 (73.1771) lr 4.8943e-05 eta 0:02:17
epoch [47/50] batch [80/403] time 0.089 (0.086) data 0.000 (0.008) loss 1.9764 (1.7913) teacher_loss 0.9935 (0.7718) loss_zs_kd 1.5034 (1.8899) loss_oracle 0.8882 (0.8915) kd_loss 0.8941 (0.9303) acc 71.8750 (73.1641) lr 4.8943e-05 eta 0:02:11
epoch [47/50] batch [100/403] time 0.078 (0.084) data 0.000 (0.006) loss 1.8860 (1.7948) teacher_loss 0.8306 (0.7752) loss_zs_kd 1.5779 (1.8795) loss_oracle 0.8316 (0.8920) kd_loss 0.9723 (0.9305) acc 65.6250 (73.0625) lr 4.8943e-05 eta 0:02:07
epoch [47/50] batch [120/403] time 0.080 (0.083) data 0.000 (0.005) loss 1.8286 (1.7833) teacher_loss 0.7264 (0.7615) loss_zs_kd 2.6074 (1.8928) loss_oracle 0.9065 (0.8939) kd_loss 1.0116 (0.9324) acc 75.0000 (73.7500) lr 4.8943e-05 eta 0:02:04
epoch [47/50] batch [140/403] time 0.086 (0.083) data 0.000 (0.005) loss 2.0012 (1.7950) teacher_loss 0.9487 (0.7731) loss_zs_kd 2.2028 (1.8936) loss_oracle 0.8647 (0.8965) kd_loss 0.9661 (0.9322) acc 65.6250 (73.1473) lr 4.8943e-05 eta 0:02:02
epoch [47/50] batch [160/403] time 0.081 (0.083) data 0.000 (0.004) loss 1.7614 (1.8093) teacher_loss 0.6257 (0.7831) loss_zs_kd 2.0061 (1.9002) loss_oracle 0.8684 (0.8982) kd_loss 1.0489 (0.9364) acc 75.0000 (72.9688) lr 4.8943e-05 eta 0:02:00
epoch [47/50] batch [180/403] time 0.082 (0.083) data 0.000 (0.004) loss 1.5696 (1.8131) teacher_loss 0.5994 (0.7859) loss_zs_kd 2.0783 (1.8968) loss_oracle 0.8780 (0.8972) kd_loss 0.8824 (0.9375) acc 75.0000 (72.5174) lr 4.8943e-05 eta 0:01:58
epoch [47/50] batch [200/403] time 0.079 (0.083) data 0.000 (0.003) loss 1.9973 (1.8112) teacher_loss 0.9653 (0.7848) loss_zs_kd 2.0503 (1.8920) loss_oracle 0.8824 (0.8968) kd_loss 0.9438 (0.9367) acc 71.8750 (72.4375) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [220/403] time 0.083 (0.083) data 0.000 (0.003) loss 1.7583 (1.8061) teacher_loss 0.7896 (0.7810) loss_zs_kd 2.0057 (1.8864) loss_oracle 0.8944 (0.8950) kd_loss 0.8792 (0.9355) acc 68.7500 (72.5426) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [240/403] time 0.079 (0.083) data 0.000 (0.003) loss 1.4395 (1.8060) teacher_loss 0.5024 (0.7813) loss_zs_kd 1.9232 (1.8919) loss_oracle 0.8315 (0.8940) kd_loss 0.8540 (0.9353) acc 75.0000 (72.5130) lr 4.8943e-05 eta 0:01:53
epoch [47/50] batch [260/403] time 0.075 (0.083) data 0.000 (0.003) loss 1.7798 (1.8070) teacher_loss 0.7784 (0.7821) loss_zs_kd 2.0818 (1.8896) loss_oracle 0.8900 (0.8935) kd_loss 0.9124 (0.9355) acc 71.8750 (72.4399) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [280/403] time 0.086 (0.083) data 0.000 (0.002) loss 1.8428 (1.8047) teacher_loss 0.9014 (0.7818) loss_zs_kd 1.9430 (1.8943) loss_oracle 0.8414 (0.8932) kd_loss 0.8573 (0.9335) acc 68.7500 (72.5670) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [300/403] time 0.085 (0.084) data 0.000 (0.002) loss 1.9418 (1.8066) teacher_loss 0.9236 (0.7830) loss_zs_kd 2.0745 (1.8985) loss_oracle 0.9656 (0.8937) kd_loss 0.9216 (0.9342) acc 68.7500 (72.5000) lr 4.8943e-05 eta 0:01:50
epoch [47/50] batch [320/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.8354 (1.8099) teacher_loss 0.7481 (0.7859) loss_zs_kd 2.4124 (1.8941) loss_oracle 0.9265 (0.8934) kd_loss 0.9946 (0.9347) acc 68.7500 (72.4902) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [340/403] time 0.079 (0.084) data 0.000 (0.002) loss 1.4497 (1.8045) teacher_loss 0.5158 (0.7815) loss_zs_kd 1.9061 (1.8888) loss_oracle 0.8720 (0.8936) kd_loss 0.8466 (0.9337) acc 84.3750 (72.6471) lr 4.8943e-05 eta 0:01:47
epoch [47/50] batch [360/403] time 0.078 (0.084) data 0.000 (0.002) loss 1.9705 (1.8021) teacher_loss 0.9542 (0.7792) loss_zs_kd 2.2280 (1.8811) loss_oracle 0.8569 (0.8942) kd_loss 0.9306 (0.9335) acc 56.2500 (72.6910) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [380/403] time 0.082 (0.084) data 0.000 (0.002) loss 1.5849 (1.8011) teacher_loss 0.5650 (0.7776) loss_zs_kd 1.6560 (1.8808) loss_oracle 0.8979 (0.8940) kd_loss 0.9301 (0.9341) acc 84.3750 (72.6727) lr 4.8943e-05 eta 0:01:43
epoch [47/50] batch [400/403] time 0.074 (0.084) data 0.000 (0.002) loss 1.6919 (1.7990) teacher_loss 0.6970 (0.7760) loss_zs_kd 2.0071 (1.8792) loss_oracle 0.8223 (0.8933) kd_loss 0.9128 (0.9337) acc 75.0000 (72.7422) lr 4.8943e-05 eta 0:01:41
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 3,996
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 59.3%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,534
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [48/50] batch [20/403] time 0.074 (0.117) data 0.000 (0.027) loss 1.6032 (1.7851) teacher_loss 0.6101 (0.7849) loss_zs_kd 1.6154 (1.8602) loss_oracle 0.8557 (0.8783) kd_loss 0.9076 (0.9124) acc 81.2500 (74.2188) lr 3.1417e-05 eta 0:02:18
epoch [48/50] batch [40/403] time 0.077 (0.097) data 0.000 (0.013) loss 1.8272 (1.7992) teacher_loss 0.7684 (0.7872) loss_zs_kd 2.0163 (1.8611) loss_oracle 0.9077 (0.8894) kd_loss 0.9680 (0.9231) acc 78.1250 (73.2031) lr 3.1417e-05 eta 0:01:53
epoch [48/50] batch [60/403] time 0.133 (0.099) data 0.001 (0.009) loss 1.4653 (1.7874) teacher_loss 0.4139 (0.7755) loss_zs_kd 1.6865 (1.8470) loss_oracle 0.9346 (0.8900) kd_loss 0.9579 (0.9228) acc 90.6250 (72.9688) lr 3.1417e-05 eta 0:01:54
epoch [48/50] batch [80/403] time 0.078 (0.094) data 0.000 (0.007) loss 1.6795 (1.8013) teacher_loss 0.6446 (0.7894) loss_zs_kd 2.4114 (1.8654) loss_oracle 0.9080 (0.8899) kd_loss 0.9441 (0.9229) acc 81.2500 (72.6953) lr 3.1417e-05 eta 0:01:46
epoch [48/50] batch [100/403] time 0.078 (0.092) data 0.000 (0.006) loss 1.7475 (1.7907) teacher_loss 0.6635 (0.7766) loss_zs_kd 2.0144 (1.8702) loss_oracle 0.9029 (0.8894) kd_loss 0.9937 (0.9252) acc 81.2500 (73.1875) lr 3.1417e-05 eta 0:01:41
epoch [48/50] batch [120/403] time 0.089 (0.090) data 0.000 (0.005) loss 1.8471 (1.7795) teacher_loss 0.8804 (0.7686) loss_zs_kd 1.8854 (1.8733) loss_oracle 0.9518 (0.8883) kd_loss 0.8715 (0.9221) acc 71.8750 (73.2812) lr 3.1417e-05 eta 0:01:37
epoch [48/50] batch [140/403] time 0.083 (0.088) data 0.000 (0.004) loss 1.6210 (1.7793) teacher_loss 0.6274 (0.7663) loss_zs_kd 1.9967 (1.8670) loss_oracle 0.8631 (0.8881) kd_loss 0.9073 (0.9243) acc 75.0000 (73.3929) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [160/403] time 0.072 (0.087) data 0.000 (0.004) loss 1.5675 (1.7852) teacher_loss 0.5360 (0.7677) loss_zs_kd 1.9554 (1.8756) loss_oracle 0.9007 (0.8891) kd_loss 0.9415 (0.9285) acc 84.3750 (73.3398) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [180/403] time 0.078 (0.086) data 0.000 (0.003) loss 1.7620 (1.7862) teacher_loss 0.7237 (0.7688) loss_zs_kd 2.3721 (1.8781) loss_oracle 0.9877 (0.8922) kd_loss 0.9395 (0.9281) acc 81.2500 (73.4375) lr 3.1417e-05 eta 0:01:28
epoch [48/50] batch [200/403] time 0.082 (0.086) data 0.000 (0.003) loss 2.0351 (1.7894) teacher_loss 0.9568 (0.7700) loss_zs_kd 1.8212 (1.8715) loss_oracle 0.9279 (0.8941) kd_loss 0.9855 (0.9300) acc 65.6250 (73.4531) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [220/403] time 0.085 (0.085) data 0.000 (0.003) loss 1.8424 (1.7902) teacher_loss 0.9097 (0.7721) loss_zs_kd 1.7915 (1.8662) loss_oracle 0.9746 (0.8943) kd_loss 0.8353 (0.9287) acc 68.7500 (73.2955) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [240/403] time 0.082 (0.085) data 0.000 (0.002) loss 1.6846 (1.7943) teacher_loss 0.7134 (0.7750) loss_zs_kd 2.1341 (1.8626) loss_oracle 0.9015 (0.8940) kd_loss 0.8810 (0.9299) acc 78.1250 (73.1771) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [260/403] time 0.080 (0.084) data 0.000 (0.002) loss 1.8634 (1.7959) teacher_loss 0.8485 (0.7768) loss_zs_kd 1.7321 (1.8597) loss_oracle 0.9283 (0.8942) kd_loss 0.9220 (0.9297) acc 75.0000 (73.0529) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [280/403] time 0.104 (0.084) data 0.001 (0.002) loss 2.0124 (1.7960) teacher_loss 0.9662 (0.7769) loss_zs_kd 1.9724 (1.8652) loss_oracle 0.8894 (0.8938) kd_loss 0.9572 (0.9297) acc 65.6250 (73.0469) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [300/403] time 0.083 (0.085) data 0.000 (0.002) loss 1.5922 (1.7943) teacher_loss 0.6999 (0.7757) loss_zs_kd 2.0077 (1.8699) loss_oracle 0.8276 (0.8937) kd_loss 0.8096 (0.9293) acc 71.8750 (72.9688) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [320/403] time 0.088 (0.085) data 0.000 (0.002) loss 1.9148 (1.7913) teacher_loss 0.9241 (0.7741) loss_zs_kd 2.0711 (1.8716) loss_oracle 0.8708 (0.8928) kd_loss 0.9036 (0.9279) acc 68.7500 (73.0664) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [340/403] time 0.089 (0.085) data 0.000 (0.002) loss 1.4620 (1.7908) teacher_loss 0.5202 (0.7743) loss_zs_kd 1.7502 (1.8642) loss_oracle 0.8173 (0.8922) kd_loss 0.8601 (0.9273) acc 75.0000 (73.1710) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [360/403] time 0.088 (0.085) data 0.000 (0.002) loss 1.7642 (1.7915) teacher_loss 0.7595 (0.7744) loss_zs_kd 2.0416 (1.8682) loss_oracle 0.9014 (0.8921) kd_loss 0.9146 (0.9279) acc 71.8750 (73.1597) lr 3.1417e-05 eta 0:01:12
epoch [48/50] batch [380/403] time 0.083 (0.085) data 0.000 (0.002) loss 1.7860 (1.7945) teacher_loss 0.7677 (0.7776) loss_zs_kd 1.5889 (1.8710) loss_oracle 0.8914 (0.8921) kd_loss 0.9291 (0.9277) acc 71.8750 (73.0345) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [400/403] time 0.073 (0.084) data 0.000 (0.002) loss 1.8302 (1.7936) teacher_loss 0.7720 (0.7763) loss_zs_kd 2.1080 (1.8739) loss_oracle 0.9280 (0.8925) kd_loss 0.9654 (0.9281) acc 65.6250 (73.0312) lr 3.1417e-05 eta 0:01:08
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,006
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,537
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 32.4%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [49/50] batch [20/403] time 0.082 (0.116) data 0.000 (0.033) loss 1.9746 (1.7887) teacher_loss 1.0193 (0.7493) loss_zs_kd 1.9950 (1.8931) loss_oracle 0.8707 (0.8942) kd_loss 0.8682 (0.9500) acc 65.6250 (73.7500) lr 1.7713e-05 eta 0:01:31
epoch [49/50] batch [40/403] time 0.090 (0.099) data 0.000 (0.016) loss 1.7574 (1.8190) teacher_loss 0.7591 (0.7795) loss_zs_kd 2.4177 (1.9166) loss_oracle 0.8947 (0.8983) kd_loss 0.9089 (0.9497) acc 78.1250 (73.5156) lr 1.7713e-05 eta 0:01:16
epoch [49/50] batch [60/403] time 0.086 (0.094) data 0.001 (0.011) loss 1.4210 (1.7971) teacher_loss 0.4386 (0.7637) loss_zs_kd 1.6140 (1.9044) loss_oracle 0.8868 (0.8970) kd_loss 0.8937 (0.9437) acc 84.3750 (74.3229) lr 1.7713e-05 eta 0:01:10
epoch [49/50] batch [80/403] time 0.074 (0.091) data 0.000 (0.008) loss 1.3922 (1.7897) teacher_loss 0.4304 (0.7609) loss_zs_kd 1.9055 (1.9028) loss_oracle 0.8950 (0.8928) kd_loss 0.8724 (0.9396) acc 84.3750 (74.3359) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [100/403] time 0.081 (0.089) data 0.000 (0.007) loss 1.9660 (1.7855) teacher_loss 0.9202 (0.7602) loss_zs_kd 1.9613 (1.8874) loss_oracle 0.8339 (0.8973) kd_loss 0.9624 (0.9355) acc 71.8750 (74.5938) lr 1.7713e-05 eta 0:01:02
epoch [49/50] batch [120/403] time 0.082 (0.088) data 0.000 (0.006) loss 2.2005 (1.7878) teacher_loss 0.9877 (0.7625) loss_zs_kd 1.8751 (1.8726) loss_oracle 0.9867 (0.8960) kd_loss 1.1141 (0.9358) acc 68.7500 (74.1406) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [140/403] time 0.085 (0.088) data 0.000 (0.005) loss 1.8173 (1.7959) teacher_loss 0.8459 (0.7684) loss_zs_kd 1.6124 (1.8621) loss_oracle 0.8784 (0.8963) kd_loss 0.8836 (0.9379) acc 71.8750 (73.8170) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [160/403] time 0.082 (0.087) data 0.000 (0.004) loss 1.6329 (1.7978) teacher_loss 0.6588 (0.7719) loss_zs_kd 1.7241 (1.8568) loss_oracle 0.9281 (0.8972) kd_loss 0.8813 (0.9361) acc 75.0000 (73.8477) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [180/403] time 0.077 (0.087) data 0.000 (0.004) loss 2.0052 (1.8017) teacher_loss 0.9752 (0.7765) loss_zs_kd 1.8842 (1.8630) loss_oracle 0.8400 (0.8956) kd_loss 0.9460 (0.9356) acc 62.5000 (73.7674) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [200/403] time 0.084 (0.086) data 0.000 (0.004) loss 1.8259 (1.7982) teacher_loss 0.8074 (0.7717) loss_zs_kd 1.8297 (1.8635) loss_oracle 0.8941 (0.8961) kd_loss 0.9290 (0.9368) acc 65.6250 (73.8281) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [220/403] time 0.078 (0.087) data 0.000 (0.003) loss 1.9718 (1.7941) teacher_loss 0.9432 (0.7711) loss_zs_kd 1.3027 (1.8583) loss_oracle 0.8726 (0.8953) kd_loss 0.9413 (0.9334) acc 62.5000 (73.7784) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [240/403] time 0.086 (0.087) data 0.001 (0.003) loss 1.7573 (1.7959) teacher_loss 0.6884 (0.7734) loss_zs_kd 1.7880 (1.8543) loss_oracle 0.8447 (0.8935) kd_loss 0.9845 (0.9332) acc 81.2500 (73.5547) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [260/403] time 0.084 (0.086) data 0.000 (0.003) loss 2.2331 (1.8005) teacher_loss 1.1641 (0.7764) loss_zs_kd 1.9688 (1.8631) loss_oracle 0.8524 (0.8939) kd_loss 0.9838 (0.9347) acc 53.1250 (73.3413) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [280/403] time 0.076 (0.086) data 0.000 (0.003) loss 1.7884 (1.7981) teacher_loss 0.7988 (0.7750) loss_zs_kd 2.2253 (1.8674) loss_oracle 0.8479 (0.8937) kd_loss 0.9048 (0.9337) acc 71.8750 (73.2924) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [300/403] time 0.077 (0.086) data 0.000 (0.002) loss 1.9257 (1.7999) teacher_loss 0.8268 (0.7768) loss_zs_kd 1.9169 (1.8705) loss_oracle 0.9504 (0.8942) kd_loss 1.0038 (0.9337) acc 75.0000 (73.2812) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [320/403] time 0.075 (0.086) data 0.000 (0.002) loss 1.8017 (1.7998) teacher_loss 0.6612 (0.7764) loss_zs_kd 1.9245 (1.8665) loss_oracle 0.9520 (0.8947) kd_loss 1.0453 (0.9339) acc 78.1250 (73.3398) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [340/403] time 0.078 (0.085) data 0.000 (0.002) loss 1.4775 (1.7983) teacher_loss 0.5002 (0.7748) loss_zs_kd 2.2804 (1.8653) loss_oracle 0.8690 (0.8951) kd_loss 0.8904 (0.9340) acc 87.5000 (73.4099) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [360/403] time 0.084 (0.085) data 0.000 (0.002) loss 1.9476 (1.7963) teacher_loss 0.8036 (0.7738) loss_zs_kd 1.6343 (1.8676) loss_oracle 0.9832 (0.8956) kd_loss 1.0457 (0.9330) acc 71.8750 (73.4028) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [380/403] time 0.086 (0.085) data 0.000 (0.002) loss 2.0057 (1.7992) teacher_loss 0.9446 (0.7768) loss_zs_kd 1.5139 (1.8683) loss_oracle 0.7991 (0.8951) kd_loss 0.9812 (0.9329) acc 65.6250 (73.1579) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [400/403] time 0.081 (0.085) data 0.000 (0.002) loss 1.8690 (1.8031) teacher_loss 0.8833 (0.7798) loss_zs_kd 1.6036 (1.8670) loss_oracle 0.8989 (0.8953) kd_loss 0.8958 (0.9338) acc 78.1250 (73.0938) lr 1.7713e-05 eta 0:00:34
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,004
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 59.4%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,542
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
epoch [50/50] batch [20/403] time 0.083 (0.102) data 0.000 (0.027) loss 1.5471 (1.7298) teacher_loss 0.4859 (0.7219) loss_zs_kd 1.7837 (1.8455) loss_oracle 0.9363 (0.8781) kd_loss 0.9676 (0.9200) acc 84.3750 (75.6250) lr 7.8853e-06 eta 0:00:39
epoch [50/50] batch [40/403] time 0.074 (0.091) data 0.000 (0.014) loss 1.7126 (1.7887) teacher_loss 0.6231 (0.7635) loss_zs_kd 1.6988 (1.8436) loss_oracle 0.8952 (0.8868) kd_loss 1.0000 (0.9365) acc 78.1250 (73.3594) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [60/403] time 0.082 (0.089) data 0.001 (0.009) loss 1.7638 (1.8029) teacher_loss 0.7934 (0.7842) loss_zs_kd 1.8528 (1.8569) loss_oracle 0.9022 (0.8882) kd_loss 0.8802 (0.9299) acc 75.0000 (72.6562) lr 7.8853e-06 eta 0:00:30
epoch [50/50] batch [80/403] time 0.081 (0.086) data 0.001 (0.007) loss 1.5907 (1.7898) teacher_loss 0.6193 (0.7753) loss_zs_kd 1.7376 (1.8434) loss_oracle 0.8929 (0.8928) kd_loss 0.8821 (0.9252) acc 78.1250 (72.8906) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [100/403] time 0.081 (0.085) data 0.000 (0.006) loss 1.8399 (1.7828) teacher_loss 0.8893 (0.7669) loss_zs_kd 1.8787 (1.8422) loss_oracle 0.8947 (0.8936) kd_loss 0.8612 (0.9266) acc 65.6250 (73.3438) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [120/403] time 0.072 (0.085) data 0.000 (0.005) loss 1.5231 (1.7840) teacher_loss 0.4813 (0.7619) loss_zs_kd 1.6604 (1.8526) loss_oracle 0.8932 (0.8955) kd_loss 0.9525 (0.9326) acc 81.2500 (73.3854) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [140/403] time 0.089 (0.084) data 0.000 (0.004) loss 1.6821 (1.7763) teacher_loss 0.6980 (0.7570) loss_zs_kd 1.8212 (1.8412) loss_oracle 0.8755 (0.8940) kd_loss 0.8965 (0.9299) acc 68.7500 (73.4598) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [160/403] time 0.073 (0.083) data 0.000 (0.004) loss 2.0787 (1.7884) teacher_loss 0.9171 (0.7668) loss_zs_kd 1.4726 (1.8471) loss_oracle 0.8624 (0.8941) kd_loss 1.0754 (0.9321) acc 65.6250 (73.1836) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [180/403] time 0.084 (0.083) data 0.000 (0.003) loss 1.9345 (1.7978) teacher_loss 0.8783 (0.7760) loss_zs_kd 1.9878 (1.8452) loss_oracle 0.9252 (0.8946) kd_loss 0.9636 (0.9324) acc 65.6250 (72.7604) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [200/403] time 0.082 (0.083) data 0.000 (0.003) loss 1.8306 (1.7925) teacher_loss 0.8728 (0.7727) loss_zs_kd 2.2207 (1.8478) loss_oracle 0.9465 (0.8935) kd_loss 0.8631 (0.9305) acc 75.0000 (73.0469) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [220/403] time 0.085 (0.083) data 0.000 (0.003) loss 1.6957 (1.7959) teacher_loss 0.6855 (0.7759) loss_zs_kd 2.1671 (1.8544) loss_oracle 0.9498 (0.8936) kd_loss 0.9151 (0.9306) acc 78.1250 (72.9403) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [240/403] time 0.080 (0.083) data 0.000 (0.003) loss 1.6599 (1.7990) teacher_loss 0.6799 (0.7805) loss_zs_kd 1.4734 (1.8549) loss_oracle 0.8276 (0.8925) kd_loss 0.8973 (0.9293) acc 78.1250 (72.8516) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [260/403] time 0.082 (0.083) data 0.000 (0.002) loss 1.9280 (1.8043) teacher_loss 0.8530 (0.7845) loss_zs_kd 2.1459 (1.8627) loss_oracle 0.9213 (0.8940) kd_loss 0.9829 (0.9304) acc 71.8750 (72.7404) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [280/403] time 0.072 (0.083) data 0.000 (0.002) loss 1.6508 (1.8054) teacher_loss 0.6241 (0.7843) loss_zs_kd 1.7356 (1.8613) loss_oracle 0.8887 (0.8934) kd_loss 0.9378 (0.9318) acc 68.7500 (72.7344) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [300/403] time 0.085 (0.083) data 0.000 (0.002) loss 1.5117 (1.8020) teacher_loss 0.6074 (0.7813) loss_zs_kd 1.7909 (1.8648) loss_oracle 0.8922 (0.8936) kd_loss 0.8151 (0.9313) acc 78.1250 (72.9271) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [320/403] time 0.074 (0.083) data 0.000 (0.002) loss 2.2490 (1.8021) teacher_loss 1.1775 (0.7832) loss_zs_kd 2.2807 (1.8650) loss_oracle 0.9148 (0.8928) kd_loss 0.9800 (0.9296) acc 75.0000 (72.9004) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [340/403] time 0.074 (0.083) data 0.000 (0.002) loss 1.7590 (1.7996) teacher_loss 0.7760 (0.7813) loss_zs_kd 2.4604 (1.8693) loss_oracle 0.8574 (0.8931) kd_loss 0.8972 (0.9289) acc 71.8750 (72.9504) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [360/403] time 0.079 (0.083) data 0.000 (0.002) loss 1.6701 (1.7984) teacher_loss 0.7387 (0.7792) loss_zs_kd 1.7612 (1.8735) loss_oracle 0.9241 (0.8937) kd_loss 0.8391 (0.9298) acc 84.3750 (73.0122) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [380/403] time 0.072 (0.084) data 0.000 (0.002) loss 1.6351 (1.7973) teacher_loss 0.7475 (0.7790) loss_zs_kd 1.9130 (1.8691) loss_oracle 0.8938 (0.8931) kd_loss 0.7982 (0.9290) acc 71.8750 (73.0510) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [400/403] time 0.075 (0.084) data 0.000 (0.002) loss 1.7787 (1.7974) teacher_loss 0.7983 (0.7795) loss_zs_kd 1.5146 (1.8683) loss_oracle 0.8521 (0.8931) kd_loss 0.8952 (0.9286) acc 71.8750 (73.0000) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 5,535
* correct: 4,010
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 59.5%
Evaluate on the *test* set
=> result
* total: 5,883
* correct: 2,540
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 32.5%
******* Domain 4 best val acc:      72.8%, epoch: 42 *******
******* Domain 4 best val test acc: 43.1%, epoch: 42 *******
******* Domain 4 best test acc:     43.6%, epoch: 39 *******
Checkpoint saved to icml/multi-dg/tuning/16_seperate_prompt3_lambdao-0.1/TRIP/terra_incognita/b32_ep50/ViT-B16/4/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:44:16

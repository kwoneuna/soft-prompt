Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.136 (0.135) data 0.000 (0.019) loss 1.0354 (0.9566) teacher_loss 0.7983 (0.6787) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0008 (0.0002) kd_loss 0.4734 (0.5556) acc 71.8750 (75.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.6260 (0.5444) teacher/usage_max 0.3962 (0.4744) teacher/usage_min 0.2903 (0.2313) teacher/usage_std 0.0455 (0.1052) nleep/row_max_mean 1525.0288 (1532.5052) nleep/row_max_std 75.8094 (55.8037) nleep/row_min_mean 1521.5259 (1527.7872) lr 1.0000e-05 eta 0:17:54
epoch [1/50] batch [40/160] time 0.088 (0.122) data 0.000 (0.010) loss 0.8403 (0.9075) teacher_loss 0.6720 (0.6659) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0018 (0.0008) kd_loss 0.3346 (0.4822) acc 75.0000 (75.7031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.7658 (0.6177) teacher/usage_max 0.5492 (0.4721) teacher/usage_min 0.2090 (0.2302) teacher/usage_std 0.1532 (0.1044) nleep/row_max_mean 1518.7971 (1529.5475) nleep/row_max_std 71.4663 (59.0552) nleep/row_min_mean 1516.1426 (1525.6959) lr 1.0000e-05 eta 0:16:13
epoch [1/50] batch [60/160] time 0.098 (0.114) data 0.000 (0.006) loss 0.6579 (0.9109) teacher_loss 0.5321 (0.6924) loss_zs_kd 0.0004 (0.0002) loss_oracle 0.0042 (0.0017) kd_loss 0.2470 (0.4352) acc 81.2500 (75.2083) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.8530 (0.6647) teacher/usage_max 0.4732 (0.4697) teacher/usage_min 0.2524 (0.2333) teacher/usage_std 0.0993 (0.1021) nleep/row_max_mean 1534.7770 (1528.6450) nleep/row_max_std 69.7150 (59.1135) nleep/row_min_mean 1532.9285 (1525.2868) lr 1.0000e-05 eta 0:15:05
epoch [1/50] batch [80/160] time 0.098 (0.109) data 0.000 (0.005) loss 1.0126 (0.8967) teacher_loss 0.9108 (0.7018) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0064 (0.0024) kd_loss 0.1967 (0.3871) acc 75.0000 (74.4531) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0014 (0.0015) teacher/entropy 0.9027 (0.7127) teacher/usage_max 0.4196 (0.4583) teacher/usage_min 0.2761 (0.2403) teacher/usage_std 0.0621 (0.0942) nleep/row_max_mean 1525.4740 (1527.4016) nleep/row_max_std 73.4908 (59.7032) nleep/row_min_mean 1523.9672 (1524.4461) lr 1.0000e-05 eta 0:14:23
epoch [1/50] batch [100/160] time 0.094 (0.106) data 0.000 (0.004) loss 0.7022 (0.8747) teacher_loss 0.6263 (0.6979) loss_zs_kd 0.0013 (0.0004) loss_oracle 0.0064 (0.0031) kd_loss 0.1441 (0.3500) acc 81.2500 (74.6562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9551 (0.7496) teacher/usage_max 0.3998 (0.4486) teacher/usage_min 0.2702 (0.2461) teacher/usage_std 0.0530 (0.0873) nleep/row_max_mean 1514.2443 (1526.0819) nleep/row_max_std 67.8350 (60.1045) nleep/row_min_mean 1513.0591 (1523.4143) lr 1.0000e-05 eta 0:13:54
epoch [1/50] batch [120/160] time 0.111 (0.104) data 0.000 (0.003) loss 0.7720 (0.8476) teacher_loss 0.7047 (0.6872) loss_zs_kd 0.0012 (0.0005) loss_oracle 0.0088 (0.0038) kd_loss 0.1245 (0.3165) acc 75.0000 (74.9740) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9747 (0.7830) teacher/usage_max 0.3983 (0.4386) teacher/usage_min 0.3002 (0.2523) teacher/usage_std 0.0460 (0.0803) nleep/row_max_mean 1492.2166 (1525.8698) nleep/row_max_std 109.2258 (58.6679) nleep/row_min_mean 1491.0973 (1523.4395) lr 1.0000e-05 eta 0:13:37
epoch [1/50] batch [140/160] time 0.139 (0.105) data 0.000 (0.003) loss 0.5663 (0.8306) teacher_loss 0.4993 (0.6835) loss_zs_kd 0.0009 (0.0006) loss_oracle 0.0080 (0.0045) kd_loss 0.1251 (0.2891) acc 87.5000 (75.0893) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9735 (0.8103) teacher/usage_max 0.3894 (0.4300) teacher/usage_min 0.2822 (0.2584) teacher/usage_std 0.0439 (0.0740) nleep/row_max_mean 1525.0400 (1525.3536) nleep/row_max_std 37.2201 (58.4116) nleep/row_min_mean 1523.9004 (1523.1124) lr 1.0000e-05 eta 0:13:42
epoch [1/50] batch [160/160] time 0.115 (0.106) data 0.000 (0.003) loss 1.0108 (0.8226) teacher_loss 0.9573 (0.6865) loss_zs_kd 0.0038 (0.0008) loss_oracle 0.0132 (0.0052) kd_loss 0.0899 (0.2663) acc 65.6250 (75.0000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0085 (0.8330) teacher/usage_max 0.3476 (0.4245) teacher/usage_min 0.3206 (0.2617) teacher/usage_std 0.0111 (0.0702) nleep/row_max_mean 1524.6951 (1525.0851) nleep/row_max_std 71.2403 (58.0662) nleep/row_min_mean 1523.7267 (1522.9976) lr 2.0000e-03 eta 0:13:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,726
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 80.0%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,923
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.2%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
epoch [2/50] batch [20/160] time 0.108 (0.126) data 0.001 (0.017) loss 0.8122 (0.7450) teacher_loss 0.6581 (0.6056) loss_zs_kd 0.0092 (0.0100) loss_oracle 0.1268 (0.1275) kd_loss 0.1721 (0.1413) acc 71.8750 (78.2812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3350 (0.3349) gate/usage_min 0.3314 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9274 (0.9580) teacher/usage_max 0.4813 (0.4353) teacher/usage_min 0.1843 (0.2294) teacher/usage_std 0.1212 (0.0856) nleep/row_max_mean 1525.3077 (1524.0073) nleep/row_max_std 54.0345 (60.8646) nleep/row_min_mean 1523.9065 (1522.7810) lr 2.0000e-03 eta 0:16:24
epoch [2/50] batch [40/160] time 0.115 (0.116) data 0.000 (0.009) loss 1.0854 (0.8047) teacher_loss 0.6200 (0.5692) loss_zs_kd 0.0119 (0.0100) loss_oracle 0.3963 (0.2085) kd_loss 0.5227 (0.2525) acc 78.1250 (79.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3344 (0.3348) gate/usage_min 0.3319 (0.3314) gate/usage_std 0.0010 (0.0014) teacher/entropy 0.5778 (0.8473) teacher/usage_max 0.6460 (0.5197) teacher/usage_min 0.0900 (0.1886) teacher/usage_std 0.2322 (0.1415) nleep/row_max_mean 1536.0632 (1526.2116) nleep/row_max_std 43.4927 (60.0171) nleep/row_min_mean 1532.3662 (1524.4131) lr 2.0000e-03 eta 0:15:02
epoch [2/50] batch [60/160] time 0.092 (0.111) data 0.000 (0.006) loss 0.8571 (0.8637) teacher_loss 0.3879 (0.5449) loss_zs_kd 0.0180 (0.0121) loss_oracle 0.3777 (0.2824) kd_loss 0.5427 (0.3432) acc 87.5000 (81.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3339 (0.3345) gate/usage_min 0.3327 (0.3318) gate/usage_std 0.0005 (0.0012) teacher/entropy 0.5568 (0.7565) teacher/usage_max 0.5471 (0.5271) teacher/usage_min 0.0627 (0.1508) teacher/usage_std 0.2018 (0.1601) nleep/row_max_mean 1547.9912 (1526.8951) nleep/row_max_std 26.2305 (62.8506) nleep/row_min_mean 1543.3323 (1524.4664) lr 2.0000e-03 eta 0:14:19
epoch [2/50] batch [80/160] time 0.094 (0.107) data 0.000 (0.005) loss 0.8931 (0.9007) teacher_loss 0.2709 (0.5167) loss_zs_kd 0.0194 (0.0149) loss_oracle 0.5232 (0.3387) kd_loss 0.7018 (0.4145) acc 90.6250 (82.3828) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3338 (0.3343) gate/usage_min 0.3329 (0.3320) gate/usage_std 0.0004 (0.0010) teacher/entropy 0.3975 (0.6850) teacher/usage_max 0.5001 (0.5226) teacher/usage_min 0.0678 (0.1340) teacher/usage_std 0.1898 (0.1663) nleep/row_max_mean 1542.1104 (1527.7829) nleep/row_max_std 69.9455 (63.2587) nleep/row_min_mean 1536.8024 (1524.7993) lr 2.0000e-03 eta 0:13:52
epoch [2/50] batch [100/160] time 0.092 (0.106) data 0.000 (0.004) loss 0.8572 (0.9169) teacher_loss 0.2006 (0.4884) loss_zs_kd 0.0329 (0.0177) loss_oracle 0.4590 (0.3638) kd_loss 0.8212 (0.4754) acc 96.8750 (83.5000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3342 (0.3343) gate/usage_min 0.3326 (0.3322) gate/usage_std 0.0007 (0.0009) teacher/entropy 0.2780 (0.6240) teacher/usage_max 0.5669 (0.5260) teacher/usage_min 0.0951 (0.1302) teacher/usage_std 0.1926 (0.1690) nleep/row_max_mean 1547.2192 (1527.9723) nleep/row_max_std 38.3259 (65.0960) nleep/row_min_mean 1540.4587 (1524.4837) lr 2.0000e-03 eta 0:13:38
epoch [2/50] batch [120/160] time 0.100 (0.105) data 0.000 (0.003) loss 1.1338 (0.9373) teacher_loss 0.5357 (0.4731) loss_zs_kd 0.0181 (0.0198) loss_oracle 0.4798 (0.3890) kd_loss 0.6984 (0.5195) acc 84.3750 (84.0365) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3343) gate/usage_min 0.3315 (0.3322) gate/usage_std 0.0014 (0.0009) teacher/entropy 0.4010 (0.5799) teacher/usage_max 0.4431 (0.5302) teacher/usage_min 0.1753 (0.1346) teacher/usage_std 0.1145 (0.1689) nleep/row_max_mean 1529.5791 (1528.4512) nleep/row_max_std 77.9126 (65.7283) nleep/row_min_mean 1523.6174 (1524.4058) lr 2.0000e-03 eta 0:13:28
epoch [2/50] batch [140/160] time 0.099 (0.104) data 0.000 (0.003) loss 0.8510 (0.9507) teacher_loss 0.2147 (0.4546) loss_zs_kd 0.0166 (0.0206) loss_oracle 0.6118 (0.4170) kd_loss 0.6442 (0.5546) acc 96.8750 (84.6429) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3355 (0.3344) gate/usage_min 0.3300 (0.3320) gate/usage_std 0.0024 (0.0010) teacher/entropy 0.4515 (0.5444) teacher/usage_max 0.4579 (0.5328) teacher/usage_min 0.1249 (0.1396) teacher/usage_std 0.1483 (0.1682) nleep/row_max_mean 1524.6929 (1528.9521) nleep/row_max_std 81.4254 (65.5749) nleep/row_min_mean 1517.8534 (1524.3973) lr 2.0000e-03 eta 0:13:21
epoch [2/50] batch [160/160] time 0.077 (0.103) data 0.000 (0.002) loss 1.1723 (0.9657) teacher_loss 0.5329 (0.4437) loss_zs_kd 0.0177 (0.0211) loss_oracle 0.4995 (0.4377) kd_loss 0.7615 (0.5853) acc 78.1250 (84.8242) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3371 (0.3346) gate/usage_min 0.3279 (0.3316) gate/usage_std 0.0040 (0.0013) teacher/entropy 0.3317 (0.5132) teacher/usage_max 0.6293 (0.5377) teacher/usage_min 0.0707 (0.1335) teacher/usage_std 0.2293 (0.1725) nleep/row_max_mean 1529.3341 (1529.3159) nleep/row_max_std 102.9837 (65.7206) nleep/row_min_mean 1520.1553 (1524.2048) lr 1.9980e-03 eta 0:13:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,814
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,943
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.2%, epoch: 2 *******
******* Domain p best val test acc: 87.2%, epoch: 2 *******
******* Domain p best test acc:     87.2%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.082 (0.123) data 0.000 (0.012) loss 1.0949 (1.0706) teacher_loss 0.3378 (0.3144) loss_zs_kd 0.0479 (0.0304) loss_oracle 0.5999 (0.6083) kd_loss 0.8665 (0.8738) acc 81.2500 (88.2812) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3391 (0.3382) gate/usage_min 0.3252 (0.3265) gate/usage_std 0.0059 (0.0050) teacher/entropy 0.2231 (0.2167) teacher/usage_max 0.5984 (0.5543) teacher/usage_min 0.0442 (0.0483) teacher/usage_std 0.2269 (0.2157) nleep/row_max_mean 1548.8611 (1531.8701) nleep/row_max_std 46.8497 (61.3655) nleep/row_min_mean 1537.3416 (1520.9028) lr 1.9980e-03 eta 0:15:41
epoch [3/50] batch [40/160] time 0.091 (0.105) data 0.000 (0.006) loss 1.0668 (1.1269) teacher_loss 0.2671 (0.3516) loss_zs_kd 0.0246 (0.0307) loss_oracle 0.6649 (0.6330) kd_loss 0.9099 (0.8869) acc 87.5000 (86.4844) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3415 (0.3393) gate/usage_min 0.3226 (0.3252) gate/usage_std 0.0079 (0.0060) teacher/entropy 0.1750 (0.2015) teacher/usage_max 0.4792 (0.5390) teacher/usage_min 0.0471 (0.0433) teacher/usage_std 0.2024 (0.2147) nleep/row_max_mean 1536.5774 (1529.8653) nleep/row_max_std 72.4071 (64.9946) nleep/row_min_mean 1522.9633 (1518.0604) lr 1.9980e-03 eta 0:13:22
epoch [3/50] batch [60/160] time 0.072 (0.098) data 0.001 (0.004) loss 1.2592 (1.1606) teacher_loss 0.4442 (0.3745) loss_zs_kd 0.0164 (0.0291) loss_oracle 0.6933 (0.6453) kd_loss 0.9205 (0.8978) acc 84.3750 (86.0417) gate/entropy 1.0982 (1.0984) gate/usage_max 0.3442 (0.3405) gate/usage_min 0.3199 (0.3239) gate/usage_std 0.0101 (0.0070) teacher/entropy 0.1578 (0.1882) teacher/usage_max 0.5309 (0.5488) teacher/usage_min 0.0064 (0.0342) teacher/usage_std 0.2329 (0.2225) nleep/row_max_mean 1528.6635 (1530.3572) nleep/row_max_std 83.7736 (64.6672) nleep/row_min_mean 1513.6877 (1517.3290) lr 1.9980e-03 eta 0:12:26
epoch [3/50] batch [80/160] time 0.095 (0.096) data 0.000 (0.003) loss 1.2005 (1.1663) teacher_loss 0.3993 (0.3745) loss_zs_kd 0.0300 (0.0288) loss_oracle 0.6776 (0.6480) kd_loss 0.8946 (0.9068) acc 81.2500 (86.3672) gate/entropy 1.0979 (1.0983) gate/usage_max 0.3471 (0.3418) gate/usage_min 0.3168 (0.3225) gate/usage_std 0.0125 (0.0081) teacher/entropy 0.1806 (0.1769) teacher/usage_max 0.5145 (0.5514) teacher/usage_min 0.0060 (0.0271) teacher/usage_std 0.2319 (0.2268) nleep/row_max_mean 1549.1892 (1531.6148) nleep/row_max_std 31.9112 (64.2111) nleep/row_min_mean 1530.1846 (1517.4284) lr 1.9980e-03 eta 0:12:09
epoch [3/50] batch [100/160] time 0.100 (0.096) data 0.000 (0.003) loss 0.9957 (1.1576) teacher_loss 0.1982 (0.3604) loss_zs_kd 0.0190 (0.0276) loss_oracle 0.6886 (0.6555) kd_loss 0.8874 (0.9114) acc 90.6250 (86.8750) gate/entropy 1.0976 (1.0982) gate/usage_max 0.3502 (0.3431) gate/usage_min 0.3142 (0.3211) gate/usage_std 0.0148 (0.0092) teacher/entropy 0.1761 (0.1693) teacher/usage_max 0.6851 (0.5640) teacher/usage_min 0.0144 (0.0232) teacher/usage_std 0.2748 (0.2324) nleep/row_max_mean 1503.2285 (1532.0892) nleep/row_max_std 118.2608 (63.4114) nleep/row_min_mean 1484.8069 (1516.9557) lr 1.9980e-03 eta 0:12:06
epoch [3/50] batch [120/160] time 0.101 (0.096) data 0.000 (0.002) loss 1.0065 (1.1611) teacher_loss 0.2266 (0.3629) loss_zs_kd 0.0358 (0.0286) loss_oracle 0.5522 (0.6528) kd_loss 0.9717 (0.9151) acc 90.6250 (86.6146) gate/entropy 1.0973 (1.0981) gate/usage_max 0.3536 (0.3446) gate/usage_min 0.3115 (0.3197) gate/usage_std 0.0172 (0.0103) teacher/entropy 0.0900 (0.1626) teacher/usage_max 0.5933 (0.5738) teacher/usage_min 0.0025 (0.0202) teacher/usage_std 0.2463 (0.2367) nleep/row_max_mean 1504.5339 (1532.6749) nleep/row_max_std 87.3996 (62.9475) nleep/row_min_mean 1484.1746 (1516.6767) lr 1.9980e-03 eta 0:12:07
epoch [3/50] batch [140/160] time 0.104 (0.096) data 0.000 (0.002) loss 1.0198 (1.1618) teacher_loss 0.1750 (0.3626) loss_zs_kd 0.0320 (0.0290) loss_oracle 0.7046 (0.6498) kd_loss 0.9529 (0.9196) acc 96.8750 (86.7634) gate/entropy 1.0969 (1.0979) gate/usage_max 0.3569 (0.3461) gate/usage_min 0.3088 (0.3183) gate/usage_std 0.0197 (0.0115) teacher/entropy 0.1059 (0.1551) teacher/usage_max 0.5630 (0.5838) teacher/usage_min 0.0002 (0.0181) teacher/usage_std 0.2412 (0.2410) nleep/row_max_mean 1530.9431 (1532.0562) nleep/row_max_std 46.5029 (64.0312) nleep/row_min_mean 1509.1854 (1515.3074) lr 1.9980e-03 eta 0:12:03
epoch [3/50] batch [160/160] time 0.088 (0.095) data 0.000 (0.002) loss 1.7025 (1.1700) teacher_loss 0.8165 (0.3650) loss_zs_kd 0.0307 (0.0296) loss_oracle 0.7704 (0.6570) kd_loss 0.9709 (0.9234) acc 75.0000 (87.0312) gate/entropy 1.0964 (1.0978) gate/usage_max 0.3606 (0.3477) gate/usage_min 0.3060 (0.3169) gate/usage_std 0.0223 (0.0127) teacher/entropy 0.0660 (0.1480) teacher/usage_max 0.7854 (0.5967) teacher/usage_min 0.0011 (0.0159) teacher/usage_std 0.3312 (0.2467) nleep/row_max_mean 1520.8628 (1532.0213) nleep/row_max_std 95.4319 (64.4050) nleep/row_min_mean 1497.9812 (1514.5744) lr 1.9921e-03 eta 0:11:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,967
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.5%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     87.9%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.094 (0.155) data 0.000 (0.015) loss 1.1584 (1.2010) teacher_loss 0.2346 (0.3259) loss_zs_kd 0.0558 (0.0471) loss_oracle 0.8073 (0.7368) kd_loss 0.9844 (0.9663) acc 90.6250 (89.6875) gate/entropy 1.0958 (1.0961) gate/usage_max 0.3646 (0.3627) gate/usage_min 0.3033 (0.3045) gate/usage_std 0.0250 (0.0238) teacher/entropy 0.0470 (0.0715) teacher/usage_max 0.7619 (0.7267) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3182 (0.3018) nleep/row_max_mean 1545.4597 (1535.4593) nleep/row_max_std 50.0074 (63.4463) nleep/row_min_mean 1516.4857 (1510.3600) lr 1.9921e-03 eta 0:19:19
epoch [4/50] batch [40/160] time 0.104 (0.133) data 0.000 (0.008) loss 1.0185 (1.1599) teacher_loss 0.1508 (0.2861) loss_zs_kd 0.0490 (0.0474) loss_oracle 0.7415 (0.7404) kd_loss 0.9451 (0.9599) acc 100.0000 (91.0938) gate/entropy 1.0951 (1.0957) gate/usage_max 0.3690 (0.3648) gate/usage_min 0.3004 (0.3031) gate/usage_std 0.0281 (0.0252) teacher/entropy 0.0879 (0.0741) teacher/usage_max 0.6706 (0.7283) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2738 (0.3029) nleep/row_max_mean 1544.2891 (1536.2960) nleep/row_max_std 51.0159 (65.0940) nleep/row_min_mean 1518.6921 (1510.8202) lr 1.9921e-03 eta 0:16:32
epoch [4/50] batch [60/160] time 0.100 (0.121) data 0.000 (0.005) loss 1.1634 (1.1663) teacher_loss 0.3090 (0.2928) loss_zs_kd 0.0468 (0.0485) loss_oracle 0.7243 (0.7425) kd_loss 0.9377 (0.9560) acc 93.7500 (91.0938) gate/entropy 1.0943 (1.0954) gate/usage_max 0.3733 (0.3669) gate/usage_min 0.2977 (0.3018) gate/usage_std 0.0310 (0.0266) teacher/entropy 0.0716 (0.0728) teacher/usage_max 0.8113 (0.7421) teacher/usage_min 0.0003 (0.0010) teacher/usage_std 0.3466 (0.3099) nleep/row_max_mean 1522.7074 (1533.1769) nleep/row_max_std 80.8846 (69.0301) nleep/row_min_mean 1499.1212 (1507.7364) lr 1.9921e-03 eta 0:15:00
epoch [4/50] batch [80/160] time 0.094 (0.115) data 0.001 (0.004) loss 1.1483 (1.1744) teacher_loss 0.2558 (0.3021) loss_zs_kd 0.0321 (0.0486) loss_oracle 0.8192 (0.7440) kd_loss 0.9335 (0.9519) acc 90.6250 (90.5078) gate/entropy 1.0934 (1.0950) gate/usage_max 0.3780 (0.3691) gate/usage_min 0.2951 (0.3004) gate/usage_std 0.0341 (0.0281) teacher/entropy 0.0633 (0.0725) teacher/usage_max 0.8350 (0.7475) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.3610 (0.3129) nleep/row_max_mean 1534.4050 (1533.6109) nleep/row_max_std 62.9641 (66.7640) nleep/row_min_mean 1507.1987 (1507.9355) lr 1.9921e-03 eta 0:14:13
epoch [4/50] batch [100/160] time 0.097 (0.112) data 0.000 (0.003) loss 1.1381 (1.1910) teacher_loss 0.2761 (0.3190) loss_zs_kd 0.0428 (0.0490) loss_oracle 0.7442 (0.7457) kd_loss 0.9370 (0.9492) acc 96.8750 (90.0938) gate/entropy 1.0924 (1.0946) gate/usage_max 0.3825 (0.3714) gate/usage_min 0.2925 (0.2991) gate/usage_std 0.0372 (0.0297) teacher/entropy 0.0653 (0.0705) teacher/usage_max 0.7474 (0.7539) teacher/usage_min 0.0006 (0.0016) teacher/usage_std 0.3102 (0.3164) nleep/row_max_mean 1535.1244 (1534.1259) nleep/row_max_std 62.1748 (65.7640) nleep/row_min_mean 1507.8010 (1508.1822) lr 1.9921e-03 eta 0:13:52
epoch [4/50] batch [120/160] time 0.083 (0.110) data 0.000 (0.003) loss 1.3654 (1.1971) teacher_loss 0.5014 (0.3249) loss_zs_kd 0.0395 (0.0482) loss_oracle 0.7486 (0.7502) kd_loss 0.9400 (0.9459) acc 87.5000 (89.7917) gate/entropy 1.0913 (1.0941) gate/usage_max 0.3874 (0.3736) gate/usage_min 0.2900 (0.2977) gate/usage_std 0.0405 (0.0312) teacher/entropy 0.0522 (0.0688) teacher/usage_max 0.7603 (0.7609) teacher/usage_min 0.0015 (0.0014) teacher/usage_std 0.3170 (0.3202) nleep/row_max_mean 1523.4775 (1533.1996) nleep/row_max_std 98.8256 (66.7134) nleep/row_min_mean 1494.8342 (1507.0851) lr 1.9921e-03 eta 0:13:35
epoch [4/50] batch [140/160] time 0.096 (0.108) data 0.000 (0.002) loss 1.0665 (1.1991) teacher_loss 0.2301 (0.3303) loss_zs_kd 0.0379 (0.0473) loss_oracle 0.7258 (0.7498) kd_loss 0.9091 (0.9404) acc 93.7500 (89.5536) gate/entropy 1.0901 (1.0936) gate/usage_max 0.3923 (0.3760) gate/usage_min 0.2872 (0.2964) gate/usage_std 0.0439 (0.0328) teacher/entropy 0.0800 (0.0699) teacher/usage_max 0.7365 (0.7638) teacher/usage_min 0.0003 (0.0015) teacher/usage_std 0.3046 (0.3216) nleep/row_max_mean 1527.6921 (1532.9949) nleep/row_max_std 73.6246 (66.1981) nleep/row_min_mean 1502.6924 (1506.7575) lr 1.9921e-03 eta 0:13:16
epoch [4/50] batch [160/160] time 0.088 (0.106) data 0.000 (0.002) loss 1.0808 (1.1977) teacher_loss 0.2461 (0.3314) loss_zs_kd 0.0345 (0.0464) loss_oracle 0.7425 (0.7509) kd_loss 0.8923 (0.9353) acc 90.6250 (89.5312) gate/entropy 1.0887 (1.0931) gate/usage_max 0.3972 (0.3783) gate/usage_min 0.2846 (0.2951) gate/usage_std 0.0472 (0.0344) teacher/entropy 0.0537 (0.0695) teacher/usage_max 0.8977 (0.7718) teacher/usage_min 0.0001 (0.0014) teacher/usage_std 0.4012 (0.3261) nleep/row_max_mean 1528.8391 (1533.0241) nleep/row_max_std 90.4346 (66.2683) nleep/row_min_mean 1500.9014 (1506.6374) lr 1.9823e-03 eta 0:12:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,813
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.1%
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     87.9%, epoch: 3 *******
epoch [5/50] batch [20/160] time 0.101 (0.133) data 0.000 (0.014) loss 0.9493 (1.1810) teacher_loss 0.1387 (0.3445) loss_zs_kd 0.0209 (0.0397) loss_oracle 0.7214 (0.7301) kd_loss 0.8789 (0.9033) acc 96.8750 (90.4688) gate/entropy 1.0874 (1.0880) gate/usage_max 0.4020 (0.3999) gate/usage_min 0.2822 (0.2833) gate/usage_std 0.0504 (0.0490) teacher/entropy 0.1124 (0.0560) teacher/usage_max 0.6676 (0.8178) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.2726 (0.3527) nleep/row_max_mean 1506.4255 (1533.1267) nleep/row_max_std 90.6666 (66.4954) nleep/row_min_mean 1481.1962 (1504.3250) lr 1.9823e-03 eta 0:16:16
epoch [5/50] batch [40/160] time 0.165 (0.126) data 0.000 (0.007) loss 1.0353 (1.1759) teacher_loss 0.2267 (0.3486) loss_zs_kd 0.0303 (0.0383) loss_oracle 0.7136 (0.7262) kd_loss 0.8732 (0.8901) acc 96.8750 (89.2188) gate/entropy 1.0858 (1.0873) gate/usage_max 0.4070 (0.4023) gate/usage_min 0.2795 (0.2820) gate/usage_std 0.0539 (0.0507) teacher/entropy 0.0857 (0.0628) teacher/usage_max 0.7703 (0.8258) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3229 (0.3571) nleep/row_max_mean 1543.9360 (1532.1232) nleep/row_max_std 47.4159 (65.4757) nleep/row_min_mean 1514.8127 (1503.6611) lr 1.9823e-03 eta 0:15:19
epoch [5/50] batch [60/160] time 0.104 (0.128) data 0.001 (0.005) loss 1.3778 (1.1607) teacher_loss 0.6257 (0.3441) loss_zs_kd 0.0496 (0.0403) loss_oracle 0.6252 (0.7104) kd_loss 0.8294 (0.8827) acc 81.2500 (89.2708) gate/entropy 1.0842 (1.0865) gate/usage_max 0.4118 (0.4047) gate/usage_min 0.2770 (0.2807) gate/usage_std 0.0572 (0.0523) teacher/entropy 0.1280 (0.0676) teacher/usage_max 0.7541 (0.8202) teacher/usage_min 0.0090 (0.0021) teacher/usage_std 0.3117 (0.3533) nleep/row_max_mean 1510.9548 (1531.9896) nleep/row_max_std 102.8478 (66.9317) nleep/row_min_mean 1487.5498 (1503.9532) lr 1.9823e-03 eta 0:15:34
epoch [5/50] batch [80/160] time 0.111 (0.121) data 0.000 (0.004) loss 1.3490 (1.1639) teacher_loss 0.5333 (0.3498) loss_zs_kd 0.0530 (0.0409) loss_oracle 0.7325 (0.7071) kd_loss 0.8458 (0.8801) acc 87.5000 (89.3359) gate/entropy 1.0826 (1.0857) gate/usage_max 0.4164 (0.4071) gate/usage_min 0.2746 (0.2795) gate/usage_std 0.0604 (0.0540) teacher/entropy 0.0545 (0.0673) teacher/usage_max 0.9194 (0.8153) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.4157 (0.3504) nleep/row_max_mean 1538.0945 (1531.2056) nleep/row_max_std 85.2210 (69.1644) nleep/row_min_mean 1511.6226 (1503.6497) lr 1.9823e-03 eta 0:14:41
epoch [5/50] batch [100/160] time 0.107 (0.118) data 0.000 (0.003) loss 1.1471 (1.1477) teacher_loss 0.3403 (0.3378) loss_zs_kd 0.0253 (0.0396) loss_oracle 0.7484 (0.7048) kd_loss 0.8400 (0.8754) acc 84.3750 (89.3125) gate/entropy 1.0810 (1.0849) gate/usage_max 0.4209 (0.4094) gate/usage_min 0.2724 (0.2783) gate/usage_std 0.0635 (0.0556) teacher/entropy 0.0684 (0.0683) teacher/usage_max 0.8642 (0.8150) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3795 (0.3502) nleep/row_max_mean 1531.1501 (1531.7200) nleep/row_max_std 73.0866 (67.4951) nleep/row_min_mean 1505.3950 (1504.4361) lr 1.9823e-03 eta 0:14:16
epoch [5/50] batch [120/160] time 0.110 (0.116) data 0.000 (0.003) loss 1.2241 (1.1464) teacher_loss 0.4439 (0.3396) loss_zs_kd 0.0425 (0.0394) loss_oracle 0.6924 (0.7035) kd_loss 0.8256 (0.8706) acc 84.3750 (89.2448) gate/entropy 1.0791 (1.0841) gate/usage_max 0.4257 (0.4118) gate/usage_min 0.2700 (0.2771) gate/usage_std 0.0668 (0.0572) teacher/entropy 0.0666 (0.0684) teacher/usage_max 0.8864 (0.8171) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.3938 (0.3513) nleep/row_max_mean 1528.2158 (1531.7151) nleep/row_max_std 57.4396 (66.8543) nleep/row_min_mean 1499.6959 (1504.5483) lr 1.9823e-03 eta 0:13:59
epoch [5/50] batch [140/160] time 0.123 (0.115) data 0.001 (0.002) loss 1.4410 (1.1418) teacher_loss 0.6537 (0.3382) loss_zs_kd 0.0416 (0.0400) loss_oracle 0.7319 (0.6989) kd_loss 0.8011 (0.8683) acc 78.1250 (89.1964) gate/entropy 1.0773 (1.0833) gate/usage_max 0.4301 (0.4141) gate/usage_min 0.2678 (0.2759) gate/usage_std 0.0699 (0.0588) teacher/entropy 0.0732 (0.0676) teacher/usage_max 0.9130 (0.8152) teacher/usage_min 0.0001 (0.0029) teacher/usage_std 0.4114 (0.3501) nleep/row_max_mean 1523.0720 (1531.6583) nleep/row_max_std 65.0560 (66.2597) nleep/row_min_mean 1495.8763 (1504.5738) lr 1.9823e-03 eta 0:13:50
epoch [5/50] batch [160/160] time 0.085 (0.113) data 0.000 (0.002) loss 1.2902 (1.1324) teacher_loss 0.5204 (0.3327) loss_zs_kd 0.0303 (0.0402) loss_oracle 0.6870 (0.6940) kd_loss 0.8221 (0.8652) acc 84.3750 (89.4141) gate/entropy 1.0755 (1.0824) gate/usage_max 0.4345 (0.4164) gate/usage_min 0.2656 (0.2748) gate/usage_std 0.0729 (0.0604) teacher/entropy 0.0764 (0.0685) teacher/usage_max 0.8254 (0.8109) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3551 (0.3476) nleep/row_max_mean 1532.8673 (1531.3628) nleep/row_max_std 43.1458 (65.8392) nleep/row_min_mean 1506.8975 (1504.5062) lr 1.9686e-03 eta 0:13:30
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,809
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,974
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [6/50] batch [20/160] time 0.114 (0.120) data 0.000 (0.015) loss 0.9734 (1.0736) teacher_loss 0.1963 (0.3088) loss_zs_kd 0.0414 (0.0429) loss_oracle 0.6681 (0.6493) kd_loss 0.8448 (0.8374) acc 93.7500 (90.1562) gate/entropy 1.0735 (1.0745) gate/usage_max 0.4390 (0.4367) gate/usage_min 0.2633 (0.2645) gate/usage_std 0.0760 (0.0744) teacher/entropy 0.0668 (0.0675) teacher/usage_max 0.7748 (0.8003) teacher/usage_min 0.0030 (0.0044) teacher/usage_std 0.3247 (0.3413) nleep/row_max_mean 1537.1016 (1531.0213) nleep/row_max_std 51.9546 (60.3708) nleep/row_min_mean 1509.8499 (1505.2398) lr 1.9686e-03 eta 0:14:19
epoch [6/50] batch [40/160] time 0.089 (0.109) data 0.000 (0.007) loss 0.9559 (1.0686) teacher_loss 0.1701 (0.3057) loss_zs_kd 0.0449 (0.0423) loss_oracle 0.6516 (0.6511) kd_loss 0.8751 (0.8324) acc 96.8750 (89.6094) gate/entropy 1.0716 (1.0736) gate/usage_max 0.4431 (0.4388) gate/usage_min 0.2614 (0.2635) gate/usage_std 0.0788 (0.0759) teacher/entropy 0.0197 (0.0651) teacher/usage_max 0.8093 (0.8113) teacher/usage_min 0.0308 (0.0051) teacher/usage_std 0.3407 (0.3474) nleep/row_max_mean 1544.5223 (1527.9191) nleep/row_max_std 44.9408 (63.3301) nleep/row_min_mean 1515.5659 (1501.8378) lr 1.9686e-03 eta 0:13:00
epoch [6/50] batch [60/160] time 0.094 (0.104) data 0.001 (0.005) loss 0.9667 (1.0678) teacher_loss 0.2056 (0.3093) loss_zs_kd 0.0552 (0.0422) loss_oracle 0.6042 (0.6430) kd_loss 0.8627 (0.8318) acc 90.6250 (89.7396) gate/entropy 1.0697 (1.0726) gate/usage_max 0.4471 (0.4409) gate/usage_min 0.2594 (0.2625) gate/usage_std 0.0816 (0.0773) teacher/entropy 0.0592 (0.0664) teacher/usage_max 0.7237 (0.8018) teacher/usage_min 0.0051 (0.0046) teacher/usage_std 0.2966 (0.3422) nleep/row_max_mean 1521.1263 (1527.3320) nleep/row_max_std 72.0592 (64.2573) nleep/row_min_mean 1496.7805 (1501.5169) lr 1.9686e-03 eta 0:12:23
epoch [6/50] batch [80/160] time 0.159 (0.108) data 0.000 (0.004) loss 0.9433 (1.0687) teacher_loss 0.2061 (0.3114) loss_zs_kd 0.0772 (0.0429) loss_oracle 0.5037 (0.6370) kd_loss 0.8936 (0.8346) acc 93.7500 (89.6094) gate/entropy 1.0677 (1.0717) gate/usage_max 0.4512 (0.4429) gate/usage_min 0.2574 (0.2615) gate/usage_std 0.0845 (0.0787) teacher/entropy 0.0632 (0.0641) teacher/usage_max 0.6314 (0.7935) teacher/usage_min 0.0008 (0.0038) teacher/usage_std 0.2586 (0.3378) nleep/row_max_mean 1545.7769 (1527.8070) nleep/row_max_std 56.1566 (62.4677) nleep/row_min_mean 1522.6024 (1502.0444) lr 1.9686e-03 eta 0:12:49
epoch [6/50] batch [100/160] time 0.058 (0.111) data 0.000 (0.003) loss 0.8977 (1.0564) teacher_loss 0.1283 (0.3027) loss_zs_kd 0.0356 (0.0428) loss_oracle 0.5469 (0.6301) kd_loss 0.9561 (0.8345) acc 100.0000 (90.0938) gate/entropy 1.0662 (1.0707) gate/usage_max 0.4543 (0.4449) gate/usage_min 0.2559 (0.2605) gate/usage_std 0.0866 (0.0801) teacher/entropy 0.0576 (0.0674) teacher/usage_max 0.5016 (0.7803) teacher/usage_min 0.0011 (0.0062) teacher/usage_std 0.2349 (0.3304) nleep/row_max_mean 1541.8488 (1528.4034) nleep/row_max_std 25.8803 (61.9654) nleep/row_min_mean 1519.6108 (1502.9510) lr 1.9686e-03 eta 0:13:06
epoch [6/50] batch [120/160] time 0.091 (0.108) data 0.000 (0.003) loss 0.9650 (1.0471) teacher_loss 0.1662 (0.2920) loss_zs_kd 0.0883 (0.0454) loss_oracle 0.6105 (0.6285) kd_loss 0.8988 (0.8363) acc 96.8750 (90.6510) gate/entropy 1.0642 (1.0698) gate/usage_max 0.4581 (0.4468) gate/usage_min 0.2538 (0.2595) gate/usage_std 0.0893 (0.0814) teacher/entropy 0.0597 (0.0682) teacher/usage_max 0.6165 (0.7691) teacher/usage_min 0.0001 (0.0064) teacher/usage_std 0.2541 (0.3243) nleep/row_max_mean 1540.0370 (1527.4469) nleep/row_max_std 44.0120 (61.8278) nleep/row_min_mean 1515.0474 (1502.2399) lr 1.9686e-03 eta 0:12:48
epoch [6/50] batch [140/160] time 0.092 (0.107) data 0.000 (0.002) loss 1.0289 (1.0377) teacher_loss 0.2947 (0.2826) loss_zs_kd 0.0355 (0.0457) loss_oracle 0.5805 (0.6273) kd_loss 0.8523 (0.8373) acc 90.6250 (90.9152) gate/entropy 1.0628 (1.0689) gate/usage_max 0.4606 (0.4486) gate/usage_min 0.2525 (0.2586) gate/usage_std 0.0911 (0.0827) teacher/entropy 0.0478 (0.0676) teacher/usage_max 0.7371 (0.7631) teacher/usage_min 0.0013 (0.0072) teacher/usage_std 0.3047 (0.3208) nleep/row_max_mean 1522.2026 (1527.0159) nleep/row_max_std 56.4317 (62.1102) nleep/row_min_mean 1498.4966 (1501.9558) lr 1.9686e-03 eta 0:12:32
epoch [6/50] batch [160/160] time 0.089 (0.105) data 0.000 (0.002) loss 1.1337 (1.0419) teacher_loss 0.3446 (0.2861) loss_zs_kd 0.0622 (0.0465) loss_oracle 0.6517 (0.6276) kd_loss 0.8644 (0.8375) acc 87.5000 (90.8398) gate/entropy 1.0607 (1.0680) gate/usage_max 0.4644 (0.4503) gate/usage_min 0.2506 (0.2577) gate/usage_std 0.0938 (0.0839) teacher/entropy 0.0500 (0.0689) teacher/usage_max 0.6988 (0.7553) teacher/usage_min 0.0002 (0.0087) teacher/usage_std 0.2861 (0.3163) nleep/row_max_mean 1535.8943 (1526.7959) nleep/row_max_std 27.8795 (61.2784) nleep/row_min_mean 1511.2838 (1501.8669) lr 1.9511e-03 eta 0:12:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,805
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.2%
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [7/50] batch [20/160] time 0.086 (0.107) data 0.000 (0.016) loss 1.0520 (0.9757) teacher_loss 0.2760 (0.2098) loss_zs_kd 0.0586 (0.0520) loss_oracle 0.6338 (0.6438) kd_loss 0.8597 (0.8360) acc 90.6250 (94.5312) gate/entropy 1.0590 (1.0599) gate/usage_max 0.4676 (0.4659) gate/usage_min 0.2491 (0.2499) gate/usage_std 0.0960 (0.0948) teacher/entropy 0.0777 (0.0690) teacher/usage_max 0.6515 (0.7215) teacher/usage_min 0.0236 (0.0272) teacher/usage_std 0.2564 (0.2923) nleep/row_max_mean 1529.0266 (1526.4174) nleep/row_max_std 47.1503 (55.2852) nleep/row_min_mean 1505.8477 (1502.1309) lr 1.9511e-03 eta 0:12:34
epoch [7/50] batch [40/160] time 0.097 (0.103) data 0.000 (0.008) loss 1.1739 (1.0001) teacher_loss 0.4123 (0.2400) loss_zs_kd 0.0448 (0.0510) loss_oracle 0.6744 (0.6336) kd_loss 0.8039 (0.8355) acc 87.5000 (92.6562) gate/entropy 1.0572 (1.0590) gate/usage_max 0.4707 (0.4675) gate/usage_min 0.2477 (0.2492) gate/usage_std 0.0981 (0.0959) teacher/entropy 0.0571 (0.0753) teacher/usage_max 0.7976 (0.7066) teacher/usage_min 0.0292 (0.0270) teacher/usage_std 0.3335 (0.2856) nleep/row_max_mean 1521.4260 (1524.8813) nleep/row_max_std 84.1746 (58.2647) nleep/row_min_mean 1492.3353 (1500.6258) lr 1.9511e-03 eta 0:12:01
epoch [7/50] batch [60/160] time 0.100 (0.099) data 0.001 (0.005) loss 0.9557 (0.9969) teacher_loss 0.2298 (0.2384) loss_zs_kd 0.0694 (0.0519) loss_oracle 0.5769 (0.6301) kd_loss 0.8055 (0.8350) acc 90.6250 (92.3438) gate/entropy 1.0556 (1.0581) gate/usage_max 0.4735 (0.4691) gate/usage_min 0.2462 (0.2484) gate/usage_std 0.1001 (0.0970) teacher/entropy 0.1008 (0.0753) teacher/usage_max 0.7092 (0.7046) teacher/usage_min 0.0462 (0.0283) teacher/usage_std 0.2778 (0.2848) nleep/row_max_mean 1527.5336 (1524.1682) nleep/row_max_std 49.6042 (60.5008) nleep/row_min_mean 1502.8757 (1499.4656) lr 1.9511e-03 eta 0:11:28
epoch [7/50] batch [80/160] time 0.094 (0.098) data 0.000 (0.004) loss 1.0531 (0.9909) teacher_loss 0.3026 (0.2330) loss_zs_kd 0.0574 (0.0547) loss_oracle 0.6164 (0.6262) kd_loss 0.8272 (0.8350) acc 93.7500 (92.9297) gate/entropy 1.0538 (1.0572) gate/usage_max 0.4764 (0.4707) gate/usage_min 0.2448 (0.2476) gate/usage_std 0.1021 (0.0981) teacher/entropy 0.0905 (0.0778) teacher/usage_max 0.6808 (0.6977) teacher/usage_min 0.0427 (0.0305) teacher/usage_std 0.2636 (0.2800) nleep/row_max_mean 1523.9680 (1523.6386) nleep/row_max_std 64.4876 (61.3587) nleep/row_min_mean 1498.0089 (1498.9126) lr 1.9511e-03 eta 0:11:19
epoch [7/50] batch [100/160] time 0.074 (0.096) data 0.000 (0.003) loss 0.8205 (0.9890) teacher_loss 0.1021 (0.2334) loss_zs_kd 0.0624 (0.0557) loss_oracle 0.5564 (0.6222) kd_loss 0.8181 (0.8334) acc 96.8750 (92.8750) gate/entropy 1.0518 (1.0563) gate/usage_max 0.4797 (0.4722) gate/usage_min 0.2432 (0.2469) gate/usage_std 0.1044 (0.0991) teacher/entropy 0.1160 (0.0795) teacher/usage_max 0.6458 (0.6951) teacher/usage_min 0.0421 (0.0313) teacher/usage_std 0.2469 (0.2785) nleep/row_max_mean 1526.0684 (1522.6676) nleep/row_max_std 72.3104 (62.9095) nleep/row_min_mean 1503.0692 (1497.8559) lr 1.9511e-03 eta 0:11:03
epoch [7/50] batch [120/160] time 0.100 (0.095) data 0.000 (0.003) loss 0.8586 (0.9873) teacher_loss 0.1064 (0.2315) loss_zs_kd 0.0498 (0.0568) loss_oracle 0.6290 (0.6178) kd_loss 0.8256 (0.8370) acc 96.8750 (92.9948) gate/entropy 1.0508 (1.0555) gate/usage_max 0.4815 (0.4736) gate/usage_min 0.2423 (0.2462) gate/usage_std 0.1056 (0.1002) teacher/entropy 0.0641 (0.0786) teacher/usage_max 0.7150 (0.6885) teacher/usage_min 0.0017 (0.0340) teacher/usage_std 0.2933 (0.2743) nleep/row_max_mean 1503.9240 (1522.3605) nleep/row_max_std 91.2261 (63.5385) nleep/row_min_mean 1481.7778 (1497.4350) lr 1.9511e-03 eta 0:10:58
epoch [7/50] batch [140/160] time 0.100 (0.096) data 0.000 (0.002) loss 0.9518 (0.9758) teacher_loss 0.2022 (0.2198) loss_zs_kd 0.0561 (0.0580) loss_oracle 0.5479 (0.6158) kd_loss 0.8951 (0.8382) acc 96.8750 (93.4598) gate/entropy 1.0492 (1.0546) gate/usage_max 0.4840 (0.4750) gate/usage_min 0.2410 (0.2455) gate/usage_std 0.1075 (0.1011) teacher/entropy 0.0606 (0.0783) teacher/usage_max 0.6016 (0.6851) teacher/usage_min 0.0452 (0.0351) teacher/usage_std 0.2276 (0.2725) nleep/row_max_mean 1496.3165 (1522.4437) nleep/row_max_std 79.0576 (63.7215) nleep/row_min_mean 1473.3584 (1497.4469) lr 1.9511e-03 eta 0:10:59
epoch [7/50] batch [160/160] time 0.087 (0.095) data 0.000 (0.002) loss 1.0380 (0.9752) teacher_loss 0.2267 (0.2155) loss_zs_kd 0.0831 (0.0586) loss_oracle 0.6126 (0.6121) kd_loss 0.9268 (0.8486) acc 93.7500 (93.6328) gate/entropy 1.0475 (1.0538) gate/usage_max 0.4866 (0.4763) gate/usage_min 0.2394 (0.2448) gate/usage_std 0.1093 (0.1020) teacher/entropy 0.0401 (0.0752) teacher/usage_max 0.5851 (0.6716) teacher/usage_min 0.0665 (0.0367) teacher/usage_std 0.2120 (0.2664) nleep/row_max_mean 1523.7263 (1522.4827) nleep/row_max_std 57.2884 (63.6046) nleep/row_min_mean 1499.6306 (1497.5230) lr 1.9298e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.6%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [8/50] batch [20/160] time 0.106 (0.130) data 0.000 (0.018) loss 1.0226 (0.9694) teacher_loss 0.1764 (0.1713) loss_zs_kd 0.0819 (0.0710) loss_oracle 0.5861 (0.6096) kd_loss 1.0244 (0.9155) acc 93.7500 (95.9375) gate/entropy 1.0467 (1.0471) gate/usage_max 0.4878 (0.4872) gate/usage_min 0.2385 (0.2390) gate/usage_std 0.1101 (0.1097) teacher/entropy 0.0605 (0.0567) teacher/usage_max 0.5727 (0.5830) teacher/usage_min 0.0520 (0.0461) teacher/usage_std 0.2146 (0.2248) nleep/row_max_mean 1518.3787 (1523.2939) nleep/row_max_std 70.0013 (55.7578) nleep/row_min_mean 1496.4833 (1498.5070) lr 1.9298e-03 eta 0:14:48
epoch [8/50] batch [40/160] time 0.091 (0.116) data 0.000 (0.009) loss 0.9660 (0.9561) teacher_loss 0.1424 (0.1512) loss_zs_kd 0.0828 (0.0723) loss_oracle 0.6408 (0.6144) kd_loss 0.9237 (0.9230) acc 96.8750 (96.1719) gate/entropy 1.0454 (1.0465) gate/usage_max 0.4896 (0.4880) gate/usage_min 0.2371 (0.2384) gate/usage_std 0.1115 (0.1103) teacher/entropy 0.0644 (0.0483) teacher/usage_max 0.5313 (0.5862) teacher/usage_min 0.0069 (0.0424) teacher/usage_std 0.2326 (0.2288) nleep/row_max_mean 1529.0941 (1522.8301) nleep/row_max_std 44.6946 (59.7971) nleep/row_min_mean 1501.8843 (1497.7103) lr 1.9298e-03 eta 0:13:10
epoch [8/50] batch [60/160] time 0.110 (0.112) data 0.001 (0.006) loss 0.9153 (0.9441) teacher_loss 0.0579 (0.1371) loss_zs_kd 0.0785 (0.0718) loss_oracle 0.6132 (0.6079) kd_loss 1.0232 (0.9343) acc 100.0000 (96.4583) gate/entropy 1.0448 (1.0461) gate/usage_max 0.4904 (0.4887) gate/usage_min 0.2362 (0.2378) gate/usage_std 0.1121 (0.1108) teacher/entropy 0.0038 (0.0430) teacher/usage_max 0.4995 (0.5746) teacher/usage_min 0.0316 (0.0411) teacher/usage_std 0.2137 (0.2257) nleep/row_max_mean 1527.9590 (1523.3383) nleep/row_max_std 48.4538 (61.1997) nleep/row_min_mean 1500.7966 (1497.8571) lr 1.9298e-03 eta 0:12:44
epoch [8/50] batch [80/160] time 0.129 (0.115) data 0.000 (0.005) loss 0.8491 (0.9419) teacher_loss 0.0192 (0.1303) loss_zs_kd 0.0659 (0.0720) loss_oracle 0.5443 (0.6124) kd_loss 1.0497 (0.9388) acc 100.0000 (96.5234) gate/entropy 1.0441 (1.0457) gate/usage_max 0.4914 (0.4892) gate/usage_min 0.2352 (0.2373) gate/usage_std 0.1128 (0.1112) teacher/entropy 0.0471 (0.0420) teacher/usage_max 0.4896 (0.5713) teacher/usage_min 0.1356 (0.0425) teacher/usage_std 0.1475 (0.2238) nleep/row_max_mean 1534.0791 (1522.8786) nleep/row_max_std 47.6959 (62.6461) nleep/row_min_mean 1508.6663 (1497.0768) lr 1.9298e-03 eta 0:13:04
epoch [8/50] batch [100/160] time 0.130 (0.117) data 0.000 (0.004) loss 0.8870 (0.9393) teacher_loss 0.0319 (0.1276) loss_zs_kd 0.0670 (0.0717) loss_oracle 0.5960 (0.6085) kd_loss 1.0471 (0.9432) acc 100.0000 (96.5312) gate/entropy 1.0437 (1.0453) gate/usage_max 0.4918 (0.4897) gate/usage_min 0.2343 (0.2368) gate/usage_std 0.1132 (0.1116) teacher/entropy 0.0290 (0.0398) teacher/usage_max 0.4761 (0.5711) teacher/usage_min 0.1176 (0.0429) teacher/usage_std 0.1552 (0.2232) nleep/row_max_mean 1524.5931 (1522.2264) nleep/row_max_std 50.0113 (63.3808) nleep/row_min_mean 1497.3696 (1496.0782) lr 1.9298e-03 eta 0:13:11
epoch [8/50] batch [120/160] time 0.104 (0.118) data 0.000 (0.003) loss 0.9276 (0.9350) teacher_loss 0.0704 (0.1230) loss_zs_kd 0.1090 (0.0731) loss_oracle 0.6053 (0.6092) kd_loss 0.9999 (0.9416) acc 96.8750 (96.6927) gate/entropy 1.0429 (1.0449) gate/usage_max 0.4929 (0.4902) gate/usage_min 0.2332 (0.2363) gate/usage_std 0.1140 (0.1120) teacher/entropy 0.0278 (0.0400) teacher/usage_max 0.4757 (0.5702) teacher/usage_min 0.0556 (0.0438) teacher/usage_std 0.1964 (0.2227) nleep/row_max_mean 1534.0337 (1521.7553) nleep/row_max_std 32.1738 (62.8002) nleep/row_min_mean 1507.3234 (1495.4039) lr 1.9298e-03 eta 0:13:20
epoch [8/50] batch [140/160] time 0.106 (0.116) data 0.000 (0.003) loss 0.8932 (0.9333) teacher_loss 0.0889 (0.1200) loss_zs_kd 0.0740 (0.0740) loss_oracle 0.6447 (0.6110) kd_loss 0.8898 (0.9416) acc 96.8750 (96.8304) gate/entropy 1.0420 (1.0446) gate/usage_max 0.4941 (0.4907) gate/usage_min 0.2320 (0.2357) gate/usage_std 0.1149 (0.1123) teacher/entropy 0.0151 (0.0402) teacher/usage_max 0.6874 (0.5688) teacher/usage_min 0.0979 (0.0443) teacher/usage_std 0.2549 (0.2224) nleep/row_max_mean 1529.5763 (1521.4710) nleep/row_max_std 69.1564 (63.1328) nleep/row_min_mean 1502.9885 (1495.0313) lr 1.9298e-03 eta 0:13:01
epoch [8/50] batch [160/160] time 0.098 (0.114) data 0.000 (0.002) loss 0.8970 (0.9315) teacher_loss 0.0286 (0.1176) loss_zs_kd 0.0676 (0.0747) loss_oracle 0.6200 (0.6109) kd_loss 1.0492 (0.9422) acc 100.0000 (96.8750) gate/entropy 1.0415 (1.0443) gate/usage_max 0.4947 (0.4911) gate/usage_min 0.2312 (0.2353) gate/usage_std 0.1155 (0.1126) teacher/entropy 0.0309 (0.0397) teacher/usage_max 0.5851 (0.5692) teacher/usage_min 0.0403 (0.0448) teacher/usage_std 0.2243 (0.2220) nleep/row_max_mean 1521.9854 (1521.0873) nleep/row_max_std 78.8414 (63.1966) nleep/row_min_mean 1493.9766 (1494.4870) lr 1.9048e-03 eta 0:12:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,811
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,893
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 87.4%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [9/50] batch [20/160] time 0.087 (0.104) data 0.000 (0.015) loss 0.8806 (0.9157) teacher_loss 0.0797 (0.0987) loss_zs_kd 0.0775 (0.0772) loss_oracle 0.6395 (0.5959) kd_loss 0.8846 (0.9609) acc 96.8750 (97.8125) gate/entropy 1.0412 (1.0415) gate/usage_max 0.4951 (0.4947) gate/usage_min 0.2305 (0.2309) gate/usage_std 0.1158 (0.1155) teacher/entropy 0.0246 (0.0310) teacher/usage_max 0.6587 (0.5521) teacher/usage_min 0.0290 (0.0436) teacher/usage_std 0.2575 (0.2174) nleep/row_max_mean 1512.1868 (1516.9604) nleep/row_max_std 76.6835 (64.1064) nleep/row_min_mean 1487.2917 (1489.6744) lr 1.9048e-03 eta 0:11:36
epoch [9/50] batch [40/160] time 0.104 (0.100) data 0.000 (0.008) loss 0.9240 (0.9318) teacher_loss 0.1239 (0.1183) loss_zs_kd 0.0892 (0.0745) loss_oracle 0.5861 (0.5929) kd_loss 0.9247 (0.9596) acc 93.7500 (97.0312) gate/entropy 1.0409 (1.0413) gate/usage_max 0.4954 (0.4949) gate/usage_min 0.2298 (0.2306) gate/usage_std 0.1161 (0.1157) teacher/entropy 0.0917 (0.0377) teacher/usage_max 0.4943 (0.5544) teacher/usage_min 0.0966 (0.0584) teacher/usage_std 0.1710 (0.2105) nleep/row_max_mean 1526.7240 (1517.4360) nleep/row_max_std 49.8973 (61.4304) nleep/row_min_mean 1499.9545 (1490.1571) lr 1.9048e-03 eta 0:11:05
epoch [9/50] batch [60/160] time 0.096 (0.099) data 0.001 (0.005) loss 0.8858 (0.9333) teacher_loss 0.0694 (0.1260) loss_zs_kd 0.0800 (0.0753) loss_oracle 0.6218 (0.5878) kd_loss 0.9309 (0.9516) acc 96.8750 (96.6667) gate/entropy 1.0402 (1.0411) gate/usage_max 0.4962 (0.4952) gate/usage_min 0.2289 (0.2302) gate/usage_std 0.1167 (0.1159) teacher/entropy 0.0437 (0.0454) teacher/usage_max 0.5570 (0.5502) teacher/usage_min 0.0729 (0.0622) teacher/usage_std 0.1993 (0.2074) nleep/row_max_mean 1518.9851 (1516.1786) nleep/row_max_std 71.3873 (62.1616) nleep/row_min_mean 1490.1257 (1488.9618) lr 1.9048e-03 eta 0:10:57
epoch [9/50] batch [80/160] time 0.093 (0.099) data 0.000 (0.004) loss 0.8368 (0.9272) teacher_loss 0.0767 (0.1231) loss_zs_kd 0.0732 (0.0753) loss_oracle 0.5845 (0.5824) kd_loss 0.8626 (0.9505) acc 96.8750 (96.7969) gate/entropy 1.0399 (1.0408) gate/usage_max 0.4965 (0.4954) gate/usage_min 0.2284 (0.2298) gate/usage_std 0.1170 (0.1161) teacher/entropy 0.0773 (0.0496) teacher/usage_max 0.6105 (0.5433) teacher/usage_min 0.0543 (0.0660) teacher/usage_std 0.2271 (0.2038) nleep/row_max_mean 1512.5759 (1515.8361) nleep/row_max_std 58.0028 (62.0740) nleep/row_min_mean 1485.4990 (1488.9044) lr 1.9048e-03 eta 0:10:59
epoch [9/50] batch [100/160] time 0.082 (0.104) data 0.000 (0.003) loss 0.8418 (0.9218) teacher_loss 0.0627 (0.1207) loss_zs_kd 0.0593 (0.0735) loss_oracle 0.5411 (0.5776) kd_loss 0.9578 (0.9510) acc 96.8750 (96.8750) gate/entropy 1.0395 (1.0406) gate/usage_max 0.4970 (0.4957) gate/usage_min 0.2277 (0.2294) gate/usage_std 0.1174 (0.1163) teacher/entropy 0.0901 (0.0519) teacher/usage_max 0.4663 (0.5407) teacher/usage_min 0.0955 (0.0726) teacher/usage_std 0.1685 (0.1999) nleep/row_max_mean 1521.4807 (1515.3781) nleep/row_max_std 43.7443 (62.2087) nleep/row_min_mean 1496.1799 (1488.7563) lr 1.9048e-03 eta 0:11:26
epoch [9/50] batch [120/160] time 0.164 (0.108) data 0.000 (0.003) loss 0.8600 (0.9244) teacher_loss 0.0618 (0.1205) loss_zs_kd 0.0991 (0.0750) loss_oracle 0.5633 (0.5781) kd_loss 0.9340 (0.9547) acc 100.0000 (96.7969) gate/entropy 1.0390 (1.0404) gate/usage_max 0.4977 (0.4960) gate/usage_min 0.2270 (0.2291) gate/usage_std 0.1179 (0.1165) teacher/entropy 0.0605 (0.0527) teacher/usage_max 0.5276 (0.5379) teacher/usage_min 0.0914 (0.0740) teacher/usage_std 0.1812 (0.1982) nleep/row_max_mean 1507.8060 (1515.1507) nleep/row_max_std 76.3576 (62.3550) nleep/row_min_mean 1481.9471 (1488.5506) lr 1.9048e-03 eta 0:11:55
epoch [9/50] batch [140/160] time 0.098 (0.109) data 0.000 (0.002) loss 0.9000 (0.9207) teacher_loss 0.0613 (0.1200) loss_zs_kd 0.0817 (0.0757) loss_oracle 0.5387 (0.5704) kd_loss 1.0570 (0.9554) acc 96.8750 (96.7411) gate/entropy 1.0391 (1.0402) gate/usage_max 0.4974 (0.4962) gate/usage_min 0.2268 (0.2288) gate/usage_std 0.1177 (0.1167) teacher/entropy 0.0517 (0.0565) teacher/usage_max 0.4387 (0.5334) teacher/usage_min 0.1928 (0.0804) teacher/usage_std 0.1034 (0.1934) nleep/row_max_mean 1509.2709 (1514.8498) nleep/row_max_std 60.9771 (62.1804) nleep/row_min_mean 1480.6440 (1488.3103) lr 1.9048e-03 eta 0:11:58
epoch [9/50] batch [160/160] time 0.106 (0.108) data 0.000 (0.002) loss 0.8855 (0.9165) teacher_loss 0.1321 (0.1179) loss_zs_kd 0.0777 (0.0758) loss_oracle 0.4884 (0.5614) kd_loss 0.9408 (0.9600) acc 93.7500 (96.8164) gate/entropy 1.0388 (1.0400) gate/usage_max 0.4977 (0.4964) gate/usage_min 0.2262 (0.2285) gate/usage_std 0.1180 (0.1169) teacher/entropy 0.0926 (0.0590) teacher/usage_max 0.4858 (0.5269) teacher/usage_min 0.1625 (0.0881) teacher/usage_std 0.1326 (0.1877) nleep/row_max_mean 1500.6887 (1514.4053) nleep/row_max_std 71.3383 (62.6376) nleep/row_min_mean 1476.6805 (1487.9147) lr 1.8763e-03 eta 0:11:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,816
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,836
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 86.3%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [10/50] batch [20/160] time 0.095 (0.114) data 0.000 (0.013) loss 0.8944 (0.9074) teacher_loss 0.0755 (0.1157) loss_zs_kd 0.0680 (0.0823) loss_oracle 0.5309 (0.4933) kd_loss 1.0388 (1.0078) acc 96.8750 (96.5625) gate/entropy 1.0383 (1.0387) gate/usage_max 0.4984 (0.4979) gate/usage_min 0.2257 (0.2260) gate/usage_std 0.1185 (0.1181) teacher/entropy 0.1081 (0.0889) teacher/usage_max 0.4276 (0.4575) teacher/usage_min 0.2497 (0.1850) teacher/usage_std 0.0730 (0.1172) nleep/row_max_mean 1539.0690 (1514.5182) nleep/row_max_std 29.8140 (58.0716) nleep/row_min_mean 1510.6365 (1488.1566) lr 1.8763e-03 eta 0:12:23
epoch [10/50] batch [40/160] time 0.099 (0.104) data 0.000 (0.007) loss 0.9823 (0.9096) teacher_loss 0.1937 (0.1122) loss_zs_kd 0.0774 (0.0787) loss_oracle 0.5335 (0.4992) kd_loss 0.9661 (1.0169) acc 90.6250 (96.6406) gate/entropy 1.0384 (1.0386) gate/usage_max 0.4981 (0.4979) gate/usage_min 0.2255 (0.2259) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.0973 (0.0931) teacher/usage_max 0.4635 (0.4559) teacher/usage_min 0.2506 (0.1948) teacher/usage_std 0.0932 (0.1120) nleep/row_max_mean 1506.0405 (1513.3007) nleep/row_max_std 84.6963 (61.6263) nleep/row_min_mean 1483.4238 (1486.7350) lr 1.8763e-03 eta 0:11:18
epoch [10/50] batch [60/160] time 0.098 (0.102) data 0.000 (0.004) loss 0.8424 (0.9154) teacher_loss 0.0684 (0.1112) loss_zs_kd 0.0771 (0.0794) loss_oracle 0.4667 (0.5073) kd_loss 1.0040 (1.0216) acc 100.0000 (96.8750) gate/entropy 1.0385 (1.0386) gate/usage_max 0.4979 (0.4979) gate/usage_min 0.2253 (0.2258) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.1276 (0.0889) teacher/usage_max 0.3917 (0.4573) teacher/usage_min 0.2579 (0.1966) teacher/usage_std 0.0559 (0.1112) nleep/row_max_mean 1508.6688 (1513.4312) nleep/row_max_std 65.9621 (61.7073) nleep/row_min_mean 1483.1123 (1486.6943) lr 1.8763e-03 eta 0:11:01
epoch [10/50] batch [80/160] time 0.103 (0.100) data 0.000 (0.003) loss 1.0911 (0.9205) teacher_loss 0.2208 (0.1110) loss_zs_kd 0.1014 (0.0810) loss_oracle 0.4817 (0.5089) kd_loss 1.1574 (1.0290) acc 96.8750 (96.9531) gate/entropy 1.0384 (1.0386) gate/usage_max 0.4980 (0.4979) gate/usage_min 0.2251 (0.2257) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.0585 (0.0839) teacher/usage_max 0.3759 (0.4598) teacher/usage_min 0.2490 (0.1971) teacher/usage_std 0.0596 (0.1119) nleep/row_max_mean 1523.6594 (1513.3221) nleep/row_max_std 50.9370 (61.0358) nleep/row_min_mean 1497.1802 (1486.6750) lr 1.8763e-03 eta 0:10:49
epoch [10/50] batch [100/160] time 0.087 (0.099) data 0.000 (0.003) loss 0.8079 (0.9166) teacher_loss 0.0382 (0.1052) loss_zs_kd 0.1070 (0.0827) loss_oracle 0.4823 (0.5066) kd_loss 0.9502 (1.0334) acc 100.0000 (97.2500) gate/entropy 1.0385 (1.0386) gate/usage_max 0.4978 (0.4978) gate/usage_min 0.2249 (0.2255) gate/usage_std 0.1182 (0.1182) teacher/entropy 0.1517 (0.0821) teacher/usage_max 0.4101 (0.4638) teacher/usage_min 0.2774 (0.1979) teacher/usage_std 0.0561 (0.1134) nleep/row_max_mean 1515.1560 (1513.7934) nleep/row_max_std 62.1122 (60.3891) nleep/row_min_mean 1490.0479 (1487.1841) lr 1.8763e-03 eta 0:10:39
epoch [10/50] batch [120/160] time 0.117 (0.102) data 0.000 (0.002) loss 0.9603 (0.9216) teacher_loss 0.1323 (0.1092) loss_zs_kd 0.1093 (0.0830) loss_oracle 0.4655 (0.5043) kd_loss 1.0813 (1.0376) acc 96.8750 (97.0833) gate/entropy 1.0383 (1.0386) gate/usage_max 0.4980 (0.4978) gate/usage_min 0.2245 (0.2254) gate/usage_std 0.1185 (0.1182) teacher/entropy 0.0643 (0.0816) teacher/usage_max 0.4078 (0.4625) teacher/usage_min 0.2633 (0.2015) teacher/usage_std 0.0591 (0.1111) nleep/row_max_mean 1526.0724 (1513.7438) nleep/row_max_std 63.1345 (60.9365) nleep/row_min_mean 1497.9414 (1487.1464) lr 1.8763e-03 eta 0:10:57
epoch [10/50] batch [140/160] time 0.162 (0.104) data 0.000 (0.002) loss 0.8574 (0.9244) teacher_loss 0.0436 (0.1038) loss_zs_kd 0.0933 (0.0838) loss_oracle 0.4984 (0.5115) kd_loss 1.0358 (1.0459) acc 100.0000 (97.2768) gate/entropy 1.0391 (1.0386) gate/usage_max 0.4968 (0.4978) gate/usage_min 0.2248 (0.2253) gate/usage_std 0.1176 (0.1182) teacher/entropy 0.0882 (0.0790) teacher/usage_max 0.4255 (0.4646) teacher/usage_min 0.2250 (0.2028) teacher/usage_std 0.0827 (0.1115) nleep/row_max_mean 1496.4636 (1514.0674) nleep/row_max_std 82.6238 (61.0112) nleep/row_min_mean 1471.9535 (1487.2724) lr 1.8763e-03 eta 0:11:06
epoch [10/50] batch [160/160] time 0.075 (0.106) data 0.000 (0.002) loss 1.0436 (0.9327) teacher_loss 0.1656 (0.1086) loss_zs_kd 0.0725 (0.0854) loss_oracle 0.6224 (0.5101) kd_loss 1.0611 (1.0528) acc 93.7500 (97.1484) gate/entropy 1.0390 (1.0386) gate/usage_max 0.4967 (0.4977) gate/usage_min 0.2245 (0.2252) gate/usage_std 0.1177 (0.1181) teacher/entropy 0.1043 (0.0782) teacher/usage_max 0.3445 (0.4657) teacher/usage_min 0.3224 (0.2042) teacher/usage_std 0.0090 (0.1115) nleep/row_max_mean 1512.0444 (1513.4849) nleep/row_max_std 78.6297 (61.8443) nleep/row_min_mean 1484.8450 (1486.6288) lr 1.8443e-03 eta 0:11:16
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,847
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 86.5%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [11/50] batch [20/160] time 0.108 (0.120) data 0.000 (0.013) loss 0.9096 (0.9883) teacher_loss 0.0485 (0.1146) loss_zs_kd 0.0775 (0.0758) loss_oracle 0.4619 (0.5274) kd_loss 1.1828 (1.1441) acc 100.0000 (97.0312) gate/entropy 1.0395 (1.0393) gate/usage_max 0.4961 (0.4963) gate/usage_min 0.2248 (0.2247) gate/usage_std 0.1172 (0.1174) teacher/entropy 0.0233 (0.0697) teacher/usage_max 0.4366 (0.4556) teacher/usage_min 0.2442 (0.2225) teacher/usage_std 0.0792 (0.1003) nleep/row_max_mean 1512.8152 (1516.0096) nleep/row_max_std 70.2982 (58.0086) nleep/row_min_mean 1484.4019 (1488.4300) lr 1.8443e-03 eta 0:12:44
epoch [11/50] batch [40/160] time 0.095 (0.110) data 0.000 (0.007) loss 0.8830 (0.9890) teacher_loss 0.0331 (0.1184) loss_zs_kd 0.0821 (0.0770) loss_oracle 0.4309 (0.5195) kd_loss 1.1870 (1.1447) acc 100.0000 (97.3438) gate/entropy 1.0400 (1.0396) gate/usage_max 0.4954 (0.4960) gate/usage_min 0.2253 (0.2249) gate/usage_std 0.1167 (0.1171) teacher/entropy 0.1056 (0.0736) teacher/usage_max 0.5302 (0.4554) teacher/usage_min 0.1062 (0.2181) teacher/usage_std 0.1744 (0.1018) nleep/row_max_mean 1515.9524 (1515.3720) nleep/row_max_std 61.2800 (59.3964) nleep/row_min_mean 1488.1160 (1487.6832) lr 1.8443e-03 eta 0:11:39
epoch [11/50] batch [60/160] time 0.104 (0.108) data 0.001 (0.005) loss 0.9104 (0.9995) teacher_loss 0.0439 (0.1192) loss_zs_kd 0.0774 (0.0761) loss_oracle 0.5616 (0.5429) kd_loss 1.0940 (1.1415) acc 100.0000 (97.3958) gate/entropy 1.0405 (1.0398) gate/usage_max 0.4946 (0.4957) gate/usage_min 0.2258 (0.2251) gate/usage_std 0.1161 (0.1169) teacher/entropy 0.0787 (0.0767) teacher/usage_max 0.5342 (0.4507) teacher/usage_min 0.2095 (0.2216) teacher/usage_std 0.1433 (0.0984) nleep/row_max_mean 1494.3777 (1513.4951) nleep/row_max_std 81.7578 (62.1804) nleep/row_min_mean 1468.0361 (1485.8463) lr 1.8443e-03 eta 0:11:21
epoch [11/50] batch [80/160] time 0.106 (0.108) data 0.000 (0.004) loss 1.1039 (1.0075) teacher_loss 0.2284 (0.1160) loss_zs_kd 0.0671 (0.0775) loss_oracle 0.6223 (0.5645) kd_loss 1.0617 (1.1412) acc 93.7500 (97.3438) gate/entropy 1.0410 (1.0400) gate/usage_max 0.4939 (0.4953) gate/usage_min 0.2261 (0.2253) gate/usage_std 0.1157 (0.1167) teacher/entropy 0.1760 (0.0771) teacher/usage_max 0.4722 (0.4526) teacher/usage_min 0.2410 (0.2186) teacher/usage_std 0.1000 (0.1000) nleep/row_max_mean 1500.0083 (1512.2245) nleep/row_max_std 79.6177 (63.6428) nleep/row_min_mean 1473.6741 (1484.3879) lr 1.8443e-03 eta 0:11:22
epoch [11/50] batch [100/160] time 0.112 (0.110) data 0.000 (0.003) loss 0.9478 (1.0063) teacher_loss 0.0731 (0.1175) loss_zs_kd 0.0779 (0.0760) loss_oracle 0.4858 (0.5605) kd_loss 1.1858 (1.1411) acc 100.0000 (97.3750) gate/entropy 1.0414 (1.0403) gate/usage_max 0.4933 (0.4949) gate/usage_min 0.2265 (0.2255) gate/usage_std 0.1152 (0.1164) teacher/entropy 0.1007 (0.0838) teacher/usage_max 0.5200 (0.4553) teacher/usage_min 0.1707 (0.2111) teacher/usage_std 0.1437 (0.1041) nleep/row_max_mean 1505.3356 (1511.3590) nleep/row_max_std 74.4389 (64.0989) nleep/row_min_mean 1480.5107 (1483.2987) lr 1.8443e-03 eta 0:11:30
epoch [11/50] batch [120/160] time 0.103 (0.108) data 0.000 (0.002) loss 1.0087 (1.0052) teacher_loss 0.0799 (0.1157) loss_zs_kd 0.0720 (0.0752) loss_oracle 0.6297 (0.5591) kd_loss 1.1559 (1.1448) acc 100.0000 (97.3698) gate/entropy 1.0421 (1.0405) gate/usage_max 0.4923 (0.4946) gate/usage_min 0.2271 (0.2258) gate/usage_std 0.1145 (0.1161) teacher/entropy 0.0855 (0.0854) teacher/usage_max 0.4259 (0.4589) teacher/usage_min 0.2120 (0.2050) teacher/usage_std 0.0897 (0.1083) nleep/row_max_mean 1506.8453 (1511.3949) nleep/row_max_std 69.3021 (63.9476) nleep/row_min_mean 1477.3237 (1483.0530) lr 1.8443e-03 eta 0:11:20
epoch [11/50] batch [140/160] time 0.125 (0.111) data 0.000 (0.002) loss 1.1067 (1.0096) teacher_loss 0.1548 (0.1147) loss_zs_kd 0.1077 (0.0747) loss_oracle 0.6871 (0.5672) kd_loss 1.1091 (1.1478) acc 96.8750 (97.4554) gate/entropy 1.0426 (1.0408) gate/usage_max 0.4916 (0.4942) gate/usage_min 0.2278 (0.2260) gate/usage_std 0.1140 (0.1158) teacher/entropy 0.1429 (0.0869) teacher/usage_max 0.4916 (0.4633) teacher/usage_min 0.1627 (0.2002) teacher/usage_std 0.1346 (0.1123) nleep/row_max_mean 1507.6508 (1510.9739) nleep/row_max_std 58.9597 (63.7913) nleep/row_min_mean 1480.2617 (1482.7665) lr 1.8443e-03 eta 0:11:32
epoch [11/50] batch [160/160] time 0.132 (0.111) data 0.000 (0.002) loss 0.9221 (1.0126) teacher_loss 0.0536 (0.1180) loss_zs_kd 0.0672 (0.0742) loss_oracle 0.5715 (0.5657) kd_loss 1.0985 (1.1494) acc 100.0000 (97.3828) gate/entropy 1.0431 (1.0411) gate/usage_max 0.4911 (0.4938) gate/usage_min 0.2285 (0.2263) gate/usage_std 0.1135 (0.1156) teacher/entropy 0.0747 (0.0879) teacher/usage_max 0.4243 (0.4640) teacher/usage_min 0.2826 (0.1971) teacher/usage_std 0.0644 (0.1141) nleep/row_max_mean 1509.8364 (1510.9441) nleep/row_max_std 60.6236 (63.1216) nleep/row_min_mean 1483.5651 (1482.7140) lr 1.8090e-03 eta 0:11:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,896
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 87.4%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [12/50] batch [20/160] time 0.095 (0.111) data 0.000 (0.013) loss 0.9656 (1.0085) teacher_loss 0.0992 (0.1357) loss_zs_kd 0.0794 (0.0699) loss_oracle 0.5370 (0.5132) kd_loss 1.1164 (1.1625) acc 93.7500 (96.2500) gate/entropy 1.0433 (1.0433) gate/usage_max 0.4909 (0.4908) gate/usage_min 0.2289 (0.2287) gate/usage_std 0.1134 (0.1134) teacher/entropy 0.0723 (0.0969) teacher/usage_max 0.4393 (0.4882) teacher/usage_min 0.2531 (0.1662) teacher/usage_std 0.0782 (0.1362) nleep/row_max_mean 1517.0111 (1505.4066) nleep/row_max_std 46.7708 (63.9264) nleep/row_min_mean 1488.7358 (1478.0136) lr 1.8090e-03 eta 0:11:30
epoch [12/50] batch [40/160] time 0.104 (0.106) data 0.000 (0.007) loss 1.0168 (0.9866) teacher_loss 0.0732 (0.1074) loss_zs_kd 0.0598 (0.0694) loss_oracle 0.6142 (0.5213) kd_loss 1.2131 (1.1676) acc 93.7500 (97.1094) gate/entropy 1.0437 (1.0434) gate/usage_max 0.4904 (0.4907) gate/usage_min 0.2296 (0.2290) gate/usage_std 0.1130 (0.1132) teacher/entropy 0.0631 (0.0898) teacher/usage_max 0.5149 (0.4700) teacher/usage_min 0.1769 (0.1732) teacher/usage_std 0.1391 (0.1266) nleep/row_max_mean 1520.6313 (1507.7380) nleep/row_max_std 43.9368 (61.5111) nleep/row_min_mean 1491.9814 (1480.4924) lr 1.8090e-03 eta 0:10:58
epoch [12/50] batch [60/160] time 0.105 (0.105) data 0.001 (0.005) loss 0.9492 (0.9941) teacher_loss 0.0471 (0.1105) loss_zs_kd 0.0764 (0.0739) loss_oracle 0.5568 (0.5267) kd_loss 1.1709 (1.1666) acc 100.0000 (97.2396) gate/entropy 1.0440 (1.0436) gate/usage_max 0.4900 (0.4905) gate/usage_min 0.2301 (0.2293) gate/usage_std 0.1126 (0.1131) teacher/entropy 0.0865 (0.0847) teacher/usage_max 0.4162 (0.4706) teacher/usage_min 0.1725 (0.1807) teacher/usage_std 0.1137 (0.1243) nleep/row_max_mean 1515.8539 (1507.8029) nleep/row_max_std 44.6481 (61.3863) nleep/row_min_mean 1489.5955 (1480.7887) lr 1.8090e-03 eta 0:10:48
epoch [12/50] batch [80/160] time 0.096 (0.104) data 0.000 (0.004) loss 0.9553 (1.0056) teacher_loss 0.1055 (0.1099) loss_zs_kd 0.0760 (0.0749) loss_oracle 0.5383 (0.5503) kd_loss 1.0851 (1.1663) acc 100.0000 (97.3438) gate/entropy 1.0444 (1.0437) gate/usage_max 0.4896 (0.4903) gate/usage_min 0.2307 (0.2296) gate/usage_std 0.1123 (0.1129) teacher/entropy 0.1193 (0.0810) teacher/usage_max 0.4793 (0.4694) teacher/usage_min 0.2261 (0.1820) teacher/usage_std 0.1070 (0.1230) nleep/row_max_mean 1511.0775 (1508.1657) nleep/row_max_std 58.0796 (60.3830) nleep/row_min_mean 1487.0835 (1481.2827) lr 1.8090e-03 eta 0:10:39
epoch [12/50] batch [100/160] time 0.100 (0.102) data 0.000 (0.003) loss 1.0533 (1.0076) teacher_loss 0.0799 (0.1050) loss_zs_kd 0.1013 (0.0781) loss_oracle 0.6478 (0.5620) kd_loss 1.1979 (1.1651) acc 96.8750 (97.3750) gate/entropy 1.0448 (1.0439) gate/usage_max 0.4889 (0.4900) gate/usage_min 0.2311 (0.2299) gate/usage_std 0.1118 (0.1127) teacher/entropy 0.0741 (0.0803) teacher/usage_max 0.4853 (0.4703) teacher/usage_min 0.1682 (0.1833) teacher/usage_std 0.1298 (0.1230) nleep/row_max_mean 1522.4508 (1507.8217) nleep/row_max_std 48.6854 (60.8437) nleep/row_min_mean 1497.0488 (1481.0720) lr 1.8090e-03 eta 0:10:29
epoch [12/50] batch [120/160] time 0.084 (0.101) data 0.000 (0.002) loss 1.0788 (1.0094) teacher_loss 0.1725 (0.1045) loss_zs_kd 0.0570 (0.0781) loss_oracle 0.6036 (0.5702) kd_loss 1.1521 (1.1613) acc 96.8750 (97.3698) gate/entropy 1.0455 (1.0442) gate/usage_max 0.4879 (0.4897) gate/usage_min 0.2318 (0.2302) gate/usage_std 0.1111 (0.1124) teacher/entropy 0.1067 (0.0799) teacher/usage_max 0.4222 (0.4694) teacher/usage_min 0.1697 (0.1881) teacher/usage_std 0.1158 (0.1206) nleep/row_max_mean 1515.2205 (1507.0975) nleep/row_max_std 54.1019 (62.5400) nleep/row_min_mean 1488.9497 (1480.4867) lr 1.8090e-03 eta 0:10:19
epoch [12/50] batch [140/160] time 0.088 (0.100) data 0.000 (0.002) loss 1.1031 (1.0119) teacher_loss 0.0362 (0.1039) loss_zs_kd 0.0700 (0.0774) loss_oracle 0.8048 (0.5788) kd_loss 1.2590 (1.1598) acc 100.0000 (97.3438) gate/entropy 1.0462 (1.0444) gate/usage_max 0.4869 (0.4894) gate/usage_min 0.2324 (0.2304) gate/usage_std 0.1104 (0.1122) teacher/entropy 0.0269 (0.0776) teacher/usage_max 0.4664 (0.4706) teacher/usage_min 0.1326 (0.1885) teacher/usage_std 0.1444 (0.1207) nleep/row_max_mean 1503.9116 (1506.9594) nleep/row_max_std 76.1983 (62.8929) nleep/row_min_mean 1476.2612 (1480.3359) lr 1.8090e-03 eta 0:10:10
epoch [12/50] batch [160/160] time 0.094 (0.103) data 0.000 (0.002) loss 1.0279 (1.0179) teacher_loss 0.1117 (0.0993) loss_zs_kd 0.0789 (0.0796) loss_oracle 0.5857 (0.5947) kd_loss 1.1678 (1.1630) acc 96.8750 (97.4805) gate/entropy 1.0468 (1.0447) gate/usage_max 0.4859 (0.4890) gate/usage_min 0.2330 (0.2307) gate/usage_std 0.1097 (0.1119) teacher/entropy 0.0942 (0.0744) teacher/usage_max 0.4216 (0.4711) teacher/usage_min 0.1581 (0.1878) teacher/usage_std 0.1239 (0.1213) nleep/row_max_mean 1481.6741 (1507.0287) nleep/row_max_std 102.0571 (62.4358) nleep/row_min_mean 1456.0774 (1480.2628) lr 1.7705e-03 eta 0:10:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,882
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 87.1%
******* Domain p best val acc:      83.3%, epoch: 7 *******
******* Domain p best val test acc: 87.7%, epoch: 7 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [13/50] batch [20/160] time 0.094 (0.116) data 0.000 (0.014) loss 1.0318 (1.0300) teacher_loss 0.0159 (0.0764) loss_zs_kd 0.0791 (0.0939) loss_oracle 0.6958 (0.6156) kd_loss 1.2568 (1.1976) acc 100.0000 (98.1250) gate/entropy 1.0475 (1.0473) gate/usage_max 0.4848 (0.4851) gate/usage_min 0.2334 (0.2333) gate/usage_std 0.1089 (0.1091) teacher/entropy 0.0156 (0.0480) teacher/usage_max 0.4710 (0.5012) teacher/usage_min 0.1543 (0.1618) teacher/usage_std 0.1326 (0.1439) nleep/row_max_mean 1507.5359 (1511.0481) nleep/row_max_std 87.5286 (61.0662) nleep/row_min_mean 1480.1619 (1482.8081) lr 1.7705e-03 eta 0:11:40
epoch [13/50] batch [40/160] time 0.096 (0.107) data 0.000 (0.007) loss 1.0319 (1.0429) teacher_loss 0.0294 (0.0794) loss_zs_kd 0.0763 (0.0929) loss_oracle 0.7329 (0.6424) kd_loss 1.1957 (1.1917) acc 100.0000 (98.3594) gate/entropy 1.0485 (1.0477) gate/usage_max 0.4833 (0.4845) gate/usage_min 0.2342 (0.2336) gate/usage_std 0.1078 (0.1087) teacher/entropy 0.0217 (0.0470) teacher/usage_max 0.4046 (0.4984) teacher/usage_min 0.2182 (0.1673) teacher/usage_std 0.0822 (0.1398) nleep/row_max_mean 1502.0017 (1509.0842) nleep/row_max_std 69.3013 (62.0213) nleep/row_min_mean 1471.4856 (1480.4102) lr 1.7705e-03 eta 0:10:47
epoch [13/50] batch [60/160] time 0.107 (0.105) data 0.000 (0.005) loss 1.2681 (1.0523) teacher_loss 0.2417 (0.0934) loss_zs_kd 0.0709 (0.0856) loss_oracle 0.7469 (0.6421) kd_loss 1.2351 (1.1902) acc 90.6250 (97.9688) gate/entropy 1.0492 (1.0481) gate/usage_max 0.4822 (0.4839) gate/usage_min 0.2348 (0.2339) gate/usage_std 0.1071 (0.1083) teacher/entropy 0.0871 (0.0514) teacher/usage_max 0.5225 (0.5032) teacher/usage_min 0.0693 (0.1641) teacher/usage_std 0.1924 (0.1431) nleep/row_max_mean 1519.5005 (1507.1858) nleep/row_max_std 50.7491 (64.3742) nleep/row_min_mean 1487.5161 (1478.3295) lr 1.7705e-03 eta 0:10:30
epoch [13/50] batch [80/160] time 0.103 (0.102) data 0.000 (0.004) loss 1.0001 (1.0447) teacher_loss 0.0401 (0.0900) loss_zs_kd 0.0831 (0.0861) loss_oracle 0.6278 (0.6341) kd_loss 1.2091 (1.1892) acc 100.0000 (97.9297) gate/entropy 1.0499 (1.0485) gate/usage_max 0.4810 (0.4833) gate/usage_min 0.2353 (0.2342) gate/usage_std 0.1062 (0.1078) teacher/entropy 0.0725 (0.0551) teacher/usage_max 0.5076 (0.5034) teacher/usage_min 0.0986 (0.1591) teacher/usage_std 0.1723 (0.1462) nleep/row_max_mean 1527.7261 (1507.6422) nleep/row_max_std 47.5835 (62.2402) nleep/row_min_mean 1495.8494 (1478.6339) lr 1.7705e-03 eta 0:10:14
epoch [13/50] batch [100/160] time 0.099 (0.102) data 0.000 (0.003) loss 0.9679 (1.0438) teacher_loss 0.0597 (0.0946) loss_zs_kd 0.0505 (0.0853) loss_oracle 0.5553 (0.6218) kd_loss 1.2105 (1.1914) acc 96.8750 (97.7500) gate/entropy 1.0509 (1.0489) gate/usage_max 0.4794 (0.4826) gate/usage_min 0.2361 (0.2346) gate/usage_std 0.1051 (0.1074) teacher/entropy 0.0452 (0.0555) teacher/usage_max 0.4339 (0.5015) teacher/usage_min 0.1504 (0.1557) teacher/usage_std 0.1295 (0.1469) nleep/row_max_mean 1516.1492 (1507.7618) nleep/row_max_std 47.7500 (62.2865) nleep/row_min_mean 1487.4169 (1478.5946) lr 1.7705e-03 eta 0:10:07
epoch [13/50] batch [120/160] time 0.104 (0.101) data 0.000 (0.003) loss 1.0307 (1.0446) teacher_loss 0.0555 (0.0958) loss_zs_kd 0.0883 (0.0844) loss_oracle 0.6261 (0.6200) kd_loss 1.2361 (1.1932) acc 96.8750 (97.6042) gate/entropy 1.0517 (1.0493) gate/usage_max 0.4782 (0.4820) gate/usage_min 0.2369 (0.2349) gate/usage_std 0.1043 (0.1070) teacher/entropy 0.0385 (0.0575) teacher/usage_max 0.5568 (0.5004) teacher/usage_min 0.0896 (0.1501) teacher/usage_std 0.1913 (0.1489) nleep/row_max_mean 1508.2653 (1507.6891) nleep/row_max_std 60.9082 (62.1694) nleep/row_min_mean 1478.0890 (1478.5496) lr 1.7705e-03 eta 0:10:03
epoch [13/50] batch [140/160] time 0.105 (0.101) data 0.000 (0.002) loss 0.9628 (1.0411) teacher_loss 0.0308 (0.0962) loss_zs_kd 0.0650 (0.0832) loss_oracle 0.5896 (0.6127) kd_loss 1.2094 (1.1941) acc 100.0000 (97.7679) gate/entropy 1.0523 (1.0497) gate/usage_max 0.4772 (0.4814) gate/usage_min 0.2375 (0.2352) gate/usage_std 0.1036 (0.1065) teacher/entropy 0.0443 (0.0598) teacher/usage_max 0.6150 (0.5020) teacher/usage_min 0.1025 (0.1447) teacher/usage_std 0.2123 (0.1523) nleep/row_max_mean 1518.8777 (1507.6728) nleep/row_max_std 49.4608 (62.6906) nleep/row_min_mean 1488.6238 (1478.5576) lr 1.7705e-03 eta 0:09:58
epoch [13/50] batch [160/160] time 0.076 (0.100) data 0.000 (0.002) loss 0.9759 (1.0397) teacher_loss 0.0747 (0.0948) loss_zs_kd 0.0876 (0.0814) loss_oracle 0.5041 (0.6124) kd_loss 1.2106 (1.1959) acc 100.0000 (97.7539) gate/entropy 1.0530 (1.0500) gate/usage_max 0.4760 (0.4808) gate/usage_min 0.2383 (0.2355) gate/usage_std 0.1027 (0.1061) teacher/entropy 0.0532 (0.0610) teacher/usage_max 0.4359 (0.5016) teacher/usage_min 0.1331 (0.1404) teacher/usage_std 0.1416 (0.1541) nleep/row_max_mean 1496.2007 (1507.3086) nleep/row_max_std 72.5995 (63.3873) nleep/row_min_mean 1471.4155 (1478.2805) lr 1.7290e-03 eta 0:09:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,917
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [14/50] batch [20/160] time 0.105 (0.109) data 0.000 (0.012) loss 0.9908 (1.0741) teacher_loss 0.0245 (0.0831) loss_zs_kd 0.0928 (0.0922) loss_oracle 0.6019 (0.6654) kd_loss 1.2379 (1.2245) acc 100.0000 (97.8125) gate/entropy 1.0537 (1.0534) gate/usage_max 0.4749 (0.4755) gate/usage_min 0.2390 (0.2387) gate/usage_std 0.1019 (0.1024) teacher/entropy 0.0361 (0.0504) teacher/usage_max 0.6217 (0.5160) teacher/usage_min 0.0666 (0.1040) teacher/usage_std 0.2272 (0.1739) nleep/row_max_mean 1509.4783 (1511.0141) nleep/row_max_std 69.2133 (59.7886) nleep/row_min_mean 1482.0740 (1481.6242) lr 1.7290e-03 eta 0:10:42
epoch [14/50] batch [40/160] time 0.091 (0.108) data 0.000 (0.006) loss 1.1210 (1.0721) teacher_loss 0.1632 (0.0986) loss_zs_kd 0.0831 (0.0832) loss_oracle 0.6111 (0.6431) kd_loss 1.2214 (1.2207) acc 96.8750 (97.1094) gate/entropy 1.0547 (1.0538) gate/usage_max 0.4733 (0.4748) gate/usage_min 0.2400 (0.2391) gate/usage_std 0.1008 (0.1019) teacher/entropy 0.0512 (0.0561) teacher/usage_max 0.4997 (0.5231) teacher/usage_min 0.0969 (0.1015) teacher/usage_std 0.1717 (0.1786) nleep/row_max_mean 1504.6096 (1509.6583) nleep/row_max_std 79.9996 (60.9280) nleep/row_min_mean 1474.7554 (1480.5940) lr 1.7290e-03 eta 0:10:36
epoch [14/50] batch [60/160] time 0.099 (0.107) data 0.001 (0.004) loss 1.0317 (1.0636) teacher_loss 0.0169 (0.0962) loss_zs_kd 0.0843 (0.0822) loss_oracle 0.6819 (0.6340) kd_loss 1.2633 (1.2187) acc 100.0000 (97.1875) gate/entropy 1.0558 (1.0542) gate/usage_max 0.4716 (0.4741) gate/usage_min 0.2410 (0.2395) gate/usage_std 0.0996 (0.1014) teacher/entropy 0.0239 (0.0580) teacher/usage_max 0.6154 (0.5268) teacher/usage_min 0.0410 (0.0984) teacher/usage_std 0.2346 (0.1819) nleep/row_max_mean 1518.2103 (1508.6022) nleep/row_max_std 46.6148 (63.5041) nleep/row_min_mean 1485.8119 (1479.8261) lr 1.7290e-03 eta 0:10:26
epoch [14/50] batch [80/160] time 0.102 (0.104) data 0.000 (0.003) loss 1.2142 (1.0745) teacher_loss 0.1331 (0.1043) loss_zs_kd 0.0871 (0.0826) loss_oracle 0.7590 (0.6318) kd_loss 1.3162 (1.2261) acc 96.8750 (96.9922) gate/entropy 1.0566 (1.0547) gate/usage_max 0.4703 (0.4734) gate/usage_min 0.2420 (0.2400) gate/usage_std 0.0986 (0.1008) teacher/entropy 0.0238 (0.0547) teacher/usage_max 0.5444 (0.5266) teacher/usage_min 0.0004 (0.0900) teacher/usage_std 0.2382 (0.1864) nleep/row_max_mean 1517.4624 (1509.8565) nleep/row_max_std 34.6515 (61.4900) nleep/row_min_mean 1485.7954 (1481.0209) lr 1.7290e-03 eta 0:10:07
epoch [14/50] batch [100/160] time 0.099 (0.103) data 0.000 (0.003) loss 1.1081 (1.0649) teacher_loss 0.0837 (0.0968) loss_zs_kd 0.0872 (0.0821) loss_oracle 0.7337 (0.6275) kd_loss 1.2280 (1.2265) acc 96.8750 (97.2500) gate/entropy 1.0574 (1.0551) gate/usage_max 0.4689 (0.4726) gate/usage_min 0.2427 (0.2405) gate/usage_std 0.0977 (0.1003) teacher/entropy 0.0272 (0.0542) teacher/usage_max 0.4700 (0.5256) teacher/usage_min 0.1428 (0.0879) teacher/usage_std 0.1389 (0.1871) nleep/row_max_mean 1520.0887 (1510.1039) nleep/row_max_std 46.2053 (61.3625) nleep/row_min_mean 1487.5725 (1481.2517) lr 1.7290e-03 eta 0:10:01
epoch [14/50] batch [120/160] time 0.112 (0.103) data 0.000 (0.002) loss 0.9890 (1.0699) teacher_loss 0.0356 (0.0988) loss_zs_kd 0.0792 (0.0821) loss_oracle 0.5855 (0.6335) kd_loss 1.2421 (1.2266) acc 100.0000 (97.1875) gate/entropy 1.0583 (1.0556) gate/usage_max 0.4673 (0.4718) gate/usage_min 0.2437 (0.2409) gate/usage_std 0.0965 (0.0997) teacher/entropy 0.0318 (0.0536) teacher/usage_max 0.4999 (0.5273) teacher/usage_min 0.0807 (0.0871) teacher/usage_std 0.1816 (0.1884) nleep/row_max_mean 1529.1582 (1510.1963) nleep/row_max_std 32.4499 (61.8194) nleep/row_min_mean 1499.2094 (1481.3136) lr 1.7290e-03 eta 0:09:56
epoch [14/50] batch [140/160] time 0.094 (0.103) data 0.000 (0.002) loss 1.0757 (1.0721) teacher_loss 0.1268 (0.1006) loss_zs_kd 0.0627 (0.0817) loss_oracle 0.6221 (0.6341) kd_loss 1.2129 (1.2273) acc 96.8750 (97.1652) gate/entropy 1.0594 (1.0561) gate/usage_max 0.4655 (0.4710) gate/usage_min 0.2449 (0.2414) gate/usage_std 0.0952 (0.0992) teacher/entropy 0.0639 (0.0538) teacher/usage_max 0.4682 (0.5292) teacher/usage_min 0.0869 (0.0836) teacher/usage_std 0.1745 (0.1906) nleep/row_max_mean 1497.0237 (1510.2998) nleep/row_max_std 85.5483 (61.9824) nleep/row_min_mean 1468.6860 (1481.3196) lr 1.7290e-03 eta 0:09:54
epoch [14/50] batch [160/160] time 0.083 (0.102) data 0.000 (0.002) loss 1.0355 (1.0739) teacher_loss 0.0388 (0.1020) loss_zs_kd 0.0663 (0.0807) loss_oracle 0.6860 (0.6346) kd_loss 1.2411 (1.2286) acc 100.0000 (97.1875) gate/entropy 1.0604 (1.0566) gate/usage_max 0.4637 (0.4702) gate/usage_min 0.2462 (0.2419) gate/usage_std 0.0939 (0.0986) teacher/entropy 0.0285 (0.0528) teacher/usage_max 0.5200 (0.5276) teacher/usage_min 0.0737 (0.0812) teacher/usage_std 0.1893 (0.1914) nleep/row_max_mean 1515.1587 (1510.5177) nleep/row_max_std 74.2559 (61.8462) nleep/row_min_mean 1486.2670 (1481.6052) lr 1.6845e-03 eta 0:09:45
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,959
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     88.1%, epoch: 5 *******
epoch [15/50] batch [20/160] time 0.100 (0.119) data 0.000 (0.015) loss 1.0407 (1.0906) teacher_loss 0.0337 (0.1129) loss_zs_kd 0.0824 (0.0702) loss_oracle 0.6838 (0.6318) kd_loss 1.2479 (1.2535) acc 100.0000 (96.7188) gate/entropy 1.0613 (1.0608) gate/usage_max 0.4622 (0.4630) gate/usage_min 0.2472 (0.2466) gate/usage_std 0.0929 (0.0934) teacher/entropy 0.0284 (0.0362) teacher/usage_max 0.5135 (0.5312) teacher/usage_min 0.0611 (0.0467) teacher/usage_std 0.1958 (0.2088) nleep/row_max_mean 1529.5422 (1514.3158) nleep/row_max_std 27.8363 (55.0533) nleep/row_min_mean 1498.1960 (1485.3655) lr 1.6845e-03 eta 0:11:22
epoch [15/50] batch [40/160] time 0.100 (0.112) data 0.000 (0.007) loss 1.0770 (1.0922) teacher_loss 0.1481 (0.1154) loss_zs_kd 0.0688 (0.0736) loss_oracle 0.5325 (0.6322) kd_loss 1.2564 (1.2478) acc 96.8750 (96.8750) gate/entropy 1.0622 (1.0613) gate/usage_max 0.4606 (0.4622) gate/usage_min 0.2485 (0.2472) gate/usage_std 0.0917 (0.0928) teacher/entropy 0.0455 (0.0428) teacher/usage_max 0.5115 (0.5418) teacher/usage_min 0.0293 (0.0472) teacher/usage_std 0.2160 (0.2115) nleep/row_max_mean 1506.7732 (1512.4281) nleep/row_max_std 56.6087 (58.0884) nleep/row_min_mean 1479.8425 (1483.5976) lr 1.6845e-03 eta 0:10:40
epoch [15/50] batch [60/160] time 0.093 (0.109) data 0.001 (0.005) loss 1.1346 (1.0765) teacher_loss 0.1806 (0.1068) loss_zs_kd 0.1000 (0.0748) loss_oracle 0.5731 (0.6158) kd_loss 1.2349 (1.2489) acc 93.7500 (97.3438) gate/entropy 1.0632 (1.0618) gate/usage_max 0.4589 (0.4614) gate/usage_min 0.2496 (0.2478) gate/usage_std 0.0905 (0.0922) teacher/entropy 0.0384 (0.0422) teacher/usage_max 0.5434 (0.5433) teacher/usage_min 0.0500 (0.0449) teacher/usage_std 0.2080 (0.2141) nleep/row_max_mean 1503.1180 (1512.2045) nleep/row_max_std 55.0048 (58.0681) nleep/row_min_mean 1473.3861 (1483.3451) lr 1.6845e-03 eta 0:10:19
epoch [15/50] batch [80/160] time 0.107 (0.107) data 0.000 (0.004) loss 0.9586 (1.0711) teacher_loss 0.0659 (0.1094) loss_zs_kd 0.0774 (0.0747) loss_oracle 0.5148 (0.5996) kd_loss 1.1932 (1.2491) acc 100.0000 (97.2266) gate/entropy 1.0640 (1.0622) gate/usage_max 0.4574 (0.4606) gate/usage_min 0.2506 (0.2484) gate/usage_std 0.0894 (0.0916) teacher/entropy 0.0684 (0.0401) teacher/usage_max 0.6375 (0.5413) teacher/usage_min 0.0419 (0.0446) teacher/usage_std 0.2433 (0.2136) nleep/row_max_mean 1490.7983 (1511.0838) nleep/row_max_std 82.6574 (59.0288) nleep/row_min_mean 1462.9927 (1482.5469) lr 1.6845e-03 eta 0:10:08
epoch [15/50] batch [100/160] time 0.091 (0.107) data 0.000 (0.003) loss 1.0062 (1.0682) teacher_loss 0.0634 (0.1054) loss_zs_kd 0.0741 (0.0747) loss_oracle 0.5818 (0.6025) kd_loss 1.2297 (1.2484) acc 96.8750 (97.2500) gate/entropy 1.0649 (1.0627) gate/usage_max 0.4559 (0.4598) gate/usage_min 0.2517 (0.2489) gate/usage_std 0.0882 (0.0911) teacher/entropy 0.0333 (0.0392) teacher/usage_max 0.4785 (0.5432) teacher/usage_min 0.0862 (0.0436) teacher/usage_std 0.1756 (0.2150) nleep/row_max_mean 1508.7146 (1510.7890) nleep/row_max_std 69.5634 (60.0052) nleep/row_min_mean 1480.2544 (1482.3344) lr 1.6845e-03 eta 0:10:06
epoch [15/50] batch [120/160] time 0.111 (0.106) data 0.001 (0.003) loss 1.0479 (1.0686) teacher_loss 0.1029 (0.1067) loss_zs_kd 0.0709 (0.0754) loss_oracle 0.5861 (0.6029) kd_loss 1.2332 (1.2455) acc 93.7500 (97.2396) gate/entropy 1.0660 (1.0631) gate/usage_max 0.4538 (0.4590) gate/usage_min 0.2530 (0.2495) gate/usage_std 0.0867 (0.0905) teacher/entropy 0.0205 (0.0393) teacher/usage_max 0.5579 (0.5434) teacher/usage_min 0.0663 (0.0449) teacher/usage_std 0.2029 (0.2142) nleep/row_max_mean 1500.8278 (1510.0740) nleep/row_max_std 78.1139 (61.0185) nleep/row_min_mean 1471.9951 (1481.6382) lr 1.6845e-03 eta 0:09:58
epoch [15/50] batch [140/160] time 0.101 (0.105) data 0.000 (0.002) loss 0.9789 (1.0686) teacher_loss 0.0556 (0.1044) loss_zs_kd 0.0911 (0.0752) loss_oracle 0.5171 (0.6058) kd_loss 1.2384 (1.2474) acc 100.0000 (97.2991) gate/entropy 1.0666 (1.0636) gate/usage_max 0.4527 (0.4582) gate/usage_min 0.2539 (0.2500) gate/usage_std 0.0859 (0.0899) teacher/entropy 0.0410 (0.0375) teacher/usage_max 0.5255 (0.5447) teacher/usage_min 0.0272 (0.0420) teacher/usage_std 0.2188 (0.2160) nleep/row_max_mean 1503.3676 (1510.4385) nleep/row_max_std 73.3589 (61.1468) nleep/row_min_mean 1476.8799 (1481.8380) lr 1.6845e-03 eta 0:09:49
epoch [15/50] batch [160/160] time 0.095 (0.104) data 0.000 (0.002) loss 1.1345 (1.0743) teacher_loss 0.1295 (0.1064) loss_zs_kd 0.0761 (0.0762) loss_oracle 0.7021 (0.6115) kd_loss 1.2319 (1.2481) acc 96.8750 (97.2266) gate/entropy 1.0677 (1.0640) gate/usage_max 0.4508 (0.4574) gate/usage_min 0.2554 (0.2506) gate/usage_std 0.0845 (0.0893) teacher/entropy 0.0290 (0.0362) teacher/usage_max 0.5052 (0.5466) teacher/usage_min 0.0585 (0.0410) teacher/usage_std 0.1964 (0.2170) nleep/row_max_mean 1504.5090 (1509.9144) nleep/row_max_std 85.9206 (62.4157) nleep/row_min_mean 1476.1327 (1481.2640) lr 1.6374e-03 eta 0:09:39
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,978
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     88.2%, epoch: 15 *******
epoch [16/50] batch [20/160] time 0.112 (0.126) data 0.000 (0.015) loss 0.9952 (1.1081) teacher_loss 0.1100 (0.0922) loss_zs_kd 0.0628 (0.0805) loss_oracle 0.5279 (0.6906) kd_loss 1.1798 (1.2607) acc 96.8750 (97.3438) gate/entropy 1.0688 (1.0682) gate/usage_max 0.4485 (0.4497) gate/usage_min 0.2571 (0.2561) gate/usage_std 0.0828 (0.0838) teacher/entropy 0.0659 (0.0202) teacher/usage_max 0.5720 (0.5490) teacher/usage_min 0.0627 (0.0217) teacher/usage_std 0.2092 (0.2302) nleep/row_max_mean 1489.7307 (1513.0228) nleep/row_max_std 96.1396 (61.1968) nleep/row_min_mean 1461.0156 (1482.5528) lr 1.6374e-03 eta 0:11:40
epoch [16/50] batch [40/160] time 0.119 (0.117) data 0.000 (0.007) loss 1.0358 (1.0847) teacher_loss 0.0917 (0.0893) loss_zs_kd 0.0453 (0.0777) loss_oracle 0.6072 (0.6621) kd_loss 1.2357 (1.2510) acc 96.8750 (97.1875) gate/entropy 1.0698 (1.0687) gate/usage_max 0.4465 (0.4487) gate/usage_min 0.2584 (0.2569) gate/usage_std 0.0814 (0.0830) teacher/entropy 0.0361 (0.0264) teacher/usage_max 0.6117 (0.5585) teacher/usage_min 0.0004 (0.0243) teacher/usage_std 0.2525 (0.2304) nleep/row_max_mean 1517.6116 (1510.9002) nleep/row_max_std 54.6151 (63.8764) nleep/row_min_mean 1486.4143 (1480.3388) lr 1.6374e-03 eta 0:10:50
epoch [16/50] batch [60/160] time 0.109 (0.114) data 0.001 (0.005) loss 1.0175 (1.0890) teacher_loss 0.0337 (0.0952) loss_zs_kd 0.0625 (0.0777) loss_oracle 0.6334 (0.6610) kd_loss 1.2717 (1.2489) acc 100.0000 (97.2917) gate/entropy 1.0708 (1.0693) gate/usage_max 0.4448 (0.4477) gate/usage_min 0.2599 (0.2576) gate/usage_std 0.0801 (0.0823) teacher/entropy 0.0068 (0.0283) teacher/usage_max 0.5298 (0.5621) teacher/usage_min 0.0014 (0.0240) teacher/usage_std 0.2360 (0.2307) nleep/row_max_mean 1517.5383 (1510.2017) nleep/row_max_std 53.6182 (63.6559) nleep/row_min_mean 1485.0334 (1479.3438) lr 1.6374e-03 eta 0:10:30
epoch [16/50] batch [80/160] time 0.091 (0.111) data 0.000 (0.004) loss 1.1798 (1.0823) teacher_loss 0.1736 (0.0995) loss_zs_kd 0.0558 (0.0761) loss_oracle 0.7067 (0.6431) kd_loss 1.2499 (1.2463) acc 93.7500 (97.2266) gate/entropy 1.0715 (1.0697) gate/usage_max 0.4433 (0.4467) gate/usage_min 0.2613 (0.2584) gate/usage_std 0.0790 (0.0816) teacher/entropy 0.0328 (0.0289) teacher/usage_max 0.6720 (0.5662) teacher/usage_min 0.0468 (0.0240) teacher/usage_std 0.2579 (0.2319) nleep/row_max_mean 1520.3640 (1510.9570) nleep/row_max_std 77.9398 (61.9988) nleep/row_min_mean 1484.4709 (1480.0128) lr 1.6374e-03 eta 0:10:11
epoch [16/50] batch [100/160] time 0.110 (0.109) data 0.001 (0.003) loss 1.0131 (1.0834) teacher_loss 0.0444 (0.1033) loss_zs_kd 0.0769 (0.0777) loss_oracle 0.5795 (0.6362) kd_loss 1.2810 (1.2464) acc 100.0000 (97.0938) gate/entropy 1.0723 (1.0702) gate/usage_max 0.4416 (0.4458) gate/usage_min 0.2625 (0.2591) gate/usage_std 0.0778 (0.0809) teacher/entropy 0.0075 (0.0275) teacher/usage_max 0.5921 (0.5648) teacher/usage_min 0.0001 (0.0231) teacher/usage_std 0.2473 (0.2318) nleep/row_max_mean 1516.3728 (1510.7208) nleep/row_max_std 43.7494 (61.6157) nleep/row_min_mean 1485.4170 (1479.8949) lr 1.6374e-03 eta 0:09:57
epoch [16/50] batch [120/160] time 0.093 (0.107) data 0.000 (0.003) loss 1.0007 (1.0788) teacher_loss 0.0646 (0.1013) loss_zs_kd 0.0829 (0.0780) loss_oracle 0.5366 (0.6323) kd_loss 1.2525 (1.2446) acc 96.8750 (97.2135) gate/entropy 1.0733 (1.0706) gate/usage_max 0.4396 (0.4449) gate/usage_min 0.2639 (0.2598) gate/usage_std 0.0763 (0.0802) teacher/entropy 0.0108 (0.0276) teacher/usage_max 0.5912 (0.5626) teacher/usage_min 0.0000 (0.0230) teacher/usage_std 0.2472 (0.2311) nleep/row_max_mean 1521.2898 (1511.0411) nleep/row_max_std 28.2757 (60.9985) nleep/row_min_mean 1490.0590 (1480.2564) lr 1.6374e-03 eta 0:09:45
epoch [16/50] batch [140/160] time 0.111 (0.106) data 0.000 (0.002) loss 1.3687 (1.0803) teacher_loss 0.3398 (0.1027) loss_zs_kd 0.0697 (0.0779) loss_oracle 0.7224 (0.6317) kd_loss 1.2657 (1.2454) acc 87.5000 (97.1429) gate/entropy 1.0741 (1.0711) gate/usage_max 0.4380 (0.4440) gate/usage_min 0.2650 (0.2605) gate/usage_std 0.0751 (0.0796) teacher/entropy 0.0086 (0.0261) teacher/usage_max 0.5319 (0.5596) teacher/usage_min 0.0010 (0.0215) teacher/usage_std 0.2365 (0.2312) nleep/row_max_mean 1509.1365 (1511.2573) nleep/row_max_std 58.1692 (60.4415) nleep/row_min_mean 1476.7218 (1480.3487) lr 1.6374e-03 eta 0:09:40
epoch [16/50] batch [160/160] time 0.095 (0.105) data 0.000 (0.002) loss 1.0573 (1.0870) teacher_loss 0.0370 (0.1070) loss_zs_kd 0.0575 (0.0778) loss_oracle 0.7559 (0.6371) kd_loss 1.2272 (1.2451) acc 100.0000 (96.9531) gate/entropy 1.0752 (1.0715) gate/usage_max 0.4355 (0.4431) gate/usage_min 0.2667 (0.2611) gate/usage_std 0.0734 (0.0789) teacher/entropy 0.0275 (0.0249) teacher/usage_max 0.4998 (0.5606) teacher/usage_min 0.0244 (0.0210) teacher/usage_std 0.2187 (0.2318) nleep/row_max_mean 1489.8884 (1511.2292) nleep/row_max_std 83.6634 (60.6307) nleep/row_min_mean 1460.1666 (1480.1750) lr 1.5878e-03 eta 0:09:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,009
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [17/50] batch [20/160] time 0.098 (0.116) data 0.000 (0.016) loss 1.1296 (1.0918) teacher_loss 0.1501 (0.1101) loss_zs_kd 0.0790 (0.0646) loss_oracle 0.6445 (0.6637) kd_loss 1.2355 (1.2352) acc 96.8750 (97.6562) gate/entropy 1.0761 (1.0756) gate/usage_max 0.4337 (0.4346) gate/usage_min 0.2682 (0.2674) gate/usage_std 0.0720 (0.0727) teacher/entropy 0.0289 (0.0219) teacher/usage_max 0.5121 (0.5750) teacher/usage_min 0.0000 (0.0161) teacher/usage_std 0.2359 (0.2401) nleep/row_max_mean 1521.5073 (1512.3772) nleep/row_max_std 45.9287 (58.3138) nleep/row_min_mean 1488.4001 (1479.7056) lr 1.5878e-03 eta 0:10:29
epoch [17/50] batch [40/160] time 0.103 (0.108) data 0.000 (0.008) loss 1.0609 (1.0794) teacher_loss 0.0383 (0.1003) loss_zs_kd 0.0656 (0.0655) loss_oracle 0.7587 (0.6645) kd_loss 1.2210 (1.2281) acc 100.0000 (97.7344) gate/entropy 1.0770 (1.0761) gate/usage_max 0.4316 (0.4336) gate/usage_min 0.2699 (0.2683) gate/usage_std 0.0705 (0.0719) teacher/entropy 0.0331 (0.0268) teacher/usage_max 0.4961 (0.5716) teacher/usage_min 0.0117 (0.0130) teacher/usage_std 0.2274 (0.2402) nleep/row_max_mean 1516.5798 (1511.2316) nleep/row_max_std 57.8655 (58.2808) nleep/row_min_mean 1483.0671 (1478.6973) lr 1.5878e-03 eta 0:09:43
epoch [17/50] batch [60/160] time 0.100 (0.106) data 0.001 (0.005) loss 1.0660 (1.0936) teacher_loss 0.0622 (0.1074) loss_zs_kd 0.0849 (0.0669) loss_oracle 0.7077 (0.6763) kd_loss 1.2151 (1.2291) acc 100.0000 (97.2396) gate/entropy 1.0779 (1.0766) gate/usage_max 0.4297 (0.4326) gate/usage_min 0.2716 (0.2691) gate/usage_std 0.0690 (0.0712) teacher/entropy 0.0331 (0.0262) teacher/usage_max 0.5827 (0.5661) teacher/usage_min 0.0425 (0.0119) teacher/usage_std 0.2225 (0.2393) nleep/row_max_mean 1492.1820 (1510.2161) nleep/row_max_std 87.8009 (59.4080) nleep/row_min_mean 1462.4462 (1477.9128) lr 1.5878e-03 eta 0:09:32
epoch [17/50] batch [80/160] time 0.098 (0.105) data 0.000 (0.004) loss 1.2435 (1.0942) teacher_loss 0.2971 (0.1100) loss_zs_kd 0.0885 (0.0702) loss_oracle 0.5868 (0.6712) kd_loss 1.2177 (1.2271) acc 90.6250 (97.1484) gate/entropy 1.0788 (1.0770) gate/usage_max 0.4276 (0.4316) gate/usage_min 0.2734 (0.2700) gate/usage_std 0.0675 (0.0704) teacher/entropy 0.0293 (0.0266) teacher/usage_max 0.4981 (0.5616) teacher/usage_min 0.0117 (0.0113) teacher/usage_std 0.2275 (0.2383) nleep/row_max_mean 1500.6655 (1510.0371) nleep/row_max_std 75.0234 (59.5491) nleep/row_min_mean 1467.9453 (1477.9200) lr 1.5878e-03 eta 0:09:24
epoch [17/50] batch [100/160] time 0.099 (0.105) data 0.000 (0.003) loss 1.1201 (1.0929) teacher_loss 0.0884 (0.1100) loss_zs_kd 0.0763 (0.0720) loss_oracle 0.7913 (0.6684) kd_loss 1.1958 (1.2254) acc 96.8750 (97.0625) gate/entropy 1.0797 (1.0775) gate/usage_max 0.4255 (0.4305) gate/usage_min 0.2751 (0.2709) gate/usage_std 0.0659 (0.0697) teacher/entropy 0.0597 (0.0263) teacher/usage_max 0.6579 (0.5626) teacher/usage_min 0.0173 (0.0117) teacher/usage_std 0.2616 (0.2380) nleep/row_max_mean 1500.3455 (1509.4967) nleep/row_max_std 63.3414 (59.9692) nleep/row_min_mean 1465.6309 (1477.3684) lr 1.5878e-03 eta 0:09:18
epoch [17/50] batch [120/160] time 0.101 (0.104) data 0.000 (0.003) loss 1.1449 (1.0960) teacher_loss 0.1094 (0.1087) loss_zs_kd 0.0677 (0.0735) loss_oracle 0.7716 (0.6761) kd_loss 1.2317 (1.2251) acc 100.0000 (97.0833) gate/entropy 1.0806 (1.0779) gate/usage_max 0.4235 (0.4295) gate/usage_min 0.2771 (0.2718) gate/usage_std 0.0644 (0.0689) teacher/entropy 0.0227 (0.0255) teacher/usage_max 0.7283 (0.5656) teacher/usage_min 0.0224 (0.0114) teacher/usage_std 0.2942 (0.2390) nleep/row_max_mean 1505.9674 (1509.5873) nleep/row_max_std 69.1133 (59.8025) nleep/row_min_mean 1472.1864 (1477.4642) lr 1.5878e-03 eta 0:09:12
epoch [17/50] batch [140/160] time 0.102 (0.103) data 0.000 (0.002) loss 0.9550 (1.0937) teacher_loss 0.0216 (0.1077) loss_zs_kd 0.0858 (0.0756) loss_oracle 0.5833 (0.6732) kd_loss 1.1979 (1.2233) acc 100.0000 (97.1652) gate/entropy 1.0814 (1.0784) gate/usage_max 0.4214 (0.4285) gate/usage_min 0.2790 (0.2727) gate/usage_std 0.0629 (0.0681) teacher/entropy 0.0341 (0.0254) teacher/usage_max 0.5313 (0.5642) teacher/usage_min 0.0158 (0.0122) teacher/usage_std 0.2268 (0.2380) nleep/row_max_mean 1505.5295 (1509.3108) nleep/row_max_std 73.3615 (60.6135) nleep/row_min_mean 1473.5225 (1477.1703) lr 1.5878e-03 eta 0:09:06
epoch [17/50] batch [160/160] time 0.099 (0.102) data 0.000 (0.002) loss 1.1412 (1.0903) teacher_loss 0.1857 (0.1067) loss_zs_kd 0.0783 (0.0758) loss_oracle 0.6585 (0.6695) kd_loss 1.1741 (1.2218) acc 93.7500 (97.1875) gate/entropy 1.0821 (1.0788) gate/usage_max 0.4197 (0.4275) gate/usage_min 0.2803 (0.2735) gate/usage_std 0.0616 (0.0674) teacher/entropy 0.0474 (0.0249) teacher/usage_max 0.5917 (0.5636) teacher/usage_min 0.0264 (0.0123) teacher/usage_std 0.2333 (0.2376) nleep/row_max_mean 1494.8448 (1509.1733) nleep/row_max_std 88.4260 (60.9230) nleep/row_min_mean 1463.5137 (1477.0699) lr 1.5358e-03 eta 0:08:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,002
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [18/50] batch [20/160] time 0.128 (0.117) data 0.000 (0.012) loss 1.0517 (1.0967) teacher_loss 0.1237 (0.1180) loss_zs_kd 0.0905 (0.0794) loss_oracle 0.5386 (0.6572) kd_loss 1.2270 (1.2208) acc 96.8750 (96.8750) gate/entropy 1.0829 (1.0825) gate/usage_max 0.4176 (0.4186) gate/usage_min 0.2819 (0.2811) gate/usage_std 0.0601 (0.0608) teacher/entropy 0.0051 (0.0147) teacher/usage_max 0.5303 (0.5647) teacher/usage_min 0.0001 (0.0058) teacher/usage_std 0.2369 (0.2412) nleep/row_max_mean 1523.9988 (1513.9917) nleep/row_max_std 26.5913 (55.1242) nleep/row_min_mean 1489.1387 (1480.4384) lr 1.5358e-03 eta 0:10:15
epoch [18/50] batch [40/160] time 0.132 (0.115) data 0.000 (0.006) loss 1.2200 (1.0611) teacher_loss 0.1875 (0.0985) loss_zs_kd 0.0843 (0.0754) loss_oracle 0.7466 (0.6349) kd_loss 1.2342 (1.2149) acc 96.8750 (97.5781) gate/entropy 1.0836 (1.0829) gate/usage_max 0.4156 (0.4175) gate/usage_min 0.2834 (0.2819) gate/usage_std 0.0586 (0.0600) teacher/entropy 0.0093 (0.0163) teacher/usage_max 0.7164 (0.5715) teacher/usage_min 0.0001 (0.0070) teacher/usage_std 0.2945 (0.2421) nleep/row_max_mean 1519.0498 (1511.7384) nleep/row_max_std 58.8975 (57.8325) nleep/row_min_mean 1484.7510 (1478.3285) lr 1.5358e-03 eta 0:10:03
epoch [18/50] batch [60/160] time 0.102 (0.111) data 0.001 (0.004) loss 1.2271 (1.0648) teacher_loss 0.2363 (0.1022) loss_zs_kd 0.0710 (0.0727) loss_oracle 0.7155 (0.6445) kd_loss 1.1952 (1.2082) acc 90.6250 (97.3438) gate/entropy 1.0844 (1.0833) gate/usage_max 0.4136 (0.4165) gate/usage_min 0.2850 (0.2827) gate/usage_std 0.0572 (0.0593) teacher/entropy 0.0237 (0.0211) teacher/usage_max 0.5311 (0.5701) teacher/usage_min 0.0171 (0.0090) teacher/usage_std 0.2259 (0.2411) nleep/row_max_mean 1500.0092 (1510.5137) nleep/row_max_std 89.0427 (60.3065) nleep/row_min_mean 1466.5229 (1477.2554) lr 1.5358e-03 eta 0:09:39
epoch [18/50] batch [80/160] time 0.100 (0.108) data 0.001 (0.003) loss 0.9739 (1.0697) teacher_loss 0.0313 (0.1029) loss_zs_kd 0.0918 (0.0724) loss_oracle 0.6191 (0.6552) kd_loss 1.1742 (1.2060) acc 100.0000 (97.0312) gate/entropy 1.0851 (1.0837) gate/usage_max 0.4115 (0.4155) gate/usage_min 0.2868 (0.2835) gate/usage_std 0.0556 (0.0586) teacher/entropy 0.0434 (0.0215) teacher/usage_max 0.6274 (0.5700) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.2576 (0.2412) nleep/row_max_mean 1512.4634 (1510.2766) nleep/row_max_std 45.4308 (60.3775) nleep/row_min_mean 1477.1998 (1477.0344) lr 1.5358e-03 eta 0:09:22
epoch [18/50] batch [100/160] time 0.109 (0.107) data 0.000 (0.003) loss 1.3590 (1.0700) teacher_loss 0.4223 (0.1066) loss_zs_kd 0.0544 (0.0722) loss_oracle 0.6254 (0.6503) kd_loss 1.1936 (1.2042) acc 90.6250 (96.9688) gate/entropy 1.0858 (1.0840) gate/usage_max 0.4096 (0.4145) gate/usage_min 0.2883 (0.2843) gate/usage_std 0.0542 (0.0578) teacher/entropy 0.0238 (0.0212) teacher/usage_max 0.5743 (0.5675) teacher/usage_min 0.0195 (0.0082) teacher/usage_std 0.2323 (0.2407) nleep/row_max_mean 1509.2870 (1509.3734) nleep/row_max_std 80.0170 (61.9317) nleep/row_min_mean 1472.3757 (1476.1445) lr 1.5358e-03 eta 0:09:12
epoch [18/50] batch [120/160] time 0.113 (0.106) data 0.000 (0.002) loss 1.0779 (1.0702) teacher_loss 0.1044 (0.1090) loss_zs_kd 0.0979 (0.0713) loss_oracle 0.6304 (0.6489) kd_loss 1.2186 (1.2022) acc 96.8750 (97.0312) gate/entropy 1.0865 (1.0844) gate/usage_max 0.4075 (0.4135) gate/usage_min 0.2898 (0.2851) gate/usage_std 0.0527 (0.0571) teacher/entropy 0.0021 (0.0214) teacher/usage_max 0.5941 (0.5690) teacher/usage_min 0.0000 (0.0090) teacher/usage_std 0.2479 (0.2409) nleep/row_max_mean 1516.4828 (1509.3725) nleep/row_max_std 60.0210 (62.2283) nleep/row_min_mean 1481.7987 (1475.9854) lr 1.5358e-03 eta 0:09:06
epoch [18/50] batch [140/160] time 0.096 (0.106) data 0.000 (0.002) loss 1.2184 (1.0693) teacher_loss 0.2476 (0.1070) loss_zs_kd 0.0807 (0.0721) loss_oracle 0.6649 (0.6518) kd_loss 1.1961 (1.2007) acc 93.7500 (97.0089) gate/entropy 1.0872 (1.0847) gate/usage_max 0.4054 (0.4125) gate/usage_min 0.2914 (0.2859) gate/usage_std 0.0512 (0.0563) teacher/entropy 0.0189 (0.0213) teacher/usage_max 0.6162 (0.5674) teacher/usage_min 0.0088 (0.0088) teacher/usage_std 0.2497 (0.2406) nleep/row_max_mean 1518.8091 (1509.5303) nleep/row_max_std 60.2854 (62.6342) nleep/row_min_mean 1483.0261 (1475.8869) lr 1.5358e-03 eta 0:09:02
epoch [18/50] batch [160/160] time 0.095 (0.104) data 0.000 (0.002) loss 1.3547 (1.0674) teacher_loss 0.3621 (0.1065) loss_zs_kd 0.0882 (0.0723) loss_oracle 0.6864 (0.6494) kd_loss 1.2106 (1.2001) acc 90.6250 (97.0508) gate/entropy 1.0878 (1.0851) gate/usage_max 0.4033 (0.4114) gate/usage_min 0.2930 (0.2867) gate/usage_std 0.0497 (0.0556) teacher/entropy 0.0002 (0.0204) teacher/usage_max 0.5313 (0.5650) teacher/usage_min 0.0000 (0.0080) teacher/usage_std 0.2371 (0.2404) nleep/row_max_mean 1512.7393 (1509.5819) nleep/row_max_std 60.1927 (62.6379) nleep/row_min_mean 1475.7327 (1475.7020) lr 1.4818e-03 eta 0:08:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.2%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [19/50] batch [20/160] time 0.093 (0.114) data 0.000 (0.015) loss 1.0998 (1.0497) teacher_loss 0.0810 (0.1035) loss_zs_kd 0.0818 (0.0679) loss_oracle 0.7540 (0.6422) kd_loss 1.2017 (1.1824) acc 96.8750 (97.6562) gate/entropy 1.0884 (1.0882) gate/usage_max 0.4013 (0.4021) gate/usage_min 0.2945 (0.2939) gate/usage_std 0.0482 (0.0488) teacher/entropy 0.0044 (0.0218) teacher/usage_max 0.5006 (0.5610) teacher/usage_min 0.0001 (0.0069) teacher/usage_std 0.2356 (0.2410) nleep/row_max_mean 1514.9933 (1507.5732) nleep/row_max_std 56.0474 (64.4771) nleep/row_min_mean 1477.9255 (1471.2894) lr 1.4818e-03 eta 0:09:41
epoch [19/50] batch [40/160] time 0.100 (0.107) data 0.000 (0.007) loss 1.1094 (1.0517) teacher_loss 0.1638 (0.1051) loss_zs_kd 0.0981 (0.0728) loss_oracle 0.6283 (0.6375) kd_loss 1.1648 (1.1829) acc 96.8750 (97.7344) gate/entropy 1.0890 (1.0885) gate/usage_max 0.3995 (0.4012) gate/usage_min 0.2959 (0.2946) gate/usage_std 0.0469 (0.0481) teacher/entropy 0.0299 (0.0198) teacher/usage_max 0.5002 (0.5501) teacher/usage_min 0.0274 (0.0078) teacher/usage_std 0.2166 (0.2375) nleep/row_max_mean 1499.0791 (1508.8556) nleep/row_max_std 87.2305 (64.4561) nleep/row_min_mean 1464.7505 (1472.6293) lr 1.4818e-03 eta 0:09:01
epoch [19/50] batch [60/160] time 0.100 (0.104) data 0.001 (0.005) loss 1.0054 (1.0554) teacher_loss 0.0474 (0.1064) loss_zs_kd 0.0706 (0.0741) loss_oracle 0.6520 (0.6414) kd_loss 1.1934 (1.1825) acc 100.0000 (97.6042) gate/entropy 1.0896 (1.0888) gate/usage_max 0.3975 (0.4002) gate/usage_min 0.2973 (0.2953) gate/usage_std 0.0455 (0.0474) teacher/entropy 0.0034 (0.0189) teacher/usage_max 0.5932 (0.5520) teacher/usage_min 0.0000 (0.0069) teacher/usage_std 0.2477 (0.2380) nleep/row_max_mean 1508.3802 (1510.3921) nleep/row_max_std 74.3131 (63.1266) nleep/row_min_mean 1470.8860 (1473.8645) lr 1.4818e-03 eta 0:08:45
epoch [19/50] batch [80/160] time 0.107 (0.102) data 0.000 (0.004) loss 1.1673 (1.0539) teacher_loss 0.2192 (0.1070) loss_zs_kd 0.0749 (0.0737) loss_oracle 0.6254 (0.6377) kd_loss 1.1961 (1.1822) acc 90.6250 (97.4219) gate/entropy 1.0902 (1.0890) gate/usage_max 0.3952 (0.3992) gate/usage_min 0.2990 (0.2960) gate/usage_std 0.0438 (0.0467) teacher/entropy 0.0001 (0.0181) teacher/usage_max 0.5313 (0.5596) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2371 (0.2405) nleep/row_max_mean 1512.7046 (1510.6252) nleep/row_max_std 48.3261 (62.5283) nleep/row_min_mean 1475.9880 (1474.0655) lr 1.4818e-03 eta 0:08:36
epoch [19/50] batch [100/160] time 0.114 (0.103) data 0.000 (0.003) loss 1.0042 (1.0592) teacher_loss 0.0753 (0.1148) loss_zs_kd 0.0894 (0.0739) loss_oracle 0.5763 (0.6340) kd_loss 1.1921 (1.1809) acc 96.8750 (97.1250) gate/entropy 1.0906 (1.0893) gate/usage_max 0.3936 (0.3982) gate/usage_min 0.3005 (0.2967) gate/usage_std 0.0427 (0.0460) teacher/entropy 0.0005 (0.0181) teacher/usage_max 0.5312 (0.5564) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2371 (0.2399) nleep/row_max_mean 1516.1572 (1511.1092) nleep/row_max_std 46.5847 (61.5232) nleep/row_min_mean 1476.8046 (1474.6121) lr 1.4818e-03 eta 0:08:34
epoch [19/50] batch [120/160] time 0.090 (0.104) data 0.000 (0.003) loss 1.3127 (1.0574) teacher_loss 0.3132 (0.1156) loss_zs_kd 0.1059 (0.0737) loss_oracle 0.7030 (0.6295) kd_loss 1.1902 (1.1804) acc 90.6250 (97.0312) gate/entropy 1.0911 (1.0896) gate/usage_max 0.3918 (0.3973) gate/usage_min 0.3019 (0.2975) gate/usage_std 0.0414 (0.0453) teacher/entropy 0.0027 (0.0172) teacher/usage_max 0.6565 (0.5588) teacher/usage_min 0.0001 (0.0050) teacher/usage_std 0.2681 (0.2406) nleep/row_max_mean 1501.8418 (1511.3798) nleep/row_max_std 81.3015 (61.2985) nleep/row_min_mean 1469.7957 (1475.0312) lr 1.4818e-03 eta 0:08:41
epoch [19/50] batch [140/160] time 0.100 (0.102) data 0.000 (0.002) loss 0.9755 (1.0559) teacher_loss 0.0351 (0.1164) loss_zs_kd 0.0640 (0.0732) loss_oracle 0.6304 (0.6274) kd_loss 1.1864 (1.1784) acc 100.0000 (96.9643) gate/entropy 1.0916 (1.0898) gate/usage_max 0.3900 (0.3964) gate/usage_min 0.3034 (0.2982) gate/usage_std 0.0401 (0.0447) teacher/entropy 0.0003 (0.0177) teacher/usage_max 0.5312 (0.5588) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2371 (0.2405) nleep/row_max_mean 1529.6497 (1510.2865) nleep/row_max_std 45.1437 (62.1595) nleep/row_min_mean 1493.2112 (1474.2535) lr 1.4818e-03 eta 0:08:29
epoch [19/50] batch [160/160] time 0.097 (0.100) data 0.000 (0.002) loss 1.1035 (1.0550) teacher_loss 0.2172 (0.1158) loss_zs_kd 0.0619 (0.0737) loss_oracle 0.5623 (0.6269) kd_loss 1.1485 (1.1777) acc 93.7500 (96.9727) gate/entropy 1.0920 (1.0901) gate/usage_max 0.3881 (0.3954) gate/usage_min 0.3050 (0.2990) gate/usage_std 0.0387 (0.0440) teacher/entropy 0.0328 (0.0170) teacher/usage_max 0.5612 (0.5599) teacher/usage_min 0.0099 (0.0047) teacher/usage_std 0.2350 (0.2411) nleep/row_max_mean 1486.6549 (1509.7367) nleep/row_max_std 83.3344 (62.3494) nleep/row_min_mean 1455.4989 (1473.8586) lr 1.4258e-03 eta 0:08:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,000
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.7%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [20/50] batch [20/160] time 0.090 (0.126) data 0.000 (0.015) loss 0.9593 (1.0232) teacher_loss 0.0587 (0.1103) loss_zs_kd 0.0629 (0.0658) loss_oracle 0.5583 (0.5975) kd_loss 1.1799 (1.1626) acc 100.0000 (97.0312) gate/entropy 1.0924 (1.0922) gate/usage_max 0.3863 (0.3872) gate/usage_min 0.3064 (0.3057) gate/usage_std 0.0375 (0.0381) teacher/entropy 0.0010 (0.0192) teacher/usage_max 0.5001 (0.5753) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2357 (0.2450) nleep/row_max_mean 1521.1772 (1506.8564) nleep/row_max_std 40.0484 (61.3033) nleep/row_min_mean 1487.4540 (1472.4758) lr 1.4258e-03 eta 0:10:21
epoch [20/50] batch [40/160] time 0.106 (0.114) data 0.000 (0.008) loss 1.0678 (1.0320) teacher_loss 0.1387 (0.1144) loss_zs_kd 0.0709 (0.0675) loss_oracle 0.6239 (0.6077) kd_loss 1.1633 (1.1601) acc 96.8750 (97.3438) gate/entropy 1.0928 (1.0924) gate/usage_max 0.3846 (0.3863) gate/usage_min 0.3074 (0.3064) gate/usage_std 0.0362 (0.0375) teacher/entropy 0.0142 (0.0200) teacher/usage_max 0.5013 (0.5644) teacher/usage_min 0.0023 (0.0045) teacher/usage_std 0.2341 (0.2420) nleep/row_max_mean 1507.9840 (1505.9448) nleep/row_max_std 60.8525 (65.4392) nleep/row_min_mean 1475.0460 (1471.9707) lr 1.4258e-03 eta 0:09:21
epoch [20/50] batch [60/160] time 0.116 (0.112) data 0.001 (0.005) loss 0.9442 (1.0365) teacher_loss 0.0669 (0.1221) loss_zs_kd 0.0593 (0.0665) loss_oracle 0.5519 (0.6045) kd_loss 1.1435 (1.1577) acc 96.8750 (96.9792) gate/entropy 1.0932 (1.0926) gate/usage_max 0.3830 (0.3855) gate/usage_min 0.3078 (0.3068) gate/usage_std 0.0351 (0.0369) teacher/entropy 0.0292 (0.0209) teacher/usage_max 0.5325 (0.5668) teacher/usage_min 0.0147 (0.0049) teacher/usage_std 0.2276 (0.2426) nleep/row_max_mean 1508.4961 (1505.9062) nleep/row_max_std 61.3856 (64.1341) nleep/row_min_mean 1475.8965 (1472.1041) lr 1.4258e-03 eta 0:09:06
epoch [20/50] batch [80/160] time 0.110 (0.109) data 0.000 (0.004) loss 1.0120 (1.0358) teacher_loss 0.0812 (0.1227) loss_zs_kd 0.0817 (0.0694) loss_oracle 0.6424 (0.6001) kd_loss 1.1375 (1.1567) acc 100.0000 (96.7969) gate/entropy 1.0936 (1.0928) gate/usage_max 0.3812 (0.3846) gate/usage_min 0.3082 (0.3071) gate/usage_std 0.0339 (0.0363) teacher/entropy 0.0342 (0.0207) teacher/usage_max 0.6371 (0.5674) teacher/usage_min 0.0004 (0.0043) teacher/usage_std 0.2607 (0.2431) nleep/row_max_mean 1509.8417 (1506.3306) nleep/row_max_std 58.7548 (63.1317) nleep/row_min_mean 1477.2284 (1472.4074) lr 1.4258e-03 eta 0:08:52
epoch [20/50] batch [100/160] time 0.103 (0.107) data 0.000 (0.003) loss 1.0295 (1.0372) teacher_loss 0.1276 (0.1226) loss_zs_kd 0.0704 (0.0691) loss_oracle 0.5926 (0.6050) kd_loss 1.1408 (1.1549) acc 93.7500 (96.7188) gate/entropy 1.0939 (1.0930) gate/usage_max 0.3795 (0.3838) gate/usage_min 0.3086 (0.3074) gate/usage_std 0.0327 (0.0357) teacher/entropy 0.0288 (0.0212) teacher/usage_max 0.5262 (0.5649) teacher/usage_min 0.0003 (0.0038) teacher/usage_std 0.2365 (0.2427) nleep/row_max_mean 1509.6755 (1506.6308) nleep/row_max_std 80.9772 (62.7519) nleep/row_min_mean 1476.0193 (1472.6972) lr 1.4258e-03 eta 0:08:42
epoch [20/50] batch [120/160] time 0.104 (0.106) data 0.000 (0.003) loss 0.9809 (1.0398) teacher_loss 0.0632 (0.1243) loss_zs_kd 0.0746 (0.0701) loss_oracle 0.6100 (0.6072) kd_loss 1.1511 (1.1537) acc 96.8750 (96.6667) gate/entropy 1.0942 (1.0932) gate/usage_max 0.3780 (0.3829) gate/usage_min 0.3085 (0.3076) gate/usage_std 0.0316 (0.0351) teacher/entropy 0.0112 (0.0209) teacher/usage_max 0.5302 (0.5600) teacher/usage_min 0.0296 (0.0039) teacher/usage_std 0.2179 (0.2416) nleep/row_max_mean 1516.4602 (1506.9643) nleep/row_max_std 49.1246 (63.0720) nleep/row_min_mean 1480.6443 (1473.0371) lr 1.4258e-03 eta 0:08:33
epoch [20/50] batch [140/160] time 0.110 (0.106) data 0.000 (0.002) loss 0.9777 (1.0329) teacher_loss 0.0529 (0.1179) loss_zs_kd 0.0579 (0.0695) loss_oracle 0.6946 (0.6094) kd_loss 1.0970 (1.1512) acc 100.0000 (96.8750) gate/entropy 1.0946 (1.0934) gate/usage_max 0.3760 (0.3821) gate/usage_min 0.3089 (0.3078) gate/usage_std 0.0303 (0.0345) teacher/entropy 0.0661 (0.0222) teacher/usage_max 0.5586 (0.5583) teacher/usage_min 0.0001 (0.0035) teacher/usage_std 0.2405 (0.2413) nleep/row_max_mean 1504.5547 (1507.1651) nleep/row_max_std 79.9469 (62.8402) nleep/row_min_mean 1470.6866 (1473.1645) lr 1.4258e-03 eta 0:08:29
epoch [20/50] batch [160/160] time 0.078 (0.104) data 0.000 (0.002) loss 0.9908 (1.0335) teacher_loss 0.0264 (0.1172) loss_zs_kd 0.0676 (0.0697) loss_oracle 0.7025 (0.6135) kd_loss 1.1586 (1.1493) acc 100.0000 (96.8750) gate/entropy 1.0949 (1.0935) gate/usage_max 0.3743 (0.3812) gate/usage_min 0.3092 (0.3079) gate/usage_std 0.0291 (0.0339) teacher/entropy 0.0002 (0.0227) teacher/usage_max 0.6250 (0.5635) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2569 (0.2427) nleep/row_max_mean 1515.2563 (1506.8657) nleep/row_max_std 44.5905 (63.6361) nleep/row_min_mean 1478.9604 (1472.8654) lr 1.3681e-03 eta 0:08:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.0%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [21/50] batch [20/160] time 0.094 (0.145) data 0.000 (0.013) loss 0.9647 (1.0139) teacher_loss 0.0563 (0.1120) loss_zs_kd 0.0737 (0.0684) loss_oracle 0.5889 (0.6031) kd_loss 1.1542 (1.1322) acc 100.0000 (97.8125) gate/entropy 1.0951 (1.0950) gate/usage_max 0.3727 (0.3733) gate/usage_min 0.3094 (0.3093) gate/usage_std 0.0280 (0.0285) teacher/entropy 0.0028 (0.0278) teacher/usage_max 0.5630 (0.5741) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2412 (0.2456) nleep/row_max_mean 1518.4434 (1506.4991) nleep/row_max_std 44.5142 (67.8711) nleep/row_min_mean 1483.9739 (1472.9595) lr 1.3681e-03 eta 0:11:34
epoch [21/50] batch [40/160] time 0.084 (0.121) data 0.000 (0.007) loss 0.9470 (1.0244) teacher_loss 0.0394 (0.1160) loss_zs_kd 0.0522 (0.0685) loss_oracle 0.6134 (0.6152) kd_loss 1.1495 (1.1332) acc 100.0000 (96.9531) gate/entropy 1.0954 (1.0952) gate/usage_max 0.3709 (0.3725) gate/usage_min 0.3098 (0.3095) gate/usage_std 0.0269 (0.0279) teacher/entropy 0.0074 (0.0254) teacher/usage_max 0.5302 (0.5735) teacher/usage_min 0.0004 (0.0028) teacher/usage_std 0.2367 (0.2460) nleep/row_max_mean 1493.6130 (1509.3500) nleep/row_max_std 74.0122 (62.3710) nleep/row_min_mean 1457.9209 (1475.1357) lr 1.3681e-03 eta 0:09:34
epoch [21/50] batch [60/160] time 0.098 (0.112) data 0.000 (0.005) loss 0.9960 (1.0361) teacher_loss 0.0356 (0.1258) loss_zs_kd 0.0871 (0.0663) loss_oracle 0.7013 (0.6222) kd_loss 1.1322 (1.1321) acc 100.0000 (96.7188) gate/entropy 1.0956 (1.0953) gate/usage_max 0.3694 (0.3717) gate/usage_min 0.3100 (0.3096) gate/usage_std 0.0259 (0.0274) teacher/entropy 0.0214 (0.0252) teacher/usage_max 0.5073 (0.5658) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.2358 (0.2438) nleep/row_max_mean 1513.6711 (1509.1873) nleep/row_max_std 57.9600 (63.2767) nleep/row_min_mean 1477.8174 (1474.8535) lr 1.3681e-03 eta 0:08:48
epoch [21/50] batch [80/160] time 0.078 (0.108) data 0.000 (0.003) loss 0.9500 (1.0320) teacher_loss 0.0627 (0.1217) loss_zs_kd 0.0759 (0.0674) loss_oracle 0.5974 (0.6237) kd_loss 1.1014 (1.1296) acc 100.0000 (96.8359) gate/entropy 1.0959 (1.0954) gate/usage_max 0.3677 (0.3709) gate/usage_min 0.3101 (0.3098) gate/usage_std 0.0248 (0.0269) teacher/entropy 0.0514 (0.0265) teacher/usage_max 0.5798 (0.5652) teacher/usage_min 0.0124 (0.0028) teacher/usage_std 0.2376 (0.2433) nleep/row_max_mean 1481.0299 (1508.4901) nleep/row_max_std 96.8757 (63.5781) nleep/row_min_mean 1449.1392 (1474.3955) lr 1.3681e-03 eta 0:08:31
epoch [21/50] batch [100/160] time 0.105 (0.106) data 0.000 (0.003) loss 1.1132 (1.0351) teacher_loss 0.1356 (0.1213) loss_zs_kd 0.0841 (0.0683) loss_oracle 0.7329 (0.6310) kd_loss 1.1382 (1.1282) acc 93.7500 (96.7188) gate/entropy 1.0961 (1.0955) gate/usage_max 0.3659 (0.3701) gate/usage_min 0.3104 (0.3099) gate/usage_std 0.0237 (0.0263) teacher/entropy 0.0065 (0.0263) teacher/usage_max 0.5951 (0.5710) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2482 (0.2445) nleep/row_max_mean 1511.4867 (1508.6616) nleep/row_max_std 45.2179 (63.0200) nleep/row_min_mean 1477.6348 (1474.6757) lr 1.3681e-03 eta 0:08:18
epoch [21/50] batch [120/160] time 0.073 (0.104) data 0.000 (0.002) loss 0.9704 (1.0319) teacher_loss 0.0774 (0.1165) loss_zs_kd 0.0555 (0.0693) loss_oracle 0.6004 (0.6345) kd_loss 1.1301 (1.1270) acc 100.0000 (96.8750) gate/entropy 1.0963 (1.0956) gate/usage_max 0.3642 (0.3692) gate/usage_min 0.3104 (0.3099) gate/usage_std 0.0227 (0.0258) teacher/entropy 0.0192 (0.0263) teacher/usage_max 0.5682 (0.5682) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2422 (0.2439) nleep/row_max_mean 1497.0791 (1508.5894) nleep/row_max_std 63.4399 (62.6704) nleep/row_min_mean 1466.2974 (1474.7291) lr 1.3681e-03 eta 0:08:08
epoch [21/50] batch [140/160] time 0.097 (0.103) data 0.000 (0.002) loss 1.0525 (1.0339) teacher_loss 0.1395 (0.1168) loss_zs_kd 0.0888 (0.0692) loss_oracle 0.6568 (0.6398) kd_loss 1.0804 (1.1251) acc 96.8750 (96.6518) gate/entropy 1.0965 (1.0958) gate/usage_max 0.3627 (0.3684) gate/usage_min 0.3103 (0.3100) gate/usage_std 0.0219 (0.0253) teacher/entropy 0.0597 (0.0264) teacher/usage_max 0.5547 (0.5717) teacher/usage_min 0.0056 (0.0028) teacher/usage_std 0.2364 (0.2447) nleep/row_max_mean 1486.5503 (1508.9030) nleep/row_max_std 86.7745 (62.4660) nleep/row_min_mean 1452.5520 (1475.0407) lr 1.3681e-03 eta 0:07:58
epoch [21/50] batch [160/160] time 0.086 (0.100) data 0.000 (0.002) loss 1.0494 (1.0363) teacher_loss 0.1281 (0.1194) loss_zs_kd 0.0764 (0.0699) loss_oracle 0.6475 (0.6413) kd_loss 1.1188 (1.1226) acc 96.8750 (96.5430) gate/entropy 1.0967 (1.0959) gate/usage_max 0.3610 (0.3676) gate/usage_min 0.3105 (0.3101) gate/usage_std 0.0209 (0.0248) teacher/entropy 0.0217 (0.0274) teacher/usage_max 0.5144 (0.5710) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2360 (0.2440) nleep/row_max_mean 1522.0776 (1508.7586) nleep/row_max_std 61.9877 (63.2100) nleep/row_min_mean 1486.6094 (1474.9616) lr 1.3090e-03 eta 0:07:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,998
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.6%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [22/50] batch [20/160] time 0.174 (0.165) data 0.000 (0.014) loss 0.9589 (1.0416) teacher_loss 0.0592 (0.1234) loss_zs_kd 0.0856 (0.0758) loss_oracle 0.6083 (0.6453) kd_loss 1.1056 (1.1153) acc 100.0000 (96.4062) gate/entropy 1.0968 (1.0967) gate/usage_max 0.3594 (0.3601) gate/usage_min 0.3105 (0.3106) gate/usage_std 0.0201 (0.0204) teacher/entropy 0.0314 (0.0214) teacher/usage_max 0.5037 (0.5642) teacher/usage_min 0.0073 (0.0044) teacher/usage_std 0.2306 (0.2420) nleep/row_max_mean 1502.0293 (1508.0775) nleep/row_max_std 69.1770 (64.4471) nleep/row_min_mean 1471.3596 (1474.9268) lr 1.3090e-03 eta 0:12:40
epoch [22/50] batch [40/160] time 0.110 (0.132) data 0.000 (0.007) loss 1.0892 (1.0400) teacher_loss 0.1655 (0.1268) loss_zs_kd 0.0500 (0.0747) loss_oracle 0.7077 (0.6386) kd_loss 1.0897 (1.1130) acc 93.7500 (96.4844) gate/entropy 1.0969 (1.0968) gate/usage_max 0.3579 (0.3593) gate/usage_min 0.3106 (0.3106) gate/usage_std 0.0193 (0.0200) teacher/entropy 0.0425 (0.0232) teacher/usage_max 0.5375 (0.5756) teacher/usage_min 0.0081 (0.0034) teacher/usage_std 0.2325 (0.2456) nleep/row_max_mean 1509.3640 (1508.0573) nleep/row_max_std 81.4704 (64.7213) nleep/row_min_mean 1472.4528 (1474.6321) lr 1.3090e-03 eta 0:10:06
epoch [22/50] batch [60/160] time 0.112 (0.122) data 0.000 (0.005) loss 0.9284 (1.0333) teacher_loss 0.0221 (0.1262) loss_zs_kd 0.0568 (0.0731) loss_oracle 0.6357 (0.6293) kd_loss 1.1201 (1.1117) acc 100.0000 (96.6146) gate/entropy 1.0970 (1.0969) gate/usage_max 0.3565 (0.3586) gate/usage_min 0.3106 (0.3106) gate/usage_std 0.0187 (0.0197) teacher/entropy 0.0094 (0.0234) teacher/usage_max 0.5603 (0.5759) teacher/usage_min 0.0004 (0.0050) teacher/usage_std 0.2405 (0.2443) nleep/row_max_mean 1497.5242 (1507.7227) nleep/row_max_std 75.4181 (63.2864) nleep/row_min_mean 1467.5304 (1474.6549) lr 1.3090e-03 eta 0:09:19
epoch [22/50] batch [80/160] time 0.119 (0.117) data 0.000 (0.004) loss 0.9137 (1.0254) teacher_loss 0.0200 (0.1193) loss_zs_kd 0.0901 (0.0735) loss_oracle 0.5714 (0.6287) kd_loss 1.1260 (1.1100) acc 100.0000 (96.8359) gate/entropy 1.0971 (1.0969) gate/usage_max 0.3549 (0.3578) gate/usage_min 0.3109 (0.3107) gate/usage_std 0.0180 (0.0193) teacher/entropy 0.0058 (0.0243) teacher/usage_max 0.5000 (0.5688) teacher/usage_min 0.0013 (0.0051) teacher/usage_std 0.2348 (0.2425) nleep/row_max_mean 1516.4167 (1507.2584) nleep/row_max_std 56.3820 (64.0488) nleep/row_min_mean 1483.5596 (1474.5137) lr 1.3090e-03 eta 0:08:52
epoch [22/50] batch [100/160] time 0.092 (0.115) data 0.001 (0.003) loss 0.9923 (1.0200) teacher_loss 0.1191 (0.1168) loss_zs_kd 0.0562 (0.0722) loss_oracle 0.5765 (0.6258) kd_loss 1.1137 (1.1084) acc 93.7500 (96.9062) gate/entropy 1.0972 (1.0970) gate/usage_max 0.3534 (0.3571) gate/usage_min 0.3110 (0.3107) gate/usage_std 0.0174 (0.0190) teacher/entropy 0.0158 (0.0249) teacher/usage_max 0.5008 (0.5665) teacher/usage_min 0.0009 (0.0055) teacher/usage_std 0.2351 (0.2419) nleep/row_max_mean 1495.5029 (1507.1068) nleep/row_max_std 78.0479 (63.8045) nleep/row_min_mean 1461.9988 (1474.4415) lr 1.3090e-03 eta 0:08:41
epoch [22/50] batch [120/160] time 0.115 (0.113) data 0.000 (0.003) loss 1.1148 (1.0180) teacher_loss 0.1998 (0.1170) loss_zs_kd 0.0659 (0.0708) loss_oracle 0.6543 (0.6244) kd_loss 1.1098 (1.1066) acc 96.8750 (96.9531) gate/entropy 1.0973 (1.0970) gate/usage_max 0.3521 (0.3564) gate/usage_min 0.3108 (0.3107) gate/usage_std 0.0171 (0.0187) teacher/entropy 0.0149 (0.0253) teacher/usage_max 0.5346 (0.5662) teacher/usage_min 0.0001 (0.0048) teacher/usage_std 0.2373 (0.2423) nleep/row_max_mean 1512.6659 (1507.7770) nleep/row_max_std 70.8315 (63.3033) nleep/row_min_mean 1477.9985 (1475.1324) lr 1.3090e-03 eta 0:08:31
epoch [22/50] batch [140/160] time 0.094 (0.111) data 0.000 (0.002) loss 0.9544 (1.0119) teacher_loss 0.0303 (0.1118) loss_zs_kd 0.0850 (0.0715) loss_oracle 0.6670 (0.6250) kd_loss 1.0961 (1.1038) acc 100.0000 (97.1205) gate/entropy 1.0973 (1.0971) gate/usage_max 0.3508 (0.3557) gate/usage_min 0.3107 (0.3107) gate/usage_std 0.0168 (0.0184) teacher/entropy 0.0259 (0.0273) teacher/usage_max 0.5390 (0.5651) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2378 (0.2419) nleep/row_max_mean 1517.0520 (1507.5476) nleep/row_max_std 49.9326 (62.9684) nleep/row_min_mean 1484.6223 (1475.1885) lr 1.3090e-03 eta 0:08:17
epoch [22/50] batch [160/160] time 0.081 (0.108) data 0.000 (0.002) loss 1.0522 (1.0117) teacher_loss 0.1586 (0.1133) loss_zs_kd 0.0476 (0.0717) loss_oracle 0.6327 (0.6225) kd_loss 1.1070 (1.1025) acc 96.8750 (97.0508) gate/entropy 1.0974 (1.0971) gate/usage_max 0.3495 (0.3549) gate/usage_min 0.3108 (0.3108) gate/usage_std 0.0164 (0.0182) teacher/entropy 0.0084 (0.0277) teacher/usage_max 0.5929 (0.5639) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2476 (0.2416) nleep/row_max_mean 1508.1865 (1507.3947) nleep/row_max_std 62.2437 (63.0932) nleep/row_min_mean 1474.2588 (1475.1676) lr 1.2487e-03 eta 0:08:03
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,003
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.6%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [23/50] batch [20/160] time 0.159 (0.159) data 0.000 (0.016) loss 1.0195 (0.9883) teacher_loss 0.1265 (0.1121) loss_zs_kd 0.1005 (0.0644) loss_oracle 0.6130 (0.6057) kd_loss 1.0724 (1.0822) acc 93.7500 (96.7188) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3481 (0.3487) gate/usage_min 0.3108 (0.3109) gate/usage_std 0.0162 (0.0162) teacher/entropy 0.0423 (0.0314) teacher/usage_max 0.5640 (0.5926) teacher/usage_min 0.0065 (0.0085) teacher/usage_std 0.2375 (0.2502) nleep/row_max_mean 1491.9404 (1507.2035) nleep/row_max_std 81.9922 (60.4215) nleep/row_min_mean 1462.3668 (1475.8446) lr 1.2487e-03 eta 0:11:49
epoch [23/50] batch [40/160] time 0.112 (0.131) data 0.000 (0.008) loss 0.9393 (0.9894) teacher_loss 0.0459 (0.1200) loss_zs_kd 0.0871 (0.0660) loss_oracle 0.6069 (0.5900) kd_loss 1.0930 (1.0828) acc 100.0000 (96.2500) gate/entropy 1.0975 (1.0974) gate/usage_max 0.3468 (0.3480) gate/usage_min 0.3109 (0.3108) gate/usage_std 0.0160 (0.0162) teacher/entropy 0.0323 (0.0348) teacher/usage_max 0.5572 (0.5851) teacher/usage_min 0.0071 (0.0077) teacher/usage_std 0.2360 (0.2468) nleep/row_max_mean 1510.7573 (1505.5507) nleep/row_max_std 60.6374 (61.6710) nleep/row_min_mean 1478.7876 (1474.6813) lr 1.2487e-03 eta 0:09:40
epoch [23/50] batch [60/160] time 0.098 (0.123) data 0.001 (0.005) loss 1.0551 (1.0066) teacher_loss 0.2379 (0.1375) loss_zs_kd 0.0647 (0.0672) loss_oracle 0.4746 (0.5905) kd_loss 1.0950 (1.0806) acc 90.6250 (96.0417) gate/entropy 1.0975 (1.0974) gate/usage_max 0.3458 (0.3475) gate/usage_min 0.3108 (0.3108) gate/usage_std 0.0160 (0.0161) teacher/entropy 0.0339 (0.0360) teacher/usage_max 0.6033 (0.5822) teacher/usage_min 0.0008 (0.0077) teacher/usage_std 0.2499 (0.2459) nleep/row_max_mean 1496.5288 (1504.8704) nleep/row_max_std 70.5859 (63.9551) nleep/row_min_mean 1467.5032 (1473.9021) lr 1.2487e-03 eta 0:09:02
epoch [23/50] batch [80/160] time 0.087 (0.120) data 0.000 (0.004) loss 1.0774 (0.9967) teacher_loss 0.2370 (0.1277) loss_zs_kd 0.0628 (0.0660) loss_oracle 0.5140 (0.5915) kd_loss 1.1039 (1.0804) acc 96.8750 (96.4062) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3447 (0.3469) gate/usage_min 0.3107 (0.3108) gate/usage_std 0.0160 (0.0161) teacher/entropy 0.0214 (0.0359) teacher/usage_max 0.5838 (0.5798) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.2454 (0.2451) nleep/row_max_mean 1497.2670 (1504.1651) nleep/row_max_std 77.6624 (65.2006) nleep/row_min_mean 1466.4509 (1473.2370) lr 1.2487e-03 eta 0:08:48
epoch [23/50] batch [100/160] time 0.104 (0.117) data 0.000 (0.003) loss 0.9315 (0.9943) teacher_loss 0.0760 (0.1240) loss_zs_kd 0.0831 (0.0682) loss_oracle 0.5512 (0.5929) kd_loss 1.0768 (1.0794) acc 96.8750 (96.5312) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3459 (0.3466) gate/usage_min 0.3107 (0.3108) gate/usage_std 0.0160 (0.0160) teacher/entropy 0.0372 (0.0362) teacher/usage_max 0.4951 (0.5762) teacher/usage_min 0.0110 (0.0075) teacher/usage_std 0.2279 (0.2443) nleep/row_max_mean 1515.6636 (1504.6781) nleep/row_max_std 58.8276 (64.4862) nleep/row_min_mean 1483.9609 (1473.8490) lr 1.2487e-03 eta 0:08:30
epoch [23/50] batch [120/160] time 0.106 (0.115) data 0.000 (0.003) loss 0.9038 (0.9932) teacher_loss 0.0495 (0.1233) loss_zs_kd 0.0373 (0.0685) loss_oracle 0.6252 (0.5913) kd_loss 1.0461 (1.0801) acc 100.0000 (96.7188) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3472 (0.3466) gate/usage_min 0.3106 (0.3108) gate/usage_std 0.0162 (0.0161) teacher/entropy 0.0552 (0.0351) teacher/usage_max 0.5926 (0.5736) teacher/usage_min 0.0163 (0.0073) teacher/usage_std 0.2388 (0.2435) nleep/row_max_mean 1520.3586 (1505.2140) nleep/row_max_std 46.2366 (63.4947) nleep/row_min_mean 1487.0493 (1474.4007) lr 1.2487e-03 eta 0:08:21
epoch [23/50] batch [140/160] time 0.072 (0.113) data 0.000 (0.002) loss 0.9219 (0.9936) teacher_loss 0.0502 (0.1217) loss_zs_kd 0.0840 (0.0698) loss_oracle 0.6124 (0.5943) kd_loss 1.0470 (1.0797) acc 100.0000 (96.6071) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3482 (0.3467) gate/usage_min 0.3107 (0.3108) gate/usage_std 0.0162 (0.0161) teacher/entropy 0.0653 (0.0346) teacher/usage_max 0.5076 (0.5714) teacher/usage_min 0.0081 (0.0075) teacher/usage_std 0.2302 (0.2427) nleep/row_max_mean 1511.0662 (1505.6329) nleep/row_max_std 43.5198 (62.8785) nleep/row_min_mean 1480.2864 (1474.9541) lr 1.2487e-03 eta 0:08:08
epoch [23/50] batch [160/160] time 0.069 (0.107) data 0.000 (0.002) loss 1.0162 (0.9946) teacher_loss 0.1671 (0.1222) loss_zs_kd 0.0531 (0.0694) loss_oracle 0.5341 (0.5963) kd_loss 1.1110 (1.0790) acc 96.8750 (96.6211) gate/entropy 1.0974 (1.0974) gate/usage_max 0.3496 (0.3470) gate/usage_min 0.3106 (0.3107) gate/usage_std 0.0165 (0.0161) teacher/entropy 0.0062 (0.0345) teacher/usage_max 0.5628 (0.5693) teacher/usage_min 0.0006 (0.0078) teacher/usage_std 0.2408 (0.2419) nleep/row_max_mean 1478.6110 (1505.4870) nleep/row_max_std 86.9902 (63.0814) nleep/row_min_mean 1452.0853 (1474.9442) lr 1.1874e-03 eta 0:07:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,816
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [24/50] batch [20/160] time 0.095 (0.085) data 0.000 (0.013) loss 1.0785 (1.0099) teacher_loss 0.1913 (0.1340) loss_zs_kd 0.0569 (0.0691) loss_oracle 0.6563 (0.6025) kd_loss 1.0612 (1.0801) acc 93.7500 (96.4062) gate/entropy 1.0973 (1.0973) gate/usage_max 0.3508 (0.3502) gate/usage_min 0.3106 (0.3106) gate/usage_std 0.0168 (0.0167) teacher/entropy 0.0201 (0.0261) teacher/usage_max 0.7183 (0.5712) teacher/usage_min 0.0016 (0.0066) teacher/usage_std 0.2950 (0.2434) nleep/row_max_mean 1507.1152 (1507.8392) nleep/row_max_std 82.1274 (61.4472) nleep/row_min_mean 1473.1060 (1477.3339) lr 1.1874e-03 eta 0:06:03
epoch [24/50] batch [40/160] time 0.093 (0.087) data 0.000 (0.006) loss 0.9461 (0.9924) teacher_loss 0.1022 (0.1151) loss_zs_kd 0.0618 (0.0705) loss_oracle 0.5746 (0.6039) kd_loss 1.0515 (1.0803) acc 96.8750 (96.9531) gate/entropy 1.0973 (1.0973) gate/usage_max 0.3517 (0.3508) gate/usage_min 0.3110 (0.3107) gate/usage_std 0.0169 (0.0168) teacher/entropy 0.0566 (0.0265) teacher/usage_max 0.5057 (0.5785) teacher/usage_min 0.0267 (0.0081) teacher/usage_std 0.2174 (0.2439) nleep/row_max_mean 1505.5371 (1505.7708) nleep/row_max_std 54.4559 (64.3360) nleep/row_min_mean 1476.6646 (1475.1035) lr 1.1874e-03 eta 0:06:14
epoch [24/50] batch [60/160] time 0.089 (0.089) data 0.001 (0.004) loss 1.1142 (0.9897) teacher_loss 0.2861 (0.1157) loss_zs_kd 0.0554 (0.0696) loss_oracle 0.5211 (0.6000) kd_loss 1.0797 (1.0785) acc 93.7500 (97.0833) gate/entropy 1.0973 (1.0973) gate/usage_max 0.3527 (0.3513) gate/usage_min 0.3110 (0.3108) gate/usage_std 0.0171 (0.0169) teacher/entropy 0.0400 (0.0281) teacher/usage_max 0.6203 (0.5802) teacher/usage_min 0.0083 (0.0067) teacher/usage_std 0.2513 (0.2449) nleep/row_max_mean 1478.4282 (1505.5641) nleep/row_max_std 89.6117 (65.0352) nleep/row_min_mean 1449.5498 (1474.7250) lr 1.1874e-03 eta 0:06:17
epoch [24/50] batch [80/160] time 0.095 (0.090) data 0.000 (0.003) loss 1.0659 (0.9864) teacher_loss 0.2238 (0.1146) loss_zs_kd 0.0622 (0.0675) loss_oracle 0.5415 (0.6008) kd_loss 1.0807 (1.0753) acc 93.7500 (97.1094) gate/entropy 1.0972 (1.0973) gate/usage_max 0.3539 (0.3518) gate/usage_min 0.3112 (0.3109) gate/usage_std 0.0175 (0.0170) teacher/entropy 0.0242 (0.0301) teacher/usage_max 0.5164 (0.5807) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2361 (0.2451) nleep/row_max_mean 1509.6090 (1505.7991) nleep/row_max_std 44.8504 (64.3812) nleep/row_min_mean 1477.4292 (1474.7989) lr 1.1874e-03 eta 0:06:22
epoch [24/50] batch [100/160] time 0.096 (0.092) data 0.000 (0.003) loss 0.9421 (0.9849) teacher_loss 0.0329 (0.1114) loss_zs_kd 0.0932 (0.0683) loss_oracle 0.6415 (0.6044) kd_loss 1.0835 (1.0741) acc 100.0000 (97.1875) gate/entropy 1.0972 (1.0973) gate/usage_max 0.3549 (0.3523) gate/usage_min 0.3110 (0.3109) gate/usage_std 0.0179 (0.0171) teacher/entropy 0.0099 (0.0301) teacher/usage_max 0.5621 (0.5763) teacher/usage_min 0.0013 (0.0070) teacher/usage_std 0.2403 (0.2438) nleep/row_max_mean 1505.4349 (1506.4900) nleep/row_max_std 69.0670 (62.6481) nleep/row_min_mean 1471.0127 (1475.3931) lr 1.1874e-03 eta 0:06:26
epoch [24/50] batch [120/160] time 0.096 (0.092) data 0.000 (0.002) loss 1.2238 (0.9855) teacher_loss 0.3792 (0.1111) loss_zs_kd 0.0702 (0.0695) loss_oracle 0.6059 (0.6072) kd_loss 1.0132 (1.0720) acc 90.6250 (97.1354) gate/entropy 1.0971 (1.0973) gate/usage_max 0.3558 (0.3528) gate/usage_min 0.3112 (0.3109) gate/usage_std 0.0182 (0.0173) teacher/entropy 0.0674 (0.0305) teacher/usage_max 0.6404 (0.5765) teacher/usage_min 0.0095 (0.0068) teacher/usage_std 0.2578 (0.2440) nleep/row_max_mean 1503.1608 (1506.5531) nleep/row_max_std 69.8275 (62.0995) nleep/row_min_mean 1475.2874 (1475.4468) lr 1.1874e-03 eta 0:06:28
epoch [24/50] batch [140/160] time 0.097 (0.093) data 0.000 (0.002) loss 1.2005 (0.9857) teacher_loss 0.2967 (0.1117) loss_zs_kd 0.0628 (0.0694) loss_oracle 0.6792 (0.6062) kd_loss 1.0655 (1.0725) acc 87.5000 (97.0759) gate/entropy 1.0970 (1.0972) gate/usage_max 0.3573 (0.3534) gate/usage_min 0.3111 (0.3109) gate/usage_std 0.0189 (0.0175) teacher/entropy 0.0271 (0.0289) teacher/usage_max 0.5399 (0.5749) teacher/usage_min 0.0003 (0.0060) teacher/usage_std 0.2378 (0.2440) nleep/row_max_mean 1515.4387 (1506.5944) nleep/row_max_std 62.9987 (61.5180) nleep/row_min_mean 1483.0370 (1475.5842) lr 1.1874e-03 eta 0:06:30
epoch [24/50] batch [160/160] time 0.087 (0.093) data 0.000 (0.002) loss 0.9638 (0.9848) teacher_loss 0.1006 (0.1109) loss_zs_kd 0.0514 (0.0703) loss_oracle 0.5869 (0.6070) kd_loss 1.0882 (1.0704) acc 96.8750 (97.1289) gate/entropy 1.0969 (1.0972) gate/usage_max 0.3586 (0.3540) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0196 (0.0177) teacher/entropy 0.0176 (0.0300) teacher/usage_max 0.5647 (0.5750) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.2415 (0.2443) nleep/row_max_mean 1508.3506 (1506.6523) nleep/row_max_std 62.8694 (61.6767) nleep/row_min_mean 1474.0439 (1475.5828) lr 1.1253e-03 eta 0:06:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [25/50] batch [20/160] time 0.113 (0.109) data 0.000 (0.018) loss 1.0413 (0.9767) teacher_loss 0.1787 (0.1218) loss_zs_kd 0.0802 (0.0634) loss_oracle 0.5821 (0.5869) kd_loss 1.0628 (1.0594) acc 96.8750 (97.1875) gate/entropy 1.0968 (1.0969) gate/usage_max 0.3596 (0.3591) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0201 (0.0198) teacher/entropy 0.0136 (0.0315) teacher/usage_max 0.6255 (0.5807) teacher/usage_min 0.0004 (0.0019) teacher/usage_std 0.2568 (0.2472) nleep/row_max_mean 1496.1606 (1508.4199) nleep/row_max_std 75.9227 (61.6894) nleep/row_min_mean 1466.1962 (1476.4127) lr 1.1253e-03 eta 0:07:31
epoch [25/50] batch [40/160] time 0.083 (0.101) data 0.000 (0.009) loss 0.9162 (0.9700) teacher_loss 0.0582 (0.1126) loss_zs_kd 0.0778 (0.0649) loss_oracle 0.5736 (0.5893) kd_loss 1.0647 (1.0606) acc 96.8750 (97.1875) gate/entropy 1.0967 (1.0968) gate/usage_max 0.3606 (0.3597) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0206 (0.0201) teacher/entropy 0.0309 (0.0297) teacher/usage_max 0.5149 (0.5696) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2360 (0.2437) nleep/row_max_mean 1506.2068 (1506.8734) nleep/row_max_std 50.9156 (61.0694) nleep/row_min_mean 1473.6774 (1475.1716) lr 1.1253e-03 eta 0:06:54
epoch [25/50] batch [60/160] time 0.104 (0.097) data 0.001 (0.006) loss 0.8929 (0.9737) teacher_loss 0.0806 (0.1173) loss_zs_kd 0.0563 (0.0668) loss_oracle 0.5365 (0.5873) kd_loss 1.0317 (1.0588) acc 96.8750 (96.9792) gate/entropy 1.0966 (1.0967) gate/usage_max 0.3620 (0.3602) gate/usage_min 0.3108 (0.3109) gate/usage_std 0.0213 (0.0204) teacher/entropy 0.0369 (0.0302) teacher/usage_max 0.6501 (0.5655) teacher/usage_min 0.0055 (0.0032) teacher/usage_std 0.2633 (0.2434) nleep/row_max_mean 1510.7008 (1508.0225) nleep/row_max_std 71.1039 (59.3329) nleep/row_min_mean 1478.0155 (1476.3108) lr 1.1253e-03 eta 0:06:36
epoch [25/50] batch [80/160] time 0.080 (0.095) data 0.000 (0.005) loss 0.9417 (0.9624) teacher_loss 0.1122 (0.1096) loss_zs_kd 0.0813 (0.0662) loss_oracle 0.5558 (0.5838) kd_loss 1.0219 (1.0555) acc 93.7500 (97.2656) gate/entropy 1.0965 (1.0967) gate/usage_max 0.3628 (0.3607) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0217 (0.0207) teacher/entropy 0.0659 (0.0333) teacher/usage_max 0.5185 (0.5622) teacher/usage_min 0.0001 (0.0039) teacher/usage_std 0.2361 (0.2418) nleep/row_max_mean 1507.8616 (1507.8674) nleep/row_max_std 48.6488 (60.3146) nleep/row_min_mean 1476.4944 (1476.2769) lr 1.1253e-03 eta 0:06:25
epoch [25/50] batch [100/160] time 0.154 (0.095) data 0.001 (0.004) loss 0.9426 (0.9690) teacher_loss 0.0871 (0.1167) loss_zs_kd 0.0639 (0.0669) loss_oracle 0.5905 (0.5831) kd_loss 1.0566 (1.0547) acc 96.8750 (97.0938) gate/entropy 1.0964 (1.0966) gate/usage_max 0.3637 (0.3613) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0223 (0.0209) teacher/entropy 0.0227 (0.0345) teacher/usage_max 0.5603 (0.5608) teacher/usage_min 0.0055 (0.0044) teacher/usage_std 0.2375 (0.2412) nleep/row_max_mean 1489.6633 (1506.6648) nleep/row_max_std 80.9765 (60.8714) nleep/row_min_mean 1460.3223 (1475.2375) lr 1.1253e-03 eta 0:06:25
epoch [25/50] batch [120/160] time 0.085 (0.095) data 0.000 (0.003) loss 1.0882 (0.9758) teacher_loss 0.1973 (0.1217) loss_zs_kd 0.0697 (0.0683) loss_oracle 0.6387 (0.5832) kd_loss 1.0733 (1.0566) acc 90.6250 (96.8750) gate/entropy 1.0963 (1.0966) gate/usage_max 0.3647 (0.3617) gate/usage_min 0.3110 (0.3109) gate/usage_std 0.0229 (0.0212) teacher/entropy 0.0141 (0.0324) teacher/usage_max 0.4995 (0.5598) teacher/usage_min 0.0019 (0.0047) teacher/usage_std 0.2344 (0.2410) nleep/row_max_mean 1497.0872 (1506.4097) nleep/row_max_std 86.5487 (61.0338) nleep/row_min_mean 1467.6290 (1475.0841) lr 1.1253e-03 eta 0:06:25
epoch [25/50] batch [140/160] time 0.102 (0.094) data 0.000 (0.003) loss 0.9414 (0.9770) teacher_loss 0.0821 (0.1221) loss_zs_kd 0.0445 (0.0678) loss_oracle 0.6301 (0.5849) kd_loss 1.0440 (1.0570) acc 96.8750 (96.8750) gate/entropy 1.0962 (1.0965) gate/usage_max 0.3657 (0.3622) gate/usage_min 0.3110 (0.3109) gate/usage_std 0.0234 (0.0215) teacher/entropy 0.0311 (0.0313) teacher/usage_max 0.5702 (0.5597) teacher/usage_min 0.0014 (0.0047) teacher/usage_std 0.2418 (0.2409) nleep/row_max_mean 1510.2177 (1506.3303) nleep/row_max_std 70.5239 (60.8308) nleep/row_min_mean 1476.9230 (1475.0247) lr 1.1253e-03 eta 0:06:19
epoch [25/50] batch [160/160] time 0.091 (0.094) data 0.000 (0.002) loss 0.9304 (0.9743) teacher_loss 0.0515 (0.1200) loss_zs_kd 0.0694 (0.0679) loss_oracle 0.6145 (0.5848) kd_loss 1.0740 (1.0559) acc 96.8750 (96.8945) gate/entropy 1.0960 (1.0965) gate/usage_max 0.3667 (0.3627) gate/usage_min 0.3110 (0.3109) gate/usage_std 0.0240 (0.0218) teacher/entropy 0.0169 (0.0315) teacher/usage_max 0.5303 (0.5591) teacher/usage_min 0.0041 (0.0047) teacher/usage_std 0.2343 (0.2408) nleep/row_max_mean 1504.7151 (1505.5356) nleep/row_max_std 68.0470 (61.4730) nleep/row_min_mean 1472.8418 (1474.3251) lr 1.0628e-03 eta 0:06:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,807
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,970
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.1%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [26/50] batch [20/160] time 0.111 (0.116) data 0.000 (0.018) loss 0.8826 (0.9945) teacher_loss 0.0370 (0.1304) loss_zs_kd 0.0808 (0.0706) loss_oracle 0.5273 (0.5991) kd_loss 1.0832 (1.0585) acc 100.0000 (96.4062) gate/entropy 1.0959 (1.0960) gate/usage_max 0.3676 (0.3671) gate/usage_min 0.3109 (0.3109) gate/usage_std 0.0246 (0.0243) teacher/entropy 0.0007 (0.0264) teacher/usage_max 0.5000 (0.5580) teacher/usage_min 0.0001 (0.0055) teacher/usage_std 0.2356 (0.2404) nleep/row_max_mean 1517.3779 (1501.8075) nleep/row_max_std 42.8626 (59.4009) nleep/row_min_mean 1485.9138 (1472.0247) lr 1.0628e-03 eta 0:07:40
epoch [26/50] batch [40/160] time 0.111 (0.108) data 0.001 (0.009) loss 1.0235 (1.0013) teacher_loss 0.1709 (0.1377) loss_zs_kd 0.0825 (0.0717) loss_oracle 0.6190 (0.5986) kd_loss 1.0036 (1.0569) acc 90.6250 (95.8594) gate/entropy 1.0958 (1.0959) gate/usage_max 0.3684 (0.3675) gate/usage_min 0.3110 (0.3109) gate/usage_std 0.0251 (0.0245) teacher/entropy 0.0601 (0.0269) teacher/usage_max 0.6023 (0.5734) teacher/usage_min 0.0524 (0.0095) teacher/usage_std 0.2247 (0.2415) nleep/row_max_mean 1496.6965 (1502.6429) nleep/row_max_std 75.4128 (61.7031) nleep/row_min_mean 1471.9032 (1473.2060) lr 1.0628e-03 eta 0:07:06
epoch [26/50] batch [60/160] time 0.101 (0.105) data 0.001 (0.006) loss 0.8982 (0.9951) teacher_loss 0.0286 (0.1363) loss_zs_kd 0.0653 (0.0704) loss_oracle 0.5875 (0.5915) kd_loss 1.0864 (1.0557) acc 100.0000 (96.3021) gate/entropy 1.0957 (1.0959) gate/usage_max 0.3690 (0.3679) gate/usage_min 0.3110 (0.3110) gate/usage_std 0.0255 (0.0248) teacher/entropy 0.0063 (0.0275) teacher/usage_max 0.5639 (0.5685) teacher/usage_min 0.0000 (0.0082) teacher/usage_std 0.2414 (0.2409) nleep/row_max_mean 1509.6248 (1503.2725) nleep/row_max_std 50.7953 (63.7396) nleep/row_min_mean 1478.5844 (1473.6226) lr 1.0628e-03 eta 0:06:53
epoch [26/50] batch [80/160] time 0.094 (0.103) data 0.000 (0.005) loss 0.8931 (0.9833) teacher_loss 0.0347 (0.1266) loss_zs_kd 0.0788 (0.0707) loss_oracle 0.5890 (0.5872) kd_loss 1.0492 (1.0554) acc 100.0000 (96.7188) gate/entropy 1.0956 (1.0958) gate/usage_max 0.3699 (0.3683) gate/usage_min 0.3111 (0.3110) gate/usage_std 0.0260 (0.0251) teacher/entropy 0.0525 (0.0274) teacher/usage_max 0.6229 (0.5707) teacher/usage_min 0.0005 (0.0084) teacher/usage_std 0.2560 (0.2410) nleep/row_max_mean 1519.5720 (1504.7231) nleep/row_max_std 29.4310 (61.1443) nleep/row_min_mean 1488.2893 (1474.7921) lr 1.0628e-03 eta 0:06:43
epoch [26/50] batch [100/160] time 0.086 (0.102) data 0.000 (0.004) loss 0.9151 (0.9799) teacher_loss 0.0509 (0.1232) loss_zs_kd 0.0619 (0.0703) loss_oracle 0.6530 (0.5901) kd_loss 1.0136 (1.0530) acc 100.0000 (96.8438) gate/entropy 1.0954 (1.0958) gate/usage_max 0.3709 (0.3688) gate/usage_min 0.3111 (0.3110) gate/usage_std 0.0267 (0.0253) teacher/entropy 0.0569 (0.0291) teacher/usage_max 0.5501 (0.5682) teacher/usage_min 0.0000 (0.0087) teacher/usage_std 0.2392 (0.2402) nleep/row_max_mean 1498.2820 (1504.4303) nleep/row_max_std 64.3868 (62.4627) nleep/row_min_mean 1470.7246 (1474.4586) lr 1.0628e-03 eta 0:06:36
epoch [26/50] batch [120/160] time 0.092 (0.101) data 0.000 (0.003) loss 1.1229 (0.9749) teacher_loss 0.2683 (0.1211) loss_zs_kd 0.0707 (0.0694) loss_oracle 0.5874 (0.5862) kd_loss 1.0512 (1.0520) acc 93.7500 (96.8750) gate/entropy 1.0953 (1.0957) gate/usage_max 0.3718 (0.3692) gate/usage_min 0.3111 (0.3110) gate/usage_std 0.0273 (0.0256) teacher/entropy 0.0199 (0.0296) teacher/usage_max 0.5372 (0.5679) teacher/usage_min 0.0001 (0.0087) teacher/usage_std 0.2376 (0.2402) nleep/row_max_mean 1506.3606 (1504.9655) nleep/row_max_std 56.6033 (62.3228) nleep/row_min_mean 1472.4778 (1474.7884) lr 1.0628e-03 eta 0:06:32
epoch [26/50] batch [140/160] time 0.096 (0.101) data 0.000 (0.003) loss 1.1994 (0.9738) teacher_loss 0.2952 (0.1205) loss_zs_kd 0.0774 (0.0695) loss_oracle 0.6953 (0.5858) kd_loss 1.0358 (1.0512) acc 93.7500 (96.8527) gate/entropy 1.0952 (1.0956) gate/usage_max 0.3727 (0.3696) gate/usage_min 0.3113 (0.3110) gate/usage_std 0.0279 (0.0259) teacher/entropy 0.0192 (0.0293) teacher/usage_max 0.6168 (0.5668) teacher/usage_min 0.0083 (0.0081) teacher/usage_std 0.2502 (0.2402) nleep/row_max_mean 1513.8695 (1505.8335) nleep/row_max_std 57.9324 (61.3943) nleep/row_min_mean 1482.8586 (1475.5590) lr 1.0628e-03 eta 0:06:28
epoch [26/50] batch [160/160] time 0.089 (0.099) data 0.000 (0.003) loss 0.9189 (0.9755) teacher_loss 0.0910 (0.1203) loss_zs_kd 0.0616 (0.0701) loss_oracle 0.5138 (0.5894) kd_loss 1.0804 (1.0510) acc 96.8750 (96.8750) gate/entropy 1.0950 (1.0956) gate/usage_max 0.3737 (0.3701) gate/usage_min 0.3112 (0.3111) gate/usage_std 0.0286 (0.0262) teacher/entropy 0.0124 (0.0286) teacher/usage_max 0.5938 (0.5677) teacher/usage_min 0.0041 (0.0078) teacher/usage_std 0.2456 (0.2406) nleep/row_max_mean 1510.3176 (1506.4034) nleep/row_max_std 71.4923 (60.5649) nleep/row_min_mean 1478.4456 (1476.0295) lr 1.0000e-03 eta 0:06:21
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,805
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,936
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.5%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [27/50] batch [20/160] time 0.100 (0.122) data 0.000 (0.015) loss 0.9400 (0.9392) teacher_loss 0.0772 (0.0991) loss_zs_kd 0.0785 (0.0672) loss_oracle 0.5685 (0.5683) kd_loss 1.0786 (1.0446) acc 96.8750 (97.5000) gate/entropy 1.0949 (1.0950) gate/usage_max 0.3742 (0.3739) gate/usage_min 0.3114 (0.3113) gate/usage_std 0.0289 (0.0287) teacher/entropy 0.0066 (0.0302) teacher/usage_max 0.5619 (0.5450) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.2411 (0.2373) nleep/row_max_mean 1522.0602 (1505.3161) nleep/row_max_std 26.0179 (59.9992) nleep/row_min_mean 1490.8864 (1475.2967) lr 1.0000e-03 eta 0:07:47
epoch [27/50] batch [40/160] time 0.093 (0.110) data 0.000 (0.007) loss 1.0503 (0.9671) teacher_loss 0.1901 (0.1240) loss_zs_kd 0.0677 (0.0688) loss_oracle 0.6069 (0.5717) kd_loss 1.0455 (1.0456) acc 93.7500 (96.5625) gate/entropy 1.0948 (1.0949) gate/usage_max 0.3749 (0.3743) gate/usage_min 0.3114 (0.3113) gate/usage_std 0.0294 (0.0290) teacher/entropy 0.0370 (0.0300) teacher/usage_max 0.4998 (0.5491) teacher/usage_min 0.0493 (0.0082) teacher/usage_std 0.2019 (0.2364) nleep/row_max_mean 1502.5221 (1503.5313) nleep/row_max_std 65.7486 (63.6669) nleep/row_min_mean 1470.7073 (1473.6356) lr 1.0000e-03 eta 0:06:56
epoch [27/50] batch [60/160] time 0.102 (0.105) data 0.000 (0.005) loss 0.8616 (0.9685) teacher_loss 0.0356 (0.1249) loss_zs_kd 0.0622 (0.0676) loss_oracle 0.5552 (0.5735) kd_loss 1.0345 (1.0461) acc 100.0000 (96.5625) gate/entropy 1.0946 (1.0948) gate/usage_max 0.3757 (0.3747) gate/usage_min 0.3114 (0.3113) gate/usage_std 0.0300 (0.0292) teacher/entropy 0.0565 (0.0301) teacher/usage_max 0.5766 (0.5510) teacher/usage_min 0.0265 (0.0088) teacher/usage_std 0.2290 (0.2363) nleep/row_max_mean 1492.5670 (1503.4387) nleep/row_max_std 86.0133 (62.7686) nleep/row_min_mean 1464.0669 (1473.7433) lr 1.0000e-03 eta 0:06:37
epoch [27/50] batch [80/160] time 0.101 (0.103) data 0.000 (0.004) loss 0.9647 (0.9660) teacher_loss 0.0984 (0.1208) loss_zs_kd 0.0601 (0.0678) loss_oracle 0.5961 (0.5765) kd_loss 1.0764 (1.0461) acc 96.8750 (96.6797) gate/entropy 1.0945 (1.0948) gate/usage_max 0.3766 (0.3750) gate/usage_min 0.3115 (0.3113) gate/usage_std 0.0306 (0.0295) teacher/entropy 0.0063 (0.0300) teacher/usage_max 0.5620 (0.5528) teacher/usage_min 0.0001 (0.0077) teacher/usage_std 0.2410 (0.2374) nleep/row_max_mean 1491.3066 (1503.4820) nleep/row_max_std 73.4876 (61.6650) nleep/row_min_mean 1463.7529 (1473.7213) lr 1.0000e-03 eta 0:06:27
epoch [27/50] batch [100/160] time 0.096 (0.102) data 0.001 (0.003) loss 0.9233 (0.9677) teacher_loss 0.0467 (0.1196) loss_zs_kd 0.0765 (0.0674) loss_oracle 0.6170 (0.5834) kd_loss 1.0597 (1.0455) acc 100.0000 (96.8438) gate/entropy 1.0943 (1.0947) gate/usage_max 0.3775 (0.3754) gate/usage_min 0.3112 (0.3113) gate/usage_std 0.0312 (0.0298) teacher/entropy 0.0169 (0.0286) teacher/usage_max 0.5302 (0.5579) teacher/usage_min 0.0038 (0.0073) teacher/usage_std 0.2345 (0.2390) nleep/row_max_mean 1482.9995 (1503.1422) nleep/row_max_std 91.6737 (62.7706) nleep/row_min_mean 1451.8175 (1473.1413) lr 1.0000e-03 eta 0:06:21
epoch [27/50] batch [120/160] time 0.091 (0.102) data 0.000 (0.003) loss 0.9468 (0.9661) teacher_loss 0.0990 (0.1182) loss_zs_kd 0.0614 (0.0684) loss_oracle 0.5851 (0.5836) kd_loss 1.0491 (1.0437) acc 96.8750 (96.9010) gate/entropy 1.0942 (1.0946) gate/usage_max 0.3781 (0.3758) gate/usage_min 0.3104 (0.3113) gate/usage_std 0.0317 (0.0301) teacher/entropy 0.0196 (0.0291) teacher/usage_max 0.4991 (0.5566) teacher/usage_min 0.0018 (0.0085) teacher/usage_std 0.2344 (0.2382) nleep/row_max_mean 1488.7555 (1502.9395) nleep/row_max_std 81.3691 (62.7398) nleep/row_min_mean 1461.0007 (1472.8505) lr 1.0000e-03 eta 0:06:18
epoch [27/50] batch [140/160] time 0.094 (0.101) data 0.000 (0.002) loss 0.9001 (0.9661) teacher_loss 0.0424 (0.1183) loss_zs_kd 0.0643 (0.0689) loss_oracle 0.5639 (0.5847) kd_loss 1.0872 (1.0420) acc 100.0000 (96.8750) gate/entropy 1.0940 (1.0945) gate/usage_max 0.3789 (0.3762) gate/usage_min 0.3098 (0.3111) gate/usage_std 0.0322 (0.0303) teacher/entropy 0.0166 (0.0289) teacher/usage_max 0.6563 (0.5657) teacher/usage_min 0.0248 (0.0081) teacher/usage_std 0.2580 (0.2413) nleep/row_max_mean 1480.5670 (1503.0072) nleep/row_max_std 77.4706 (61.8779) nleep/row_min_mean 1453.9775 (1472.8320) lr 1.0000e-03 eta 0:06:14
epoch [27/50] batch [160/160] time 0.090 (0.100) data 0.000 (0.002) loss 1.2025 (0.9663) teacher_loss 0.3293 (0.1185) loss_zs_kd 0.0930 (0.0693) loss_oracle 0.6249 (0.5861) kd_loss 1.0284 (1.0402) acc 90.6250 (96.8945) gate/entropy 1.0938 (1.0945) gate/usage_max 0.3798 (0.3766) gate/usage_min 0.3090 (0.3108) gate/usage_std 0.0329 (0.0306) teacher/entropy 0.0267 (0.0299) teacher/usage_max 0.5587 (0.5655) teacher/usage_min 0.0066 (0.0088) teacher/usage_std 0.2365 (0.2408) nleep/row_max_mean 1489.7413 (1502.9704) nleep/row_max_std 78.1851 (61.4521) nleep/row_min_mean 1455.5688 (1472.8167) lr 9.3721e-04 eta 0:06:08
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,818
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,943
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [28/50] batch [20/160] time 0.100 (0.127) data 0.000 (0.017) loss 0.8272 (0.9587) teacher_loss 0.0812 (0.1320) loss_zs_kd 0.0425 (0.0639) loss_oracle 0.4958 (0.5631) kd_loss 0.9538 (1.0262) acc 100.0000 (96.5625) gate/entropy 1.0937 (1.0937) gate/usage_max 0.3806 (0.3803) gate/usage_min 0.3083 (0.3086) gate/usage_std 0.0334 (0.0332) teacher/entropy 0.1136 (0.0348) teacher/usage_max 0.5074 (0.5582) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.2358 (0.2386) nleep/row_max_mean 1514.1345 (1502.7173) nleep/row_max_std 23.7659 (56.4546) nleep/row_min_mean 1484.1525 (1472.7484) lr 9.3721e-04 eta 0:07:43
epoch [28/50] batch [40/160] time 0.104 (0.115) data 0.000 (0.009) loss 0.8777 (0.9580) teacher_loss 0.0652 (0.1279) loss_zs_kd 0.0820 (0.0646) loss_oracle 0.5375 (0.5654) kd_loss 1.0054 (1.0302) acc 100.0000 (96.8750) gate/entropy 1.0935 (1.0937) gate/usage_max 0.3815 (0.3807) gate/usage_min 0.3075 (0.3083) gate/usage_std 0.0341 (0.0335) teacher/entropy 0.0382 (0.0308) teacher/usage_max 0.6061 (0.5595) teacher/usage_min 0.0199 (0.0062) teacher/usage_std 0.2410 (0.2394) nleep/row_max_mean 1499.5237 (1500.9671) nleep/row_max_std 66.9297 (60.9496) nleep/row_min_mean 1469.7615 (1471.1453) lr 9.3721e-04 eta 0:06:56
epoch [28/50] batch [60/160] time 0.104 (0.110) data 0.001 (0.006) loss 0.9763 (0.9546) teacher_loss 0.0744 (0.1187) loss_zs_kd 0.0567 (0.0668) loss_oracle 0.6797 (0.5751) kd_loss 1.0674 (1.0298) acc 96.8750 (96.9271) gate/entropy 1.0933 (1.0936) gate/usage_max 0.3823 (0.3811) gate/usage_min 0.3069 (0.3080) gate/usage_std 0.0347 (0.0338) teacher/entropy 0.0029 (0.0320) teacher/usage_max 0.5308 (0.5602) teacher/usage_min 0.0001 (0.0070) teacher/usage_std 0.2370 (0.2393) nleep/row_max_mean 1517.6422 (1501.4843) nleep/row_max_std 42.7820 (61.1982) nleep/row_min_mean 1486.9739 (1471.7165) lr 9.3721e-04 eta 0:06:36
epoch [28/50] batch [80/160] time 0.096 (0.106) data 0.000 (0.005) loss 0.9046 (0.9498) teacher_loss 0.0770 (0.1110) loss_zs_kd 0.0842 (0.0676) loss_oracle 0.5685 (0.5791) kd_loss 1.0026 (1.0307) acc 96.8750 (97.1484) gate/entropy 1.0932 (1.0935) gate/usage_max 0.3828 (0.3814) gate/usage_min 0.3064 (0.3076) gate/usage_std 0.0350 (0.0340) teacher/entropy 0.0630 (0.0313) teacher/usage_max 0.4955 (0.5587) teacher/usage_min 0.0128 (0.0074) teacher/usage_std 0.2267 (0.2387) nleep/row_max_mean 1492.0354 (1502.5347) nleep/row_max_std 86.0882 (59.3572) nleep/row_min_mean 1464.5835 (1472.8890) lr 9.3721e-04 eta 0:06:23
epoch [28/50] batch [100/160] time 0.100 (0.105) data 0.000 (0.004) loss 0.9040 (0.9501) teacher_loss 0.0867 (0.1118) loss_zs_kd 0.0711 (0.0690) loss_oracle 0.5722 (0.5801) kd_loss 0.9913 (1.0275) acc 100.0000 (97.0312) gate/entropy 1.0931 (1.0934) gate/usage_max 0.3834 (0.3818) gate/usage_min 0.3059 (0.3073) gate/usage_std 0.0354 (0.0343) teacher/entropy 0.0650 (0.0337) teacher/usage_max 0.5349 (0.5604) teacher/usage_min 0.0315 (0.0090) teacher/usage_std 0.2174 (0.2387) nleep/row_max_mean 1484.8789 (1502.3194) nleep/row_max_std 79.6047 (60.3863) nleep/row_min_mean 1457.7345 (1472.7879) lr 9.3721e-04 eta 0:06:14
epoch [28/50] batch [120/160] time 0.075 (0.105) data 0.000 (0.003) loss 0.8370 (0.9514) teacher_loss 0.0438 (0.1161) loss_zs_kd 0.0532 (0.0686) loss_oracle 0.5521 (0.5766) kd_loss 0.9811 (1.0252) acc 100.0000 (96.8750) gate/entropy 1.0929 (1.0934) gate/usage_max 0.3842 (0.3821) gate/usage_min 0.3052 (0.3070) gate/usage_std 0.0361 (0.0345) teacher/entropy 0.0568 (0.0345) teacher/usage_max 0.6148 (0.5641) teacher/usage_min 0.0002 (0.0107) teacher/usage_std 0.2535 (0.2385) nleep/row_max_mean 1509.0037 (1502.6057) nleep/row_max_std 42.9900 (59.9289) nleep/row_min_mean 1480.8058 (1473.1430) lr 9.3721e-04 eta 0:06:12
epoch [28/50] batch [140/160] time 0.088 (0.103) data 0.000 (0.003) loss 0.9330 (0.9505) teacher_loss 0.1198 (0.1163) loss_zs_kd 0.0792 (0.0677) loss_oracle 0.5180 (0.5755) kd_loss 1.0293 (1.0251) acc 96.8750 (96.8080) gate/entropy 1.0927 (1.0933) gate/usage_max 0.3853 (0.3825) gate/usage_min 0.3046 (0.3067) gate/usage_std 0.0368 (0.0348) teacher/entropy 0.0337 (0.0349) teacher/usage_max 0.5068 (0.5648) teacher/usage_min 0.0004 (0.0102) teacher/usage_std 0.2355 (0.2390) nleep/row_max_mean 1521.1526 (1502.2778) nleep/row_max_std 33.7351 (60.0114) nleep/row_min_mean 1488.1710 (1472.8708) lr 9.3721e-04 eta 0:06:05
epoch [28/50] batch [160/160] time 0.086 (0.101) data 0.000 (0.002) loss 0.8977 (0.9554) teacher_loss 0.0401 (0.1187) loss_zs_kd 0.0652 (0.0686) loss_oracle 0.6480 (0.5802) kd_loss 1.0020 (1.0246) acc 100.0000 (96.7969) gate/entropy 1.0925 (1.0932) gate/usage_max 0.3860 (0.3829) gate/usage_min 0.3039 (0.3064) gate/usage_std 0.0373 (0.0351) teacher/entropy 0.0416 (0.0346) teacher/usage_max 0.5763 (0.5644) teacher/usage_min 0.0004 (0.0096) teacher/usage_std 0.2436 (0.2393) nleep/row_max_mean 1521.8810 (1502.7237) nleep/row_max_std 29.9895 (59.7730) nleep/row_min_mean 1490.7705 (1473.2092) lr 8.7467e-04 eta 0:05:57
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,949
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [29/50] batch [20/160] time 0.099 (0.122) data 0.000 (0.015) loss 0.9353 (0.9587) teacher_loss 0.0910 (0.1282) loss_zs_kd 0.0941 (0.0680) loss_oracle 0.5689 (0.5772) kd_loss 1.0257 (1.0158) acc 96.8750 (97.1875) gate/entropy 1.0924 (1.0924) gate/usage_max 0.3864 (0.3862) gate/usage_min 0.3035 (0.3037) gate/usage_std 0.0376 (0.0375) teacher/entropy 0.0299 (0.0368) teacher/usage_max 0.5230 (0.5713) teacher/usage_min 0.0093 (0.0113) teacher/usage_std 0.2303 (0.2409) nleep/row_max_mean 1496.1086 (1503.1848) nleep/row_max_std 65.9890 (60.2331) nleep/row_min_mean 1467.4102 (1473.3333) lr 8.7467e-04 eta 0:07:05
epoch [29/50] batch [40/160] time 0.093 (0.114) data 0.000 (0.008) loss 0.9553 (0.9435) teacher_loss 0.1089 (0.1109) loss_zs_kd 0.0812 (0.0701) loss_oracle 0.6351 (0.5787) kd_loss 0.9765 (1.0164) acc 96.8750 (97.3438) gate/entropy 1.0922 (1.0923) gate/usage_max 0.3873 (0.3866) gate/usage_min 0.3029 (0.3034) gate/usage_std 0.0383 (0.0377) teacher/entropy 0.0469 (0.0341) teacher/usage_max 0.6651 (0.5775) teacher/usage_min 0.0414 (0.0082) teacher/usage_std 0.2562 (0.2440) nleep/row_max_mean 1517.4094 (1505.1696) nleep/row_max_std 25.1432 (57.6200) nleep/row_min_mean 1484.5503 (1474.6224) lr 8.7467e-04 eta 0:06:35
epoch [29/50] batch [60/160] time 0.096 (0.110) data 0.001 (0.005) loss 0.8950 (0.9354) teacher_loss 0.0956 (0.1049) loss_zs_kd 0.0856 (0.0690) loss_oracle 0.5278 (0.5745) kd_loss 0.9855 (1.0176) acc 100.0000 (97.6562) gate/entropy 1.0919 (1.0923) gate/usage_max 0.3885 (0.3870) gate/usage_min 0.3020 (0.3031) gate/usage_std 0.0391 (0.0380) teacher/entropy 0.0226 (0.0331) teacher/usage_max 0.7246 (0.5769) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.2986 (0.2447) nleep/row_max_mean 1517.8081 (1504.2708) nleep/row_max_std 47.4469 (58.8209) nleep/row_min_mean 1484.6594 (1473.5605) lr 8.7467e-04 eta 0:06:22
epoch [29/50] batch [80/160] time 0.097 (0.107) data 0.000 (0.004) loss 0.8976 (0.9415) teacher_loss 0.0583 (0.1111) loss_zs_kd 0.0569 (0.0671) loss_oracle 0.6072 (0.5806) kd_loss 1.0144 (1.0133) acc 100.0000 (97.4219) gate/entropy 1.0917 (1.0922) gate/usage_max 0.3892 (0.3874) gate/usage_min 0.3014 (0.3028) gate/usage_std 0.0396 (0.0383) teacher/entropy 0.0344 (0.0352) teacher/usage_max 0.5373 (0.5812) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.2376 (0.2458) nleep/row_max_mean 1507.2271 (1503.4127) nleep/row_max_std 50.2599 (60.4638) nleep/row_min_mean 1475.7380 (1472.5021) lr 8.7467e-04 eta 0:06:07
epoch [29/50] batch [100/160] time 0.096 (0.104) data 0.001 (0.003) loss 0.9789 (0.9468) teacher_loss 0.1410 (0.1152) loss_zs_kd 0.0742 (0.0665) loss_oracle 0.5962 (0.5846) kd_loss 1.0056 (1.0123) acc 96.8750 (97.2188) gate/entropy 1.0915 (1.0920) gate/usage_max 0.3899 (0.3878) gate/usage_min 0.3009 (0.3025) gate/usage_std 0.0401 (0.0386) teacher/entropy 0.0324 (0.0354) teacher/usage_max 0.5822 (0.5776) teacher/usage_min 0.0002 (0.0083) teacher/usage_std 0.2450 (0.2441) nleep/row_max_mean 1502.4905 (1503.2906) nleep/row_max_std 52.3110 (60.6213) nleep/row_min_mean 1470.7283 (1472.3140) lr 8.7467e-04 eta 0:05:57
epoch [29/50] batch [120/160] time 0.127 (0.104) data 0.001 (0.003) loss 1.0652 (0.9521) teacher_loss 0.2531 (0.1183) loss_zs_kd 0.0836 (0.0677) loss_oracle 0.5448 (0.5877) kd_loss 0.9957 (1.0121) acc 93.7500 (97.1875) gate/entropy 1.0914 (1.0919) gate/usage_max 0.3906 (0.3882) gate/usage_min 0.3004 (0.3022) gate/usage_std 0.0406 (0.0389) teacher/entropy 0.0529 (0.0358) teacher/usage_max 0.5341 (0.5798) teacher/usage_min 0.0036 (0.0080) teacher/usage_std 0.2350 (0.2447) nleep/row_max_mean 1500.5569 (1502.4194) nleep/row_max_std 75.8157 (61.1157) nleep/row_min_mean 1470.2120 (1471.5978) lr 8.7467e-04 eta 0:05:53
epoch [29/50] batch [140/160] time 0.086 (0.101) data 0.000 (0.002) loss 1.2067 (0.9581) teacher_loss 0.3450 (0.1239) loss_zs_kd 0.0651 (0.0677) loss_oracle 0.6367 (0.5885) kd_loss 1.0216 (1.0121) acc 87.5000 (96.9196) gate/entropy 1.0912 (1.0919) gate/usage_max 0.3914 (0.3886) gate/usage_min 0.2998 (0.3019) gate/usage_std 0.0412 (0.0392) teacher/entropy 0.0515 (0.0354) teacher/usage_max 0.5500 (0.5810) teacher/usage_min 0.0187 (0.0082) teacher/usage_std 0.2277 (0.2449) nleep/row_max_mean 1504.0579 (1502.9996) nleep/row_max_std 78.4377 (60.1627) nleep/row_min_mean 1473.9788 (1472.1110) lr 8.7467e-04 eta 0:05:42
epoch [29/50] batch [160/160] time 0.089 (0.099) data 0.000 (0.002) loss 1.0184 (0.9616) teacher_loss 0.1534 (0.1250) loss_zs_kd 0.0831 (0.0687) loss_oracle 0.5997 (0.5921) kd_loss 1.0472 (1.0122) acc 93.7500 (96.8555) gate/entropy 1.0910 (1.0918) gate/usage_max 0.3918 (0.3890) gate/usage_min 0.2995 (0.3016) gate/usage_std 0.0415 (0.0395) teacher/entropy 0.0090 (0.0354) teacher/usage_max 0.5014 (0.5799) teacher/usage_min 0.0002 (0.0084) teacher/usage_std 0.2355 (0.2444) nleep/row_max_mean 1498.0852 (1502.7830) nleep/row_max_std 50.9908 (60.0575) nleep/row_min_mean 1469.0403 (1471.8682) lr 8.1262e-04 eta 0:05:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,814
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,938
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.2%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [30/50] batch [20/160] time 0.096 (0.113) data 0.000 (0.017) loss 1.0651 (0.9516) teacher_loss 0.2416 (0.1249) loss_zs_kd 0.0947 (0.0669) loss_oracle 0.5403 (0.5727) kd_loss 1.0122 (1.0138) acc 93.7500 (96.8750) gate/entropy 1.0909 (1.0909) gate/usage_max 0.3924 (0.3923) gate/usage_min 0.2989 (0.2991) gate/usage_std 0.0420 (0.0419) teacher/entropy 0.0212 (0.0352) teacher/usage_max 0.5948 (0.5673) teacher/usage_min 0.0307 (0.0142) teacher/usage_std 0.2321 (0.2366) nleep/row_max_mean 1492.4182 (1498.0362) nleep/row_max_std 67.8591 (63.5753) nleep/row_min_mean 1461.5723 (1468.0421) lr 8.1262e-04 eta 0:06:18
epoch [30/50] batch [40/160] time 0.097 (0.106) data 0.000 (0.009) loss 0.9546 (0.9455) teacher_loss 0.1116 (0.1135) loss_zs_kd 0.0620 (0.0684) loss_oracle 0.6033 (0.5870) kd_loss 1.0206 (1.0087) acc 96.8750 (96.9531) gate/entropy 1.0907 (1.0908) gate/usage_max 0.3933 (0.3926) gate/usage_min 0.2984 (0.2989) gate/usage_std 0.0426 (0.0421) teacher/entropy 0.0211 (0.0369) teacher/usage_max 0.5568 (0.5673) teacher/usage_min 0.0355 (0.0122) teacher/usage_std 0.2192 (0.2383) nleep/row_max_mean 1496.8406 (1500.2269) nleep/row_max_std 66.0863 (61.6572) nleep/row_min_mean 1469.3062 (1470.0942) lr 8.1262e-04 eta 0:05:52
epoch [30/50] batch [60/160] time 0.094 (0.099) data 0.001 (0.006) loss 0.8788 (0.9483) teacher_loss 0.0378 (0.1156) loss_zs_kd 0.0547 (0.0681) loss_oracle 0.6079 (0.5888) kd_loss 1.0194 (1.0083) acc 100.0000 (96.8750) gate/entropy 1.0904 (1.0907) gate/usage_max 0.3942 (0.3930) gate/usage_min 0.2979 (0.2986) gate/usage_std 0.0432 (0.0424) teacher/entropy 0.0031 (0.0358) teacher/usage_max 0.6251 (0.5686) teacher/usage_min 0.0004 (0.0101) teacher/usage_std 0.2567 (0.2401) nleep/row_max_mean 1514.4128 (1500.9219) nleep/row_max_std 48.2021 (61.2542) nleep/row_min_mean 1480.4019 (1470.8074) lr 8.1262e-04 eta 0:05:27
epoch [30/50] batch [80/160] time 0.092 (0.094) data 0.000 (0.004) loss 0.8583 (0.9547) teacher_loss 0.0904 (0.1226) loss_zs_kd 0.0724 (0.0690) loss_oracle 0.4458 (0.5899) kd_loss 1.0177 (1.0054) acc 93.7500 (96.6406) gate/entropy 1.0903 (1.0906) gate/usage_max 0.3948 (0.3933) gate/usage_min 0.2974 (0.2984) gate/usage_std 0.0437 (0.0426) teacher/entropy 0.0289 (0.0378) teacher/usage_max 0.5273 (0.5729) teacher/usage_min 0.0072 (0.0102) teacher/usage_std 0.2320 (0.2410) nleep/row_max_mean 1499.9336 (1499.6054) nleep/row_max_std 56.9692 (62.3174) nleep/row_min_mean 1471.8938 (1469.5188) lr 8.1262e-04 eta 0:05:09
epoch [30/50] batch [100/160] time 0.128 (0.103) data 0.000 (0.004) loss 0.9688 (0.9529) teacher_loss 0.1214 (0.1201) loss_zs_kd 0.0603 (0.0683) loss_oracle 0.6321 (0.5929) kd_loss 1.0023 (1.0044) acc 96.8750 (96.7188) gate/entropy 1.0901 (1.0905) gate/usage_max 0.3953 (0.3937) gate/usage_min 0.2969 (0.2981) gate/usage_std 0.0440 (0.0429) teacher/entropy 0.0285 (0.0380) teacher/usage_max 0.5891 (0.5719) teacher/usage_min 0.0312 (0.0105) teacher/usage_std 0.2301 (0.2407) nleep/row_max_mean 1502.0986 (1499.6711) nleep/row_max_std 49.0316 (62.4741) nleep/row_min_mean 1470.9919 (1469.5943) lr 8.1262e-04 eta 0:05:35
epoch [30/50] batch [120/160] time 0.147 (0.108) data 0.000 (0.003) loss 0.8673 (0.9518) teacher_loss 0.0497 (0.1193) loss_zs_kd 0.0387 (0.0677) loss_oracle 0.5901 (0.5921) kd_loss 1.0064 (1.0051) acc 100.0000 (96.7708) gate/entropy 1.0899 (1.0904) gate/usage_max 0.3961 (0.3941) gate/usage_min 0.2964 (0.2979) gate/usage_std 0.0446 (0.0431) teacher/entropy 0.0612 (0.0387) teacher/usage_max 0.5429 (0.5734) teacher/usage_min 0.0171 (0.0101) teacher/usage_std 0.2275 (0.2409) nleep/row_max_mean 1487.6667 (1499.0120) nleep/row_max_std 85.2078 (63.7279) nleep/row_min_mean 1461.6797 (1469.1444) lr 8.1262e-04 eta 0:05:51
epoch [30/50] batch [140/160] time 0.117 (0.113) data 0.000 (0.003) loss 0.8631 (0.9517) teacher_loss 0.0366 (0.1184) loss_zs_kd 0.0767 (0.0680) loss_oracle 0.5117 (0.5919) kd_loss 1.0644 (1.0067) acc 100.0000 (96.8527) gate/entropy 1.0898 (1.0903) gate/usage_max 0.3964 (0.3944) gate/usage_min 0.2960 (0.2976) gate/usage_std 0.0449 (0.0434) teacher/entropy 0.0172 (0.0366) teacher/usage_max 0.6197 (0.5733) teacher/usage_min 0.0003 (0.0093) teacher/usage_std 0.2550 (0.2417) nleep/row_max_mean 1475.8123 (1499.0816) nleep/row_max_std 77.3684 (62.5540) nleep/row_min_mean 1449.0293 (1469.2893) lr 8.1262e-04 eta 0:06:02
epoch [30/50] batch [160/160] time 0.116 (0.115) data 0.000 (0.002) loss 0.9641 (0.9550) teacher_loss 0.0792 (0.1202) loss_zs_kd 0.0705 (0.0688) loss_oracle 0.6428 (0.5940) kd_loss 1.0565 (1.0067) acc 100.0000 (96.8359) gate/entropy 1.0895 (1.0903) gate/usage_max 0.3973 (0.3947) gate/usage_min 0.2955 (0.2974) gate/usage_std 0.0455 (0.0436) teacher/entropy 0.0041 (0.0359) teacher/usage_max 0.4992 (0.5727) teacher/usage_min 0.0321 (0.0094) teacher/usage_std 0.2134 (0.2417) nleep/row_max_mean 1509.3552 (1499.0394) nleep/row_max_std 19.9708 (62.2457) nleep/row_min_mean 1480.0388 (1469.2941) lr 7.5131e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [31/50] batch [20/160] time 0.153 (0.155) data 0.000 (0.013) loss 1.0499 (0.9360) teacher_loss 0.2192 (0.1064) loss_zs_kd 0.0917 (0.0675) loss_oracle 0.5674 (0.5791) kd_loss 1.0023 (1.0127) acc 93.7500 (98.2812) gate/entropy 1.0894 (1.0894) gate/usage_max 0.3977 (0.3977) gate/usage_min 0.2951 (0.2952) gate/usage_std 0.0458 (0.0458) teacher/entropy 0.0323 (0.0286) teacher/usage_max 0.5664 (0.5956) teacher/usage_min 0.0241 (0.0120) teacher/usage_std 0.2279 (0.2481) nleep/row_max_mean 1482.6428 (1495.5098) nleep/row_max_std 79.3849 (64.3863) nleep/row_min_mean 1453.7402 (1465.9486) lr 7.5131e-04 eta 0:08:11
epoch [31/50] batch [40/160] time 0.161 (0.149) data 0.000 (0.007) loss 0.8600 (0.9566) teacher_loss 0.0533 (0.1242) loss_zs_kd 0.0727 (0.0731) loss_oracle 0.5144 (0.5824) kd_loss 1.0262 (1.0093) acc 100.0000 (97.1094) gate/entropy 1.0892 (1.0893) gate/usage_max 0.3985 (0.3980) gate/usage_min 0.2945 (0.2950) gate/usage_std 0.0464 (0.0460) teacher/entropy 0.0314 (0.0326) teacher/usage_max 0.4771 (0.5731) teacher/usage_min 0.0507 (0.0157) teacher/usage_std 0.1999 (0.2394) nleep/row_max_mean 1487.6130 (1495.0497) nleep/row_max_std 79.7412 (66.1561) nleep/row_min_mean 1457.8181 (1465.8037) lr 7.5131e-04 eta 0:07:50
epoch [31/50] batch [60/160] time 0.096 (0.130) data 0.001 (0.005) loss 0.8586 (0.9468) teacher_loss 0.0533 (0.1117) loss_zs_kd 0.0768 (0.0732) loss_oracle 0.5670 (0.5887) kd_loss 0.9668 (1.0082) acc 100.0000 (97.3958) gate/entropy 1.0890 (1.0893) gate/usage_max 0.3992 (0.3983) gate/usage_min 0.2940 (0.2947) gate/usage_std 0.0469 (0.0462) teacher/entropy 0.0998 (0.0346) teacher/usage_max 0.5466 (0.5671) teacher/usage_min 0.0173 (0.0135) teacher/usage_std 0.2280 (0.2390) nleep/row_max_mean 1502.4817 (1496.3618) nleep/row_max_std 53.9639 (64.5160) nleep/row_min_mean 1474.5696 (1467.2622) lr 7.5131e-04 eta 0:06:48
epoch [31/50] batch [80/160] time 0.092 (0.128) data 0.000 (0.004) loss 0.9531 (0.9454) teacher_loss 0.0483 (0.1069) loss_zs_kd 0.0998 (0.0737) loss_oracle 0.6511 (0.5937) kd_loss 1.0588 (1.0097) acc 100.0000 (97.5000) gate/entropy 1.0889 (1.0892) gate/usage_max 0.3996 (0.3986) gate/usage_min 0.2938 (0.2945) gate/usage_std 0.0472 (0.0464) teacher/entropy 0.0164 (0.0335) teacher/usage_max 0.5593 (0.5710) teacher/usage_min 0.0345 (0.0130) teacher/usage_std 0.2204 (0.2405) nleep/row_max_mean 1480.4034 (1496.8185) nleep/row_max_std 77.5282 (63.9160) nleep/row_min_mean 1455.3125 (1467.7041) lr 7.5131e-04 eta 0:06:39
epoch [31/50] batch [100/160] time 0.093 (0.123) data 0.000 (0.003) loss 0.8692 (0.9484) teacher_loss 0.0465 (0.1103) loss_zs_kd 0.0564 (0.0728) loss_oracle 0.5978 (0.5946) kd_loss 0.9911 (1.0088) acc 100.0000 (97.3125) gate/entropy 1.0887 (1.0891) gate/usage_max 0.4003 (0.3989) gate/usage_min 0.2932 (0.2943) gate/usage_std 0.0477 (0.0466) teacher/entropy 0.0545 (0.0341) teacher/usage_max 0.5110 (0.5689) teacher/usage_min 0.0089 (0.0132) teacher/usage_std 0.2298 (0.2399) nleep/row_max_mean 1496.3772 (1497.4448) nleep/row_max_std 84.1870 (63.1838) nleep/row_min_mean 1469.9551 (1468.3687) lr 7.5131e-04 eta 0:06:22
epoch [31/50] batch [120/160] time 0.081 (0.123) data 0.000 (0.002) loss 1.1726 (0.9558) teacher_loss 0.3313 (0.1180) loss_zs_kd 0.0828 (0.0720) loss_oracle 0.5849 (0.5971) kd_loss 1.0148 (1.0066) acc 90.6250 (97.0573) gate/entropy 1.0885 (1.0890) gate/usage_max 0.4008 (0.3991) gate/usage_min 0.2930 (0.2941) gate/usage_std 0.0480 (0.0468) teacher/entropy 0.0255 (0.0338) teacher/usage_max 0.5289 (0.5734) teacher/usage_min 0.0048 (0.0126) teacher/usage_std 0.2337 (0.2412) nleep/row_max_mean 1490.3716 (1497.6938) nleep/row_max_std 66.9546 (62.4940) nleep/row_min_mean 1461.8281 (1468.7682) lr 7.5131e-04 eta 0:06:18
epoch [31/50] batch [140/160] time 0.088 (0.121) data 0.000 (0.002) loss 0.8729 (0.9561) teacher_loss 0.0430 (0.1188) loss_zs_kd 0.0673 (0.0719) loss_oracle 0.5753 (0.5965) kd_loss 1.0172 (1.0062) acc 100.0000 (96.8973) gate/entropy 1.0884 (1.0889) gate/usage_max 0.4012 (0.3994) gate/usage_min 0.2927 (0.2939) gate/usage_std 0.0483 (0.0470) teacher/entropy 0.0259 (0.0344) teacher/usage_max 0.5151 (0.5725) teacher/usage_min 0.0000 (0.0127) teacher/usage_std 0.2360 (0.2408) nleep/row_max_mean 1507.5375 (1497.3532) nleep/row_max_std 30.4652 (63.0496) nleep/row_min_mean 1479.5027 (1468.5877) lr 7.5131e-04 eta 0:06:10
epoch [31/50] batch [160/160] time 0.134 (0.118) data 0.000 (0.002) loss 0.8700 (0.9547) teacher_loss 0.0393 (0.1176) loss_zs_kd 0.0896 (0.0715) loss_oracle 0.5911 (0.5978) kd_loss 0.9807 (1.0049) acc 100.0000 (96.9922) gate/entropy 1.0881 (1.0888) gate/usage_max 0.4022 (0.3997) gate/usage_min 0.2922 (0.2937) gate/usage_std 0.0490 (0.0472) teacher/entropy 0.0261 (0.0353) teacher/usage_max 0.6487 (0.5723) teacher/usage_min 0.0016 (0.0134) teacher/usage_std 0.2644 (0.2402) nleep/row_max_mean 1500.1873 (1497.3669) nleep/row_max_std 49.4541 (62.4828) nleep/row_min_mean 1472.5774 (1468.7256) lr 6.9098e-04 eta 0:05:58
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.7%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [32/50] batch [20/160] time 0.144 (0.144) data 0.000 (0.012) loss 0.8697 (0.9315) teacher_loss 0.0669 (0.1087) loss_zs_kd 0.0540 (0.0653) loss_oracle 0.5552 (0.5937) kd_loss 0.9965 (0.9867) acc 96.8750 (97.1875) gate/entropy 1.0880 (1.0880) gate/usage_max 0.4027 (0.4025) gate/usage_min 0.2918 (0.2919) gate/usage_std 0.0494 (0.0492) teacher/entropy 0.0301 (0.0465) teacher/usage_max 0.5700 (0.5767) teacher/usage_min 0.0009 (0.0136) teacher/usage_std 0.2420 (0.2403) nleep/row_max_mean 1479.9280 (1495.1329) nleep/row_max_std 80.5875 (66.9464) nleep/row_min_mean 1453.5671 (1467.4841) lr 6.9098e-04 eta 0:07:15
epoch [32/50] batch [40/160] time 0.145 (0.136) data 0.000 (0.006) loss 1.0381 (0.9660) teacher_loss 0.2345 (0.1413) loss_zs_kd 0.0599 (0.0637) loss_oracle 0.5472 (0.5917) kd_loss 1.0000 (0.9941) acc 90.6250 (95.9375) gate/entropy 1.0878 (1.0879) gate/usage_max 0.4032 (0.4027) gate/usage_min 0.2914 (0.2917) gate/usage_std 0.0497 (0.0494) teacher/entropy 0.0319 (0.0419) teacher/usage_max 0.5523 (0.5778) teacher/usage_min 0.0127 (0.0147) teacher/usage_std 0.2317 (0.2394) nleep/row_max_mean 1479.5032 (1495.6284) nleep/row_max_std 82.5971 (64.3512) nleep/row_min_mean 1452.7739 (1467.7274) lr 6.9098e-04 eta 0:06:48
epoch [32/50] batch [60/160] time 0.114 (0.134) data 0.000 (0.004) loss 0.8543 (0.9635) teacher_loss 0.0336 (0.1390) loss_zs_kd 0.0534 (0.0658) loss_oracle 0.5809 (0.5913) kd_loss 1.0071 (0.9918) acc 100.0000 (96.0938) gate/entropy 1.0875 (1.0878) gate/usage_max 0.4040 (0.4030) gate/usage_min 0.2909 (0.2915) gate/usage_std 0.0503 (0.0496) teacher/entropy 0.0276 (0.0434) teacher/usage_max 0.5402 (0.5763) teacher/usage_min 0.0006 (0.0140) teacher/usage_std 0.2376 (0.2401) nleep/row_max_mean 1507.6016 (1496.4578) nleep/row_max_std 57.3409 (63.5762) nleep/row_min_mean 1476.7946 (1468.6755) lr 6.9098e-04 eta 0:06:38
epoch [32/50] batch [80/160] time 0.127 (0.133) data 0.000 (0.003) loss 0.9418 (0.9488) teacher_loss 0.1296 (0.1232) loss_zs_kd 0.0657 (0.0675) loss_oracle 0.5584 (0.5930) kd_loss 1.0004 (0.9906) acc 96.8750 (96.5625) gate/entropy 1.0874 (1.0878) gate/usage_max 0.4044 (0.4033) gate/usage_min 0.2906 (0.2913) gate/usage_std 0.0506 (0.0498) teacher/entropy 0.0511 (0.0448) teacher/usage_max 0.4987 (0.5753) teacher/usage_min 0.0210 (0.0152) teacher/usage_std 0.2210 (0.2391) nleep/row_max_mean 1508.3848 (1498.0807) nleep/row_max_std 33.5149 (60.1195) nleep/row_min_mean 1480.0818 (1470.2013) lr 6.9098e-04 eta 0:06:32
epoch [32/50] batch [100/160] time 0.143 (0.133) data 0.000 (0.003) loss 0.9020 (0.9471) teacher_loss 0.1046 (0.1242) loss_zs_kd 0.0656 (0.0674) loss_oracle 0.5721 (0.5876) kd_loss 0.9572 (0.9909) acc 100.0000 (96.5000) gate/entropy 1.0872 (1.0877) gate/usage_max 0.4050 (0.4036) gate/usage_min 0.2902 (0.2911) gate/usage_std 0.0510 (0.0500) teacher/entropy 0.0634 (0.0442) teacher/usage_max 0.5938 (0.5760) teacher/usage_min 0.0426 (0.0152) teacher/usage_std 0.2261 (0.2391) nleep/row_max_mean 1503.5684 (1497.7752) nleep/row_max_std 45.4842 (60.7540) nleep/row_min_mean 1474.7058 (1469.9524) lr 6.9098e-04 eta 0:06:29
epoch [32/50] batch [120/160] time 0.150 (0.134) data 0.001 (0.002) loss 0.9761 (0.9465) teacher_loss 0.1588 (0.1244) loss_zs_kd 0.0777 (0.0676) loss_oracle 0.5592 (0.5855) kd_loss 0.9977 (0.9911) acc 96.8750 (96.5365) gate/entropy 1.0871 (1.0876) gate/usage_max 0.4055 (0.4039) gate/usage_min 0.2897 (0.2909) gate/usage_std 0.0514 (0.0502) teacher/entropy 0.0305 (0.0439) teacher/usage_max 0.5643 (0.5725) teacher/usage_min 0.0343 (0.0152) teacher/usage_std 0.2217 (0.2381) nleep/row_max_mean 1505.1401 (1497.7656) nleep/row_max_std 59.2759 (61.0991) nleep/row_min_mean 1476.8469 (1469.8793) lr 6.9098e-04 eta 0:06:30
epoch [32/50] batch [140/160] time 0.146 (0.134) data 0.000 (0.002) loss 0.9163 (0.9426) teacher_loss 0.0659 (0.1202) loss_zs_kd 0.0684 (0.0675) loss_oracle 0.6292 (0.5849) kd_loss 1.0032 (0.9926) acc 100.0000 (96.7188) gate/entropy 1.0870 (1.0875) gate/usage_max 0.4057 (0.4041) gate/usage_min 0.2897 (0.2907) gate/usage_std 0.0515 (0.0504) teacher/entropy 0.0222 (0.0435) teacher/usage_max 0.5701 (0.5689) teacher/usage_min 0.0237 (0.0153) teacher/usage_std 0.2290 (0.2369) nleep/row_max_mean 1493.8440 (1497.2143) nleep/row_max_std 58.8109 (61.4508) nleep/row_min_mean 1464.5602 (1469.4644) lr 6.9098e-04 eta 0:06:28
epoch [32/50] batch [160/160] time 0.126 (0.134) data 0.000 (0.002) loss 0.9308 (0.9443) teacher_loss 0.0996 (0.1213) loss_zs_kd 0.0880 (0.0681) loss_oracle 0.6165 (0.5852) kd_loss 0.9580 (0.9926) acc 100.0000 (96.6602) gate/entropy 1.0867 (1.0874) gate/usage_max 0.4065 (0.4044) gate/usage_min 0.2890 (0.2905) gate/usage_std 0.0521 (0.0506) teacher/entropy 0.0865 (0.0429) teacher/usage_max 0.5041 (0.5703) teacher/usage_min 0.0298 (0.0155) teacher/usage_std 0.2152 (0.2372) nleep/row_max_mean 1495.9321 (1497.1972) nleep/row_max_std 65.7347 (61.2983) nleep/row_min_mean 1469.7395 (1469.4082) lr 6.3188e-04 eta 0:06:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,946
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.5%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [33/50] batch [20/160] time 0.074 (0.126) data 0.000 (0.018) loss 0.8647 (0.9265) teacher_loss 0.0476 (0.1037) loss_zs_kd 0.0652 (0.0737) loss_oracle 0.6222 (0.5882) kd_loss 0.9469 (0.9837) acc 100.0000 (97.5000) gate/entropy 1.0866 (1.0866) gate/usage_max 0.4068 (0.4068) gate/usage_min 0.2888 (0.2889) gate/usage_std 0.0524 (0.0523) teacher/entropy 0.0444 (0.0451) teacher/usage_max 0.6827 (0.5910) teacher/usage_min 0.0069 (0.0188) teacher/usage_std 0.2764 (0.2431) nleep/row_max_mean 1497.4973 (1498.9452) nleep/row_max_std 60.9198 (58.2672) nleep/row_min_mean 1471.1025 (1470.8467) lr 6.3188e-04 eta 0:05:59
epoch [33/50] batch [40/160] time 0.150 (0.110) data 0.000 (0.009) loss 0.9262 (0.9253) teacher_loss 0.1329 (0.1134) loss_zs_kd 0.0601 (0.0683) loss_oracle 0.5161 (0.5695) kd_loss 1.0105 (0.9859) acc 93.7500 (96.7969) gate/entropy 1.0864 (1.0866) gate/usage_max 0.4075 (0.4071) gate/usage_min 0.2883 (0.2887) gate/usage_std 0.0528 (0.0525) teacher/entropy 0.0342 (0.0441) teacher/usage_max 0.4996 (0.5768) teacher/usage_min 0.0276 (0.0157) teacher/usage_std 0.2165 (0.2403) nleep/row_max_mean 1508.4652 (1498.4653) nleep/row_max_std 27.9540 (60.9351) nleep/row_min_mean 1480.5889 (1470.7140) lr 6.3188e-04 eta 0:05:12
epoch [33/50] batch [60/160] time 0.079 (0.105) data 0.001 (0.006) loss 1.0131 (0.9420) teacher_loss 0.1180 (0.1241) loss_zs_kd 0.0832 (0.0665) loss_oracle 0.7031 (0.5820) kd_loss 1.0039 (0.9871) acc 96.8750 (96.6146) gate/entropy 1.0862 (1.0865) gate/usage_max 0.4080 (0.4074) gate/usage_min 0.2879 (0.2885) gate/usage_std 0.0532 (0.0527) teacher/entropy 0.0380 (0.0441) teacher/usage_max 0.5053 (0.5732) teacher/usage_min 0.0215 (0.0168) teacher/usage_std 0.2209 (0.2384) nleep/row_max_mean 1511.5554 (1498.8705) nleep/row_max_std 24.0994 (59.7634) nleep/row_min_mean 1480.7437 (1470.9904) lr 6.3188e-04 eta 0:04:56
epoch [33/50] batch [80/160] time 0.076 (0.103) data 0.000 (0.005) loss 1.0179 (0.9353) teacher_loss 0.1620 (0.1174) loss_zs_kd 0.0684 (0.0658) loss_oracle 0.6392 (0.5819) kd_loss 1.0043 (0.9881) acc 96.8750 (96.9141) gate/entropy 1.0860 (1.0864) gate/usage_max 0.4087 (0.4076) gate/usage_min 0.2874 (0.2883) gate/usage_std 0.0537 (0.0529) teacher/entropy 0.0006 (0.0443) teacher/usage_max 0.6250 (0.5662) teacher/usage_min 0.0000 (0.0165) teacher/usage_std 0.2568 (0.2366) nleep/row_max_mean 1513.5557 (1498.6840) nleep/row_max_std 27.6710 (59.8648) nleep/row_min_mean 1482.2170 (1470.8971) lr 6.3188e-04 eta 0:04:47
epoch [33/50] batch [100/160] time 0.079 (0.099) data 0.000 (0.004) loss 0.9716 (0.9364) teacher_loss 0.1709 (0.1184) loss_zs_kd 0.0652 (0.0661) loss_oracle 0.5764 (0.5797) kd_loss 0.9597 (0.9903) acc 93.7500 (96.8750) gate/entropy 1.0859 (1.0863) gate/usage_max 0.4091 (0.4079) gate/usage_min 0.2871 (0.2881) gate/usage_std 0.0540 (0.0531) teacher/entropy 0.0279 (0.0426) teacher/usage_max 0.6828 (0.5634) teacher/usage_min 0.0023 (0.0166) teacher/usage_std 0.2781 (0.2356) nleep/row_max_mean 1498.2559 (1498.7450) nleep/row_max_std 81.2517 (60.1049) nleep/row_min_mean 1469.4312 (1470.9393) lr 6.3188e-04 eta 0:04:36
epoch [33/50] batch [120/160] time 0.077 (0.098) data 0.001 (0.003) loss 0.9360 (0.9351) teacher_loss 0.1001 (0.1176) loss_zs_kd 0.0988 (0.0671) loss_oracle 0.5667 (0.5763) kd_loss 1.0063 (0.9915) acc 96.8750 (96.9531) gate/entropy 1.0858 (1.0862) gate/usage_max 0.4094 (0.4081) gate/usage_min 0.2868 (0.2879) gate/usage_std 0.0542 (0.0533) teacher/entropy 0.0070 (0.0408) teacher/usage_max 0.5937 (0.5616) teacher/usage_min 0.0000 (0.0160) teacher/usage_std 0.2478 (0.2357) nleep/row_max_mean 1499.8557 (1498.8278) nleep/row_max_std 33.2456 (59.0899) nleep/row_min_mean 1469.8022 (1471.0155) lr 6.3188e-04 eta 0:04:30
epoch [33/50] batch [140/160] time 0.147 (0.100) data 0.000 (0.003) loss 1.0789 (0.9359) teacher_loss 0.2277 (0.1180) loss_zs_kd 0.0592 (0.0673) loss_oracle 0.6278 (0.5770) kd_loss 1.0154 (0.9915) acc 93.7500 (96.8973) gate/entropy 1.0855 (1.0861) gate/usage_max 0.4101 (0.4084) gate/usage_min 0.2863 (0.2877) gate/usage_std 0.0548 (0.0535) teacher/entropy 0.0409 (0.0405) teacher/usage_max 0.5154 (0.5610) teacher/usage_min 0.0308 (0.0158) teacher/usage_std 0.2154 (0.2356) nleep/row_max_mean 1484.9871 (1498.2244) nleep/row_max_std 94.6300 (60.1630) nleep/row_min_mean 1456.7266 (1470.3564) lr 6.3188e-04 eta 0:04:34
epoch [33/50] batch [160/160] time 0.148 (0.100) data 0.000 (0.003) loss 0.8371 (0.9341) teacher_loss 0.0394 (0.1165) loss_zs_kd 0.0539 (0.0674) loss_oracle 0.5887 (0.5765) kd_loss 0.9529 (0.9913) acc 100.0000 (96.9141) gate/entropy 1.0853 (1.0860) gate/usage_max 0.4107 (0.4086) gate/usage_min 0.2859 (0.2875) gate/usage_std 0.0552 (0.0537) teacher/entropy 0.0652 (0.0413) teacher/usage_max 0.5770 (0.5618) teacher/usage_min 0.0230 (0.0154) teacher/usage_std 0.2310 (0.2358) nleep/row_max_mean 1492.8108 (1497.2260) nleep/row_max_std 76.1116 (61.7332) nleep/row_min_mean 1464.8843 (1469.3168) lr 5.7422e-04 eta 0:04:33
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,933
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.2%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [34/50] batch [20/160] time 0.148 (0.137) data 0.000 (0.016) loss 0.9006 (0.9040) teacher_loss 0.1123 (0.0881) loss_zs_kd 0.0662 (0.0660) loss_oracle 0.4803 (0.5622) kd_loss 1.0301 (1.0037) acc 93.7500 (97.5000) gate/entropy 1.0852 (1.0853) gate/usage_max 0.4110 (0.4108) gate/usage_min 0.2856 (0.2858) gate/usage_std 0.0554 (0.0552) teacher/entropy 0.0309 (0.0366) teacher/usage_max 0.5676 (0.5909) teacher/usage_min 0.0018 (0.0141) teacher/usage_std 0.2410 (0.2436) nleep/row_max_mean 1486.2798 (1495.1777) nleep/row_max_std 85.4222 (61.7153) nleep/row_min_mean 1459.1699 (1466.8386) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [40/160] time 0.118 (0.132) data 0.000 (0.008) loss 0.9320 (0.9261) teacher_loss 0.0872 (0.1078) loss_zs_kd 0.0714 (0.0690) loss_oracle 0.6260 (0.5700) kd_loss 0.9922 (0.9977) acc 96.8750 (96.8750) gate/entropy 1.0850 (1.0852) gate/usage_max 0.4115 (0.4110) gate/usage_min 0.2852 (0.2856) gate/usage_std 0.0557 (0.0554) teacher/entropy 0.0094 (0.0357) teacher/usage_max 0.6229 (0.5739) teacher/usage_min 0.0005 (0.0136) teacher/usage_std 0.2560 (0.2396) nleep/row_max_mean 1504.5850 (1496.9125) nleep/row_max_std 62.7242 (57.6344) nleep/row_min_mean 1474.5742 (1468.3731) lr 5.7422e-04 eta 0:05:54
epoch [34/50] batch [60/160] time 0.140 (0.133) data 0.001 (0.005) loss 1.0308 (0.9473) teacher_loss 0.2041 (0.1280) loss_zs_kd 0.0650 (0.0695) loss_oracle 0.5652 (0.5732) kd_loss 1.0232 (0.9960) acc 93.7500 (96.2500) gate/entropy 1.0850 (1.0852) gate/usage_max 0.4116 (0.4111) gate/usage_min 0.2849 (0.2854) gate/usage_std 0.0559 (0.0555) teacher/entropy 0.0169 (0.0388) teacher/usage_max 0.4988 (0.5660) teacher/usage_min 0.0028 (0.0146) teacher/usage_std 0.2338 (0.2367) nleep/row_max_mean 1487.7560 (1495.6674) nleep/row_max_std 71.6357 (59.1464) nleep/row_min_mean 1460.3851 (1467.1798) lr 5.7422e-04 eta 0:05:54
epoch [34/50] batch [80/160] time 0.147 (0.135) data 0.000 (0.004) loss 0.9056 (0.9417) teacher_loss 0.0814 (0.1256) loss_zs_kd 0.0734 (0.0689) loss_oracle 0.5819 (0.5670) kd_loss 0.9929 (0.9964) acc 100.0000 (96.4453) gate/entropy 1.0849 (1.0851) gate/usage_max 0.4119 (0.4113) gate/usage_min 0.2847 (0.2853) gate/usage_std 0.0561 (0.0557) teacher/entropy 0.0310 (0.0377) teacher/usage_max 0.5522 (0.5675) teacher/usage_min 0.0103 (0.0139) teacher/usage_std 0.2331 (0.2377) nleep/row_max_mean 1480.9734 (1496.4504) nleep/row_max_std 74.3878 (59.4174) nleep/row_min_mean 1452.4125 (1467.8390) lr 5.7422e-04 eta 0:05:56
epoch [34/50] batch [100/160] time 0.143 (0.136) data 0.000 (0.003) loss 0.8461 (0.9405) teacher_loss 0.0386 (0.1247) loss_zs_kd 0.0673 (0.0697) loss_oracle 0.5441 (0.5673) kd_loss 1.0035 (0.9946) acc 100.0000 (96.4375) gate/entropy 1.0846 (1.0850) gate/usage_max 0.4128 (0.4115) gate/usage_min 0.2841 (0.2851) gate/usage_std 0.0567 (0.0558) teacher/entropy 0.0050 (0.0380) teacher/usage_max 0.5944 (0.5688) teacher/usage_min 0.0002 (0.0136) teacher/usage_std 0.2479 (0.2382) nleep/row_max_mean 1521.8860 (1496.6938) nleep/row_max_std 42.1748 (59.9848) nleep/row_min_mean 1489.7832 (1468.0070) lr 5.7422e-04 eta 0:05:57
epoch [34/50] batch [120/160] time 0.147 (0.137) data 0.000 (0.003) loss 0.8786 (0.9400) teacher_loss 0.0448 (0.1244) loss_zs_kd 0.0811 (0.0689) loss_oracle 0.5086 (0.5655) kd_loss 1.0779 (0.9968) acc 100.0000 (96.4583) gate/entropy 1.0845 (1.0849) gate/usage_max 0.4130 (0.4117) gate/usage_min 0.2839 (0.2849) gate/usage_std 0.0569 (0.0559) teacher/entropy 0.0085 (0.0375) teacher/usage_max 0.6547 (0.5673) teacher/usage_min 0.0004 (0.0132) teacher/usage_std 0.2672 (0.2381) nleep/row_max_mean 1512.7136 (1497.0501) nleep/row_max_std 42.7154 (59.7678) nleep/row_min_mean 1485.7720 (1468.4489) lr 5.7422e-04 eta 0:05:56
epoch [34/50] batch [140/160] time 0.137 (0.137) data 0.000 (0.002) loss 1.0488 (0.9350) teacher_loss 0.2014 (0.1177) loss_zs_kd 0.0762 (0.0683) loss_oracle 0.6027 (0.5663) kd_loss 1.0159 (1.0000) acc 90.6250 (96.6964) gate/entropy 1.0843 (1.0849) gate/usage_max 0.4135 (0.4119) gate/usage_min 0.2834 (0.2847) gate/usage_std 0.0573 (0.0561) teacher/entropy 0.0023 (0.0353) teacher/usage_max 0.5625 (0.5675) teacher/usage_min 0.0000 (0.0128) teacher/usage_std 0.2411 (0.2384) nleep/row_max_mean 1509.4526 (1497.6874) nleep/row_max_std 39.9692 (59.1794) nleep/row_min_mean 1479.0468 (1468.8669) lr 5.7422e-04 eta 0:05:54
epoch [34/50] batch [160/160] time 0.080 (0.130) data 0.000 (0.002) loss 1.0191 (0.9335) teacher_loss 0.1960 (0.1150) loss_zs_kd 0.0465 (0.0683) loss_oracle 0.5731 (0.5692) kd_loss 1.0267 (0.9994) acc 96.8750 (96.8359) gate/entropy 1.0842 (1.0848) gate/usage_max 0.4137 (0.4121) gate/usage_min 0.2831 (0.2846) gate/usage_std 0.0574 (0.0562) teacher/entropy 0.0109 (0.0353) teacher/usage_max 0.5001 (0.5672) teacher/usage_min 0.0031 (0.0138) teacher/usage_std 0.2335 (0.2377) nleep/row_max_mean 1491.7096 (1497.8298) nleep/row_max_std 72.5174 (59.3999) nleep/row_min_mean 1463.6775 (1468.9557) lr 5.1825e-04 eta 0:05:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,802
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,894
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 87.4%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [35/50] batch [20/160] time 0.112 (0.121) data 0.000 (0.016) loss 0.8501 (0.9625) teacher_loss 0.0311 (0.1400) loss_zs_kd 0.0537 (0.0641) loss_oracle 0.5992 (0.5763) kd_loss 0.9851 (1.0047) acc 100.0000 (96.4062) gate/entropy 1.0841 (1.0842) gate/usage_max 0.4141 (0.4139) gate/usage_min 0.2828 (0.2830) gate/usage_std 0.0577 (0.0576) teacher/entropy 0.0327 (0.0297) teacher/usage_max 0.5666 (0.5560) teacher/usage_min 0.0247 (0.0181) teacher/usage_std 0.2276 (0.2318) nleep/row_max_mean 1494.3622 (1499.1342) nleep/row_max_std 73.1910 (59.5199) nleep/row_min_mean 1466.9250 (1469.9114) lr 5.1825e-04 eta 0:05:06
epoch [35/50] batch [40/160] time 0.142 (0.122) data 0.000 (0.008) loss 0.8623 (0.9464) teacher_loss 0.0503 (0.1213) loss_zs_kd 0.0511 (0.0637) loss_oracle 0.5352 (0.5721) kd_loss 1.0377 (1.0144) acc 100.0000 (96.7969) gate/entropy 1.0839 (1.0841) gate/usage_max 0.4144 (0.4141) gate/usage_min 0.2824 (0.2828) gate/usage_std 0.0580 (0.0577) teacher/entropy 0.0233 (0.0301) teacher/usage_max 0.5622 (0.5634) teacher/usage_min 0.0138 (0.0137) teacher/usage_std 0.2329 (0.2366) nleep/row_max_mean 1500.4075 (1498.7578) nleep/row_max_std 73.9526 (61.7562) nleep/row_min_mean 1469.2246 (1469.2450) lr 5.1825e-04 eta 0:05:08
epoch [35/50] batch [60/160] time 0.087 (0.117) data 0.001 (0.006) loss 1.0000 (0.9379) teacher_loss 0.1177 (0.1150) loss_zs_kd 0.0616 (0.0635) loss_oracle 0.6627 (0.5703) kd_loss 1.0402 (1.0121) acc 96.8750 (96.9792) gate/entropy 1.0837 (1.0840) gate/usage_max 0.4150 (0.4142) gate/usage_min 0.2819 (0.2826) gate/usage_std 0.0584 (0.0578) teacher/entropy 0.0044 (0.0317) teacher/usage_max 0.5304 (0.5575) teacher/usage_min 0.0000 (0.0138) teacher/usage_std 0.2370 (0.2350) nleep/row_max_mean 1521.6343 (1499.8375) nleep/row_max_std 25.5564 (59.4414) nleep/row_min_mean 1487.1128 (1470.4188) lr 5.1825e-04 eta 0:04:53
epoch [35/50] batch [80/160] time 0.074 (0.115) data 0.000 (0.004) loss 1.0609 (0.9472) teacher_loss 0.2305 (0.1239) loss_zs_kd 0.0896 (0.0654) loss_oracle 0.5588 (0.5685) kd_loss 1.0124 (1.0127) acc 93.7500 (96.6797) gate/entropy 1.0838 (1.0840) gate/usage_max 0.4149 (0.4144) gate/usage_min 0.2818 (0.2824) gate/usage_std 0.0583 (0.0579) teacher/entropy 0.0039 (0.0322) teacher/usage_max 0.5626 (0.5545) teacher/usage_min 0.0003 (0.0151) teacher/usage_std 0.2410 (0.2339) nleep/row_max_mean 1508.3727 (1498.6769) nleep/row_max_std 42.3352 (60.8705) nleep/row_min_mean 1478.9807 (1469.3940) lr 5.1825e-04 eta 0:04:45
epoch [35/50] batch [100/160] time 0.075 (0.113) data 0.000 (0.004) loss 0.9227 (0.9442) teacher_loss 0.1348 (0.1208) loss_zs_kd 0.0468 (0.0658) loss_oracle 0.5852 (0.5683) kd_loss 0.9439 (1.0128) acc 96.8750 (96.7812) gate/entropy 1.0836 (1.0839) gate/usage_max 0.4154 (0.4145) gate/usage_min 0.2814 (0.2823) gate/usage_std 0.0587 (0.0580) teacher/entropy 0.0620 (0.0314) teacher/usage_max 0.5960 (0.5558) teacher/usage_min 0.0151 (0.0161) teacher/usage_std 0.2404 (0.2338) nleep/row_max_mean 1488.6932 (1498.4561) nleep/row_max_std 88.7202 (59.9014) nleep/row_min_mean 1461.6069 (1469.1782) lr 5.1825e-04 eta 0:04:37
epoch [35/50] batch [120/160] time 0.131 (0.114) data 0.000 (0.003) loss 0.9531 (0.9513) teacher_loss 0.1063 (0.1260) loss_zs_kd 0.0723 (0.0674) loss_oracle 0.5780 (0.5689) kd_loss 1.0433 (1.0143) acc 93.7500 (96.4062) gate/entropy 1.0835 (1.0839) gate/usage_max 0.4156 (0.4146) gate/usage_min 0.2812 (0.2821) gate/usage_std 0.0588 (0.0581) teacher/entropy 0.0011 (0.0302) teacher/usage_max 0.5314 (0.5585) teacher/usage_min 0.0000 (0.0159) teacher/usage_std 0.2371 (0.2345) nleep/row_max_mean 1509.1763 (1498.1801) nleep/row_max_std 39.3801 (59.3540) nleep/row_min_mean 1477.0642 (1468.9363) lr 5.1825e-04 eta 0:04:39
epoch [35/50] batch [140/160] time 0.133 (0.118) data 0.000 (0.003) loss 1.0195 (0.9521) teacher_loss 0.2115 (0.1265) loss_zs_kd 0.0631 (0.0666) loss_oracle 0.5651 (0.5713) kd_loss 0.9877 (1.0133) acc 96.8750 (96.3839) gate/entropy 1.0835 (1.0838) gate/usage_max 0.4154 (0.4148) gate/usage_min 0.2811 (0.2820) gate/usage_std 0.0588 (0.0582) teacher/entropy 0.0437 (0.0314) teacher/usage_max 0.5171 (0.5571) teacher/usage_min 0.0227 (0.0159) teacher/usage_std 0.2209 (0.2340) nleep/row_max_mean 1486.3173 (1498.0552) nleep/row_max_std 72.7999 (59.0455) nleep/row_min_mean 1457.1262 (1468.8133) lr 5.1825e-04 eta 0:04:44
epoch [35/50] batch [160/160] time 0.124 (0.120) data 0.000 (0.002) loss 0.9169 (0.9512) teacher_loss 0.0789 (0.1241) loss_zs_kd 0.0632 (0.0675) loss_oracle 0.5939 (0.5730) kd_loss 1.0188 (1.0136) acc 100.0000 (96.4258) gate/entropy 1.0834 (1.0838) gate/usage_max 0.4157 (0.4149) gate/usage_min 0.2807 (0.2818) gate/usage_std 0.0590 (0.0583) teacher/entropy 0.0531 (0.0319) teacher/usage_max 0.5190 (0.5588) teacher/usage_min 0.0806 (0.0164) teacher/usage_std 0.1852 (0.2340) nleep/row_max_mean 1486.2443 (1498.3519) nleep/row_max_std 73.5823 (58.3526) nleep/row_min_mean 1459.7363 (1469.2095) lr 4.6417e-04 eta 0:04:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,784
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,860
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 86.7%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [36/50] batch [20/160] time 0.131 (0.153) data 0.000 (0.014) loss 0.9603 (0.9571) teacher_loss 0.0884 (0.1237) loss_zs_kd 0.0783 (0.0646) loss_oracle 0.6600 (0.5837) kd_loss 1.0056 (1.0185) acc 96.8750 (97.0312) gate/entropy 1.0833 (1.0834) gate/usage_max 0.4161 (0.4159) gate/usage_min 0.2803 (0.2806) gate/usage_std 0.0593 (0.0591) teacher/entropy 0.0637 (0.0317) teacher/usage_max 0.5812 (0.5755) teacher/usage_min 0.0262 (0.0092) teacher/usage_std 0.2304 (0.2406) nleep/row_max_mean 1482.3589 (1496.3898) nleep/row_max_std 83.0160 (58.8444) nleep/row_min_mean 1454.6348 (1468.0335) lr 4.6417e-04 eta 0:06:03
epoch [36/50] batch [40/160] time 0.124 (0.143) data 0.000 (0.007) loss 1.0471 (0.9580) teacher_loss 0.2611 (0.1368) loss_zs_kd 0.0617 (0.0664) loss_oracle 0.5234 (0.5706) kd_loss 0.9870 (1.0053) acc 96.8750 (96.5625) gate/entropy 1.0832 (1.0833) gate/usage_max 0.4161 (0.4160) gate/usage_min 0.2801 (0.2804) gate/usage_std 0.0593 (0.0592) teacher/entropy 0.0469 (0.0381) teacher/usage_max 0.5030 (0.5612) teacher/usage_min 0.0205 (0.0114) teacher/usage_std 0.2215 (0.2363) nleep/row_max_mean 1481.2739 (1496.7531) nleep/row_max_std 80.8129 (59.5560) nleep/row_min_mean 1458.5455 (1468.2331) lr 4.6417e-04 eta 0:05:36
epoch [36/50] batch [60/160] time 0.136 (0.139) data 0.001 (0.005) loss 0.8961 (0.9495) teacher_loss 0.0322 (0.1312) loss_zs_kd 0.0575 (0.0639) loss_oracle 0.6200 (0.5687) kd_loss 1.0504 (1.0040) acc 100.0000 (96.5625) gate/entropy 1.0831 (1.0833) gate/usage_max 0.4164 (0.4160) gate/usage_min 0.2798 (0.2803) gate/usage_std 0.0595 (0.0593) teacher/entropy 0.0122 (0.0371) teacher/usage_max 0.5913 (0.5625) teacher/usage_min 0.0023 (0.0135) teacher/usage_std 0.2459 (0.2361) nleep/row_max_mean 1479.2515 (1496.7485) nleep/row_max_std 80.5589 (58.3349) nleep/row_min_mean 1453.5496 (1468.3150) lr 4.6417e-04 eta 0:05:25
epoch [36/50] batch [80/160] time 0.078 (0.132) data 0.000 (0.004) loss 0.8677 (0.9485) teacher_loss 0.0251 (0.1288) loss_zs_kd 0.0657 (0.0652) loss_oracle 0.6080 (0.5675) kd_loss 1.0116 (1.0066) acc 100.0000 (96.4062) gate/entropy 1.0830 (1.0832) gate/usage_max 0.4168 (0.4161) gate/usage_min 0.2797 (0.2802) gate/usage_std 0.0598 (0.0593) teacher/entropy 0.0219 (0.0368) teacher/usage_max 0.5009 (0.5613) teacher/usage_min 0.0010 (0.0152) teacher/usage_std 0.2350 (0.2348) nleep/row_max_mean 1497.2627 (1495.8679) nleep/row_max_std 68.6559 (59.8784) nleep/row_min_mean 1467.9661 (1467.4335) lr 4.6417e-04 eta 0:05:07
epoch [36/50] batch [100/160] time 0.143 (0.122) data 0.000 (0.003) loss 1.0014 (0.9503) teacher_loss 0.1949 (0.1314) loss_zs_kd 0.0604 (0.0653) loss_oracle 0.5629 (0.5644) kd_loss 0.9897 (1.0080) acc 93.7500 (96.3125) gate/entropy 1.0830 (1.0832) gate/usage_max 0.4168 (0.4162) gate/usage_min 0.2793 (0.2801) gate/usage_std 0.0599 (0.0594) teacher/entropy 0.0443 (0.0362) teacher/usage_max 0.4969 (0.5617) teacher/usage_min 0.0115 (0.0156) teacher/usage_std 0.2276 (0.2349) nleep/row_max_mean 1496.1266 (1496.1116) nleep/row_max_std 74.9228 (60.2592) nleep/row_min_mean 1469.7117 (1467.7609) lr 4.6417e-04 eta 0:04:41
epoch [36/50] batch [120/160] time 0.076 (0.121) data 0.000 (0.003) loss 0.8529 (0.9450) teacher_loss 0.0238 (0.1277) loss_zs_kd 0.0596 (0.0659) loss_oracle 0.5439 (0.5626) kd_loss 1.0548 (1.0060) acc 100.0000 (96.3542) gate/entropy 1.0829 (1.0832) gate/usage_max 0.4170 (0.4163) gate/usage_min 0.2791 (0.2799) gate/usage_std 0.0600 (0.0595) teacher/entropy 0.0060 (0.0372) teacher/usage_max 0.5930 (0.5604) teacher/usage_min 0.0000 (0.0176) teacher/usage_std 0.2476 (0.2337) nleep/row_max_mean 1511.3099 (1496.6403) nleep/row_max_std 40.0716 (60.7751) nleep/row_min_mean 1479.8433 (1468.1421) lr 4.6417e-04 eta 0:04:35
epoch [36/50] batch [140/160] time 0.086 (0.117) data 0.001 (0.002) loss 0.8851 (0.9389) teacher_loss 0.0383 (0.1225) loss_zs_kd 0.0900 (0.0660) loss_oracle 0.5209 (0.5624) kd_loss 1.0828 (1.0043) acc 100.0000 (96.5848) gate/entropy 1.0829 (1.0831) gate/usage_max 0.4170 (0.4164) gate/usage_min 0.2791 (0.2798) gate/usage_std 0.0600 (0.0596) teacher/entropy 0.0197 (0.0382) teacher/usage_max 0.6851 (0.5628) teacher/usage_min 0.0288 (0.0187) teacher/usage_std 0.2700 (0.2337) nleep/row_max_mean 1507.1071 (1496.8526) nleep/row_max_std 47.5261 (60.9354) nleep/row_min_mean 1476.4894 (1468.3106) lr 4.6417e-04 eta 0:04:24
epoch [36/50] batch [160/160] time 0.079 (0.114) data 0.000 (0.002) loss 0.9161 (0.9342) teacher_loss 0.1143 (0.1169) loss_zs_kd 0.0679 (0.0670) loss_oracle 0.5468 (0.5611) kd_loss 0.9890 (1.0065) acc 96.8750 (96.7383) gate/entropy 1.0827 (1.0831) gate/usage_max 0.4173 (0.4165) gate/usage_min 0.2787 (0.2797) gate/usage_std 0.0603 (0.0596) teacher/entropy 0.0254 (0.0365) teacher/usage_max 0.5623 (0.5643) teacher/usage_min 0.0305 (0.0180) teacher/usage_std 0.2233 (0.2344) nleep/row_max_mean 1510.7354 (1497.6408) nleep/row_max_std 25.6815 (59.7636) nleep/row_min_mean 1478.5488 (1468.9806) lr 4.1221e-04 eta 0:04:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,807
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,927
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.2%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [37/50] batch [20/160] time 0.081 (0.136) data 0.000 (0.017) loss 0.8415 (0.9255) teacher_loss 0.0481 (0.1138) loss_zs_kd 0.0770 (0.0690) loss_oracle 0.5321 (0.5412) kd_loss 0.9777 (1.0133) acc 100.0000 (97.0312) gate/entropy 1.0826 (1.0827) gate/usage_max 0.4177 (0.4174) gate/usage_min 0.2783 (0.2785) gate/usage_std 0.0606 (0.0603) teacher/entropy 0.0458 (0.0326) teacher/usage_max 0.5279 (0.5606) teacher/usage_min 0.0176 (0.0142) teacher/usage_std 0.2252 (0.2352) nleep/row_max_mean 1511.3757 (1499.6973) nleep/row_max_std 60.5339 (60.2018) nleep/row_min_mean 1481.9470 (1470.4614) lr 4.1221e-04 eta 0:05:02
epoch [37/50] batch [40/160] time 0.134 (0.126) data 0.000 (0.008) loss 0.8673 (0.9152) teacher_loss 0.0320 (0.1025) loss_zs_kd 0.0637 (0.0661) loss_oracle 0.5285 (0.5465) kd_loss 1.0783 (1.0128) acc 100.0000 (97.4219) gate/entropy 1.0827 (1.0827) gate/usage_max 0.4173 (0.4175) gate/usage_min 0.2784 (0.2784) gate/usage_std 0.0603 (0.0604) teacher/entropy 0.0021 (0.0319) teacher/usage_max 0.6563 (0.5602) teacher/usage_min 0.0000 (0.0166) teacher/usage_std 0.2680 (0.2337) nleep/row_max_mean 1498.6038 (1498.7427) nleep/row_max_std 53.4608 (61.9061) nleep/row_min_mean 1469.3650 (1469.6243) lr 4.1221e-04 eta 0:04:36
epoch [37/50] batch [60/160] time 0.078 (0.117) data 0.000 (0.006) loss 1.0601 (0.9155) teacher_loss 0.2299 (0.1030) loss_zs_kd 0.0406 (0.0674) loss_oracle 0.6280 (0.5505) kd_loss 0.9919 (1.0072) acc 93.7500 (97.6562) gate/entropy 1.0827 (1.0826) gate/usage_max 0.4174 (0.4175) gate/usage_min 0.2781 (0.2783) gate/usage_std 0.0604 (0.0605) teacher/entropy 0.0820 (0.0341) teacher/usage_max 0.5953 (0.5555) teacher/usage_min 0.0321 (0.0187) teacher/usage_std 0.2316 (0.2315) nleep/row_max_mean 1497.5916 (1500.0725) nleep/row_max_std 56.3952 (61.3332) nleep/row_min_mean 1469.0256 (1470.9434) lr 4.1221e-04 eta 0:04:15
epoch [37/50] batch [80/160] time 0.128 (0.117) data 0.000 (0.004) loss 0.9063 (0.9179) teacher_loss 0.1097 (0.1046) loss_zs_kd 0.0504 (0.0684) loss_oracle 0.5501 (0.5517) kd_loss 0.9928 (1.0064) acc 96.8750 (97.5391) gate/entropy 1.0825 (1.0826) gate/usage_max 0.4177 (0.4176) gate/usage_min 0.2779 (0.2782) gate/usage_std 0.0606 (0.0605) teacher/entropy 0.0611 (0.0339) teacher/usage_max 0.5192 (0.5583) teacher/usage_min 0.0425 (0.0179) teacher/usage_std 0.2083 (0.2325) nleep/row_max_mean 1487.6611 (1500.2782) nleep/row_max_std 84.4372 (59.5956) nleep/row_min_mean 1457.0355 (1471.3240) lr 4.1221e-04 eta 0:04:11
epoch [37/50] batch [100/160] time 0.122 (0.121) data 0.000 (0.003) loss 1.0715 (0.9163) teacher_loss 0.2842 (0.1013) loss_zs_kd 0.1124 (0.0684) loss_oracle 0.5612 (0.5523) kd_loss 0.9010 (1.0092) acc 87.5000 (97.5000) gate/entropy 1.0825 (1.0826) gate/usage_max 0.4178 (0.4177) gate/usage_min 0.2778 (0.2781) gate/usage_std 0.0607 (0.0606) teacher/entropy 0.0770 (0.0340) teacher/usage_max 0.6823 (0.5608) teacher/usage_min 0.0588 (0.0207) teacher/usage_std 0.2599 (0.2322) nleep/row_max_mean 1501.5098 (1500.2551) nleep/row_max_std 33.3868 (59.8114) nleep/row_min_mean 1474.3199 (1471.3130) lr 4.1221e-04 eta 0:04:18
epoch [37/50] batch [120/160] time 0.126 (0.124) data 0.000 (0.003) loss 0.8658 (0.9246) teacher_loss 0.0267 (0.1076) loss_zs_kd 0.0899 (0.0699) loss_oracle 0.5445 (0.5539) kd_loss 1.0437 (1.0103) acc 100.0000 (97.1615) gate/entropy 1.0824 (1.0825) gate/usage_max 0.4181 (0.4177) gate/usage_min 0.2773 (0.2780) gate/usage_std 0.0610 (0.0606) teacher/entropy 0.0153 (0.0340) teacher/usage_max 0.5919 (0.5601) teacher/usage_min 0.0018 (0.0216) teacher/usage_std 0.2464 (0.2314) nleep/row_max_mean 1515.2966 (1500.3576) nleep/row_max_std 29.5157 (59.0262) nleep/row_min_mean 1484.2538 (1471.4714) lr 4.1221e-04 eta 0:04:21
epoch [37/50] batch [140/160] time 0.137 (0.125) data 0.000 (0.003) loss 0.9755 (0.9234) teacher_loss 0.1368 (0.1054) loss_zs_kd 0.0762 (0.0705) loss_oracle 0.5690 (0.5562) kd_loss 1.0322 (1.0093) acc 93.7500 (97.2545) gate/entropy 1.0824 (1.0825) gate/usage_max 0.4180 (0.4178) gate/usage_min 0.2773 (0.2779) gate/usage_std 0.0609 (0.0607) teacher/entropy 0.0081 (0.0355) teacher/usage_max 0.5324 (0.5584) teacher/usage_min 0.0002 (0.0241) teacher/usage_std 0.2371 (0.2297) nleep/row_max_mean 1495.9004 (1499.7980) nleep/row_max_std 57.7841 (60.0990) nleep/row_min_mean 1465.4062 (1470.9612) lr 4.1221e-04 eta 0:04:22
epoch [37/50] batch [160/160] time 0.145 (0.125) data 0.000 (0.002) loss 1.1376 (0.9327) teacher_loss 0.3006 (0.1137) loss_zs_kd 0.0624 (0.0703) loss_oracle 0.6384 (0.5585) kd_loss 0.9730 (1.0092) acc 90.6250 (96.9727) gate/entropy 1.0822 (1.0825) gate/usage_max 0.4186 (0.4179) gate/usage_min 0.2768 (0.2778) gate/usage_std 0.0614 (0.0608) teacher/entropy 0.0564 (0.0348) teacher/usage_max 0.5183 (0.5598) teacher/usage_min 0.0702 (0.0244) teacher/usage_std 0.1911 (0.2300) nleep/row_max_mean 1489.8306 (1499.4930) nleep/row_max_std 82.2720 (60.7442) nleep/row_min_mean 1461.9583 (1470.6539) lr 3.6258e-04 eta 0:04:18
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,812
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,919
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 88.0%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [38/50] batch [20/160] time 0.132 (0.155) data 0.000 (0.013) loss 0.8943 (0.9283) teacher_loss 0.0787 (0.1022) loss_zs_kd 0.0847 (0.0763) loss_oracle 0.5292 (0.5814) kd_loss 1.0171 (0.9946) acc 100.0000 (97.5000) gate/entropy 1.0823 (1.0823) gate/usage_max 0.4181 (0.4184) gate/usage_min 0.2769 (0.2769) gate/usage_std 0.0611 (0.0612) teacher/entropy 0.0257 (0.0438) teacher/usage_max 0.5436 (0.5525) teacher/usage_min 0.0009 (0.0315) teacher/usage_std 0.2378 (0.2227) nleep/row_max_mean 1505.8225 (1495.2872) nleep/row_max_std 33.6314 (66.6372) nleep/row_min_mean 1478.5125 (1467.0103) lr 3.6258e-04 eta 0:05:20
epoch [38/50] batch [40/160] time 0.076 (0.144) data 0.000 (0.007) loss 0.9997 (0.9431) teacher_loss 0.1393 (0.1206) loss_zs_kd 0.0838 (0.0747) loss_oracle 0.6672 (0.5705) kd_loss 0.9697 (0.9997) acc 93.7500 (96.7188) gate/entropy 1.0822 (1.0822) gate/usage_max 0.4185 (0.4184) gate/usage_min 0.2768 (0.2769) gate/usage_std 0.0613 (0.0612) teacher/entropy 0.0474 (0.0404) teacher/usage_max 0.5485 (0.5570) teacher/usage_min 0.0330 (0.0260) teacher/usage_std 0.2189 (0.2269) nleep/row_max_mean 1498.9556 (1496.0861) nleep/row_max_std 56.0215 (62.9254) nleep/row_min_mean 1466.3201 (1467.4829) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [60/160] time 0.138 (0.131) data 0.001 (0.004) loss 0.9275 (0.9300) teacher_loss 0.1025 (0.1133) loss_zs_kd 0.0696 (0.0747) loss_oracle 0.6009 (0.5632) kd_loss 0.9794 (0.9954) acc 96.8750 (96.6667) gate/entropy 1.0820 (1.0822) gate/usage_max 0.4189 (0.4185) gate/usage_min 0.2765 (0.2768) gate/usage_std 0.0616 (0.0613) teacher/entropy 0.0240 (0.0428) teacher/usage_max 0.5798 (0.5530) teacher/usage_min 0.0002 (0.0285) teacher/usage_std 0.2445 (0.2247) nleep/row_max_mean 1507.1851 (1495.2878) nleep/row_max_std 42.7779 (63.5931) nleep/row_min_mean 1475.7166 (1466.6482) lr 3.6258e-04 eta 0:04:25
epoch [38/50] batch [80/160] time 0.088 (0.126) data 0.000 (0.003) loss 0.9964 (0.9255) teacher_loss 0.1733 (0.1074) loss_zs_kd 0.0808 (0.0751) loss_oracle 0.5159 (0.5651) kd_loss 1.0493 (0.9961) acc 93.7500 (96.9141) gate/entropy 1.0820 (1.0821) gate/usage_max 0.4189 (0.4186) gate/usage_min 0.2763 (0.2767) gate/usage_std 0.0616 (0.0614) teacher/entropy 0.0237 (0.0412) teacher/usage_max 0.5612 (0.5493) teacher/usage_min 0.0616 (0.0270) teacher/usage_std 0.2063 (0.2249) nleep/row_max_mean 1507.7607 (1496.5057) nleep/row_max_std 46.5036 (61.7545) nleep/row_min_mean 1476.6204 (1467.5040) lr 3.6258e-04 eta 0:04:11
epoch [38/50] batch [100/160] time 0.095 (0.122) data 0.000 (0.003) loss 0.9690 (0.9241) teacher_loss 0.1985 (0.1077) loss_zs_kd 0.0624 (0.0746) loss_oracle 0.4924 (0.5626) kd_loss 0.9861 (0.9957) acc 96.8750 (97.0000) gate/entropy 1.0819 (1.0821) gate/usage_max 0.4191 (0.4187) gate/usage_min 0.2760 (0.2766) gate/usage_std 0.0618 (0.0614) teacher/entropy 0.0775 (0.0406) teacher/usage_max 0.5342 (0.5485) teacher/usage_min 0.0584 (0.0258) teacher/usage_std 0.2012 (0.2255) nleep/row_max_mean 1469.1660 (1496.6830) nleep/row_max_std 103.4710 (61.5152) nleep/row_min_mean 1443.8584 (1467.5537) lr 3.6258e-04 eta 0:04:02
epoch [38/50] batch [120/160] time 0.149 (0.120) data 0.000 (0.002) loss 0.9684 (0.9195) teacher_loss 0.1660 (0.1037) loss_zs_kd 0.0742 (0.0740) loss_oracle 0.5220 (0.5627) kd_loss 1.0087 (0.9949) acc 96.8750 (97.1875) gate/entropy 1.0818 (1.0821) gate/usage_max 0.4194 (0.4188) gate/usage_min 0.2758 (0.2765) gate/usage_std 0.0620 (0.0615) teacher/entropy 0.0403 (0.0410) teacher/usage_max 0.5644 (0.5488) teacher/usage_min 0.0023 (0.0257) teacher/usage_std 0.2401 (0.2256) nleep/row_max_mean 1496.1555 (1497.0578) nleep/row_max_std 65.2560 (60.9439) nleep/row_min_mean 1468.9606 (1467.9473) lr 3.6258e-04 eta 0:03:55
epoch [38/50] batch [140/160] time 0.148 (0.120) data 0.000 (0.002) loss 0.9138 (0.9220) teacher_loss 0.1111 (0.1052) loss_zs_kd 0.0529 (0.0745) loss_oracle 0.5984 (0.5648) kd_loss 0.9541 (0.9942) acc 100.0000 (97.0759) gate/entropy 1.0819 (1.0820) gate/usage_max 0.4192 (0.4189) gate/usage_min 0.2760 (0.2764) gate/usage_std 0.0619 (0.0616) teacher/entropy 0.0580 (0.0404) teacher/usage_max 0.5579 (0.5483) teacher/usage_min 0.0280 (0.0265) teacher/usage_std 0.2237 (0.2252) nleep/row_max_mean 1493.3590 (1497.5101) nleep/row_max_std 58.8784 (60.4578) nleep/row_min_mean 1465.8069 (1468.4525) lr 3.6258e-04 eta 0:03:51
epoch [38/50] batch [160/160] time 0.074 (0.115) data 0.000 (0.002) loss 0.8504 (0.9219) teacher_loss 0.0442 (0.1031) loss_zs_kd 0.0598 (0.0747) loss_oracle 0.5234 (0.5662) kd_loss 1.0292 (0.9967) acc 100.0000 (97.1289) gate/entropy 1.0817 (1.0820) gate/usage_max 0.4197 (0.4190) gate/usage_min 0.2756 (0.2763) gate/usage_std 0.0623 (0.0617) teacher/entropy 0.0079 (0.0394) teacher/usage_max 0.5299 (0.5488) teacher/usage_min 0.0012 (0.0272) teacher/usage_std 0.2362 (0.2249) nleep/row_max_mean 1501.7754 (1497.9191) nleep/row_max_std 41.9034 (60.0413) nleep/row_min_mean 1473.2664 (1468.9176) lr 3.1545e-04 eta 0:03:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,799
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,898
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 87.5%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [39/50] batch [20/160] time 0.116 (0.125) data 0.000 (0.018) loss 0.8702 (0.9339) teacher_loss 0.0762 (0.1103) loss_zs_kd 0.0325 (0.0750) loss_oracle 0.5843 (0.5749) kd_loss 0.9713 (0.9972) acc 96.8750 (97.1875) gate/entropy 1.0816 (1.0817) gate/usage_max 0.4198 (0.4196) gate/usage_min 0.2753 (0.2755) gate/usage_std 0.0623 (0.0622) teacher/entropy 0.0696 (0.0416) teacher/usage_max 0.5284 (0.5700) teacher/usage_min 0.0117 (0.0254) teacher/usage_std 0.2292 (0.2330) nleep/row_max_mean 1512.9293 (1498.0479) nleep/row_max_std 43.1160 (58.1458) nleep/row_min_mean 1484.0702 (1469.4151) lr 3.1545e-04 eta 0:03:56
epoch [39/50] batch [40/160] time 0.127 (0.129) data 0.000 (0.009) loss 0.9880 (0.9377) teacher_loss 0.1904 (0.1202) loss_zs_kd 0.0691 (0.0712) loss_oracle 0.4898 (0.5676) kd_loss 1.0361 (0.9961) acc 96.8750 (96.9531) gate/entropy 1.0817 (1.0817) gate/usage_max 0.4198 (0.4197) gate/usage_min 0.2754 (0.2754) gate/usage_std 0.0623 (0.0622) teacher/entropy 0.0124 (0.0426) teacher/usage_max 0.5296 (0.5577) teacher/usage_min 0.0303 (0.0301) teacher/usage_std 0.2174 (0.2268) nleep/row_max_mean 1499.5784 (1496.9239) nleep/row_max_std 59.2949 (60.8695) nleep/row_min_mean 1471.6035 (1468.3059) lr 3.1545e-04 eta 0:04:02
epoch [39/50] batch [60/160] time 0.131 (0.132) data 0.001 (0.006) loss 0.9599 (0.9353) teacher_loss 0.1477 (0.1151) loss_zs_kd 0.0490 (0.0720) loss_oracle 0.5564 (0.5681) kd_loss 1.0189 (1.0003) acc 93.7500 (96.9271) gate/entropy 1.0817 (1.0817) gate/usage_max 0.4195 (0.4197) gate/usage_min 0.2754 (0.2754) gate/usage_std 0.0621 (0.0623) teacher/entropy 0.0298 (0.0413) teacher/usage_max 0.5374 (0.5548) teacher/usage_min 0.0233 (0.0307) teacher/usage_std 0.2229 (0.2263) nleep/row_max_mean 1484.3309 (1497.1398) nleep/row_max_std 62.3932 (59.2140) nleep/row_min_mean 1456.6658 (1468.5550) lr 3.1545e-04 eta 0:04:05
epoch [39/50] batch [80/160] time 0.148 (0.133) data 0.000 (0.005) loss 0.9669 (0.9364) teacher_loss 0.1395 (0.1157) loss_zs_kd 0.0759 (0.0726) loss_oracle 0.5906 (0.5687) kd_loss 0.9884 (1.0000) acc 96.8750 (97.0312) gate/entropy 1.0816 (1.0816) gate/usage_max 0.4200 (0.4198) gate/usage_min 0.2751 (0.2753) gate/usage_std 0.0625 (0.0623) teacher/entropy 0.0434 (0.0410) teacher/usage_max 0.5012 (0.5560) teacher/usage_min 0.0625 (0.0317) teacher/usage_std 0.1933 (0.2261) nleep/row_max_mean 1502.1013 (1497.9080) nleep/row_max_std 55.3765 (57.7733) nleep/row_min_mean 1474.0369 (1469.3498) lr 3.1545e-04 eta 0:04:03
epoch [39/50] batch [100/160] time 0.130 (0.134) data 0.000 (0.004) loss 0.8853 (0.9383) teacher_loss 0.0462 (0.1156) loss_zs_kd 0.0754 (0.0739) loss_oracle 0.5590 (0.5697) kd_loss 1.0440 (1.0017) acc 96.8750 (96.9688) gate/entropy 1.0814 (1.0816) gate/usage_max 0.4203 (0.4198) gate/usage_min 0.2748 (0.2752) gate/usage_std 0.0627 (0.0624) teacher/entropy 0.0260 (0.0420) teacher/usage_max 0.5603 (0.5514) teacher/usage_min 0.0579 (0.0360) teacher/usage_std 0.2079 (0.2222) nleep/row_max_mean 1503.9916 (1497.2730) nleep/row_max_std 51.0065 (58.5187) nleep/row_min_mean 1476.3406 (1468.9078) lr 3.1545e-04 eta 0:04:03
epoch [39/50] batch [120/160] time 0.121 (0.135) data 0.000 (0.003) loss 1.0020 (0.9397) teacher_loss 0.1845 (0.1173) loss_zs_kd 0.0744 (0.0734) loss_oracle 0.5439 (0.5685) kd_loss 1.0168 (1.0029) acc 90.6250 (96.9271) gate/entropy 1.0815 (1.0816) gate/usage_max 0.4200 (0.4199) gate/usage_min 0.2750 (0.2752) gate/usage_std 0.0625 (0.0624) teacher/entropy 0.0745 (0.0431) teacher/usage_max 0.5999 (0.5516) teacher/usage_min 0.0779 (0.0399) teacher/usage_std 0.2133 (0.2199) nleep/row_max_mean 1497.8884 (1496.5684) nleep/row_max_std 64.2288 (59.4725) nleep/row_min_mean 1469.8679 (1468.4318) lr 3.1545e-04 eta 0:04:02
epoch [39/50] batch [140/160] time 0.153 (0.135) data 0.000 (0.003) loss 0.8026 (0.9364) teacher_loss 0.0218 (0.1146) loss_zs_kd 0.0443 (0.0724) loss_oracle 0.5222 (0.5688) kd_loss 0.9952 (1.0024) acc 100.0000 (97.0312) gate/entropy 1.0814 (1.0816) gate/usage_max 0.4203 (0.4199) gate/usage_min 0.2745 (0.2751) gate/usage_std 0.0628 (0.0624) teacher/entropy 0.0526 (0.0428) teacher/usage_max 0.5075 (0.5519) teacher/usage_min 0.0469 (0.0391) teacher/usage_std 0.2041 (0.2202) nleep/row_max_mean 1512.1023 (1497.0622) nleep/row_max_std 56.6264 (58.6777) nleep/row_min_mean 1482.0001 (1468.9002) lr 3.1545e-04 eta 0:03:59
epoch [39/50] batch [160/160] time 0.131 (0.134) data 0.000 (0.002) loss 0.8555 (0.9353) teacher_loss 0.0386 (0.1133) loss_zs_kd 0.0897 (0.0730) loss_oracle 0.5527 (0.5670) kd_loss 0.9914 (1.0040) acc 100.0000 (97.0508) gate/entropy 1.0814 (1.0816) gate/usage_max 0.4202 (0.4199) gate/usage_min 0.2744 (0.2751) gate/usage_std 0.0627 (0.0624) teacher/entropy 0.0282 (0.0423) teacher/usage_max 0.5234 (0.5532) teacher/usage_min 0.0081 (0.0396) teacher/usage_std 0.2311 (0.2204) nleep/row_max_mean 1506.5830 (1496.9958) nleep/row_max_std 43.6022 (59.1248) nleep/row_min_mean 1478.3303 (1468.8185) lr 2.7103e-04 eta 0:03:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,796
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,891
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 87.3%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [40/50] batch [20/160] time 0.109 (0.134) data 0.000 (0.018) loss 0.8649 (0.9019) teacher_loss 0.0295 (0.0788) loss_zs_kd 0.0706 (0.0702) loss_oracle 0.5903 (0.5671) kd_loss 1.0100 (1.0089) acc 100.0000 (97.9688) gate/entropy 1.0815 (1.0814) gate/usage_max 0.4201 (0.4203) gate/usage_min 0.2745 (0.2745) gate/usage_std 0.0626 (0.0628) teacher/entropy 0.0392 (0.0297) teacher/usage_max 0.4989 (0.5298) teacher/usage_min 0.0568 (0.0422) teacher/usage_std 0.1968 (0.2119) nleep/row_max_mean 1492.5592 (1499.9923) nleep/row_max_std 64.8475 (54.4345) nleep/row_min_mean 1461.4100 (1471.0601) lr 2.7103e-04 eta 0:03:53
epoch [40/50] batch [40/160] time 0.076 (0.116) data 0.000 (0.009) loss 0.9775 (0.9106) teacher_loss 0.1486 (0.0808) loss_zs_kd 0.0680 (0.0715) loss_oracle 0.5793 (0.5744) kd_loss 1.0106 (1.0136) acc 96.8750 (97.9688) gate/entropy 1.0813 (1.0814) gate/usage_max 0.4205 (0.4203) gate/usage_min 0.2742 (0.2744) gate/usage_std 0.0629 (0.0628) teacher/entropy 0.0285 (0.0334) teacher/usage_max 0.5001 (0.5393) teacher/usage_min 0.0334 (0.0449) teacher/usage_std 0.2126 (0.2144) nleep/row_max_mean 1494.3467 (1499.5558) nleep/row_max_std 74.9354 (57.1159) nleep/row_min_mean 1465.7867 (1470.5440) lr 2.7103e-04 eta 0:03:18
epoch [40/50] batch [60/160] time 0.081 (0.113) data 0.001 (0.006) loss 0.8533 (0.9095) teacher_loss 0.0144 (0.0762) loss_zs_kd 0.0614 (0.0747) loss_oracle 0.5721 (0.5735) kd_loss 1.0443 (1.0186) acc 100.0000 (98.0208) gate/entropy 1.0814 (1.0814) gate/usage_max 0.4201 (0.4203) gate/usage_min 0.2742 (0.2743) gate/usage_std 0.0627 (0.0628) teacher/entropy 0.0303 (0.0308) teacher/usage_max 0.5649 (0.5405) teacher/usage_min 0.0681 (0.0443) teacher/usage_std 0.2042 (0.2145) nleep/row_max_mean 1491.4012 (1499.6212) nleep/row_max_std 71.9300 (58.1307) nleep/row_min_mean 1463.7816 (1470.3783) lr 2.7103e-04 eta 0:03:12
epoch [40/50] batch [80/160] time 0.082 (0.112) data 0.000 (0.005) loss 0.9351 (0.9232) teacher_loss 0.0705 (0.0886) loss_zs_kd 0.0773 (0.0754) loss_oracle 0.6572 (0.5772) kd_loss 0.9947 (1.0165) acc 96.8750 (97.6172) gate/entropy 1.0814 (1.0813) gate/usage_max 0.4202 (0.4204) gate/usage_min 0.2742 (0.2743) gate/usage_std 0.0627 (0.0628) teacher/entropy 0.0139 (0.0300) teacher/usage_max 0.5635 (0.5384) teacher/usage_min 0.0326 (0.0417) teacher/usage_std 0.2224 (0.2151) nleep/row_max_mean 1495.6278 (1498.9300) nleep/row_max_std 53.5910 (59.0665) nleep/row_min_mean 1468.0239 (1469.7898) lr 2.7103e-04 eta 0:03:07
epoch [40/50] batch [100/160] time 0.078 (0.111) data 0.000 (0.004) loss 0.9149 (0.9245) teacher_loss 0.0976 (0.0925) loss_zs_kd 0.0602 (0.0749) loss_oracle 0.5104 (0.5738) kd_loss 1.0642 (1.0152) acc 96.8750 (97.4688) gate/entropy 1.0813 (1.0813) gate/usage_max 0.4202 (0.4204) gate/usage_min 0.2739 (0.2742) gate/usage_std 0.0628 (0.0629) teacher/entropy 0.0183 (0.0308) teacher/usage_max 0.6802 (0.5440) teacher/usage_min 0.0000 (0.0387) teacher/usage_std 0.2778 (0.2180) nleep/row_max_mean 1496.6198 (1498.6751) nleep/row_max_std 51.1461 (58.7811) nleep/row_min_mean 1464.4465 (1469.4799) lr 2.7103e-04 eta 0:03:04
epoch [40/50] batch [120/160] time 0.079 (0.110) data 0.000 (0.003) loss 0.9965 (0.9263) teacher_loss 0.1367 (0.0928) loss_zs_kd 0.1030 (0.0756) loss_oracle 0.6024 (0.5749) kd_loss 1.0141 (1.0165) acc 96.8750 (97.4479) gate/entropy 1.0812 (1.0813) gate/usage_max 0.4207 (0.4204) gate/usage_min 0.2738 (0.2742) gate/usage_std 0.0631 (0.0629) teacher/entropy 0.0000 (0.0301) teacher/usage_max 0.5312 (0.5457) teacher/usage_min 0.0000 (0.0377) teacher/usage_std 0.2371 (0.2187) nleep/row_max_mean 1517.2858 (1498.5357) nleep/row_max_std 24.1657 (58.2111) nleep/row_min_mean 1482.1863 (1469.2343) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [140/160] time 0.142 (0.109) data 0.000 (0.003) loss 0.9389 (0.9270) teacher_loss 0.0667 (0.0927) loss_zs_kd 0.0813 (0.0760) loss_oracle 0.6808 (0.5774) kd_loss 0.9822 (1.0152) acc 100.0000 (97.3884) gate/entropy 1.0812 (1.0813) gate/usage_max 0.4206 (0.4204) gate/usage_min 0.2737 (0.2741) gate/usage_std 0.0631 (0.0629) teacher/entropy 0.0684 (0.0310) teacher/usage_max 0.5812 (0.5460) teacher/usage_min 0.0005 (0.0387) teacher/usage_std 0.2445 (0.2185) nleep/row_max_mean 1511.2571 (1498.3656) nleep/row_max_std 44.1334 (58.1088) nleep/row_min_mean 1478.8083 (1469.0011) lr 2.7103e-04 eta 0:02:56
epoch [40/50] batch [160/160] time 0.164 (0.107) data 0.000 (0.002) loss 0.8766 (0.9295) teacher_loss 0.0638 (0.0960) loss_zs_kd 0.0729 (0.0764) loss_oracle 0.5932 (0.5772) kd_loss 0.9594 (1.0133) acc 100.0000 (97.3438) gate/entropy 1.0812 (1.0813) gate/usage_max 0.4207 (0.4205) gate/usage_min 0.2736 (0.2741) gate/usage_std 0.0632 (0.0629) teacher/entropy 0.0165 (0.0307) teacher/usage_max 0.6527 (0.5482) teacher/usage_min 0.0040 (0.0378) teacher/usage_std 0.2649 (0.2196) nleep/row_max_mean 1501.9337 (1497.8985) nleep/row_max_std 51.0293 (58.5564) nleep/row_min_mean 1468.6882 (1468.5794) lr 2.2949e-04 eta 0:02:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,803
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,899
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 87.5%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [41/50] batch [20/160] time 0.147 (0.158) data 0.000 (0.014) loss 0.8888 (0.9104) teacher_loss 0.0501 (0.0974) loss_zs_kd 0.0915 (0.0732) loss_oracle 0.5677 (0.5598) kd_loss 1.0184 (0.9931) acc 100.0000 (97.6562) gate/entropy 1.0810 (1.0811) gate/usage_max 0.4211 (0.4208) gate/usage_min 0.2733 (0.2735) gate/usage_std 0.0634 (0.0632) teacher/entropy 0.0262 (0.0450) teacher/usage_max 0.5289 (0.5562) teacher/usage_min 0.0252 (0.0389) teacher/usage_std 0.2205 (0.2208) nleep/row_max_mean 1508.2740 (1494.2863) nleep/row_max_std 57.0643 (61.8568) nleep/row_min_mean 1477.2347 (1465.0048) lr 2.2949e-04 eta 0:04:10
epoch [41/50] batch [40/160] time 0.128 (0.149) data 0.000 (0.007) loss 0.9495 (0.9277) teacher_loss 0.1190 (0.1083) loss_zs_kd 0.0859 (0.0742) loss_oracle 0.5672 (0.5633) kd_loss 1.0080 (1.0012) acc 93.7500 (97.5000) gate/entropy 1.0809 (1.0811) gate/usage_max 0.4213 (0.4208) gate/usage_min 0.2732 (0.2735) gate/usage_std 0.0636 (0.0632) teacher/entropy 0.0225 (0.0416) teacher/usage_max 0.4999 (0.5598) teacher/usage_min 0.0151 (0.0391) teacher/usage_std 0.2251 (0.2216) nleep/row_max_mean 1502.8929 (1495.4769) nleep/row_max_std 67.6774 (60.2411) nleep/row_min_mean 1472.9175 (1466.2008) lr 2.2949e-04 eta 0:03:52
epoch [41/50] batch [60/160] time 0.147 (0.147) data 0.001 (0.005) loss 0.9064 (0.9267) teacher_loss 0.0417 (0.1048) loss_zs_kd 0.0715 (0.0742) loss_oracle 0.6760 (0.5715) kd_loss 0.9819 (0.9981) acc 100.0000 (97.5000) gate/entropy 1.0809 (1.0811) gate/usage_max 0.4212 (0.4209) gate/usage_min 0.2731 (0.2734) gate/usage_std 0.0636 (0.0633) teacher/entropy 0.0134 (0.0378) teacher/usage_max 0.5911 (0.5579) teacher/usage_min 0.0033 (0.0366) teacher/usage_std 0.2454 (0.2224) nleep/row_max_mean 1500.1421 (1496.5476) nleep/row_max_std 63.6559 (58.3564) nleep/row_min_mean 1471.2402 (1467.1387) lr 2.2949e-04 eta 0:03:46
epoch [41/50] batch [80/160] time 0.139 (0.141) data 0.000 (0.004) loss 0.8415 (0.9351) teacher_loss 0.0277 (0.1078) loss_zs_kd 0.0659 (0.0761) loss_oracle 0.4867 (0.5755) kd_loss 1.0749 (1.0029) acc 100.0000 (97.3828) gate/entropy 1.0812 (1.0811) gate/usage_max 0.4206 (0.4209) gate/usage_min 0.2734 (0.2734) gate/usage_std 0.0631 (0.0633) teacher/entropy 0.0030 (0.0353) teacher/usage_max 0.6247 (0.5564) teacher/usage_min 0.0315 (0.0347) teacher/usage_std 0.2423 (0.2230) nleep/row_max_mean 1501.2778 (1497.7003) nleep/row_max_std 45.4409 (56.8258) nleep/row_min_mean 1471.2064 (1467.9802) lr 2.2949e-04 eta 0:03:34
epoch [41/50] batch [100/160] time 0.131 (0.139) data 0.000 (0.003) loss 0.8415 (0.9300) teacher_loss 0.0335 (0.1035) loss_zs_kd 0.0833 (0.0769) loss_oracle 0.5555 (0.5733) kd_loss 0.9772 (1.0028) acc 100.0000 (97.4688) gate/entropy 1.0808 (1.0811) gate/usage_max 0.4216 (0.4210) gate/usage_min 0.2728 (0.2733) gate/usage_std 0.0638 (0.0634) teacher/entropy 0.0062 (0.0343) teacher/usage_max 0.6253 (0.5596) teacher/usage_min 0.0000 (0.0317) teacher/usage_std 0.2570 (0.2254) nleep/row_max_mean 1515.3435 (1498.5826) nleep/row_max_std 26.0991 (55.6365) nleep/row_min_mean 1484.0955 (1468.7519) lr 2.2949e-04 eta 0:03:27
epoch [41/50] batch [120/160] time 0.125 (0.138) data 0.000 (0.003) loss 0.9338 (0.9281) teacher_loss 0.0989 (0.1023) loss_zs_kd 0.0853 (0.0760) loss_oracle 0.5807 (0.5734) kd_loss 1.0039 (1.0023) acc 96.8750 (97.3438) gate/entropy 1.0809 (1.0810) gate/usage_max 0.4212 (0.4210) gate/usage_min 0.2729 (0.2732) gate/usage_std 0.0636 (0.0634) teacher/entropy 0.0410 (0.0337) teacher/usage_max 0.5313 (0.5587) teacher/usage_min 0.0276 (0.0306) teacher/usage_std 0.2193 (0.2258) nleep/row_max_mean 1499.2266 (1498.1946) nleep/row_max_std 57.8321 (56.6758) nleep/row_min_mean 1469.9336 (1468.4119) lr 2.2949e-04 eta 0:03:24
epoch [41/50] batch [140/160] time 0.106 (0.136) data 0.000 (0.002) loss 0.9829 (0.9300) teacher_loss 0.1999 (0.1043) loss_zs_kd 0.0617 (0.0755) loss_oracle 0.4999 (0.5730) kd_loss 1.0045 (1.0028) acc 93.7500 (97.3214) gate/entropy 1.0810 (1.0810) gate/usage_max 0.4211 (0.4210) gate/usage_min 0.2729 (0.2732) gate/usage_std 0.0635 (0.0634) teacher/entropy 0.0608 (0.0338) teacher/usage_max 0.5990 (0.5581) teacher/usage_min 0.0240 (0.0305) teacher/usage_std 0.2367 (0.2257) nleep/row_max_mean 1486.7166 (1497.7765) nleep/row_max_std 78.5648 (56.5604) nleep/row_min_mean 1457.5492 (1468.1454) lr 2.2949e-04 eta 0:03:17
epoch [41/50] batch [160/160] time 0.067 (0.131) data 0.000 (0.002) loss 1.0190 (0.9286) teacher_loss 0.1938 (0.1035) loss_zs_kd 0.0894 (0.0753) loss_oracle 0.5934 (0.5732) kd_loss 0.9677 (1.0016) acc 93.7500 (97.3047) gate/entropy 1.0809 (1.0810) gate/usage_max 0.4213 (0.4211) gate/usage_min 0.2728 (0.2731) gate/usage_std 0.0637 (0.0635) teacher/entropy 0.0586 (0.0343) teacher/usage_max 0.4977 (0.5579) teacher/usage_min 0.0144 (0.0310) teacher/usage_std 0.2256 (0.2254) nleep/row_max_mean 1500.9707 (1497.2008) nleep/row_max_std 42.9747 (56.8167) nleep/row_min_mean 1471.5598 (1467.6693) lr 1.9098e-04 eta 0:03:08
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,913
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [42/50] batch [20/160] time 0.070 (0.114) data 0.000 (0.017) loss 1.1588 (0.9287) teacher_loss 0.3083 (0.0987) loss_zs_kd 0.0947 (0.0772) loss_oracle 0.6293 (0.5846) kd_loss 0.9770 (0.9983) acc 90.6250 (97.3438) gate/entropy 1.0808 (1.0808) gate/usage_max 0.4215 (0.4214) gate/usage_min 0.2727 (0.2727) gate/usage_std 0.0638 (0.0637) teacher/entropy 0.0184 (0.0396) teacher/usage_max 0.5954 (0.5503) teacher/usage_min 0.0290 (0.0398) teacher/usage_std 0.2331 (0.2194) nleep/row_max_mean 1493.5260 (1491.0141) nleep/row_max_std 57.3522 (64.7727) nleep/row_min_mean 1460.7833 (1461.7279) lr 1.9098e-04 eta 0:02:41
epoch [42/50] batch [40/160] time 0.094 (0.100) data 0.000 (0.009) loss 0.9182 (0.9259) teacher_loss 0.0798 (0.1018) loss_zs_kd 0.0636 (0.0762) loss_oracle 0.5790 (0.5790) kd_loss 1.0342 (0.9931) acc 96.8750 (97.5000) gate/entropy 1.0809 (1.0808) gate/usage_max 0.4213 (0.4215) gate/usage_min 0.2728 (0.2726) gate/usage_std 0.0637 (0.0638) teacher/entropy 0.0390 (0.0396) teacher/usage_max 0.5912 (0.5563) teacher/usage_min 0.0479 (0.0352) teacher/usage_std 0.2226 (0.2224) nleep/row_max_mean 1489.6021 (1491.9302) nleep/row_max_std 58.7202 (62.2346) nleep/row_min_mean 1463.7148 (1462.9717) lr 1.9098e-04 eta 0:02:19
epoch [42/50] batch [60/160] time 0.070 (0.098) data 0.001 (0.006) loss 1.0155 (0.9258) teacher_loss 0.2165 (0.1053) loss_zs_kd 0.0676 (0.0742) loss_oracle 0.5163 (0.5797) kd_loss 1.0141 (0.9872) acc 93.7500 (97.4479) gate/entropy 1.0806 (1.0808) gate/usage_max 0.4219 (0.4216) gate/usage_min 0.2724 (0.2726) gate/usage_std 0.0641 (0.0639) teacher/entropy 0.0395 (0.0416) teacher/usage_max 0.5963 (0.5615) teacher/usage_min 0.0000 (0.0322) teacher/usage_std 0.2485 (0.2254) nleep/row_max_mean 1508.4427 (1493.8817) nleep/row_max_std 37.8054 (59.4191) nleep/row_min_mean 1479.2827 (1464.8876) lr 1.9098e-04 eta 0:02:15
epoch [42/50] batch [80/160] time 0.138 (0.100) data 0.000 (0.005) loss 0.8663 (0.9196) teacher_loss 0.0537 (0.0971) loss_zs_kd 0.0641 (0.0738) loss_oracle 0.5135 (0.5830) kd_loss 1.0476 (0.9881) acc 96.8750 (97.6953) gate/entropy 1.0807 (1.0808) gate/usage_max 0.4218 (0.4216) gate/usage_min 0.2724 (0.2726) gate/usage_std 0.0640 (0.0639) teacher/entropy 0.0151 (0.0411) teacher/usage_max 0.6217 (0.5546) teacher/usage_min 0.0025 (0.0314) teacher/usage_std 0.2546 (0.2241) nleep/row_max_mean 1491.0010 (1494.1093) nleep/row_max_std 68.1827 (59.0262) nleep/row_min_mean 1463.0573 (1465.1921) lr 1.9098e-04 eta 0:02:16
epoch [42/50] batch [100/160] time 0.156 (0.099) data 0.001 (0.004) loss 0.8748 (0.9192) teacher_loss 0.0995 (0.0988) loss_zs_kd 0.0467 (0.0728) loss_oracle 0.5468 (0.5814) kd_loss 0.9570 (0.9866) acc 96.8750 (97.4062) gate/entropy 1.0806 (1.0807) gate/usage_max 0.4219 (0.4216) gate/usage_min 0.2724 (0.2725) gate/usage_std 0.0641 (0.0639) teacher/entropy 0.0316 (0.0413) teacher/usage_max 0.6200 (0.5538) teacher/usage_min 0.0372 (0.0290) teacher/usage_std 0.2380 (0.2253) nleep/row_max_mean 1511.2094 (1495.0872) nleep/row_max_std 25.4746 (57.4783) nleep/row_min_mean 1480.6902 (1466.1631) lr 1.9098e-04 eta 0:02:12
epoch [42/50] batch [120/160] time 0.085 (0.098) data 0.000 (0.003) loss 0.9181 (0.9187) teacher_loss 0.1116 (0.0991) loss_zs_kd 0.0578 (0.0718) loss_oracle 0.6280 (0.5820) kd_loss 0.9272 (0.9853) acc 96.8750 (97.4479) gate/entropy 1.0806 (1.0807) gate/usage_max 0.4220 (0.4217) gate/usage_min 0.2720 (0.2725) gate/usage_std 0.0642 (0.0639) teacher/entropy 0.0671 (0.0411) teacher/usage_max 0.5978 (0.5557) teacher/usage_min 0.0266 (0.0289) teacher/usage_std 0.2351 (0.2258) nleep/row_max_mean 1494.0906 (1494.8432) nleep/row_max_std 71.6590 (57.1895) nleep/row_min_mean 1466.4109 (1465.9918) lr 1.9098e-04 eta 0:02:09
epoch [42/50] batch [140/160] time 0.142 (0.099) data 0.000 (0.003) loss 0.9061 (0.9211) teacher_loss 0.1055 (0.1023) loss_zs_kd 0.0616 (0.0719) loss_oracle 0.5431 (0.5815) kd_loss 0.9966 (0.9841) acc 93.7500 (97.2768) gate/entropy 1.0805 (1.0807) gate/usage_max 0.4222 (0.4218) gate/usage_min 0.2720 (0.2724) gate/usage_std 0.0644 (0.0640) teacher/entropy 0.0647 (0.0423) teacher/usage_max 0.5821 (0.5557) teacher/usage_min 0.0281 (0.0298) teacher/usage_std 0.2297 (0.2253) nleep/row_max_mean 1504.2688 (1494.7319) nleep/row_max_std 58.8608 (58.3719) nleep/row_min_mean 1478.3500 (1465.8354) lr 1.9098e-04 eta 0:02:08
epoch [42/50] batch [160/160] time 0.123 (0.102) data 0.000 (0.002) loss 0.8806 (0.9182) teacher_loss 0.0861 (0.0998) loss_zs_kd 0.0739 (0.0723) loss_oracle 0.6032 (0.5805) kd_loss 0.9120 (0.9840) acc 96.8750 (97.4023) gate/entropy 1.0804 (1.0807) gate/usage_max 0.4225 (0.4218) gate/usage_min 0.2720 (0.2724) gate/usage_std 0.0645 (0.0640) teacher/entropy 0.0368 (0.0418) teacher/usage_max 0.7284 (0.5545) teacher/usage_min 0.0001 (0.0287) teacher/usage_std 0.3005 (0.2259) nleep/row_max_mean 1513.0616 (1495.0528) nleep/row_max_std 24.4191 (57.7758) nleep/row_min_mean 1481.9840 (1466.1715) lr 1.5567e-04 eta 0:02:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,935
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.3%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [43/50] batch [20/160] time 0.150 (0.157) data 0.000 (0.016) loss 1.0711 (0.9051) teacher_loss 0.2906 (0.0950) loss_zs_kd 0.0930 (0.0712) loss_oracle 0.5349 (0.5705) kd_loss 0.9332 (0.9786) acc 93.7500 (96.8750) gate/entropy 1.0805 (1.0805) gate/usage_max 0.4223 (0.4223) gate/usage_min 0.2720 (0.2719) gate/usage_std 0.0644 (0.0644) teacher/entropy 0.0994 (0.0451) teacher/usage_max 0.4885 (0.5565) teacher/usage_min 0.0316 (0.0307) teacher/usage_std 0.2134 (0.2255) nleep/row_max_mean 1490.3525 (1494.4991) nleep/row_max_std 49.9075 (59.2808) nleep/row_min_mean 1462.0139 (1465.0012) lr 1.5567e-04 eta 0:03:17
epoch [43/50] batch [40/160] time 0.112 (0.148) data 0.000 (0.008) loss 0.8774 (0.9046) teacher_loss 0.0451 (0.0926) loss_zs_kd 0.0879 (0.0702) loss_oracle 0.5748 (0.5719) kd_loss 1.0017 (0.9819) acc 100.0000 (97.3438) gate/entropy 1.0804 (1.0804) gate/usage_max 0.4224 (0.4224) gate/usage_min 0.2718 (0.2719) gate/usage_std 0.0645 (0.0645) teacher/entropy 0.0181 (0.0374) teacher/usage_max 0.5071 (0.5570) teacher/usage_min 0.0001 (0.0261) teacher/usage_std 0.2357 (0.2281) nleep/row_max_mean 1504.3030 (1496.5509) nleep/row_max_std 43.3412 (58.4329) nleep/row_min_mean 1472.3777 (1466.5219) lr 1.5567e-04 eta 0:03:03
epoch [43/50] batch [60/160] time 0.132 (0.144) data 0.000 (0.006) loss 0.8868 (0.9138) teacher_loss 0.0368 (0.0978) loss_zs_kd 0.1152 (0.0722) loss_oracle 0.5703 (0.5752) kd_loss 1.0144 (0.9845) acc 100.0000 (97.1354) gate/entropy 1.0802 (1.0804) gate/usage_max 0.4230 (0.4224) gate/usage_min 0.2714 (0.2718) gate/usage_std 0.0649 (0.0645) teacher/entropy 0.0158 (0.0384) teacher/usage_max 0.5260 (0.5610) teacher/usage_min 0.0002 (0.0252) teacher/usage_std 0.2366 (0.2298) nleep/row_max_mean 1502.2678 (1496.7281) nleep/row_max_std 58.3650 (58.8048) nleep/row_min_mean 1474.4355 (1467.1213) lr 1.5567e-04 eta 0:02:55
epoch [43/50] batch [80/160] time 0.128 (0.141) data 0.000 (0.004) loss 0.8922 (0.9214) teacher_loss 0.0591 (0.1035) loss_zs_kd 0.0863 (0.0740) loss_oracle 0.5574 (0.5760) kd_loss 1.0224 (0.9858) acc 100.0000 (97.1094) gate/entropy 1.0804 (1.0804) gate/usage_max 0.4224 (0.4225) gate/usage_min 0.2717 (0.2718) gate/usage_std 0.0645 (0.0646) teacher/entropy 0.0472 (0.0388) teacher/usage_max 0.6183 (0.5545) teacher/usage_min 0.0208 (0.0270) teacher/usage_std 0.2447 (0.2274) nleep/row_max_mean 1479.3220 (1495.6115) nleep/row_max_std 76.6217 (60.1104) nleep/row_min_mean 1451.7966 (1466.3541) lr 1.5567e-04 eta 0:02:49
epoch [43/50] batch [100/160] time 0.090 (0.140) data 0.000 (0.003) loss 0.8320 (0.9202) teacher_loss 0.0205 (0.1006) loss_zs_kd 0.0708 (0.0726) loss_oracle 0.5550 (0.5771) kd_loss 0.9973 (0.9896) acc 100.0000 (97.2812) gate/entropy 1.0803 (1.0804) gate/usage_max 0.4227 (0.4225) gate/usage_min 0.2716 (0.2717) gate/usage_std 0.0647 (0.0646) teacher/entropy 0.0239 (0.0379) teacher/usage_max 0.5036 (0.5541) teacher/usage_min 0.0003 (0.0271) teacher/usage_std 0.2355 (0.2271) nleep/row_max_mean 1502.9348 (1495.6261) nleep/row_max_std 48.8466 (59.3402) nleep/row_min_mean 1473.2527 (1466.5509) lr 1.5567e-04 eta 0:02:45
epoch [43/50] batch [120/160] time 0.124 (0.135) data 0.000 (0.003) loss 0.8186 (0.9207) teacher_loss 0.0086 (0.1011) loss_zs_kd 0.0577 (0.0732) loss_oracle 0.5301 (0.5751) kd_loss 1.0321 (0.9909) acc 100.0000 (97.1875) gate/entropy 1.0804 (1.0804) gate/usage_max 0.4225 (0.4225) gate/usage_min 0.2714 (0.2717) gate/usage_std 0.0646 (0.0646) teacher/entropy 0.0218 (0.0382) teacher/usage_max 0.5612 (0.5559) teacher/usage_min 0.0281 (0.0278) teacher/usage_std 0.2244 (0.2268) nleep/row_max_mean 1501.7820 (1495.1574) nleep/row_max_std 57.0191 (59.4806) nleep/row_min_mean 1473.4711 (1466.2571) lr 1.5567e-04 eta 0:02:37
epoch [43/50] batch [140/160] time 0.132 (0.131) data 0.000 (0.003) loss 0.8955 (0.9172) teacher_loss 0.0631 (0.0969) loss_zs_kd 0.0564 (0.0726) loss_oracle 0.5891 (0.5769) kd_loss 1.0195 (0.9912) acc 96.8750 (97.2991) gate/entropy 1.0803 (1.0803) gate/usage_max 0.4227 (0.4226) gate/usage_min 0.2716 (0.2717) gate/usage_std 0.0647 (0.0646) teacher/entropy 0.0117 (0.0376) teacher/usage_max 0.5286 (0.5550) teacher/usage_min 0.0001 (0.0270) teacher/usage_std 0.2368 (0.2271) nleep/row_max_mean 1490.9043 (1494.9028) nleep/row_max_std 54.1748 (59.5226) nleep/row_min_mean 1462.0642 (1466.0387) lr 1.5567e-04 eta 0:02:29
epoch [43/50] batch [160/160] time 0.150 (0.128) data 0.000 (0.002) loss 0.9436 (0.9185) teacher_loss 0.0536 (0.0971) loss_zs_kd 0.1021 (0.0733) loss_oracle 0.6843 (0.5766) kd_loss 0.9936 (0.9929) acc 100.0000 (97.3242) gate/entropy 1.0802 (1.0803) gate/usage_max 0.4228 (0.4226) gate/usage_min 0.2714 (0.2716) gate/usage_std 0.0648 (0.0647) teacher/entropy 0.0248 (0.0362) teacher/usage_max 0.5222 (0.5564) teacher/usage_min 0.0307 (0.0266) teacher/usage_std 0.2162 (0.2280) nleep/row_max_mean 1494.0212 (1494.9469) nleep/row_max_std 64.9274 (59.2406) nleep/row_min_mean 1463.5602 (1466.1219) lr 1.2369e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,915
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [44/50] batch [20/160] time 0.100 (0.117) data 0.000 (0.014) loss 0.8654 (0.9246) teacher_loss 0.0360 (0.0938) loss_zs_kd 0.0799 (0.0747) loss_oracle 0.5780 (0.5864) kd_loss 1.0011 (1.0004) acc 100.0000 (97.5000) gate/entropy 1.0803 (1.0802) gate/usage_max 0.4226 (0.4229) gate/usage_min 0.2713 (0.2713) gate/usage_std 0.0647 (0.0649) teacher/entropy 0.0341 (0.0289) teacher/usage_max 0.5347 (0.5497) teacher/usage_min 0.0045 (0.0290) teacher/usage_std 0.2345 (0.2248) nleep/row_max_mean 1489.3137 (1492.3120) nleep/row_max_std 58.8412 (58.9212) nleep/row_min_mean 1460.6558 (1463.6186) lr 1.2369e-04 eta 0:02:08
epoch [44/50] batch [40/160] time 0.086 (0.112) data 0.000 (0.007) loss 0.9819 (0.9351) teacher_loss 0.1484 (0.1047) loss_zs_kd 0.0875 (0.0756) loss_oracle 0.5971 (0.5825) kd_loss 0.9824 (1.0027) acc 96.8750 (97.1875) gate/entropy 1.0801 (1.0802) gate/usage_max 0.4231 (0.4230) gate/usage_min 0.2711 (0.2712) gate/usage_std 0.0650 (0.0649) teacher/entropy 0.0288 (0.0329) teacher/usage_max 0.5425 (0.5555) teacher/usage_min 0.0307 (0.0271) teacher/usage_std 0.2192 (0.2265) nleep/row_max_mean 1486.9337 (1491.7833) nleep/row_max_std 69.8468 (60.9248) nleep/row_min_mean 1459.6205 (1463.4681) lr 1.2369e-04 eta 0:02:01
epoch [44/50] batch [60/160] time 0.159 (0.107) data 0.001 (0.005) loss 0.9848 (0.9360) teacher_loss 0.1617 (0.1066) loss_zs_kd 0.0692 (0.0738) loss_oracle 0.5676 (0.5850) kd_loss 1.0096 (1.0000) acc 96.8750 (97.1875) gate/entropy 1.0801 (1.0801) gate/usage_max 0.4232 (0.4230) gate/usage_min 0.2711 (0.2712) gate/usage_std 0.0651 (0.0650) teacher/entropy 0.0283 (0.0350) teacher/usage_max 0.4998 (0.5512) teacher/usage_min 0.0359 (0.0295) teacher/usage_std 0.2108 (0.2247) nleep/row_max_mean 1491.3846 (1492.3905) nleep/row_max_std 64.2763 (60.6008) nleep/row_min_mean 1462.6521 (1464.1876) lr 1.2369e-04 eta 0:01:53
epoch [44/50] batch [80/160] time 0.142 (0.110) data 0.000 (0.004) loss 0.8654 (0.9344) teacher_loss 0.0250 (0.1063) loss_zs_kd 0.0729 (0.0739) loss_oracle 0.6176 (0.5829) kd_loss 0.9902 (0.9993) acc 100.0000 (97.2656) gate/entropy 1.0800 (1.0801) gate/usage_max 0.4232 (0.4230) gate/usage_min 0.2710 (0.2712) gate/usage_std 0.0651 (0.0650) teacher/entropy 0.0424 (0.0356) teacher/usage_max 0.5039 (0.5488) teacher/usage_min 0.0236 (0.0297) teacher/usage_std 0.2194 (0.2244) nleep/row_max_mean 1506.6191 (1492.1860) nleep/row_max_std 58.7320 (61.1834) nleep/row_min_mean 1475.7751 (1464.0172) lr 1.2369e-04 eta 0:01:54
epoch [44/50] batch [100/160] time 0.118 (0.113) data 0.000 (0.003) loss 0.8260 (0.9307) teacher_loss 0.0512 (0.1052) loss_zs_kd 0.0530 (0.0737) loss_oracle 0.4952 (0.5789) kd_loss 1.0015 (0.9985) acc 100.0000 (97.2812) gate/entropy 1.0800 (1.0801) gate/usage_max 0.4233 (0.4230) gate/usage_min 0.2710 (0.2711) gate/usage_std 0.0652 (0.0650) teacher/entropy 0.0215 (0.0355) teacher/usage_max 0.4986 (0.5491) teacher/usage_min 0.0028 (0.0306) teacher/usage_std 0.2337 (0.2239) nleep/row_max_mean 1499.7681 (1493.1437) nleep/row_max_std 39.4422 (59.3666) nleep/row_min_mean 1472.3420 (1464.8301) lr 1.2369e-04 eta 0:01:55
epoch [44/50] batch [120/160] time 0.130 (0.117) data 0.000 (0.003) loss 0.8586 (0.9266) teacher_loss 0.0373 (0.1013) loss_zs_kd 0.0718 (0.0727) loss_oracle 0.5707 (0.5791) kd_loss 1.0002 (0.9989) acc 100.0000 (97.4219) gate/entropy 1.0799 (1.0801) gate/usage_max 0.4235 (0.4231) gate/usage_min 0.2707 (0.2711) gate/usage_std 0.0653 (0.0650) teacher/entropy 0.0158 (0.0356) teacher/usage_max 0.5272 (0.5485) teacher/usage_min 0.0314 (0.0301) teacher/usage_std 0.2164 (0.2239) nleep/row_max_mean 1501.5364 (1493.1106) nleep/row_max_std 61.9120 (58.8938) nleep/row_min_mean 1473.1536 (1464.8698) lr 1.2369e-04 eta 0:01:56
epoch [44/50] batch [140/160] time 0.129 (0.119) data 0.000 (0.002) loss 0.9179 (0.9216) teacher_loss 0.0745 (0.0975) loss_zs_kd 0.1068 (0.0731) loss_oracle 0.5824 (0.5760) kd_loss 0.9976 (0.9992) acc 100.0000 (97.5670) gate/entropy 1.0801 (1.0801) gate/usage_max 0.4231 (0.4231) gate/usage_min 0.2709 (0.2711) gate/usage_std 0.0651 (0.0650) teacher/entropy 0.0663 (0.0348) teacher/usage_max 0.5872 (0.5479) teacher/usage_min 0.0319 (0.0284) teacher/usage_std 0.2292 (0.2246) nleep/row_max_mean 1487.7698 (1493.3607) nleep/row_max_std 48.2547 (57.9045) nleep/row_min_mean 1463.1882 (1465.2303) lr 1.2369e-04 eta 0:01:56
epoch [44/50] batch [160/160] time 0.128 (0.121) data 0.000 (0.002) loss 1.2111 (0.9238) teacher_loss 0.3435 (0.0999) loss_zs_kd 0.0827 (0.0733) loss_oracle 0.7075 (0.5776) kd_loss 0.9450 (0.9968) acc 90.6250 (97.4219) gate/entropy 1.0801 (1.0801) gate/usage_max 0.4231 (0.4231) gate/usage_min 0.2709 (0.2711) gate/usage_std 0.0651 (0.0651) teacher/entropy 0.0696 (0.0363) teacher/usage_max 0.5595 (0.5449) teacher/usage_min 0.1060 (0.0299) teacher/usage_std 0.1852 (0.2232) nleep/row_max_mean 1488.5317 (1493.0248) nleep/row_max_std 68.0440 (58.1111) nleep/row_min_mean 1458.5436 (1464.9194) lr 9.5173e-05 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,807
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,914
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [45/50] batch [20/160] time 0.121 (0.155) data 0.000 (0.015) loss 0.9334 (0.8985) teacher_loss 0.1137 (0.0810) loss_zs_kd 0.0691 (0.0714) loss_oracle 0.6013 (0.5754) kd_loss 0.9690 (0.9881) acc 96.8750 (97.8125) gate/entropy 1.0800 (1.0800) gate/usage_max 0.4234 (0.4234) gate/usage_min 0.2708 (0.2708) gate/usage_std 0.0653 (0.0653) teacher/entropy 0.0194 (0.0396) teacher/usage_max 0.6011 (0.5571) teacher/usage_min 0.0000 (0.0326) teacher/usage_std 0.2497 (0.2241) nleep/row_max_mean 1505.8591 (1492.1716) nleep/row_max_std 28.6214 (62.4118) nleep/row_min_mean 1478.3635 (1464.4279) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [40/160] time 0.098 (0.142) data 0.001 (0.008) loss 0.9945 (0.9075) teacher_loss 0.1606 (0.0872) loss_zs_kd 0.0610 (0.0729) loss_oracle 0.6264 (0.5768) kd_loss 0.9805 (0.9910) acc 93.7500 (97.7344) gate/entropy 1.0799 (1.0800) gate/usage_max 0.4236 (0.4234) gate/usage_min 0.2706 (0.2708) gate/usage_std 0.0654 (0.0653) teacher/entropy 0.0683 (0.0399) teacher/usage_max 0.5266 (0.5597) teacher/usage_min 0.0444 (0.0325) teacher/usage_std 0.2082 (0.2244) nleep/row_max_mean 1490.3396 (1493.9460) nleep/row_max_std 71.7655 (59.6911) nleep/row_min_mean 1464.1157 (1465.9657) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [60/160] time 0.149 (0.124) data 0.001 (0.005) loss 0.8594 (0.9176) teacher_loss 0.0789 (0.0939) loss_zs_kd 0.0654 (0.0748) loss_oracle 0.5290 (0.5798) kd_loss 0.9667 (0.9929) acc 96.8750 (97.6042) gate/entropy 1.0798 (1.0800) gate/usage_max 0.4238 (0.4234) gate/usage_min 0.2706 (0.2707) gate/usage_std 0.0655 (0.0653) teacher/entropy 0.0296 (0.0401) teacher/usage_max 0.5868 (0.5533) teacher/usage_min 0.0324 (0.0342) teacher/usage_std 0.2288 (0.2220) nleep/row_max_mean 1484.0195 (1493.9369) nleep/row_max_std 75.9376 (60.5380) nleep/row_min_mean 1457.3323 (1465.8466) lr 9.5173e-05 eta 0:01:51
epoch [45/50] batch [80/160] time 0.149 (0.117) data 0.000 (0.004) loss 0.8907 (0.9222) teacher_loss 0.0505 (0.0950) loss_zs_kd 0.0778 (0.0746) loss_oracle 0.5597 (0.5851) kd_loss 1.0428 (0.9947) acc 96.8750 (97.5391) gate/entropy 1.0800 (1.0799) gate/usage_max 0.4234 (0.4234) gate/usage_min 0.2707 (0.2707) gate/usage_std 0.0653 (0.0653) teacher/entropy 0.0143 (0.0378) teacher/usage_max 0.5311 (0.5555) teacher/usage_min 0.0577 (0.0344) teacher/usage_std 0.2010 (0.2223) nleep/row_max_mean 1498.9185 (1494.0169) nleep/row_max_std 24.0163 (59.6625) nleep/row_min_mean 1474.6350 (1465.9456) lr 9.5173e-05 eta 0:01:43
epoch [45/50] batch [100/160] time 0.077 (0.113) data 0.000 (0.003) loss 0.9717 (0.9265) teacher_loss 0.1487 (0.0995) loss_zs_kd 0.0728 (0.0745) loss_oracle 0.5686 (0.5856) kd_loss 1.0046 (0.9938) acc 96.8750 (97.3750) gate/entropy 1.0798 (1.0799) gate/usage_max 0.4237 (0.4235) gate/usage_min 0.2705 (0.2707) gate/usage_std 0.0655 (0.0653) teacher/entropy 0.0463 (0.0376) teacher/usage_max 0.5008 (0.5552) teacher/usage_min 0.0676 (0.0328) teacher/usage_std 0.1900 (0.2229) nleep/row_max_mean 1475.4150 (1493.9077) nleep/row_max_std 91.9345 (59.8816) nleep/row_min_mean 1450.2395 (1465.9005) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [120/160] time 0.081 (0.109) data 0.000 (0.003) loss 0.8770 (0.9235) teacher_loss 0.0924 (0.0973) loss_zs_kd 0.0789 (0.0745) loss_oracle 0.5336 (0.5821) kd_loss 0.9569 (0.9958) acc 96.8750 (97.3958) gate/entropy 1.0799 (1.0799) gate/usage_max 0.4236 (0.4235) gate/usage_min 0.2706 (0.2707) gate/usage_std 0.0654 (0.0653) teacher/entropy 0.0511 (0.0375) teacher/usage_max 0.5566 (0.5566) teacher/usage_min 0.0462 (0.0329) teacher/usage_std 0.2132 (0.2233) nleep/row_max_mean 1490.6729 (1493.9592) nleep/row_max_std 51.5872 (59.7590) nleep/row_min_mean 1464.9904 (1466.0284) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [140/160] time 0.088 (0.108) data 0.001 (0.002) loss 0.8962 (0.9186) teacher_loss 0.0916 (0.0937) loss_zs_kd 0.0594 (0.0734) loss_oracle 0.5366 (0.5816) kd_loss 1.0131 (0.9948) acc 100.0000 (97.5446) gate/entropy 1.0800 (1.0799) gate/usage_max 0.4233 (0.4235) gate/usage_min 0.2707 (0.2707) gate/usage_std 0.0652 (0.0654) teacher/entropy 0.0216 (0.0381) teacher/usage_max 0.5001 (0.5535) teacher/usage_min 0.0300 (0.0327) teacher/usage_std 0.2148 (0.2229) nleep/row_max_mean 1506.4662 (1494.3091) nleep/row_max_std 23.7653 (59.2868) nleep/row_min_mean 1477.6600 (1466.3769) lr 9.5173e-05 eta 0:01:28
epoch [45/50] batch [160/160] time 0.078 (0.107) data 0.000 (0.002) loss 0.9409 (0.9186) teacher_loss 0.1214 (0.0943) loss_zs_kd 0.0764 (0.0731) loss_oracle 0.5389 (0.5787) kd_loss 1.0237 (0.9967) acc 96.8750 (97.5781) gate/entropy 1.0798 (1.0799) gate/usage_max 0.4237 (0.4235) gate/usage_min 0.2704 (0.2706) gate/usage_std 0.0655 (0.0654) teacher/entropy 0.0241 (0.0372) teacher/usage_max 0.4686 (0.5517) teacher/usage_min 0.0826 (0.0325) teacher/usage_std 0.1775 (0.2227) nleep/row_max_mean 1509.3270 (1494.3666) nleep/row_max_std 33.5363 (58.9486) nleep/row_min_mean 1479.5151 (1466.4148) lr 7.0224e-05 eta 0:01:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,917
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [46/50] batch [20/160] time 0.135 (0.119) data 0.000 (0.013) loss 1.2297 (0.9552) teacher_loss 0.4262 (0.1308) loss_zs_kd 0.0706 (0.0746) loss_oracle 0.5632 (0.5773) kd_loss 0.9731 (0.9968) acc 87.5000 (96.4062) gate/entropy 1.0798 (1.0798) gate/usage_max 0.4237 (0.4237) gate/usage_min 0.2704 (0.2704) gate/usage_std 0.0655 (0.0655) teacher/entropy 0.0430 (0.0417) teacher/usage_max 0.5192 (0.5512) teacher/usage_min 0.0161 (0.0387) teacher/usage_std 0.2254 (0.2197) nleep/row_max_mean 1490.4711 (1492.4427) nleep/row_max_std 67.4223 (62.9547) nleep/row_min_mean 1461.1340 (1464.8192) lr 7.0224e-05 eta 0:01:32
epoch [46/50] batch [40/160] time 0.114 (0.109) data 0.000 (0.007) loss 0.7951 (0.9538) teacher_loss 0.0387 (0.1372) loss_zs_kd 0.0761 (0.0737) loss_oracle 0.4331 (0.5635) kd_loss 1.0037 (0.9961) acc 100.0000 (96.3281) gate/entropy 1.0798 (1.0798) gate/usage_max 0.4238 (0.4237) gate/usage_min 0.2704 (0.2704) gate/usage_std 0.0656 (0.0655) teacher/entropy 0.0480 (0.0425) teacher/usage_max 0.5222 (0.5438) teacher/usage_min 0.0538 (0.0368) teacher/usage_std 0.2017 (0.2191) nleep/row_max_mean 1498.4706 (1493.3081) nleep/row_max_std 61.6658 (60.7962) nleep/row_min_mean 1471.8206 (1465.8324) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [60/160] time 0.116 (0.115) data 0.001 (0.005) loss 0.8656 (0.9360) teacher_loss 0.0480 (0.1182) loss_zs_kd 0.0682 (0.0722) loss_oracle 0.5942 (0.5679) kd_loss 0.9728 (0.9956) acc 96.8750 (96.7708) gate/entropy 1.0798 (1.0798) gate/usage_max 0.4238 (0.4237) gate/usage_min 0.2703 (0.2704) gate/usage_std 0.0656 (0.0655) teacher/entropy 0.0541 (0.0410) teacher/usage_max 0.4915 (0.5534) teacher/usage_min 0.0323 (0.0345) teacher/usage_std 0.2130 (0.2232) nleep/row_max_mean 1488.2480 (1493.4699) nleep/row_max_std 66.1565 (60.7809) nleep/row_min_mean 1461.3196 (1465.9264) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [80/160] time 0.131 (0.119) data 0.000 (0.004) loss 0.9353 (0.9317) teacher_loss 0.0656 (0.1104) loss_zs_kd 0.0652 (0.0722) loss_oracle 0.6377 (0.5738) kd_loss 1.0368 (0.9965) acc 100.0000 (96.9531) gate/entropy 1.0799 (1.0798) gate/usage_max 0.4236 (0.4237) gate/usage_min 0.2705 (0.2704) gate/usage_std 0.0654 (0.0655) teacher/entropy 0.0072 (0.0404) teacher/usage_max 0.5302 (0.5540) teacher/usage_min 0.0317 (0.0349) teacher/usage_std 0.2165 (0.2231) nleep/row_max_mean 1488.7178 (1493.0142) nleep/row_max_std 53.8274 (61.3100) nleep/row_min_mean 1461.9478 (1465.4683) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [100/160] time 0.141 (0.123) data 0.000 (0.003) loss 0.8852 (0.9238) teacher_loss 0.0432 (0.1014) loss_zs_kd 0.0661 (0.0715) loss_oracle 0.5920 (0.5731) kd_loss 1.0261 (1.0003) acc 96.8750 (97.1562) gate/entropy 1.0798 (1.0798) gate/usage_max 0.4238 (0.4237) gate/usage_min 0.2704 (0.2704) gate/usage_std 0.0656 (0.0655) teacher/entropy 0.0552 (0.0384) teacher/usage_max 0.6320 (0.5577) teacher/usage_min 0.0400 (0.0340) teacher/usage_std 0.2417 (0.2246) nleep/row_max_mean 1494.8788 (1492.9213) nleep/row_max_std 65.8873 (61.1537) nleep/row_min_mean 1466.1824 (1465.3554) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [120/160] time 0.124 (0.125) data 0.000 (0.002) loss 1.0795 (0.9248) teacher_loss 0.2508 (0.1021) loss_zs_kd 0.0889 (0.0733) loss_oracle 0.5696 (0.5721) kd_loss 0.9989 (1.0000) acc 93.7500 (97.1615) gate/entropy 1.0797 (1.0798) gate/usage_max 0.4239 (0.4237) gate/usage_min 0.2703 (0.2704) gate/usage_std 0.0657 (0.0656) teacher/entropy 0.0634 (0.0372) teacher/usage_max 0.5465 (0.5555) teacher/usage_min 0.0601 (0.0332) teacher/usage_std 0.2031 (0.2243) nleep/row_max_mean 1493.0034 (1493.6393) nleep/row_max_std 56.7759 (60.5166) nleep/row_min_mean 1468.2273 (1466.0069) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [140/160] time 0.144 (0.127) data 0.000 (0.002) loss 0.8510 (0.9275) teacher_loss 0.0330 (0.1053) loss_zs_kd 0.0502 (0.0729) loss_oracle 0.5973 (0.5737) kd_loss 0.9883 (0.9979) acc 100.0000 (96.9196) gate/entropy 1.0798 (1.0798) gate/usage_max 0.4239 (0.4237) gate/usage_min 0.2704 (0.2704) gate/usage_std 0.0656 (0.0656) teacher/entropy 0.0177 (0.0370) teacher/usage_max 0.5668 (0.5567) teacher/usage_min 0.0585 (0.0337) teacher/usage_std 0.2096 (0.2240) nleep/row_max_mean 1492.0771 (1493.3755) nleep/row_max_std 68.9817 (60.8774) nleep/row_min_mean 1465.0593 (1465.7258) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [160/160] time 0.145 (0.128) data 0.000 (0.002) loss 0.8666 (0.9249) teacher_loss 0.0547 (0.1029) loss_zs_kd 0.0788 (0.0727) loss_oracle 0.6279 (0.5747) kd_loss 0.9171 (0.9967) acc 100.0000 (96.9141) gate/entropy 1.0797 (1.0798) gate/usage_max 0.4240 (0.4238) gate/usage_min 0.2703 (0.2703) gate/usage_std 0.0658 (0.0656) teacher/entropy 0.0578 (0.0367) teacher/usage_max 0.6508 (0.5573) teacher/usage_min 0.0319 (0.0333) teacher/usage_std 0.2529 (0.2245) nleep/row_max_mean 1488.9254 (1493.2704) nleep/row_max_std 66.0930 (60.3444) nleep/row_min_mean 1460.1411 (1465.6023) lr 4.8943e-05 eta 0:01:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,907
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 87.7%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [47/50] batch [20/160] time 0.083 (0.115) data 0.000 (0.016) loss 0.8419 (0.9057) teacher_loss 0.0531 (0.0809) loss_zs_kd 0.0614 (0.0718) loss_oracle 0.5301 (0.5770) kd_loss 0.9861 (1.0008) acc 96.8750 (97.3438) gate/entropy 1.0797 (1.0798) gate/usage_max 0.4239 (0.4238) gate/usage_min 0.2701 (0.2702) gate/usage_std 0.0657 (0.0656) teacher/entropy 0.0151 (0.0414) teacher/usage_max 0.5581 (0.5483) teacher/usage_min 0.0005 (0.0330) teacher/usage_std 0.2401 (0.2224) nleep/row_max_mean 1499.3300 (1489.8505) nleep/row_max_std 44.1945 (62.8385) nleep/row_min_mean 1472.9578 (1462.1977) lr 4.8943e-05 eta 0:01:11
epoch [47/50] batch [40/160] time 0.121 (0.109) data 0.000 (0.008) loss 0.8877 (0.9185) teacher_loss 0.0860 (0.0934) loss_zs_kd 0.0644 (0.0704) loss_oracle 0.5272 (0.5876) kd_loss 1.0118 (0.9922) acc 96.8750 (97.2656) gate/entropy 1.0797 (1.0797) gate/usage_max 0.4238 (0.4239) gate/usage_min 0.2701 (0.2702) gate/usage_std 0.0656 (0.0657) teacher/entropy 0.0362 (0.0428) teacher/usage_max 0.5839 (0.5415) teacher/usage_min 0.0002 (0.0335) teacher/usage_std 0.2454 (0.2205) nleep/row_max_mean 1497.6528 (1489.9111) nleep/row_max_std 48.1859 (62.0472) nleep/row_min_mean 1470.0770 (1462.3722) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [60/160] time 0.154 (0.111) data 0.001 (0.006) loss 0.8974 (0.9198) teacher_loss 0.0429 (0.0949) loss_zs_kd 0.0665 (0.0720) loss_oracle 0.6268 (0.5878) kd_loss 1.0158 (0.9899) acc 100.0000 (97.3438) gate/entropy 1.0797 (1.0797) gate/usage_max 0.4241 (0.4239) gate/usage_min 0.2702 (0.2702) gate/usage_std 0.0658 (0.0657) teacher/entropy 0.0117 (0.0428) teacher/usage_max 0.5025 (0.5407) teacher/usage_min 0.0608 (0.0343) teacher/usage_std 0.1946 (0.2200) nleep/row_max_mean 1496.6449 (1490.2363) nleep/row_max_std 56.5560 (61.3967) nleep/row_min_mean 1467.5693 (1462.6879) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [80/160] time 0.086 (0.108) data 0.000 (0.004) loss 1.0141 (0.9179) teacher_loss 0.1801 (0.0951) loss_zs_kd 0.0532 (0.0719) loss_oracle 0.6108 (0.5852) kd_loss 1.0041 (0.9886) acc 96.8750 (97.5000) gate/entropy 1.0797 (1.0797) gate/usage_max 0.4239 (0.4239) gate/usage_min 0.2701 (0.2702) gate/usage_std 0.0657 (0.0657) teacher/entropy 0.0614 (0.0426) teacher/usage_max 0.5739 (0.5448) teacher/usage_min 0.0480 (0.0343) teacher/usage_std 0.2170 (0.2207) nleep/row_max_mean 1484.5416 (1491.0592) nleep/row_max_std 77.0158 (58.8377) nleep/row_min_mean 1459.5051 (1463.5347) lr 4.8943e-05 eta 0:01:00
epoch [47/50] batch [100/160] time 0.083 (0.109) data 0.000 (0.003) loss 0.9204 (0.9209) teacher_loss 0.0779 (0.0966) loss_zs_kd 0.0714 (0.0745) loss_oracle 0.6137 (0.5836) kd_loss 0.9999 (0.9905) acc 100.0000 (97.5000) gate/entropy 1.0796 (1.0797) gate/usage_max 0.4243 (0.4239) gate/usage_min 0.2700 (0.2702) gate/usage_std 0.0659 (0.0657) teacher/entropy 0.0336 (0.0413) teacher/usage_max 0.5013 (0.5459) teacher/usage_min 0.0283 (0.0348) teacher/usage_std 0.2161 (0.2205) nleep/row_max_mean 1493.5907 (1490.5105) nleep/row_max_std 64.6735 (59.5062) nleep/row_min_mean 1466.9905 (1463.1457) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [120/160] time 0.106 (0.109) data 0.000 (0.003) loss 1.0402 (0.9204) teacher_loss 0.1633 (0.0945) loss_zs_kd 0.0966 (0.0747) loss_oracle 0.6288 (0.5844) kd_loss 1.0285 (0.9927) acc 96.8750 (97.5260) gate/entropy 1.0796 (1.0797) gate/usage_max 0.4242 (0.4239) gate/usage_min 0.2700 (0.2701) gate/usage_std 0.0659 (0.0657) teacher/entropy 0.0012 (0.0400) teacher/usage_max 0.5311 (0.5438) teacher/usage_min 0.0002 (0.0361) teacher/usage_std 0.2369 (0.2192) nleep/row_max_mean 1503.0989 (1490.5566) nleep/row_max_std 42.3865 (59.6252) nleep/row_min_mean 1472.0585 (1463.1757) lr 4.8943e-05 eta 0:00:56
epoch [47/50] batch [140/160] time 0.098 (0.109) data 0.000 (0.003) loss 0.8485 (0.9178) teacher_loss 0.0469 (0.0934) loss_zs_kd 0.0927 (0.0749) loss_oracle 0.5271 (0.5793) kd_loss 0.9834 (0.9945) acc 100.0000 (97.5223) gate/entropy 1.0796 (1.0797) gate/usage_max 0.4241 (0.4240) gate/usage_min 0.2700 (0.2701) gate/usage_std 0.0658 (0.0657) teacher/entropy 0.0533 (0.0396) teacher/usage_max 0.4829 (0.5452) teacher/usage_min 0.0486 (0.0353) teacher/usage_std 0.2014 (0.2202) nleep/row_max_mean 1490.8320 (1491.1697) nleep/row_max_std 64.6577 (59.2518) nleep/row_min_mean 1465.3867 (1463.8314) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [160/160] time 0.078 (0.106) data 0.000 (0.002) loss 1.0777 (0.9214) teacher_loss 0.2580 (0.0974) loss_zs_kd 0.0823 (0.0746) loss_oracle 0.5377 (0.5787) kd_loss 1.0193 (0.9946) acc 90.6250 (97.4023) gate/entropy 1.0798 (1.0797) gate/usage_max 0.4237 (0.4240) gate/usage_min 0.2703 (0.2701) gate/usage_std 0.0655 (0.0657) teacher/entropy 0.0483 (0.0403) teacher/usage_max 0.5881 (0.5471) teacher/usage_min 0.0412 (0.0363) teacher/usage_std 0.2248 (0.2205) nleep/row_max_mean 1477.4458 (1491.3058) nleep/row_max_std 73.9310 (59.5574) nleep/row_min_mean 1450.6689 (1463.9334) lr 3.1417e-05 eta 0:00:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,914
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [48/50] batch [20/160] time 0.135 (0.147) data 0.000 (0.013) loss 0.8887 (0.9551) teacher_loss 0.0569 (0.1192) loss_zs_kd 0.0740 (0.0746) loss_oracle 0.5409 (0.5887) kd_loss 1.0486 (1.0085) acc 100.0000 (96.7188) gate/entropy 1.0797 (1.0797) gate/usage_max 0.4239 (0.4241) gate/usage_min 0.2701 (0.2700) gate/usage_std 0.0657 (0.0658) teacher/entropy 0.0230 (0.0350) teacher/usage_max 0.6144 (0.5422) teacher/usage_min 0.0314 (0.0436) teacher/usage_std 0.2385 (0.2149) nleep/row_max_mean 1498.9259 (1490.1774) nleep/row_max_std 42.6492 (65.4123) nleep/row_min_mean 1473.8267 (1462.7568) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [40/160] time 0.131 (0.142) data 0.000 (0.007) loss 0.8803 (0.9324) teacher_loss 0.0459 (0.1030) loss_zs_kd 0.0840 (0.0752) loss_oracle 0.5529 (0.5775) kd_loss 1.0318 (1.0060) acc 100.0000 (97.4219) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4241) gate/usage_min 0.2700 (0.2700) gate/usage_std 0.0658 (0.0658) teacher/entropy 0.0243 (0.0349) teacher/usage_max 0.5637 (0.5523) teacher/usage_min 0.0340 (0.0406) teacher/usage_std 0.2217 (0.2185) nleep/row_max_mean 1497.0129 (1492.7636) nleep/row_max_std 65.9249 (62.6306) nleep/row_min_mean 1466.9043 (1465.0116) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [60/160] time 0.128 (0.141) data 0.001 (0.005) loss 0.9162 (0.9272) teacher_loss 0.1190 (0.1036) loss_zs_kd 0.0988 (0.0739) loss_oracle 0.5422 (0.5715) kd_loss 0.9534 (1.0018) acc 93.7500 (97.1354) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4242 (0.4241) gate/usage_min 0.2699 (0.2700) gate/usage_std 0.0659 (0.0658) teacher/entropy 0.0746 (0.0373) teacher/usage_max 0.4956 (0.5543) teacher/usage_min 0.0514 (0.0382) teacher/usage_std 0.2001 (0.2207) nleep/row_max_mean 1501.5181 (1493.0628) nleep/row_max_std 69.8737 (61.4961) nleep/row_min_mean 1473.7244 (1465.3916) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [80/160] time 0.145 (0.140) data 0.000 (0.003) loss 0.8766 (0.9238) teacher_loss 0.0560 (0.1009) loss_zs_kd 0.0804 (0.0727) loss_oracle 0.5834 (0.5751) kd_loss 0.9774 (0.9981) acc 100.0000 (97.1875) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4241 (0.4241) gate/usage_min 0.2700 (0.2700) gate/usage_std 0.0658 (0.0658) teacher/entropy 0.0022 (0.0382) teacher/usage_max 0.6248 (0.5458) teacher/usage_min 0.0001 (0.0396) teacher/usage_std 0.2567 (0.2178) nleep/row_max_mean 1505.9609 (1493.4404) nleep/row_max_std 24.1872 (60.8271) nleep/row_min_mean 1475.5411 (1465.7199) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [100/160] time 0.129 (0.140) data 0.000 (0.003) loss 0.9046 (0.9185) teacher_loss 0.1185 (0.0954) loss_zs_kd 0.0760 (0.0726) loss_oracle 0.4980 (0.5765) kd_loss 0.9981 (0.9970) acc 96.8750 (97.4688) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4241 (0.4241) gate/usage_min 0.2699 (0.2700) gate/usage_std 0.0658 (0.0658) teacher/entropy 0.0405 (0.0371) teacher/usage_max 0.5133 (0.5485) teacher/usage_min 0.0316 (0.0372) teacher/usage_std 0.2147 (0.2198) nleep/row_max_mean 1504.5745 (1494.5214) nleep/row_max_std 48.2823 (59.4094) nleep/row_min_mean 1477.1926 (1466.6806) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [120/160] time 0.112 (0.139) data 0.000 (0.002) loss 0.8306 (0.9162) teacher_loss 0.0232 (0.0922) loss_zs_kd 0.0673 (0.0724) loss_oracle 0.5393 (0.5790) kd_loss 1.0083 (0.9965) acc 100.0000 (97.5521) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4243 (0.4241) gate/usage_min 0.2698 (0.2700) gate/usage_std 0.0660 (0.0658) teacher/entropy 0.0427 (0.0379) teacher/usage_max 0.5705 (0.5474) teacher/usage_min 0.0183 (0.0369) teacher/usage_std 0.2321 (0.2195) nleep/row_max_mean 1516.6196 (1493.7745) nleep/row_max_std 22.8477 (59.8660) nleep/row_min_mean 1487.0505 (1465.9811) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [140/160] time 0.144 (0.137) data 0.000 (0.002) loss 0.9558 (0.9163) teacher_loss 0.1058 (0.0925) loss_zs_kd 0.0827 (0.0724) loss_oracle 0.6202 (0.5784) kd_loss 0.9970 (0.9967) acc 96.8750 (97.5446) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4241) gate/usage_min 0.2700 (0.2700) gate/usage_std 0.0658 (0.0658) teacher/entropy 0.0685 (0.0379) teacher/usage_max 0.4861 (0.5476) teacher/usage_min 0.1106 (0.0363) teacher/usage_std 0.1611 (0.2199) nleep/row_max_mean 1478.7925 (1493.5542) nleep/row_max_std 79.0655 (60.2019) nleep/row_min_mean 1454.8564 (1465.7876) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [160/160] time 0.127 (0.137) data 0.000 (0.002) loss 0.9455 (0.9183) teacher_loss 0.1379 (0.0960) loss_zs_kd 0.0765 (0.0725) loss_oracle 0.5126 (0.5770) kd_loss 1.0263 (0.9950) acc 93.7500 (97.4219) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4243 (0.4241) gate/usage_min 0.2698 (0.2700) gate/usage_std 0.0660 (0.0658) teacher/entropy 0.0231 (0.0394) teacher/usage_max 0.5619 (0.5456) teacher/usage_min 0.0208 (0.0380) teacher/usage_std 0.2287 (0.2186) nleep/row_max_mean 1493.4500 (1493.5961) nleep/row_max_std 61.5095 (60.3067) nleep/row_min_mean 1466.3101 (1465.7956) lr 1.7713e-05 eta 0:00:43
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,911
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [49/50] batch [20/160] time 0.152 (0.111) data 0.000 (0.016) loss 1.0230 (0.9004) teacher_loss 0.1942 (0.0916) loss_zs_kd 0.0862 (0.0692) loss_oracle 0.5673 (0.5641) kd_loss 1.0043 (0.9844) acc 96.8750 (97.9688) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4243 (0.4241) gate/usage_min 0.2697 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0437 (0.0539) teacher/usage_max 0.5533 (0.5328) teacher/usage_min 0.0225 (0.0355) teacher/usage_std 0.2260 (0.2174) nleep/row_max_mean 1482.8832 (1492.1574) nleep/row_max_std 76.3810 (61.7180) nleep/row_min_mean 1456.4935 (1464.8910) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [40/160] time 0.172 (0.112) data 0.000 (0.008) loss 0.8658 (0.9169) teacher_loss 0.0377 (0.0978) loss_zs_kd 0.0818 (0.0716) loss_oracle 0.5575 (0.5716) kd_loss 1.0168 (0.9949) acc 100.0000 (97.6562) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4241 (0.4242) gate/usage_min 0.2700 (0.2699) gate/usage_std 0.0659 (0.0659) teacher/entropy 0.0312 (0.0460) teacher/usage_max 0.5822 (0.5359) teacher/usage_min 0.0020 (0.0440) teacher/usage_std 0.2439 (0.2135) nleep/row_max_mean 1495.3982 (1492.7382) nleep/row_max_std 49.8247 (62.8006) nleep/row_min_mean 1466.6219 (1465.1317) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [60/160] time 0.084 (0.113) data 0.001 (0.005) loss 1.0830 (0.9126) teacher_loss 0.2547 (0.0939) loss_zs_kd 0.0865 (0.0720) loss_oracle 0.5795 (0.5708) kd_loss 0.9906 (0.9947) acc 93.7500 (97.6562) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4243 (0.4242) gate/usage_min 0.2698 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0575 (0.0426) teacher/usage_max 0.5346 (0.5500) teacher/usage_min 0.0364 (0.0421) teacher/usage_std 0.2143 (0.2185) nleep/row_max_mean 1480.6476 (1492.9521) nleep/row_max_std 71.0570 (61.4193) nleep/row_min_mean 1455.7520 (1465.1866) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [80/160] time 0.091 (0.106) data 0.000 (0.004) loss 0.8380 (0.9104) teacher_loss 0.0656 (0.0950) loss_zs_kd 0.0593 (0.0730) loss_oracle 0.5182 (0.5667) kd_loss 0.9673 (0.9912) acc 96.8750 (97.4219) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4244 (0.4242) gate/usage_min 0.2699 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0497 (0.0433) teacher/usage_max 0.5118 (0.5542) teacher/usage_min 0.0049 (0.0388) teacher/usage_std 0.2325 (0.2213) nleep/row_max_mean 1508.3784 (1493.3315) nleep/row_max_std 24.9389 (58.1701) nleep/row_min_mean 1481.7021 (1465.5525) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [100/160] time 0.161 (0.106) data 0.000 (0.003) loss 0.9634 (0.9180) teacher_loss 0.1292 (0.1019) loss_zs_kd 0.0879 (0.0727) loss_oracle 0.6240 (0.5689) kd_loss 0.9565 (0.9906) acc 93.7500 (97.1562) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4242) gate/usage_min 0.2699 (0.2699) gate/usage_std 0.0658 (0.0659) teacher/entropy 0.0142 (0.0413) teacher/usage_max 0.6533 (0.5540) teacher/usage_min 0.0010 (0.0378) teacher/usage_std 0.2664 (0.2216) nleep/row_max_mean 1496.0999 (1493.6086) nleep/row_max_std 52.3383 (57.2216) nleep/row_min_mean 1469.0139 (1465.9632) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [120/160] time 0.094 (0.106) data 0.000 (0.003) loss 1.0211 (0.9216) teacher_loss 0.1145 (0.1022) loss_zs_kd 0.0658 (0.0725) loss_oracle 0.7401 (0.5732) kd_loss 1.0073 (0.9930) acc 96.8750 (97.1615) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4242) gate/usage_min 0.2700 (0.2699) gate/usage_std 0.0658 (0.0659) teacher/entropy 0.0479 (0.0399) teacher/usage_max 0.4983 (0.5554) teacher/usage_min 0.0782 (0.0377) teacher/usage_std 0.1830 (0.2217) nleep/row_max_mean 1472.1315 (1493.1310) nleep/row_max_std 89.4134 (57.7583) nleep/row_min_mean 1443.7844 (1465.4953) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [140/160] time 0.077 (0.107) data 0.000 (0.002) loss 0.9470 (0.9209) teacher_loss 0.1223 (0.1024) loss_zs_kd 0.0779 (0.0723) loss_oracle 0.5963 (0.5710) kd_loss 0.9752 (0.9936) acc 96.8750 (97.0536) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4242 (0.4242) gate/usage_min 0.2696 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0434 (0.0402) teacher/usage_max 0.5212 (0.5560) teacher/usage_min 0.0440 (0.0379) teacher/usage_std 0.2076 (0.2218) nleep/row_max_mean 1494.0275 (1493.0883) nleep/row_max_std 64.5012 (57.7187) nleep/row_min_mean 1465.6202 (1465.4703) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [160/160] time 0.141 (0.107) data 0.000 (0.002) loss 0.9632 (0.9208) teacher_loss 0.1623 (0.1015) loss_zs_kd 0.0875 (0.0724) loss_oracle 0.4948 (0.5709) kd_loss 1.0196 (0.9952) acc 93.7500 (97.1094) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4239 (0.4242) gate/usage_min 0.2699 (0.2699) gate/usage_std 0.0657 (0.0659) teacher/entropy 0.0589 (0.0391) teacher/usage_max 0.6312 (0.5543) teacher/usage_min 0.0355 (0.0381) teacher/usage_std 0.2432 (0.2213) nleep/row_max_mean 1486.6184 (1493.0912) nleep/row_max_std 57.1374 (57.3501) nleep/row_min_mean 1458.8048 (1465.5066) lr 7.8853e-06 eta 0:00:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,809
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,914
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
epoch [50/50] batch [20/160] time 0.138 (0.156) data 0.000 (0.017) loss 1.0266 (0.9290) teacher_loss 0.2221 (0.1122) loss_zs_kd 0.0602 (0.0722) loss_oracle 0.5594 (0.5770) kd_loss 0.9896 (0.9843) acc 93.7500 (96.2500) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4241) gate/usage_min 0.2698 (0.2699) gate/usage_std 0.0658 (0.0659) teacher/entropy 0.0271 (0.0539) teacher/usage_max 0.5098 (0.5534) teacher/usage_min 0.0002 (0.0357) teacher/usage_std 0.2357 (0.2230) nleep/row_max_mean 1484.1328 (1489.5564) nleep/row_max_std 65.2704 (60.3432) nleep/row_min_mean 1457.5427 (1462.3848) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [40/160] time 0.157 (0.149) data 0.000 (0.009) loss 0.8945 (0.9202) teacher_loss 0.0990 (0.1011) loss_zs_kd 0.0952 (0.0720) loss_oracle 0.5676 (0.5771) kd_loss 0.9283 (0.9892) acc 93.7500 (97.2656) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4242 (0.4242) gate/usage_min 0.2698 (0.2699) gate/usage_std 0.0659 (0.0659) teacher/entropy 0.0417 (0.0440) teacher/usage_max 0.6663 (0.5506) teacher/usage_min 0.0324 (0.0367) teacher/usage_std 0.2598 (0.2218) nleep/row_max_mean 1502.4824 (1491.1444) nleep/row_max_std 31.4521 (58.4684) nleep/row_min_mean 1471.0667 (1463.4288) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [60/160] time 0.150 (0.146) data 0.000 (0.006) loss 1.0309 (0.9168) teacher_loss 0.1960 (0.0948) loss_zs_kd 0.0626 (0.0717) loss_oracle 0.5878 (0.5802) kd_loss 1.0193 (0.9919) acc 93.7500 (97.6042) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4243 (0.4242) gate/usage_min 0.2698 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0376 (0.0419) teacher/usage_max 0.5327 (0.5460) teacher/usage_min 0.0586 (0.0360) teacher/usage_std 0.2008 (0.2206) nleep/row_max_mean 1472.7871 (1491.1196) nleep/row_max_std 92.4015 (58.8622) nleep/row_min_mean 1445.1964 (1463.5580) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [80/160] time 0.136 (0.144) data 0.000 (0.004) loss 0.8503 (0.9180) teacher_loss 0.0533 (0.0969) loss_zs_kd 0.0743 (0.0723) loss_oracle 0.5264 (0.5787) kd_loss 0.9932 (0.9911) acc 100.0000 (97.4219) gate/entropy 1.0796 (1.0796) gate/usage_max 0.4241 (0.4242) gate/usage_min 0.2698 (0.2699) gate/usage_std 0.0658 (0.0659) teacher/entropy 0.0617 (0.0416) teacher/usage_max 0.5638 (0.5451) teacher/usage_min 0.0301 (0.0350) teacher/usage_std 0.2239 (0.2209) nleep/row_max_mean 1480.9189 (1491.0305) nleep/row_max_std 72.1214 (59.0882) nleep/row_min_mean 1455.2166 (1463.4923) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [100/160] time 0.135 (0.143) data 0.000 (0.004) loss 0.9549 (0.9158) teacher_loss 0.1309 (0.0954) loss_zs_kd 0.0454 (0.0725) loss_oracle 0.6260 (0.5773) kd_loss 0.9766 (0.9910) acc 93.7500 (97.4375) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4243 (0.4242) gate/usage_min 0.2697 (0.2699) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0465 (0.0411) teacher/usage_max 0.5121 (0.5446) teacher/usage_min 0.0575 (0.0360) teacher/usage_std 0.1979 (0.2200) nleep/row_max_mean 1492.7144 (1491.4180) nleep/row_max_std 71.2338 (59.0734) nleep/row_min_mean 1463.1287 (1463.8729) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [120/160] time 0.098 (0.141) data 0.000 (0.003) loss 0.8650 (0.9134) teacher_loss 0.0353 (0.0949) loss_zs_kd 0.0599 (0.0725) loss_oracle 0.5828 (0.5730) kd_loss 1.0167 (0.9916) acc 100.0000 (97.5260) gate/entropy 1.0798 (1.0796) gate/usage_max 0.4237 (0.4242) gate/usage_min 0.2701 (0.2698) gate/usage_std 0.0656 (0.0659) teacher/entropy 0.0249 (0.0405) teacher/usage_max 0.4701 (0.5454) teacher/usage_min 0.0928 (0.0363) teacher/usage_std 0.1706 (0.2200) nleep/row_max_mean 1476.0748 (1491.7408) nleep/row_max_std 80.7878 (58.9001) nleep/row_min_mean 1448.9182 (1464.1640) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/160] time 0.080 (0.133) data 0.000 (0.003) loss 0.8496 (0.9118) teacher_loss 0.0264 (0.0926) loss_zs_kd 0.0702 (0.0727) loss_oracle 0.4833 (0.5725) kd_loss 1.0930 (0.9931) acc 100.0000 (97.5223) gate/entropy 1.0797 (1.0796) gate/usage_max 0.4240 (0.4242) gate/usage_min 0.2700 (0.2698) gate/usage_std 0.0658 (0.0659) teacher/entropy 0.0177 (0.0407) teacher/usage_max 0.7775 (0.5472) teacher/usage_min 0.0010 (0.0361) teacher/usage_std 0.3267 (0.2209) nleep/row_max_mean 1492.7173 (1491.9310) nleep/row_max_std 53.0114 (58.2931) nleep/row_min_mean 1467.2007 (1464.4780) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [160/160] time 0.151 (0.129) data 0.000 (0.002) loss 0.8688 (0.9134) teacher_loss 0.0347 (0.0936) loss_zs_kd 0.0823 (0.0723) loss_oracle 0.6233 (0.5755) kd_loss 0.9627 (0.9919) acc 100.0000 (97.4609) gate/entropy 1.0795 (1.0796) gate/usage_max 0.4243 (0.4242) gate/usage_min 0.2697 (0.2698) gate/usage_std 0.0660 (0.0659) teacher/entropy 0.0513 (0.0409) teacher/usage_max 0.5398 (0.5487) teacher/usage_min 0.0561 (0.0358) teacher/usage_std 0.2037 (0.2212) nleep/row_max_mean 1482.4222 (1491.9070) nleep/row_max_std 80.9079 (58.2532) nleep/row_min_mean 1455.0167 (1464.4070) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,809
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,914
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 13 *******
******* Domain p best val test acc: 86.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 16 *******
Checkpoint saved to icml/multi-dg/tuning/tuning/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:20:34
